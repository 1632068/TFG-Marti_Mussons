type,content,article_id
theorem,The approximate peak time for a small fluorescence lifetime satisfies   t^{p}_0 =  k^{-\frac{1}{2}}\lambda - \frac{7}{4}k^{-1} + \frac{\sqrt{k}}{\sqrt{k}+\beta\sqrt{vD}}k^{-1} + \ell + O\left(\lambda^{-1}\right) \quad \mbox{as} \quad \lambda \gg 1.,2502.01037
theorem,"The approximate peak time for a large fluorescence lifetime satisfies   t^{p}_\infty = (k-\ell^{-1})^{-\frac{1}{2}} \lambda + (k-\ell^{-1})^{-\frac{3}{4}} \alpha_\lambda \lambda^\frac{1}{2}  + O\left( \lambda^{-\frac{1}{2}} \right) \quad \mbox{as} \quad \lambda \gg 1,    where $\alpha_\lambda>0$ is   \alpha_\lambda := \left(-\log\left[ (\pi^{\frac{1}{2}} \ell^{-1} (k-\ell^{-1})^{-\frac{3}{4}}) \lambda^\frac{1}{2} \right] \right)^\frac{1}{2} < \infty.",2502.01037
definition,We define approximate peak time $t^{p}_0$ by the positive solution to    P(t) = \ell \left( P^{'}(t) + P(t)^2 \right)   in the case of a small fluorescence lifetime.,2502.01037
definition,Assume \eqref{ellcondition1} and \eqref{ellcondition2}. We define approximate peak time $t^{p}_\infty$ by the positive solution to \eqref{NonlinearScheme} in the case of a large fluorescence lifetime.,2502.01037
proof,"We first study the asymptotic behavior of the positive solution to $P(t)=0$ in \eqref{cubicpoly}.  The positive solution $t_0>0$ to   - k  - \frac{3}{2} t^{-1} + \lambda^2 t^{-2} - \frac{2\beta v D}{x_{c_3} + \beta v D t} = 0  satisfies     t_0 =  k^{-\frac{1}{2}}\lambda - \frac{7}{4}k^{-1} + \frac{\sqrt{k}}{\sqrt{k}+\beta\sqrt{vD}}k^{-1}  + O\left(\lambda^{-1}\right) \quad \mbox{as} \quad \lambda \gg 1.     Define $\tilde{t}>0$ as the positive solution to $$ -k  - \frac{3}{2} t^{-1} + \lambda^2 t^{-2} =0. $$ Then we obtain   \tilde{t} = \frac{1}{2k} \left( \left[ 4k\lambda^2 + \left(\frac{3}{2}\right)^2 \right]^\frac{1}{2} - \frac{3}{2}  \right)  = k^{-\frac{1}{2}}\lambda - \frac{3}{4}k^{-1} + O\left( \lambda^{-1} \right)    as $\lambda \gg 1$. Set $t_0 := \tilde{t} + \varepsilon$ with $\varepsilon = o(\lambda)$ as $\lambda \gg 1$. By \eqref{betazeroeq}, we obtain   P(t_0) &= - k  - \frac{3}{2} \left(\tilde{t} + \varepsilon\right)^{-1} + \lambda^2 \left(\tilde{t} + \varepsilon\right)^{-2}  - 2\beta v D  \left( x_{c_3} + \beta v D [\tilde{t} + \varepsilon]\right)^{-1} \\  &=  -2\beta v D \left( x_{c_3} + \beta v D \tilde{t} \right)^{-1}  + \left[ -2 \lambda^2 \tilde{t}^{-3} + \frac{3}{2}\tilde{t}^{-2} + 2(\beta v D)^2  \left( x_{c_3} + \beta v D \tilde{t} \right)^{-2}\right]\varepsilon +  O\left( \lambda^{-2}\varepsilon^2 \right) \\   &= 0.   This together with  \eqref{defk} and \eqref{betazeroasymp} implies that   \varepsilon &= \frac{2\beta v D}{ x_{c_3} + \beta v D \tilde{t}} \times \frac{1}{-2 \lambda^2 \tilde{t}^{-3} + \frac{3}{2}\tilde{t}^{-2} + 2(\beta v D)^2  \left( x_{c_3} + \beta v D \tilde{t} \right)^{-2}} + \cdots \\  &= -\frac{\beta v D}{ x_{c_3} + \beta v D \tilde{t}} \times \frac{\tilde{t}^3}{\lambda^2} +  O\left( \lambda^{-1} \right) \quad \mbox{as} \quad \lambda \gg 1.   Note that $x_{c_3} \sim \sqrt{vD} \lambda$.  By \eqref{betazeroasymp}, the dominant part of $\varepsilon$ is    -\frac{\beta v D}{ x_{c_3} + \beta v D \tilde{t}} \times \frac{\tilde{t}^3}{\lambda^2}  &= -\frac{\beta v D}{ \sqrt{vD} + \beta v D k^{-\frac{1}{2}}} k^{-\frac{3}{2}} +  O\left( \lambda^{-1} \right)\\ &= -\frac{\beta\sqrt{vD}}{\sqrt{k} + \beta\sqrt{vD}}k^{-1}  +  O\left( \lambda^{-1} \right) \quad \mbox{as} \quad \lambda \gg 1.   Then we obtain the asymptotic expansion    t_0 &= \tilde{t} + \varepsilon  =  k^{-\frac{1}{2}}\lambda - \frac{3}{4}k^{-1} - \frac{\beta\sqrt{vD}}{\sqrt{k} + \beta\sqrt{vD}}k^{-1} +  O\left( \lambda^{-1} \right) \\ &=  k^{-\frac{1}{2}}\lambda - \frac{7}{4}k^{-1} + \frac{\sqrt{k}}{\sqrt{k}+\beta\sqrt{vD}}k^{-1}  +  O\left( \lambda^{-1} \right) \quad \mbox{as} \quad \lambda \gg 1,   and the proof of Proposition \ref{ellzero} is complete.",2502.01037
proof,"Set  t = (k-\ell^{-1})^{-\frac{1}{2}} \lambda + \varepsilon, \quad \mbox{where} \quad \varepsilon = o (\lambda) \quad \mbox{as} \quad \lambda \gg 1.  Since $$ \left(\frac{x_{c_3}+\beta vDt }{x_{c_3}+\beta vD \lambda (k-\ell^{-1})^{-\frac{1}{2}}}\right)^2 = 1 + O\left( \lambda^{-1} \varepsilon \right), $$ we obtain from \eqref{NonlinearScheme} that   e^{-\frac{(k-\ell^{-1})\varepsilon^2}{(k-\ell^{-1})^{-1/2} \lambda + \varepsilon}} &= \pi^{\frac{1}{2}} \ell^{-1} \lambda^{-1} t^{\frac{3}{2}} \left[ 1+ O\left( \lambda^{-1} \varepsilon \right) \right] \\  &=\pi^{\frac{1}{2}} \ell^{-1} \lambda^{-1}   \left( [(k-\ell^{-1})^{-\frac{1}{2}} \lambda ]^{\frac{3}{2}} + O\left( \lambda^\frac{1}{2} \right) \right)  \left( 1+ O\left( \lambda^{-1} \varepsilon \right) \right) \\ &= \alpha \lambda^\frac{1}{2} \left[ 1 + O\left( \lambda^{-1} \right) \right] \quad \mbox{with} \quad  \alpha:= \pi^{\frac{1}{2}} \ell^{-1} (k-\ell^{-1})^{-\frac{3}{4}}   as $\lambda \gg 1$. By   -\frac{(k-\ell^{-1})\varepsilon^2}{(k-\ell^{-1})^{-1/2} \lambda + \varepsilon} = -(k-\ell^{-1})^\frac{3}{2} \varepsilon^2 \left[ \lambda^{-1} + O\left( \lambda^{-2}\varepsilon \right) \right] \quad \mbox{as} \quad \lambda \gg 1,   and   \log\left( \alpha \lambda^\frac{1}{2} \left[ 1 + O\left( \lambda^{-1} \right) \right]\right) = \log\left(\alpha \lambda^\frac{1}{2} \right) +  O\left( \lambda^{-1} \right) \quad \mbox{as} \quad \lambda \gg 1,   we obtain   \varepsilon^2 = (k-\ell^{-1})^{-\frac{3}{2}} \left( -\log\left[ \alpha \lambda^\frac{1}{2} \right] \right) \lambda + O\left( 1 \right) \quad \mbox{as} \quad \lambda \gg 1.  Since $0<\alpha \lambda^{1/2} <1$, we have  $$ \varepsilon =  (k-\ell^{-1})^{-\frac{3}{4}} \left( -\log\left[ \alpha \lambda^\frac{1}{2} \right] \right)^\frac{1}{2} \lambda^\frac{1}{2} + O\left( \lambda^{-\frac{1}{2}} \right) \quad \mbox{as} \quad \lambda \gg 1. $$ Then we have the asymptotic expansion of the approximate peak time   t &= (k-\ell^{-1})^{-\frac{1}{2}} \lambda + \varepsilon \\ &=(k-\ell^{-1})^{-\frac{1}{2}} \lambda + (k-\ell^{-1})^{-\frac{3}{4}} \left( -\log\left[ (\pi^{\frac{1}{2}} \ell^{-1} (k-\ell^{-1})^{-\frac{3}{4}}) \lambda^\frac{1}{2} \right] \right)^\frac{1}{2} \lambda^\frac{1}{2}    as $\lambda \gg 1$, and the proof the Theorem \ref{thm_linfty} is complete.",2502.01037
proposition,The positive solution $t_0>0$ to   - k  - \frac{3}{2} t^{-1} + \lambda^2 t^{-2} - \frac{2\beta v D}{x_{c_3} + \beta v D t} = 0  satisfies     t_0 =  k^{-\frac{1}{2}}\lambda - \frac{7}{4}k^{-1} + \frac{\sqrt{k}}{\sqrt{k}+\beta\sqrt{vD}}k^{-1}  + O\left(\lambda^{-1}\right) \quad \mbox{as} \quad \lambda \gg 1.,2502.01037
lemma,"Let $x_d, \; x_s\in\partial\Omega$, and assume that   \Big| |x_d-x_c|^2-|x_s-x_c|^2 \Big| \le C t \quad {\rm for\; some} \quad C>0.   Define  k: = v \mu _a , \quad \lambda^2: = \frac{|x_d-x_c|^2+|x_s-x_c|^2}{2vD}.  Then, $u_m$ satisfies   u_m(t) = u^a_m(t) + O \left( u^a_m(t) \lambda^{-1}  \right),\;\; \lambda \gg 1,   where   &u^a_m(t) = C_0 e^{-kt}  t^{-\frac{3}{2}} e^{-\frac{\lambda^2}{t}} \left(\frac{x_{c_3}}{x_{c_3}+\beta v D t}\right)^2 \quad \mbox{with} \quad C_0 := \frac{c}{8\pi^\frac{5}{2} v^\frac{1}{2} D^\frac{3}{2} } \left( \frac{1}{|x_d-x_c|} + \frac{1}{|x_s-x_c|} \right).",2502.01037
lemma,"Assume $t>\lambda k^{-\frac{1}{2}}$. Then $u^a_m$ of \eqref{defIt} satisfies   \int_0^t  e^{-(ks+\lambda^2 s^{-1})} f(s) \; {\rm d}s = k^{-\frac{3}{4}} \left( \pi \lambda \right)^\frac{1}{2}   e^{-2 \lambda \sqrt{k}} f( \lambda k^{-\frac{1}{2}})  + O\left( \lambda^{-\frac{3}{2}} e^{-2 \lambda \sqrt{k} }  f( \lambda k^{-\frac{1}{2}}) \right)   as $\lambda \gg 1$, where $k>0$ and $\lambda$ are as in \eqref{defk}.",2502.01037
example,"Let $\ell=100 \; {\rm ps}$. Supposing that  $x_c=(8,\,7,\,20)$ and $x_c=(8,\,7,\,30)$, we show the results of numerical reconstructions from noise-free measurements for different initial S-D pairs in Table \ref{tbl:ex_small_lt01}. The results of the measurements containing different noise levels are shown in Table \ref{tbl:ex_small_lt02}.",2502.01037
example,"Let $\ell=1000\; {\rm ps}$. Supposing that  $x_c=(8,\,7,\,20)$ and $x_c=(8,\,7,\,30)$, we show the results of numerical reconstructions from noise-free measurements for different initial S-D pairs in Table \ref{tbl:ex_large_lt01}. The results of the measurements containing different noise levels are shown in Table \ref{tbl:ex_large_lt02}.",2502.01037
theorem,"For a given right-end state $(v_+,u_+)\in \mathbb{R}_+\times\mathbb{R}$, there exist positive constants $\delta_0$ and $\varepsilon_0$ such that the following statements hold.             For any $(v_m,u_m) \in S_2(v_+,u_+)$ and $(v_-,u_-) \in R_1(v_m,u_m)$ such that     \[|(v_+,u_+)-(v_m-u_m)|+|(v_m-u_m)-(v_-,u_-)|<\delta_0,\]    let $(v^r,u^r)(\frac{x}{t})$ be the 1-rarefaction \eqref{eq:rarefaction wave} with end states $(v_-,u_-)$ and $(v_m,u_m)$, and  $(\vs,\us)(x-\sigma t)$ be the 2-viscous-dispersive shock wave \eqref{viscous-dispersive-shock} with the end states $(v_m,u_m)$ and $(v_+,u_+)$. Let $(v_0,u_0)$ be any initial data such that    \[\sum_{\pm}\left\|(v_0-v_{\pm},u_0-u_{\pm})\right\|_{L^2(\R_\pm)}+\|v_{0x}\|_{H^1(\R)}+\|u_{0x}\|_{L^2(\R)}<\e_0,\]    where $\R_-:=-\R_+=(-\infty,0)$. Then, the Navier--Stokes--Korteweg system \eqref{eq:NSK} admits a unique global-in-time solution $(v,u)$. Moreover, there exists a Lipschitz continuous shift function $X:[0,\infty)\to \bbr$ such that $X(0)=0$ and                &v(t,x)-\left(v^r(x/t) + \vs(x-\sigma t -X(t)) -v_m \right)\in C(0,\infty;H^2(\R)),\\       &u(t,x)-\left(u^r(x/t) + \us(x-\sigma t -X(t)) -v_m \right)\in C(0,\infty;H^1(\R))\cap L^2(0,\infty;H^2(\R)).            In addition, we have            &\lim_{t\to\infty}\|v(t,\cdot)-\left(v^r(\cdot/t)+v^S(\cdot-\sigma t-X(t))-v_m\right)\|_{W^{1,\infty}(\R)}=0,\\    &\lim_{t\to\infty}\|u(t,\cdot)-\left(u^r(\cdot/t)+u^S(\cdot-\sigma t-X(t))-u_m\right)\|_{L^{\infty}(\R)}=0,         	and 	 		\lim_{t\to\infty} |\dot{X}(t)|=0.",2502.01063
proof,"Since the proof can be found in \cite{MN86}, except for the estimate on the third- and fourth-order derivatives, we only need to prove the estimates on the high-order derivatives. For brevity, we present the proof in Appendix \ref{sec:app-rarefaction-proof}.",2502.01063
proof,"The local existence can be proven, as presented in \cite{S76}, by using the standard argument of constructing a sequence of approximate solutions and applying the Cauchy estimate. For the sake of brevity, the proof is omitted.",2502.01063
proof,"The proofs of the first three estimates in \eqref{est-interaction} are identical to those of \cite[Lemma 4.2]{KVW23}. Since the properties of the viscous-dispersive shock wave in \eqref{shock-property} are the same as those of the viscous shock wave in \cite[Lemma 2.2]{KVW23}, we can directly apply the proof of \cite{KVW23}. Therefore, we focus on estimating $Q_1^I$ and $Q_2$.\\ 	 	\noindent $\bullet$ (Estimate of $Q_1^I$): Recall the definition of $Q_1^I$ in \eqref{Q1I}:      Q_1^I&=(p(\overline{v})-p(v^R)-p(v^S))_x-\left(\m\frac{\ou_x}{\ov}-\mu^R\frac{\ur_x}{\vr}-\mu^S\frac{\us_x}{\vs}\right)_x\\     &-\left( \ok \left(-\frac{\ov_{xx}}{\ov^5} + \frac{5(\ov_x)^2}{2\ov^6} \right)-\kr \left(-\frac{\vr_{xx}}{(\vr)^5} + \frac{5(\vr_x)^2}{2(\vr)^6} \right)-\ks \left(-\frac{\vs_{xx}}{(\vs)^5} + \frac{5((\vs)_x)^2}{2(\vs)^6} \right)\right)_x\\     &+\left(  \ok' \frac{(\ov_x)^2}{2\ov^5} -(\kr)' \frac{(\vr_x)^2}{2(\vr)^5}-(\ks)' \frac{(\vs_x)^2}{2(\vs)^5}\right)_x.  Using $\ov=\vr+\vs-v_m$, the first two terms of $Q_1^I$ can be easily estimated as              (p(\overline{v})-p(v^R)-p(v^S))_x & =p'(\ov)(\vr_x+\vs_x)-p'(\vr)\vr_x-p'(\vs)\vs_x\\         &\le C \big[ |\vr_x| |\vs-v_m| + |\vs_x| |\vr-v_m|\big],      and              \left(\m\frac{\ou_x}{\ov}-\mr \frac{\ur_x}{\vr}-\ms \frac{\us_x}{\vs}\right)_x          &\le \left| \left( \ur_x \left( \frac{\m}{\ov}-\frac{\mr}{\vr} \right) \right)_x \right| +\left|\left( \us_x \left( \frac{\m}{\ov}- \frac{\ms}{\vs}\right) \right)_x \right|\\         &\le C \big[ |\ur_{xx}| |\vs-v_m| + |\us_{xx}| |\vr-v_m| + |\ur_x||\vs_x| +|\us_x| |\vr_x|\big].      Next, we estimate the third term of $Q^I_1$ as              &\left| \left( \ok \left(-\frac{\ov_{xx}}{\ov^5} + \frac{5(\ov_x)^2}{2\ov^6} \right)-\kr \left(-\frac{\vr_{xx}}{(\vr)^5} + \frac{5(\vr_x)^2}{2(\vr)^6} \right)-\ks \left(-\frac{\vs_{xx}}{(\vs)^5} + \frac{5(\vs_x)^2}{2(\vs)^6} \right) \right)_x \right| \\         &\le \left| \left(  - \ok \frac{\ov_{xx}}{\ov^5} + \kr \frac{\vr_{xx}}{(\vr)^5} +(\ks)\frac{\vs_{xx}}{(\vs)^5} \right)_x \right| +\frac{5}{2} \left| \left( \ok  \frac{(\ov_x)^2}{\ov^6} -\kr  \frac{(\vr_x)^2}{(\vr)^6} -\ks  \frac{(\vs_x)^2}{(\vs)^6} \right)_x \right|.          However, since $\ov_{xx}=\vr_{xx}+\vs_{xx}$, we have              &\left| \left(  - \ok \frac{\ov_{xx}}{\ov^5} + \kr \frac{\vr_{xx}}{(\vr)^5} +\ks \frac{\vs_{xx}}{(\vs)^5} \right)_x \right|         \\         &=\left| \left( \vr_{xx} \left(\frac{\ok}{\ov^5}-\frac{\kr}{(\vr)^5} \right)+ \vs_{xx} \left(\frac{\ok}{\ov^5}-\frac{\ks}{(\vs)^5} \right) \right)_x \right|\\         &\le \left| \vr_{xxx} \left(\frac{\ok}{\ov^5}-\frac{\kr}{(\vr)^5} \right)+ \vs_{xxx} \left(\frac{\ok}{\ov^5}-\frac{\ks}{(\vs)^5} \right) \right| +\left|  \vr_{xx} \left(\frac{\ok}{\ov^5}-\frac{\kr}{(\vr)^5} \right)_x+ \vs_{xx} \left(\frac{\ok}{\ov^5}-\frac{\ks}{(\vs)^5} \right)_x \right| \\         &\le C \big[ |\vr_{xxx}| | \vs-v_m| + |\vs_{xxx}| |\vr-v_m| +  |\vr_{xx}| |\vs_x| +  |\vr_{xx}| |\vr_x| |\vs-v_m| +  |\vs_{xx}| |\vr_x| + |\vs_{xx}| |\vs_x| |\vr-v_m| \big]\\         &\le C\left[ |(\vr_{xx}\vr_x,\vr_{xxx})| |\vs-v_m| + |(\vs_{xx}\vs_x,\vs_{xxx})| | \vr-v_m| + |\vr_{xx}||\vs_x|+|\vs_{xx}||\vr_x|\right].          Similarly, we use   $(\ov_{x})^2=(\vr_{x})^2+(\vs_{x})^2+2 \vr_x \vs_x$ to obtain              &\left| \left( \ok  \frac{(\ov_x)^2}{\ov^6} -\kr  \frac{(\vr_x)^2}{(\vr)^6} -\ks  \frac{(\vs_x)^2}{(\vs)^6} \right)_x \right|\\         &\le \left| \left( (\vr_{x})^2 \left(\frac{\ok}{\ov^6}-\frac{\kr}{(\vr)^6} \right)+ (\vs_{x})^2 \left(\frac{\ok}{\ov^6}-\frac{\ks}{(\vs)^6} \right) \right)_x \right|  +2 \left|   \left( \frac{\ok}{\ov^6}\vr_x\vs_x  \right)_x \right| \\         &\le C \big[  |\vr_{x}\vr_{xx}| | \vs-v_m| + |\vs_{x}\vs_{xx}| | \vr-v_m|  \\          &\quad +  |\vr_{x}|^2 |\vs_x| +  |\vr_{x}|^3  |\vs-v_m| +  |\vs_{x}|^2 |\vr_x| +  |\vs_{x}|^3  |\vr-v_m| + |\vr_{xx}| |\vs_x| + |\vr_{x}| |\vs_{xx}|\big] \\         &\le C\big[ | (\vr_x\vr_{xx},|\vr_x|^3 ) | |\vs-v_m| + | (\vs_x\vs_{xx},|\vs_x|^3 ) | |\vr-v_m| \\          &\quad +|( |\vr_x|^2,\vr_{xx})| |\vs_x|+|( |\vs_x|^2,\vs_{xx})| |\vr_x|\big].          Finally, the fourth term of $Q^I_1$ can be estimated by using similar argument as              &\frac{1}{2}\left| \left(  \ok' \frac{(\ov_x)^2}{\ov^5} -(\kr)' \frac{(\vr_x)^2}{(\vr)^5}-(\ks)' \frac{(\vs_x)^2}{(\vs)^5}\right)_x \right|\\         &\le \frac{1}{2} \left| \left( (\vr_{x})^2 \left(\frac{\ok'}{\ov^5}-\frac{(\kr)'}{(\vr)^5} \right)+ (\vs_{x})^2 \left(\frac{\ok'}{\ov^5}-\frac{(\ks)'}{(\vs)^5} \right) \right)_x \right|  + \left|   \left( \frac{\ok'}{\ov^5}\vr_x\vs_x  \right)_x \right| \\         &\le C \big[  |\vr_{x}\vr_{xx}| | \vs-v_m| + |\vs_{x}\vs_{xx}| | \vr-v_m|  \\          &\quad +  |\vr_{x}|^2 |\vs_x| +  |\vr_{x}|^3  |\vs-v_m| +  |\vs_{x}|^2 |\vr_x| +  |\vs_{x}|^3  |\vr-v_m| + |\vr_{xx}| |\vs_x| + |\vr_{x}| |\vs_{xx}|\big] \\         &\le C\big[ | (\vr_x\vr_{xx},|\vr_x|^3 ) | |\vs-v_m| + | (\vs_x\vs_{xx},|\vs_x|^3 ) | |\vr-v_m| \\          &\quad +|( |\vr_x|^2,\vr_{xx})| |\vs_x|+|( (\vs_x)^2,\vs_{xx})| |\vr_x|\big].          Combining all the estimates above, we obtain              |Q_1^I| &\le C\Big[ |(\vr_x,\vr_{xx},\vr_{xx}\vr_x,\vr_{xxx},|\vr_x|^3)| |\vs-v_m| + |(\vs_x,\vs_{xx},\vs_{xx}\vs_x,\vs_{xxx},|\vs_x|^3)| | \vr-v_m|  \\         &\quad +|( \ur_x,|\vr_x|^2,\vr_{xx})| |\vs_x|+|(\us_x, |\vs_x|^2,\vs_{xx})| |\vr_x|\Big],      and using Lemma \ref{lem:rarefaction_property} and Lemma \ref{lem:shock-property}, one has \[\|Q_1^I\|_{L^2} \le C \delta_S \delta_R e^{-C \delta_S t}. \]  \noindent $\bullet$ (Estimate of $Q_2$): Again, we recall the definition of $Q_2$ \[ Q_2= - \dot{X} \left(   \sqrt{\kappa(\vs)} \dfrac{ \vs_x}{(\vs)^{5/2}} -  \sqrt{\kappa(\ov)}\dfrac{ \vs_x}{\ov^{5/2}}  \right)_x,\] from which we directly obtain       |Q_2| &\le C |\dot{X}| \left[ |\vs_{xx}| |\vr-v_m| + |\vs_{x}| |\vr_x|\right].  Therefore, we again use Lemma \ref{lem:rarefaction_property} and Lemma \ref{lem:shock-property} to derive \[\|Q_2\|_{L^2} \le C \e_1 \delta_R \delta_S^{3/2} e^{-C \delta_S t}.\]",2502.01063
proof,"Since $U$ and $\overline{U}$ satisfy general form of the hyperbolic system \eqref{eq:NS-abs} and \eqref{eq:composite_wave}, we can use a similar estimate as in \cite[Lemma 2.3]{KV21} (see also \cite[Lemma 4.2]{HKKL_pre}). Precisely, we have   \frac{d}{dt} \int_\mathbb{R} a \eta (U|\oU) \, dx &=\dot{X}(t)Y-\sigma\int_\mathbb{R} a_x\eta(U|\oU) \, dx+ \sum_{i=1}^5 I_{1i},  where   I_{11}&:=-\int_\mathbb{R} a G(U;\oU)_x \, dx,\quad I_{12}:=-\int_\mathbb{R} a (D \eta (\oU))_x A(U| \oU) \, dx,\\ I_{13}&:=\int_\mathbb{R} a \left(D\eta(U)-D\eta(\oU) \right) \left(M(U)\left(D\eta (U)-D\eta(\oU) \right)_x\right)_x\, dx,\\ I_{14}&:=\int_\mathbb{R} a \left( D \eta(U)-D\eta(\oU)\right)\left( (M(U) -M(\oU))(D \eta(\oU))_x\right)_x\,dx,\\ I_{15}&:=\int_\mathbb{R}a (D\eta)(U|\oU) \left( M(\oU) \partial_x D \eta(\oU) \right)_x\, dx,\quad I_{16}:=-\int_\mathbb{R} a D^2 \eta(\oU)(U-\oU)  0 \\ Q_1 \\ Q_2  \, dx.   Using \eqref{relative_functional}, we explicitly compute each term as  I_{11}&=\int_\R a_x (p(v)-p(\ov) )(u-\ou)\, dx, \quad I_{12}=-\int_\R a \ou_x p(v|\ov) \, dx=-\int_{\R}a(u^R_x+u^S_x)p(v|\ov)\,dx, \\ I_{13}&=- \int_\R a \frac{\mu|(u-\ou)_x|^2}{v} \, dx \\ &\quad -\int_\R a_x \left(  \frac{\mu (u-\ou)(u-\ou)_x}{v}+\frac{\sqrt{\kappa}(u-\ou)(w-\ow)_x}{v^{5/2}}-\frac{\sqrt{\kappa}(w-\ow)(u-\ou)_x}{v^{5/2}}\right) dx,\\ I_{14}&=-\int_\R a_x\Bigg( (u-\ou)\left(\frac{\mu}{v}-\frac{\m}{\ov} \right)\ou_x+ (u-\ou)\left( \frac{\sqrt{\kappa}}{v^{5/2}}-\frac{\sqrt{\ok}}{\ov^{5/2}} \right)\ow_x-(w-\ow) \left( \frac{\sqrt{\kappa}}{v^{5/2}}-\frac{\sqrt{\ok}}{\ov^{5/2}} \right)\ou_x \Bigg) dx \\ &\quad  -\int_\R a \Bigg( (u-\ou)_x\left(\frac{\mu}{v}-\frac{\m}{\ov} \right)\ou_x+ (u-\ou)_x\left( \frac{\sqrt{\kappa}}{v^{5/2}}-\frac{\sqrt{\ok}}{\ov^{5/2}} \right)\ow_x-(w-\ow)_x \left( \frac{\sqrt{\kappa}}{v^{5/2}}-\frac{\sqrt{\ok}}{\ov^{5/2}} \right)\ou_x \Bigg) dx,\\ I_{15}&=0, \quad I_{16}=-\int_\mathbb{R} a (u-\ou) Q_1 \, dx -\int_\R a (w-\ow) Q_2 \, dx.  After expanding the terms, one can obtain the desired estimate.",2502.01063
proof,"The proof shares a similar estimate with \cite[Lemma 4.3]{HKKL_pre}, except that we consider the composite wave instead of a single shock. Let us define              I_{21}:=-\int_{\mathbb{R}} a \us_x p(v|\ov) \, dx =\int_{\mathbb{R}}  a \sqrt{\delta_S} a_x p(v | \ov) \,dx, \quad I_{22}:=\sigma \int_{\mathbb{R}} a_x Q(v|\ov) \, dx,      	where we use \eqref{a_x}. We use Lemma \ref{lem : Estimate-relative} and      \[|p(\ov)-p(v_m)| \le C \left( |\vs-v_m| + |\vr-v_m|\right) \le C \delta_0 \]      to estimate $I_{21}$ as              I_{21} &\le \frac{1}{2} \left( (\sqrt{\delta_S}+\delta_S)  \frac{\gamma+1}{ \gamma } \frac{1}{p(v_m)} \right) \int_\mathbb{R} a_x  |p(v)-p(\ov)|^2 \, dx \\          &\quad +C (\sqrt{\delta_S}+\delta_S) \delta_0 \int_\mathbb{R}a_x |p(v)-p(\ov)|^2 \, dx +C \int_\mathbb{R} a_x |p(v)-p(\ov)|^3 \, dx.          Next, we use Lemma \ref{lem : Estimate-relative}, \eqref{shock_speed_est}, and \eqref{shock_speed_est-2} to estimate $I_{22}$ as                  -I_{22} &\le -\frac{1}{2 \sigma_m}  \int_\mathbb{R} a_x |p(v)-p(\ov)|^2 \, dx - \frac{\sigma}{2\gamma}\int_\mathbb{R} a_x \left( p(\ov)^{-\frac{1}{\gamma}-1} -p(\vs)^{-\frac{1}{\gamma}-1} \right) |p(v)-p(\ov)|^2\, dx \\          &\quad + C \delta_S \int_\mathbb{R} a_x |p(v)-p(\ov)|^2 \, dx + C \int_\mathbb{R} a_x |p(v)-p(\ov)|^3 \, dx.                  Therefore, one can obtain                   %         I_{21} -I_{22}          &\le - C_1  \int_\R a_x |p(v)-p(\ov)|^2 \, d x  - \frac{\sigma}{2\gamma}\int_\mathbb{R} a_x \left( p(\ov)^{-\frac{1}{\gamma}-1} -p(\vs)^{-\frac{1}{\gamma}-1} \right) |p(v)-p(\ov)|^2\, dx \\          &\quad +C\sqrt{\delta_S}(\sqrt{\delta_S}+\delta_0) \int_\R a_x\big|p(v)-p(\ov)\big|^2 \, d x+C\int_\R a_x\big|p(v)-p(\ov)\big|^3 \, d x,                           where                  C_1 = \frac{1}{2}\left(\frac{1}{\sigma_m}-\sqrt{\delta_S}\frac{\gamma+1}{\gamma}\frac{1}{p(v_m)}\right).",2502.01063
proof,"Since $|v-\ov|\sim|p(v)-p(\ov)|$, and $|\vs_x| \sim \sqrt{\delta_S}|a_x|$, we observe that there exists a positive constant $C$ such that               G^S_v &\le C \int_\mathbb{R} |\vs_x| \left|p(v)-p(\ov)\right|^2 \, dx  \\          &\le C  \int_\mathbb{R} |\vs_x| \left|p(v)-p(\ov) - \frac{u-\ou}{2C_1}\right|^2 \, dx +C  \int_\mathbb{R} |\vs_x| \left|u-\ou\right|^2 \, dx \\          &\le C \sqrt{\delta_S} \mathcal{G}_1 + C G^S_u.     Considering the smallness of $\sqrt{\delta_S}$, one can choose small enough $C_3$, but independent of $\delta_0$ and $\e_1$ such that \eqref{C_2} holds.",2502.01063
proof,"By \eqref{shock-property} in Lemma \ref{lem:shock-property}, we recall that $|\vs_x| \sim |\us_x|$ and $\|\us_x\|_{L^\infty} \le C \delta_S^2$. Also,  we recall the equivalence between $|v-\ov|$ and $|p(v)-p(\ov)|$ in Lemma \ref{lem : Estimate-relative}. Then, the fist inequality can be directly obtained as              &\int_\mathbb{R} (|\vs_x|+|\us_x|)^{1+p} \left( \left|u-\ou\right|^2 +\left| v-\ov \right|^2 + \left| p(v)-p(\ov) \right|^2 \right) \, dx \\          &\le \|\us_x\|_{L^\infty}^p \int_\mathbb{R} |\us_x| \left( |u-\ou|^2 + |v-\ov|^2 \right) \, dx\le C \delta_S^{2p}  \left(G^S_u +G^S_v\right).       The proof of the second inequality follows a similar approach as the first one. It relies on the equivalence between $|v-\ov|$, $|p(v)-p(\ov)|$, and $p(v|\ov)$. Additionally, since $\| \ur_x\|_{L^\infty} \le \delta_R$ from the Lemma \ref{lem:rarefaction_property}, we have       &\int_\mathbb{R} (|\vr_x|+|\ur_x|)^{1+p} \left(  \left| v-\ov \right|^2 +\left| p(v)-p(\ov) \right|^2 \right) \, dx \\       &\le C \|\ur_x\|_{L^\infty}^p \int_\mathbb{R}  \ur_x p(v|\ov) \, dx \le C \delta_R^p \mathcal{G}^R.  The third inequality can be obtained by combining the first and second inequalities, using the $\ou_x=\ur_x+\us_x$. Finally, the fourth inequality follows immediately from the first inequality by using $|a_x| \sim \frac{|\us_x|}{\sqrt{\delta_S}}$ in \eqref{a}.",2502.01063
proof,"Since the proof is complicated, we refer to Appendix \ref{app:proof_high_order_1} for the proof.",2502.01063
proof,We refer to Appendix \ref{app:proof_high_order_2} for the proof of Lemma \ref{lem: est-1}.,2502.01063
proof,"Again, since the proof is technical, we postpone the proof of Lemma \ref{lem: est-2} to Appendix \ref{app:proof_high_order_3}.",2502.01063
proposition,"Let $\underbar{v}$ and $\underbar{u}$ be smooth monotone functions such that 	\[(\underbar{v},\underbar{u})(x) = (v_{\pm},u_{\pm} )\quad \mbox{for}\quad\pm x\ge 1.\] 	Then, for any constants $M_0$, $M_1$, $\underline{\kappa}_0$, $\overline{\kappa}_0$, $\underline{\kappa}_{1}$, and $\overline{\kappa}_1$ satisfying              0<M_0<M_1 \quad \text{and} \quad 0<\underline{\kappa}_1<\underline{\kappa}_0<\overline{\kappa}_0<\overline{\kappa}_1,      	there exists a finite time $T_0>0$ such that if the initial data $(v_0,u_0)$ satisfy          \|v_0-\underline{v}\|_{H^2(\R)}+\|u_0-\underline{u}\|_{H^1(\R)}\le M_0      \quad \text{and} \quad     \underline{\kappa}_0\le v_0(x)\le\overline{\kappa}_0,\quad\forall x\in\R,      	then the Navier-Stokes-Korteweg equations \eqref{eq:NS} admit a unique solution $(v,u)$ on $[0,T_0]$ such that  	 	&v-\underline{v}\in L^\infty ([0,T_0];H^2(\R))\cap L^2([0,T_0];H^3(\R)),\\      & u-\underline{u}\in L^\infty([0,T_0];H^1(\R))\cap L^2([0,T_0];H^2(\R)). 	     Moreover, the solution $(v,u)$ satisfies 	\[\|v-\underline{v}\|_{L^\infty([0,T_0];H^2(\R))}+\|u-\underline{u}\|_{L^\infty([0,T_0];H^1(\R))}\le M_1\] 	and  	\[\underline{\kappa}_1\le v(t,x)\le \overline{\kappa}_1,\quad \forall(t,x)\in [0,T_0]\times \R.\]",2502.01063
proposition,"\cite{ KVW23} 		For any $c_1,c_2,c_3>0$, there exists a constant $C>0$ such that the following holds. For any $T>0$, and any functions $v,u\in L^\infty((0,T)\times\R)$ with 		\[c_1\le v(t,x)\le c_2,\quad |u(t,x)|\le c_3,\quad \forall (t,x)\in[0,T]\times\R,\] 		the ODE \eqref{ODE_X} has a unique Lipschitz continuous solution $X$ on $[0,T]$. Moreover, we have 		\[|X(t)|\le Ct,\quad t\in[0,T].\]",2502.01063
proposition,"For a given state $(v_+,u_+)\in\bbr_+\times\bbr$, there exist positive constants $C_0,\delta_0$, and $\e_1$ such that the following holds: 		 	Suppose that $(v,u,w)$ is the solution to \eqref{NSK-w} on $[0,T]$ for some $T>0$, and $(\ov,\ou,\ow)$ is the composite waves defined in \eqref{superposition wave-ext}. Let $X$ be the Lipschitz continuous solution to \eqref{ODE_X} with the weight function $a$ defined in \eqref{a}. Assume that $\delta_R,\delta_S<\delta_0$ and 	 	&v-\ov\in L^\infty(0,T;H^2(\bbr))\cap L^2(0,T;H^3(\R)),\\ 	&u-\ou\in L^\infty(0,T;H^1(\bbr))\cap L^2(0,T;H^2(\bbr)) , 	 	with 	 	\|v-\ov\|_{L^\infty(0,T;H^2(\bbr))}+\|u-\ou\|_{L^\infty(0,T;H^1(\bbr))}\le \e_1. 	 	Then, for all $0\le t\le T$, 	 	 	&\left(\norm{v-\ov}_{L^2(\mathbb{R})}^2 +\norm{u-\ou}_{H^1(\mathbb{R})}^2+\norm{w-\ow}_{H^1(\mathbb{R})}^2\right)+\delta_S \int_0^t | \dot{X}(s)|^2 \, d s \\  	&\quad +\int_0^t \left( G_1+G_3+G^S_u+G^S_v+G^R \right) \, ds +  \int_0^t \left( D_{u_1} + D_{u_2} + G_{w} + D_{w_1} + D_{w_2} \right)\, ds   \\  	& \le C_0 \left(\norm{(v-\ov)(0,\cdot)}_{L^2(\mathbb{R})}^2 +\norm{(u-\ou)(0,\cdot)}_{H^1(\mathbb{R})}^2+\norm{w_0-\ow}_{H^1(\mathbb{R})}^2\right)+C_0\delta_R^{1/3}, 	 	 	 	where $C_0$ is independent of $T$, and 	 	 	&G_1:=\int_\R |a_x|\left|p(v)-p(\ov)-\frac{u-\ou}{2C_1}\right|^2\,dx,\quad G_3:=\int_\R |a_x||w-\ow|^2\,dx,\\ 	&G^S_u:=\int_\R |u_x^S||u-\ou|^2\,dx,\quad G^S_v:=\int_{\R} |u^S_x||v-\ov|^2\,dx,\quad G^R:=\int_\R u^R_x |v-\overline{v}|^2\,dx,\\ 	&D_{u_1}:=\int_\R |(u-\ou)_x|^2\,dx,\quad D_{u_2}:=\int_\R |(u-\ou)_{xx}|^2\,dx,\\ 	&G_w:=\int_\R |w-\ow|^2\,dx,\quad D_{w_1}:=\int_{\R}|(w-\ow)_x|^2\,dx,\quad D_{w_2}:=\int_{\R}|(w-\ow)_{xx}|^2\,dx. 	 	 	Here, $C_1$ is a positive constant defined in \eqref{C_star}.",2502.01063
lemma,"[\cite{KV21}] Let $\gamma>1$ and $v_+$ be given constants. Then, there exist positive constants $C$ and $\delta_*$ such that the following assertions hold:                      \item For any $v$ and $\bar{v}$ satisfying $0<\bar{v}<2v_+$ and $0<v<3v_+$,                          |v-\bar{v}|^2 \le C Q(v|\bar{v}), \quad |v-\bar{v}|^2 \le C p(v|\overline{v}).                          \item For any $v,\bar{v}$ satisfying $v,\bar{v} > v_+ /2$,                          |p(v)-p(\bar{v})| \le C |v-\bar{v}|.                          \item For any $0<\delta<\delta_*$ and any $(v,\bar{v}) \in \mathbb{R}^2_+$ satisfying $|p(v)-p(\bar{v})|<\delta$ and $|p(\bar{v})-p(v_+)| < \delta,$                                       &p(v|\bar{v}) \le \left( \frac{\gamma +1 }{2 \gamma } \frac{1}{p(\bar{v})} +C \delta \right) |p(v)-p(\bar{v})|^2,\\              &Q(v|\bar{v}) \ge \frac{p(\bar{v})^{- \frac{1}{\gamma}-1}}{2 \gamma}|p(v)-p(\bar{v})|^2- \frac{1+\gamma}{3\gamma^2}p(\bar{v})^{- \frac{1}{\gamma}-2}(p(v)-p(\bar{v}))^3,\\              &Q(v|\bar{v}) \le \left( \frac{p(\bar{v})^{- \frac{1}{\gamma}-1}}{2 \gamma} +C \delta \right)|p(v)-p(\bar{v})|^2.",2502.01063
lemma,"Let $\delta_R :=|u_m-u_-| \sim |v_m-v_-|$. Then, the smooth approximate 1-rarefaction wave $(\vr, \ur)(t, x)$ satisfies the following properties.                       \item $\ur_x=\frac{2\vr}{\gamma+1}w_x>0$ and $\vr_x=\frac{(\vr)^{\frac{\gamma+1}{2}}}{\sqrt{\gamma}}u^R_x>0$, $\forall x \in \mathbb{R}$ and $t \ge 0.$             \item For any $p \in [1,+\infty]$, there exists a positive constant $C$ such that, for all $t\ge0$,                          &\|(v^R_x,u^R_x)\|_{L^p(\mathbb{R})} \le C \min \left\{\delta_R, \frac{\delta_R^{1/p}}{(1+t)^{1-1/p}} \right\}, \\             &\|(v^R_{xx},u^R_{xx})\|_{L^p(\mathbb{R})} \le C \min \left\{\delta_R, \frac{1}{(1+t)} \right\}, \\             &\|\pa_x^j(v^R,u^R)\|_{L^p(\mathbb{R})} \le C \min \left\{\delta_R, \frac{\delta_R^{1/p}}{(1+t)^{1-1/p}} ,\frac{1}{1+t}+\frac{\delta_R^{1/p-1}}{(1+t)^{2-1/p}}\right\}, \quad j = 3,4,\\             &|u^R_{xx}| \le C |u^R_x|, \quad \forall x \in \mathbb{R}.                          \item For $x \ge \lambda_{1}(v_m)(1+t)$ and for all $t\ge0$,                          &|(\vr,\ur)(t,x) -(v_m,u_m)| \le C \delta_R e^{-2|x-\lambda_{1}(v_m)(1+t)|} , \\             &|(v^R_{x},u^R_{x})(t,x)| \le C \delta_R e^{-2|x-\lambda_{1}(v_m)(1+t)|}.                          \item For $x \le \lambda_{1}(v_-)t$ and for all $t\ge0$,                           &|(\vr,\ur)(t,x) -(v_-,u_-)| \le C \delta_R e^{-2|x-\lambda_{1}(v_-)t|} , \\             &|(v^R_{x},u^R_{x})(t,x)| \le C \delta_R e^{-2|x-\lambda_{1}(v_-)t|}.                          \item $\displaystyle{\lim_{t \to +\infty}\sup_{x \in \mathbb{R}}}|(\vr,\ur)(t,x)-(v^r,u^r)(x/t)|=0$.",2502.01063
lemma,"[\cite{HKKL_pre}]         For a given right-end state $(v_+,u_+)$, there exists a positive constant $\delta_0$ such that the following statement holds. For any left-end state $(v_m,u_m) \in S_2(v_+,u_+)$ with $|v_+-v_m| \sim |u_+ - u_m|=:\delta_S<\delta_0$, there exists a unique solution $(\vs,\us)(\xi)$ to \eqref{viscous-dispersive-shock} such that $\vs(0)=\frac{v_m+v_+}{2}$. Moreover, there exists a positive constant $C$ such that the following estimates hold:                           & (\us)'<0,\quad (\vs)'>0,\quad ' = d/d\xi,\\         &C^{-1} (\vs)'(\xi) \le |(\us)'(\xi)| \le C (\vs)' (\xi), \quad \xi \in \mathbb{R},\\         &|\vs(\xi)-v_\pm|\le C\delta_Se^{-C\delta_S|\xi|},\quad \pm \xi>0,\\         &|(\vs)'(\xi)|\le C\delta_S^2e^{-C\delta_S|\xi|},\quad |(\vs)''(\xi)|\le C\delta_S|(\vs)'(\xi)|.",2502.01063
lemma,"Under the hypotheses of Proposition \ref{apriori-estimate}, there exists a positive constant $C$ such that for all $t \in [0,T],$ 		  		 		& \left\| \left( v-\ov, u-\ou, w-\ow \right) \right\|_{L^2}^2  +  \int_0^t \left(\delta_S|\dot{X}|^2 +G_1+ G_3 + G^R + G^S_u+ G^S_v+ D_{u_1}\right)\, ds \\  		&\quad \le C \left\| \left( v-\ov, u-\ou, w-\ow \right)(0,\cdot) \right\|_{L^2}^2 +C \delta_R^{1/3} + C\sqrt{\delta_0} \int_0^t \| (w-\ow)_x\|_{L^2}^2 \, ds, 		 		 		where $G_1, G_3, G^R,  G^S_u, G^S_v,$ and $D_{u_1}$ are defined in \eqref{good terms}.",2502.01063
lemma,"Let $X$ be the shift defined by \eqref{ODE_X}. Under the same hypotheses as in Proposition \ref{apriori-estimate}, the following holds for all $t\in [0,T]$:                           &\|\vs_x(\vr-v_m)\|_{L^1}+\|\vr_x \vs_x \|_{L^1} \le C \delta_R \delta_S e^{-C \delta_S t},\\             &\|\vs_x(\vr-v_m)\|_{L^2}+\|\vr_x \vs_x \|_{L^2} \le C \delta_R \delta_S^{3/2} e^{-C \delta_S t},\\             &\|\vr_x( \vs-v_m)\|_{L^2} \le C \delta_R \delta_S e^{-C \delta_S t}, \\             &\|Q_1^I\|_{L^2} \le C \delta_S \delta_R e^{-C \delta_S t},\quad \|Q_2\|_{L^2} \le C \e_1 \delta_R \delta_S^{3/2} e^{-C \delta_S t}.",2502.01063
lemma,"%     Let $a$ be the weight function defined in \eqref{a} and $X:[0,T]\to\bbr$ be any Lipschitz continuous function. Let $U$ be a solution to \eqref{eq:NS-abs},  and $\overline{U}$ be the composite wave satisfying \eqref{eq:composite_wave}. Then,   \frac{d}{dt}\int_\mathbb{R} a(t,x) \eta (U(t,x))|\oU(t,x)) \, dx=\dot{X}(t)Y+\mathcal{J}^{\textup{bad}}-\mathcal{J}^{\textup{good}},  where the terms $Y$, $\mathcal{J}^{\textup{bad}}$, and $\mathcal{J}^{\textup{good}}$ are defined as  Y&:=-\int_\mathbb{R} a_x \eta(U|\overline{U})\,d x +\int_\mathbb{R} a D^2\eta(\overline{U})U^S_x (U-\overline{U})\,d x,\\ \mathcal{J}^{\textup{bad}}&:=\int_\mathbb{R} a_x (p(v)-p(\ov))(u-\ou) \, dx-\int_\mathbb{R} a\us_x p(v | \ov) \,d x  -\int_\mathbb{R}  a_x \frac{\mu(u-\ou) (u-\ou)_x}{v}  \, dx\\ &\quad - \int_\mathbb{R} a_x \frac{\sqrt{\kappa} (u-\ou) (w-\ow)_x}{v^{5/2}}  \, dx+ \int_\mathbb{R} a_x \frac{\sqrt{\kappa} (w-\ow)(u-\ou)_x}{v^{5/2}}  \, dx \\ &\quad-  \int_\mathbb{R} a_x   (u-\ou) \left( \frac{\mu}{v}-\frac{\overline{\mu}}{\ov} \right) \ou_x \, dx   - \int_\mathbb{R} a_x (u-\ou) \left( \frac{\sqrt{\kappa}}{v^{5/2}}-\frac{\sqrt{\ok}}{\ov^{5/2}} \right) \ow_x  \, dx  \\  &\quad+ \int_\mathbb{R} a_x (w-\ow) \left( \frac{\sqrt{\kappa}}{v^{5/2}}-\frac{\sqrt{\ok}}{\ov^{5/2}} \right) \ou_x  \, dx -  \int_\mathbb{R} a (u-\ou)_x \left( \frac{\mu}{v}-\frac{\overline{\mu}}{\ov} \right) \ou_x \, dx \\ &\quad -\int_\mathbb{R} a (u-\ou)_x \left( \frac{\sqrt{\kappa}}{v^{5/2}}-\frac{\sqrt{\ok}}{\ov^{5/2}} \right) \ow_x \, dx + \int_\mathbb{R} a (w-\ow)_x \left( \frac{\sqrt{\kappa}}{v^{5/2}}-\frac{\sqrt{\ok}}{\ov^{5/2}} \right) \ou_x \, dx,\\ &\quad-\int_\mathbb{R} a (u-\ou)  Q_1  \, dx -\int_\mathbb{R} a(w-\ow) Q_2 \, dx ,\\ \mathcal{J}^{\textup{good}}&:= \frac{\sigma}{2}\int_\mathbb{R} a_x |u-\ou|^2 \, dx +\sigma \int_\mathbb{R} a_x Q(v|\ov) \, dx+\frac{\sigma}{2}\int_\mathbb{R} a_x |w-\ow|^2 \, dx\\ &\quad+\int_\mathbb{R} a \ur_x p(v|\ov) \, dx +  \int_\mathbb{R} a \frac{\mu|(u-\ou)_x|^2}{v} \,dx.",2502.01063
lemma,"%     There exists a positive constant $C_1$ such that                    -\int_{\mathbb{R}}& a \us_x p(v|\ov) \, dx-\sigma \int_{\mathbb{R}} a_x Q(v|\ov) \, dx\\         &\le -C_1\int_{\R}a_x|p(v)-p(\ov)|^2\,dx - \frac{\sigma}{2\gamma}\int_\mathbb{R} a_x \left( p(\ov)^{-\frac{1}{\gamma}-1} -p(\vs)^{-\frac{1}{\gamma}-1} \right) |p(v)-p(\ov)|^2\, dx \\          &\quad +C\sqrt{\delta_S}(\sqrt{\delta_S}+\delta_0) \int_\R a_x\big|p(v)-p(\ov)\big|^2 \, d x+C\int_\R a_x\big|p(v)-p(\ov)\big|^3 \, d x.",2502.01063
lemma,"There exists a positive constant $C_3$ such that               -\frac{1}{2}( \mathcal{G}_1 +C_2 G^S_u ) \le -C_3 G^S_v,       where   %      G^S_v:=\int_\mathbb{R}|\us_x||v-\ov|^2 \, dx .",2502.01063
lemma,"There exists a positive constant $C$ such that for $p \ge 0$, $q \ge \frac{1}{3}$,  %          &\int_\mathbb{R} (|\vs_x|+|\us_x|)^{1+p} \left( \left|u-\ou\right|^2 +\left| v-\ov \right|^2 + \left| p(v)-p(\ov) \right|^2 \right) \, dx \le C \delta_S^{2p}  \left(G^S_u +G^S_v\right) , \\      &\int_\mathbb{R} (|\vr_x|+|\ur_x|)^{1+p} \left(  \left| v-\ov \right|^2 +\left| p(v)-p(\ov) \right|^2 \right) \, dx  \le C \delta_R^p    \mathcal{G}^R  , \\     &\int_\mathbb{R} (|\ov_x|+|\ou_x|)^{1+p} \left(  \left| v-\ov \right|^2 +\left| p(v)-p(\ov) \right|^2 \right) \, dx   \le C \delta_S^{2p} G^S_v +C \delta_R^p  \mathcal{G}^R ,\\     &\int_\mathbb{R} |a_x|^{1+q} \left(|u-\ou|^2 + \left|v-\ov\right|^2 \right)\, dx \le C \delta_S^{\frac{3q-1}{2}}  \left( G^S_u + G^S_v \right) .",2502.01063
lemma,"Under the hypotheses of Proposition \ref{apriori-estimate}, there exists a positive constant $C$ that is independent of $\delta_0$ and $\e_1$, such that for all $t \in [0,T],$    	&\norm{ \left(\psi, \omega \right)_x(t,\cdot)}_{L^2}^2+  \int_0^t D_{u_2} \, d s \\ 	&\le C \norm{  \left( \psi,\omega\right)_x(0,\cdot)}_{L^2}^2+C\delta_S \int_0^t |\dot{X}|^2 \, d s + C \int_0^t \| \phi_x\|_{L^2}^2 \, d s \\  	& \quad +C (\varepsilon_1+\sqrt{\delta_0})\int_0^t  \left( G^S_v+G^R  + D_{u_1}+D_{w_1} + D_{w_2} \right) \, d s +C \delta_R.",2502.01063
lemma,"Under the assumptions of Proposition \ref{apriori-estimate}, there exist positive constant $C$ that is independent of $\delta_0$ and $\e_1$, such that for $0 \le t \le T$,    &\norm{\omega}_{L^2}^2+  \int_\mathbb{R} \psi\omega \, dx  +  \int_0^t \left(G_w + D_{w_1} \right) \, d s \\  &\le  C \norm{\omega(0,\cdot)}_{L^2}^2 + C \int_\mathbb{R} \psi(0,\cdot)\omega(0,\cdot) \, dx + \int_\mathbb{R} | \ow \phi \omega |\, dx + C \int_\mathbb{R} \left|  \ow(0,\cdot) \phi(0,\cdot)\omega(0,\cdot) \right|\, dx \\ & \quad + C \delta_S \int_0^t | \dot{X}|^2 ds + C \int_0^t D_{u_1} \, d s +C \sqrt{\delta_0} \int_0^t \left( \| \phi_x \|_{L^2}^2 + D_{u_2} + G^S_v +G^R \right) \, d s +C \delta_R.",2502.01063
lemma,"Under the assumptions of Proposition \ref{apriori-estimate}, there exists a positive constant $C$ that is independent of $\delta_0$ and $\e_1$, such that for $0 \le t \le T$ 	 	 	&\int_{\mathbb{R}} \psi_x\omega_x \, dx+ \int_{0}^t \left( D_{w_1} + D_{w_2} \right) \, ds  	\\ 	&\le \int_{\mathbb{R}} \psi(0,\cdot)_x\omega(0,\cdot)_x \, dx+C \delta_S \int_0^t |\dot{X}(s)|^2 \, d s + C_2 \int_{0}^{t} D_{u_2} ds \\  	&\quad  +C(\varepsilon_1+\sqrt{\delta_0}) \int_0^t \left(\norm{\phi_x}_{L^2}^2+G_w+G^S_v+G^R+D_{u_1} \right) \, d s+C \delta_R.",2502.01063
theorem,"Let $N \ge 2$ be an integer and let $(C(\Sigma),d_{C},m_{C})$ be the metric measure cone over an $RCD(N-2,N-1)$ metric measure space $(\Sigma,d_{\Sigma},m_{\Sigma})$ with vertex $p$. Let $u_{1},u_{2} : C(\Sigma) \to [0,\infty)$ be continuous and in $W^{1,2}_{\mathrm{loc}}(C(\Sigma))$ satisfying that:     	     		\item[(1)] $u_{1}(p) = u_{2}(p) = 0$;     		\item[(2)] $u_{1} u_{2} = 0$ in $C(\Sigma)$;     		\item[(3)] $\mathbf{\Delta} u_{i} \ge 0$ in $C(\Sigma)$, $i=1,2$.     	         Then the quantity                  	J(r) := \frac{1}{r^{4}} \int_{B_{r}(p)} \frac{\lvert \nabla u_{1} \rvert^{2}}{d(x,p)^{N-2}} \mathrm{d}m_{C} \int_{B_{r}(p)} \frac{\lvert \nabla u_{2} \rvert^{2}}{d(x,p)^{N-2}} \mathrm{d}m_{C}                  is monotone nondecreasing in $r \in (0,\infty)$.",2502.01064
theorem,"Let $(C(\Sigma),d_{\Sigma},m_{\Sigma})$ be as in Theorem \ref{main_theorem}. If there exist $u_{1},u_{2}$ as in Theorem \ref{main_theorem} such that, for some $0<r_{1}<r_{2}<\infty$,     	     		0<J(r_{1})=J(r_{2}) < \infty,     	     	then $(\Sigma,d_{\Sigma},m_{\Sigma})$ is a spherical suspension, i.e. there exists an $RCD(N-3,N-2)$-space $(Y,d_{Y},m_{Y})$ such that $(\Sigma,d_{\Sigma},m_{\Sigma})$ is isometric to $[0,\pi] \times_{\sin}^{N-2} Y$. If, in addition, $(\Sigma,d_{\Sigma},m_{\Sigma})$ is an $(N-1)$-dimensional smooth Riemannian manifold, then we have that:     	     		\item[(1)] $(\Sigma,d_{\Sigma},m_{\Sigma})$ is isometric to the sphere $\partial B_{1} \subset \mathbb{R}^{N}$;     		\item[(2)] there exist $k_{1},k_{2}>0$ and $\nu \in \partial B_{1}$ such that     		     			u_{1}(x)=k_{1}(x \cdot \nu)^{+},\quad u_{2}(x)=k_{2}(x\cdot\nu)^{-},\quad \text{in } B_{r_{2}}(p).",2502.01064
theorem,"Let $(C(\Sigma),d_{C},m_{C})$ be the metric measure cone over the metric measure space $(\Sigma,d_{\Sigma},m_{\Sigma})$, and $N \ge 2$. Then $(C(\Sigma),d_{C},m_{C})$ is an $RCD(0,N)$-space if and only if $(\Sigma,d_{\Sigma},m_{\Sigma})$ is an $RCD(N-2,N-1)$-space and $\mathrm{diam}(\Sigma) \le \pi$.",2502.01064
theorem,"It holds that $\lambda(\Gamma) \ge \lambda(\overline{\Gamma})$. If the equality holds, then $(\Sigma,d_{\Sigma},m_{\Sigma      	})$ is a spherical suspension, i.e. there exists an $RCD(N-3,N-2)$-space $(Y,d_{Y},m_{Y})$ such that $(\Sigma,d_{\Sigma},m_{\Sigma})$ is isomorphic to $[0,\pi]\times_{\sin}^{N-2}Y$. If, in addition, $(\Sigma,d_{\Sigma},m_{\Sigma})$ is an $(N-1)$-dimensional smooth Riemannian manifold, then $(\Sigma,d_{\Sigma},m_{\Sigma})$ is isometric to the sphere $\partial B_{1} \subset \mathbb{R}^{N}$.",2502.01064
theorem,"Let $\Gamma_{1},\Gamma_{2}$ be two disjoint open subsets of $\partial B_{1}$. Then it holds that 	 		\alpha(\Gamma_{1})+\alpha(\Gamma_{2}) \ge 2. 	 	The equality holds if and only if $\Gamma_{1},\Gamma_{2}$ are half-spheres.",2502.01064
definition,"We say that an $RCD(K,N)$-space $(X,d,m)$ is non-collapsed if $m = \mathcal{H}^{N}$, the $N$-dimensional Hausdorff measure. We also say that $(X,d,m)$ is a $ncRCD(K,N)$-space for short.",2502.01064
definition,"Given a metric measure space $(\Sigma,d_{\Sigma},m_{\Sigma})$ with $\mathrm{diam}\Sigma \le 2\pi$ and $N \ge 2$, the metric measure cone over $(\Sigma,d_{\Sigma},m_{\Sigma})$ with vertex $p$ is defined to be the metric measure space $(C(\Sigma),d_{C},m_{C})$, where      	      		\item $C(\Sigma) := \Sigma \times (0,\infty) \cup \{p\}$;      		\item For $(r_{1},\xi_{1}),(r_{2},\xi_{2}) \in C(\Sigma)$, where $r_{i} \in \mathbb{R}^{+}, \xi_{i} \in \Sigma$, the distance between them is defined to be      		      			d_{C}\big((r_{1},\xi_{1}),(r_{2},\xi_{2})\big) := \sqrt{r_{1}^{2} + r_{2}^{2} - 2r_{1}r_{2}\cos d_{\Sigma}(\xi_{1},\xi_{2})}      		      	    \item $m_{C} := r^{N-1}\mathrm{d}r \otimes m_{\Sigma}$.",2502.01064
definition,"Given $f \in W^{1,2}_{\mathrm{loc}}(X)$, its distributional Laplacian $\mathbf{\Delta} f$ is a linear functional on $\mathrm{LIP}_{0}(X)$ defined as      	      		\mathbf{\Delta} f (\phi) := - \int_{X} \langle \nabla f, \nabla \phi \rangle \mathrm{d}m      	         for all $\phi \in \mathrm{LIP}_{0}(X)$. If there exists a signed Radon measure $\mu$ such that                  	\mathbf{\Delta} f (\phi) = \int_{X} \phi \mathrm{d}\mu                  for all $\phi \in \mathrm{LIP}_{0}(X)$, then we say that $\mathbf{\Delta} f = \mu$ in the sense of distribution, denoted by $f \in \mathrm{D}(\mathbf{\Delta})$.",2502.01064
proof,"Since both $\mathbf{\Delta} u$ and $m$ are Radon measure, we have     	     		     			\lim\limits_{j \to \infty} \left| \mathbf{\Delta} u \right|\big(\overline{B_{r + j^{-1}}(x_{0})} \setminus B_{r}(x_{0})\big) = 0,\\     			\lim\limits_{j \to \infty} m\big(\overline{B_{r + j^{-1}}(x_{0})} \setminus B_{r}(x_{0})\big) = 0,     		     	         for almost all $r \in (R_{1},R_{2})$. On the other hand, we have that                  	\left| \int_{B_{r}(x_{0}) \setminus B_{s}(x_{0})} \langle \nabla u, \nabla \rho \rangle \mathrm{d}m \right| \le \sqrt{m(B_{R_{2}}(x_{0}))} \Big( \int_{B_{r}(x_{0}) \setminus B_{s}(x_{0})} \left| \nabla u \right|^{2} \mathrm{d}m \Big)^{1/2}                  Since $u \in W^{1,2}(B_{R_{2}}(x_{0})\setminus B_{R_{1}}(x_{0}))$, we get that the function                  	r \mapsto \int_{B_{r}(x_{0})} \langle \nabla u, \nabla \rho \rangle \mathrm{d}m              is locally absolutely continuous and hence differentiable for almost all $r \in (R_{1},R_{2})$.          Now we fix such $r_{1} < r_{2}$, and, for $j \in \mathbb{N}$, define          	\eta_{j} (t) :=      		0, & \text{if } t \in [0,r_{1} - j^{-1}] \cup [r_{2} + j^{-1},R_{2}],\\     		j(t - r_{1} + j^{-1}), & \text{if } t \in (r_{1} - j^{-1},r_{1}),\\     		1, & \text{if } t \in [r_{1},r_{2}],\\     		1 - j(t -r_{2}), & \text{if } t \in (r_{2},r_{2} + j^{-1}).     	          And, we let $\psi_{j} := \eta_{j}(\rho) \psi \in W^{1,2}_{0}(B_{R_{2}}(x_{0}) \setminus B_{R_{1}}(x_{0}))$.          Then, on the one hand, we have that          	     		\int_{B_{R_{2}}(x_{0})} \psi_{j} \mathrm{d}\mathbf{\Delta}u & = \int_{B_{r_{2}}(x_{0}) \setminus B_{r_{1}}(x_{0})} \psi \mathrm{d}\mathbf{\Delta}u\\     		& + \Big(\int_{B_{R_{2}}(x_{0}) \setminus B_{r_{2}}(x_{0})} + \int_{B_{r_{1}}(x_{0})} \Big) \eta_{j}(\rho) \psi \mathrm{d}\mathbf{\Delta}u.     	          Note that          	     		\left| \int_{B_{R_{2}}(x_{0}) \setminus B_{r_{2}}(x_{0})} \eta_{j}(\rho) \psi \mathrm{d}\mathbf{\Delta}u \right| & \le \int_{B_{r_{2} + j^{-1}}(x_{0}) \setminus B_{r_{2}}(x_{0})} \Big(\sup_{[R_{1},R_{2}]} \lvert \phi \rvert \Big) \mathrm{d}\mathbf{\Delta}u\\     		& \le \Big(\sup_{[R_{1},R_{2}]}  \lvert \phi \rvert \Big) \lvert \mathbf{\Delta} u \rvert(\overline{B_{r_{2} + j^{-1}}(x_{0})} \setminus B_{r_{2}}(x_{0}))\\     		& \to 0,\quad \text{as } j \to \infty.     	          Similiarly, $\lim\limits_{j \to \infty} \int_{B_{r_{1}}(x_{0})} \eta_{j}(\rho) \psi \mathrm{d}\mathbf{\Delta}u = 0$.          Therefore, we get that          	\lim_{j \to \infty} \int_{B_{R_{2}}(x_{0})} \psi_{j} \mathrm{d}\mathbf{\Delta}u = \int_{B_{r_{2}}(x_{0}) \setminus B_{r_{1}}(x_{0})} \psi \mathrm{d}\mathbf{\Delta}u.          On the other hand, we have that          	     		\int_{B_{R_{2}}(x_{0})} \psi_{j} \mathrm{d}\mathbf{\Delta}u & = - \int_{B_{R_{2}}(x_{0})} \langle \nabla u, \nabla \psi_{j} \rangle \mathrm{d}m\\     		& = - \int_{B_{R_{2}}(x_{0})} \langle \nabla u, \eta_{j} \nabla \psi + \psi \nabla \eta_{j} \rangle \mathrm{d}m\\     		& = - \int_{B_{r_{2}}(x_{0}) \setminus B_{r_{1}}(x_{0})} \langle \nabla u, \nabla \psi \rangle \mathrm{d}m\\     		& - \Big(\int_{B_{R_{2}(x_{0})} \setminus B_{r_{2}}(x_{0})} + \int_{B_{r_{1}}(x_{0})} \Big) \langle \nabla u, \nabla \psi \rangle \eta_{j} \mathrm{d}m\\     		& - \int_{B_{R_{2}}(x_{0})} \langle \nabla u, \nabla \eta_{j} \rangle \psi \mathrm{d}m     	          We estimate $\int_{B_{R_{2}(x_{0})} \setminus B_{r_{2}}(x_{0})} \langle \nabla u, \nabla \psi \rangle \eta_{j} \mathrm{d}m$ as follow:          	     		\left| \int_{B_{R_{2}(x_{0})} \setminus B_{r_{2}}(x_{0})} \langle \nabla u, \nabla \psi \rangle \eta_{j} \mathrm{d}m \right| & \le \int_{B_{r_{2} + j^{-1}}(x_{0}) \setminus B_{r_{2}}(x_{0})} \lvert \nabla u \rvert \lvert \nabla \psi \rvert \mathrm{d}m\\     		& \le \Big(\sup_{[R_{1},R_{2}]} \lvert {\phi}' \rvert \Big) \lvert \nabla u \rvert_{L^{2}(B_{r_{2} + j^{-1}}(x_{0}) \setminus B_{r_{2}}(x_{0}))} \Big(m(B_{r^{2}+j^{-1}}(x_{0})\setminus B_{r_{2}}(x_{0}))\Big)^{1/2}\\     		& \to 0,\quad \text{as } j \to \infty.     	          Similiarly, we have that $\lim\limits_{j \to \infty} \int_{B_{r_{1}}(x_{0})} \langle \nabla u, \nabla \psi \rangle \eta_{j} \mathrm{d}m = 0$.          While for $\int_{B_{R_{2}}(x_{0})} \langle \nabla u, \nabla \eta_{j} \rangle \psi \mathrm{d}m$, we have that          	     		\int_{B_{R_{2}}(x_{0})} \langle \nabla u, \nabla \eta_{j} \rangle \psi \mathrm{d}m & = \Big(- \int_{B_{r_{2} + j^{-1}}(x_{0}) \setminus B_{r_{2}}(x_{0})} + \int_{B_{r_{1}}(x_{0}) \setminus B_{r_{1} - j^{-1}}(x_{0})} \Big) \langle \nabla u, j \nabla \rho \rangle \psi \mathrm{d}m\\     		& = - \int_{B_{r_{2} + j^{-1}}(x_{0}) \setminus B_{r_{2}}(x_{0})} j \langle \nabla u, \nabla \rho \rangle (\phi(r_{2}) + \phi - \phi(r_{2})) \mathrm{d}m\\     		& + \int_{B_{r_{1}}(x_{0}) \setminus B_{r_{1} - j^{-1}}(x_{0})} j \langle \nabla u, \nabla \rho \rangle (\phi(r_{1}) + \phi - \phi(r_{1})) \mathrm{d}m     	          Since          	     		\left| \int_{B_{r_{2} + j^{-1}}(x_{0}) \setminus B_{r_{2}}(x_{0})} j \langle \nabla u, \nabla \rho \rangle (\phi - \phi(r_{2})) \mathrm{d}m \right| & \le \Big(\sup_{[R_{1},R_{2}]} \lvert {\phi}' \rvert\Big) \int_{B_{r_{2} + j^{-1}}(x_{0}) \setminus B_{r_{2}}(x_{0})} \lvert \nabla u \rvert \lvert \nabla \rho \rvert \mathrm{d}m\\     		& \to 0,\quad \text{as } j \to \infty.     	          Similiarly, $\lim_{j \to \infty} \int_{B_{r_{1}}(x_{0}) \setminus B_{r_{1} - j^{-1}}(x_{0})} j \langle \nabla u, \nabla \rho \rangle \big(\phi - \phi(r_{1})\big) \mathrm{d}m = 0$.          Therefore, we get that           	     		\lim_{j \to \infty} \int_{B_{R_{2}}(x_{0})} \psi_{j} \mathrm{d}\mathbf{\Delta}u & = - \int_{B_{r_{2}}(x_{0}) \setminus B_{r_{1}}(x_{0})} \langle \nabla u, \nabla \psi \rangle \mathrm{d}m\\     		& + \phi(r_{2}) \left. \frac{\mathrm{d}}{\mathrm{d}s} \right|_{s = r_{2}} \int_{B_{s}(x_{0})} \langle \nabla u, \nabla \rho \rangle \mathrm{d}m - \phi(r_{1}) \left. \frac{\mathrm{d}}{\mathrm{d}s} \right|_{s = r_{1}} \int_{B_{s}(x_{0})} \langle \nabla u, \nabla \rho \rangle \mathrm{d}m     	          The conclusion follows from \eqref{step_1}\eqref{step_2}.",2502.01064
proof,"Recall that     	     		\lvert \nabla u_{i} \rvert^{2}(r,\xi) = \lvert \nabla_{\mathbb{R}^{+}} u_{i} (\cdot,\xi)\rvert^{2} + r^{-2} \lvert \nabla_{\Sigma} u_{i}(r,\cdot) \rvert^{2}(\xi).     	     	The conclusion follows from the definition of $\lambda(\Gamma_{i}(r))$.",2502.01064
proof,"Let $f(r,\theta) = f(x):=d(x,p)$. For each $\phi \in \mathrm{LIP}_{0}(C(\Sigma)\setminus\{p\})$, it holds that     	     		     			&\int_{C(\Sigma)} \langle \nabla \phi ,\nabla f^{2-N} \rangle \mathrm{d}m_{C}\\     			= & \int_{C(\Sigma)} (2-N)f^{1-N} \langle \nabla \phi ,\nabla f \rangle \mathrm{d}m_{C}\\     			= & \int_{0}^{\infty} \int_{\Sigma} (2-N)r^{1-N} \Big( \langle \nabla_{\mathbb{R}^{+}} \phi, \nabla_{\mathbb{R}^{+}} f \rangle + r^{-2}\langle \nabla_{\Sigma} \phi, \nabla_{\Sigma} f \rangle \Big) r^{N-1} \mathrm{d}m_{\Sigma}\mathrm{d}r.     		     	     	Note that $f (r,\cdot) \equiv r$ on $\{r\} \times \Sigma$. Thus $\nabla_{\Sigma} f \equiv 0, \nabla_{\mathbb{R}^{+}} f \equiv 1$ and therefore     	     		     			\int_{C(\Sigma)} \langle \nabla \phi, \nabla f^{2-N}\rangle \mathrm{d}m_{C} =& (2-N) \int_{0}^{\infty} \int_{\Sigma} \frac{\mathrm{d}}{\mathrm{d}r} \phi \mathrm{d}m_{\Sigma}\mathrm{d}r\\     			= & (2-N)\int_{\Sigma} \Big(\lim_{r \to \infty} \phi (r,\theta) - \lim_{r\to 0} \phi(r,\theta) \Big) \mathrm{d}m_{\Sigma}\\     			= & 0,     		     	     	i.e. $\mathbf{\Delta} d(x,p)^{2-N} = 0$ in $C(\Sigma) \setminus \{p\}$ as a Radon measure.",2502.01064
proof,"Since $u_{i}\mathbf{\Delta} u_{i} \ge 0$ in $C(\Sigma)$, we get that     	     		\mathbf{\Delta} \frac{u_{i}^{2}}{2} = \frac{1}{2}u_{i}\mathbf{\Delta} u_{i} + \lvert \nabla u_{i} \rvert^{2} \ge \lvert u_{i} \rvert^{2},\quad \text{in } C(\Sigma).     	     	Therefore, we get that     	     		A_{i}(r) \le \int_{B_{r}(p)} \frac{1}{d(x,p)^{N-2}} \mathrm{d}\mathbf{\Delta} \frac{u_{i}^{2}}{2}.     	     	By Lemma \ref{Stokes_1} and Lemma \ref{Stokes_2}, we have that, for almost all $0<r_{1}<r_{2}<r$,     	     		     			& \int_{B_{r_{2}}(p)\setminus B_{r_{1}}(p)} \frac{u_{i}^{2}}{2} \mathrm{d} \mathbf{\Delta} d(x,p)^{2-N} - \frac{2-N}{2} \int_{\Sigma} u_{i}^{2}(r_{2},\cdot) \mathrm{d}m_{\Sigma} + \frac{2-N}{2} \int_{\Sigma} u_{i}^{2}(r_{1},\cdot) \mathrm{d}m_{\Sigma}\\     			= & - \int_{B_{r_{2}}(p)\setminus B_{r_{1}}(p)} \langle \nabla \frac{u_{i}^{2}}{2},\nabla d(x,p)^{2-N} \rangle \mathrm{d}m_{C}\\     			= & \int_{B_{r_{2}}(p) \setminus B_{r_{1}}(p)} d(x,p)^{2-N} \mathrm{d}\mathbf{\Delta} \frac{u_{i}^{2}}{2} -r_{2} \int_{\Sigma} u_{i}(r_{2},\cdot) \nabla_{\mathbb{R}^{+}} u_{i}(r_{2},\cdot) \mathrm{d}m_{\Sigma} + r_{1} \int_{\Sigma} u_{i}(r_{1},\cdot) \nabla_{\mathbb{R}^{+}} u_{i}(r_{1},\cdot) \mathrm{d}m_{\Sigma}.     		     	     	Since $\lim\limits_{x \to p} u_{i}(x) = u_{i}(p)=0$, we have that     	     		\lim\limits_{r_{1} \to 0} \int_{\Sigma} u_{i}^{2}(r_{1},\cdot) \mathrm{d}m_{\Sigma} = 0.     	     	Recall that we always assume that $A_{i}(r) < \infty$. Thus, we have that     	     		A_{i}(r) = \int_{0}^{r} \int_{\Sigma} \rho \lvert \nabla u_{i} \rvert^{2}(\rho,\xi) \mathrm{d}m_{\Sigma}(\xi) \mathrm{d}\rho \to 0,\quad \text{as } r \to 0.     	     	On the other hand, for each $r > 0$, the set     	     		\{\rho \in (\frac{r}{2},r) : \int_{\Sigma} \rho \lvert \nabla u_{i} \rvert^{2}(\rho,\cdot) \mathrm{d}m_{\Sigma} \le \frac{4A_{i}(r)}{\rho}\}     	     	has positive $\mathcal{L}^{1}$ measure. In particular, there exists a sequence of $r_{1} \to 0$ with \eqref{equation_1_lemma_4_proof_of_main_theorem} holds such that     	     		     			& r_{1} \int_{\Sigma} u_{i}(r_{1},\cdot) \lvert \nabla_{\mathbb{R}^{+}}u_{i}\rvert(r_{1},\cdot) \mathrm{d}m_{\Sigma}\\     			\le & \lvert u_{i}(r_{1},\cdot) \rvert_{L^{2}(\Sigma,m_{\Sigma})} \Big(\int_{\Sigma} r_{1}^{2} \lvert \nabla u_{i} \rvert^{2}(r_{1},\cdot) \mathrm{d}m_{\Sigma}\Big)^{\frac{1}{2}},\\     			\to& 0,\quad \text{as } r_{1} \to 0.     		     	     	Finally, by Lemma \ref{lemma_3_proof_of_main_theorem}, we have that     	     		\int_{B_{r_{2}}(p)\setminus B_{r_{1}}(p)} \frac{u_{i}^{2}}{2} \mathrm{d}\mathbf{\Delta} d(x,p)^{2-N} = 0.     	     	By \eqref{equation_1_lemma_4_proof_of_main_theorem}, \eqref{equation_2_lemma_4_proof_of_main_theorem}, \eqref{equation_3_lemma_4_proof_of_main_theorem},\eqref{equation_4_lemma_4_proof_of_main_theorem}, we conclude that, for almost all $r > 0$, it holds that     	     		     			A_{i}(r) & \le \int_{B_{r}(p)} \frac{1}{d(x,p)^{N-2}} \mathrm{d}\mathbf{\Delta} \frac{u_{i}^{2}}{2}\\     			& = \int_{\Sigma} ru_{i}(r,\cdot) \nabla_{\mathbb{R}^{+}} u_{i}(r,\cdot) + \frac{N-2}{2} u_{i}^{2}(r,\cdot) \mathrm{d}m_{\Sigma}\\     			& = \int_{\Gamma_{i}(r)} ru_{i}(r,\cdot) \nabla_{\mathbb{R}^{+}} u_{i}(r,\cdot) + \frac{N-2}{2} u_{i}^{2}(r,\cdot) \mathrm{d}m_{\Sigma}.",2502.01064
proof,"[Proof of Theorem \ref{main_theorem}]     	For each $r$, we choose $\beta_{i}(r) \in (0,1]$ be such that     	     		\frac{N-2}{2} = \frac{(1-\beta_{i}(r))\lambda(\Gamma_{i}(r))}{2\sqrt{\beta_{i}(r)\lambda(\Gamma_{i}(r))}}.     	     	We let $\alpha_{i}(r) := \sqrt{\beta_{i}(r)\lambda(\Gamma_{i}(r))}$. Then $\alpha_{i}(r)$ is the positive solution to the following equation:     	     		\lambda(\Gamma_{i}(r)) = \alpha_{i}(r)\big(N-2+\alpha_{i}(r)\big).     	     	Let $\overline{\Gamma}_{i}(r)$ be a geodesic ball in the sphere $\partial B_{1} \subset \mathbb{R}^{N}$ such that     	     		\frac{m_{\Sigma}(\Gamma_{i}(r))}{m_{\Sigma}(\Sigma)} = \frac{\mathrm{Vol}(\overline{\Gamma}_{i}(r))}{\mathrm{Vol}(\partial B_{1})}.     	     	Then, by Theorem \ref{Faber_Krahn}, we get that $\lambda (\Gamma_{i}(r)) \ge \lambda (\overline{\Gamma}_{i}(r))$ and therefore     	     		\alpha_{i}(r) \ge \alpha (\overline{\Gamma}_{i}(r)).     	     	By Lemma \ref{Friedland-Haymen_inequality}, we get that     	     		\alpha_{1}(r) + \alpha_{2}(r) \ge \alpha(\overline{\Gamma}_{1}(r))+\alpha(\overline{\Gamma}_{2}(r)) \ge 2.     	     	By Lemma \ref{lemma_2_proof_of_main_theorem} and Lemma \ref{lemma_4_proof_of_main_theorem}, we get that     	     		     			A_{i}^{\prime}(r) & \ge \int_{\Gamma_{i}(r)} 2\sqrt{\beta_{i}(r)\lambda(\Gamma_{i}(r))} u_{i}(r,\xi) \lvert \nabla_{\mathbb{R}^{+}} u_{i} (\cdot,\xi)\rvert(r) + (1-\beta_{i}(r)) \lambda(\Gamma_{i}(r)) r^{-1} \lvert u_{i}(r,\xi) \rvert^{2} \mathrm{d}m_{\Sigma}\\     			& = 2 \alpha_{i}(r) \int_{\Gamma_{i}(r)} u_{i}(r,\xi) \lvert \nabla_{\mathbb{R}^{+}} u(\cdot,\xi) \rvert(r) + \frac{N-2}{2}r^{-1} \lvert u_{i}(r,\xi)\rvert^{2} \mathrm{d}m_{\Sigma}\\     			& \ge \frac{2\alpha_{i}(r)}{r}A_{i}(r).     		     	     	Finally, by Corollary \ref{corollary_1_proof_of_main_theorem}, we get that     	     		     			\frac{J^{\prime}(r)}{J(r)} & \ge \frac{A_{1}^{\prime}(r)}{A_{1}(r)} + \frac{A_{2}^{\prime}(r)}{A_{2}(r)} - \frac{4}{r}\\     			& \ge \frac{2\big(\alpha_{1}(r)+\alpha_{2}(r)\big)-4}{r} \ge 0.",2502.01064
proof,"[Proof of Theorem \ref{rigidity_theorem}] 	If $0<J(r_{1})=J(r_{2})<\infty$, then all inequality in the proof of Theorem \ref{main_theorem} must be equality. At first, for almost all $r \in (r_{1},r_{2})$, it holds that 	 		 			& \lambda(\Gamma_{i}(r))=\lambda(\overline{\Gamma}_{i}(r))\\ 			& \alpha_{1}(r)+\alpha_{2}(r) = \alpha(\overline{\Gamma}_{1}(r)) + \alpha (\overline{\Gamma}_{2}(r)) = 2, 		 	 	where $\alpha_{i}(r),\Gamma_{i}(r)$ and $\overline{\Gamma}_{i}(r)$ are as in the proof of Theorem \ref{main_theorem}. By Theorem \ref{Faber_Krahn}, the first equality above implies that $(\Sigma,d_{\Sigma},m_{\Sigma})$ is a spherical suspension. By Theorem \ref{Friedland-Haymen_inequality}, the second equality above implies that $\overline{\Gamma}_{i}(r)$ are half-spheres. If $(\Sigma,d_{\Sigma},m_{\Sigma})$ is an $(N-1)$-dimensional smooth Riemannian manifold, then, by Theorem \ref{Faber_Krahn}, $(\Sigma,d_{\Sigma},m_{\Sigma})$ is isometric to the sphere $\partial B_{1} \subset \mathbb{R}^{N}$. In this case, $\Gamma_{1}(r),\Gamma_{2}(r)$ are upper and lower half-spheres, i.e. there exists a $\nu(r) \in \partial B_{1}$ such that 	 		\Gamma_{1}(r) = \{x \in \partial B_{1} : x\cdot \nu(r) >0\},\quad \Gamma_{2}(r) = \{x\in \partial B_{1} : x\cdot \nu(r)<0\}. 	 	Next, the inequality in Lemma \ref{lemma_4_proof_of_main_theorem} must be equality. This requires that 	 		\lvert \nabla u_{i} \rvert^{2} = \mathbf{\Delta} \frac{u_{i}^{2}}{2},\quad \text{in } B_{r_{2}}(p), 	 	i.e. $u_{i}\mathbf{\Delta}u_{i}=0$ in $B_{r_{2}}(p)$. This implies that $u_{i}$ is harmonic in $B_{r_{2}}(p) \cap \{u_{i}>0\}$. On the other hand, the inequality in Lemma \ref{lemma_2_proof_of_main_theorem} must be equality. This requires that 	 		\int_{\Gamma_{i}(r)} \lvert \nabla_{\Sigma} u_{i}(r,\cdot)\rvert^{2} \mathrm{d}m_{\Sigma} = \lambda(\Gamma_{i}(r)) \int_{\Gamma_{i}(r)} \lvert u_{i}\rvert^{2}(r,\cdot) \mathrm{d}m_{\Sigma},\quad \text{for almost all } r \in (r_{1},r_{2}), 	 	i.e. $u_{i}(r,\cdot)$ is the eigenfunction. Since $\Gamma_{i}(r)$ are half-spheres, we get that $u_{i}$ has the form 	 		u_{i}(x) = \big(a_{i}(r)\cdot x\big)^{+},\quad \text{for } r_{1}<r=\lvert x\rvert <r_{2}, 	 	where $a_{i} : (r_{1},r_{2}) \to \mathbb{R}^{N}$. A simple calculation gives that 	 		0=\Delta u_{i}(x) = \big(a_{i}^{\prime\prime}(r)+\frac{N+1}{r}a_{i}^{\prime}(r)\big) \cdot x,\quad \text{in } \{r_{1}<\lvert x\rvert <r_{2}\} \cap \{u_{i}>0\}. 	 	This implies that $a_{i}$ solves the following ODE: 	 		a_{i}^{\prime\prime}(r) + \frac{N+1}{r} a_{i}^{\prime}(r)=0,\quad r_{1}<r<r_{2}. 	 	Therefore, $a_{i}(r) = \nu_{i} + \frac{\sigma_{i}}{r^{N}}$ for some constant vector $\nu_{i},\sigma_{i} \in \mathbb{R}^{N}$. Hence 	 		u_{i}(x) = \big((\nu_{i}+\frac{\sigma_{i}}{\lvert x \rvert^{N}}) \cdot x\big)^{+},\quad r_{1}<\lvert x \rvert <r_{2}. 	 	By the unique continuation of harmonic function, we get that 	 		u_{i}(x) = \big((\nu_{i}+\frac{\sigma_{i}}{\lvert x \rvert^{N}}) \cdot x\big)^{+},\quad 0<\lvert x \rvert <r_{2}. 	 	Finally, since $\lim\limits_{x \to p}u_{i}(x)=0$, we get that $\sigma_{i}=0$. While $J(r_{2})>0$, we get that $\nu_{i}$ is non-zero. Thus $u_{i}$ has the form 	 		u_{1}(x) = k_{1}(x\cdot \nu)^{+},\quad u_{2}(x) = k_{2}(x\cdot \nu)^{-},\quad \text{in } B_{r_{2}}(p), 	 	for some constant $k_{1},k_{2}>0$ and some unit vector $\nu \in \partial B_{1}$.",2502.01064
lemma,"Let $(X,d,m)$ be an $RCD(K,N)$-space, $K \in \mathbb{R}, N \in (1,\infty)$. Let $\overline{B_{R_{2}}(x_{0})} \setminus B_{R_{1}}(x_{0}) \subset X$, $\rho(x) := d(x,x_{0})$, $\phi \in C^{2}([R_{1},R_{2}])$, and let $\psi := \phi(\rho)$. Suppose that     	     		u \in C(\overline{B_{R_{2}}(x_{0})} \setminus B_{R_{1}}(x_{0})) \cap W^{1,2}(B_{R_{2}}(x_{0}) \setminus B_{R_{1}}(x_{0})),     	         and suppose that $\mathbf{\Delta} \psi$ is a signed Radon measure. Then it holds that                  	         		\int_{B_{r_{2}}(x_{0}) \setminus B_{r_{1}}(x_{0})} u \mathrm{d} \mathbf{\Delta} \psi = & - \int_{B_{r_{2}}(x_{0}) \setminus B_{r_{1}}(x_{0})} \langle \nabla u, \nabla \psi \rangle \mathrm{d}m\\         		& + {\phi}'(r_{2}) \left. \frac{\mathrm{d}}{\mathrm{d}s} \right|_{s = r_{2}} \int_{B_{s}(x_{0})} u \mathrm{d}m - {\phi}'(r_{1}) \left. \frac{\mathrm{d}}{\mathrm{d}s} \right|_{s = r_{1}} \int_{B_{s}(x_{0})} u \mathrm{d}m         	                  for almost all $R_{1} < r_{1} < r_{2} < R_{2}$.",2502.01064
lemma,"Let $(X,d,m)$ be an $RCD(K,N)$-space, $K \in \mathbb{R}, N \in (1,\infty)$. Let $\overline{B_{R_{2}}(x_{0})} \setminus B_{R_{1}}(x_{0}) \subset X$, $\rho(x) := d(x,x_{0})$, $\phi \in C^{1}([R_{1},R_{2}])$, and let $\psi := \phi(\rho)$. Suppose that     	     		u \in C(\overline{B_{R_{2}}(x_{0})} \setminus B_{R_{1}}(x_{0})) \cap W^{1,2}(B_{R_{2}}(x_{0}) \setminus B_{R_{1}}(x_{0})),     	     	and suppose that $\mathbf{\Delta} u$ is a signed Radon measure. Then it holds that     	     		     			\int_{B_{r_{2}}(x_{0}) \setminus B_{r_{1}}(x_{0})} \psi \mathrm{d} \mathbf{\Delta} u = & - \int_{B_{r_{2}}(x_{0}) \setminus B_{r_{1}}(x_{0})} \langle \nabla u , \nabla \psi \rangle \mathrm{d}m\\     			& + \phi(r_{2}) \left. \frac{\mathrm{d}}{\mathrm{d}s} \right|_{s = r_{2}} \int_{B_{s}(x_{0})} \langle \nabla u, \nabla \rho \rangle \mathrm{d}m - \phi(r_{1}) \left. \frac{\mathrm{d}}{\mathrm{d}s} \right|_{s = r_{1}} \int_{B_{s}(x_{0})} \langle \nabla u, \nabla \rho \rangle \mathrm{d}m     		     	         for almost all $R_{1} < r_{1} < r_{2} < R_{2}$.",2502.01064
lemma,"If $A_{i}(r_{0}) < \infty$ for some $r_{0} >0$, then $A_{i}(r)$ is absolutely continuous in $r \in (0,r_{0})$ and thus differentiable for almost all $r \in (0,r_{0})$. Moreover, at a differentiable point $r \in (0,r_{0})$, it holds that      	      		A_{i}^{\prime}(r) = \int_{\Sigma} r \lvert \nabla u_{i} \rvert^{2}(r,\cdot) \mathrm{d}m_{\Sigma}.",2502.01064
lemma,"For almost all $r \in (0,\infty)$, it holds that     	     		A_{i}^{\prime}(r) \ge \int_{\Gamma_{i}(r)} r\lvert \nabla_{\mathbb{R}^{+}} u_{i}(\cdot,\xi) \rvert^{2} (r) + \lambda(\Gamma_{i}(r))r^{-1} \lvert u_{i}(r,\xi) \rvert^{2} \mathrm{d}m_{\Sigma}.     	     	Recall that $\lambda(\Gamma_{i}(r))$ is the first eigenvalue of $\Gamma_{i}(r)$.",2502.01064
lemma,"$\mathbf{\Delta} d(x,p)^{2-N} \equiv 0$ in $C(\Sigma) \setminus \{p\}$ as a Radon measure.",2502.01064
lemma,"For almost all $r \in (0,\infty)$, it holds that     	      		A_{i}(r) \le r \int_{\Gamma_{i}(r)} u_{i}(r,\xi) \lvert \nabla_{\mathbb{R}^{+}} u_{i}(\cdot,\xi) \rvert(r) + \frac{N-2}{2}r^{-1}u_{i}^{2}(r,\xi) \mathrm{d}m_{\Sigma}.",2502.01064
theorem,"[Sachs' theorem]     Let \(G\) be a graph in \(n\) vertices and \(\phi_G(x) = \sum_{k = 0}^n b_k x^{n-k}\) be its characteristic polynomial. The coefficients \((b_k)_{k \geq 1}\) satisfies the equality     \[         b_k = \sum_{S \in \mathcal{S}_k(G)} (-1)^{r(S)}2^{c(S)},     \]     where \(\mathcal{S}_k(G)\) denotes the set of sub-graphs of \(G\) with exactly \(k\) vertices that are Sachs' graphs. Furthermore, \(b_0 = 1\).",2502.01065
theorem,"[Sach's theorem for weighted graphs]     Let \(G\) be a weighted graph in \(n\) vertices and \(\phi_G(x) = \sum_{k = 0}^n b_k x^{n-k}\) its characteristic polynomial. The coefficients \((b_k)_{k \geq 1}\) satisfies the equality     \[         b_k = \sum_{S \in \mathcal{S}_k(G)} (-1)^{r(S)}2^{c(S)}W(S),     \]     where \(\mathcal{S}_k(G)\) denotes the set of Sachs' sub-graphs of \(G\) with exactly \(k\) vertices. Furthermore, \(b_0 = 1\).",2502.01065
theorem,"[Ky-Fan's theorem for weighted sub-graphs]     Let \(G\) be a weighted graph and \(H_1, \ldots, H_n\) be weighted sub-graphs of \(G\) whose weight matrices satisfy that \(W_G = W_{H_1} + \ldots + W_{H_n}\). Then     \[         \energy{G} \leq \energy{H_1} + \ldots + \energy{H_n},     \]     with equality if and only if \(n = 1\).",2502.01065
theorem,"Every connected graph \(G = (V,E)\) with at least three nodes satisfies the inequality     \[         \energy{G} \leq \sum_{v \in V'} \sqrt{3l(v) + d(v)} = \sum_{v \in V'} \sqrt{4l(v) + \delta(v)}.     \]     This equality holds if and only if \(G\) is isomorphic to a star.",2502.01065
theorem,"For a graph \(G = (V,E)\) we have     \[     \energy G \leq 2 e_{11} + \sum_{v \in V'} \sqrt{3l(v) + d(v)}.     \]",2502.01065
theorem,"Let \(f\) be the real function defined by     \[         f(x,y) = \sqrt{4x + 4(y-1)} - \sqrt{4x + y}, \qquad \mbox{for } x, y \geq 1,     \]     \(T = (V,E)\) be a tree with \(n \geq 3\) vertices and \(V_1, V_2\) be the subsets of vertices defined by     \[         V_1 := \{v \in V' : \delta(v) = 1\}, \qquad V_2 := \{v \in V' : \delta(v) \geq 2\}.     \]     Theorem \ref{TP} improves Proposition \ref{eq:AD} for the energy of \(T\) if one of the following conditions hold:     [i)]         \item \(\sum_{v \in V'} f(l(v),\delta(v)) \geq 0;\)         \item \(\sum_{v \in V_1} f(l(v),1) + \sum_{v \in V_2} f(l(v),2) \geq 0;\)         \item \(\left(\sqrt{l_2 + 1} - \sqrt{l_2 + 1/2}\right)\abs{V_2} \geq \left(\sqrt{l_1 + 1/4} - \sqrt{l_1}\right)\abs{V_1},\) where \(l_1 := \min_{v \in V_1} l(v);\) and \(l_2 := \max_{v \in V_2} l(v);\)         \item \(2\left(\sqrt{n} - \sqrt{n-1/2}\right)\abs{V_2} \geq \abs{V_1}.\)",2502.01065
theorem,"With high probability, as $n$ tends to infinity, the next inequality follows $$\limsup_{n\to\infty} \frac{\energy{T_n}}{n} \leq 0.96.$$",2502.01065
theorem,"With high probability,        \limsup_{n \to \infty} \frac{\energy{G_n}}{n} &\leq& 2\lambda e^{-2\lambda} + e^{-\lambda}\sqrt{3e^{-\lambda} + 1}\sum_{k = 2}^{\infty} \frac{\lambda^k\sqrt{k}}{k!}",2502.01065
theorem,"For \(\lambda \in (0,4/3]\), it is satisfied that \[     \limsup_{n \to \infty} \frac{\energy{G_n}}{n} < 1. \]",2502.01065
definition,"[Sachs' graph]     A graph \(S\) is called a Sachs' graph if its connected components are isomorphic to \(K_2\) or to a cycle. Associated to a Sachs' graph \(S\), we can define \(r(S)\) to be the number of connected components of \(S\) and \(c(S)\) to be the number of connected components in \(S\) isomorphic to a cycle.",2502.01065
definition,"[Sachs' sub-graph for a weighted graph]     Let \(G\) be a weighted graph in \(n\) vertices \(v_1, \ldots, v_n\) with weight matrix \(W_G = (w_{ij})_{i,j}\). A sub-graph \(S\) of \(G\) is called a Sachs' sub-graph if its connected components are isomorphic to a weighted \(K_2\) or to a weighted cycle. Associated to \(S\), we can define the function \(W(S)\) which is the product of the weights of its connected components. The weight of a component isomorphic to a weighted \(K_2\) is \(w_{i,j}^2\) the square of the weight of its only edge \(\{v_i,v_j\}\) and the weight of a component isomorphic to a weighted cycle is the product of the weights \(w_{i,j}\) of all its edges \(\{v_i,v_j\}\). In addition, we define \(r(S)\) and \(c(S)\) to be the number of connected components of \(S\) and the number of connected components in \(S\) isomorphic to a cycle, respectively.",2502.01065
proof,"By Sachs' theorem for weighted graphs, we get the characteristic polynomial $\phi_S$ of \(S\) given by      \phi_{S}(x) &= x^{n + 1} - \left(\sum_{i = 1}^n w_i^2\right)x^{n - 1} = x^{n - 1}\left(x^2 - \sum_{i = 1}^n w_i^2\right).       We conclude that the eigenvalues of \(S\) are 0, with multiplicity $n-1$ and \(\pm\sqrt{\sum_{i = 1}^n w_i^2}\). Therefore, \[     \energy{S_n} = 2\sqrt{\sum_{i = 1}^n w_i^2}. \]",2502.01065
proof,"Let \(v \in V'\) and define \(S(v)\) as the weighted sub-graph of \(G\) induced by \(N(v) \cup \{v\}\). We assign weights to every edge \(\{v,w\}\) of \(S(v)\) as follows:              \item if \(w \in L(v)\), we assign a weight of 1 to \(\{v,w\}\),         \item if \(w \notin L(v)\), we assign a weight of \(\frac{1}{2}\) to \(\{v,w\}\).           Notice that     \[         G = \bigcup_{v \in V'} S(v).     \]     Indeed, it is clear that     \[         \bigcup_{v \in V'} V(S(v)) \subseteq V(G).     \]     On the other hand, if \(v \in L\), there is a unique \(w \in V\) such that \(v \sim w\). Since \(G\) is connected and it has at least three vertices, we have \(v \in N(w)\) with \(w \in V'\). Therefore, since \(V(S(v)) = N(v) \cup \{v\}\), one can see that     \[         V(G) \subseteq \bigcup_{v \in V'} V(S(v))     \]     and we can conclude that     \[         V(G) = \bigcup_{v \in V'} V(S(v)).     \]     In a similar way, we can see that     \[         E(G) = \bigcup_{v \in V'} E(S(v)).     \]          It only remains to check that each edge has a total weight of 1 when considering the decomposition into weighted stars of the graph \(G\). Let \(\{v,w\} \in E\) be an edge of \(G\). Since \(V = L \cup V'\) with \(L \cap V' = \emptyset\), we examine two cases:              \item If \(v \in L\), then the edge \(\{v,w\}\) is the only edge that contains to \(v\) as an endpoint. The vertex \(v\) appears only once in the star decomposition of \(G\) and it is in \(S(w)\) with weight 1. It is the same analysis when \(w \in L\).         \item If \(v,w \in V'\), the edge \(\{v,w\}\) appears only twice in the star decomposition of \(G\). It appears once in \(S(v)\) with weight \(\frac{1}{2}\) and another time in \(S(w)\) with the same weight of \(\frac{1}{2}\). At the end, the edge \(\{v,w\}\) has a total weight of 1.           By using Ky-Fan theorem for weighted sub-graphs, we get the inequality     \[         \energy G \leq \sum_{v \in V'} \energy{S(v)},     \]     where the equality holds if and only if \(G\) has just one weighted star component, i.e., if and only if \(G\) is isomorphic to a star.  Consequently, by Lemma \ref{lema:weighedstar}     \[         \energy G \leq \sum_{v \in V'} \sqrt{3l(v) + d(v)} = \sum_{v \in V'} \sqrt{4l(v) + \delta(v)},     \]     where the last inequality holds because \(d(v) = l(v) + \delta(v)\) for every vertex \(v \in V\).",2502.01065
proof,"Let \(G = (V,E)\) be a graph with connected components \(H_1, \ldots, H_n\). Since the energy is linear over connected components, we obtain     \[     \energy G = \sum_{k = 1}^n \energy{H_k}.     \]      Notice there are three types of connected components: isolated vertices which have energy zero; isolated edges which have energy 2; connected graphs with at least three vertices. Since     \[         V'(G) = \bigcup_{k = 1}^n V'(H_k)     \]     where \(V'(H_1), \ldots V'(H_n)\) are disjoint by pairs and \(V'(H) = \emptyset\) for a graph \(H\) isomorphic to an edge, we conclude by Theorem \ref{TP} that     \[         \energy G \leq 2 e_{11} + \sum_{v \in V'} \sqrt{3l(v) + d(v)}.     \]",2502.01065
proof,"Let \(G = (V,E)\) be a graph. By the theorem below and Cauchy-Schwartz inequality, we get the next series of inequalities              \energy G &\leq \sum_{v \in V'} \sqrt{3l(v) + d(v)}\\         &\leq \sqrt{\abs{V'}\left(\sum_{v \in V'} 3l(v) + d(v)\right)}.           Since $G$ does not have isolated vertices, we have that \(\abs{V'} = \abs{V} - \abs{L}\). Note also that for every leaf \(v \in L\) of \(G\) there exist a unique \(w \in L\) where \(v,w\) is and edge counted in \(e_{11}\) or a unique \(w \in V'\) such that \(v \sim w\). Then, for every $v \in L$, it is satisfied that \(l(v) = 1\) if \(v\) is endpoint of an edge counted in \(e_{11}\) or \(l(v) = 0\) otherwise. It follows that     \[         \sum_{v \in V'} l(v) =  \abs{L} - 2e_{11}.     \]      Using that \(\sum_{v \in V} d(v) = 2\abs{E}\), we obtain in a similar way that     \[         \sum_{v \in V'} d(v) = 2\abs{E} - \abs{L}.     \]      Placing all together, we obtain              \energy G &\leq 2e_{11} + \sqrt{2(\abs{V} - \abs{L})(\abs{E} + \abs{L} - 3e_{11})}.",2502.01065
proof,"We have that Theorem \ref{TP} improves Proposition \ref{eq:AD} for the energy of \(T\) if and only if     \[         \sum_{v \in V'} \sqrt{3l(v) + d(v)} \leq \sum_{v \in V} 2\sqrt{d(v) - 1} + 2\left(\sqrt{\Delta} - \sqrt{\Delta - 1}\right),     \]     where \(\Delta\) is the maximum degree of the vertices in \(T\).          Using that \(\sqrt{d(v) - 1} = 0\) for every \(v \in L\) and \(d(v) = \delta(v) + l(v)\), we obtain that the above inequality is equivalent to              0 \leq 2\left(\sqrt{\Delta} - \sqrt{\Delta - 1}\right) + \sum_{v \in V'} \sqrt{4l(v) + 4(\delta(v) - 1)} - \sqrt{4l(v) + \delta(v)}.          In particular, if the inequality     \[         \sum_{v \in V'} f(l(v),\delta(v)) \geq 0     \]     holds, the inequality in \eqref{AD-TP} is satisfied. In consequence, Theorem \ref{TP} improves Proposition \ref{eq:AD} for the energy of \(T\).      We will show that condition ii) implies condition i), condition iii) implies condition ii) and condition iv) implies condition iii) to complete the proof.          Notice now that \(f(x,y)\) is a decreasing function over \(x\) for \(y \geq 4/3\), it is an increasing function over \(x\) for \(y \leq 4/3\) and it is an increasing function over \(y\) for every \(x \geq 1\). This implies the following inequalities:              \sum_{v \in V_1} f(l(v),\delta(v)) \geq \sum_{v \in V_1} f(l(v),1), \qquad \sum_{v \in V_2} f(l(v),\delta(v)) \geq \sum_{v \in V_2} f(l(v),2).          It means condition ii) implies condition i).      In a similar way, we have     \[         \left(\sqrt{l_1 + 1/4} - \sqrt{l_1}\right)\abs{V_1} = -f(l_1,1)\abs{V_1} \geq \sum_{v \in V_1} -f(l(v),1)     \]     and     \[          \sum_{v \in V_2} f(l(v),2) \geq f(l_2, 2)\abs{V_2} = \left(\sqrt{l_2 + 1} - \sqrt{l_2 + 1/2}\right)\abs{V_2},     \]     i.e., condition iii) implies condition ii).      Finally, we have that     \[         \sqrt{l_1 + 1} - \sqrt{l_1 + 1/2} \geq \sqrt{n} - \sqrt{n-1/2} \qquad \mbox{and} \qquad 1/2 \geq \sqrt{l_2 + 1/4} - \sqrt{l_2}     \]     since \(0 \leq l(v) \leq n-1\). In consequence, condition iv) implies condition iii).",2502.01065
proof,"By the Theorem \ref{TP}, we get the next inequality:      \energy{T_n} &\leq \sum_{v \in V'} \sqrt{3l(v) + d(v)}\\     &\leq \sum_{k = 2}^n \sum_{v \in N_k(n)} \sqrt{3l(v) + k}.   For each \(k \geq 2\), by using Cauchy-Schwartz inequality,      \sum_{v \in N_k(n)} \sqrt{3l(v) + k} &\leq \sqrt{\abs{N_k(n)}\left(\sum_{v \in N_k(n)} 3l(v) + k\right)}\\     &= \sqrt{\abs{N_k(n)}\left(3\abs{N_{k,1}(n)} + k\abs{N_k(n)}\right)}\\     &= \abs{N_k(n)}\sqrt{3\frac{\abs{N_{k,1}(n)}}{\abs{N_k(n)}} + k}.   Combining the previous calculations with Proposition \ref{BA-coefficients}, for any fixed \(m \geq 2\) and large \(n\), we get      \frac{1}{n}\energy{T_n} &\leq \sum_{k = 2}^{n} \frac{\abs{N_k(n)}}{n} \sqrt{3\frac{\abs{N_{k,1}(n)}}{\abs{N_k(n)}} + k}\\     &= \sum_{k = 2}^{m} n_k \sqrt{3\frac{n_{k,1}}{n_k} + k} + o(1) + \sum_{k = m+1}^n \frac{\abs{N_k(n)}}{n} \sqrt{3\frac{\abs{N_{k,1}(n)}}{\abs{N_k(n)}} + k}.   Note that, for \(v \in N_k(n)\), we have at most \(d(v) = k\) neighbors that are leaf. Then, we get \[     \abs{N_{k,1}(n)} \leq k\abs{N_k(n)}, \qquad\mbox{for every } k \geq 2. \] Moreover, we have the next inequality (see \cite{Arizmendi22}) \[     \frac{1}{n}\sum_{k = m+1}^n \abs{N_k(n)}\sqrt{k} \leq \frac{2}{m} + o(1). \]  This way,      \frac{1}{n}\energy{T_n} &\leq \sum_{k = 2}^{m} n_k \sqrt{3\frac{n_{k,1}}{n_k} + k} + o(1) + \frac{2}{n}\sum_{k = m+1}^n \abs{N_k(n)}\sqrt{k}\\     &= \sum_{k = 2}^m n_k \sqrt{3\frac{n_{k,1}}{n_k} + k} + \frac{4}{m} + o(1),  where \[     n_k = \frac{4}{k(k+1)(k+2)}, \qquad n_{k,1} = \frac{2(k+2)(k+3)-24}{k(k+1)(k+2)(k+3)}. \]  Since \(m\) is fixed but arbitrary, we obtain the asymptotic bound      \limsup_{n \to \infty} \frac{1}{n}\energy{T_n} &\leq \sum_{k = 2}^{\infty} n_k\sqrt{3\frac{n_{k,1}}{n_k} + k}\\     &= \sum_{k = 2}^{\infty} \frac{4}{k(k+1)(k+2)} \sqrt{\frac{k(5k+21)-18}{2(k+3)}}.   Notice that, for a fixed $m \geq 21$,      \delta &:= \sum_{k = m}^{\infty} n_k \sqrt{3\frac{n_{k,1}}{n_k} + k}     \leq \sum_{k = m}^{\infty} \frac{4\sqrt{3}}{k^{5/2}}\\     &\leq \int_{m-1}^{\infty} \frac{4\sqrt{3}}{x^{5/2}}dx = \frac{8\sqrt{3}}{3(m-1)^{3/2}}.   Taking $m = 10^5 + 1$, we have $\delta = \frac{8\sqrt{3}}{3\cdot 10^{15/2}} \approx 1.46059 \cdot 10^{-7}$. Therefore, \[     \limsup_{n \to \infty} \frac{1}{n}\energy{G} \leq \sum_{k = 2}^{m} n_k \sqrt{3\frac{n_{k,1}}{n_k} + k} + \delta \approx 0.95999. \]",2502.01065
proof,"Let \(n,k \in \N\) be fixed, with \(k < n\), and \(v \in V_n\). Notice that     \[         \Pp{v \in N_k(n)} = \binom{n-1}{k}p^k(1-p)^{n-1-k}     \]     and     \[         \lim_{n \to \infty} \Pp{v \in N_k(n)} = \lim_{n \to \infty} \frac{(n)_k}{n^k}\frac{(np)^k}{k!} \left(1 - \frac{np}{n}\right)^{n-1-k} = n_k.     \]          However,     \[         \abs{N_k(n)} = \sum_{v \in V_n} \mathbbm{1}_{v \in N_k(n)}.     \]     Then,     \[         \E{\frac{\abs{N_k(n)}}{n}} = \frac{1}{n}\sum_{v \in V_n} \E{\mathbbm{1}_{v \in N_k(n)}} = \Pp{v_0 \in N_k(n)},     \]     where \(v_0 \in V_n\) is a fixed vertex. In consequence,     \[         \lim_{n \to \infty} \E{\frac{\abs{N_k(n)}}{n}} = \lim_{n \to \infty} \Pp{v \in N_k(n)} = n_k.     \]      Let \(v,w \in V_n\) be distinct vertices. Considering the possibilities: \(v \sim w\) or \(v \not\sim w\); and the number of shared neighbors \(j\) between \(v\) and \(w\), we obtained              \Pp{v,w \in N_k(n)} &= \sum_{j = 0}^k \binom{n-2}{j}\binom{n-2-j}{k-j}\binom{n-2-k}{k-j}p^{2k}(1-p)^{2n-2k-3}\\         &\quad + \sum_{j = 0}^{k-1} \binom{n-2}{j}\binom{n-2-j}{k-j-1}\binom{n-1-k}{k-j-1}p^{2k-1}(1-p)^{2n-2k-2)}.          Then, using a similar limit to the previously used, we get     \[         \lim_{n \to \infty} \Pp{v,w \in N_k(n)} = n_k^2.     \]          However,              \Var{\frac{\abs{N_k(n)}}{n}} &= \frac{1}{n^2}\left[\sum_{v \in V_n}\E{\mathbbm{1}_{v \in N_k(n)}} + \sum_{\substack{v,w \in V_n\\         v \neq w}} \E{\mathbbm{1}_{v, w \in N_k(n)}}\right] - \E{\frac{\abs{N_k(n)}}{n}}^2\\         &= \frac{1}{n}\Pp{v_0 \in N_k(n)} + \frac{n-1}{n}\Pp{v_0,w_0 \in N_k(n)} - \Pp{v \in N_k(n)}^2,          where \(v_0,w_0 \in V\) are fixed. In consequence,     \[         \lim_{n \to \infty} \Var{\frac{\abs{N_k(n)}}{n}} = 0.     \]     Therefore, \(\abs{N_k(n)}/n\) tends to \(n_k\) almost surely while \(n\) tends to \(\infty\).      Let again \(n,k \in \N\) be fixed, with \(k < n\), and \(v \in V_n\). Note that     \[         \Pp{v \in N_{k,1}(n)} = (n-1)\binom{n-2}{k-1}p^k(1-p)^{2n-k-3}     \]     and     \[         \lim_{n \to \infty} \Pp{v \in N_{k,1}(n)} = n_{k,1}.     \]      Nevertheless,     \[         \abs{N_{k,1}(n)} = \sum_{v \in V_n} \mathbbm{1}_{v \in N_{k,1}(n)}.     \]     It follows that     \[         \E{\frac{\abs{N_{k,1}(n)}}{n}} = \frac{1}{n}\sum_{v \in V_n} \E{\mathbbm{1}_{v \in N_{k,1}(n)}} = \Pp{v \in N_{k,1}(n)}.     \]     As a result,     \[         \lim_{n \to \infty} \E{\frac{\abs{N_{k,1}(n)}}{n}} = \Pp{v \in N_{k,1}(n)} = n_{k,1}.     \]      Let \(v,w \in V_n\) be distinct. If \(v, w \in N_{k,1}(n)\), there exist \(v',w' \in V_n\) such that \(v \sim v'\), \(w \sim w\) and \(d(v') = k = d(w')\). We have several options:              \item \(v' = w'\);         \item \(v' \neq w'\) and \(v' \not\sim w'\);         \item \(v' \neq w'\) and \(v' \sim w'\).          Considering the number of shared neighbors \(j\) and \(w'\), we get              \Pp{v,w \in N_{k,1}(n)} &= (n-2)\binom{n-3}{k-2}p^k(1-p)^{3n-k-4}\\         &\quad + \sum_{j = 0}^{k-1} (n-2)(n-3)\binom{n-4}{j}\binom{n-j-4}{k-j-1}\binom{n-k-3}{k-j-1}p^{2k}(1-p)^{4n-2k-10}\\         &\quad + \sum_{j = 0}^{k-2} (n-2)(n-3)\binom{n-4}{j}\binom{n-j-4}{k-j-2}\binom{n-k-2}{k-j-2}p^{2k-1}(1-p)^{4n-2k-9}.          Using a similar limit to the previously used, we obtained     \[         \lim_{n \to \infty} \Pp{v,w \in N_{k,1}(n)} = n_{k,1}^2.     \]      However,              \Var{\frac{\abs{N_{k,1}(n)}}{n}} &= \frac{1}{n^2}\left[\sum_{v \in V}\E{\mathbbm{1}_{v \in N_{k,1}(n)}} + \sum_{\substack{v,w \in V\\         v \neq w}} \E{\mathbbm{1}_{v, w \in N_{k,1}(n)}}\right] - \E{\frac{\abs{N_{k,1}(n)}}{n}}^2\\         &= \frac{1}{n}\Pp{v_0 \in N_{k,1}(n)} + \frac{n-1}{n}\Pp{v_0,w_0 \in N_{k,1}(n)} - \Pp{v \in N_{k,1}(n)}^2,          where \(v_0,w_0 \in V_n\) are fixed. In consequence,     \[         \lim_{n \to \infty} \Var{\frac{\abs{N_{k,1}(n)}}{n}} = 0.     \]     Therefore, \(\abs{N_{k,1}(n)}/n\) tends to \(n_{k,1}\) almost surely while \(n\) tends to \(\infty\).",2502.01065
proof,"%Note that %\[ %    \frac{1}{n}\abs{E_n} = \frac{1}{n}\sum_{\substack{v,w \in V_n\\ v \neq w}} \mathbbm{1}_{\{v,w\} \in E_n}. %\] %Since the probability of an edge \(\{v,w\}\) is \(p_n\), for every \(v,w \in V_n\) distinct, and every edge appears or not independent from the other, we have %\[ %    \E{\frac{1}{n}\abs{E_n}} = \binom{n}{2}\frac{p_n}{n} %\] %and %\[ %    \Var{\frac{1}{n}\abs{E_n}} = \binom{n}{2}\frac{p_n(1-p_n)}{n^2}. %\] %Then %\[ %    \lim_{n \to \infty} \E{\frac{1}{n}\abs{E_n}} = \frac{\lambda}{2}, \qquad \lim_{n \to \infty} \Var{\frac{1}{n}\abs{E_n}} = 0. %\] %Therefore, with high probability \(\abs{E_n}/n \to \lambda/2\) while \(n \to \infty\).  %",2502.01065
proof,"Let \[     n_k = \frac{\lambda^ke^{-\lambda}}{k!}, \qquad n_{k,1} = \frac{\lambda^ke^{-2\lambda}}{(k-1)!}. \]  Notice that the total number of vertices may be calculated by      \sum_{k = 1}^n \abs{N_k(n)} = n,  while the sum of degrees may be calculated by      \sum_{k = 1}^n k \abs{N_k(n)} = 2\abs{E_n} = n\lambda + o(n),  using the Proposition \ref{ER-edges}.  In the other hand, for any fixed \(m \in \N\), \[     \sum_{k = 1}^m k \,n_k = \lambda e^{-\lambda}\sum_{k = 0}^{m-1} \frac{\lambda^k}{k!} \geq \lambda - \frac{\lambda^{m+1}}{m!} + o(1), \] where the second inequality is result of Taylor's Theorem used in \(e^{\lambda}\), \[     e^{\lambda} = \sum_{k = 0}^{m-1} \frac{\lambda^k}{k!} + \frac{\lambda^m e^{\lambda'}}{m!} + o(1), \qquad \mbox{for some } \lambda' \in (0,\lambda). \] Comparing with the equation \eqref{eq-sum-deg}, we infer that \[     \frac{1}{n}\sum_{k = m+1}^n k\abs{N_k(n)} \leq \frac{\lambda^{m+1}}{m!} + o(1). \] From this equation, together with equation \eqref{eq-sum-nk}, by Cauchy-Schwarz we obtain that \[     \frac{1}{n}\sum_{k = m+1}^n \abs{N_k(n)}\sqrt{k} \leq \sqrt{\frac{\lambda^{m+1}}{m!}} + o(1). \]  By the Corollary \ref{cor-BA-model}, we get that \[     \frac{\energy{G_n}}{n} \leq 2\frac{\abs{N_{1,1}(n)}}{n} + \sum_{k = 2}^n \frac{\abs{N_k(n)}}{n} \sqrt{3 \frac{\abs{N_{k,1}(n)}}{\abs{N_k(n)}} + k} \] Combining this equation with the previous calculations, for any fixed \(m \geq 2\) and large \(n\), we get      \frac{1}{n}\energy{G_n} &\leq 2n_{1,1} + \sum_{k = 2}^m n_k\sqrt{3\frac{n_{k,1}}{n_k} + k} + o(1) + \frac{2}{n}\sum_{k = m+1}^n \abs{N_k(n)}\sqrt{k}\\     &\leq 2n_{1,1} + \sum_{k = 2}^m n_k\sqrt{3\frac{n_{k,1}}{n_k} + k} + 2\sqrt{\frac{\lambda^{m+1}}{m!}} + o(1)   Since \(m\) is fixed but arbitrary, we obtain the asymptotic bound      \limsup_{n \to \infty} \frac{1}{n}\energy{G_n} &\leq 2n_{1,1} + \sum_{k = 2}^{\infty} n_k\sqrt{3\frac{n_{k,1}}{n_k} + k}\\     &= 2\lambda e^{-2\lambda} + e^{-\lambda}\sqrt{3e^{-\lambda} + 1}\sum_{k = 2}^{\infty} \frac{\lambda^k\sqrt{k}}{k!}.",2502.01065
proof,"Let $f : (0,\infty) \to \R$ given by \[     f(\lambda) = 2\lambda e^{-2\lambda} + e^{-\lambda}\sqrt{3e^{-\lambda} + 1}\sum_{k = 2}^{\infty} \frac{\lambda^k\sqrt{k}}{k!}. \] We note first that $f$ is increasing for $\lambda \in [0,4/3]$. Indeed, \[     f'(\lambda) = g(\lambda) + \sum_{k = 5}^{\infty} h_k(\lambda), \] where, for every \(k \geq 2\), \[     g(\lambda) := (2 - 4\lambda)e^{-2\lambda} + \sum_{k = 2}^4 h_k(\lambda), \qquad h_k(\lambda) := \frac{\sqrt{k}e^{-2\lambda}\left(2e^{\lambda}(k - \lambda) + 6k - 9\lambda\right)}{2k!\sqrt{3e^{-\lambda} + 1}}. \] It is clear that \(h_k > 0\) whenever \(2e^{\lambda}(k - \lambda) + 6k - 9\lambda > 0\), in particular, when $k\geq 5$ we can take  \(\lambda \in (0,3]\). In addition, after some calculations one can verify that \(g(\lambda) > 0\) for \(\lambda \in (0,4/3]\). In consequence \(f\) is increasing in \((0,4/3]\).  Thus it is enough to check if $f(4/3)\leq 1$.  To bound $f(4/3)$ we can consider the partial sum \[     f_n(\lambda) = 2\lambda e^{-2\lambda} + e^{-\lambda}\sqrt{3e^{-\lambda} + 1}\sum_{k = 2}^{n} \frac{\lambda^k\sqrt{k}}{k!}. \] and verify that $|f(\lambda)-f_n(\lambda)|\leq\sqrt{3e^{-\lambda} + 1}\lambda^n/n!$, which for $\lambda=4/3$ and $n = 13$ yields and error of $\delta \approx 9.04577\cdot 10^{-9}$, which is a small as desired as $n\to \infty$. In conclusion, we obtain that \(f(4/3) \approx 0.99911\) and therefore, for every \(\lambda \in (0,4/3]\) it is satisfied that \[     \limsup_{n \to \infty} \frac{\energy{G_n}}{n} \leq f(\lambda) < 1. \]",2502.01065
proof,"Using Taylor expansion around \(2\) for $\sqrt{\cdot}$ function, we notice that \[     \sqrt{x} \leq \frac{1}{\sqrt{8}} x + \frac{1}{\sqrt{2}}, \qquad \mbox{for } x \geq 2. \] Then,      \sum_{k = 2}^{\infty} \frac{\lambda^k\sqrt{k}}{k!} &\leq \frac{1}{\sqrt{8}}\left(\lambda\sum_{k = 1}^{\infty} \frac{\lambda^k}{k!} + 2\sum_{k = 2}^{\infty} \frac{\lambda^k}{k!}\right)\\     &= \frac{\lambda(e^{\lambda} - 1) + 2(e^{\lambda} - \lambda - 1)}{\sqrt{8}}\\     &= \frac{(\lambda + 2)e^{\lambda} - (3\lambda + 2)}{\sqrt{8}}.   Therefore, for \(\lambda \in (0,\infty)\), \[     f(\lambda) \leq 2\lambda e^{-2\lambda} + \frac{1}{\sqrt{8}}\sqrt{3e^{-\lambda} + 1}\left(\lambda + 2 - e^{-\lambda}(3\lambda + 2)\right). \]  Let \(g : \R_+ \to \R\) be the function given by \[     g(\lambda) = 2\lambda e^{-2\lambda} + \frac{1}{\sqrt{8}}\sqrt{3e^{-\lambda} + 1}\left(\lambda + 2 - e^{-\lambda}(3\lambda + 2)\right) - \lambda. \] We obtain that \[     g'(\lambda) = \frac{2\sqrt{2}e^{\lambda} + \sqrt{2}(3\lambda - 2) + 27\sqrt{2}\lambda e^{-\lambda} - 16\sqrt{3e^{-\lambda} + 1}(\lambda - 1)}{8e^{\lambda}\sqrt{3e^{-\lambda} + 1}} - 1. \] By writing $g'(\lambda)=g_1(\lambda)+ g_2(\lambda)+g_3(\lambda)-1$ where, for $\lambda\geq 4/3,$ $$g_1(\lambda)=\frac{2\sqrt{2}e^{\lambda}}{{8e^{\lambda}\sqrt{3e^{-\lambda} + 1}}}\leq \frac{1}{2\sqrt{2}},\quad  g_2(\lambda)=\frac{27\sqrt{2}\lambda e^{-\lambda}}{8e^{\lambda}\sqrt{3e^{-\lambda} + 1}}\leq \frac{1}{2}, $$ and $$g_3(\lambda)=\frac{\sqrt{2}(3\lambda - 2) - 16\sqrt{3e^{-\lambda} + 1}(\lambda - 1)}{8e^{\lambda}\sqrt{3e^{-\lambda} + 1}} \leq \frac{\sqrt{2}(3\lambda - 2) - 16(\lambda - 1)}{8e^{\lambda}\sqrt{3e^{-\lambda} + 1}}\leq 0$$  One sees that $g'(\lambda)\leq0$ for \(\lambda>4/3\).  %Now, it is clear that for \(\lambda\) sufficiently big, we have the following inequality: %\[   \sqrt{2}(3\lambda - 2) + 27 \sqrt{2} \lambda e^{-\lambda} \leq 16 (\lambda - 1) + (8 - 2\sqrt{2})e^{\lambda}. %\] %In particular, for \(\lambda = \)",2502.01065
proposition,"[Arizmendi and Juarez \cite{Arizmendi18}] For a graph \(G\) with vertices of degrees \(d_1, \ldots, d_n\) it is satisfied      \energy G \leq \sum_{i = 1}^n \sqrt{d_i}.",2502.01065
proposition,"[Arizmendi and Dominguez \cite{Arizmendi22}] For a tree \(T\) with vertices degrees \(\Delta = d_1 \geq \ldots \geq d_n\), \(n \geq 3\), it is satisfied      \energy T \leq \sum_{i = 2}^n 2\sqrt{d_1 - 1} + 2\sqrt{\Delta} \leq \sum_{i = 1}^n 2\sqrt{d_i - 1} + 1.",2502.01065
proposition,"\cite{Bollobas01, McDonald} With high probability \(\abs{N_k(n)}/n \to n_k\) and \(\abs{N_{k,1}(n)}/n \to n_{k,1}\) when \(n \to \infty\), where \[     n_k = \frac{4}{k(k+1)(k+2)}, \qquad n_{k,1} = \frac{2(k+2)(k+3)-24}{k(k+1)(k+2)(k+3)}. \]",2502.01065
proposition,"With high probability \(\abs{N_k(n)}/n \to n_k\) and \(\abs{N_{k,1}(n)}/n \to n_{k,1}\) when \(n \to \infty\), where     \[     n_k = \frac{\lambda^ke^{-\lambda}}{k!}, \qquad n_{k,1} = \frac{\lambda^ke^{-2\lambda}}{(k-1)!}.     \]",2502.01065
proposition,"%With high probability,  \(\abs{E_n}/n \to \lambda/2\) as \(n \to \infty\), almost surely.",2502.01065
proposition,"Let      f(\lambda) := 2\lambda e^{-2\lambda} + e^{-\lambda}\sqrt{3e^{-\lambda} + 1}\sum_{k = 2}^{\infty} \frac{\lambda^k\sqrt{k}}{k!}   Then \[     f(\lambda) \leq 2\lambda e^{-2\lambda} + \frac{1}{\sqrt{8}}\sqrt{3e^{-\lambda} + 1}\left((\lambda + 2) - e^{-\lambda}(3\lambda + 2)\right), \qquad \lambda \in (0,\infty) \] and \[     f(\lambda) \leq \lambda, \qquad \lambda \in (4/3,\infty). \]",2502.01065
lemma,"Let $S:=(S_n,W)$ be a weighted star with $n$ edges and weights $(w_{i})_{i = 1}^n$. Then, $$\mathcal{E}(S) = 2\sqrt{\sum_{i = 1}^n w_i^2}.$$",2502.01065
example,"For a connected graph with at least three vertices, according to Cauchy-Schwartz inequality, the equality between local and global bounds are equal if and only if      4l(v) + \delta(v) = k, \qquad \mbox{for every } v \in V',  for some constant \(k \in \N\). Equivalently, \[     \delta(v) = k - 4l(v), \qquad \mbox{for every } v \in V'. \]  It means if the equality between local and global bounds are the same, then the inner degree of inner vertices differs by a multiple of 4. In the particular case when \(d(v) = d\) and \(l(v) = l\)  for some constants \(d,l \in \N\) and every \(v \in V'\), we obtain this graph as a copy of a \(d\)-regular graph and then attaching \(l\) leaves to every vertex of the \(d\)-regular graph.   [!htp]     \centering     [b]{0.3\textwidth}         \centering                      \foreach \n in {1, ..., 7}{                 \node[style = {my_style}] at ({\n*360/7 + 90}:1) (\n) {};             }              \draw (1) -- (2) -- (3) -- (4) -- (5) -- (6) -- (7) -- (1);              \foreach \n in {1, ..., 14}{                 \node[style = {my_style}] at ({(\n + 0.5)*360/14 + 90}:1.8) (n\n) {};)              }              \draw (n1) -- (1) -- (n2);             \draw (n3) -- (2) --  (n4);             \draw (n5) -- (3) --  (n6);             \draw (n7) -- (4) --  (n8);             \draw (n9) -- (5) --  (n10);             \draw (n11) -- (6) --  (n12);             \draw (n13) -- (7) -- (n14);                               \caption{}     %     [b]{0.3\textwidth}         \centering                      \foreach \n in {1, ..., 7}{                 \node[style = {my_style}] at ({(\n - 1)*360/7 + 90}:1) (\n) {};             }              \foreach \n in {2, ..., 7}{                 \draw (1) -- (\n);             }              \draw (2) -- (5); \draw (3) -- (6); \draw (4) -- (7);              \node[style = {my_style}] at (90:1.8) (n11) {};             \draw (n11) -- (1);              \foreach \n in {2, ..., 7}{                 \node[style = {my_style}] at ({(2*\n - 2.5)*360/14 + 90}:1.8) (n1\n) {};                 \node[style = {my_style}] at ({(2*\n - 1.5)*360/14 + 90}:1.8) (n2\n) {};                 \draw (n1\n) -- (\n) -- (n2\n);             }                               \caption{}     %     [b]{0.3\textwidth}         \centering                      \foreach \n in {1, ..., 7}{                 \node[style = {my_style}] at ({(\n - 0.5)*360/7 + 90}:1) (\n) {};             }              \foreach \n in {2, ..., 7}{                 \draw (1) -- (\n);             }              \foreach \n in {2, ..., 6}{                 \draw (7) -- (\n);             }              \node[style = {my_style}] at (360/14 + 90:1.8) (n11) {};             \draw (n11) -- (1);              \node[style = {my_style}] at (-360/14 + 90:1.8) (n17) {};             \draw (n17) -- (7);              \foreach \n in {2, ..., 6}{                 \node[style = {my_style}] at ({(2*\n - 1.5)*360/14 + 90}:1.8) (n1\n) {};                 \node[style = {my_style}] at ({(2*\n - 0.5)*360/14 + 90}:1.8) (n2\n) {};                 \draw (n1\n) -- (\n) -- (n2\n);             }                               \caption{}          \caption{Some examples of connected graphs where the equality between local and global bound holds.}",2502.01065
example,"The bound offered by Theorem \ref{TP} is smaller than the bound of Proposition \ref{eq:AJ} for a double stars \(S_{p,q}\) (obtained by connecting with an edge the centers of a star \(S_p\) and a star \(S_q\)) when \(p \leq q \leq 3p - 1\).      In fact, let \(S_{p,q}\) be a double star with \(p \leq q\) for which the bound of Theorem \ref{TP} improves the bound of Proposition \ref{eq:AJ}. We have     \[         \sqrt{4p + 1} + \sqrt{4q + 1} \leq 2\left(\sqrt{p} + \sqrt{q + 1}\right),     \]     which is equivalent to the inequality     \[         \sqrt{\left(p + \frac{1}{4}\right)\left(q + \frac{1}{4}\right)} \leq \frac{1}{4} + \sqrt{p\left(q + 1\right)}     \]     Particularly, if \(q \leq 3p - 1\) then the above inequality holds.",2502.01065
theorem,The optimization problems \eqref{eq:D1} and \eqref{eq:D1equiv} are equivalent.,2502.01075
theorem,"For each $x\in X$, it holds that 			 				\mc{K}(x) = \bigcup\limits_{J\in \mc{P}}\mathcal{K}_{J}(x).",2502.01075
theorem,"Consider the inner loop of Algorithm~\ref{alg:1} produces an infinite sequence 			$\{(x_J^k, u_J^k,\hat{u}_J^k)\}_{k=0}^{\infty}$ under \Cref{as:feasext}. 		Suppose $(\hat{x}, \hat{u})$ is an accumulation point of the  			sequence $\{(x_J^k,\hat{u}_J^k)\}_{k=0}^{\infty}$. 		Let $q^{(k)}$ denote the feasible extension at the order $k$ that satisfies \eqref{eq:qinalg}. 		If $v(x)$ is continuous at $\hat{x}$ and $q^{(k)}(x)$ is uniformly continuous at $\hat{x}$, 			then $v(\hat{x}) = 0$ and $\hat{x}$ is an optimizer of \eqref{eq:PJ}.",2502.01075
theorem,"In Algorithm~\ref{alg:1}, assume the inner loop terminates finitely 			for all $J\in \mc{P}$.  			Then $f^*\coloneqq \min\, \{\bar{f},\, f_J^*\,(J\in \mc{P})\}$  			is the global optimal value  			of \eqref{primal-GSIP} and the corresponding output $x^*$ is a global optimizer of \reff{primal-GSIP}.",2502.01075
theorem,"Suppose $(\bar{x},\bar{y})$ is an optimizer \reff{eq:D1equiv}. 			If $\bar{h}(\bar{x})>0$, 			then $\bar{x}$ is a local optimizer of \reff{primal-GSIP}.",2502.01075
theorem,"For each $J\in \mc{P}$, suppose $(x_J^*,u_J^*)$ is an optimizer of \eqref{eq:PJ}. 			Assume $v(x_J^*) = g(x_J^*,u_J^*)$ and $v(x)$ is continuous at $x_J^*$. 			Then $x_J^*$ is a local optimizer of \reff{primal-GSIP} if one of the following conditions holds: 			 				\item[(i)] $J\supseteq \mc{I}(x_J^*,u_J^*)$; 				\item[(ii)] $f_J^*\le f_{J'}^*$ holds for every $J'\in \mc{P}$ such that $J'\subseteq \mc{I}(x_J^*,u_J^*)$.",2502.01075
proof,"By Farkas' Lemma, every feasible point of \eqref{eq:D1} corresponds to a feasible point of \reff{eq:D1equiv}. 		Let $(x,y)$ be a feasible point of \reff{eq:D1equiv}. 		If $x$ is not feasible for \eqref{eq:D1}, then there exists $u\in\re^p$ such that  		$Au- b(x)\ge 0$. Since $y\ge 0$ and $y$ has the same dimension as $Au-b(x)$,  		we have 		\[ 		y^T\big(Au-b(x)\big) = y^TAu-y^Tb(x)\ge 0. 		\] 		On the other hand, since $A^Ty = 0$ and $b(x)^Ty = 1$, we also have  		\[ (A^Ty)^Tu-b(x)^Ty = y^TAu -y^Tb(x) = -1<0. \] 		This is a contradiction. So \eqref{eq:D1} and \reff{eq:D1equiv} are equivalent.",2502.01075
proof,"For each $J\in \mc{P}$, let $\lambda_J(x,u)$ be the PLME as in \eqref{eq:plme} 		and let $\hat{\mc{K}}_J(x)$ denote the set in the right-hand-side of \reff{eq:Kjexp}. 		If $u\in \hat{\mc{K}}_J(x)$, then $u$ belongs to $\mc{K}_J(x)$ with  		the vector of Lagrange multipliers $\lambda_J = \lambda_J(x,u)$. 		For a pair $(\hat{x}, \hat{u})$ with $\hat{x}\in X$ and $\hat{u}\in \mc{K}_J(\hat{x})$,          suppose $\hat{\lambda}_J$ is a corresponding vector of Lagrange multipliers. 		Since $A_J^T$ has full column rank, $\hat{\lambda}_J$ is the unique solution of          \eqref{eq:KKTjeq}, so it must satisfy $\hat{\lambda}_J = \lambda(\hat{x}, \hat{u})$. 		Therefore, $\mc{K}(x)=\hat{K}(x)$ for every $J\in\mc{P}$. 		For the special case that $p=r$, $A_J$ itself is invertible, thus 		\[ A_J^T(A_JA_J^T)^{-1}A_J = I_r,\quad (A_JA_J^T)^{-1}A_J = A_J^{-T}\] 		for every $J\in\mc{P}$.  		Then \eqref{eq:Kjexp} is simplified to \eqref{eq:Kjsimple}.",2502.01075
proof,"The result is trivial when $U(x)$ is empty. 			Consider the case that $U(x)$ is nonempty. 			By Carath\'{e}odorys Theorem, every $u\in \mc{K}(x)$ has a vector of Lagrange multipliers  			$\lambda^{x,u} = (\lambda_j^{x,u})$ such that $\{a_j\,\vert\, \lambda_j^{x,u}>0\}$ is linearly independent. Let 			\[ J_0 = \{ j\in [m]\,\vert\, \lambda_j^{x,u}>0 \}. \] 			Since $|J_0|\le r$, there exists $J\in \mc{P}$ such that 			$J_0$ is a subset of $J$. Then $u\in \mc{K}_J$ since it has a vector 			of Lagrange multiplier $\lambda_J= (\lambda_j)_{j\in J}$, defined entrywise by 			$\lambda_j = \lambda_j^{x,u}$ if $j\in J_0$ and $\lambda_j = 0$ otherwise. 			So the conclusion holds.",2502.01075
proof,"Since $\Phi_0(x)\subseteq U(x)$ and each $q^{(k)}$ satisfies \eqref{eq:qinalg}, 			for each $\phi\in \Phi_k(x)$, the constraint $g(x, \phi(x))\ge 0$ is satisfied 			at every feasible point of \eqref{eq:PJ}. 			So \eqref{eq:PJk} is a relaxation of \eqref{eq:PJ} for every $k$. 			Let $f_J^*$ denote the optimal values of \eqref{eq:PJ}. 			Suppose \eqref{eq:PJk} is solvable with the optimal value $f_{J,k}$ and an  			optimizer $(x_J^k, u_J^k)$. Then 			\[ 			f_{J,0}\le f_{J,1}\le \cdots\le f_{J,k}\le f_J^* 			\] 			and that $(x_J^k, u_J^k)$ is also an optimizer of \eqref{eq:PJ} 			if and only if $v(x_J^k)\ge 0$.",2502.01075
proof,"(i) Under the given assumption, we have $\mc{K}_J(x)\cap S(x) = \mc{K}_J(x)$  			for every $x\in X$ and every $J\in\mc{P}$.             So \eqref{eq:PJk} and \eqref{eq:PJ} are equivalent at the initial order $k=0$. 			 			(ii) Let $G(x)=\{u\in\re^p\,\vert\, g(x,u)\ge 0\}$.  			The robust constraint in \reff{primal-GSIP} is equivalent to  			$U(x)\subseteq G(x)$ for every $x\in X$. 			Suppose $\Phi_0(x)$ is the vertex set of $U(x)$ for every $x\in X$. 			Since $-g$ is convex in $u$, the $G(x)$ is a convex set for every $x\in X$. 			Then $U(x)\subseteq G(x)$ if and only if $\Phi_0(x)\subseteq G(x)$.  			Therefore, \eqref{eq:PJk} is a tight relaxation of \eqref{eq:PJ} at the  			initial order $k=0$.",2502.01075
proof,"Without loss of generality, we may assume $(\hat{x}, \hat{v})$ is a limit point of $(x_J^k, v_J^k)$  			up to a selection of subsequence. 			Let $f_J^*$ denote the optimal value of \eqref{eq:PJ}. 			Since $f$ is a polynomial and $f(x_J^k)\le f_J^*$ for each $k$, we have 			\[ 			f(\hat{x})\, =\, \lim_{k\to \infty} f(x_J^k) \, \le\, f_J^*. 			\] 			By feasibility, the optimizer $x_J^k$ must satisfy all extra constraints added in the previous iterations.  			For all $s\le k$, we have 			\[ g(x_J^{k},q^{(s)}(x_J^{k}))\ge 0\quad \Rightarrow 			\quad g(\hat{x}, q^{(s)}(\hat{x})) = \lim_{k\to \infty}g(x_J^{k},q^{(s)}(x_J^{k}))\ge 0. \] 			Note that $q^{(s)}(x_J^s) = \hat{u}_J^s$ for each $s$ by \reff{eq:feasext}. 			Under the assumption that $q^{(k)}(x)$ is uniformly continuous at $\hat{x}$, we have 			\[  			\hat{u} = \lim_{s\to \infty} \hat{u}_J^{s} =  			\lim_{s\to \infty} q^{(s)}(\hat{x}) =  			\lim_{s\to\infty}q^{(s)}(x_J^{s}). 			\] 			Since $\hat{u}_J^s\in S(x_J^s)$, it holds that  			$v(x_J^s) = g(x_J^s, \hat{u}_J^s) = g(x_J^s, q^{(s)}(x_J^s))$. Then 			\[ 			 				v(\hat{x}) &= v(x_J^{s})+v(\hat{x})-v(x_J^{s})\\ 				& \ge \big( g(x_J^{s},q^{(s)}(x_J^s))-g(\hat{x},q^{(s)}(\hat{x}))\big)+\big(v(\hat{x})-v(x_J^{s})\big), 			 			\] 			since $g(\hat{x}, q^{(s)}(\hat{x}))\ge 0$ as showed earlier. 			When $s\to \infty$, $g(x_J^{s},q^{(s)}(x_J^s))\to g(\hat{x},\hat{u})$ by the uniform continuity  			of $q^{(s)}$ and $v(x_J^{s})\to v(\hat{x})$ by the continuity of $v(x)$. 			This implies $v(\hat{x})\ge 0$.  			So $\hat{x}$ is feasible for \eqref{eq:PJ}, thus it is a global optimizer of \eqref{eq:PJ}.",2502.01075
proof,"By \Cref{thm:D1equiv}, $\bar{f}$ is the optimal value of \eqref{eq:D1}. 			By \Cref{thm:kktdcp} and \Cref{lem:PJ}, the minimum of $f_J^*\, (J\in \mc{P})$ 			is the optimal value of \eqref{eq:D2}. 			Then $f^*$ is the optimal value of \eqref{eq:vfreform}. 			The conclusions hold since \eqref{primal-GSIP} and \eqref{eq:vfreform} are equivalent.",2502.01075
proof,"By \Cref{thm:D1equiv}, \eqref{eq:D1} and \eqref{eq:D1equiv} are equivalent. 			Given that $(\bar{x},\bar{y})$ is an optimizer of \reff{eq:D1equiv}, 			$\bar{x}$ is a global minimizer of \eqref{eq:D1}. 			By the given conditions and the feasibility of \eqref{eq:D1equiv},  			the pair $(\bar{x}, \bar{y})$ satisfies 			 			\bar{h}(\bar{x})>0,\quad A^T\bar{y} = 0, 			\quad b(\bar{x})^T\bar{y} = 1,\quad \bar{y}\ge 0. 			 			Since $\bar{h},\, b$ are polynomials, there exists a small $\epsilon>0$ such that 			$\bar{h}(x)>0$ and $b(x)^T\bar{y}>0$ for every $x\in B_{\epsilon}(\bar{x})$. 			Then each $x\in B_{\epsilon}(\bar{x})$ corresponds to a pair $(x, \bar{y}/b(x)^T\bar{y})$ 			that is feasible point for \eqref{eq:D1equiv}.  			The feasibility of $(x, \bar{y}/b(x)^T\bar{y})$ is easy to verify. 			By \eqref{eq:barfeas}, we have 			\[ x\in B_{\epsilon}(\bar{x})\subseteq X,\quad  			A^T\frac{\bar{y}}{b(x)^T\bar{y}}= 0,\quad   			b(x)^T \frac{\bar{y}}{b(x)^T\bar{y}} =1,\quad   			\frac{\bar{y}}{b(x)^T\bar{y}}\ge 0. \] 			This implies that $B_{\epsilon}(\bar{x})\subseteq \{x\in X\,\vert\, U(x)\not=0\}$. Since 			\[ 			f(\bar{x}) = \min\limits_{x\in X, U(x)\not=\emptyset} f(x) 			\le \min\limits_{x\in B_{\epsilon}(\bar{x})} f(x), 			\]  			we can conclude that $\bar{x}$ is a local optimizer of \eqref{primal-GSIP}",2502.01075
proof,"Let $\mc{F}$ denote the feasible set of \eqref{eq:D2equiv}. 			If condition (i) or (ii) holds, then $(x_J^*,u_J^*)$ is a local optimizer of 			 \eqref{eq:D2equiv} by \cite[Theorem~3.1]{nie2023plmes}. 			That is, there exists a small $\epsilon>0$ such that  			 				f(x_J^*)\le f(x)\quad \forall (x,u)\in B_{2\epsilon}(x_J^*, u_J^*)\cap\mc{F}.   			 			If $x_J^*$ is not a local minmizer of \reff{primal-GSIP}, 			then there exists a sequence $\{x^{(s)}\}_{s=0}^{\infty}$ in the feasible set  			of \eqref{eq:D2} such that $x^{(s)}\to x_J^*$ as $s\to \infty$ and  			\[ 			f(x^{(s)})>f(x_J^*),\,\,\,\forall s\in \N. 			\] 			Without loss of generality, we may assume each $x^{(s)}\in B_{\epsilon}(x_J^*)$. 			Since the Cartesian product $B_{\epsilon}(x_J^*)\times B_{\epsilon} (u_J^*)\subseteq B_{2\epsilon}(x_J^*,u_J^*)$, by \eqref{eq:locmin}, we must have 			\[ 			S(x^{(s)})\cap B_{\epsilon}(u_J^*)=\emptyset\quad \forall s\in\N. 			\] 			On the other hand, since $U(x)$ is continuous and $u_J^*\in U(x_J^*)$, 			there exists $N>0$ such that 			$U(x^{(s)})\cap B_{\epsilon}(u_J^*)\neq \emptyset$ for every $s\ge N$. 			Since $g$ is a polynomial, then we can find a small scalar $\epsilon_1>0$ and a sequence $\{u^{(s)}\}_{s=0}^{\infty}$ such that for each $s\ge N$, 			\[ u^{(s)}\in B_{\epsilon}(u_J^*)\cap U(x^{(s)}),\quad \mbox{and}\] 			\[ 			v(x^{(s)}) = \min\limits_{u\in U(x^{(s)})} g(x^{(s)},u)\le  			g(x^{(s)}, u^{(s)})-\epsilon_1. 			\] 			Up to a proper selection of subsequence, we may assume 			$(x^{(s)}, u^{(s)}) \to  (x_J^*, u_J^*)$ as $s\to \infty$ without loss of generality. 			Since $v(x)$ is continuous at $x_J^*$, we have 			\[  			v(x_J^*) = \lim_{s\to \infty} v(x^{(s)})\le \lim_{s\to \infty} g(x^{(s)},u^{(s)})-\epsilon_1 < v(x_J^*), \] 			which is a contradiction.  			So $x_J^*$ is a local minimizer of \reff{primal-GSIP}.",2502.01075
proof,"Since $U$ is a polytope, a point $x\in X$ is feasible for \eqref{eq:sip_multi} 			if and only if for each $i\in[s]$, there exists $u\in S_i(x)$ such that  			$g_i(x,u)\ge 0$. 			For every $i\in \mc{I}_1$, since $g_i$ is convex in $u$, we have  			$\mc{K}_i(x) = S_i(x)$ for every $x\in X$, 			where $S_i(x)$ is the optimizer set of \eqref{eq:vi}. 			For every $j\in\mc{I}_2$, since $-g_j$ is convex in $u$,  			the $G_j(x)$ is a convex set. 			Then $U\subseteq G_j(x)$ if and only if the vertex set $\Phi_0\subseteq G_j(x)$, 			which is equivalent to $g_j(x,\phi)\ge 0$ for every $\phi\in \Phi_0$. 			Then the conclusion holds since $\mc{I}_1\cup \mc{I}_2 = [s]$.",2502.01075
lemma,"Given $J\in\mc{P}$, \eqref{eq:PJk} is a relaxation of \eqref{eq:PJ} for every $k\ge 0$.  		Suppose $(x_J^k, u_J^{k})$ is an optimizer of \eqref{eq:PJk} at the relaxation order $k$.  		If $v(x_J^k)\ge 0$, then \eqref{eq:PJk} is a tight relaxation of \eqref{eq:PJ} 		and $(x_J^k, u_J^k)$ is an optimizer of \eqref{eq:PJ}.			 		Specifically, we present explicit feasible extensions for boxed and simplex 		constraints in the beginning of \Cref{sc:num}.",2502.01075
theorem,"[quadratic case]   Suppose that $f$ in (\ref{blp}) takes the following quadratic form:   	f(x,y)=\frac{1}{2}y^T A y-y^T  x,  where $\mu I\preceq A \preceq LI$. Assume that Assumption \ref{ass:F} and \ref{ass:phi} hold.  Set $Q_k=k+1$ and \textcolor{black}{$H_0=LI$}. Let $\kappa:=L/\mu$, $t_b:=4n{\rm ln}\kappa$, $c_t:=2t_b^{\frac{T}{2}}$, and $\omega:=c_1(1+\frac{1}{\varepsilon})c_t^2 \kappa^3(\frac{1}{T})^{T}$, where $c_1$ is a positive constant given in Theorem \ref{agblprate1}. We can choose positive parameters $\alpha$, $\varepsilon$ and $T$ such that $\tau:=c_t^2 \kappa^3(\frac{1}{T})^{T}\big((1+\varepsilon)+(1+\frac{1}{\varepsilon})\alpha^2c_1\big)<1$ and $\alpha L_{\Phi}+\omega \alpha^2 \left( \frac{1}{2} + \alpha L_{\Phi} \right)\frac{1}{1-\tau}\leq \frac{1}{4}$.  Then the iterates $x_k$ generated by  qNBO~(BFGS) satisfy:        \frac{1}{K}\sum_{k=0}^{K-1}\|\nabla{\Phi}(x_k)\|^2\leq  \frac{4(\Phi(x_0)-{\color{black}\inf_x \Phi(x)})}{\alpha K}+\frac{3\delta_0}{K(1-\tau)}+{\color{black}\frac{18nL C_{F_y}^2{\rm ln}K}{\mu^3 K}},    with the initial error $\delta_0=3c_t^2 \kappa^3(\frac{1}{T})^{T}c_2\|y_0^*-y_{0}\|^2$, where $c_2$ is a constant.",2502.01076
theorem,"[general case]  Suppose that Assumptions \ref{ass:F}, \ref{ass:f} and \ref{ass:phi}  hold. Set $Q_k=k+1$.  Choose the parameters $\beta$ and  $P$ such that $(1-\beta\mu)^P\|y_{k}-y_{k}^*\|\leq \frac{1}{300\sqrt{\mu}}$,  and assume $H_0$ satisfies: $\|\nabla^2_{yy}f(x_k,y^*(x_k))^{-1/2}\big(H_0^{-1}-\nabla^2_{yy}f(x_k,y^*(x_k))\big)\nabla^2_{yy}f(x_k,y^*(x_k))^{-1/2}\|_F\leq\frac{1}{7}$.  Define $\tau:=\kappa (\frac{1}{T})^{T}(1-\beta\mu)^P\big((1+\varepsilon)+(1+\frac{1}{\varepsilon})\alpha^2c_3\big)$ and $\omega:=c_3(1+\frac{1}{\varepsilon})\kappa (\frac{1}{T})^{T}(1-\beta\mu)^P$, with a constant $c_3$ given in Theorem \ref{thm36g}.  We can choose positive parameters $\alpha$, $\varepsilon$ and $T$ such that $\tau<1$ and $\alpha L_{\Phi}+\omega \alpha^2 \left( \frac{1}{2} + \alpha L_{\Phi} \right)\frac{1}{1-\tau}\leq \frac{1}{4}$.   Then the iterates $x_k$ generated by qNBO~(BFGS) satisfy:        \frac{1}{K}\sum_{k=0}^{K-1}\|\nabla{\Phi}(x_k)\|^2\leq  \frac{4(\Phi(x_0)-{\color{black}\inf_x \Phi(x)})}{\alpha K}+\frac{3\delta_0}{K(1-\tau)}+\frac{18nLM_{f_{xy}}^2 C_{F_y}^2{\rm ln}K}{\mu^3{\tilde{\xi}}  K},    where $\delta_0=3\kappa (\frac{1}{T})^{T}(1-\beta\mu)^Pc_4\|y_0^*-y_{0}\|^2$ is the initial error with constant $c_4$. The constant $\tilde{\xi}$ is related to the property of $f$, as given in (\ref{tildexi}).",2502.01076
theorem,"({\rm Restatement of Theorem \ref{qfblprate} with full parameter specifications}) Suppose that the LL function $f$ in (\ref{blp}) takes the quadratic form:   	f(x,y)=\frac{1}{2}y^T A y-y^T  x,  where $\mu I\preceq A \preceq LI$  such that Assumption \ref{ass:f}  holds. Choose the stepsize $\alpha>0$, the positive constant $\varepsilon>0$,  \textcolor{black}{$H_0=LI$} and $T\geq t_b$ ($t_b=4n{\rm ln}\kappa$) such that  \[  \tau<1\quad {\rm and} \quad \alpha L_{\Phi}+\omega \alpha^2 \left( \frac{1}{2} + \alpha L_{\Phi} \right)\frac{1}{1-\tau}\leq \frac{1}{4},  \]   where $\tau=c_t^2 \kappa^3(\frac{1}{T})^{T}\big((1+\varepsilon)+6(1+\frac{1}{\varepsilon})L_y^2\alpha^2(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}+\frac{2M_{f_{xy}}^2L_{F_y}^2}{\mu^2})\big)$, $\omega=6(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}+\frac{2M_{f_{xy}}^2L_{F_y}^2}{\mu^2})(1+\frac{1}{\varepsilon})c_t^2 \kappa^3(\frac{1}{T})^{T}L_y^2$, $\kappa=\frac{L}{\mu}$ and $c_t=2t_b^{\frac{T}{2}}$. Then, under Assumptions \ref{ass:F} and \ref{ass:phi} , the iterate generated by the qNBO~(BFGS) algorithm  (Algorithm \ref{alg:foa}) has the following convergence rate:        \frac{1}{K}\sum_{k=0}^{K-1}\|\nabla{\Phi}(x_k)\|^2\leq  \frac{4(\Phi(x_0)-\Phi(x^*))}{\alpha K}+\frac{3\delta_0}{K(1-\tau)}+\frac{1}{K}\sum_{k=0}^{K-1}\frac{18nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3 Q_k},    with the initial error $\delta_0=3c_t^2 \kappa^3(\frac{1}{T})^{T}(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}+\frac{2M_{f_{xy}}^2L_{F_y}^2}{\mu^2})\|y_0^*-y_{0}\|^2$. Specifically, if $Q_k={k+1}$, we have:        \frac{1}{K}\sum_{k=0}^{K-1}\|\nabla{\Phi}(x_k)\|^2\leq  \frac{4(\Phi(x_0)-{\inf_x \Phi(x)})}{\alpha K}+\frac{3\delta_0}{K(1-\tau)}+\frac{18nLM_{f_{xy}}^2 C_{F_y}^2{\rm ln}K}{\mu^3 K}.",2502.01076
theorem,"({\rm Warm-up for quadratic $f$}) Suppose that the LL function $f$ in (\ref{blp}) takes the quadratic form:   	f(x,y)=\frac{1}{2}y^T A y-y^T  x,  where $\mu I\preceq A \preceq LI$  such that Assumption \ref{ass:f}  holds. Choose the stepsize $\beta$ and warm-start iteration steps $P$ such that $(1-\beta\mu)^P\|y_{k}-y_{k}^*\|\leq \frac{1}{300\sqrt{\mu}}$, and ensure the initial Hessian approximation matrix $H_0$ satisfies: $\|\nabla^2_{yy}f(x_k,y^*(x_k))^{-1/2}\big(H_0^{-1}-\nabla^2_{yy}f(x_k,y^*(x_k))\big)\nabla^2_{yy}f(x_k,y^*(x_k))^{-1/2}\|_F\leq\frac{1}{7}$. Choose the stepsize $\alpha>0$ and the positive constant $\varepsilon>0$ such that  \[  \tau<1\quad {\rm and} \quad \alpha L_{\Phi}+\omega \alpha^2 \left( \frac{1}{2} + \alpha L_{\Phi} \right)\frac{1}{1-\tau}\leq \frac{1}{4},  \]   where $\tau=\kappa (\frac{1}{T})^{T}(1-\beta\mu)^P\big((1+\varepsilon)+6(1+\frac{1}{\varepsilon})L_y^2\alpha^2(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}+\frac{2M_{f_{xy}}^2L_{F_y}^2}{\mu^2})\big)$, $\omega=6(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}+\frac{2M_{f_{xy}}^2L_{F_y}^2}{\mu^2})(1+\frac{1}{\varepsilon})\kappa (\frac{1}{T})^{T}(1-\beta\mu)^PL_y^2$ and $\kappa=\frac{L}{\mu}$.  Then, under Assumptions \ref{ass:F} and \ref{ass:phi}, the iterate generated by the qNBO~(BFGS) algorithm  (Algorithm \ref{alg:foa}) has the following convergence rate:        \frac{1}{K}\sum_{k=0}^{K-1}\|\nabla{\Phi}(x_k)\|^2\leq  \frac{4(\Phi(x_0)-\Phi(x^*))}{\alpha K}+\frac{3\delta_0}{K(1-\tau)}+\frac{1} {K}\sum_{k=0}^{K-1}\frac{18nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3 Q_k},    with the initial error $\delta_0=3\kappa (\frac{1}{T})^{T}(1-\beta\mu)^P(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}+\frac{2M_{f_{xy}}^2L_{F_y}^2}{\mu^2})\|y_0^*-y_{0}\|^2$.",2502.01076
theorem,"({\rm Restatement of Theorem \ref{gblprate} with full parameter specifications}) Suppose that Assumptions \ref{ass:F}, \ref{ass:f} and \ref{ass:phi} hold. Choose the stepsize $\beta$ and warm-up iteration steps $P$ such that $(1-\beta\mu)^P\|y_{k}-y_{k}^*\|\leq \frac{1}{300\sqrt{\mu}}$, and ensure the initial Hessian approximation matrix $H_0$ satisfies: $\|\nabla^2_{yy}f(x_k,y^*(x_k))^{-1/2}\big(H_0^{-1}-\nabla^2_{yy}f(x_k,y^*(x_k))\big)\nabla^2_{yy}f(x_k,y^*(x_k))^{-1/2}\|_F\leq\frac{1}{7}$. Define $\tau=\kappa (\frac{1}{T})^{T}(1-\beta\mu)^P\big((1+\varepsilon)+6(1+\frac{1}{\varepsilon})L_y^2\alpha^2(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}+\frac{4M_{f_{xy}}^2L_{F_y}^2}{\mu^2}+\frac{4M_{f_{xy}}^2C^2_{F_y}L^2_{f_{yy}}}{\mu^4})\big)$ and $\omega=6(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}+\frac{4M_{f_{xy}}^2L_{F_y}^2}{\mu^2}+\frac{4M_{f_{xy}}^2C^2_{F_y}L^2_{f_{yy}}}{\mu^4})(1+\frac{1}{\varepsilon})\kappa (\frac{1}{T})^{T}(1-\beta\mu)^PL_y^2$. Choose the stepsize $\alpha>0$, the positive constant $\varepsilon>0$  and iterate $T>0$ such that  \[  \tau<1 \quad {\rm and} \quad \alpha L_{\Phi}+\omega \alpha^2 \left( \frac{1}{2} + \alpha L_{\Phi} \right)\frac{1}{1-\tau}\leq \frac{1}{4}.  \]   Then, the solution $x_k$ generated by Algorithm \ref{alg:foa} achieves the following convergence rate:        \frac{1}{K}\sum_{k=0}^{K-1}\|\nabla{\Phi}(x_k)\|^2\leq  \frac{4(\Phi(x_0)-{\inf_x \Phi(x)})}{\alpha K}+\frac{3\delta_0}{K(1-\tau)}+\frac{1}{K}\sum_{k=0}^{K-1}\frac{18nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3{\tilde{\xi}}  Q_k},    where $\delta_0=3\kappa (\frac{1}{T})^{T}(1-\beta\mu)^P(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}+\frac{4M_{f_{xy}}^2L_{F_y}^2}{\mu^2}+\frac{4M_{f_{xy}}^2C^2_{F_y}L^2_{f_{yy}}}{\mu^4})\|y_0^*-y_{0}\|^2$ is the initial error. Specifically, if $Q_k=k+1$, we have:        \frac{1}{K}\sum_{k=0}^{K-1}\|\nabla{\Phi}(x_k)\|^2\leq  \frac{4(\Phi(x_0)-\Phi(x^*))}{\alpha K}+\frac{3\delta_0}{K(1-\tau)}+\frac{18nLM_{f_{xy}}^2 C_{F_y}^2{\rm ln}K}{\mu^3{\tilde{\xi}}K}.",2502.01076
theorem,"Suppose that Assumptions \ref{ass:F}, \ref{ass:f} and \ref{ass:phi}  hold. Choose the stepsize $\beta$ and warm-up iteration steps $P$ such that $(1-\beta\mu)^P\|y_{k}-y_{k}^*\|\leq K_1$, where $K_1$ is defined in (\ref{eqlca}). Set $H_0=LI$ and $T\geq 8n{\rm ln}{\frac{2L}{\mu}}$. Define $\tau=c_l^2 \kappa^3 (\frac{1}{T})^{T}(1-\beta\mu)^P\big((1+\varepsilon)+6(1+\frac{1}{\varepsilon})L_y^2\alpha^2(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}+\frac{4M_{f_{xy}}^2L_{F_y}^2}{\mu^2}+\frac{4M_{f_{xy}}^2C^2_{F_y}L^2_{f_{yy}}}{\mu^4})\big)$ and $\omega=6(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}+\frac{4M_{f_{xy}}^2L_{F_y}^2}{\mu^2}+\frac{4M_{f_{xy}}^2C^2_{F_y}L^2_{f_{yy}}}{\mu^4})(1+\frac{1}{\varepsilon})c_l^2 \kappa^3 (\frac{1}{T})^{T}(1-\beta\mu)^PL_y^2$. Choose the stepsize $\alpha>0$, the positive constant $\varepsilon>0$  and iterate $T>0$ such that   \[  \tau<1 \quad {\rm and} \quad \alpha L_{\Phi}+\omega \alpha^2 \left( \frac{1}{2} + \alpha L_{\Phi} \right)\frac{1}{1-\tau}\leq \frac{1}{4}.  \]   Then, the solution $x_k$ generated by Algorithm \ref{alg:foa} achieves the following convergence rate:        \frac{1}{K}\sum_{k=0}^{K-1}\|\nabla{\Phi}(x_k)\|^2\leq  \frac{4(\Phi(x_0)-\Phi(x^*))}{\alpha K}+\frac{3\delta_0}{K(1-\tau)}+\frac{1}{K}\sum_{k=0}^{K-1}\frac{18nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3{\tilde{\xi}}  Q_k},    where $\delta_0=3c_l^2 \kappa^3\kappa (\frac{1}{T})^{T}(1-\beta\mu)^P(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}+\frac{4M_{f_{xy}}^2L_{F_y}^2}{\mu^2}+\frac{4M_{f_{xy}}^2C^2_{F_y}L^2_{f_{yy}}}{\mu^4})\|y_0^*-y_{0}\|^2$ is the initial error. Specifically, if $Q_k=k+1$, we have:         \frac{1}{K}\sum_{k=0}^{K-1}\|\nabla{\Phi}(x_k)\|^2\leq  \frac{4(\Phi(x_0)-{\inf_x \Phi(x)})}{\alpha K}+\frac{3\delta_0}{K(1-\tau)}+\frac{18nLM_{f_{xy}}^2 C_{F_y}^2{\rm ln}K}{\mu^3{\tilde{\xi}}K}.",2502.01076
definition,"Define          \psi(A, G) \triangleq \langle A^{-1}, G - A \rangle - \ln {\rm Det}(A^{-1} G),  where ${\rm Det}$ denotes the determinant of the matrix.",2502.01076
definition,"Define \[ \theta(A, B, u) := \left[ \frac{\langle (B - A)A^{-1}(B - A)u, u \rangle}{\langle BA^{-1}Bu, u \rangle} \right]^{1/2}, \] and let \(\vartheta : (-1, +\infty) \rightarrow \mathbb{R}\) be the univarite function: \[\vartheta(t) :=  t - \ln(1 + t) \geq 0.\]",2502.01076
proof,"Define $\sigma_i:=\sigma(A, B_i) = \langle A^{-1}, B_i - A \rangle {=}{\rm Tr}(A^{-1}(B_i- A)) \geq 0$, then 		  	  	 \sigma(A, B_i) - \sigma(A, B_{i+1}) &=\langle A^{-1}, B_i -B_{i+1}\rangle\\   &=\frac{\langle B_iA^{-1}B_is_i, s_i \rangle}{\langle B_is_i, s_i \rangle}-1\\    &=\frac{\left\langle B_i \left(A^{-1} - B_i^{-1}\right)B_i s_i, s_i \right\rangle}{\left\langle B_i s_i, s_i \right\rangle}\\ 	 &\geq \frac{\left\langle (B_i - A)A^{-1}(B_i - A)s_i, s_i \right\rangle}{\left\langle B_i s_i, s_i \right\rangle}, 	  	  	where the last inequality follows from the fact that 	  (B_i - A)A^{-1}(B_i - A) &= B_iA^{-1}B_i - 2B_i + A \nonumber \\ \overset{A\preceq B_{i}}{\preceq} \ B_iA^{-1}B_i - B_i &= B_i(A^{-1} - B_i^{-1})B_i. \nonumber   Thus, it is derived that  	\sigma_i-\sigma_{i+1}\geq \frac{\left\langle (B_i - A)A^{-1}(B_i - A)s_i, s_i \right\rangle}{\left\langle B_i s_i, s_i \right\rangle},\quad \forall 0\leq i\leq {k-1}.   Finally, summing the above inequality over $i$ yields:  \sum_{i=0}^{k-1} \frac{\left\langle (B_i - A)A^{-1}(B_i - A)s_i, s_i \right\rangle}{\left\langle B_i s_i, s_i \right\rangle} &\leq \sigma_0 - \sigma_q {\leq} \sigma_0 = \sigma(A, LI) {=} \langle A^{-1}, LI - A\rangle \\ &{\leq} \left\langle A^{-1}, \frac{L}{\mu}A - A \right\rangle{=} n \left( \frac{L}{\mu} - 1 \right) {\leq} \frac{nL}{\mu}.",2502.01076
proof,"Note that      \frac{1}{\xi_{i+1}} J_i \preceq B_i \preceq  \frac{\xi_{i+1} L}{\mu} J_i.    From Lemma 2.4 of \cite{Nesterov2021rates}, it can be further deduced that:            \psi_i - \tilde{\psi}_{i+1} \geq \vartheta \left(\frac{1}{\xi_{i+1}}\theta_i \right).     Since $\bar{\xi}=\underset{i=0,\cdots, k-1}{\rm max}\xi_{i+1}\leq 2$, it follows from the definition of $\theta_i$ that:        \theta_i^2=\frac{\langle (B_i - J_i)J_i^{-1}(B_i - J_i)u_i, u_i \rangle}{\langle B_iJ_i^{-1}B_iu_i, u_i \rangle}=1-\frac{\langle (2B_i - J_i)u_i, u_i \rangle}{\langle B_iJ_i^{-1}B_iu_i, u_i \rangle}\stackrel{(\ref{Jx})}{\leq} 1.     Then, it is derived that:   \vartheta \left( \frac{1}{\xi_{i+1}} \theta_i \right) \stackrel{(\ref{vart})}{\geq} \frac{\frac{1}{\xi_{i+1}^2} \theta_{i}^2}{2 \left(1 + \frac{1}{\xi_{i+1}} \theta_i \right)}  \geq\frac{\frac{1}{\xi_{i+1}^2} }{2 \left(1 + \frac{1}{\xi_{i+1}}  \right)}\theta_i^2= \frac{1}{2 \left(\xi_{i+1}^2 + \xi_{i+1}  \right)}\theta_i^2.   Thus, it holds that:      \tilde{\xi}\theta_i^2\leq \psi_i - \tilde{\psi}_{i+1}=\psi_i - \psi_{i+1}+\Delta_i,\quad \forall i\in \{0,\ldots, k-1\},  where $ \tilde{\xi}=\frac{1}{2 \left(\bar{\xi}^2 + \bar{\xi}  \right)}$ and  \Delta_i:= \psi_{i+1} - \tilde{\psi}_{i+1} = \langle J^{-1}_{i+1} - J^{-1}_i, B_{i+1} \rangle + \ln \text{Det}(J^{-1}_i, J_{i+1}).   By summing equation (\ref{psire}) over $i$ and given that \(\psi_k \geq 0\), it follows that:       & \tilde{\xi} \sum_{i=0}^{k-1} \theta_{i}^2 \leq \psi_0 - \psi_k + \sum_{i=0}^{k-1} \Delta_i \leq \psi_0 + \sum_{i=0}^{k-1} \Delta_i \\ &= \psi(J_0, LI) + \sum_{i=0}^{k-1} \Delta_i\\ &= \langle J^{-1}_0, LI - J_0 \rangle - \ln \text{Det}(J^{-1}_0, LI) + \sum_{i=0}^{k-1} \Delta_i \\ &\leq \langle J^{-1}_0, LI - J_0 \rangle + \sum_{i=0}^{k-1} \Delta_i\\ &\leq \langle J^{-1}_0, \frac{L}{\mu}J_0 - J_0 \rangle + \sum_{i=0}^{k-1} \Delta_i\\ &= n \left( \frac{L}{\mu}  - 1\right) +  \sum_{i=0}^{k-1} \Delta_i.",2502.01076
proof,"Let $u_k^*=[\nabla^2_{y y} f(x_k, y^*_k)]^{-1}\nabla_y F(x_k, y^*_k)$, then               &\|\tilde{\nabla} \Phi(x_k)-\nabla\Phi(x_k)\|^2\\         =&\big\|\nabla_{x} F(x_k, y_{k,T})-[\nabla^2_{x y}f(x_k, y_{k,T})]^Tu_{k,Q_k}-\big(\nabla_{x} F(x_k, y^*_k)-[\nabla^2_{xy}f(x_k, y^*_k)]^Tu_k^*\big)\big\|^2\\         =&\|\nabla_{x} F(x_k, y_{k,T})-\nabla_{x} F(x_k, y^*_k)-([\nabla^2_{x y}f(x_k, y_{k,T})]^Tu_{k,Q_k}-[\nabla^2_{xy}f(x_k, y^*_k)]^Tu_k^*)\|^2\\         =&\|\nabla_{x} F(x_k, y_{k,T})-\nabla_{x} F(x_k, y^*_k)\\         -&\big([\nabla^2_{x y}f(x_k, y_{k,T})]^Tu_{k,Q_k}-[\nabla^2_{x y}f(x_k, y_{k,T})]^Tu_k^*-([\nabla^2_{xy}f(x_k, y^*_k)]^Tu_k^*-[\nabla^2_{x y}f(x_k, y_{k,T})]^Tu_k^*)\big)\|^2\\         =&\|\nabla_{x} F(x_k, y_{k,T})-\nabla_{x} F(x_k, y^*_k)\\         -&[\nabla^2_{x y}f(x_k, y_{k,T})]^T(u_{k,Q_k}-u_k^*)-\big([\nabla^2_{x y}f(x_k, y_{k,T})]^T-[\nabla^2_{xy}f(x_k, y^*_k)]^T\big)u_k^*\|^2\\         \leq&3\|\nabla_{x} F(x_k, y_{k,T})-\nabla_{x} F(x_k, y^*_k)\|^2+3\|\nabla^2_{x y}f(x_k, y_{k,T})\|^2\|u_{k,Q_k}-u_k^*\|^2\\         &+3\|\nabla^2_{x y}f(x_k, y_{k,T})-\nabla^2_{xy}f(x_k, y^*_k)\|^2\|u_k^*\|^2.        Based on Assumptions \ref{ass:F} and \ref{ass:f}, it can be derived that:      &\|\tilde{\nabla} \Phi(x_k)-\nabla\Phi(x_k)\|^2\\     \leq &3L_{F_{x}}^2 \|y_{k,T}-y^*_k\|^2+3M_{f_{xy}}^2\|u_{k,Q_k}-u_k^*\|^2+3\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}\|y_{k,T}-y^*_k\|^2\\     =&3\big(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}\big)\|y_{k,T}-y^*_k\|^2+3M_{f_{xy}}^2\|u_{k,Q_k}-u_k^*\|^2.",2502.01076
proof,"From Lemma \ref{lemqfu}, it follows that: 	  	&\sum_{i=1}^{Q_k}	\frac{(A^{-1}\nabla_y F(x_k, y_{k+1})-u_{k,i})^T A (A^{-1}\nabla_y F(x_k, y_{k+1})-u_{k,i})}{u_{k,i}^T B_{k,i} u_{k,i}}\\ 	=&\sum_{i=1}^{Q_k}	\frac{(A^{-1}\nabla_y F(x_k, y_{k+1})-u_{k,i})^T A (A^{-1}\nabla_y F(x_k, y_{k+1})-u_{k,i})}{\nabla_y F(x_k, y_{k+1})^T B_{k,i}^{-1}\nabla_y F(x_k, y_{k+1})}\\ 	\leq  &\frac{nL}{\mu},   with $B_{k,i}=H_{k,i}^{-1}$.  Since $\mu I \preceq A\preceq LI$ and $A\preceq B_{k,i}\preceq\frac{L}{\mu}A$, we have:  	\sum_{i=1}^{Q_k}	\frac{\mu \|A^{-1}\nabla_y F(x_k, y_{k+1})-u_{k,i}\|^2}{\frac{1}{\mu}\|\nabla_y F(x_k, y_{k+1})\|^2}\leq \frac{nL}{\mu}.   Since $\|\nabla_y F(x_k, y_{k+1})\|\leq C_{F_y}$, it can be further derived that:  	\sum_{i=1}^{Q_k} \|A^{-1}\nabla_y F(x_k, y_{k+1})-u_{k,i}\|^2\leq \frac{nL{C^2_{F_y}}}{\mu^3}.   Finally, by applying the Cauchy-Schwarz inequality, we can deduce that  \sum_{i=1}^{Q_k}\|A^{-1}\nabla_y F(x_k, y_{k+1})-u_{k,i}\|\leq \frac{C_{F_y}}{\mu}\sqrt{\frac{nLQ_k}{\mu}}.",2502.01076
proof,"Under the setting of parameters $\beta, P$ and $H_0$, the condition (\ref{yass}) is satisfied.      Furthermore, based on Lemma \ref{lemuserate} and the fact that $y_{k,0}=y_{k}^P$ and $y_{k}=y_{k}^0$, it holds that:              \|y_{k,T}-y_k^*\|^2\leq \kappa(\frac{1}{T})^{T}\|y_{k,0}-y_k^*\|^2\leq \kappa(\frac{1}{T})^{T}(1-\beta\mu)^P\|y_{k}-y_k^*\|^2,          where $\kappa=\frac{L}{\mu}$. Finally, since $y_{k}=y_{k-1,T}$, using Young's inequality yields:              \|y_{k,T}-y_k^*\|^2&\leq (1+\varepsilon)\kappa (\frac{1}{T})^{T}(1-\beta\mu)^P\|y_{k-1,T}-y_{k-1}^*\|^2+(1+\frac{1}{\varepsilon})\kappa (\frac{1}{T})^{T}(1-\beta\mu)^P\|y_{k-1}^*-y_{k}^*\|^2\\         &\leq (1+\varepsilon)\kappa (\frac{1}{T})^{T}(1-\beta\mu)^P\|y_{k-1,T}-y_{k-1}^*\|^2+(1+\frac{1}{\varepsilon})\kappa (\frac{1}{T})^{T}(1-\beta\mu)^PL_y^2\|x_{k-1}-x_{k}\|^2,          where $\varepsilon$ is a positive constant and the last inequality  follows from Lemma 2.2 in \cite{ghadimi2018approximation}.",2502.01076
proof,"From Lemma \ref{gc}, if $T\geq t_b$, it holds that:              \|y_{k,T}-y_k^*\|^2\leq c_t^2 \kappa^{3}(\frac{1}{T})^{T}\|y_{k,0}-y_k^*\|^2,          where $c_t=2t_b^{\frac{T}{2}}$. Furthermore, since $y_{k,0}=y_{k-1,T}$, using Young's inequality yields:              \|y_{k,T}-y_k^*\|^2&\leq (1+\varepsilon)c_t^2 \kappa^{3} (\frac{1}{T})^{T}\|y_{k-1,T}-y_{k-1}^*\|^2+(1+\frac{1}{\varepsilon})c_t^2 \kappa^{3} (\frac{1}{T})^{T}\|y_{k-1}^*-y_{k}^*\|^2\\         &\leq (1+\varepsilon)c_t^2 \kappa^{3} (\frac{1}{T})^{T}\|y_{k-1,T}-y_{k-1}^*\|^2+(1+\frac{1}{\varepsilon})c_t^2 \kappa^{3} (\frac{1}{T})^{T}L_y^2\|x_{k-1}-x_{k}\|^2,          where $\varepsilon$ is a positive constant and the last inequality  follows from Lemma 2.2 in \cite{ghadimi2018approximation}.",2502.01076
proof,"From Lemma \ref{lc}, if $T\geq K_0$, it holds that:              \|y_{k,T}-y_k^*\|^2\leq c_l^2 \kappa^{3}(\frac{1}{T})^{T}\|y_{k,0}-y_k^*\|^2\leq c_l^2 \kappa^{3}(\frac{1}{T})^{T}(1-\beta\mu)^P\|y_{k}-y_k^*\|^2,          where $c_l=2t_c^{\frac{T}{2}}$. Furthermore,  using Young's inequality yields:              \|y_{k,T}-y_k^*\|^2&\leq (1+\varepsilon)c_l^2 \kappa^{3}(1-\beta\mu)^P (\frac{1}{T})^{T}\|y_{k-1,T}-y_{k-1}^*\|^2+(1+\frac{1}{\varepsilon})c_l^2 \kappa^{3}(1-\beta\mu)^P (\frac{1}{T})^{T}\|y_{k-1}^*-y_{k}^*\|^2\\         &\leq (1+\varepsilon)c_l^2 \kappa^{3}(1-\beta\mu)^P (\frac{1}{T})^{T}\|y_{k-1,T}-y_{k-1}^*\|^2+(1+\frac{1}{\varepsilon})c_l^2 \kappa^{3}(1-\beta\mu)^P (\frac{1}{T})^{T}L_y^2\|x_{k-1}-x_{k}\|^2,          where $\varepsilon$ is a positive constant and the last inequality  follows from Lemma 2.2 in \cite{ghadimi2018approximation}.",2502.01076
proof,"From Lemma \ref{lemqfurate1}, we have:               \|A^{-1}\nabla_y F(x_k, y_{k+1})-\bar{u}_k\|^2\leq \frac{nL{C^2_{F_y}}}{\mu^3 Q_k}.       Moreover, under Assumption \ref{ass:F} and given that $y_{k+1} = y_{k,T}$, it holds that:                \|u_{k,Q_k}-u_k^*\|^2&\leq 2\|\bar{u}_k-A^{-1}\nabla_y F(x_k, y_{k+1})\|^2+2\|A^{-1}\nabla_y F(x_k, y_{k+1})-A^{-1}\nabla_y F(x_k, y_k^*)\|^2\\          &\leq2\frac{nL{C^2_{F_y}}}{\mu^3 Q_k}+2\frac{L_{F_y}^2}{\mu^2}\|y_k^*-y_{k,T}\|^2.",2502.01076
proof,"Substituting the inequality (\ref{quaequ}) into (\ref{eqphi}) yields:         \|\tilde{\nabla} \Phi(x_k)-\nabla\Phi(x_k)\|^2     &\leq 3\big(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}\big)\|y_{k,T}-y^*_k\|^2\\     &+3M_{f_{xy}}^2\big(2\frac{nL{C^2_{F_y}}}{\mu^3 Q_k}+2\frac{L_{F_y}^2}{\mu^2}\|y_k^*-y_{k,T}\|^2\big)\\     &\leq \big(3L_{F_{x}}^2+\frac{3L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}+\frac{6M_{f_{xy}}^2L_{F_y}^2}{\mu^2}\big)\|y_k^*-y_{k,T}\|^2\\     &+6\frac{nLM_{f_{xy}}^2{C^2_{F_y}}}{\mu^3 Q_k}.         Then, by plugging the inequality (\ref{eqphi1})  into (\ref{eqy}), we obtain that:               \|y_k^*-y_{k,T}\|^2&\leq (1+\varepsilon)c_t^2 \kappa^3 (\frac{1}{T})^{T}\|y_{k-1,T}-y_{k-1}^*\|^2+2(1+\frac{1}{\varepsilon})c_t^2 \kappa^3 (\frac{1}{T})^{T}L_y^2\alpha^2\|\nabla \Phi(x_{k-1})\|^2\\     &+2(1+\frac{1}{\varepsilon})c_t^2 \kappa^3 (\frac{1}{T})^{T}L_y^2\alpha^2\|\tilde{\nabla} \Phi(x_{k-1})-\nabla\Phi(x_{k-1})\|^2\\     &\leq \tau\|y_{k-1}^*-y_{k-1,T}\|^2+2(1+\frac{1}{\varepsilon})c_t^2 \kappa^3(\frac{1}{T})^{T}L_y^2\alpha^2\|\nabla \Phi(x_{k-1})\|^2\\     &+12(1+\frac{1}{\varepsilon})c_t^2 \kappa^3(\frac{1}{T})^{T}L_y^2\alpha^2\frac{nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3 Q_{k-1}},\\       where $\tau=c_t^2 \kappa^3(\frac{1}{T})^{T}\big((1+\varepsilon)+6(1+\frac{1}{\varepsilon})L_y^2\alpha^2(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_y}^2}{\mu^2}+\frac{2M_{f_{xy}}^2L_{F_y}^2}{\mu^2})\big)$.  By telescoping (\ref{eqyk}) over $k$, it follows that:               \|y_k^*-y_{k,T}\|^2&\leq \tau^k\|y_0^*-y_{0,T}\|^2+2(1+\frac{1}{\varepsilon})c_t^2 \kappa^3 (\frac{1}{T})^{T}L_y^2\alpha^2\sum_{j=0}^{k-1}{\tau^j \|\nabla \Phi(x_{k-1-j})\|^2}\\         &+12(1+\frac{1}{\varepsilon})c_t^2 \kappa^3(\frac{1}{T})^{T}L_y^2\alpha^2\frac{nLM_{f_{xy}}^2C_{F_y}^2}{\mu^3}\sum_{j=0}^{k-1}{\tau^j \frac{1}{Q_{k-1-j}}}.        Combining the inequality (\ref{eqphi1}) and $\|y_0^*-y_{0,T}\|^2\leq c_t^2 \kappa^3(\frac{1}{T})^{T}\|y_0^*-y_{0,0}\|^2,$ we can further derive that         \|\tilde{\nabla} \Phi(x_k)-\nabla\Phi(x_k)\|^2&\leq \delta_0 \tau^k+\omega \alpha^2\sum_{j=0}^{k-1}{\tau^j \|\nabla \Phi(x_{k-1-j})\|^2}\\ &+6\omega\alpha^2\frac{nLM_{f_{xy}}^2C_{F_y}^2}{\mu^3 }\sum_{j=0}^{k-1}{\tau^j \frac{1}{Q_{k-1-j}}}+6\frac{nLM_{f_{xy}}^2C_{F_y}^2}{\mu^3 Q_k},         with $\delta_0=3c_t^2 \kappa^3(\frac{1}{T})^{T}(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}+\frac{2M_{f_{xy}}^2L_{F_y}^2}{\mu^2})\|y_0^*-y_{0,0}\|^2$ and  $\omega=6(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}+\frac{2M_{f_{xy}}^2L_{F_y}^2}{\mu^2})(1+\frac{1}{\varepsilon})c_t^2 \kappa^3(\frac{1}{T})^{T}L_y^2$.  Since $\nabla\Phi(\cdot)$ is $L_{\Phi}-$lipschitz continuous (Lemma 2.2 in \cite{ghadimi2018approximation}), we have:                   \Phi(x_{k+1}) &\leq \Phi(x_k) + \langle \nabla \Phi(x_k), x_{k+1} - x_k \rangle + \frac{L_{\Phi}}{2} \|x_{k+1} - x_k\|^2 \\ &\leq \Phi(x_k) - \alpha\langle \nabla \Phi(x_k), \tilde{\nabla} \Phi(x_k) - \nabla \Phi(x_k) \rangle - \alpha\| \nabla \Phi(x_k)\|^2 + \alpha^2 L_{\Phi} \|\nabla \Phi(x_k)\|^2 \\ &+ \alpha^2 L_{\Phi} \|\nabla \Phi(x_k) - \tilde{\nabla} \Phi(x_k)\|^2\\ &\leq \Phi(x_k) - \left( \frac{\alpha}{2} - \alpha^2 L_{\Phi} \right) \|\nabla \Phi(x_k)\|^2 + \left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right) \|\nabla \Phi(x_k) - \tilde{\nabla} \Phi(x_k)\|^2.            Using the inequality (\ref{eqphid1}), it holds that:                   \Phi(x_{k+1}) \leq & \Phi(x_k) - \left( \frac{\alpha}{2} - \alpha^2 L_{\Phi} \right) \|\nabla \Phi(x_{k})\|^2 + \left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right) \|\nabla \Phi(x_k) - \tilde{\nabla} \Phi(x_{k})\|^2\\         \leq& \Phi(x_k) - \left( \frac{\alpha}{2} - \alpha^2 L_{\Phi} \right) \|\nabla \Phi(x_k)\|^2 + \left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right)\delta_0 \tau^k\\         &+ \omega \alpha^2 \left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right) \sum_{j=0}^{k-1} \tau^j \|\nabla \Phi(x_{k-1-j})\|^2 + \left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right) \frac{6nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3 Q_k}\\         &+ 6\omega\left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right)\alpha^2 \frac{nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3}\sum_{j=0}^{k-1}{\tau^j \frac{1}{Q_{k-1-j}}}.        Finally, summing the inequality (\ref{eqph1}) from $k=0$ to $k=K-1$ yields:               \left( \frac{\alpha}{2} - \alpha^2 L_{\Phi} \right) \sum_{k=0}^{K-1}\|\nabla \Phi(x_{k})\|^2\leq& \Phi(x_0)-\Phi(x_K)+\left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right)\frac{\delta_0}{1-\tau}\\         &+\omega \alpha^2 \left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right) \sum_{k=0}^{K-1}\sum_{j=0}^{k-1} \tau^j \|\nabla \Phi(x_{k-1-j})\|^2\\         &+6\omega \left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right)\alpha^2 \frac{nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3}\sum_{k=0}^{K-1}\sum_{j=0}^{k-1}{\tau^j \frac{1}{Q_{k-1-j}}}\\         &+ \sum_{k=0}^{K-1}\left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right) \frac{6nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3 Q_k}.        Furthermore, from the inequality $\sum_{k=0}^{K-1}\sum_{j=0}^{k-1}a_j b_{k-1-j}\leq \sum_{k=0}^{K-1}a_k\sum_{j=0}^{K-1}b_j$, we obtain       &\sum_{k=0}^{K-1}\sum_{j=0}^{k-1} \tau^j \|\nabla \Phi(x_{k-1-j})\|^2\leq \sum_{k=0}^{K-1} \tau^k \sum_{k=0}^{K-1}\|\nabla\Phi(x_{k})\|^2\leq \frac{1}{1-\tau}\sum_{k=0}^{K-1}\|\nabla\Phi(x_{k})\|^2,\\      &\sum_{k=0}^{K-1}\sum_{j=0}^{k-1} \tau^j \frac{1}{Q_{k-1-j}}\leq \sum_{k=0}^{K-1} \tau^k \sum_{k=0}^{K-1}\frac{1}{Q_{k}}\leq \frac{1}{1-\tau}\sum_{k=0}^{K-1}\frac{1}{Q_{k}}.    Thus, we can conclude that       &\left( \frac{1}{2} - \alpha L_{\Phi}-\omega \alpha^2 \left( \frac{1}{2} + \alpha L_{\Phi} \right)\frac{1}{1-\tau} \right)\frac{1} {K}\sum_{k=0}^{K-1}\|\nabla \Phi(x_{k})\|^2\\ \leq&\frac{\Phi(x_0)-\Phi(x_K)}{\alpha K}+\left( \frac{1}{2} + \alpha L_{\Phi} \right)\frac{\delta_0}{K(1-\tau)}\\ &+ \left( \frac{1}{2} + \alpha L_{\Phi} \right) \frac{1} {K}\sum_{k=0}^{K-1}\frac{6nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3 Q_k}+\frac{6\omega}{1-\tau} \left( \frac{1}{2} + \alpha L_{\Phi} \right)\alpha^2\frac{1} {K}\sum_{k=0}^{K-1} \frac{nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3 Q_k}.    Moreover, if  $\alpha L_{\Phi}+\omega \alpha^2 \left( \frac{1}{2} + \alpha L_{\Phi} \right)\frac{1}{1-\tau}\leq \frac{1}{4} $, then      \frac{1} {K}\sum_{k=0}^{K-1}\|\nabla \Phi(x_{k})\|^2\leq \frac{4(\Phi(x_0)-\Phi(x^*))}{\alpha K}+\frac{3\delta_0}{K(1-\tau)}+\frac{1} {K}\sum_{k=0}^{K-1}\frac{18nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3 Q_k},  where $\Phi(x^*)=\inf_x \Phi(x)$. Finally, if $Q_k={k+1}$, then (\ref{aqblpratek}) is established.",2502.01076
proof,"Using the Lipschitz continuity of the Hessian, we have               \nabla_{yy}^2 f(x,y_1) - \nabla_{yy}^2 f(x,y_2) &\preceq {L_{f_{yy}}} \|y_1-y_2\| I\\         &\preceq \frac{L_{f_{yy}}}{\mu^{1/2}}\langle \nabla_{y y} ^2f(x,z)(y_1-y_2), y_1-y_2\rangle ^{1/2}I\\         &=\frac{L_{f_{yy}}}{\mu^{1/2}}\|y_1-y_2\|_z I\preceq \frac{L_{f_{yy}}}{\mu^{3/2}}\|y_1-y_2\|_z \nabla_{y y} ^2f(x,w),       where the second and the last inequalities follow from the fact that  $\mu I \preceq \nabla_{yy}^2 f(x,y)$.  This demonstrates that $f$ is strongly self-concordant with constant \( M = \frac{L_{f_{yy}}}{\mu^{3/2}} \).",2502.01076
proof,"Note that in Algorithm \ref{alg:uk}:      J_i := \int_0^1 \nabla_{yy}^2 f(x_k,y_{k+1} + t s_i) \, dt,\quad  J_{i+1} := \int_0^1 \nabla_{yy}^2 f(x_k,y_{k+1} + t s_{i+1}) \, dt,  with $s_i=\zeta_i H_{k,i}\nabla_y F(x_k, y_{k+1})$.  When the step size $\zeta_i$ is chosen appropriately, based on the definition of $J_i$ and the properties of $f$ as stated in Assumption \ref{ass:f}, it can be concluded that $J_i$ is nearly equal to $J_{i+1}$, i.e., $\Delta_i \approx 0$, and $\mu I \preceq J_i \preceq LI$. From Lemma \ref{generalju}, it follows that      \sum_{i=1}^{Q_k}\frac{ (J_i^{-1}\nabla_y F(x_k, y_{k+1}) - u_{k,i})^T J_i(J_i^{-1}\nabla_y F(x_k, y_{k+1}) - u_{k,i})}{\nabla_y F(x_k, y_{k+1})^T J_i^{-1}\nabla_y F(x_k, y_{k+1})}\leq \frac{nL}{\tilde{\xi}\mu}.   Since $\mu I \preceq J_i \preceq LI$, we have      \sum_{i=1}^{Q_k}\frac{ \mu \|J_i^{-1}\nabla_y F(x_k, y_{k+1}) - u_{k,i}\|^2}{\frac{1}{\mu}\|\nabla_y F(x_k, y_{k+1})\|^2}\leq \frac{nL}{\tilde{\xi}\mu}.   Moreover, it follows from Assumption \ref{ass:F}:      \sum_{i=1}^{Q_k}\|J_i^{-1}\nabla_y F(x_k, y_{k+1}) - u_{k,i}\|^2 \leq \frac{nL C^2_{F_y}}{\tilde{\xi}\mu^3}.   If the parameter $M$ of function $f$ or $\zeta_i u_{k,i}$ is sufficiently small, $J_i$ can be considered  as an approximation of $\nabla_{yy}^2 f(x_k, y_{k+1})$. Therefore, $\theta(J_i, B_i, u_i)$ can be used to characterize the approximation  between $H_{k,i}$ and $[\nabla_{yy}^2 f(x_k, y_{k+1})]^{-1}$ along the gradient direction $\nabla_y F(x_k, y_{k+1})$, i.e.,      \sum_{i=1}^{Q_k}\|\nabla_{yy}^2 f(x_k,y_{k+1})^{-1}\nabla_y F(x_k, y_{k+1}) - u_{k,i}\|^2 \leq \frac{nL C^2_{F_y}}{\tilde{\xi}\mu^3},  where $\tilde{\xi}=\underset{i=1,\cdots, Q_k}{\rm min}\frac{1}{2 \left({\xi_i}^2 + {\xi_i}  \right)}$ and $\xi_i=e^{M\sum_{j=0}^{i-1} \|\zeta_j u_{k,j}\|_{y_{k+1}}}$.",2502.01076
proof,"Combining Lemma \ref{lemurate1} and the definition of $\bar{u}_k$  yields:      \|\nabla_{yy}^2 f(x_k,y_{k+1})^{-1}\nabla_y F(x_k, y_{k+1}) - u_{k,Q_k}\|^2 \leq \frac{nL C^2_{F_y}}{\tilde{\xi}\mu^3Q_k}.   Under Assumptions \ref{ass:F} and \ref{ass:f}, since $y_{k+1}=y_{k,T}$, it holds that                               &\|\nabla_{yy}^2 f(x_k,y_{k+1})^{-1}\nabla_y F(x_k, y_{k+1})-\nabla_{yy}^2 f(x_k,y_k^*)^{-1}\nabla_y F(x_k, y_k^*)\|^2\\              \leq& 2\|\nabla_{yy}^2 f(x_k,y_{k+1})^{-1}\nabla_y F(x_k, y_{k+1})-\nabla_{yy}^2 f(x_k,y_{k+1})^{-1}\nabla_y F(x_k, y_k^*)\|^2\\              &+2\|\nabla_{yy}^2 f(x_k,y_{k+1})^{-1}\nabla_y F(x_k, y_k^*)-\nabla_{yy}^2 f(x_k,y_k^*)^{-1}\nabla_y F(x_k, y_k^*)\|^2\\              \leq & 2\frac{L_{F_y}^2}{\mu^2}\|y_k^*-y_{k,T}\|^2+2C^2_{F_y}\|\nabla_{yy}^2 f(x_k,y_{k+1})^{-1}-\nabla_{yy}^2 f(x_k,y_k^*)^{-1}\|^2\\              \leq & 2\frac{L_{F_y}^2}{\mu^2}\|y_k^*-y_{k,T}\|^2\\              &+2C^2_{F_y}\|\nabla_{yy}^2 f(x_k,y_{k+1})^{-1}\|^2\|\nabla_{yy}^2 f(x_k,y_{k+1})-\nabla_{yy}^2 f(x_k,y_k^*)\|^2\|\nabla_{yy}^2 f(x_k,y_k^*)^{-1}\|^2\\              \leq & 2\frac{L_{F_y}^2}{\mu^2}\|y_k^*-y_{k,T}\|^2+2\frac{C^2_{F_y}L^2_{f_{yy}}}{\mu^4}\|y_k^*-y_{k,T}\|^2\\              =&2\left(\frac{L_{F_y}^2}{\mu^2}+\frac{C^2_{F_y}L^2_{f_{yy}}}{\mu^4}\right)\|y_k^*-y_{k,T}\|^2.                       Finally, from Assumption \ref{ass:F} and the inequality (\ref{yk*}), it is derived that                              \|u_{k,Q_k}-u_k^*\|^2\leq &2\|u_{k,Q_k}-\nabla_{yy}^2 f(x_k,y_{k+1})^{-1}\nabla_y F(x_k, y_{k+1})\|^2\\          &+2\|\nabla_{yy}^2 f(x_k,y_{k+1})^{-1}\nabla_y F(x_k, y_{k+1})-\nabla_{yy}^2 f(x_k,y_k^*)^{-1}\nabla_y F(x_k, y_k^*)\|^2\\          &\leq2\frac{nL{C^2_{F_y}}}{\tilde{\xi}\mu^3 Q_k}+4\left(\frac{L_{F_y}^2}{\mu^2}+\frac{C^2_{F_y}L^2_{f_{yy}}}{\mu^4}\right)\|y_k^*-y_{k,T}\|^2.",2502.01076
proof,"Substituting the inequality (\ref{equerror}) into (\ref{eqphi}) yields:         \|\tilde{\nabla} \Phi(x_k)-\nabla\Phi(x_k)\|^2     &\leq 3\big(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}\big)\|y_{k,T}-y^*_k\|^2\\     &+3M_{f_{xy}}^2\left(2\frac{nL{C^2_{F_y}}}{\tilde{\xi}\mu^3 Q_k}+4\big(\frac{L_{F_y}^2}{\mu^2}+\frac{C^2_{F_y}L^2_{f_{yy}}}{\mu^4}\big)\|y_k^*-y_{k,T}\|^2\right)\\     &\leq \left(3L_{F_{x}}^2+\frac{3L_{f_{xy}}^2C^2_{F_{y}}}{\mu^2}+{12 M_{f_{xy}}^2}\big(\frac{L_{F_y}^2}{\mu^2}+\frac{C^2_{F_y}L^2_{f_{yy}}}{\mu^4}\big)\right)\|y_k^*-y_{k,T}\|^2\\     &+6\frac{nLM_{f_{xy}}^2{C^2_{F_y}}}{\mu^3{\tilde{\xi}} Q_k}.\\     Then, based on Lemma \ref{lemy1}, substituting the above inequality into (\ref{eqy1}) yields:               \|y_k^*-y_{k,T}\|^2&\leq (1+\varepsilon)\kappa (\frac{1}{T})^{T}(1-\beta\mu)^P\|y_{k-1,T}-y_{k-1}^*\|^2+2(1+\frac{1}{\varepsilon})\kappa (\frac{1}{T})^{T}(1-\beta\mu)^PL_y^2\alpha^2\|\nabla \Phi(x_{k-1})\|^2\\     &+2(1+\frac{1}{\varepsilon})\kappa (\frac{1}{T})^{T}(1-\beta\mu)^PL_y^2\alpha^2\|\tilde{\nabla} \Phi(x_{k-1})-\nabla\Phi(x_{k-1})\|^2\\     &\leq \tau\|y_{k-1}^*-y_{k-1,T}\|^2+2(1+\frac{1}{\varepsilon})\kappa (\frac{1}{T})^{T}(1-\beta\mu)^PL_y^2\alpha^2\|\nabla \Phi(x_{k-1})\|^2\\     &+12(1+\frac{1}{\varepsilon})\kappa (\frac{1}{T})^{T}(1-\beta\mu)^PL_y^2\alpha^2\frac{nLM_{f_{xy}}^2{C^2_{F_y}}}{\mu^3{\tilde{\xi}} Q_{k-1}},\\       where $\tau=\kappa (\frac{1}{T})^{T}(1-\beta\mu)^P\big((1+\varepsilon)+6(1+\frac{1}{\varepsilon})L_y^2\alpha^2(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C^2_{F_{y}}}{\mu^2}+\frac{4M_{f_{xy}}^2L_{F_y}^2}{\mu^2}+\frac{4M_{f_{xy}}^2C^2_{F_y}L^2_{f_{yy}}}{\mu^4})\big)$.  Summing the inequality (\ref{eqyk1}) from 0 to $k$ results in:               \|y_k^*-y_{k,T}\|^2&\leq \tau^k\|y_0^*-y_{0,T}\|^2+2(1+\frac{1}{\varepsilon})\kappa (\frac{1}{T})^{T}(1-\beta\mu)^PL_y^2\alpha^2\sum_{j=0}^{k-1}{\tau^j \|\nabla \Phi(x_{k-1-j})\|^2}\\         &+12(1+\frac{1}{\varepsilon})\kappa (\frac{1}{T})^{T}(1-\beta\mu)^PL_y^2\alpha^2\frac{nLM_{f_{xy}}^2{C^2_{F_y}}}{\mu^3{\tilde{\xi}} }\sum_{j=0}^{k-1}{\tau^j \frac{1}{Q_{k-1-j}}}.         Combining the inequality (\ref{eqphi1g}) and $\|y_0^*-y_{0,T}\|^2\leq \kappa(\frac{1}{T})^{T}(1-\beta\mu)^P\|y_0^*-y_{0}\|^2$, it follows that         \|\tilde{\nabla} \Phi(x_k)-\nabla\Phi(x_k)\|^2&\leq \delta_0 \tau^k+\omega \alpha^2\sum_{j=0}^{k-1}{\tau^j \|\nabla \Phi(x_{k-1-j})\|^2}\\ &+6\omega\alpha^2\frac{nLM_{f_{xy}}^2{C^2_{F_y}}}{\mu^3 {\tilde{\xi}}}\sum_{j=0}^{k-1}{\tau^j \frac{1}{Q_{k-1-j}}}+6\frac{nLM_{f_{xy}}^2{C^2_{F_y}}}{\mu^3{\tilde{\xi}} Q_k},         where $\delta_0=3\kappa (\frac{1}{T})^{T}(1-\beta\mu)^P(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}+\frac{4M_{f_{xy}}^2L_{F_y}^2}{\mu^2}+\frac{4M_{f_{xy}}^2C^2_{F_y}L^2_{f_{yy}}}{\mu^4})\|y_0^*-y_{0}\|^2$ and $\omega=6(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}+\frac{4M_{f_{xy}}^2L_{F_y}^2}{\mu^2}+\frac{4M_{f_{xy}}^2C^2_{F_y}L^2_{f_{yy}}}{\mu^4})(1+\frac{1}{\varepsilon})\kappa (\frac{1}{T})^{T}(1-\beta\mu)^PL_y^2$.  Since $\nabla\Phi(\cdot)$ is $L_{\Phi}-$Lipschitz, it can be obtained that                   \Phi(x_{k+1}) &\leq \Phi(x_k) + \langle \nabla \Phi(x_k), x_{k+1} - x_k \rangle + \frac{L_{\Phi}}{2} \|x_{k+1} - x_k\|^2 \\ &\leq \Phi(x_k) - \alpha\langle \nabla \Phi(x_k), \tilde{\nabla} \Phi(x_k) - \nabla \Phi(x_k) \rangle - \alpha\| \nabla \Phi(x_k)\|^2 + \alpha^2 L_{\Phi} \|\nabla \Phi(x_k)\|^2 \\ &+ \alpha^2 L_{\Phi} \|\nabla \Phi(x_k) - \tilde{\nabla} \Phi(x_k)\|^2\\ &\leq \Phi(x_k) - \left( \frac{\alpha}{2} - \alpha^2 L_{\Phi} \right) \|\nabla \Phi(x_k)\|^2 + \left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right) \|\nabla \Phi(x_k) - \tilde{\nabla} \Phi(x_k)\|^2.                Using the inequality (\ref{eqphid}) yields:                   \Phi(x_{k+1}) \leq & \Phi(x_k) - \left( \frac{\alpha}{2} - \alpha^2 L_{\Phi} \right) \|\nabla \Phi(x_{k})\|^2 + \left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right) \|\nabla \Phi(x_k) - \tilde{\nabla} \Phi(x_{k})\|^2\\         \leq& \Phi(x_k) - \left( \frac{\alpha}{2} - \alpha^2 L_{\Phi} \right) \|\nabla \Phi(x_k)\|^2 + \left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right)\delta_0 \tau^k\\         &+ \omega \alpha^2 \left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right) \sum_{j=0}^{k-1} \tau^j \|\nabla \Phi(x_{k-1-j})\|^2 + \left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right) \frac{6nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3{\tilde{\xi}} Q_k}\\         &+ 6\omega\left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right)\alpha^2 \frac{nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3{\tilde{\xi}}  }\sum_{j=0}^{k-1}{\tau^j \frac{1}{Q_{k-1-j}}}.        Finally, by telescoping the inequality (\ref{eqph}) from $k=0$ to $k=K-1$, it is derived that               \left( \frac{\alpha}{2} - \alpha^2 L_{\Phi} \right) \sum_{k=0}^{K-1}\|\nabla \Phi(x_{k})\|^2\leq& \Phi(x_0)-\Phi(x_K)+\left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right)\frac{\delta_0}{1-\tau}\\         &+\omega \alpha^2 \left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right) \sum_{k=0}^{K-1}\sum_{j=0}^{k-1} \tau^j \|\nabla \Phi(x_{k-1-j})\|^2\\         &+ \sum_{k=0}^{K-1}\left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right) \frac{6nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3 {\tilde{\xi}}Q_k}\\         &+6\omega \left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right)\alpha^2 \frac{nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3{\tilde{\xi}} }\sum_{k=0}^{K-1}\sum_{j=0}^{k-1}{\tau^j \frac{1}{Q_{k-1-j}}}.        Moreover, due to $\sum_{k=0}^{K-1}\sum_{j=0}^{k-1}a_j b_{k-1-j}\leq \sum_{k=0}^{K-1}a_k\sum_{j=0}^{K-1}b_j$, we can deduce that       &\sum_{k=0}^{K-1}\sum_{j=0}^{k-1} \tau^j \|\nabla \Phi(x_{k-1-j})\|^2\leq \sum_{k=0}^{K-1} \tau^k \sum_{k=0}^{K-1}\|\nabla\Phi(x_{k})\|^2\leq \frac{1}{1-\tau}\sum_{k=0}^{K-1}\|\nabla\Phi(x_{k})\|^2,\\     &\sum_{k=0}^{K-1}\sum_{j=0}^{k-1} \tau^j \frac{1}{Q_{k-1-j}}\leq \sum_{k=0}^{K-1} \tau^k \sum_{k=0}^{K-1}\frac{1}{Q_{k}}\leq \frac{1}{1-\tau}\sum_{k=0}^{K-1}\frac{1}{Q_{k}}.        Then, the following inequality holds:       &\left( \frac{1}{2} - \alpha L_{\Phi}-\omega \alpha^2 \left( \frac{1}{2} + \alpha L_{\Phi} \right)\frac{1}{1-\tau} \right)\frac{1} {K}\sum_{k=0}^{K-1}\|\nabla \Phi(x_{k})\|^2\\ \leq&\frac{\Phi(x_0)-\Phi(x_K)}{\alpha K}+\left( \frac{1}{2} + \alpha L_{\Phi} \right)\frac{\delta_0}{K(1-\tau)}\\ &+ \frac{1} {K}\sum_{k=0}^{K-1}\left( \frac{1}{2} + \alpha L_{\Phi} \right)\frac{6nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3{\tilde{\xi}} Q_k}+\frac{1} {K}\sum_{k=0}^{K-1}\frac{6\omega}{1-\tau} \left( \frac{1}{2} + \alpha L_{\Phi} \right)\alpha^2 \frac{nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3{\tilde{\xi}} Q_k}.    If $\alpha L_{\Phi}+\omega \alpha^2 \left( \frac{1}{2} + \alpha L_{\Phi} \right)\frac{1}{1-\tau}\leq \frac{1}{4} $, then      \frac{1} {K}\sum_{k=0}^{K-1}\|\nabla \Phi(x_{k})\|^2\leq \frac{4(\Phi(x_0)-{\inf_x \Phi(x)})}{\alpha K}+\frac{3\delta_0}{K(1-\tau)}+\frac{1} {K}\sum_{k=0}^{K-1}\frac{18nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3{\tilde{\xi}} Q_k}.    Finally, by substituting \(Q_k = k + 1\) into  (\ref{corocite}), (\ref{agblpratek}) is derived.",2502.01076
proof,"Substituting the inequality (\ref{equerror}) into (\ref{eqphi}) yields:         \|\tilde{\nabla} \Phi(x_k)-\nabla\Phi(x_k)\|^2     &\leq 3\big(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}\big)\|y_{k,T}-y^*_k\|^2\\     &+3M_{f_{xy}}^2\left(2\frac{nL{C^2_{F_y}}}{\tilde{\xi}\mu^3 Q_k}+4\big(\frac{L_{F_y}^2}{\mu^2}+\frac{C^2_{F_y}L^2_{f_{yy}}}{\mu^4}\big)\|y_k^*-y_{k,T}\|^2\right)\\     &\leq \left(3L_{F_{x}}^2+\frac{3L_{f_{xy}}^2C^2_{F_{y}}}{\mu^2}+{12 M_{f_{xy}}^2}\big(\frac{L_{F_y}^2}{\mu^2}+\frac{C^2_{F_y}L^2_{f_{yy}}}{\mu^4}\big)\right)\|y_k^*-y_{k,T}\|^2\\     &+6\frac{nLM_{f_{xy}}^2{C^2_{F_y}}}{\mu^3{\tilde{\xi}} Q_k}.\\    Then, based on Lemma \ref{lemylc}, substituting the above inequality into (\ref{eqylc}) yields:               \|y_k^*-y_{k,T}\|^2&\leq (1+\varepsilon)c_l^2 \kappa^3 (\frac{1}{T})^{T}(1-\beta\mu)^P\|y_{k-1,T}-y_{k-1}^*\|^2+2(1+\frac{1}{\varepsilon})c_l^2 \kappa^3 (\frac{1}{T})^{T}(1-\beta\mu)^PL_y^2\alpha^2\|\nabla \Phi(x_{k-1})\|^2\\     &+2(1+\frac{1}{\varepsilon})c_l^2 \kappa^3 (\frac{1}{T})^{T}(1-\beta\mu)^PL_y^2\alpha^2\|\tilde{\nabla} \Phi(x_{k-1})-\nabla\Phi(x_{k-1})\|^2\\     &\leq \tau\|y_{k-1}^*-y_{k-1,T}\|^2+2(1+\frac{1}{\varepsilon})c_l^2 \kappa^3(\frac{1}{T})^{T}(1-\beta\mu)^PL_y^2\alpha^2\|\nabla \Phi(x_{k-1})\|^2\\     &+12(1+\frac{1}{\varepsilon})c_l^2 \kappa^3 (\frac{1}{T})^{T}(1-\beta\mu)^PL_y^2\alpha^2\frac{nLM_{f_{xy}}^2{C^2_{F_y}}}{\mu^3{\tilde{\xi}} Q_{k-1}},\\       where $\tau=c_l^2 \kappa^3 (\frac{1}{T})^{T}(1-\beta\mu)^P\big((1+\varepsilon)+6(1+\frac{1}{\varepsilon})L_y^2\alpha^2(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C^2_{F_{y}}}{\mu^2}+\frac{4M_{f_{xy}}^2L_{F_y}^2}{\mu^2}+\frac{4M_{f_{xy}}^2C^2_{F_y}L^2_{f_{yy}}}{\mu^4})\big)$.  Summing the inequality (\ref{eqyk1l}) from 0 to $k$ results in:               \|y_k^*-y_{k,T}\|^2&\leq \tau^k\|y_0^*-y_{0,T}\|^2+2(1+\frac{1}{\varepsilon})c_l^2 \kappa^3 (\frac{1}{T})^{T}(1-\beta\mu)^PL_y^2\alpha^2\sum_{j=0}^{k-1}{\tau^j \|\nabla \Phi(x_{k-1-j})\|^2}\\         &+12(1+\frac{1}{\varepsilon})c_l^2 \kappa^3 (\frac{1}{T})^{T}(1-\beta\mu)^PL_y^2\alpha^2\frac{nLM_{f_{xy}}^2{C^2_{F_y}}}{\mu^3{\tilde{\xi}} }\sum_{j=0}^{k-1}{\tau^j \frac{1}{Q_{k-1-j}}}.         Combining the inequality (\ref{eqphi1g1}) and $\|y_0^*-y_{0,T}\|^2\leq c_l^2 \kappa^3(\frac{1}{T})^{T}(1-\beta\mu)^P\|y_0^*-y_{0}\|^2$, it follows that         \|\tilde{\nabla} \Phi(x_k)-\nabla\Phi(x_k)\|^2&\leq \delta_0 \tau^k+\omega \alpha^2\sum_{j=0}^{k-1}{\tau^j \|\nabla \Phi(x_{k-1-j})\|^2}\\ &+6\omega\alpha^2\frac{nLM_{f_{xy}}^2{C^2_{F_y}}}{\mu^3 {\tilde{\xi}}}\sum_{j=0}^{k-1}{\tau^j \frac{1}{Q_{k-1-j}}}+6\frac{nLM_{f_{xy}}^2{C^2_{F_y}}}{\mu^3{\tilde{\xi}} Q_k},         where $\delta_0=3c_l^2 \kappa^3 (\frac{1}{T})^{T}(1-\beta\mu)^P(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}+\frac{4M_{f_{xy}}^2L_{F_y}^2}{\mu^2}+\frac{4M_{f_{xy}}^2C^2_{F_y}L^2_{f_{yy}}}{\mu^4})\|y_0^*-y_{0}\|^2$ and $\omega=6(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}+\frac{4M_{f_{xy}}^2L_{F_y}^2}{\mu^2}+\frac{4M_{f_{xy}}^2C^2_{F_y}L^2_{f_{yy}}}{\mu^4})(1+\frac{1}{\varepsilon})c_l^2 \kappa^3(\frac{1}{T})^{T}(1-\beta\mu)^PL_y^2$.  Since $\nabla\Phi(\cdot)$ is $L_{\Phi}-$Lipschitz, it can be obtained that                   \Phi(x_{k+1}) &\leq \Phi(x_k) + \langle \nabla \Phi(x_k), x_{k+1} - x_k \rangle + \frac{L_{\Phi}}{2} \|x_{k+1} - x_k\|^2 \\ &\leq \Phi(x_k) - \alpha\langle \nabla \Phi(x_k), \tilde{\nabla} \Phi(x_k) - \nabla \Phi(x_k) \rangle - \alpha\| \nabla \Phi(x_k)\|^2 + \alpha^2 L_{\Phi} \|\nabla \Phi(x_k)\|^2 \\ &+ \alpha^2 L_{\Phi} \|\nabla \Phi(x_k) - \tilde{\nabla} \Phi(x_k)\|^2\\ &\leq \Phi(x_k) - \left( \frac{\alpha}{2} - \alpha^2 L_{\Phi} \right) \|\nabla \Phi(x_k)\|^2 + \left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right) \|\nabla \Phi(x_k) - \tilde{\nabla} \Phi(x_k)\|^2.                Using the inequality (\ref{eqphidl}) yields:                   \Phi(x_{k+1}) \leq & \Phi(x_k) - \left( \frac{\alpha}{2} - \alpha^2 L_{\Phi} \right) \|\nabla \Phi(x_{k})\|^2 + \left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right) \|\nabla \Phi(x_k) - \tilde{\nabla} \Phi(x_{k})\|^2\\         \leq& \Phi(x_k) - \left( \frac{\alpha}{2} - \alpha^2 L_{\Phi} \right) \|\nabla \Phi(x_k)\|^2 + \left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right)\delta_0 \tau^k\\         &+ \omega \alpha^2 \left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right) \sum_{j=0}^{k-1} \tau^j \|\nabla \Phi(x_{k-1-j})\|^2 + \left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right) \frac{6nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3{\tilde{\xi}} Q_k}\\         &+ 6\omega\left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right)\alpha^2 \frac{nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3{\tilde{\xi}}  }\sum_{j=0}^{k-1}{\tau^j \frac{1}{Q_{k-1-j}}}.        Finally, by telescoping the inequality (\ref{eqphl}) from $k=0$ to $k=K-1$, it is derived that               \left( \frac{\alpha}{2} - \alpha^2 L_{\Phi} \right) \sum_{k=0}^{K-1}\|\nabla \Phi(x_{k})\|^2\leq& \Phi(x_0)-\Phi(x_K)+\left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right)\frac{\delta_0}{1-\tau}\\         &+\omega \alpha^2 \left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right) \sum_{k=0}^{K-1}\sum_{j=0}^{k-1} \tau^j \|\nabla \Phi(x_{k-1-j})\|^2\\         &+ \sum_{k=0}^{K-1}\left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right) \frac{6nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3 {\tilde{\xi}}Q_k}\\         &+6\omega \left( \frac{\alpha}{2} + \alpha^2 L_{\Phi} \right)\alpha^2 \frac{nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3{\tilde{\xi}} }\sum_{k=0}^{K-1}\sum_{j=0}^{k-1}{\tau^j \frac{1}{Q_{k-1-j}}}.        Moreover, due to $\sum_{k=0}^{K-1}\sum_{j=0}^{k-1}a_j b_{k-1-j}\leq \sum_{k=0}^{K-1}a_k\sum_{j=0}^{K-1}b_j$, we can deduce that       &\sum_{k=0}^{K-1}\sum_{j=0}^{k-1} \tau^j \|\nabla \Phi(x_{k-1-j})\|^2\leq \sum_{k=0}^{K-1} \tau^k \sum_{k=0}^{K-1}\|\nabla\Phi(x_{k})\|^2\leq \frac{1}{1-\tau}\sum_{k=0}^{K-1}\|\nabla\Phi(x_{k})\|^2,\\     &\sum_{k=0}^{K-1}\sum_{j=0}^{k-1} \tau^j \frac{1}{Q_{k-1-j}}\leq \sum_{k=0}^{K-1} \tau^k \sum_{k=0}^{K-1}\frac{1}{Q_{k}}\leq \frac{1}{1-\tau}\sum_{k=0}^{K-1}\frac{1}{Q_{k}}.        Then, the following inequality holds:       &\left( \frac{1}{2} - \alpha L_{\Phi}-\omega \alpha^2 \left( \frac{1}{2} + \alpha L_{\Phi} \right)\frac{1}{1-\tau} \right)\frac{1} {K}\sum_{k=0}^{K-1}\|\nabla \Phi(x_{k})\|^2\\ \leq&\frac{\Phi(x_0)-\Phi(x_K)}{\alpha K}+\left( \frac{1}{2} + \alpha L_{\Phi} \right)\frac{\delta_0}{K(1-\tau)}\\ &+ \frac{1} {K}\sum_{k=0}^{K-1}\left( \frac{1}{2} + \alpha L_{\Phi} \right)\frac{6nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3{\tilde{\xi}} Q_k}+\frac{1} {K}\sum_{k=0}^{K-1}\frac{6\omega}{1-\tau} \left( \frac{1}{2} + \alpha L_{\Phi} \right)\alpha^2 \frac{nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3{\tilde{\xi}} Q_k}.    If $\alpha L_{\Phi}+\omega \alpha^2 \left( \frac{1}{2} + \alpha L_{\Phi} \right)\frac{1}{1-\tau}\leq \frac{1}{4} $, then      \frac{1} {K}\sum_{k=0}^{K-1}\|\nabla \Phi(x_{k})\|^2\leq \frac{4(\Phi(x_0)-\Phi(x^*))}{\alpha K}+\frac{3\delta_0}{K(1-\tau)}+\frac{1} {K}\sum_{k=0}^{K-1}\frac{18nLM_{f_{xy}}^2 C_{F_y}^2}{\mu^3{\tilde{\xi}} Q_k},  where $\Phi(x^*)=\inf_x \Phi(x)$.  Finally, by substituting \(Q_k = k + 1\) into  (\ref{corocitel}), (\ref{agblpratekl}) is derived.",2502.01076
proof,"For Theorem \ref{gblprate}, by Theorem \ref{thm36g}, we have      c_3=6L_y^2(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}+\frac{4M_{f_{xy}}^2L_{F_y}^2}{\mu^2}+\frac{4M_{f_{xy}}^2C^2_{F_y}L^2_{f_{yy}}}{\mu^4}) = \Theta(\kappa^6).     Since $0<(1-\beta\mu)^P\leq 1$ and $\alpha= \Theta (\kappa^{-3}) $, it is derived that           \tau&=\kappa (\frac{1}{T})^{T}(1-\beta\mu)^P\big((1+\varepsilon)+(1+\frac{1}{\varepsilon})\alpha^2c_3\big)=\Theta(\kappa(1/T)^T),\\      \omega &=c_3(1+\frac{1}{\varepsilon})\kappa (\frac{1}{T})^{T}(1-\beta\mu)^P=\Theta(\kappa^7(1/T)^T).\\          Based on Lemma \ref{prelemma}, $\nabla \Phi$ is $L_\Phi$-Lipschitz with $L_\Phi= \Theta(\kappa^3)$. For a suitable choice of $\alpha= \Theta (\kappa^{-3}) $, it follows that $\alpha L_\Phi<\frac{1}{8}$. Additionally,  with $T= \Theta(\ln \kappa)$, the conditions $0 < \tau \leq \frac{1}{2}$ and $\omega\alpha^2 = \Theta(\kappa(1/T)^T) \leq \frac{1}{10}$ are satisfied.   Consequently, \[ \alpha L_{\Phi} + \omega\alpha^2 \left( \frac{1}{2} + \alpha L_{\Phi} \right) \frac{1}{1-\tau} \leq \frac{1}{8} + \frac{1}{10} \left( \frac{1}{2} + \frac{1}{8} \right) \frac{1}{1 - \frac{1}{2}} \leq \frac{1}{4}. \]  Since $\alpha = \Theta(\kappa^{-3})$, it can be obtained from (\ref{agblpratek}) that $\frac{1}{K}\sum_{k=0}^{K-1}\Vert\nabla \Phi(x_k)\Vert^2={\cal O}(\frac{\kappa^3}{K}+\frac{{\kappa^3}{\rm ln}K}{K})$. Furthermore, in order to achieve an $\epsilon$-stationary point, we have $K ={\cal O}(\kappa^3 \epsilon^{-1}{\rm ln}\frac{\kappa^3} {\epsilon})=\tilde{{\cal O}} (\kappa^3 \epsilon^{-1})$. Therefore, the following complexity results are derived:      \item $Gc(f, \epsilon) =K(T+P)+\sum_{k=0}^{K-1} {Q_k}=K(T+P)+\frac{K(K+1)}{2}=\tilde{{\cal O}} (\kappa^6 \epsilon^{-2})$;     \item $Gc(F, \epsilon)=2K= \tilde{{\cal O}}(\kappa^3 \epsilon^{-1})$;     \item $JV(\epsilon) = K=\tilde{{\cal O}}(\kappa^3 \epsilon^{-1})$.   \textbf{Details for obtaining $\tau \leq 1/2$ and $\omega\alpha^2 \leq 1/10$:} Since $\tau = \Theta\left(\kappa(1/T)^T\right)$, $\omega\alpha^2 = \Theta\left(\kappa(1/T)^T\right)$ and $\kappa \geq 1$, it is enough to show that $C_0\kappa(1/T)^T \leq 1/10$ by choosing $T= \Theta(\ln \kappa)$. Here, $C_0 \geq 1$ is a positive constant in $\tau$ and $\omega\alpha^2$, depending explicitly on the Lipschitz constants in the assumptions.  By taking the logarithm on both sides of $C_0\kappa(1/T)^T \leq 1/10$, we get: \[ \ln \kappa - T \ln T \leq -\ln(10C_0). \] This is equivalent to $T \ln T \geq \ln \kappa + \ln(10C_0)$. Therefore, choosing $T \geq \ln \kappa + \ln(10C_0) + \epsilon$ is sufficient, since $\ln T \geq 1$. Similarly, we can prove the result for Theorem \ref{qfblprate}.",2502.01076
proposition,"{\rm (Example 4.1 of \cite{greedyqn})} Suppose  that $\forall x$, the LL  function \( f \) is \( \mu \)-strongly convex \textit{w.r.t.} $y$ and its Hessian is \( L_{f_{yy}} \)-Lipschitz continuous \textit{w.r.t.} $y$. Then \( f \) is strongly self-concordant with constant \( M = \frac{L_{f_{yy}}}{\mu^{3/2}} \), i.e.,  \[ \nabla_{y y} ^2f(x,y_1)-\nabla_{y y} ^2f(x,y_2)\preceq M\|y_1-y_2\|_z \nabla_{y y} ^2f(x,w),\forall y_1,y_2, z, w\in\mathbb{R}^{n}, \]	 where $\|y\|_z:=\langle \nabla_{y y} ^2f(x,z)y, y\rangle^{1/2}$.",2502.01076
lemma,"({\rm \cite{newqn}, Global convergence}) If the function $g$ has the following quadratic form:   	g(y)=\frac{1}{2}y^T A y-y^T  x,  where $\mu I \preceq A \preceq LI$ such that Assumption \ref{ass:g} holds. If the BFGS method is used to solve the problem (\ref{pro}), and if  \textcolor{black}{$H_0=LI$} and the number of iterations $i \geq 4n \ln \frac{L}{\mu}$, then for all $i \geq 4n \ln \frac{L}{\mu}$, the following inequality holds:      \|y_i-y^*\|\leq 2\kappa^{3/2}(\frac{t_b}{i})^{\frac{i}{2}}\|y_0-y^*\|,  with $\kappa=\frac{L}{\mu}$ and $t_b=4n{\rm ln}\frac{L}{\mu}$.",2502.01076
lemma,"({\rm \cite{newqn}, local convergence}) Suppose that Assumption \ref{ass:g} on \( g \) holds. If $H_0=LI$ and the initial point \( y_0 \) satisfies:  \|y_0-y^*\|\leq K_1, K_1=\frac{2{\rm ln}\frac{3}{2}\sqrt{L}}{\frac{3}{2}^\frac{3}{2}M\mu}{\rm max}\{\frac{\mu}{2L},\frac{1}{K_0+9}\},   where $K_0=8n {\rm ln}{\frac{2L}{\mu}}$ and $i \geq K_0$, then for all $i \geq K_0$,  the iterate generated by the  BFGS algorithm has the following superlinear convergence rate:,      \|y_i-y^*\|\leq 2\kappa^{3/2}(\frac{t_c}{i})^{\frac{i}{2}}\|y_0-y^*\|,  with $t_c=\frac{9}{8}K_0$ and $\kappa=\frac{L}{\mu}$.",2502.01076
lemma,"{\rm(Theorem 3 of \cite{jin2023non}) }  Suppose that Assumption \ref{ass:g} on \( g \) holds. If the initial point \( y_0 \) and the initial Hessian approximation matrix \( B_0 \) (with \( H_0 = B_0^{-1} \)) satisfy: 	 		  &\|\nabla^2g(y^*)^{1/2}(y_0-y^*)\|\leq \frac{\epsilon}{6},\\  &\|\nabla ^2g(y^*)^{-1/2}\big(B_0-\nabla ^2g(y^*)\big)\nabla^2g(y^*)^{-1/2}\|_F\leq\delta, 		 	 where $\epsilon, \delta\in (0,\frac{1}{2}), \rho\in(0,1),$  \frac{(3+\epsilon)\epsilon}{(1-\epsilon)(1-\rho)}\leq \delta, {\rm and}\ \frac{\epsilon}{3}+2\delta\leq(1-2\delta)\rho,   then the iterate generated by the  BFGS algorithm has the following superlinear convergence rate:      \|y_i-y^*\|\leq \sqrt{\frac{L}{\mu}}\big(\frac{C_1 q\sqrt{i}+C_2}{i}\big)^i\|y_0-y^*\|,      where $C_1=2\sqrt{2}\delta (1+\rho)(1+\frac{\epsilon}{3})$, $C_2=\frac{(1+\rho)(1+\frac{\epsilon}{3})\epsilon}{3(1-\rho)}$ and $q=\sqrt{\frac{1+2\delta}{1-2\delta}}$.",2502.01076
lemma,"{\rm(Corollary 4 of \cite{jin2023non}) }     Suppose that Assumption \ref{ass:g} on $g$ holds. If the initial point $y_0$ and the initial BFGS matrix $B_0$ satisfy: 	 		  &\|\nabla^2 g(y^*)^{1/2}(y_0-y^*)\|\leq \frac{1}{300},\\  &\|\nabla^2g(y^*)^{-1/2}\big(B_0-\nabla^2 g(y^*)\big)\nabla ^2g(y^*)^{-1/2}\|_F\leq\frac{1}{7}, 		 	 then the iterate solved by the BFGS algorithm  exhibits the following convergence rate:      \|y_i-y^*\|\leq \sqrt{\frac{L}{\mu}}\big(\frac{1}{i}\big)^\frac{i}{2}\|y_0-y^*\|.",2502.01076
lemma,"If the function $g$ in the problem (\ref{pro}) has the following quadratic form:   	g(y)=\frac{1}{2}y^T A y-y^T  x, 	 with $\mu I \preceq A \preceq LI$, then the BFGS matrix $B_i$ satisfies:  	\sum_{i=0}^{k-1}	\frac{(B_i s_i-As_i)^T A^{-1} (B_i s_i-As_i)}{s_i^T B_i s_i}\leq \frac{nL}{\mu}.",2502.01076
lemma,"{\rm(\cite{newqn}, Lemma 5.2 ) }   Define $J_i := \int_0^1 \nabla^2 g(y_i + t s_i) \, dt$ and $y_{i+1}=y_i + s_i$. Then, $J_i s_i=\nabla g(y_{i+1})-\nabla g(y_i)$. If $B_0=L I$, then $\forall i\geq 0$, the {\rm BFGS} matrix $B_{i}$ satisfies:   \frac{1}{\xi_i} \nabla^2 g(y_i) \preceq B_i \preceq \xi_i\frac{L}{\mu} \nabla^2 g(y_i),   \frac{1}{\xi_{i+1}} J_i \preceq B_i\preceq \xi_{i+1}\frac{L}{\mu} J_i,  where $r_i := \left\| s_i \right\|_{y_i}, \quad \xi_i := e^{M \sum_{j=0}^{i-1} r_j} \quad (\geq 1)$ and the strongly self-concordant constant $M$ of $g$.",2502.01076
lemma,"When $B_0=L I$, the {\rm BFGS} matrix $B_{i}$ satisfies (\ref{hesb}) and (\ref{hesj}). If $\bar{\xi}=\underset{i=0,\cdots, k-1}{\rm max}\xi_{i+1}\leq 2$ in (\ref{hesj}), then  the following inequality holds:      \tilde{\xi} \sum_{i=0}^{k-1} \theta_{i}^2\leq n \left( \frac{L}{\mu}  - 1\right) +  \sum_{i=0}^{k-1} \Delta_i,  where $\tilde{\xi}=\frac{1}{2 \left({\bar{\xi}}^2 + {\bar{\xi}}  \right)}$, $\theta_i:=\theta(J_i, B_i,u_i)$, $\psi_i:=\psi(J_i,B_i)$, $\tilde{\psi}_{i+1}:=\psi(J_i,B_{i+1})$, and $\Delta_i:= \psi_{i+1} - \tilde{\psi}_{i+1}$.",2502.01076
lemma,"{\rm(Lemma 2.2 of \cite{ghadimi2018approximation}) }  Under Assumptions \ref{ass:F} and \ref{ass:f}, we have:      \item For all \(x, y\),     \[     \| \bar{\nabla} F(x; y) - \bar{\nabla} F(x; y^*(x)) \| \leq C \| y^*(x) - y \|,     \]     where $\bar{\nabla} F(x; y)=\nabla_x F(x, y)-[\nabla^2_{x y}f(x, y)]^T [\nabla^2_{y y} f(x, y)]^{-1} \nabla_y F(x, y)$ and \(C = L_{F_x} + \frac{L_{F_y} M_{f_{xy}}}{\mu} + C_{F_y} \left( \frac{L_{f_{xy}}}{\mu} + \frac{L_{f_{yy}} M_{f_{xy}}}{\mu^2} \right)\).  \item \( y^*(x) \) is \( L_y \)-Lipschitz continuous in $x$: \[ \| y^*(x_1) - y^*(x_2) \| \leq L_y \| x_1 - x_2 \|, \] where \( L_y = \frac{M_{f_{xy}}}{\mu} \).  \item \( \nabla \Phi \) is \( L_\Phi \)-Lipschitz continuous in $x$: \[ \| \nabla \Phi(x_1) - \nabla \Phi(x_2) \| \leq L_\Phi \| x_1 - x_2 \|, \] where \( L_\Phi = \frac{\left(\bar{L}_{F_y} + C\right) M_{f_{xy}}}{\mu} + L_{F_x} + C_{F_y} \left( \frac{\bar{L}_{f_{xy}} C_{F_y}}{\mu} + \frac{\bar{L}_{f_{yy}} M_{f_{xy}}}{\mu^2} \right) \).",2502.01076
lemma,"Suppose that Assumptions \ref{ass:F} and \ref{ass:f} hold. The error between the approximate hypergradient $\tilde{\nabla} \Phi(x_k)$ and the true hypergradient in Algorithm \ref{alg:foa} can be bounded by:          \|\tilde{\nabla} \Phi(x_k)-\nabla\Phi(x_k)\|^2     \leq 3\big(L_{F_{x}}^2+\frac{L_{f_{xy}}^2C_{F_{y}}^2}{\mu^2}\big)\|y_{k,T}-y^*_k\|^2+3M_{f_{xy}}^2\|u_{k,Q_k}-u_k^*\|^2.",2502.01076
lemma,"When the qNBO algorithm (Algorithm \ref{alg:foa}) is applied to solve the problem (\ref{blp}), if  the LL objective function $f$ takes the quadratic form (\ref{qf}) and $H_0 = (1/L)I$, it holds that:  \sum_{i=1}^{Q_k}\|A^{-1}\nabla_y F(x_k, y_{k+1})-u_{k,i}\|\leq \frac{C_{F_y}}{\mu}\sqrt{\frac{nLQ_k}{\mu}},  with $Q_k>1$.",2502.01076
lemma,"Choose the parameters  $\beta$ and  $P$ such that $(1-\beta\mu)^P\|y_{k}-y_{k}^*\|\leq \frac{1}{300\sqrt{\mu}}$, and ensure $H_0$ satisfies: $\|\nabla^2_{yy}f(x_k,y^*(x_k))^{-1/2}\big(H_0^{-1}-\nabla^2_{yy}f(x_k,y^*(x_k))\big)\nabla^2_{yy}f(x_k,y^*(x_k))^{-1/2}\|_F\leq\frac{1}{7}$.  Then, under Assumptions \ref{ass:F} and \ref{ass:f}, it holds that     \|y_k^*-y_{k,T}\|^2\leq (1+\varepsilon)\kappa (\frac{1}{T})^{T}(1-\beta\mu)^P\|y_{k-1,T}-y_{k-1}^*\|^2+(1+\frac{1}{\varepsilon})\kappa (\frac{1}{T})^{T}(1-\beta\mu)^PL_y^2\|x_{k}-x_{k-1}\|^2,      with a positive constant $\varepsilon$.",2502.01076
lemma,"If the LL function $f$ takes the quadratic form and $T\geq t_b$, under Assumptions \ref{ass:F} and \ref{ass:f}, it is derived that      \|y_k^*-y_{k,T}\|^2\leq (1+\varepsilon)c_t^2 \kappa^3 (\frac{1}{T})^{T}\|y_{k-1,T}-y_{k-1}^*\|^2+(1+\frac{1}{\varepsilon})c_t^2\kappa^3 (\frac{1}{T})^{T}L_y^2\|x_{k}-x_{k-1}\|^2,      with $t_b=4n{\rm ln}\frac{L}{\mu}$ and a positive constant $\varepsilon$.",2502.01076
lemma,"Choose the parameters  $\beta$, $P$ such that $(1-\beta\mu)^P\|y_{k}-y_{k}^*\|\leq K_1$, and $H_0=LI$, under Assumptions \ref{ass:F} and \ref{ass:f}, it is derived that      \|y_k^*-y_{k,T}\|^2\leq (1+\varepsilon)c_l^2 \kappa^{3}(1-\beta\mu)^P (\frac{1}{T})^{T}\|y_{k-1,T}-y_{k-1}^*\|^2+(1+\frac{1}{\varepsilon})c_l^2 \kappa^{3}(1-\beta\mu)^P (\frac{1}{T})^{T}L_y^2\|x_{k-1}-x_{k}\|^2,      with a positive constant $\varepsilon$, $T\geq K_0$, $K_0:=8n{\rm ln}\frac{2L}{\mu}$, $c_l=2t_c^{\frac{T}{2}}$.",2502.01076
lemma,"({\rm Error of $u_{k,Q_k}$}) Suppose that the lower level function $f$ has the quadratic form and Assumptions \ref{ass:F} and \ref{ass:f} hold. If $u_{k,Q_k}=\bar{u}_k$ and       \bar{u}_k:=\underset{i}{\rm arg min}\|A^{-1}\nabla_y F(x_k, y_{k+1})-u_{k,i}\|,  then for $Q_k>1$, the following inequality holds:                \|u_{k,Q_k}-u_k^*\|^2\leq 2\frac{nL{C^2_{F_y}}}{\mu^3 Q_k}+2\frac{L_{F_y}^2}{\mu^2}\|y_k^*-y_{k,T}\|^2.",2502.01076
lemma,"If the Assumptions \ref{ass:F} and \ref{ass:f} hold, then $u_{k,i}$ generated in the step 2 of the Algorithm \ref{alg:foa} satisfies:          \sum_{i=1}^{Q_k}\|\nabla_{yy}^2 f(x_k,y_{k+1})^{-1}\nabla_y F(x_k, y_{k+1}) - u_{k,i}\|^2 \leq \frac{nL C^2_{F_y}}{\tilde{\xi}\mu^3},  where $Q_k>1$, $\tilde{\xi}=\underset{i=1,\cdots, Q_k}{\rm min}\ \frac{1}{2 \left({\xi^2_i} + {\xi_i}  \right)}$ and $\xi_i=e^{M\sum_{j=0}^{i-1} \|\zeta_j u_{k,j}\|_{y_{k+1}}}$.",2502.01076
lemma,"Suppose that Assumption \ref{ass:f} holds. Note that $u_{k+1}=u_{k,Q_k}$ in the step 2 of Algorithm \ref{alg:foa}. If $u_{k,Q_k}=\bar{u}_k$  with       \bar{u}_k:=\underset{i}{\rm arg min}\|\nabla_{yy}^2 f(x_k,y_{k+1})^{-1}\nabla_y F(x_k, y_{k+1}) - u_{k,i}\|^2,   then       \|u_{k,Q_k}-u_k^*\|^2\leq 2\frac{nL{C^2_{F_y}}}{\tilde{\xi}\mu^3 Q_k}+4\left(\frac{L_{F_y}^2}{\mu^2}+\frac{C^2_{F_y}L^2_{f_{yy}}}{\mu^4}\right)\|y_k^*-y_{k,T}\|^2, \rm{ \forall Q_k>1},   where $\tilde{\xi}=\underset{i=1,\cdots, Q_k}{\rm min}\frac{1}{2 \left({\xi_i}^2 + {\xi_i}  \right)}$ and $\xi_i=e^{M\sum_{j=0}^{i-1} \|\zeta_j u_{k,j}\|_{y_{k+1}}}$.",2502.01076
proof,"The first isomorphism is a general fact mentioned earlier. 		For the second, from 		$$ 		C_\nfk(z) = z\prod_{0\neq \lambda \in \Lambda_\nfk} (z - \lambda), 		$$ 		we take derivative and substitute $z=0$, which results in 		$$ 		\nfk = \prod_{0\neq \lambda \in \Lambda_\nfk} (-\lambda). 		$$ 		Since the reduction of $\nfk$ is non-zero in $\FF_{\Pfk}$, we obtain an injection $\Lambda_{\nfk} \to C(\FF_{\Pfk})[\nfk] \sbe C(\FF_\Pfk)$. 		In particular, we have $\Lambda_{v^\l-1} \simeq C(\FF_{\Pfk})$ by counting cardinality. 		(Here, we identify the residue field of $v$ in $K_{v^\l-1}$ with $\FF_{\Pfk}$.)",2502.01109
proof,See \cite[Theorem 1.7.11]{goss1996basic}.,2502.01109
proof,"A similar argument to that of Proposition \ref{reduction-of-lambda} applies in the adjoint setting. 		The first isomorphism is also a general property. 		For the second, one considers 		$$ 		(C_\nfk^*(z) / \nfk)^{q^{\deg\nfk}} 		= z\prod_{0 \neq \lambda^* \in \Lambda_\nfk^*} (z - \lambda^*). 		$$ 		We omit the details.",2502.01109
proof,See \cite[\nopp 8]{ore1933special} or \cite[Theorem 1.7.13]{goss1996basic}.,2502.01109
proof,This is equivalent to \cite[Lemma I]{thakur1988gauss}.,2502.01109
proof,"We begin with the right-hand side of the proposition. 		For each $z \in \FF_{\Pfk'}^\times$, we have 		 			\omega\left(C_{x(v^{\l'}-1)}(z^{-1})\right) 			&= \omega\left(C_{x(v^\l-1) \sum_{i=0}^{m-1} v^{i\l}}(z^{-1})\right) 			= \sum_{i=0}^{m-1} \omega\left(C_{x(v^\l-1)v^{i\l}}(z^{-1})\right) 			\\ 			&= \sum_{i=0}^{m-1} \omega\left(C_{x(v^\l-1)}(z^{-q^{d\l i}})\right) 			= \omega\left(C_{x(v^\l-1)} (\Tr_{\FF_{\Pfk'}/\FF_{\Pfk}}(z^{-1}))\right) 		 		where the third equality is because $C_v \equiv \tau^d \pmod{v}$ sends $z$ to $z^{q^d}$ (recall \ref{section-cyclotomic-function-fields}). 		So by Lemma \ref{descending-ggs}, we have 		 			\sum_{z \in \FF_{\Pfk'}^\times} \omega\left(C_{x(v^{\l'}-1)}(z^{-1})\right)\psi(z) 			&= \sum_{z \in \FF_{\Pfk'}^\times} \omega\left(C_{x(v^\l-1)}(\Tr_{\FF_{\Pfk'}/\FF_{\Pfk}}(z^{-1}))\right)\psi(z)        \\ 			&= \sum_{z \in \FF_{\Pfk}^\times} \omega\left(C_{x(v^\l-1)}(z^{-1})\right)\psi(z).",2502.01109
proof,"(1) follows from the commutativity of $A$-actions $\rho_a \circ \omega = \omega \circ C_a$. 		For (2), by change of variables and using the fact that $C_v \equiv \tau^d \pmod{v}$, we have 		$$ 		(\bggs_x)^{\sigma_{1,-d}} 		= 1 + \sum_{z \in \FF_\Pfk^\times} \omega\left(C_{x(v^\l-1)} (z^{-q^d})\right) \psi(y) 		= 1 + \sum_{z \in \FF_\Pfk^\times} \omega\left(C_{vx(v^\l-1)} (z^{-1})\right) \psi(y) 		= \bggs_{vx}. 		$$",2502.01109
proof,"From Theorem \ref{restatement-of-abp-5.4.4}(2), we have 		$$ 		\sum_{i=1}^{d\l} \lambda_i^* \cdot \lambda_i^{q^{d\l}} = 1. 		$$ 		Taking reduction modulo $\Pfk_\mfk$ and applying $\psi$ on both sides yield 		$$ 		\sum_{i=1}^{d\l} \psi(\ovl{\lambda}{}^*_i) \psi(\ovl{\lambda}_i) = 1. 		$$ 		Now, using the observation right before the theorem, we have 		 			\bggs_x 			&= 1 + \sum_{z \in \FF_{\Pfk_\mfk}^\times} \omega\left(C_{\mfk x} (z^{-1})\right)\psi(z) \sum_{i=1}^{d\l} \psi(\ovl{\lambda}{}^*_i) \psi(\ovl{\lambda}_i)    \\ 			&= 1 + \sum_{i=1}^{d\l} \sum_{z \in \FF_{\Pfk_\mfk}^\times} \omega\left(C_{\mfk x} (z^{-1})\right) \psi(z \ovl{\lambda}_i) \psi(\ovl{\lambda}{}^*_i)  \\ 			&= 1 + \sum_{z \in \FF_{\Pfk_\mfk}^\times} \sum_{i=1}^{d\l} \omega\left(C_{\mfk x} (z^{-1}\ovl{\lambda}_i)\right) \psi(z\ovl{\lambda}{}^*_i). 		 		The last equality is by the change of variables $z \ovl{\lambda}_i \mapsto z$. 		We will claim that for each $z \in \FF_{\Pfk_\mfk}^\times$, 		       			\sum_{i=1}^{d\l} \omega\left(C_{\mfk x} (z^{-1}\ovl{\lambda}_i)\right) \psi(z \ovl{\lambda}{}^*_i) 			=  \sum_{i=1}^{d\l} \omega\left(C_{\mfk x} (\ovl{\lambda}_i)\right) \psi(\ovl{\lambda}{}^*_i). 		 		Assuming this for a moment, then the above becomes 		$$ 		\bggs_x 		= 1 + \sum_{z \in \FF_{\Pfk_\mfk}^\times} \sum_{i=1}^{d\l} \omega\left(C_{\mfk x} (\ovl{\lambda}_i)\right) \psi(\ovl{\lambda}{}^*_i) 		= 1 - \sum_{i=1}^{d\l} C_{\mfk x}(\lambda_i) \psi(\ovl{\lambda}{}^*_i), 		$$ 		where the last equality is because 		$$ 		\omega\left(C_{\mfk x} (\ovl{\lambda}_i)\right) 		= C_{\mfk x}\left(\omega(\ovl{\lambda}_i)\right) 		= C_{\mfk x}(\lambda_i). 		$$ 		And this is exactly what we want. 		 		It remains to prove the claim. 		Let $X := (\ovl{\lambda}_1, \ldots, \ovl{\lambda}_{d\l})$ and $Y := (\ovl{\lambda}{}^*_1, \ldots, \ovl{\lambda}{}^*_{d\l})$ be as row vectors.  		From Propositions \ref{reduction-of-lambda} and \ref{reduction-of-lambda*}, we know the entries of $X$ and $Y$ are both $\Fq$-bases of the finite field $\FF_{\Pfk_\mfk}$.  		For each $z \in \FF_{\Pfk_\mfk}^\times$, we let $z$ act on the vectors $X$ and $Y$ componentwise by the usual multiplication, and write 		$$ 		z^{-1}X = X\Mcal^{-1} 		\quad 		\text{and} 		\quad  		z Y = Y\Ncal 		$$ 		for some $\Mcal,\Ncal \in \GL_{d\l}(\Fq)$. 		We next apply $\omega \circ C_{\mfk x}$ to the first equation componentwise and $\psi$ to the second. 		Since they are $\Fq$-linear, we obtain 		     			\omega\left(C_{\mfk x} (z^{-1}X)\right) 			= \omega\left(C_{\mfk x} (X)\right)  \Mcal^{-1} 			\quad 			\text{and} 			\quad  			\psi(zY) = \psi(Y) \Ncal. 		 		In Section \ref{section-pairing-comparisons-and-geometric-gauss-sums-at-infinity} (Theorem \ref{pairing-summary} to be exact), we will show that in fact, $X$ and $Y$ are dual bases with respect to the trace pairing $\angtr{\cdot,\cdot}: \FF_{\Pfk_\mfk} \times \FF_{\Pfk_\mfk} \to \Fq$ defined by $\angtr{a,b} := \Tr_{\FF_{\Pfk}/\Fq}(ab)$. 		Then since $\angtr{za,b} = \angtr{a,zb}$, it follows that $\Mcal = \Ncal^t$. 		Thus, \eqref{claim-in-coleman-function-and-gauss-sum} becomes 		 			&\sum_{i=1}^{d\l} \omega\left(C_{\mfk x} (z^{-1}\ovl{\lambda}_i)\right) \psi(z \ovl{\lambda}{}^*_i) 			= \omega\left(C_{\mfk x} (z^{-1}X)\right) \cdot \psi(zY)^t   \\ 			\overset{\eqref{MNcal-omega-psi}}{=}{} &\omega\left(C_{\mfk x} (X)\right)  \Mcal^{-1} 			\cdot \Ncal^t \psi(Y)^t 			= \omega\left(C_{\mfk x} (X)\right) \cdot \psi(Y)^t 			= \sum_{i=1}^{d\l} \omega\left(C_{\mfk x} (\ovl{\lambda}_i)\right) \psi(\ovl{\lambda}{}^*_i). 		 		This completes the claim, and hence the proof.",2502.01109
proof,"The second congruence equation follows from the observation that for each $a\in\Ami$, $(x+a)^\flat$ and $(y+a)^\flat$ are either simultaneously $1$ or $x+a$ and $y+a$. 		For the first one, we write $n=\sum n_iq^i$ and $m=\sum m_iq^i$ in $q$-adic expansions. 		By assumption we have $n_i = m_i$ for $i < s$. 		So it's sufficient to show that 		$$ 		\prod_{a\in\Ami} \frac{a^\flat}{(x+a)^\flat} \equiv 1 \pmod{v^{\floor{s/d}}} 		$$ 		for all $i\geq s$. 		For the numerator, write $i=ed+j$ where $0\leq j < d$. 		And for each $a\in\Ami$, write $a=f\cdot v^e+g$ where $\deg f=j$ and $\deg g<ed$. 		Note that $v\nmid a$ if and only if $v\nmid g$, and as $a$ runs through $\Ami$, we get $q^i/q^{ed} = q^j$ copies of complete residue system modulo $v^e$. 		Hence, we see by Wilson's theorem that 		$$ 		\prod_{a\in\Ami} a^\flat 		= \prod_{\substack{a\in\Ami \\ v\nmid a}} a 		\equiv \left(\prod_{g \in (A/v^eA)^\times} g \right)^{q^j}  		\equiv -1 \pmod{v^e = v^{\floor{i/d}}}. 		$$ 		This shows that the numerator is congruent to $-1$ modulo $v^{\floor{s/d}}$. 		A similar argument shows that this is also true for the denominator. 		Writing $x+a = f\cdot v^e+g$, we observe that there are $q^j$ possibilities of $f$, each corresponding to a complete residue system modulo $v^e$. 		Hence, the result follows.",2502.01109
proof,"Starting with $\vgf(\cdot,\cdot)$ (Definition \ref{v-adic-gamma-definition}(3)), we have 		    			\prod_\alpha \vgf\left(\frac{x+\alpha}{g},y\right) 			= \lim_{N\to\infty} 			\left( \prod_{i=0}^N \left( \prod_{a\in\Ami} \prod_{\alpha} \frac{1}{(ga+\alpha+x)^\flat} \right)^{y_i} \right)   \\ 			\left( \prod_{i=0}^N \prod_{a\in\Ami} \prod_\alpha (a^\flat)^{y_i} \right) 			\left( \prod_{i=0}^N \left( \prod_{a\in\Ami} \prod_{\substack{\alpha \\ v\nmid ga+\alpha+x}} g \right)^{y_i} \right).  		 		In the first term, we see from the division algorithm that for each such $a$ and $\alpha$, $ga+\alpha$ corresponds to a unique $b \in A_+$ with $h \leq \deg b\leq N+h$, and vice versa. 		So by change of variables, the first two terms of \eqref{multiplication-formula-eq-1} are 		 			&\left( \prod_{i=0}^N \left( \prod_{a\in\Ami} \prod_{\alpha} \frac{1}{(ga+\alpha+x)^\flat} \right)^{y_i} \right)  			\left( \prod_{i=0}^N \prod_{a\in\Ami} \prod_\alpha (a^\flat)^{y_i} \right)    \\ 			={} &\left( \prod_{i=h}^{N+h} \left( \prod_{b\in\Ami} \frac{b^\flat}{(b+x)^\flat} \right)^{y_{i-h}} \right) 			\left( \prod_{i=h}^{N+h} \left( \prod_{b\in\Ami} \frac{1}{b^\flat} \right)^{y_{i-h}} \right) 			\left( \prod_{i=0}^N \prod_{a\in\Ami} (a^\flat)^{y_i} \right)^{q^h} 		 		Note that the first term converges to $\vgf(x,q^h y)$. 		And for the latter two, by multiplying $-1$ to each of their terms, they converge to $1/\vaf(q^h y)$ and $\vaf(y)^{q^h}$, respectively. 		Recall by Definition \ref{v-adic-gamma-definition}(3), $\vtf(x,y) = \vgf(x,y)/\vaf(y)$. 		Thus, \eqref{multiplication-formula-eq-1} becomes 		$$ 		\prod_{\alpha} \vtf\left(\frac{x+\alpha}{g},y\right) = \vtf(x,q^h y)  \lim_{N\to\infty} \prod_{i=0}^N \left( \prod_{a\in\Ami} \prod_{\substack{\alpha \\ v\nmid ga+\alpha+x}} g \right)^{y_i}. 		$$ 		 		It remains to show that the limit converges to a power of $g$ times a one-unit. 		By using the same change of variables again, we see that 		$$ 		\lim_{N\to\infty} \prod_{i=0}^N \left( \prod_{a\in\Ami} \prod_{\substack{\alpha \\ v\nmid ga+\alpha+x}} g \right)^{y_i} 		= \lim_{N\to\infty} \prod_{i=h}^{N+h} \left( \prod_{b\in\Ami} \prod_{ v \nmid b+x} g \right)^{y_{i-h}} 		= \lim_{N\to\infty} g^{\sum_{i=h}^{N+h} k_iy_{i-h}} 		$$ 		where 		$$ 		k_i = 		 			(q^d-1)q^{i-d}, & \text{if } i \geq d,  \\ 			q^i-1, & \text{if } h \leq i = i' < d  \text{ and } \sgn(x_0)=-1, \\ 			q^i, & \text{otherwise}, 		 		$$ 		which counts the cardinality of the set $\{b \in\Ami \mid v \nmid b+x\}$. 		Thus, by the definitions of $\delta_x,i'$ and $m$, we have 		$$ 		\sum_{i=h}^{N+h} k_iy_{i-h} 		= -\delta_x y_{i'-h} + m + (q^d-1)\sum_{i=d}^{N+h} y_{i-h} q^{i-d}. 		$$ 		So the power of $g$ is established. 		On the other hand, note that $g_N := g^{(q^d-1)\sum_{i=d}^{N+h} y_{i-h} q^{i-d}}$ satisfies 		$$ 		g_N \equiv 1 \pmod{v} 		\quad 		\text{and} 		\quad 		\frac{g_{N+1}}{g_N} = g^{(q^d-1)y_{N+1}q^{N+1+h-d}} \equiv 1 \pmod{v^{q^{N+1+h-d}}}. 		$$  		So by the non-Archimedean property, the limit converges to a one-unit $u_g(y)$. 		This completes the proof.",2502.01109
proof,"Assume $y \in (q^t-1)^{-1}\ZZ$. 		During the proof of Theorem \ref{multiplication-formula}, we saw that 		$$ 		u_g(y) 		= \lim_{N\to\infty} g^{ (q^d-1)\sum_{i=d}^{N+h} y_{i-h} q^{i-d} } 		= \lim_{N\to\infty} g^{ (q^d-1)q^{h-d} \sum_{i=d-h}^{N} y_i q^i }. 		$$ 		Let $n \in \NN$ be large enough so that we have $y_{nt+i} = y_{nt+j}$ if and only if $i \equiv j \pmod{t}$. 		Put $m := \sum_{i=nt}^{nt+t-1} y_iq^i$. 		Then the $(q^t-1)$-st power of $u_g(y)$ is seen to be 		$$ 		u_g(y)^{q^t-1} 		\sim \lim_{N\to\infty} g^{ (q^d-1) (q^t-1) \sum_{i=nt}^{(n+N)t-1} y_i q^i } 		= \lim_{N\to\infty} g^{ (q^d-1)(q^{Nt}-1)m} 		\sim \lim_{N\to\infty} g^{ (q^d-1)q^{Nt}} 		= 1 		$$ 		as $g^{q^d-1} \equiv 1 \pmod{v}$. 		Hence, $u_g(y)$ is algebraic.",2502.01109
proof,"Since all the quantities are unchanged when replacing $(x,y)$ by $(\anginf{x},\ang{y})$, we may assume $\anginf{x} = x$ and $\ang{y} = y$. 		For each $0 \leq i \leq \l-1$, set 		$$ 		\ang{|v^i|_\infty y} 		= \ang{q^{di}y} 		= \ang{\frac{q^{s+di}}{q^{d\l}-1}} 		=: \frac{q^{s_i}}{q^{d\l}-1} 		$$ 		where $s_i \equiv s+di \pmod{d\l}$ with $0 \leq s_i < d\l$ (the index is considered modulo $\l$). 		Then by the definition of $\vgf(\cdot,\cdot)$ (Definition \ref{v-adic-gamma-definition}(3)), we have 		    			\prod_{i=0}^{\l-1} \vgf \left( \anginf{v^ix}, -\ang{|v^i|_\infty y} \right) 			= \lim_{N\to\infty}  \prod_{i=0}^{\l-1} \prod_{j=0}^N  \prod_{a \in A_{+,s_i+jd\l}} \frac{a^\flat}{\left(\anginf{v^ix}+a\right)^\flat}.        		 		Put $x_\l := x_0$ and note that $\anginf{v^ix} \equiv -x_{\l-i} \pmod{v}$ in $A_v$ for all $0\leq i \leq \l-1$. 		So 		$$ 		v \mid \anginf{v^ix} + a 		\iff a \equiv x_{\l-i} \pmod{v}. 		$$ 		We now split the right-hand side of \eqref{gkt-eq1} into two cases according to the value of $s_i$: 		 			\item Case 1: 			$s_i = s'$ (which means $i \equiv \l-e \pmod{\l}$ as $s_i \equiv s+d(\l-e) \equiv s' \pmod{d\l}$). 			Then \eqref{gkt-eq1} corresponds to 			 				&\prod_{j=0}^N  \prod_{a \in A_{+,s'+jd\l}} \frac{a^\flat}{\left(\anginf{v^{\l-e} x}+a \right)^\flat}     \nonumber     \\ 				={} &\left( \prod_{a \in A_{+,s'}} \frac{a^\flat}{\left(\anginf{v^{\l-e} x}+a\right)^\flat} \right) 				\left( \prod_{j=1}^N  \prod_{a \in A_{+,s'+jd\l}} \frac{a^\flat}{\left(\anginf{v^{\l-e} x}+a\right)^\flat} \right).      			 			The reason of singling out $j=0$ term is because $0 \leq s' <d$, making the situation slightly different. 			For the first term, the numerator $a$ is never divisible by $v$ as $0 \leq \deg a = s' < d$. 			And the denominator $\anginf{v^{\l-e} x}+a$ is divisible by $v$ if and only if $a = x_e \in A_{+,s'}$, in which case $\anginf{v^{\l-e} x} + a = v\anginf{v^{\l-e-1}x}$. 			So this term is (recall \eqref{Psi} the definition of $\Psi$) 			 				\prod_{a \in A_{+,s'}} \frac{a^\flat}{\left(\anginf{v^{\l-e} x}+a\right)^\flat} 				&= \delta_x^{(s)} 				\prod_{a \in A_{+,s'}} 	\frac{a}{\anginf{v^{\l-e} x}+a}   \\ 				&= \delta_x^{(s)} \left(1+ \Psi_{s'}\left(\anginf{v^{\l-e} x}\right)\right)^{-1}. 			 			For the second term, note that when $a \in A_{+,s'+jd\l}$, we have $v \mid \anginf{v^{\l-e} x} + a$ if and only if $a \equiv x_e \pmod{v}$. 			And in this case, $a = x_e + va'$ for some $a' \in A_{+,s'+jd\l-d}$ and $\anginf{v^{\l-e}x} + a = v(\anginf{v^{\l-e-1}x} + a')$. 			So this term is 			 				&\prod_{j=1}^N \prod_{a \in A_{+,s'+jd\l}} \frac{a^\flat}{\left(\anginf{v^{\l-e}x}+a\right)^\flat}   \\ 				={} &\prod_{j=1}^N \frac{ \prod_{a\in A_{+,s'+jd\l}} a \Big/ \prod_{a\in A_{+,s'+jd\l-d}} va }{ \prod_{a\in A_{+,s'+jd\l}} \left(\anginf{v^{\l-e}x}+a\right) \Big/ \prod_{a\in A_{+,s'+jd\l-d}} v\left(\anginf{v^{\l-e-1}x} + a\right) }      \\ 				={} &\prod_{j=1}^N \frac{1+\Psi_{s'+jd\l-d} \left(\anginf{v^{\l-e-1}x}\right)}{1+\Psi_{s'+jd\l} \left(\anginf{v^{\l-e}x}\right)}. 			 			Hence, \eqref{gkt-case1} becomes 			$$ 			\delta_x^{(s)} \left(1+ \Psi_{s'}\left(\anginf{v^{\l-e}x}\right)\right)^{-1} 			\prod_{j=1}^N \frac{1+\Psi_{s'+jd\l-d} \left(\anginf{v^{\l-e-1}x}\right)}{1+\Psi_{s'+jd\l} \left(\anginf{v^{\l-e}x}\right)}. 			$$ 			 			\item Case 2: 			$s_i \neq s'$ (which means $i \not\equiv \l-e \pmod{\l}$). 			Note that in this case, $d\leq s_i < d\l$. 			So similar to the second term in the previous case, when $a \in A_{+,s_i+jd\l}$, we have $v \mid \anginf{v^ix} + a$ if and only if $a \equiv x_{\l-i} \pmod{v}$. 			And in this case, $a = x_{\l-i} + va'$ for some $a' \in A_{+,s_i+jd\l-d}$ and $\anginf{v^ix} + a = v(\anginf{v^{\l+i-1}x} + a')$. 			So \eqref{gkt-eq1} corresponds to 			 				&\prod_{j=0}^N \prod_{a \in A_{+,s_i+jd\l}} \frac{a^\flat}{\left(\anginf{v^ix}+a\right)^\flat}   \\ 				={} &\prod_{j=0}^N \frac{ \prod_{a\in A_{+,s_i+jd\l}} a \Big/ \prod_{a\in A_{+,s_i+jd\l-d}} va }{ \prod_{a\in A_{+,s_i+jd\l}} \left(\anginf{v^ix}+a\right) \Big/ \prod_{a\in A_{+,s_i+jd\l-d}} v \left(\anginf{v^{\l+i-1}x} + a\right) }      \\ 				={} &\prod_{j=0}^N \frac{1+\Psi_{s_i+jd\l-d} \left(\anginf{v^{\l+i-1}x}\right)}{1+\Psi_{s_i+jd\l} \left(\anginf{v^ix}\right)}.    			 		 		 		Combining the results of these two cases, the right-hand side of \eqref{gkt-eq1} is seen to be 		 			\delta_x^{(s)} 			\lim_{N\to\infty} \left( \frac{1}{1+ \Psi_{s'} \left(\anginf{v^{\l-e}x}\right)} \prod_{j=1}^N \frac{1+\Psi_{s'+jd\l-d} \left(\anginf{v^{\l-e-1}x}\right)}{1+\Psi_{s'+jd\l} \left(\anginf{v^{\l-e}x}\right)} \right) 			\\ 			\left( \prod_{\substack{i=0 \\ i \not\equiv \l-e \bmod \l}}^{\l-1} \prod_{j=0}^N \frac{1+\Psi_{s_i+jd\l-d} \left(\anginf{v^{\l+i-1}x}\right)}{1+\Psi_{s_i+jd\l} \left(\anginf{v^ix}\right)} \right). 		 		A careful inspection shows that except for the term 		$$ 		\left(1+\Psi_{s_{\l-e-1}+Nd\l} \left(\anginf{v^{\l-e-1}x}\right) \right)^{-1} 		= \left(1+\Psi_{s+d(\l-e-1)+Nd\l} \left(\anginf{v^{\l-e-1}x}\right) \right)^{-1}, 		$$ 		the denominator of the former product will cancel out the numerator of the latter one. 		And it converges to 		 			&\lim_{N \to \infty} \left(1+\Psi_{s+d(\l-e-1)+Nd\l} \left(\anginf{v^{\l-e-1}x}\right) \right)^{-1}   \\ 			={} &\lim_{N \to \infty} \left( 1 - \sum_{i=1}^{d\l} (\lambda_i^*)^{q^{s+d(\l-e-1)+Nd\l}} C_{\mfk\anginf{v^{\l-e-1}x}}(\lambda_i) \right)^{-1}    \\ 			={} &\left( 1 - \sum_{i=1}^{d\l} \psi(\ovl{\lambda}{}^*_i)^{q^{s+d(\l-e-1)}} C_{\mfk\anginf{v^{\l-e-1}x}}(\lambda_i) \right)^{-1}   \\ 			={} &\left(\bggs_{v^{\l-e-1}x}\right)^{-\sigma_{1,s+d(\l-e-1)}} 			= (\bggs_x)^{-\sigma_{1,s}} 			= \ggs (x,y)^{-1} 		 		by applying Theorem \ref{restatement-of-abp-5.4.4}(1), \eqref{ari-teichmller}, Theorem \ref{coleman-function-and-gauss-sum}, Proposition \ref{galois-action}(2), and \eqref{product-of-ggs} sequentially. 		This completes the proof.",2502.01109
proof,"Note we may once again assume $\anginf{x} = x$. 		For each $0 \leq s <d$, by Definition \ref{v-adic-gamma-definition}(3) and Theorem \ref{first-gkt-formula}, one has 		 			\prod_{i=0}^{\l-1} \vgf \left( \anginf{v^ix}, \frac{q^s}{1-q^d} \right) 			&= \prod_{i=0}^{\l-1} \prod_{j=0}^{\l-1} \vgf \left( \anginf{v^ix}, -\ang{\frac{q^{s+dj+di}}{q^{d\l}-1}} \right)   \\ 			&= \prod_{j=0}^{\l-1} \delta_x^{(s,j)} \ggs \left(x, \frac{q^{s+dj}}{q^{d\l}-1}\right)^{-1}  		 		where $\delta_x^{(s,j)} = v\anginf{v^{\l-j-1}x}$ if $x_j \in A_{+,s}$ and $1$ otherwise. 		Now, we may reproduce the geometric gamma function in terms of the above equation. 		More precisely, one has 		     			&\prod_{i=0}^{\l-1} \vgf(\anginf{v^ix}) 			= \prod_{i=0}^{\l-1} \prod_{s=0}^{d-1} \vgf \left( \anginf{v^ix}, \frac{q^s}{1-q^d} \right)    \\ 			={} &\prod_{s=0}^{d-1}  \prod_{j=0}^{\l-1} \delta_x^{(s,j)} \ggs \left(x, \frac{q^{s+dj}}{q^{d\l}-1}\right)^{-1} 			= \left( \prod_{i=0}^{\l-1} \delta_{x,i} \right) \ggs (x)^{-1}.  \nonumber",2502.01109
proof,"We assume $\anginf{x} = x$ and $\ang{y} = y$. 		By Definition \ref{v-adic-gamma-definition}(3) and Theorem \ref{first-gkt-formula}, one sees that 		 			&\prod_{i=0}^{\l-1} \vgf \left( \anginf{v^ix}, -\ang{|v^i|_\infty y} \right) 			= \prod_{s=0}^{d\l-1} \prod_{i=0}^{\l-1} \vgf \left( \anginf{v^ix}, -\ang{\frac{q^{s+di}}{q^{d\l}-1}} \right)^{y_s}      \\ 			={} &\prod_{s=0}^{d\l-1} \left( \delta_x^{(s)} \ggs\left(x,\frac{q^s}{q^{d\l}-1}\right)^{-1} \right)^{y_s} 			= \left( \prod_{s=0}^{d\l-1} \left( \delta_x^{(s)} \right)^{y_s} \right) \ggs (x,y)^{-1} 		 		where $\delta_x^{(s)}$ is defined as in Theorem \ref{first-gkt-formula}: 		Let $0 \leq e \leq \l-1$ be the unique integer such that $ed \leq s < (e+1)d$ and $s' := s - ed$. 		Then $\delta_x^{(s)} := v \anginf{v^{\l-e-1}x}$ if $x_e \in A_{+,s'}$ and $1$ otherwise. 		 		For each $s$, we write $s = ed + r$ for some unique $0 \leq r \leq d-1$. 		Then $\delta_x^{(s)} = v \anginf{v^{\l-e-1}x}$ if $x_e \in A_{+,r}$ (in which case, $s = ed + \deg x_e$) and $1$ otherwise. 		Therefore, the delta part is seen to be 		$$ 		\prod_{s=0}^{d\l-1} \left( \delta_x^{(s)} \right)^{y_s} 		= \prod_{i=0}^{\l-1} \delta_{x,i}^{y_{di+\deg x_i}}. 		$$ 		So we get 		 			\prod_{i=0}^{\l-1} \vgf \left( \anginf{v^ix}, -\ang{|v^i|_\infty y} \right) 			&= \left( \prod_{i=0}^{\l-1} \delta_{x,i}^{y_{di+\deg x_i}} \right) 			\cdot 			\ggs (x,y)^{-1}. 		 		 		Using this, the reflection formula of $\vgf(\cdot,\cdot)$ \cite[Lemma 2.3]{thakur1991gamma}, and Gross-Koblitz-Thakur formula for the geometric case (Theorem \ref{gkt-formula-for-geometric-gamma-function}, but see \eqref{reflection-for-vgf}), we have 		 			&\prod_{i=0}^{\l-1} \vgg \left( \anginf{v^ix}, \ang{|v^i|_\infty y} \right)   \\ 			={} &\prod_{i=0}^{\l-1} \frac{1}{\anginf{v^ix}^\flat} \vgf\left(\anginf{v^ix}\right)^{q-1} 			\vgf \left( \anginf{v^ix}, -\ang{|v^i|_\infty y} \right)^{-1}       \\ 			={} &\left( \prod_{i=0}^{\l-1} \frac{\delta_{x,i}^{q-1-y_{di+\deg x_i}}}{\anginf{v^ix}^\flat} \right) 			\ggs (x)^{-(q-1)} \ggs(x,y).",2502.01109
proof,"The first assertion follows from Proposition \ref{galois-action}(1) and \eqref{product-of-ggs}. 		For the second, we may assume $\anginf{x} = x$ and write 		$$ 		x = \sum_{i=0}^{\l-1} \frac{x_i v^i}{v^\l-1} 		\quad 		(\deg x_i < d \text{ for all } i). 		$$ 		By Theorem \ref{gkt-formula-for-geometric-gamma-function} (but see \eqref{reflection-for-vgf}), we have 		      			\prod_{\epsilon \in \Fqst} \ggs (\epsilon x) 			= \prod_{\epsilon \in \Fqst} \left( \prod_{i=0}^{\l-1} \delta_{\epsilon x,i} \cdot  \prod_{i=0}^{\l-1} \vgf(\anginf{v^i \epsilon x})^{-1} \right) 		 		where $\delta_{\epsilon x,i} := v\anginf{v^{\l-i-1} \epsilon x}$ if $\epsilon x_i \in A_+$ and $1$ otherwise. 		Note the former case happens if and only if $x_i \neq 0$ and $\epsilon = \sgn( x_i)^{-1}$. 		So the delta part is 		$$ 		\prod_{\epsilon \in \Fqst} \prod_{i=0}^{\l-1} \delta_{\epsilon x,i} 		= \prod_{\substack{i=0 \\ x_i \neq 0}}^{\l-1} v \cdot \sgn(x_i)^{-1} \cdot \anginf{v^{\l-i-1}x}. 		$$ 		For the gamma (factorial) part, we apply the reflection formula of $\vgf(\cdot)$ \cite[Theorem 4.10.5]{thakur2004function} and see that 		$$ 		\prod_{\epsilon \in \Fqst} \prod_{i=0}^{\l-1} \vgf(\anginf{v^i \epsilon x}) 		= \prod_{\substack{i=0 \\ x_i \neq 0}}^{\l-1} \sgn(x_i)^{-1} \cdot \anginf{v^{\l-i}x}. 		$$ 		Combining these two with \eqref{gauss-sum-above-v-eq1}, we have 		    			\prod_{\epsilon \in \Fqst} \ggs(\epsilon x) 			= \prod_{\substack{i=0 \\ x_i \neq 0}}^{\l-1} v \cdot \frac{\anginf{v^{\l-i-1}x}}{\anginf{v^{\l-i}x}}. 		 		 		Now, we rewrite $x$ as 		$$ 		x = \frac{x_{i_1}v^{i_1} + \cdots + x_{i_n}v^{i_n}}{v^\l-1} 		$$ 		so that $x_{i_1},\ldots,x_{i_n}$ are all non-zero digits in the $v$-adic expansion of the numerator of $x$. 		Then \eqref{gauss-sum-above-v-eq2} becomes 		        			\prod_{\epsilon \in \Fqst} \ggs(\epsilon x) 			= v^n \prod_{j=1}^n \frac{\anginf{v^{\l-i_j-1}x}}{\anginf{v^{\l-i_j}x}}. 		 		In the last product, one sees that for $1\leq j \leq n-1$, the numerator of the $j$-th term cancels out the denominator of the $(j+1)$-st term, leaving $v^{i_{j+1}-i_j-1}$ in the numerator. 		And similarly, the numerator of the last term cancels out the denominator of the first term, leaving $v^{\l+i_1-i_n-1}$ also in the numerator. 		So \eqref{gauss-sum-above-v-eq3} becomes 		$$ 		\prod_{\epsilon \in \Fqst} \ggs(\epsilon x) 		= v^n \cdot v^{i_2-i_1-1} \cdot v^{i_3-i_2-1} \cdots v^{\l + i_1 - i_n - 1} 		= v^\l. 		$$ 		This completes the proof.",2502.01109
proof,Write $\ang{y} = \sum_{s=0}^{d\l-1} y_sq^s/(q^{d\l}-1)$ where $0\leq y_s < q$ for all $s$. 		Then the first assertion follows from \eqref{product-of-ggs} and the observation that $\ang{1-y} = \sum_{s=0}^{d\l-1} (q-1-y_s)q^s/(q^{d\l}-1)$. 		And the second follows from (1) and Theorem \ref{gauss-sum-lies-above-v}.,2502.01109
proof,"Choose any infinite place $\td{\infty}$ of $K$ above $\infty$. 		Let $K_{\td{\infty}}$ (resp. $k_\infty$) be the completion of $K$ at $\td{\infty}$ (resp. $k$ at $\infty$) with normalized valuation $\ord_{\td{\infty}} (\T) = -1$. 		The Galois group $\Gal(K_{\td{\infty}}/k_\infty)$ is isomorphic to $\Fqst \times \ZZ/d\l \ZZ$ (recall \ref{section-cyclotomic-function-fields}). 		So by Theorem \ref{gauss-sum-lies-above-v}, we have 		$$ 		\ord_{\td{\infty}} (\bggs_x) 		= \frac{1}{[K_{\td{\infty}} : k_\infty]} \ord_{\infty} \left( \Nr_{K_{\td{\infty}}/k_\infty} (\bggs_x) \right) 		=  \frac{1}{(q-1)d\l} \ord_{\infty}(v^\l) 		= -\frac{1}{q-1}. 		$$",2502.01109
proof,"It suffices to show the case $y = 1/(q^{df}-1)$. 		The general situation will follow by applying the group ring element $\sum_{s=0}^{df-1} y_s\tau_q^s$ to both sides (we put $y = \sum_{s=0}^{df-1} y_sq^s/(q^{df}-1)$ as always). 		Note we may also assume $x \in \nfk^{-1}A \setminus A$ because otherwise the result is trivial. 		Observe that for each $0 \leq i \leq \l-1$, we have 		$$ 		\left\{ \lranginf{v^i\left(\frac{x+\alpha}{g}\right)} \Biggm| \deg \alpha < \deg g \right\} 		= \left\{ \frac{\anginf{v^ix}+\alpha}{g} \Biggm| \deg \alpha < \deg g \right\} 		$$ 		and 		$$ 		\left\{ \lranginf{v^i \frac{\alpha}{g}} \biggm| \deg \alpha < \deg g \right\} 		= \left\{ \frac{\alpha}{g} \biggm| \deg \alpha < \deg g \right\}. 		$$ 		Using these, Theorems \ref{first-gkt-formula}, \ref{multiplication-formula}, and the translation formula of $\vgf(x,\cdot)$ (see the proof of \cite[Lemma 4.6.2]{thakur2004function}), we have up to explicit rational multiples (for $\kappa_1,\kappa_2 \in \CC_v$, we write $\kappa_1 \sim_k \kappa_2$ if $\kappa_1/\kappa_2 \in k^\times$), 		{2} 			& &&\prod_{\alpha} \ggsf\left( \frac{x+\alpha}{g},y \right) \bigg/ \ggsf\left( \frac{\alpha}{g},y \right) 			\sim_k \prod_{\alpha} \prod_{i=0}^{f-1} \frac{\vgf\left(\anginf{v^i \alpha/g},-|v^i|_\infty y\right)}{\vgf\left(\anginf{v^i(x+\alpha)/g},-|v^i|_\infty y\right)}    \\ 			&= &&\prod_{i=0}^{f-1} \prod_{\alpha} \frac{\vgf\left(\alpha/g,-|v^i|_\infty y\right)}{\vgf\left((\anginf{v^ix}+\alpha)/g,-|v^i|_\infty y\right)} 			\sim_k \prod_{i=0}^{f-1} \vgf\left(\anginf{v^ix},-|v^i|_\infty q^hy\right)^{-1}   \\ 			&\sim_k &&\prod_{i=0}^{f-1} \vgf\left(\anginf{v^ix}, -\ang{|v^i|_\infty q^hy}\right)^{-1} 			\sim_k \ggsf(x,q^hy). 		 		Thus, the result is proved up to some $\kappa \in k^\times$. 		 		Since the geometric Gauss sums lie above $v$ by Theorem \ref{gauss-sum-lies-above-v}, we see that $\kappa$ is up to an $\Fqst$-multiple, an integral power of $v$. 		Furthermore, note that $(x+\alpha)/g \notin A$ for all $\alpha$ and $\alpha/g \in A$ if and only if $\alpha=0$. 		Since $x \notin A$, by Proposition \ref{absolute-values} and Remark \ref{remark-of-absolute-values}, we see that the $\infty$-adic valuation of $\kappa$ is $0$. 		This shows that $\kappa \in \Fqst$ is a constant. 		Finally, from the explicit expression of $\kappa$, one sees that both of its denominator and numerator are monic polynomials. 		(Note that all the deltas coming from Theorem \ref{first-gkt-formula} have this property by the definition.) 		Hence, we conclude that $\kappa = 1$.",2502.01109
proof,"We define a function $g$ on $\ZZ_p$ by 		$$ 		g\left(1 + \sum_{i=0}^\infty y_iq^i\right) := \prod_{i=0}^{df-1} \left( (\bggs_x)^{\tau_q^i} \right)^{y_i} 		\text{ where } 		0 \leq y_i < q 		\text{ for all } 		i. 		$$ 		Then $g$ fits into the framework of \cite[Section 2]{thakur1991gamma}, and we have for all $y \in (q^{df}-1)^{-1}\ZZ$, 		$$ 		\ggsf(x,y) = g(1 - \ang{y}). 		$$ 		Now, observe that 		$$ 		\left\{ 1 - \frac{y+i}{n} \biggm| 0\leq i \leq n-1 \right\} 		= \left\{ \frac{(1-y)+i}{n} \biggm| 0\leq i \leq n-1 \right\}. 		$$ 		So by \cite[Lemma 2.4]{thakur1991gamma}, 		 			\prod_{i=0}^{n-1} \ggsf\left(x,\frac{y+i}{n}\right) 			&= \prod_{i=0}^{n-1} g\left(1-\frac{y+i}{n}\right) 			= \prod_{i=0}^{n-1} g\left(\frac{(1-y)+i}{n}\right)   \\ 			&= g(0)^{(n-1)/2} g(1-y) 			= \ggsf(x)^{(n-1)(q-1)/2} \ggsf(x,y).",2502.01109
proof,This follows immediately from \eqref{product-of-ggs} because $\bggs_x$ is fixed by $\tau_q^{d\l}$ and 		$$ 		\sum_{s=0}^{d\l-1} \frac{y_sq^s}{q^{d\l}-1} 		= \sum_{j=0}^{m-1} q^{jd\l} \cdot \frac{y_0 + y_1 q+ \cdots + y_{d\l-1} q^{d\l-1}}{q^{d\l'}-1}. 		$$,2502.01109
proof,"It suffices to show the case $a_0 = 1$. 		Put $\mfk := v^\l-1$ and write 		$$ 		\frac{1}{\nfk} = \frac{b_0}{\mfk}. 		$$ 		Fix any $a \in A_+$, $\deg a< \deg \nfk$ with $(a,\nfk) = 1$. 		From Theorem \ref{first-gkt-formula}, we take 		$$ 		x 		= \frac{a}{\nfk} 		= \frac{ab_0}{\mfk} 		:= \sum_{i=0}^{e} \frac{x_i v^i}{v^\l-1} 		\quad 		\text{and} 		\quad 		y = \frac{q^{\deg ab_0}}{q^{d\l}-1} 		$$ 		where $0 \leq e \leq \l-1$, $x_e \in A_+$, and $\deg x_i < d$ for all $i$. 		Then we have 		     			\ggs (x,y) 			= \left(\bggs_{ab_0/\mfk}\right)^{\sigma_{1,\deg ab_0}} 			= v\anginf{v^{\l-e-1}x} \cdot 			\prod_{i=0}^{\l-1} \vgf \left( \anginf{v^ix}, -\ang{|v^i|_\infty y} \right)^{-1}. 		 		By Proposition \ref{galois-action}(1), 		$$ 		\left(\bggs_{ab_0/\mfk}\right)^{\sigma_{1,\deg ab_0}} 		= \left(\bggs_{1/\nfk}\right)^{\sigma_{a,\deg ab_0}}. 		$$ 		On the other hand, one sees that 		$$ 		v\anginf{v^{\l-e-1}x} 		= v \cdot v^{\l-e-1} x 		= v^{\l-e} \frac{ab_0}{\mfk}. 		$$ 		So \eqref{stickelberger-apply-gkt-formula} becomes 		$$ 		\left(\bggs_{1/\nfk}\right)^{\sigma_{a,\deg ab_0}} 		= v^{\l-e} \frac{ab_0}{\mfk} \cdot \prod_{i=0}^{\l-1} \vgf \left( \anginf{v^ix}, -\ang{|v^i|_\infty y} \right)^{-1}. 		$$ 		From here we take the $\Pfk_{\nfk,d\l}$-adic valuations to both sides, using the fact that $\vgf(\cdot , \cdot)$ is a unit in $A_v$, we get 		$$ 		\ord_{\Pfk_{\nfk,d\l}} \left( \left(\bggs_{1/\nfk}\right)^{\sigma_{a,\deg ab_0}} \right) 		= \ord_{\Pfk_{\nfk,d\l}} \left( v^{\l-e} \frac{ab_0}{\mfk} \right) 		= \l - e + \ord_v(ab_0). 		$$ 		 		We will claim that this quantity is exactly the number of elements of the form $\sigma_{b,\deg b}$ in the coset $\sigma_{a,\deg a}D$ (the decomposition group of $v$ in $K_{\nfk,d\l}$) of $\Gal(K_{\nfk,d\l}/k)$, where $b \in A_+$, $\deg b< \deg \nfk$ and $(b,\nfk) = 1$. 		Assuming this for a moment, then since every such $\sigma_{b,\deg b}$ results in the same prime as $\sigma_{a,\deg a}$ does after applying to $\Pfk_{\nfk,d\l}$, and since this holds for each $a \in A_+$, $\deg a< \deg \nfk$ with $(a,\nfk) = 1$, we obtain 		       			\Pfk_{\nfk,d\l}^{\sigma_{1,\deg b_0}^{-1} \eta_{\nfk,d\l}} 			\Bigm|  			\bggs_{1/\nfk} \cdot\Ocal_{\nfk,d\l}. 		 		Now, applying both sides by $\sum_{\epsilon \in\Fqst} \sum_{s=0}^{d\l-1} \sigma_{\epsilon,s}$ and using Theorem \ref{gauss-sum-lies-above-v}, we have 		$$ 		\left( \Pfk_{\nfk,d\l}^{\sigma_{1,\deg b_0}^{-1} \eta_{\nfk,d\l}} \right)^{\sum_{\epsilon \in\Fqst} \sum_{s=0}^{d\l-1} \sigma_{\epsilon,s}}  		\Biggm| 		\left(\bggs_{1/\nfk}\right)^{\sum_{\epsilon \in\Fqst} \sum_{s=0}^{d\l-1} \sigma_{\epsilon,s}} \cdot\Ocal_{\nfk,d\l} 		= v^\l \cdot\Ocal_{\nfk,d\l}. 		$$ 		Since both sides consist of the same amount of primes (counting multiplicity) in $K_{\nfk,d\l}$ (recall Remark \ref{fixed-field} that $v$ splits into $[K_{\nfk}:k]d$ primes in $K_{\nfk,d\l}$), we see in fact they are identical. 		This means \eqref{divisors-of-geometric-gauss-sum} actually gives the equality 		$$ 		\bggs_{1/\nfk} \cdot\Ocal_{\nfk,d\l} 		= \Pfk_{\nfk,d\l}^{\sigma_{1,\deg b_0}^{-1} \eta_{\nfk,d\l}}, 		$$ 		as any other prime divisors will violate the factorization of $v^\l$. 		And this is what we want. 		(Note $\deg b_0 = \deg \mfk - \deg \nfk = d\l - \deg\nfk$.) 		 		It remains to prove the claim. 		In fact, we prove a stronger result that for any $a \in A_+$ with $\deg a < \deg \mfk$, if 		$$ 		a = a_rv^r + \cdots + a_ev^e 		\quad 		(0 \leq r \leq e \leq \l-1), 		$$ 		with $r = \ord_v(a)$, $\deg a_i < d$ for all $i$, $a_e \in A_+$, then the number of $b \in A_+$, $\deg b< \deg \mfk$ satisfying 		      			b \equiv av^i \Mod{\mfk} 			\text{ and } 			\deg b \equiv \deg a + di \Mod{d\l} 			\text{ for some } 			0 \leq i \leq \l-1 		 		is precisely $\l - e + r$. 		We split $i$ into three cases: 		 			\item Case 1: $0 \leq i \leq \l-e-1$. 			Then automatically $b := av^i$ satisfies \eqref{condition-on-b}. 			 			\item Case 2: $\l-e \leq i \leq \l-r-1$. 			Say $i = \l-e+j$ for some $j = 0,\ldots,e-r-1$. 			Note 			$$ 			av^i = a_rv^{r+i} + \cdots + a_ev^{e+i} 			\equiv \cdots + a_rv^{r+i} + \cdots + a_{\l-1-i}v^{\l-1}  			=: b \pmod{\mfk}. 			$$ 			And $\deg a + di \equiv \deg a_e + dj \pmod{d\l}$. 			As $a_r \neq 0$, we have 			$$ 			d\l 			> 			\deg b  			\geq \deg a_r + d(r + i) 			\geq \deg a_r + d(1 + j) 			> \deg a_e + dj. 			$$ 			So \eqref{condition-on-b} must not hold. 			 			\item Case 3: $\l-r \leq i \leq \l-1$. 			Note 			$$ 			av^i = a_rv^{r+i} + \cdots + a_ev^{e+i} 			\equiv a_rv^{r+i-\l} + \cdots + a_ev^{e+i-\l}  			=: b \pmod{\mfk}, 			$$ 			which can be seen to satisfy \eqref{condition-on-b}. 		 		In conclusion, those $b$ satisfying \eqref{condition-on-b} are precisely in Cases 1 and 3, giving $\l-e+r$ elements in total. 		This completes the claim. 		 		Finally, to apply the claim to our situation, observe that there is a bijection from 		$$ 		\{b \mid b\in A_+, \deg b < \deg \nfk, b \equiv av^i \Mod{\nfk}, \deg b \equiv \deg a + di \Mod{d\l}\} 		$$ 		to 		$$ 		\{b \mid b\in A_+, \deg b < \deg \mfk, b \equiv ab_0v^i \Mod{\mfk}, \deg b \equiv \deg ab_0 + di \Mod{d\l}\} 		$$ 		sending $b$ to $bb_0$.",2502.01109
proof,"The second assertion follows from the functional equation and the fact that $\ker e^* = A$.  		And the containment is due to Theorem \ref{goss-1.7.11}.  		So we turn to verify the functional equation.  		As $C^*$ is an $\Fq$-algebra homomorphism on $A$, it's sufficient to check for the case $\nfk = \T$. 		From $\Omega^{(-1)}(t) = \sum c_it^i$ and the functional equation $(t-\T)\Omega = \Omega^{(-1)}$, we have 		$$ 		(t-\T) \sum c_i^q t^i = \sum c_i t^i. 		$$ 		By comparing the coefficients of $t^i$, it follows that 		$$ 		\T c_i^q + c_i =  		 			c_{i-1}^q, & \text{if } i>0, \\ 			0, & \text{if } i=0. 		 		$$ 		Thus, 		$$ 		C_\T^*(e^*(z)^q) 		= \T e^*(z)^q +  e^*(z) 		= \sum_{i=0}^\infty \Res(\T^iz)^q (\T c_i^q+c_i) 		= \sum_{i=1}^\infty \Res(\T^iz)^q c_{i-1}^q 		=  e^*(\T z)^q. 		$$",2502.01109
proof,"We start with noticing that 		$$ 		\Delta^q  		= \left(\det_{1 \leq i,j \leq d} \lambda_j^{q^{i-1}}\right)^q 		= \det_{1 \leq i,j \leq d} \lambda_j^{q^i} 		\equiv (-1)^{d-1} \Delta \pmod{\Pfk} 		$$ 		where the power of $-1$ comes from moving the last row to the first. 		On the one hand, this implies (note $\Delta \not\equiv 0 \pmod{\Pfk}$ as $\{\ovl{\lambda}_1,\ldots,\ovl{\lambda}_d\}$ is still an $\Fq$-basis of $\FF_{\Pfk}$) 		$$ 		\lambda_i^*  		= (-1)^{d+i} \left(\frac{\Delta_i}{\Delta}\right)^q 		\equiv (-1)^{i-1} \frac{\Delta_i^q}{\Delta}   \pmod{\Pfk}, 		$$ 		and on the other, we have by induction that for any $k\in\NN$, 		$$ 		\Delta^{q^k} \equiv (-1)^{k(d-1)} \Delta \pmod{\Pfk}. 		$$ 		These two imply 		        			\sum_{k=0}^{d-1} (\lambda_i^* \lambda_j)^{q^k} 			\equiv \sum_{k=0}^{d-1} \left( (-1)^{i-1} \frac{\Delta_i^q}{\Delta} \lambda_j \right)^{q^k} 			\equiv \frac{1}{\Delta} \sum_{k=0}^{d-1} (-1)^{(i-1)+k(d-1)} (\Delta_i^q \lambda_j)^{q^k} 			\pmod{\Pfk}. 		 		 		Consider the matrices 		$$ 		\Mcal \equiv \left( \lambda_j^{q^{i-1}}  \right), 		\quad   		\Zcal \equiv (z_{ij}) 		\pmod{\Pfk} 		$$ 		and the system of linear equations 		     			\Mcal \cdot \Zcal \equiv I_d   \pmod{\Pfk}. 		 		Let $\{e_1,\ldots,e_d\}$ be the standard ordered basis of $\FF_\Pfk$ over $\Fq$. Then by Cramer's rule, we have 		$$ 		z_{ij} \equiv \frac{\det \Mcal_i'}{\Delta}  \pmod{\Pfk} 		$$ 		where $\Mcal_i'$ is obtained by replacing the $i$-th column of $\Mcal$ with $e_j$. And by applying the cofactor expansion to $\Mcal_i'$ along the $i$-th column and exchanging rows, one sees that 		       			z_{ij}  			\equiv \frac{\det \Mcal_i'}{\Delta}   			\equiv (-1)^{(i+j)+(j-1)(d-j)} \frac{\Delta_i^{q^j}}{\Delta} 			\pmod{\Pfk}. 		 		Now, by exchanging the product of matrices 		$$ 		\Zcal \cdot \Mcal \equiv I_d  \pmod{\Pfk}, 		$$ 		we have 		 			\delta_{ij}  			&\equiv \sum_{k=1}^d z_{ik} \lambda_j^{q^{k-1}} 			\overset{\eqref{zij}}{\equiv} \sum_{k=1}^d (-1)^{(i+k)+(k-1)(d-k)} \frac{\Delta_i^{q^k}}{\Delta} \lambda_j^{q^{k-1}}    \\ 			&= \frac{1}{\Delta} \sum_{k=0}^{d-1} (-1)^{(i-1)+k(d-1)} (\Delta_i^q \lambda_j)^{q^k} 			\overset{\eqref{trace-of-lambda*-and-lambda}}{\equiv} \sum_{k=0}^{d-1} (\lambda_i^* \lambda_j)^{q^k}  \pmod{\Pfk}. 		 		And this is what we want.",2502.01109
proof,"As $\{\alpha' a_i\}_{i=1}^d, \{\alpha b_j\}_{j=1}^d$ is also a pair of $\nfk$-dual families, we may assume without loss of generality that $\alpha = 1$. 		Let $\lambda_i^* := e^*(a_i/\nfk)^q$ and $\lambda_j := e(b_j/\nfk)$. We will show that 		     			\left( \lambda_j^{q^{i-1}} \right) 			\left( (\lambda_i^*)^{q^{j-1}} \right) 			\equiv I_d  \pmod{\Pfk}. 		 		Assuming this for a moment, then we have 		$$ 		\left( (\lambda_i^*)^{q^{j-1}} \right) 		\left( \lambda_j^{q^{i-1}} \right) 		\equiv I_d  \pmod{\Pfk}. 		$$ 		So the $(i,j)$-entry is 		$$ 		\delta_{ij} 		\equiv \sum_{k=1}^d (\lambda_i^*)^{q^{k-1}} \lambda_j^{q^{k-1}} 		= \left( \sum_{k=1}^d \lambda_i^* \lambda_j \right)^{q^{k-1}} 		\pmod{\Pfk}. 		$$ 		And this is what we want. 		(Note that \eqref{claim-in-residue-and-trace} is exactly the system of linear equations \eqref{linear-equations-MZ-I} considered in the proof of Proposition \ref{lambdai*-and-trace-pairing}. 		This already suggests that $e^*(a_i/\nfk)^q$ can be obtained from Ore's formula. 		Note that the trick of exchanging the product of two matrices was also used during that proof.) 		 		It remains to prove the claim. 		Note that the $(i,j)$-entry in the product of \eqref{claim-in-residue-and-trace} is 		     			\sum_{k=1}^d \lambda_k^{q^{i-1}} (\lambda_k^*)^{q^{j-1}}  \pmod{\Pfk}. 		 		And we have by Theorem \ref{original-abp-5.4.4}(1), 		      			\sum_{k=1}^d (\lambda_k^*)^{q^N} \lambda_k 			= -\Psi_N(1/\nfk) 			= 1 - \prod_{a\in A_{+,N}} \left(1+\frac{1}{\nfk a}\right) 			= 1 - \prod_{a\in A_{+,N}} \frac{\nfk a+1}{\nfk a}. 		 		for all integers $N \geq 0$. 		We split $i$ and $j$ into three cases: 		 		 			\item Case 1: $i=j$. 			Then 			$$ 			\eqref{ij-entry} 			= \left( \sum_{k=1}^d \lambda_k \cdot 	\lambda_k^* \right)^{q^{i-1}}        			\overset{\eqref{note-lambda-and-lambda*}}{=} \left( -\frac{1}{v-1} \right)^{q^{i-1}}     			\equiv 1 \pmod{\Pfk}. 			$$ 			 			\item Case 2: $i<j$. 			We see that 			$$ 			\eqref{ij-entry} 			= \left( \sum_{k=1}^d \lambda_k (\lambda_k^*)^{q^{j-i}} \right)^{q^{i-1}}       			\overset{\eqref{note-lambda-and-lambda*}}{=} \left( 1 - \prod_{a\in A_{+,j-i}} \frac{\nfk a+1}{\nfk a} \right)^{q^{i-1}}. 			$$ 			We check that the product is congruent to $1$ modulo $\Pfk$. 			For the numerator, note that $\nfk a+1 = v a-a+1$. 			So $v \mid \nfk a+1$ if and only if $v \mid -a+1$, which is impossible as $1 \leq \deg(-a+1) = j-i \leq d-1$. 			Similar for the denominator, note that $\nfk a = v a-a$. 			So $v \mid \nfk a$ if and only if $v \mid -a$, which is also impossible for the same reason. 			These two imply that 			$$ 			\prod_{a\in A_{+,j-i}} \frac{\nfk a+1}{\nfk a} 			\equiv \prod_{a\in A_{+,j-i}} \frac{-a+1}{-a} = 1 \pmod{\Pfk}. 			$$ 			 			\item Case 3: $i>j$. 			We see that 			$$ 			\eqref{ij-entry} 			= \left( \sum_{k=1}^d \lambda_k 			(\lambda_k^*)^{q^{d+j-i}} \right)^{q^{i-1}} 			\overset{\eqref{note-lambda-and-lambda*}}{=} \left( 1 - \prod_{a\in A_{+,d+j-i}} \frac{\nfk a+1}{\nfk a} \right)^{q^{i-1}} 			\equiv 0 \pmod{\Pfk} 			$$ 			by a similar argument as in Case 2. 			We omit the details.",2502.01109
proof,"Fix $1\leq i \leq \deg\nfk$. As $a_i := \lambda_i^*$ satisfies $C_\nfk^*(z)$, we have $a_i^{(1-q)/q} \tau^0 - \tau$ left divides $C_\nfk(z)$ (see \cite[Corollary 1.7.7]{goss1996basic}). 		So we may write 		$$ 		C_\nfk(\tau) = \left(a_i^{(1-q)/q} \tau^0 - \tau\right) Q_i(\tau) 		$$ 		for some $Q_i(\tau) \in \ovl{k}\{\tau\}$. 		Note that 		    			a_i\tau^0 C_\nfk(\tau) 			= a_i\tau^0 \left(a_i^{(1-q)/q} \tau^0 - \tau\right) Q_i(\tau) 			= (\tau^0-\tau) a_i^{1/q} Q_i(\tau). 		 		So by Definition \ref{definition-of-poonen-pairing}, we have 		$$ 		-\delta_{ij} 		= \ang{a_i, \lambda_j}_{\textnormal{Poon}(\nfk)} 		= a_i^{1/q} Q_i(\lambda_j) 		\quad 		\text{for all} 		\quad 		1 \leq j \leq \deg\nfk. 		$$ 		In particular, $Q_i(\lambda_j) = 0$ for all $j\neq i$. 		So the subspace $W_i \sbe \Lambda_\nfk$ of roots of $Q_i(z) = 0$ is spanned by $\{\lambda_1,\ldots,\lambda_{i-1},\lambda_{i+1},\ldots,\lambda_{\deg\nfk}\}$. 		The leading coefficient of $Q_i(z)$ is seen to be $-1$ from \eqref{apply-poonen-pairing}.  		Thus, we may write 		$$ 		Q_i(z) = - \prod_{\lambda \in W_i} (z - \lambda) =: -P_i(z). 		$$ 		Also, note that 		$$ 		-1  		= \ang{a_i, \lambda_i}_{\textnormal{Poon}(\nfk)} 		= a_i^{1/q} Q_i(\lambda_i) 		= -a_i^{1/q} P_i(\lambda_i) 		\implies 		a_i = P_i(\lambda_i)^{-q}. 		$$ 		A property of the Moore determinant (see \cite[Theorem 1.3.5.2]{goss1996basic}) now implies that 		$$ 		\lambda_i^*  		= a_i 		= P_i(\lambda_i)^{-q} 		= \left(\frac{\Delta(\lambda_1,\ldots,\lambda_{i-1},\lambda_{i+1},\ldots,\lambda_{\deg\nfk})}{\Delta(\lambda_1,\ldots,\lambda_{i-1},\lambda_{i+1},\ldots,\lambda_{\deg\nfk},\lambda_i)}\right)^q 		= (-1)^{\deg\nfk+i} \left(\frac{\Delta_i}{\Delta}\right)^q. 		$$ 		This completes the proof.",2502.01109
proof,"As $\{\alpha' a_i\}_{i=1}^{\deg\nfk}, \{\alpha b_j\}_{j=1}^{\deg\nfk}$ is also a pair of $\nfk$-dual families, we may assume without loss of generality that $\alpha = 1$. 		First, we consider the special case $\nfk = v - 1$ where $v \in A_{+,d}$ is irreducible. 		Let $\Pfk$ be a prime in $K_\nfk$ above $v$. 		In the definition of Poonen pairing, one considers everything modulo $\Pfk$ in the residue field $\FF_\Pfk$ and defines the reduction of Poonen pairing. 		More precisely, put (recall Propositions \ref{reduction-of-lambda} and \ref{reduction-of-lambda*}) 		$$ 		\ovl{\Lambda}_\nfk := \{ \ovl{\lambda} \mid \lambda \in \Lambda_\nfk \} 		\quad 		\text{and} 		\quad 		\ovl{\Lambda}{}^*_\nfk := \{ \ovl{\lambda}{}^* \mid \lambda^* \in \Lambda_\nfk^* \}. 		$$ 		For $\ovl{a} \in \ovl{\Lambda}{}^*_\nfk$ and $\ovl{b} \in \ovl{\Lambda}_\nfk$, write 		$$ 		\ovl{a} \tau^0 \ovl{C}_\nfk(\tau) = (\tau^0 - \tau) \ovl{h}_{\ovl{a}}(\tau) 		$$ 		where $\ovl{C}_\nfk(\tau)$ is the twisted polynomial obtained from reducing the coefficients of $C_\nfk(\tau)$ modulo $v$. 		Then the reduced Poonen pairing (with respect to $\nfk = v-1$) is defined as 		$$ 		\ang{\cdot,\cdot}_{\ovl{\textnormal{Poon}}(\nfk)}: \ovl{\Lambda}{}^*_\nfk \times \ovl{\Lambda}_\nfk \to \Fq, 		\quad  		\ang{\ovl{a},\ovl{b}}_{\ovl{\textnormal{Poon}}(\nfk)} 		:= \text{the unique lift of } 		\ovl{h}_{\ovl{a}} (\ovl{b}) \sbe \FF_{\Pfk} 		\text{ to } 		\Fq. 		$$ 		 		Note that 		$$ 		\ovl{h}_{\ovl{a}} (\ovl{b}) 		= \ovl{h_a(b)} 		= \ovl{\ang{a,b}_{\textnormal{Poon}(\nfk)}}. 		$$ 		So in fact, 		     			\ang{\ovl{a},\ovl{b}}_{\ovl{\textnormal{Poon}}(\nfk)} 			= \ang{a,b}_{\textnormal{Poon}(\nfk)}. 		 		On the other hand, as $\nfk = v-1$, we know $\ovl{C}_\nfk (\tau) = \tau^d - \tau^0$. 		This implies that 		$$ 		\ovl{h}_{\ovl{a}} (\tau) = -(\tau^0 + \tau^1 + \cdots + \tau^{d-1}) \ovl{a}\tau^0 		\implies 		\ovl{h}_{\ovl{a}} (\ovl{b}) 		= -\sum_{k=0}^{d-1} (\ovl{ab})^{q^k}. 		$$ 		Thus, using the trace pairing considered in \ref{section-residue-pairing-and-trace-pairing}, we have 		        			\ang{\ovl{a},\ovl{b}}_{\ovl{\textnormal{Poon}}(\nfk)} 			= -\angtr{\ovl{a},\ovl{b}}. 		 		Hence, by Proposition \ref{residue-and-trace}, \eqref{reduced-poonen-and-trace}, and \eqref{reduced-poonen-and-poonen}, we have 		$$ 		\delta_{ij} 		= \angtr{\ovl{e^*(a_i/\nfk)^q},\ovl{e(b_j/\nfk)}} 		= -\ang{e^*(a_i/\nfk)^q,e(b_j/\nfk)}_{\textnormal{Poon}(\nfk)}. 		$$ 		This completes the case where $\nfk = v-1$. 		 		For general $\nfk$, we apply the Dirichlet density theorem (see \cite[Chapter 4]{rosen2002number}) to take an irreducible $v \in A_+$ such that $v \equiv 1 \pmod{\nfk}$. 		Write $\nfk\mfk = v - 1 =: \nfk'$ for some $\mfk \in A_+$. 		Note that for the pair $\{a_i\mfk\}_{i=1}^{\deg\nfk}, \{b_j\}_{j=1}^{\deg\nfk}$, we have 		$$ 		\Res(a_i\mfk \cdot b_j / \nfk') = \Res(a_ib_j/\nfk) = \delta_{ij}. 		$$ 		So we may extend it to a pair of $\nfk'$-dual families $\{a_i'\}_{i=1}^{\deg\nfk'}, \{b_j'\}_{j=1}^{\deg\nfk'}$ so that 		$$ 		a_i' = a_i\mfk 		\quad 		\text{and} 		\quad 		b_j' = b_j 		\quad 		\text{for all} 		\quad 		1\leq i,j \leq \deg\nfk. 		$$ 		Then for any such $i,j$, we have by the previous case and Proposition \ref{compatibility-of-poonen-pairing-with-respect-to-different-nfk} that 		 			-\delta_{ij} 			&= \ang{e^*(a_i'/\nfk')^q,e(b_j'/\nfk')}_{\textnormal{Poon}(\nfk')} 			= \ang{e^*(a_i/\nfk)^q,e(b_j'/\nfk')}_{\textnormal{Poon}(\nfk\mfk)}    \\ 			&= \ang{e^*(a_i/\nfk)^q,C_\mfk(e(b_j'/\nfk'))}_{\textnormal{Poon}(\nfk)} 			= \ang{e^*(a_i/\nfk)^q, e(b_j/\nfk)}_{\textnormal{Poon}(\nfk)}. 		 		This proves the general case.",2502.01109
proof,"Let $\Sigma$ be the summation in Definition \ref{ggs-definition}, so that $\bggs_x = 1 + \Sigma$. 		Note by Proposition \ref{absolute-values} and the non-Archimedean property, we have $\ord_{\td{\infty}}(\bggs_x) = \ord_{\td{\infty}} (\Sigma) = -1/(q-1)$. 		Thus, it's sufficient to determine the sign of $\Sigma$. 		 		Write $x = a_0/\mfk$ with $\deg a_0 < d\l$. 		Since every element in $\FF_{\Pfk}^\times$ is represented by $e(a/\mfk) \in \Lambda_{\mfk}$ for some unique $0 \neq a \in A/\mfk$, we have 		$$ 		\Sigma 		= \sum_{z \in \FF_{\Pfk}^\times} \omega\left(C_{\mfk x} (z^{-1})\right)\psi(z) 		= \sum_{0 \neq a \in A/\mfk} e(a_0a/\mfk) \psi\left( \ovl{e(a/\mfk)}^{-1} \right). 		$$ 		For each such $a$, we let $a'$ be the unique element in $A$ such that $a' \equiv a_0a \pmod{\mfk}$ and $\deg a' < d\l$. 		Then from the infinite product expression 		$$ 		e(z) = \td{\pi}z \prod_{0 \neq a \in A} \left( 1+\frac{z}{a} \right), 		$$ 		we see that 		 			&e(a_0a/\mfk) = e(a'/\mfk) \text{ has minimal valuation}   \\ 			\iff{} &\ord_{\infty}(a'/\mfk) = d\l - \deg a' \text{ is minimal}   \\ 			\iff{} &\deg a' = d\l-1     \\ 			\iff{} &\Res(a'/\mfk) = \Res(a_0a/\mfk)\neq 0. 		 		And in this case, $\sgn(e(a_0a/\mfk)) = \epsilon \Res(a_0a/\mfk)$ where $\epsilon := \sgn(\td{\pi})$. 		Thus, we have 		$$ 		\sgn(\Sigma) 		= \epsilon \sum_{0 \neq a \in A/\mfk} \Res(a_0a/\mfk) \psi\left( \ovl{e(a/\mfk)}^{-1} \right). 		$$ 		Put $\lambda_a := e(a/\mfk)$ and $\lambda_{a_0}^* := e^*(a_0/\mfk)^q$. 		Then by the compatibility of the residue pairing and the trace pairing (Theorem \ref{pairing-summary}), this implies that 		 			\sgn(\Sigma) 			&= \epsilon \sum_{0 \neq a \in A/\mfk} \Tr_{\FF_\Pfk/\Fq} (\ovl{\lambda}{}^*_{a_0} \ovl{\lambda}_a) \psi \left( \ovl{\lambda}_a^{-1} \right)   \\ 			&= \epsilon \sum_{0 \neq b \in A/\mfk} \Tr_{\FF_\Pfk/\Fq}(\ovl{\lambda}_b) \psi\left( \ovl{\lambda}{}^*_{a_0} \ovl{\lambda}_b^{-1} \right) 			= \epsilon \psi\left( \ovl{\lambda}{}^*_{a_0} \right) \sum_{z \in \FF_{\Pfk}^\times} \Tr_{\FF_\Pfk/\Fq}(z) \psi(z^{-1}). 		 		By Lemma \ref{descending-ggs}, the last sum is seen to be $-1$. 		This completes the proof.",2502.01109
theorem,"Let $p \in [2,\infty]$.  Then $\beta^*_n(\ell_p) = O(\log^{1-1/p}{n})$.  That is, for every $n$-point metric $X\subset \ell_{p}$ and $\Delta > 0$, there exists an $(O(\log^{1-1/p}{n}), \Delta)$-Lipschitz decomposition of $X$.",2502.01120
theorem,"Let \( p \in [2, \infty) \) and \( t \geq 1 \). Then every \( n \)-point metric \( X \subset \ell_{p} \) admits an \( O(t) \)-spanner of size \( \tO\left(n^{1 + 1/t^{q}}\right) \) and lightness \( \tO\left(n^{1/t^{q}}\right) \), where \( q \in (1, 2) \) is such that \( \frac{1}{p} + \frac{1}{q} = 1 \).",2502.01120
theorem,"Let \( p \in (1, 2] \) and \( t \geq 1 \). Then every \( n \)-point metric \( X \subset \ell_{p} \) admits an \( O(t) \)-spanner of size \( \tO(n^{1 + 1/t^{p}}) \) and lightness \( \tO(n^{1/t^{p}}) \).",2502.01120
theorem,"Let \( p \in (2, \infty) \). Then the family of \( n \)-point metrics in \( \ell_{p} \) with pairwise distances in the range $[1,\Delta_{\text{max}}]$ admits a distance labeling scheme with approximation $O(\log^{1/q}{n})$ and label size $O(\log{n}\log{\Delta_{\text{max}}})$ bits, where \( q \in (1, 2) \) is such that \( \frac{1}{p} + \frac{1}{q} = 1 \).",2502.01120
theorem,"[\cite{Bartal96}]  Every $n$-point metric \((X, \rho)\) admits an \(\left(O\left(\log n\right), \Delta\right)\)-Lipschitz decomposition for every \(\Delta > 0\).",2502.01120
theorem,"[\cite{benyamini1998geometric,BG19}] Let $1\leq{q}<p<\infty$ and $C_0>0$, % and let $M$ be the Mazur map $M_{p,q}$ scaled down by factor $\frac{p}{q}{C_0}^{p/q-1}$. Then for all $x,y\in\ell_{p}$ such that $||x||_p,||y||_p\leq C_0$, \[   \tfrac{q}{p} (2 C_0 )^{1 - p/q} ||x - y||_{p}^{p/q}   \leq ||M(x) - M(y)||_{q}   \leq ||x - y||_{p} . \]",2502.01120
theorem,"Let \( p \in (2,\infty) \). Then every $n$-point metric in \( \ell_{p} \) admits a \( (t, n^{-O(1/t^q)}) \)-capped decomposition for all $t \geq 1$, where $q \in (1,2)$ is such that $\frac{1}{p}+\frac{1}{q}=1$.",2502.01120
theorem,"[\cite{FN22}]  Let \( (X, \rho) \) be an \( n \)-point metric space admitting a \( (t, \eta) \)-capped decomposition for some $t \geq 1$. Then, for every \( \epsilon \in (0, 1/8) \), there exists a \( (2+\epsilon)t \)-spanner for \( X \) with \( O_{\epsilon} (\frac{n}{\eta} \cdot \log n \cdot \log t ) \) edges and lightness \( O_{\epsilon} (\frac{t}{\eta} \cdot \log^2 n ) \).",2502.01120
theorem,"For every fixed $p\in(1,2)$, every $n$-point metric $X\subset \ell_{p}$ admits an $O(\log^{1/p}{n})$-spanner of size $\Tilde{O}(n)$.",2502.01120
theorem,"[\cite{BG16}]   Let \( 1 \leq p \leq 2 \). For every \( n \)-point set \( S \subset \ell_{p} \), and for every range parameter \( R > 1 \), there exists an \( R \)-range preserving embedding \( f : S \rightarrow \ell_{p}^{k} \) with distortion \( 1 + \epsilon \), such that $k = O\left(\frac{R^{O(1/\epsilon)} \cdot \log n}{\epsilon}\right)$.",2502.01120
theorem,"[\cite{GKL03}]  Let $\cX$ be a family of $n$-point metrics,  and assume that all the pairwise distances in all metrics $(X,\rho)$ in $\cX$ are in the range $[1,\Delta_{\text{max}}]$. Then $\cX$ admits a distance-labeling scheme with approximation $O(\beta^*(\cX))$ and label size $O(\log n \log\Delta_{\max})$ bits.",2502.01120
definition,"[Lipschitz decomposition \cite{Bartal96}]  Let $(X, \rho)$ be a metric space. A distribution $\mathcal{D}$ over partitions of $X$ is called \emph{$(\beta, \Delta)$-Lipschitz} if   \compactify \item for every partition $P \in \supp(\mathcal{D})$, all clusters $C \in P$   satisfy $\diam(C) \leq \Delta$; and  \item for all $x, y \in X$,   \[     \Pr_{P \in \mathcal{D}} [P(x) \neq P(y)]     \leq \beta\cdot \tfrac{\rho(x, y)}{\Delta} ,   \]   where $P(z)$ denotes the cluster of $P$ containing $z \in X$   and $\diam(C) := \sup_{x,y\in C} \rho(x,y)$.",2502.01120
definition,"Let $(X, \rho)$ be a metric space.  A distribution $\mathcal{D}$ over partitions of $X$  is called \emph{$(t, \Delta, \eta)$-capped} if  \compactify     \item for every partition $P \in \supp(\mathcal{D})$, all clusters $C \in P$ have $\diam(C) \leq \Delta$; and     \item for every $x, y \in X$ such that \( \rho(x, y) \leq \frac{\Delta}{t} \),     \[     \Pr_{P\in\mathcal{D}}[P(x) = P(y)] \geq \eta.     \]",2502.01120
definition,"[\cite{OR02}] Let \( (X, \rho) \), \( (Y, \tau) \) be metric spaces and \([a, b]\) be a real interval. An embedding \( f : X \rightarrow Y \) is called \emph{\([a, b]\)-range preserving with distortion $D \ge 1$ } if there exists \( c > 0 \) such that for all \( x, x' \in X \):  \compactify     \item If \( a \leq \rho(x, x') \leq b \), then \( \rho(x, x') \leq c \cdot \tau(f(x), f(x')) \leq D \cdot \rho(x, x') \).     \item If \( \rho(x, x') > b \), then \( c \cdot \tau(f(x), f(x')) \geq b \).     \item If \( \rho(x, x') < a \), then \( c \cdot \tau(f(x), f(x')) \leq D \cdot a \).",2502.01120
definition,"[LSH~\cite{IM98}] Let $\mathcal{H}$ be a family of hash functions mapping a metric $(X, \rho)$ to some universe $U$. We say that $\mathcal{H}$ is \emph{$(r, tr, p_1, p_2)$-sensitive} if for every $x, y \in X$, the following is satisfied:  \compactify     \item If $\rho(x, y) \leq r$, then $\Pr_{h \in \mathcal{H}}[h(x) = h(y)] \geq p_1$.     \item If $\rho(x, y) > tr$, then $\Pr_{h \in \mathcal{H}}[h(x) = h(y)] \leq p_2$.      Such $\mathcal{H}$ is called an \emph{LSH family} with parameter $\gamma := \frac{\log (1/p_1)}{\log (1/p_2)}$.",2502.01120
definition,"A scheme is \emph{a distance labeling} with approximation $D\ge 1$ and label size of $k$ if   \compactify \item   every label (for every point in every metric in $\cX$)   consists of at most $k$ bits; and  \item   there is an algorithm $\cA$ that, given the labels $l(x),l(y)$   of two points $x,y$ in a metric $(X,\rho)\in \cX$   (but not given $(X, \rho)$ or the points $x,y$),   outputs an estimate $\cA(l(x), l(y))$ that satisfies    \[     \rho(x, y) \leq \cA(l(x), l(y)) \leq D \cdot \rho(x, y) .   \]",2502.01120
proof,"[Proof of \cref{thm:(Lipschitz-Decompositions-in-lp)}] Let \( \Delta > 0 \), and let \( X \subset \ell_{p} \) be an \( n \)-point metric space for \( p \in (2, \infty) \). Construct a partition of $X$ in the following steps:  \compactify \item   Construct for \( X \) an \( (O(\log{n}), \log^{1/p}{n} \cdot \Delta/4) \)-Lipschitz decomposition \( \Pinit  = \{ K_{1}, \ldots, K_{t} \} \)   using \cref{thm:(Bartal-Prob-Partitions)}. \item   Embed each cluster $K_i \subset \ell_p$ into \( \ell_2 \)   using the embedding \( f^{K_{i}} \) provided by \cref{cor:(low-dist-l_p-to-l_2-embedding)} for $C_0 := \log^{1/p}{n} \cdot \Delta/4$. \item   For each embedded cluster \( f^{K_{i}}(K_{i}) \),   construct an \( (O(\sqrt{\log{n}}), \frac12 \Delta/ \log^{1/2 -1/p} n) \)-Lipschitz decomposition \( P_{i} = \{K_{i}^{1}, \ldots,K_{i}^{k_{i}} \} \)    using \cite{CCGGP98} and the JL Lemma~\cite{JL84}. \item    The final decomposition $\Pout$ is obtained by taking the preimage of every cluster of every $P_i$.    It is easy to see that that $\Pout$ is indeed a partition of $X$, consisting of $\sum_{i=1}^t k_i$ clusters. % Next, consider $x,y\in X$ and let us bound $\Pr[\Pout(x) \neq \Pout(y)]$.  Observe that a pair of points can be separated only in steps 1 or 3.  Therefore,     \Pr &\Big[\Pout(x) \neq \Pout(y)\Big]   \\   & \leq \Pr\Big[\Pinit (x) \neq \Pinit (y)\Big]   +  \Pr\Big[P_i(f^{K_i}(x)) \neq P_i(f^{K_i}(y)) \mid \Pinit (x) = \Pinit (y) = K_{i}\Big]   \\   & \leq O(\log{n})\frac{\|x - y\|_{p}}{\log^{1/p}{n} \cdot \Delta/4} + O(\sqrt{\log{n}}) \frac{\|f^{K_i}(x) - f^{K_i}(y)\|_{2}}{\frac12 \Delta / \log^{1/2-1/p} n }   \\   & \leq O(\log^{1-1/p}{n}) \frac{\|x - y\|_{p}}{\Delta} ,  where the last inequality follows because each $f^{K_i}$  is non-expanding on its cluster $K_{i}\subset \ell_p$.  It remains to show that the final clusters all have diameter at most \( \Delta \). Let \( x, y \in X \) be in the same cluster, i.e., \( \Pout(x) = \Pout(y) \). Then $\Pinit (x)=\Pinit (y)=K_i$ and $P_{i}(f^{K_i}(x))=P_{i}(f^{K_i}(y))$. Combining the maximum possible diameter of \( \Pinit (x) \) and \( P_{i}(f^{K_i}(x)) \) with the contraction guarantees of \( f = f^{K_i} \), we get \[   \frac{2}{p} \Big( 2(\log^{1/p}{n})\frac{\Delta}{4} \Big)^{1 - p/2} \|x - y\|_{p}^{p/2}    \leq \|f(x) - f(y)\|_{2}    \leq \frac{\Delta}{2}\log^{1/p-1/2}{n}. \] Rearranging this, we obtain \( \|x - y\|_p \leq \frac{\sqrt[2/p]{p/2}}{2}\Delta \leq \Delta \), which completes the proof.",2502.01120
proof,"[Proof of \cref{thm:(Decomposability-Of-lp)}] Let \(\Delta > 0\) and \(t \geq 1\). Let \(X \subset \ell_p\) be an \(n\)-point subset of \(p \in (2, \infty)\), where \(q\) is such that \(\frac{1}{p} + \frac{1}{q} = 1\). Construct a partition of $X$ in the following steps:  \compactify \item   Construct for $X$ a \( (t_{1} := t^{q}/4, \Delta_{1} := \Delta/4t^{1-q}, n^{-O(1/t^{q})}) \)-capped decomposition \(  \Pinit = \{ K_{1}, \ldots, K_{t} \} \)   using \cref{prop:(Decomposability-Of-General-Metrics)}. \item   Embed each cluster $K_i \subset \ell_p$ into \( \ell_2 \)   using the embedding \( f^{K_{i}} \) provided by \cref{cor:(low-dist-l_p-to-l_2-embedding)} for $C_0 := \Delta_{1}$. \item   For each embedded cluster \( f^{K_{i}}(K_{i}) \)   construct a \( (t_{2} := t^{q/2}/2, \Delta_{2} := \Delta/2t^{1-q/2}, n^{-O(1/t^{q})}) \)-capped decomposition \( P_{i} = \{ K_{i}^{1}, \ldots, K_{i}^{k_{i}} \}\)   using \cref{prop:(Decomposability-Of-l2)}. \item    The final decomposition $\Pout$ is obtained by taking the preimage of every cluster of every $P_i$.    It is easy to see that that $\Pout$ is indeed a partition of $X$, consisting of $\sum_{i=1}^t k_i$ clusters. % Next, consider $x,y\in X$ with \( \|x - y\|_p \leq \Delta/t \) and let us bound $\Pr[\Pout(x) = \Pout(y)]$. Observe that $\Delta_{1}/t_{1} = \Delta_{2}/t_{2} = \Delta/t$, and therefore    \Pr & \Big[ \Pout(x) = \Pout(y) \Big]   \\   & = \Pr \Big[ \Pinit(x) = \Pinit(y) \Big]     \cdot \Pr\Big[ P_{i}(f^{K_{i}}(x)) = P_{i}(f^{K_{i}}(y)) \mid \Pinit(x) = \Pinit(y) = K_{i} \Big]   \\   & \geq n^{-O\left(1/t^{q}\right)} \cdot n^{-O\left(1/t^{q}\right)} = n^{-O\left(1/t^{q}\right)} ,  where the inequality follows because each $f^{K_i}$ is non-expanding on its cluster $K_i \subset \ell_p$.   It remains to show that each cluster has diameter at most \( \Delta \). Let \( x, y \in X \) be in the same cluster, i.e., \( \Pout(x) = \Pout(y) \). Then $\Pinit (x)=\Pinit (y)=K_i$ and $P_{i}(f^{K_i}(x))=P_{i}(f^{K_i}(y))$. Combining the maximum possible diameter of \( \Pinit (x) \) and \( P_{i}(f^{K_i}(x)) \) with the contraction guarantees of \( f = f^{K_i} \), we get \[   \frac{2}{p} \Big( 2\frac{\Delta}{4t^{1-q}} \Big)^{1 - p/2} \|x - y\|_{p}^{p/2}    \leq \|f(x) - f(y)\|_{2}    \leq \frac{\Delta}{2t^{1-q/2}}. \] Rearranging this, we obtain \( \|x - y\|_p \leq \frac{\sqrt[2/p]{p/2}}{2}\Delta \leq \Delta \), which completes the proof.",2502.01120
proof,"[Proof of \cref{thm:(Spanner-In-l_p-p-greater-than-2)}] The proof follows directly by combining \cref{thm:(Decomposability-Of-lp)} and \cref{thm:(Decomposable-Metrics-Spanner)},  as we can assume \( t = O(\log{n}) \) without loss of generality.",2502.01120
proof,"[Proof of \cref{thm:linear-size-spanners-in-l_p-p-less-than-two} via Lipschitz Decomposition] Observe that the above algorithm of \cite{HIS13} uses the fact that the points lie in $\ell_2$ only for the construction of Lipschitz Decompositions, and relies on an optimal decomposition for finite $\ell_2$ metrics to conclude that the spanner's stretch is $O(\beta^{*}_{n}(\ell_2))$.  % For finite \(\ell_p\) metrics, \(p \in (1, 2)\), we can use instead a Lipschitz decomposition from~\cite{LN03draft, Naor17}, which has \(\beta = \frac{O(\log^{1/p}{n})}{p - 1}\), to conclude the claimed stretch.",2502.01120
proof,"[Proof of \cref{thm:linear-size-spanners-in-l_p-p-less-than-two} via Weak Dimension Reduction] Observe that the above algorithm of \cite{HIS13} only requires the decomposition of each net \(N_i\) to ensure that points \(x, y \in N_i\) with \(\|x - y\|_2 \leq 2^{i+1}\) are clustered together with constant probability,  and that the diameter of all clusters is at most \( O(\sqrt{\log{n}}) \cdot 2^i\); of course, for $X \subset \ell_p$, $p\in(1,2)$, we replace the $O(\sqrt{\log{n}})$ factor with $O(\log^{1/p}{n})$. A careful examination shows that these properties are preserved by first reducing the dimension using the range-preserving embedding provided by \Cref{thm:weak-dimension-reduction} with \(\varepsilon = \frac{1}{2}\) and \(R = 2\), and then constructing a Lipschitz decomposition for the image points in \(\ell_p^{O(\log{n})}\) using~\cite{CCGGP98}.",2502.01120
proof,"Let \( p \in (1,2) \), \( r > 0 \), and sufficiently large \( t > 1 \). Let \( f : \ell_p \to \ell_2 \) be the isometric embedding of the \( (p/2) \)-snowflake of \( \ell_p \) into \( \ell_2 \) from~\cite[Theorem 4.1]{Kal08}. Take \( r' = r^{p/2} \) and \( t' = t^{p/2} \), and let \( \mathcal{H} \) be the \( (r', t' r', p_1, p_2) \)-sensitive LSH family for \( \ell_2 \) with parameter \( \gamma = \frac{1}{t'^2} + o(1) \) from~\cite{AI06}. Observe that, for every \( x, y \in \ell_p \), if \( \|x - y\|_p \leq r \), then \( \|f(x) - f(y)\|_2 = \|x - y\|_p^{p/2} \leq r^{p/2} = r' \), and thus  \[ \Pr_{h \in \mathcal{H}}[h(f(x)) = h(f(y))] \geq p_1. \] Similarly, if \( \|x - y\|_p > t r \), then \( \|f(x) - f(y)\|_2 = \|x - y\|_p^{p/2} > (t r)^{p/2} = t' r' \), and hence  \[ \Pr_{h \in \mathcal{H}}[h(f(x)) = h(f(y))] \leq p_2. \] We therefore conclude that \( \mathcal{H} \circ f \) is an \( (r, tr, p_1, p_2) \)-sensitive LSH family for \( \ell_p \) with parameter \( \gamma = \frac{1}{t^p} + o(1) \).",2502.01120
proof,"[Proof of \cref{thm:(Spanner-In-l_p-p-less-than-2)}] The proof follows immediately by constructing a capped decomposition  based on \cref{lem:LSH-implies-capped-decomposition} and \cref{lem:LSH-for-l_p}, and using it in the spanner construction from \cref{thm:(Decomposable-Metrics-Spanner)}.",2502.01120
proof,"[Proof of \cref{thm:(Distance-Labeling-In-Decomposable-Metrics)}] We first describe the preprocessing algorithm, denoting $\beta := \beta^*(\cX)$.  Perform the following steps for all levels \( i = 0, \ldots, \log{\Delta_{\text{max}}} \). Begin by constructing a \( (\beta, \Delta_i := 4\beta 2^{i}) \)-Lipschitz decomposition, and observe that every two points \( x, y \in X \) with \( \rho(x,y) \leq 2^{i} \) are separated with probability at most \( \frac{1}{4} \). Then, assign a random bit to each cluster, and observe that if two points are at distance greater than \( \Delta_i \), they always fall in different clusters, hence, the probability that they are assigned the same bit is exactly \( \frac{1}{2} \), and if they are at distance at most $2^i = \Delta_i/(4\beta)$ they are assigned the same bit with probability at least \( \frac{3}{4} \). Repeat the last two steps \( k = O(\log{n}) \) times, and then with high probability, every two points \( x, y \) are assigned the same bit at least \( \frac{5}{8}k \) times if \( \rho(x, y) \leq \Delta_i/(4\beta) \) and fewer than \( \frac{5}{8}k \) times if \( \rho(x, y) > \Delta_i \). Finally, label each point by concatenating the bit assigned to its cluster in all the repetitions at all levels.  The label-size analysis is straightforward. It remains to show that, given two labels \(l(x),l(y)\), it is possible to approximate the distance \(\rho(x, y)\) within factor $O(\beta)$. This can be achieved by identifying the smallest level $i$ such that $x$ and $y$ are assigned the same bit at least $\frac{5}{8}k$ times, and then the above analysis (used in contrapositive form) implies that $\Delta_{i-1}/(4\beta) < \rho(x,y) \leq \Delta_i$, where by convention $\Delta_{-1}:=1$.",2502.01120
proposition,"[\cite{FN22}]  Every $n$-point subset of \( \ell_2 \) admits a \( (t, n^{-O(1/t^{2})}) \)-capped decomposition for all $t \geq 1$.",2502.01120
proposition,"[Implicit in~\cite{MN07}]  Every $n$-point metric space admits a \( (t, n^{-O(1/t)}) \)-capped decomposition for all $t \geq 1$.",2502.01120
lemma,"[\cite{FN22}]      Let $(X, \rho)$ be a metric space such that for every $r > 0$, there exists a $(r, t r, p_1, p_2)$-sensitive LSH family with parameter $\gamma$. Then $(X, \rho)$ admits a $(t, n^{-\mathcal{O}(\gamma)})$-capped decomposition.",2502.01120
lemma,"[\cite{AndoniIndyk}]      Let $p\in(1,2)$, $r>0$, and large enough $t>1$. Then there exists a $(r, t  r, p_1, p_2)$-sensitive LSH family for $\ell_p$ with parameter $\gamma=\frac{1}{t^p}+o(1)$.",2502.01120
definition,"A framework realization has a $n^{th}$-order flex if for each vertex $\Vkt x_i$ ($i=1,\ldots,w$)  there is a polynomial function   \Vkt x_i':=\Vkt x_i+ \Vkt x_{i,1}t+\ldots + \Vkt x_{i,n}t^n \quad \text{with} \quad n>0  such that  \item the replacement of $\Vkt x_i$ by $\Vkt x_i'$ in the equations $c_1,\ldots ,c_e$ gives stationary values  of multiplicity $\geq n+1$ at $t=0$; \item the velocity vectors $\Vkt x_{1,1},\ldots ,\Vkt x_{w,1}$ do not originate from a rigid body motion (incl.\ standstill)  of the complete framework; i.e.\ they are said to be non-trivial.",2502.01124
definition,"A bar-joint framework, which is not continuous flexible, has a 1-parametric $(k,n)$-flex if for each vertex $\Vkt x_i$ ($i=1,\ldots,w$)  there is a polynomial function given in Eq.\ (\ref{eq:flexk}) such that  \item the replacement of $\Vkt x_i$ by $\Vkt x_i'$ in the equations $c_1,\ldots,c_e$ of the edge lengths gives stationary values  of multiplicity $\geq n+1$ at $t=0$; \item the vectors $\Vkt x_{1,k},\ldots ,\Vkt x_{w,k}$ are non-trivial;  \item Eq.\ (\ref{eq:flexk}) can be extended to a minimal parametrization of a branch of order $k$ of an algebraic curve,  which corresponds to a one-dimensional irreducible component of a variety determined by an ideal, whose generators   are contained in the linear  family of quadrics spanned by $c_1,\ldots, c_e$.",2502.01124
example,"For purpose of illustration we do not use an example which corresponds to an actual framework.  The example is constructed based on the data provided in \cite[Table 1]{tu}. Let us consider the three quadrics $C_i$ in $\RR^3$ given by $c_i(x,y,z)$ with:   c_1(x,y,z):=&x^2+y^2-2z, \quad c_2(x,y,z):=y^2+xy-z, \\ c_3(x,y,z):=&2x^2-3xy-2y^2-2yz+z.   Note that the three regular quadrics intersect in the origin with multiplicity 4 ($\Rightarrow$ $r=3$), which can for example be checked with the method given in \cite[Sec.\ 3.1]{MMT}.  It can easily be seen that these quadrics have a common tangent plane $z=0$ at the origin, which is also a double point of each three possible intersection curves (cf.\ Fig.\ \ref{fig1}-left).  By applying only the removal procedure one would end up with the conclusion that there are always two linear branches, which both imply flexes of order $1$. \hfill $\diamond$",2502.01124
example,"Let us continue with Example \ref{ex2}.   Within the bundle of quadrics spanned by $C_1,C_2,C_3$ there also exists a pencil of cones $\mathcal{P}$ having their apexes in the origin (cf.\ \cite{li}).  Moreover $\mathcal{P}$ touches the plane  $z=0$ in a pencil of lines through the origin.  Therefore each cone of $\mathcal{P}$ intersect $C_1$ in a quartic curve having a cusp in the origin in direction of the cone's generator contained in $z=0$.  This is illustrated in Fig.\ \ref{fig1}-center for the cone $C_4\in\mathcal{P}$ given by $c_4=0$ with $c_4(x,y,z):=x^2-2yz$.  Therefore there exists also a pencil of $(2,3)$-flexes.  Note that higher-order cusps with $k>2$ are not possible due to degree reasons\footnote{For a non-planar branch two points of this branch would span with the cusp a plane intersecting the branch (which is maximal of order 4) in at least five points (counted with multiplicity) if $k>2$; a contradiction. A planar branch has to be a conic, which cannot have cusps.}.  The geometric reasoning given within this example  will also be verified by the detailed algebraic analysis presented in Example \ref{ex3} of the next section. \hfill $\diamond$",2502.01124
example,"First we look at the ideal $I_1=\langle c_1+\lambda_1c_3,c_2+\lambda_2c_3\rangle$. For $\lambda_1,\lambda_2\neq 0$ this ideal is equivalent with the ideals $\langle c_1+\mu_1c_2,c_3+\mu_3c_2\rangle$ with $\mu_1,\mu_3\neq 0$ and  $\langle c_2+\nu_2c_1,c_3+\nu_3c_1\rangle$ with $\nu_2,\nu_3\neq 0$, respectively.  It can easily be seen that we only have to discuss this ideal $I_1$ as well as the ideals      $I_2=\langle c_1+\mu_1c_2,c_3\rangle$ and      $I_3=\langle c_2,c_3\rangle$ in order to cover all algebraic curves which can be obtained by the intersection of two quadrics belonging to the bundle spanned by $C_1,C_2,C_3$.   In order to demonstrate the procedure we start with the discussion of the ideal $I_1$: First we eliminate $z$ from the two generators of $I_1$ by the resultant method, which yields the polynomial $P(x,y)$ given by:  x^2 - 2xy - y^2  + \lambda_1(2x^2 - 2xy - y^2 - 2xy^2 - 2y^3) +  \lambda_2 (2x^2y + 2y^3  - 5x^2 + 6xy + 3y^2).   By using {\sc Maple} one can compute the Puiseux series in dependence of $\lambda_1,\lambda_2$ under the assumption    (\lambda_1-3\lambda_2+1)(3\lambda_1-8\lambda_2+2)\neq 0.      In this case we get two linear branches with minimal parametrization  x(t)=t, \quad y_{\mp}(t)= -\tfrac{ \lambda_1 - 3\lambda_2 +1 \mp \sqrt{(3\lambda_1 - 8\lambda_2 + 2)(\lambda_1 - 3\lambda_2 + 1)} }{\lambda_1 - 3\lambda_2 + 1}t +\ldots .   Now we eliminate $y$ by the resultant method from the generators of $I_1$ yielding the polynomial $P(x,z)$ with:    &2x^4 - 4x^2z + z^2   +\lambda_1\lambda_2(32x^2z + 26xz^2 + 12z^3 -25x^4 - 12x^3z - 4x^2z^2  - 6z^2) +\\  &\lambda_1( 7x^4+ 2zx^3-10 z x^2-6 z^2 x+2 z^2)  +2\lambda_2(13x^2z + 4xz^2 -7x^4 - 2x^3z  - 3z^2).   Again under the assumption of Eq.\ (\ref{eq:assume}) we can compute the  Puiseux series in dependence of $\lambda_1,\lambda_2$. We get again two linear branches with minimal parametrization  x(t)=t, \quad z_{\mp}(t)= \tfrac{3\lambda_1 - 7\lambda_2 + 2 \mp \sqrt{(3\lambda_1 - 8\lambda_2 + 2)(\lambda_1 - 3\lambda_2 + 1)} }{\lambda_1 - 3\lambda_2 + 1}t +\ldots .   Then the two linear branches of the space curve have the minimal parametrization $(x(t),y_\mp(t),z_\mp(t))$. Plugging both  parametrizations into $c_3$ yield   \tfrac{1}{\lambda_1 - 3\lambda_2 + 1}t^2 \mp  \tfrac{(8\lambda_1 - 20\lambda_2 + 6)\sqrt{(3\lambda_1 - 8\lambda_2 + 2)(\lambda_1 - 3\lambda_2 + 1)} + 2(\lambda_1 - 3\lambda_2 + 1)(4 + 6\lambda_1 - 15\lambda_2)}{\lambda_1 - 3\lambda_2 + 1}^3 t^3 +o(t^3).  This shows that each of the two linear branches imply a $(1,1)$-flex.  % Due to limitation of pages we refer  For the discussion of the special cases excluded by  Eq.\ (\ref{eq:assume}) we refer to Appendix A, where also the ideals $I_2$ and $I_3$ are discussed in detail. In summary, these computations prove that only $(1,1)$ and $(2,3)$-flexes are possible verifying the argumentation given in Example \ref{ex:con}. \hfill $\diamond$",2502.01124
example,"We use the same dimensioning for the immobile 4-bar mechanism (cf.\ Fig.\ \ref{fig1}-right) as in \cite[Sec.\ 3.2]{nayak} and coordinatize the fixed joints by $F_1=(-1,0)$, $F_2=(5,0)$ and the moving ones by $M_1=(a,b)$, $M_2=(3+c,d)$.  Moreover, we have the constraints:  c_1:\,\,\|M_1-F_1\|^2-1^2=0,\quad c_2:\,\,\|M_2-M_1\|^2-3^2=0,\quad c_3:\,\,\|M_2-F_2\|^2-2^2=0.  The parametrization of the space curve splits up into two conjugate complex linear branches (see Appendix B for the detailed computation) given by $b(t)=t$ and  a(t)=\tfrac{-1}{2}t^2  -\tfrac{1}{8}t^4  + \ldots, \,\,\,\,\,\,\,\, c(t)=\tfrac{-8 \pm 6I}{25}t^2  + \tfrac{-79 \pm 3I}{1250}t^4 + \ldots,  \,\,\,\,\,\,\,\, d(t)=\tfrac{2\pm 6I}{5}t +  \tfrac{6\pm 33I}{250}t^3 +\ldots  through the origin, which is the only real point.  By plugging the real part of this parametrization %; i.e.\ $(a(t), b(t), \Re c(t), \Re d(t))$,  into $c_1,c_2,c_3$ it can be seen that  at least $t^2$ factors out from the resulting three expressions. This implies that the triple $(r;k_{\max},n_{\max})$ equals $(\infty;1,1)$. \hfill $\diamond$  % $(0,t,0,2/5t)$.",2502.01124
theorem,"Let $M$ be a closed hyperbolic $3$-manifold. There exists an $\epsilon_0>0$ such that every homotopy class of  $(1+\epsilon)$-\qf surfaces with $0<\epsilon\leq \epsilon_0$ is filling, and the set of incompressible embedded surfaces is decomposed into  	 		\item at most finitely many totally geodesic surfaces, and 		\item surfaces with quasi-Fuchsian constant $\geq 1+\epsilon_0$.",2502.01134
theorem,"\footnote{Independently, Al Assal-Lowe \cite{flInprep} obtain a similar result with different perspectives and applications.} 	Let $M$ be a closed hyperbolic $3$-manifold. If $S_j$ is a sequence of asymptotically Fuchsian surfaces in distinct commensurability classes, then the Grassmann $2$-plane bundle $\gt S_i \rightarrow \gt M$ in the Hausdorff metric. \footnote{On the other hand, Al Assal \cite{afLimitsAsymptoticalFuchsian} shows that the measure limits achieve every convex combination of $\sltr$-invariant ergodic measures.}",2502.01134
theorem,"Let $M$ be a closed hyperbolic $3$-manifold. Then there exists a constant $g_0$ such that every Fuchsian surface $S$ with $\gc(S) \geq g_0$ is filling. Moreover, the number of components of $M-S$ tends to infinity as $\gc(S)\rightarrow \infty$.  [h] \centering \includegraphics[scale=0.2]{filling-nbhd.png} \caption{The filling nature of nearly geodesic surfaces.}",2502.01134
theorem,"[\citenum{bwBoundaryCriterionCubulation}, Corollary 4.2] 	Let $M$ be a closed hyperbolic $3$-manifold. Each pair of distinct points $p, q \in \partial \widetilde{M}$ is separated by a quasi-Fuchsian surface $F$ in $ M$.",2502.01134
theorem,"If $M$ is a geometric $3$-manifold and admits a $\pi_1$-injective filling surface, then $M$ is hyperbolic, Euclidean, or $\hp \times \R$.",2502.01134
theorem,"Let $M$ be a closed hyperbolic $3$-manifold and $S$ be a filling $\pi_1$-injective surface. Then  	 		\area(S) > \vol(M), 	 	and there is an absolute constant $C$ such that  	 		\rank(S)>C\rank(M).",2502.01134
proof,"For a term $f$ in an abstract category,   \[      \tgt{(\tgt{f})}=\tgt{(\src{(\tgt{f})})}=\src{(\tgt{f})}=\tgt{f}.   \]    A similar argument shows $\src{(\src{f})} =\src{f}$, so (a) holds.    For (b), suppose $g$ is another term and $\src{f}=\tgt{g}$. Now    $\tgt{(fg)} \asymp \tgt{(f(\tgt{g}))}$ is an equality: $\tgt{(fg)} =   \tgt{(f(\tgt{g}))}$. Since $f(\src{f}) = f$,         \tgt{(fg)} = \tgt{(f(\tgt{g}))} = \tgt{(f(\src{f}))} = \tgt{f}.      Hence, $\tgt{(fg)} \venturi \tgt{f}$, and the other formula follows similarly.",2502.01138
proof,"If $f:U \to V$ in $\acat{C}$, then    \(     \tgt{(\src{f})}       = \id_{\text{Codom} \id_{U}}       = \id_{U}       = \src{f}.   \)   Similarly, $\src{(\tgt{f})}=\tgt{f}$.    Since the operators $\src{(-)}$ and   $\tgt{(-)}$ have trivial rails, both of the equations $\tgt{(\src{f})} =   \src{f}$ and $\src{(\tgt{f})}=\tgt{f}$ are everywhere defined.      Observe that $(\tgt{f})f$ is defined and equals $\id_{V}f=f$; also   $f(\src{f})$ is defined and equals $f\id_{U}=f$. For $g:\acat{C}_1(U',V')$,   the expression $\tgt{(fg)}$ is defined whenever $\src{f}=\tgt{g}$, and   $f(\tgt{g})$ is defined whenever $\src{f} = \tgt{(\tgt{g})}$. Since   $\tgt{(-)}$ is idempotent by   Lemma~\ref{lem:idempotent-guards}\ref{lempart:idem}, both $\tgt{(fg)}$ and   $f(\tgt{g})$ are defined when $\src{f}=\tgt{g}$. Thus, $\src{f}=\tgt{g}$   implies     \[      \tgt{(fg)} = \id_{V}       = \tgt{(f(\src{f}))} = \tgt{(f(\tgt{g}))} ,   \]    so $\tgt{(fg)} \asymp \tgt{(f (\tgt{g}))}$. A similar argument holds for   $\src{(fg)} \asymp \src{((\src{f})g)}$.      Lastly, composition is associative everywhere it is defined,    so $f(gh) \asymp (fg)h$.",2502.01138
proof,"Let $\Omega$ be a signature, and let $A$ be an $\Omega$-eastern algebra. If   every operation in $A$ is total, then we apply Noether's Isomorphism Theorem~\cite{Cohn}*{Theorem~II.3.7}. It is clear that the existence of the stated algebras and morphisms is constructive.    Otherwise, at least one operation is a partial-function. We define a new   eastern algebra where all operations are total. Let $\NaN$ be a formal symbol,   disjoint from $\Omega$. Define a new type $E \defeq A \sqcup \{\NaN\}$ with   inclusion function $\iota_A : A \hookrightarrow E$. By abuse of notation, we also apply $\iota_A$ to tuples over $A$. Define a new signature   $\Sigma$, obtained from $\Omega$ by including $\NaN$ as a constant. We use   trivial rails for every operator, and define $\omega_E : E^{|\omega|} \to E$ via    \[      e\mapsto        \iota_A(\omega_A(a)) & \text{if $e=\iota_A(a)$ for some $a: A^{|\omega|}$ with $\omega_A(a):A$,} \\       \NaN  & \text{otherwise}.        \]    Now every operation in $E$ is total, so the Isomorphism Theorem applies.   Since every homomorphism of $\Sigma$-eastern algebras fixes constants, the   statement follows.",2502.01138
proof,"By Theorem~\ref{thm:Noether}, there exist isomorphisms $\psi_b, \psi_{ab} : \acat{E}$   such that         b &= \mathrm{im}(b)\psi_b\mathrm{coim}(b), & ab &= \mathrm{im}(ab)\psi_{ab}\mathrm{coim}(ab) .      By the universal property of coimages, there exists a unique morphism   $\pi:\acat{E}$ such that $\mathrm{coim}(ab) = \pi\,\mathrm{coim}(b)$.   Therefore,         a\,\mathrm{im}(b)\psi_b\mathrm{coim}(b) = ab = \mathrm{im}(ab) \psi_{ab} \mathrm{coim}(ab) = \mathrm{im}(ab) \psi_{ab} \pi\, \mathrm{coim}(b).      Since $\mathrm{coim}(b)$ is an epimorphism, $a\,\mathrm{im}(b) =   \mathrm{im}(ab) \psi_{ab} \pi \psi_b^{-1} \ll \mathrm{im}(ab)$.",2502.01138
proof,"The first claim follows from the universal property of images, so we assume $a$ is monic.   By Theorem~\ref{thm:Noether}, there exists an isomorphism $\psi_b : \acat{E}$ such   that         b &= \mathrm{im}(b)\psi_b\mathrm{coim}(b) .      Since $a\,\mathrm{im}(b)$ is monic and   $ab=(a\,\mathrm{im}(b))(\psi_b\mathrm{coim}(b))$, by the universal property of   images, there exists a morphism $\iota : \acat{E}$ such that $\mathrm{im}(ab)   = a\,\mathrm{im}(b)\iota\ll a\,\mathrm{im}(b)$.",2502.01138
proof,"Condition (1) of Definition~\ref{def:cat-act} is satisfied by the defined action.    For the first part of Condition (2), let $a\tin\acat{A}$. Since $\func{F}$ is   a morphism and $\src{(-)}$ is everywhere defined,   $\func{F}(\src{a})=\src{\func{F}(a)}$. Hence, by   Lemma~\ref{lem:idempotent-guards}\ref{lempart:idem},         (\src{a})\lhd & = \src{\func{F}(\src{a})} = \src{(\src{\func{F}(a)})} = \src{\func{F}(a)} = a\!\lhd.      For the second part of Condition (2), let $a\tin\acat{A}$ and $x\tin\acat{X}$   with $a\lhd=\lhd x$, so $\src{\func{F}(a)} =\tgt{x}$ by definition. Thus,   $$(\src{a}) \cdot x = \func{F}(\src{a})x = (\src{\func{F}(a)})x = (\tgt{x}) x =   x,$$ so $(\src{a})\cdot x\venturi x$ for every $a:\acat{A}$ and $x:\acat{X}$.     For Condition (3), let $a,b\tin\acat{A}$ and $x\tin\acat{X}$ with $\src{a} =   \tgt{b}$ and $(ab)\lhd=\lhd x$, so $(ab)\cdot x$ is defined and   $\src{(ab)}=\src{b}$. We need to show that $(ab)\cdot x=a\cdot (b\cdot x)$.   Since $\func{F}$ is a morphism,    $$     (ab)\lhd=\src{(\func{F}(ab))}=\func{F}(\src{(ab)})=\func{F}(\src{b})=\src{\func{F}(b)}=b\lhd.   $$    Hence, $(ab)\lhd=\lhd x$ implies $b\lhd =\lhd x$. Thus, $\func{F}(b)x$ is   defined. Also,  $\src{a} = \tgt{b}$ implies $\src{\func{F}(a)} =   \tgt{(\func{F}(b))}$, so   \[     a \lhd = \src{\func{F}(a)} = \tgt{(\func{F}(b))} =\tgt{(\func{F}(b)x)}=\tgt{(b\cdot x)}=\lhd (b\cdot x).   \]   It follows that $a\cdot (b\cdot x)$ is defined. Since $\func{F}$ is a   morphism,    $$     a\cdot (b\cdot x) = \func{F}(a)(\func{F}(b)x) = \func{F}(ab)x = (ab)\cdot x,   $$    and therefore $(ab)\cdot x \venturi a\cdot (b\cdot x)$ for every   $a,b\tin\acat{A}$ and $x\tin\acat{X}$.    To see that the action is full, consider  $a\tin \acat{A}$ and define   $x=\src{\func{F}(a)}$. By the laws of an abstract category,     $a \lhd = \src{\func{F}(a)} = \tgt{({\src{\func{F}(a)}})} = \tgt{x} = \lhd x$.   Finally, $(a\cdot x)y=\fF(a)xy\asymp a\cdot (xy)$, so $\cX$ is a left   $\cat{A}$-capsule.",2502.01138
proof,"Since the action is full, for each $a\tin \acat{A}$ there exists   $x\tin\aX$ such that $a\lhd = \lhd x$, so $a\cdot x$ is defined.   Since $\acat{X}$ is a left $\acat{A}$-capsule, $a\lhd = \lhd x = \tgt{x}$, so   \[     \lhd(\tgt{x})=\tgt{(\tgt{x})}=\tgt{x}.   \]   Hence, $a\cdot (\tgt{x})$ is defined and has type $a\cdot \one_{\aX}$.   Suppose $e,f\tin\one_{\acat{X}}$ and $a\lhd = \lhd e = \lhd f$, so that   $a\cdot e, a\cdot f \tin a\cdot \one_{\aX}$.  Furthermore,    \[     e = \tgt{e} = \lhd e = \lhd f = \tgt{f} = f.   \]    Thus, $a\cdot e = a\cdot f$, and there is exactly one term with type $a\cdot   \one_{\aX}$.",2502.01138
proof,"[Proof of Proposition~$\ref{prop:functors-are}$]   By Lemma~\ref{lem:induced-act}, it remains to prove the forward direction and uniqueness.    Suppose that $\cX$ is a left $\cA$-capsule.   By Lemma~\ref{lem:unique-identity}, for each $a:\cA$ there is a unique   $\fF(\src{a}):\one_{\cX}$ such that $(\src{a})\cdot \fF(\src{a})$ is defined.   Since $\cX$ is a left $\cA$-capsule and $\fF(\src{a})$ is an identity,   \[     (\src{a})\lhd=a\lhd=\lhd\fF(\src{a})=\tgt\fF(\src{a})=\fF(\src{a}).   \]   Thus, $a\cdot \fF(\src{a})$ is also defined. Put $\fF(a)\defeq a\cdot   \fF(\src{a})$. If $x:\cX$, then $a\cdot x$ is defined whenever    \[     \tgt{x}=\lhd x=a\lhd=\fF(\src{a})=\src{\fF(\src{a})}.   \]   Hence, $\fF(\src{a})x$ is also defined in $\cX$. Because $\fF(\src{a})$ is an   identity, $\fF(\src{a})x=x$.  Since $\acat{X}$ is a left $\acat{A}$-capsule, $a\cdot x=a\cdot   (\fF(\src{a}) x)=(a\cdot \fF(\src{a}))x=\fF(a)x$. Hence, it remains to prove   that $\fF:\cA\to \cX$ is a morphism of categories.    For $a,b\tin \acat{A}$, by the action laws        \func{F}(ab)       & \asymp (ab)\cdot \fF(\src{(ab)})       \asymp (ab)\cdot \fF(\src{b})       \venturi a\cdot (b\cdot \fF(\src{b}))      \asymp a\cdot \func{F}(b).      Thus, $\func{F}(ab) \venturi a\cdot \func{F}(b)$.  But $\cX$ is a left $\cA$-capsule, so Fact~\ref{fact:capsule} implies that        a\cdot \func{F}(b) &\asymp a\cdot (\one_{\cX}\func{F}(b)) \asymp (a\cdot \one_{\cX}) \func{F}(b) \asymp \func{F}(a)\func{F}(b).      Hence, $\func{F}(ab) \venturi \func{F}(a)\func{F}(b)$. By Lemma~\ref{lem:idempotent-guards}\ref{lempart:guard-reduc} and \eqref{eqn:act-comp} for all $a:\cA$,    \[     \src{\fF(a)}= \src{(a\cdot \fF(\src{a}))}=\src{(\fF(a) \fF(\src{a}))}=\src{\fF(\src{a})}=\fF(\src{a}).   \]   Similarly, $\func{F}(\tgt{a}) = \tgt{\func{F}(a)}$. Hence, $\fF$ is a   morphism.    Lastly, we prove uniqueness of  $\fF$. Suppose there exists $\func{G}:   \cA\to \cX$ such that $a\cdot x = \func{G}(a)x$ for every $a:\cA$ and $x:\cX$   whenever $a\lhd = \lhd x$. Since $a\lhd=\fF(\src{a})$, it follows that   $\src{\fG(a)}=\fF(\src{a})$, so $\func{G}(a) = \func{G}(a)\fF(\src{a}) =   a\cdot \fF(\src{a})  = \fF(a)$.",2502.01138
proof,"\item  By Lemma~\ref{lem:idempotent-guards}\ref{lempart:guard-reduc} for all $a,b,c\tin \acat{A}$,        \fM(ab)     & \asymp (ab) \cdot \mu_{\src{(ab)}} \asymp \func{F}(ab)\mu_{\src{(ab)}}     \venturi \func{F}(a)\func{F}(b)\mu_{\src{b}}     \asymp a\cdot \fM(b) .      Since $\mu$ is a   natural transformation,         \fM(bc)     & \asymp \func{F}(bc)\mu_{\src{(bc)}}        \asymp \mu_{\tgt{(bc)}}\func{G}(bc)        \venturi \mu_{\tgt{b}}\func{G}(b)\func{G}(c)        \asymp \func{F}(b)\mu_{\src{b}}\func{G}(c)        \asymp \fM(b)\cdot c.   \enlargethispage{0.3cm}   Thus, $\fM(abc)\venturi a\cdot \fM(b)\cdot c$, so $\fM$ is an   $\cA$-bimorphism.    \item We apply Proposition~\ref{prop:functors-are}, so there are functors   $\func{F},\func{G}:\acat{A}\to \acat{X}$ determined by the left and right   actions, respectively. Let $a\tin\acat{A}$ and define   $\mu_e\defeq\func{M}(e)$ for $e:\one_{\acat{A}}$. Now         \func{F}(a) \mu_{\src{a}} &= \func{F}(a) \fM(\src{a}) = a\cdot \fM(\src{a}) = \fM(a(\src{a})) = \fM(a)\\     &= \fM((\tgt{a})a) = \fM(\tgt{a})\cdot a = \fM(\tgt{a})\func{G}(a) = \mu_{\tgt{a}}\func{G}(a).      Therefore, $\mu$ is a natural transformation, as required.\qedhere",2502.01138
proof,"\item  By Proposition~\ref{prop:functors-are}, the maps $\fF$ and $\fG$  define functors    where $x\cdot b\asymp x\fF(b)$ and $a\cdot y\asymp \fG(a)y$, for $a,x:\cA$ and $b,y:\cB$.   Put $\nu=\fN(\fG(\one_A))$. For $a:\acat{A}$,         a\nu_{\src{a}}     & = a\fN\fG(\src{a})       = a\fN(\src{\fG(a)})       = \fN(a\cdot \src{(\fG(a))})        = \fN(\fG(a)\src{(\fG(a))})        = \fN\fG(a),       and         \nu_{\tgt{a}} \fF\fG(a)     & = \fN\fG(\tgt{a})\cdot\fG(a)       = \fN(\tgt{\fG(a)})\cdot \fG(a)        = \fN((\tgt{\fG(a)})\fG(a))        = \fN\fG(a).      Hence, $a\nu_{\src{a}} = \nu_{\tgt{a}} \fF\fG(a)$ for all $a:\acat{A}$, so $\nu:\fF\fG\Rightarrow \id_{\cA}$ is a natural transformation.     We show that $\mathcal{N}'(b) \defeq \fF(b)\nu_{\src{\fF(b)}}$ yields an   $(\cA,\cB)$-morphism $\mathcal{N}': \cB \to \cA$.    First, if $a:\cA$ and $y:\cB$   with $a\lhd = \lhd y$, then         \mathcal{N}'(a\cdot y) &= \mathcal{N}'(\fG(a)y) \\     &= \fF(\fG(a)y) \nu_{\src{\fF(\fG(a)y)}} \\     &= \fF\fG(a)\fF(y) \nu_{\src{(\fF\fG(a)\fF(y))}} \\     &= \fF\fG(a) \fF(y)\nu_{\src{\fF(y)}} \\     &= \fF\fG(a) \mathcal{N}'(y) \\     &= a\cdot \mathcal{N}'(y).      Next, if $b:\cB$ such that $y\lhd = \lhd b$, then         \mathcal{N}'(yb) &= \fF(yb)\nu_{\src{\fF(yb)}} \\     &= \nu_{\tgt{\fF(yb)}}\fF\fG\fF(yb) \\      &= \nu_{\tgt{(\fF(y)\fF(b))}}\fF\fG\fF(y)\fF\fG\fF(b) \\     &= \nu_{\tgt{\fF(y)}}\fF\fG\fF(y)\fF\fG\fF(b) \\     &= \fF(y)\nu_{\src{\fF(y)}}\fF\fG\fF(b) \\     &= \mathcal{N}'(y)\fF\fG\fF(b) \\     &= \mathcal{N}'(y) \cdot b.      Finally, consider $e:\one_{\cA}$. Since    functors map identities to identities, we deduce that         \mathcal{N}'(\fG(e)) &= \fF\fG(e) \nu_{\src{\fF\fG(e)}} = \nu_{\fF\fG(e)} . \qedhere",2502.01138
proof,"First we prove (a). Since $\acat{A}$ and $\acat{B}$ are   $(\acat{A},\acat{B})$-bicapsules, by Proposition~\ref{prop:functors-are} there   are functors $\fF:\cB\to \cA$ and $\fG:\cA\to \cB$ defining the right   $\cB$-capsule $\cA_{\cB}$ and the left $\cA$-capsule ${_{\cA} \cB}$   respectively. Since $\fM$ and $\fN$ are pseudo-inverses and capsule   actions are full, $\fM$ inverts $\fN$ on $\cA\cdot \one_{\cB}$ and $\fN$   inverts $\fM$ on $\one_{\cA}\cdot \cB$. For objects $U$ of $\cB$ and $V$ of   $\cA$, let $e=\id_U$ and $f=\id_V$. For $x:\cA_1(\fF(U),V)=f\cA\cdot e$ (see   Remark~\ref{rem:bi-inter}), we define $\Psi_{UV}(x) \defeq \fM(x)$. Therefore,   for $y:\cB_1(U,\fG(V))=f\cdot \cB e$, the map $y\mapsto \fN(y)$ inverts   $\Psi_{UV}$, so the result follows.   Now we prove (b). By Proposition~\ref{prop:functors-are}, we can exchange functors for capsules, so $\fF:\cB\to \cA$ affords a right $\cB$-capsule $\cA_{\cB}$. We enrich this action by adding the left regular action by $\cA$ to produce an $(\cA,\cB)$-bicapsule $_{\cA}\cA_{\cB}$.  We do likewise with $\fG:\cA\to \cB$ producing a second $(\cA,\cB)$-capsule $_{\cA}\cB_{\cB}$.  To encode $\Psi$, we define an $(\cA,\cB)$-bimorphism $\fM:\cA\to \cB^?$ by $\fM(x) \defeq \Psi_{UV}(x)$ for $x:A_1(\fF(U),V)$. This defines $\fM$ on  \[   \bigsqcup_{U:\cB_0}\bigsqcup_{V:\cA_0}\cA_1(\fF(U),V)   =\bigsqcup_{e:\one_{\cB}}\bigsqcup_{f:\one_{\cA}}f\cA\cdot e   = \cA\cdot \one_{\cB}. \] For all other values, $\fM$ is undefined.  Now \eqref{def:adjoint-classic} shows that  on  $\cA\cdot \one_{\cB}$ with $a:\cA_1(V,Y)$, $b:\cB_1(X,U)$, and $x : \cA_1(\fF(U),V)$,     \fM(ax\cdot b) & = \Psi_{UV}(ax\fF(b)) = \fG(a)\Psi_{XY}(x)b=a\cdot \fM(x)b,  so $\fM$ is an $(\cA,\cB)$-bimorphism.  We define $\fN:\cB\to \cA^?$ analogously: if $y:\one_{\cA}\cdot \cB$, then  $\fN(y)\defeq \Psi^{-1}(y)$ (for suitable subscripts of $\Psi$), and otherwise $\fN(y)$ is undefined. Therefore, for $x: \acat{A}\cdot\one_{\acat{B}}$ and $y: \one_{\cA}\cdot \cB$,     (\fM\fN\fM)(x) & = \Psi(\Psi^{-1}(\Psi(x)))=\Psi(x)=\fM(x)\\   (\fN\fM\fN)(y) & = \Psi^{-1}(\Psi(\Psi^{-1}(y)))=\Psi^{-1}(y)=\fN(y).  \qedhere",2502.01138
proof,"We assume (1) holds and prove (2). By   Proposition~\ref{prop:nat-trans-biact}\ref{proppart:get-nat-trans}, there exists a unique   functor $\func{G} : \acat{C}\to \acat{E}$ that induces the action of   $\acat{C}$ on the right of $\acat{E}$. Since $\fS$ is a function and a    $\cC$-bimorphism by assumption, $c\lhd= \lhd \sigma_{\src{c}}$ for all   $c:\acat{C}$, and         c\cdot \sigma_{\src{c}}      & = \fS(c) =\fS((\tgt c)\cdot c)= \fS(\tgt{c})\cdot c     = ((\tgt{c}) \cdot \sigma_{\src{(\tgt{c})}}) \cdot c       =\sigma_{\tgt{c}}\fG(c) .       Thus, (2) holds.    We now assume (2) holds and prove (1). First, we show that an $x:\acat{E}$   satisfying $c\cdot \sigma_{\src{c}} = \sigma_{\tgt{c}}x$ is unique. Suppose   $y:\acat{E}$ satisfies $c\cdot \sigma_{\src{c}} = \sigma_{\tgt{c}}y$, so   $\sigma_{\tgt{c}}x = \sigma_{\tgt{c}}y$. Since $\sigma_{\tgt{c}}$ is a   monomorphism, $x=y$. We denote this unique morphism by $u_c:\acat{E}$. Since   $\sigma_{\tgt{c}}u_c$ is defined for all $c:\cC$,         \tgt{u_{\tgt{c}}} = \src{(\sigma_{\tgt{(\tgt{c})}})}      = \src{(\sigma_{\tgt{c}})} = \tgt{u_c}.      Next, we define a right $\cC$-capsule structure on $\acat{E}$ as   follows. Let $\lhd (-) : \cC \to \one_{\cE}$ be given by $\lhd c =   \tgt{u_c}$, and let $(-)\lhd : \cE \to \one_{\cE}$ be given by   $x\lhd = \src{x}$. For all $c:\cC$ and $x:\cE$, let $x\cdot c =   xu_c$, which is defined if, and only if, $\src{x} = \tgt{u_c}$. Condition (2)   of Definition~\ref{def:cat-act} follows from $\lhd (\tgt{c}) = \tgt{u_{\tgt{c}}} =   \tgt{u_c} = \lhd c$ and $u_e:\one_{\cE}$ for all $e:\one_{\cC}$   since $\sigma_e$ is monic. Lastly, let $c,d:\cC$ with $\src{c}=\tgt{d}$.   Then $(cd) \cdot \sigma_{\src{(cd)}} = \sigma_{\tgt{(cd)}}u_{cd} =   \sigma_{\tgt{c}}u_{cd}$ and, since we have a regular left action,          (cd) \cdot \sigma_{\src{(cd)}}       = c \cdot (d \cdot \sigma_{\src{(cd)}})     = c\cdot (d\cdot \sigma_{\src{d}})      = c\cdot \sigma_{\tgt{d}} u_d      = \sigma_{\tgt{c}}u_cu_d.      Since $\sigma_{\tgt{c}}$ is a monomorphism, $u_{cd}=u_cu_d$. Hence, this   defines a right $\cC$-capsule on $\cE$ since $\lhd c = \tgt{u_c}:\one_{\cE}$   for all $c:\cC$. Since $\acat{C}$ acts regularly on $\acat{E}$ on the left,   there exists a $\acat{C}$-bicapsule $\Sigma$ on $\acat{E}$ by   Proposition~\ref{prop:functors-are}, with the regular left and right actions   just defined. Finally, we prove that $\fS$ is a $\cC$-bimorphism. For all   $c,x,y:\cC$,         \func{S}(cx) &= (cx)\cdot \sigma_{\src{(cx)}}      = (cx)\cdot \sigma_{\src{x}}      = c\cdot (x\cdot \sigma_{\src{x}})      = c\cdot \fS(x),      provided $\src{c}=\tgt{x}$. If $\src{y} = \tgt{c}$, then         \fS(yc) &= (yc)\cdot \sigma_{\src{(yc)}}      = (yc)\cdot \sigma_{\src{c}}      = y\cdot (c\cdot \sigma_{\src{c}})      = y\cdot (\sigma_{\tgt{c}}u_c)     = (y\cdot \sigma_{\src{y}})u_c \\     &= \fS(y)\cdot c.\qedhere",2502.01138
proof,"Let $c:\acat{C}$, so $c \lhd = \src{c}$, and $\src{c} = \lhd \sigma_{\src{c}}$   by definition of $\sigma$. We show that $c\cdot \sigma_{\src{c}}   \ll\sigma_{\tgt{c}}$. By Lemma~\ref{lem:im},          &(\forall \langle e,x\rangle:\mathbb{U}_{\acat{C}}(f))&  c\cdot \mathrm{im}(x\cdot \fR(e))& \ll\mathrm{im}(c\cdot (x\cdot \fR(e))) = \mathrm{im}((cx)\cdot \fR(e)).      Thus, by Fact~\ref{fact:coprod}\ref{factpart:ignore-inside},             \coprod_{\langle e,x\rangle:\mathbb{U}_{\acat{C}}(f)} \left(c\cdot \mathrm{im}(x\cdot \fR(e))\right)       &\ll \coprod_{\langle e,x\rangle:\mathbb{U}_{\acat{C}}(f)} \mathrm{im}((cx)\cdot \fR(e)).      Therefore, using \eqref{eq:coprod_im_comment},    c\cdot \mathrm{im}\left(     \coprod_{\langle e,x\rangle}         \mathrm{im}(x\cdot \fR(e))   \right)    & \ll  \mathrm{im}\left(     c\cdot      \coprod_{\langle e,x\rangle}         \mathrm{im}(x\cdot \fR(e))   \right) & & (\text{Lemma~\ref{lem:im}}) \\   & =  \mathrm{im}\left(     \coprod_{\langle e,x\rangle}       (c\cdot          \mathrm{im}(x\cdot \fR(e)))   \right) & & (\text{Fact~\ref{fact:coprod}\ref{factpart:factor-out}}) \\   & \ll  \mathrm{im}\left(     \coprod_{\langle e,x\rangle}         \mathrm{im}((cx)\cdot \fR(e))   \right) & & (\text{Equation (\ref{eq:coprod-ineq})})    where all of the coproducts are over $\langle e,x\rangle:\mathbb{U}_{\acat{C}}(\src{c})$. By  Fact~\ref{fact:coprod}\ref{factpart:smaller-coprod},  \[    \mathrm{im}\left(     \coprod_{\langle e,x\rangle:\mathbb{U}_{\acat{C}}(\src{c})}         \mathrm{im}((cx)\cdot \fR(e))   \right) \ll \mathrm{im}\left(         \coprod_{\langle e,z\rangle:\mathbb{U}_{\acat{C}}(\tgt{c})}            \mathrm{im}(z\cdot \fR(e))     \right). \] Putting this together, we deduce that     c\cdot \sigma_{\src{c}} &= c\cdot \mathrm{im}\left(     \coprod_{\langle e,x\rangle:\mathbb{U}_{\acat{C}}(\src{c})}         \mathrm{im}(x\cdot \fR(e))   \right)    \ll \mathrm{im}\left(     \coprod_{\langle e,z\rangle:\mathbb{U}_{\acat{C}}(\tgt{c})}        \mathrm{im}(z\cdot \fR(e)) \right) = \sigma_{\tgt{c}},   so $c\cdot \sigma_{\src{c}}=\sigma_{\src{c}}y$ for some $y:\acat{E}$. Since $\sigma_{\tgt{c}}$ is monic, $y$ is unique.",2502.01138
proof,"Take $e,f:\one_{\acat{A}}$, and recall that $\acat{A}$ acts regularly on both   the left and right of $\acat{C}$. Since $\acat{A}$ is full in $\acat{C}$,  these actions are full, so    \[     f\cdot\acat{C}\cdot e = \one_{\acat{C}} \cdot (f\acat{A}e) = (f\acat{A}e) \cdot \one_{\acat{C}} .    \]   Since the left actions of $\acat{A}$ on $\acat{C}$ and on $\acat{E}$  and the left action of $\acat{C}$ on $\acat{E}$ are regular, for each   $a:\acat{A}$ and $x:\acat{E}$ with $a\lhd = \lhd x$,        (a\cdot \one_{\acat{C}}) \cdot x &= a\cdot x.       Fix $a:\acat{A}$. Set $c = a\cdot\one_{\acat{C}}$, so $(\src{c})\acat{C} = (\src{a})\cdot   \acat{C}$. Thus, since the $\acat{A}$-action on $\acat{C}$ is full,        \mathbb{U}_{\acat{C}}(\src{c}) \defeq \bigsqcup_{e:\one_{\acat{A}}} \left((\src{c})\acat{C}\cdot e\right) &= \bigsqcup_{e:\one_{\acat{A}}} \left((\src{a})\cdot \acat{C}\cdot e\right) = ((\src{a})\acat{A})\cdot \one_{\acat{C}},      where $(\src{a})\acat{A}$ acts on $\one_{\acat{C}}$ in the final expression.   Therefore,         \fS(a\cdot\one_{\acat{C}})      & = a\cdot \mathrm{im}\left(\coprod_{\langle e,x\rangle:\mathbb{U}_{\acat{C}}((\src{a})\cdot \one_{\acat{C}})} \mathrm{im}(x\cdot \fR(e))\right)          & & (\text{Equation \eqref{eqn:C-to-A}}) \\      & = a\cdot \mathrm{im}\left(\coprod_{a':(\src{a})\acat{A}} \mathrm{im}(a'\cdot \fR(\src{a'}))\right)          & & (\text{Equation \eqref{eqn:subscripts}})\\     & = a\cdot \mathrm{im}\left(\coprod_{a':(\src{a})\acat{A}} \mathrm{im}(\fR(\src{a})\cdot a')\right)          & & (\text{$\acat{A}$-bimorphism, $\tgt{a'} = \src{a}$})\\     & \ll a\cdot \fR(\src{a}) = \fR(a).     & & (\text{Lemma~\ref{lem:im-monic},  Fact~\ref{fact:coprod}\ref{factpart:factor-out}})    \noindent  For the application of Lemma~\ref{lem:im-monic} in the last step, recall that  $\func{R}(e)$ is monic for $e:\acat{A}$ by our assumption  (Table~\ref{tab_setup_exthm}).   We establish the other direction as follows:        \fR(\src{a}) &\ll \mathrm{im}(\fR(\src{a})) = \mathrm{im}((\src{a})\cdot \fR(\src{a})) & & (\text{Theorem~\ref{thm:Noether}}) \\     &\ll \coprod_{a':(\src{a})\acat{A}} \mathrm{im}(a' \cdot \fR(\src{a'})) & & (\text{Fact~\ref{fact:coprod}\ref{factpart:smaller-coprod}}) \\     &\ll \mathrm{im}\left(\coprod_{a':(\src{a})\acat{A}} \mathrm{im}(a' \cdot \fR(\src{a'}))\right). & & (\text{Theorem~\ref{thm:Noether}})       Acting with $a:\acat{A}$ from the left, we obtain $\fR(a) \ll \fS(a\cdot \one_{\acat{C}})$.    From both computations, there exist $\lambda,\mu : \prod_{f:\one_{\acat{A}}}   f\acat{E}f$ such that         \fR(a) &= \fS(a \cdot\one_{\acat{C}}) \lambda_{\src{a}},      & \fS(a \cdot\one_{\acat{C}}) &= \fR(a) \mu_{\src{a}}.       It remains to show that $\mu_{\src{a}} = \lambda_{\src{a}}^{-1}$ for all   $a:\acat{A}$ and $\lambda$ is unique. For all $e:\one_{\acat{A}}$,    $\fR(e)$ is monic by the assumptions in Theorem~\ref{thm:extension}, and    $\fS(e\cdot \one_{\acat{C}})$ is also monic by the definition of $\fS$.   Since $\fR(e)$ is monic,         \fR(e) &= \fS(e \cdot\one_{\acat{C}}) \lambda_{e} = \fR(e)\mu_{e}\lambda_{e}      implies $\mu_{e}\lambda_{e} : \one_{\acat{E}}$. Similarly, $\lambda_{e} \mu_{e}   : \one_{\acat{E}}$ because $\fS(e\cdot\one_{\acat{C}})$ is monic and        \fS(e \cdot\one_{\acat{C}}) &= \fR(e) \mu_{e} = \fS(e \cdot\one_{\acat{C}}) \lambda_{e} \mu_{e} .      The uniqueness of $\lambda$ follows since $\fR(e)$ is monic.",2502.01138
proof,"We prove (1) in detail; the proof of (3) is analogous but requires replacing $\core{E}$ with $\cat{E}$. The proofs of (2) and (4) are dual to the proofs of (1) and (3), respectively.    Let $\iota : H\hookrightarrow G$, which is a morphism in $\cat{E}$. Recall that the single-object category $\Autcat(G)$ consists of $G$ and all its automorphisms,  and likewise for  $\Autcat(H)$. Both are subcategories of $\cat{E}$, and full subcategories of  $\core{E}$. We denote the relevant inclusion functors by  $\fI:\Autcat(G)\to \cE$, $\fJ:\Autcat(H)\to \cE$,   $\fL:\Autcat(G)\to \;\core{E}$, and $\fK:\;\core{E}\;\to \cE$. As in Section~\ref{sec:nat-trans-express}, we obtain a natural transformation $\rho:\fJ\fC\Rightarrow \fI$ with (restriction) functor $\fC:\Autcat(G)\to\Autcat(H)$, so $\rho: \text{Counital}(\Autcat(G),\cE)$ is a monic counital.  We now use Proposition~\ref{prop:nat-trans-biact} to pass to the associated cyclic $\Autcat(G)$-bicapsule  $\Delta=\Autcat(G)\cdot \rho\cdot \Autcat(G)$. Recall that the left action is defined by $\func{I}$, hence regular, and the right action is defined by $\func{JC}$.  By construction, $\Delta$ satisfies the conditions of Theorem~\ref{thm:extension} since $\Autcat(G)$ is full in $\core{E}$. We extend $\Delta$ to a cyclic $\core{E}$-bicapsule $\Sigma=\core{E}\cdot \sigma \cdot \core{E}$ where $\sigma:\fK\fD\Rightarrow \fK$ is a monic counital extending $\rho$, namely, there exists an isomorphism $\tau_G : \func{JC}(G) \to \func{DL}(G)$ such that $\iota = \rho_G=\sigma_{\func{L}(G)}\tau_G$; see \eqref{eqn:extension-nat-trans}. Since $\fL$ is the inclusion functor, there exists an isomorphism $\tau':\acat{E}$ such that $\iota = \sigma_G\tau'$, so $\iota$ and $\sigma_G$ are equivalent. Hence, $\iota$ and $\mathrm{im}(\sigma_G)$ are equivalent. Since $\sigma:\text{Counital}(\core{E},\cE)$, this proves the ``$\subseteq$'' part of (1).   For the converse, consider $\eta: \text{Counital}(\core{E},\cE)$, say $\eta: \func{HD}\Rightarrow\func{K}$ for some functor $\fD:\; \core{E}\;\to \cat{C}$, subcategory $\cat{C}\leq\acat{E}$, and inclusion $\func{H}:\cat{C}\to \cE$.  If $\varphi:\Autcat(G)$, then $\fL(\varphi):\; \core{E}$, and so $\func{K}\fL(\varphi) \eta_G =\eta_G \func{H}\fD\func{L}(\varphi)$. Since $G=\func{L}(G)=\func{K}(G)$, it follows that the morphism  $\eta_G: \func{HD}(G)\to G$ is characteristic, and therefore so is its monic image $\mathrm{im}(\eta_G)$. This proves the ``$\supseteq$'' part of (1).",2502.01138
proof,"We define a subcategory $\cat{A}$ of $\cat{E}$ as follows: its objects are the   objects of~$\acat{E}$; its morphisms are given as finite compositions of   morphisms $\func{I}(\varphi):\acat{E}$, where $\varphi$ is a morphism in   $\acat{B}$, and morphisms $\eta_X:\acat{E}$, where $X$ an object in   $\acat{B}$. Hence, we have inclusions $\func{J} : \cat{B} \to \cat{A}$ and   $\func{K} : \cat{A} \to \cat{E}$ such that $\func{I} = \func{KJ}$. Since both   $\acat{A}$ and $\acat{B}$ have the same objects as $\acat{E}$, it follows that   $\func{I}$, $\func{J}$, and $\func{K}$ are the identities on objects. Moreover, $\func{K}$ is the identity on morphisms.    We now construct a functor $\fD:\cat{A}\to \cat{A}$ such that $\func{J}   \func{E}= \fD \func{J}$. It suffices to define $\fD$ on morphisms and then   verify that $\fD$ is a functor. Set         \fD (\varphi) & =        \func{JE}(\varphi') & \varphi = \fJ(\varphi')\text{ for a morphism $\varphi'$ in } \cat{B}, \\       \eta_{\func{E}(X)} & \varphi=\eta_X\text{ for some object $X$ in $\acat{B}$}, \\       \func{D}(\sigma)\func{D}(\tau) & \varphi=\sigma\tau.           If $\fD$ is well defined, then $\func{D}(\varphi)$ is a morphism in   $\acat{A}$, and $\func{J} \func{E}=\fD \func{J}$ by construction. To verify   that $\fD$ is well defined, it suffices to consider the case where  $\eta_X$   (with $X$ an object in $\acat{B}$) is also a morphism in $\acat{B}$:   specifically, there is a morphism $\beta :\acat{B}$ such that $\eta_X =   \func{I}(\beta)$. Since $\fI$ is the identity on objects, $\beta : \fE(X) \to   X$. We will show that $\eta_{\func{E}(X)}=\fK\fD(\eta_X)=\func{IE}(\beta)$. To   see this, we apply $\eta$ to the morphism $\beta:\func{E}(X)\to X$ and obtain   the following diagram (see shaded entry $(2,2)$ of   Figure~\ref{fig:functor-cat-act}).   \[             \func{I}\func{E}\func{E}(X) \arrow[r, ""\func{IE}(\beta)""] \arrow[d, ""\eta_{\fE(X)}""]          & \func{I}\func{E}(X) \arrow[d, ""\eta_{X}""] \\       \func{I}\func{E}(X) \arrow[r, ""\func{I}(\beta)""] & \func{I}(X)        \]   Since $\eta_X = \fI(\beta)$, the diagram implies that $\eta_X   \eta_{\func{E}(X)}=\eta_X \func{IE}(\beta)$. Since $\eta_X$ is monic by   assumption,  $\func{IE}(\beta)=\eta_{\func{E}(X)}$. This proves that   $\func{D}$ is well defined.     We claim that there exists a natural transformation   $\hat{\eta}:\func{K}\func{D}\Rightarrow \func{K}$ such that   $\hat{\eta}\func{J} = \eta$.    Since the   objects of $\cat{A}$ are those of $\cat{B}$, we define $\hat{\eta}_X$ to be   $\eta_X$ and show that this yields the required counital. First, we consider   the case that $\varphi : X\to Y$ is a morphism in $\cat{B}$. Then $\func{K} \func{D}   \func{J}(\varphi)=\func{K} \func{J} \func{E}(\varphi)=\func{I}   \func{E}(\varphi)$, so        \hat{\eta}_Y \func{K} \func{D}(\func{J}(\varphi))      & = \eta_Y \func{I} \func{E}(\varphi) = \func{I}(\varphi)\eta_X       = \func{K}(\func{J}(\varphi))\hat{\eta}_X.       Now we assume $\varphi = \eta_X: \func{IE}(X)\to \func{I}(X)$ for some   object $X$ in $\cat{B}$. Since $\fI$ is the identity on objects and $\fK$ is the identity on morphisms,         \hat{\eta}_{\func{I}(X)} \func{K} \func{D}(\eta_X)      & = \hat{\eta}_X\func{KD}(\eta_X) = \eta_{X} \func{K}(\eta_{ \func{E}(X)})        = \eta_{X} \eta_{ \func{E}(X)}  = \func{K}(\eta_X)\hat{\eta}_{ \func{E}(X)}.      Lastly, we consider the case of an arbitrary finite composition   $\varphi=\varphi_1\cdots \varphi_n$ where each  $\varphi_k$ is either $\fJ(\varphi_k')$ for some morphism $\varphi_k'$ in $\acat{B}$ or a morphism $\eta_X$ for some object $X$ in $\acat{B}$. It suffices to consider   only the case where $n=2$, say $\varphi = \varphi_1\varphi_2$ with $\varphi_2   : X\to Z$ and $\varphi_1: Z\to Y$. Now         \hat{\eta}_Y \func{K} \func{D}(\varphi)      & = \hat{\eta}_Y \func{K} \func{D}(\varphi_1) \func{K} \func{D}(\varphi_2) \\     & = \func{K}(\varphi_1)\hat{\eta}_{Z} \func{K} \fD(\varphi_2) \\     & = \func{K}(\varphi_1) \func{K}(\varphi_2)\hat{\eta}_{X}\\     & = \func{K}(\varphi)\hat{\eta}_X.      Thus,  $\hat{\eta}:\func{K} \func{D}\Rightarrow \func{K}$. Since $\eta$ is monic, so is $\hat{\eta}$.  Also, $\hat{\eta}_X$ is a morphism in $\cat{A}$ for every object $X$, so it is  internal, as claimed.",2502.01138
proof,"Let $\func{I}: \core{E}\to \acat{E}$ be  the inclusion functor. The proof of   Theorem~\ref{thm:char-counital-eastern} shows that there exists  a functor   $\func{E}:\;\core{E}\;\to \;\core{E}$ and a monic counital $\eta:\func{I}   \func{E}\Rightarrow \func{I}$ such that  $\eta_X=\iota$. We use   Proposition~\ref{prop:isosceles-to-internal}  (with $\cB=\;\core{E}$) to create   a category $\cat{A}$ generated from $\core{E}$ and $\eta$, an inclusion   functor $\func{K} : \cat{A} \to \cat{E}$, a functor $\func{D} : \cat{A} \to   \cat{A}$, and an internal monic counital $\hat{\eta} : \func{K}\func{D}   \Rightarrow \func{K}$ with  $\hat{\eta}_{Z}=\eta_Z$ for all objects in   $\core{E}$. Lastly, we  apply Proposition~\ref{prop:nat-trans-biact}(a) to   $\hat{\eta}$ to obtain an $\acat{A}$-bimorphism $\mathcal{N} : \acat{A} \to   \acat{E}$ such that $\hat{\eta} = \mathcal{N}(\one_{\acat{A}})$. Since   $\hat{\eta}$ is internal, there exists an $\acat{A}$-bimorphism $\mathcal{M} :   \acat{A} \to \acat{A}$ such that $\mathcal{N}=\mathcal{KM}$. Hence,   $\hat{\eta}=\func{K}\func{M}(\one_{\acat{A}})$. With $\acat{B} \defeq   \acat{A}$, it follows that  $\mathcal{M}(\id_X\cdot \one_{\acat{B}})   =\hat{\eta}_X=\eta_X=\iota$, as claimed.",2502.01138
proof,"\item For every morphism $\varphi:G\to H$ in $\cat{A}$, there is an induced   morphism $\varphi':\im(\unital_G)\to \im (\unital_{H})$ such that   $\varphi'\unital_{G}=\unital_H\varphi$, so   \[     \unital_{H}\varphi(\ker(\unital_G))     =\varphi' \unital_G (\ker (\unital_G))=1.   \]   Therefore $\varphi(\ker(\unital_G))\leq \ker (\unital_{H})$.   In particular, the restriction         \varphi|_{\ker (\unital_G)}:\ker(\unital_G)\to \ker(\unital_{H})      is well defined. Let $\cat{C}$ be the category whose objects   are $\ker(\unital_G)$ for all groups $G$ and whose morphisms are $\varphi|_{\ker (\unital_G)}$ for all morphisms $\varphi : G\to  H$ in $\cat{A}$. Let $\func{K}: \acat{C}\to \acat{Grp}$ be the inclusion functor. Moreover,   there is a functor $\func{C}: \cat{A} \to \cat{C}$ given   by $\func{C}(G) = \ker(\unital_G)$ and $\func{C}(\varphi) = \varphi|_{\ker   (\unital_G)}$. If we define $\counital_G: \ker(\unital_G)\hookrightarrow G$ to be the   associated inclusion map for the kernel, then  $\counital:   \func{K}\func{C}\Rightarrow \func{I}$ is the required counital.    \item The proof is dual to that of (a).    \item Consider the unital $\unital : \func{I} \Rightarrow   \func{J} \func{U}$. By Theorem~\ref{thm:Noether},   for each group $G$ there is an isomorphism   \[      \mu: \fU(G)=\mathrm{Im}\pi_G \to  G/\ker\unital_G=\coker (\ker\unital_G).   \]    Thus,  $\coker (\ker (\unital))=\mu (\text{im}(\pi))$;     likewise, for $\ker (\coker (\counital))$ and  $\counital$. \qedhere",2502.01138
proof,"By Proposition~\ref{prop:functors-are}, the functors $\func{R}$ and $\func{I}$ turn both   $\acat{Var}(W)$ and $\acat{Grp}$ into $(\acat{Var}(W),\acat{Grp})$-bicapsules. The   functor $\func{R}$ is a $(\acat{Var}(W),\acat{Grp})$-morphism: for morphisms   $\alpha$ in $\acat{Var}(W)$ and $\varphi,\tau$ in $\acat{Grp}$,         \func{R}(\alpha\varphi\cdot\tau) &= (\alpha\varphi\func{I}(\tau))|^{\mathrm{Rad}_W} = \alpha|^{\mathrm{Rad}_W}\; \varphi|^{\mathrm{Rad}_W}\; \tau = \alpha\cdot \func{R}(\varphi)\tau.      Since $\func{R}$ and $\func{I}$ are pseudo-inverses,   the result follows from Theorem~\ref{thm:iso-biacts-adjoints}\ref{thmpart:biaction-to-adjoint}.",2502.01138
proof,"The functor $\func{B}$ induces a left $\acat{G}$-action on (the morphisms of)      $\cB$,     and $\func{G}$ induces a right $\acat{B}$-action on $\cG$,     so $\cB$ and     $\cG$ are $(\cB,\cG)$-bicapsules.     Let $\lambda, \mu$ be morphisms of $\cG$ and let $(\alpha,\beta)$ be a     morphism of $\cB$ such that $\lambda \mu\cdot (\alpha,\beta) =     \lambda\mu (\alpha\boxtimes \beta)$ is defined.      Now              \func{B}(\lambda\mu\cdot (\alpha,\beta))          &= \left((\lambda\mu(\alpha\boxtimes\beta))|^{\gamma_2},\ (\lambda\mu(\alpha\boxtimes\beta))|_{\gamma_2}\right) \\         &= \left(\lambda|^{\gamma_2} \mu|^{\gamma_2}\alpha,\ \lambda|_{\gamma_2} \mu|_{\gamma_2} \beta\right) \\ &= \lambda \cdot\func{B}(\mu) (\alpha,\beta),          so $\func{B}$ is a $(\cG,\cB)$-morphism.",2502.01138
theorem,"[Uniform weighted energy estimates in $\Omega_{\delta}$; adapted from Theorem 1.1 in  \cite{Xu} for the study of rigidity]  	 	Let $N\in \mathbb{Z}_{\geqslant 5}$, $\delta\in(0,1]$ and  $\sigma\in(0,\frac{1}{3})$.   	There exists a universal constant $\varepsilon_0\in(0,1)$ such that if the initial data $(z_{+,0}(x),z_{-,0}(x))$ of the system \eqref{MHD equation}  satisfy 	  		\mathcal{E}(0):= 	\sum_{+,-}\bigg(\!\sum_{k+l\leqslant 2N}\!\delta^{2(l-\frac{1}{2})}E_{\pm}^{(k,l)}(z_{\pm,0})	+\!\sum_{k\leqslant 2N-1}\!\delta^{-3}E_{\pm}^{(k,0)}(z_{\pm,0}^3) +\!\sum_{k+l\leqslant N+2}\!\delta^{2(l-\frac{1}{2})}E_{\pm}^{(k,l)}(\partial_3z_{\pm,0})\bigg) \leqslant\varepsilon_0^2, 	 	then the system \eqref{MHD equation}  admits a unique global  solution $\big(z_+(t,x),z_-(t,x)\big)$.  	Moreover,   	there is a universal constant $C$ such that the following  uniform (with respect to $\delta$) weighted energy estimates hold: 	 		\mathcal{E}:= & \sum_{+,-}\bigg(\sum_{k+l\leqslant 2N}\delta^{2(l-\frac{1}{2})}\big(E_{\pm}^{(k,l)}(z_{\pm})+F_{\pm}^{(k,l)}(z_{\pm})\big)   +\sum_{k\leqslant 2N-1}\delta^{-3}\big(E_{\pm}^{(k,0)}(z_{\pm}^3)+F_{\pm}^{(k,0)}(z_{\pm}^3)\big)\\ 		&\ \ \ \ \ \ \  +\sum_{k+l\leqslant N+2}\delta^{2(l-\frac{1}{2})}\big(E_{\pm}^{(k,l)}(\partial_3z_{\pm})+F_{\pm}^{(k,l)}(\partial_3z_{\pm})\big)\bigg)\\ 		&\leqslant C\mathcal{E}(0).\stepcounter{equation}\tag{\theequation} 	  In particular, both the constants  $\varepsilon_0$ and $C$ are independent of the thickness parameter $\delta$ and the position parameter $a$. These facts are indeed important keys to ensuring the further study on rigidity.",2502.01139
theorem,"[Asymptotics of the global solution  from $\Omega_{\delta}$ to $\mathbb{R}^2$ as  $\delta$ goes to zero; extracted from Theorem 1.3 in \cite{Xu}]  	 	Let $N\in \mathbb{Z}_{\geqslant 5}$, $\delta\in(0,1]$ and  $\sigma\in(0,\frac{1}{3})$.   	Assume that    	the initial data $(z_{+(\delta),0},z_{-(\delta),0})$ converge to $(z_{+(0),0},z_{-(0),0})$ in $H^{N+1}(\Omega_1)$ 	with respect to $\delta$: 	 		\lim_{\delta\to 0}	\big(z_{\pm(\delta),0}^h(x_h,x_3),z_{\pm(\delta),0}^3(x_h,x_3)\big) 	=\big(z_{\pm(0),0}^h(x_h),0\big)\ \ \text{ in }H^{N+1}(\Omega_1),  i.e.   	\lim_{\delta\to 0}\sum_{k\leqslant N+1}\big\|\langle u_\mp\rangle^{1+\sigma}\nabla^k(z_{\pm(\delta),0} -z_{\pm(0),0} )\big\|_{L^2(\Omega_1)}=0,  where $z_{\pm(0),0}^h$ satisfies $\nabla_h\cdot z_{\pm(0),0}^h=0$.  If $\big(z_{+(\delta)}(t,x),z_{-(\delta)}(t,x)\big)$ is a solution to the rescaled system  \eqref{eq:rescale}, then there exist functions $z_{\pm(0)}^h(t,x_h)$ such that for any $x_3\in(-1,1)$, there hold  	 		\lim_{\delta\to 0}z_{\pm(\delta)}^h(t,x_h,x_3)&=z_{\pm(0)}^h(t,x_h)\ \ \text{ in }H^N(\mathbb{R}^2),\\ 		\lim_{\delta\to 0}z_{\pm(\delta)}^3(t,x_h,x_3)&=0\ \ \text{ in }H^{N-1}(\mathbb{R}^2).",2502.01139
theorem,"[Scattering fields in $\Omega_{\delta}$]   All the integrals in  \eqref{eq:def-sca} converge. Therefore the vector fields $\delta^{-\frac{1}{2}}z_{+}(\infty;u_-,x_2,x_3)$ and  $\delta^{-\frac{1}{2}}z_{-}(\infty;u_+,x_2,x_3)$ are well-defined by \eqref{eq:def-sca}, and we call them the left scattering field and the right scattering field respectively. Moreover, for any $\alpha_h\in(\mathbb{Z}_{\geqslant 0})^2$ and $l\in\mathbb{Z}_{\geqslant 0}$ with  $0\leqslant|\alpha_h|+l\leqslant N+2$,  there hold the following two properties of scattering fields: [(i)] \item  these scattering fields live in the following functional spaces in the weighted energy sense:  &\delta^{l-\frac{1}{2}}\partial_h^{\alpha_h}\partial_3^l z_{\pm}(\infty;u_\mp,x_2,x_3)\in L^2(\mathcal{C}_\pm,\langle u_\mp\rangle^{2(1+\sigma)}du_\mp dx_2dx_3),\\ &\delta^{-\frac{3}{2}}\partial_h^{\alpha_h} z^3_{\pm}(\infty;u_\mp,x_2,x_3)\in L^2(\mathcal{C}_\pm,\langle u_\mp\rangle^{2(1+\sigma)}du_\mp dx_2dx_3),\\ &\delta^{l-\frac{1}{2}}\partial_h^{\alpha_h}\partial_3^l(\partial_3 z_{\pm})(\infty;u_\mp,x_2,x_3)\in L^2(\mathcal{C}_\pm,\langle u_\mp\rangle^{2(1+\sigma)}du_\mp dx_2dx_3).   \item these scattering fields can be approximated by the large time solution in the weighted energy sense:   &	\lim_{T\to\infty}\Big\|\delta^{l-\frac{1}{2}}\partial_h^{\alpha_h}\partial_3^lz_{\pm}(\infty;u_\mp,x_2,x_3)-\delta^{l-\frac{1}{2}}\partial_h^{\alpha_h}\partial_3^lz_{\pm}(T,u_\mp\mp T,x_2,x_3)\Big\|_{L^2(\mathcal{C}_\pm,\langle u_\mp\rangle^{2(1+\sigma)}du_\mp dx_2dx_3)}=0,\\ &	\lim_{T\to\infty}\Big\|\delta^{-\frac{3}{2}}\partial_h^{\alpha_h}z^3_{\pm}(\infty;u_\mp,x_2,x_3)-\delta^{-\frac{3}{2}}\partial_h^{\alpha_h}z^3_{\pm}(T,u_\mp\mp T,x_2,x_3)\Big\|_{L^2(\mathcal{C}_\pm,\langle u_\mp\rangle^{2(1+\sigma)}du_\mp dx_2dx_3)}=0,\\ &	\lim_{T\to\infty}\Big\|\delta^{l-\frac{1}{2}}\partial_h^{\alpha_h}\partial_3^l(\partial_3z_{\pm})(\infty;u_\mp,x_2,x_3)-\delta^{l-\frac{1}{2}}\partial_h^{\alpha_h}\partial_3^l(\partial_3z_{\pm})(T,u_\mp\mp T,x_2,x_3)\Big\|_{L^2(\mathcal{C}_\pm,\langle u_\mp\rangle^{2(1+\sigma)}du_\mp dx_2dx_3)}=0.",2502.01139
theorem,"[Rigidity theorem in  $\Omega_{\delta}$] If the scattering fields constructed in Theorem \ref{thm1}  vanish on the infinities, i.e. \[ 	&\delta^{-\frac{1}{2}}z_+(\infty;u_-,x_2,x_3)\equiv 0 \ \ \text{on} \ \ \mathcal{C}_+,\\ 	&\delta^{-\frac{1}{2}}z_-(\infty;u_+,x_2,x_3)\equiv 0 \ \ \text{on} \ \ \mathcal{C}_-,  \] then the initial Alfv\'en waves governed by the system  \eqref{MHD equation} vanish identically, i.e.  \[\big(z_{+,0}(x),z_{-,0}(x)\big)\equiv(0,0)\ \text{ for all }x\in\Omega_\delta,\] and hence the Alfv\'en waves  governed by the system  \eqref{MHD equation} vanish identically, i.e. \[\big(z_+(t,x),z_-(t,x)\big)\equiv(0,0)\  \text{ for all }(t,x)\in \mathbb{R}\times \Omega_\delta.\]",2502.01139
theorem,"[Weighted energy estimates in $\mathbb{R}^2$]  Let $N_* \in \mathbb{Z}_{\geqslant 5}$ and $\sigma \in\big(0,\frac{1}{3}\big)$. There exists a universal constant $\varepsilon_0\in(0,1)$ such that if the initial data $\big(z_{+,0}(x),z_{-,0}(x)\big)$ of \eqref{MHD equation2} satisfy 		 			\mathcal{E}^{N_*}(0): =\sum_{+,-}\sum_{k=0}^{N_*+1}\Big\|\left(1+|x_1\pm a|^2\right)^{\frac{1+\sigma}{2}}\nabla^{k} z_{\pm}(0,x)\Big\|_{L^2(\mathbb{R}^2)}^2\leqslant\varepsilon_0^2, 		 		then the system \eqref{MHD equation2} admits a unique global solution  $\big(z_+(t,x),z_-(t,x)\big)$. Moreover, there exists a universal constant $C$ such that the following weighted energy estimates hold: 		 			\sum_{+,-}\sum_{k=0}^{N_*+1}\sup_{t\geqslant 0}\Big\|\left(1+|u_\mp \pm a|^2\right)^{\frac{1+\sigma}{2}}\nabla^{k}z_{\pm}(t,x)\Big\|_{L^2(\mathbb{R}^2)}^2 \leqslant C \mathcal{E}^{N_*}(0).",2502.01139
theorem,"[Scattering fields in $\mathbb{R}^2$] 		For the solution $\left(z_+(t,x),z_-(t,x)\right)$ constructed in Theorem \ref{Main Energy Estimates MHD 2d}, the following two vector fields 		 			 				&\displaystyle z_+(\infty;u_-,x_2):=z_+(0,u_-,x_2)-\int_0^{\infty} \left(\nabla p+z_{-}\cdot\nabla z_{+}\right)(\tau,u_--\tau,x_2)d\tau\\ 				&\displaystyle z_-(\infty;u_+,x_2):=z_-(0,u_+,x_2)-\int_0^{\infty} \left(\nabla p+z_{+}\cdot\nabla z_{-}\right)(\tau,u_++\tau,x_2)d\tau 			 		 		are well-defined on the infinities   $\mathcal{C}_+$  (the 2D version of the $\mathcal{C}_+$ above) and $\mathcal{C}_-$ (the 2D version of the  $\mathcal{C}_-$ above) respectively. We call  $z_+(\infty;u_-,x_2)$ as the left scattering field and $z_-(\infty;u_+,x_2)$ as the right  scattering field. Moreover, for any $\beta\in(\mathbb{Z}_{\geqslant 0})^2$ with $0\leqslant |\beta|\leqslant N_*$ there hold the following two properties of scattering fields: 		[(i)] 	\item these scattering fields live in the following functional spaces in the weighted energy sense: 	\[\nabla^\beta z_\pm(\infty;u_\mp,x_2)\in L^2(\mathcal{C}_\pm,\langle u_\mp\rangle^{2(1+\sigma)}du_\mp dx_2).\] 	\item these scattering fields can be approximated by the large time solution in the weighted energy sense: 	\[\lim_{T\to\infty}\Big\|\nabla^{\beta} z_{\pm}(\infty;u_\mp,x_2)-\nabla^\beta z_{\pm}(T,u_\mp\mp T,x_2)\Big\|_{L^2(\mathcal{C}_\pm,\langle u_\mp\rangle^{2(1+\sigma)}du_\mp dx_2)}=0\]",2502.01139
theorem,"[Rigidity theorem in $\mathbb{R}^2$] 		If the scattering fields  constructed in Theorem \ref{futurescatteringfields MHD 2d} vanish on the  infinities, i.e.  		 			 				& z_+(\infty;u_-,x_2)\equiv 0\ \ \text{on} \ \ \mathcal{C}_+\text{ (the 2D version of the  $\mathcal{C}_+$ above)},\\ 				& z_-(\infty;u_+,x_2)\equiv 0\ \ \text{on} \ \ \mathcal{C}_-\text{ (the 2D version of the  $\mathcal{C}_-$ above)}, 			 			 	then the initial Alfv\'en waves vanish identically, i.e.  \[\big(z_{+,0}(x),z_{-,0}(x)\big)\equiv(0,0)\ \text{ for all }x\in\mathbb{R}^2,\] and hence 	the Alfv\'en waves  vanish identically, i.e.,  \[\big(z_+(t,x),z_-(t,x)\big)\equiv(0,0)\  \text{ for all }(t,x)\in \mathbb{R}\times \mathbb{R}^2.\]",2502.01139
proof,"We first recall the vector calculus identity   	-\Delta v=-\nabla(\operatorname{div}v)+\operatorname{curl}\operatorname{curl}v.  Multiplying this identity by $\lambda v$ and then integrating over $\Omega_\delta$ lead us to    	-\int_{\Omega_\delta}\lambda v\cdot \Delta vdx=-\int_{\Omega_\delta}\lambda v\cdot \nabla(\operatorname{div}v)dx+\int_{\Omega_\delta}\lambda v\cdot \operatorname{curl}\operatorname{curl}vdx.   After integration by parts, we infer that  	&-\int_{\Omega_\delta}\lambda v\cdot \Delta vdx		 	=-\int_{\partial\Omega_\delta} \lambda v\cdot \nabla v\cdot ndS+\int_{\Omega_\delta} \lambda|\nabla v|^2dx+\int_{\Omega_\delta}\nabla \lambda\cdot v\cdot \nabla vdx,\\ 	&-\int_{\Omega_\delta}\lambda v\cdot \nabla(\operatorname{div}v)dx 	=-\int_{\partial\Omega_\delta} \lambda v\cdot (\operatorname{div} v) ndS+\int_{\Omega_\delta} \lambda|\operatorname{div} v|^2dx+\int_{\Omega_\delta}\nabla \lambda\cdot  v \operatorname{div} vdx,\\ 	&\int_{\Omega_\delta}\lambda v\cdot \operatorname{curl}\operatorname{curl}vdx 	=-\int_{\partial\Omega_\delta} \lambda v\cdot (\operatorname{curl} v\times n)dS+\int_{\Omega_\delta} \lambda|\operatorname{curl} v|^2dx+\int_{\Omega_\delta}(\nabla \lambda\wedge v)\cdot \operatorname{curl} vdx,  where $n$ is the unit outward normal of $\partial\Omega_{\delta}$ and $dS$ is the surface measure of $\partial\Omega_{\delta}$.  Therefore we derive  	\int_{\Omega_\delta} \lambda|\nabla v|^2dx&=\int_{\partial\Omega_\delta} \lambda v\cdot \big[\nabla v\cdot n- 	(\operatorname{div}v) n-(\operatorname{curl}v\times n)\big]dS+\int_{\Omega_\delta} \lambda|\operatorname{div} v|^2dx+\int_{\Omega_\delta} \lambda|\operatorname{curl} v|^2dx\\ 	&\ \ \ \ -\int_{\Omega_\delta}\nabla \lambda\cdot v\cdot \nabla vdx+\int_{\Omega_\delta}\nabla \lambda\cdot v \operatorname{div} vdx+\int_{\Omega_\delta}(\nabla \lambda\wedge v)\cdot \operatorname{curl} vdx.\stepcounter{equation}\tag{\theequation}   By direct calculation, we acquire   \int_{\partial\Omega_\delta} \lambda v\cdot \big[\nabla v\cdot n- (\operatorname{div}v) n-(\operatorname{curl}v\times n)\big]dS=\int_{\partial\Omega_\delta} \lambda v^j(\partial_jv^in_i-\partial_iv^in_j)dS.  In view of \eqref{div1} and \eqref{div2}, we deduce that   	\int_{\Omega_\delta} \lambda|\nabla v|^2dx&\leqslant\Big|\int_{\partial\Omega_\delta} \lambda v^j(\partial_jv^in_i-\partial_iv^in_j)dS\Big|+\int_{\Omega_\delta} \lambda|\operatorname{div} v|^2dx+\int_{\Omega_\delta} \lambda|\operatorname{curl} v|^2dx\\ 	&\ \ \ \ +\int_{\Omega_\delta}|\nabla \lambda||v||\nabla v|dx 	+\int_{\Omega_\delta}|\nabla \lambda| |v||\operatorname{div} v|dx+\int_{\Omega_\delta}|\nabla \lambda||v||\operatorname{curl} v|dx.    Noticing that $n\big|_{\partial\Omega_{\delta}}=n\big|_{x_3=\pm\delta}=(0,0,\pm 1)^T$ and $dS=dx_h$, we obtain \[ 	\Big|\int_{\partial\Omega_\delta} \lambda v^j(\partial_jv^in_i-\partial_iv^in_j)dS\Big|=\Big|\int_{\partial\Omega_\delta} \lambda (v\cdot\nabla v^3-v^3\operatorname{div}v)dx_h\Big|=\Big|\int_{\partial\Omega_\delta} \lambda (v^h\cdot\nabla_h v^3-v^3\nabla_hv^h)dx_h\Big|.\] Then using Cauchy-Schwarz inequality gives rise to   \int_{\mathbb{R}^3} \lambda|\nabla v|^2dx&\leqslant\Big|\int_{\partial\Omega_\delta} \lambda (v^h\cdot\nabla_h v^3-v^3\nabla_hv^h)dx_h\Big|+\frac{3}{2}\int_{\mathbb{R}^3} \lambda|\operatorname{div} v|^2dx +\frac{3}{2}\int_{\mathbb{R}^3} \lambda|\operatorname{curl} v|^2dx\\ &\ \ \ \ +\frac{3}{2}\int_{\mathbb{R}^3}\frac{|\nabla\lambda|^2}{\lambda}|v|^2dx +\frac{1}{2}\int_{\mathbb{R}^3}\lambda|\nabla v|^2dx.   	Since   	$|\nabla\lambda|\lesssim\lambda$ gives $\frac{|\nabla\lambda|}{\sqrt{\lambda}}\lesssim\sqrt{\lambda}$, we finally summarize that   	  		\big\|\sqrt\lambda\nabla v\big\|_{L^2(\mathbb{R}^3)}^2 \lesssim\big\|\sqrt\lambda\operatorname{div }v\big\|_{L^2(\mathbb{R}^3)}^2+ \big\|\sqrt\lambda\operatorname{curl }v\big\|_{L^2(\mathbb{R}^3)}^2+ \big\|\sqrt\lambda v\big\|_{L^2(\mathbb{R}^3)}^2+\Big|\int_{\partial\Omega_\delta} \lambda (v^h\cdot\nabla_h v^3-v^3\nabla_hv^h)dx_h\Big|.  	 This ends the proof of the lemma.",2502.01139
proof,"For any $1\leqslant k\leqslant m$, we have $\nabla^{k-1}v\in H^{m-k+1}(\Omega_{\delta})\subset H^1(\Omega_{\delta})$. Thus, applying \eqref{eq:d-c} to the vector field $\nabla^{k-1}v$ yields  \big\|\sqrt\lambda\nabla^k v\big\|_{L^2(\Omega_\delta)}^2 &\lesssim\big\|\sqrt\lambda\operatorname{div }\nabla^{k-1}v\big\|_{L^2(\Omega_\delta)}^2+ \big\|\sqrt\lambda\operatorname{curl }\nabla^{k-1}v\big\|_{L^2(\Omega_\delta)}^2+ \big\|\sqrt\lambda\nabla^{k-1} v\big\|_{L^2(\Omega_\delta)}^2\\ &\ \ \ \ +\Big|\int_{\partial\Omega_\delta} \lambda (\nabla^{k-1}v^h\cdot\nabla^{k-1}\nabla_h v^3-\nabla^{k-1}v^3\cdot\nabla^{k-1}\nabla_hv^h)dx_h\Big|.   By induction on $k$, we can infer   \eqref{eq:d-c2} immediately.  Hence the lemma is proved.",2502.01139
proof,"We only derive the estimate for $\mathbf{I}_+^{(\alpha_h,l)}$. The estimate on $\mathbf{I}_-^{(\alpha_h,l)}$ can be given in the same way.     By the divergence free condition $\operatorname{div}z_-=0$, we see that   	\nabla z_-\cdot\nabla z_+ 	&=\nabla z_-^k\cdot\partial_kz_+=\nabla z_-^h\cdot\nabla_hz_++\nabla z_-^3\cdot\partial_3z_+\\ 	&=(\nabla_hz_-^h,\partial_3z_-^h) \cdot\nabla_hz_++(\nabla_hz_-^3,\partial_3 z_-^3)\cdot\partial_3z_+\\ 	&=(\nabla_hz_-^h,\partial_3z_-^h) \cdot\nabla_hz_++(\nabla_hz_-^3,-\nabla_h z_-^h)\cdot\partial_3z_+,    and therefore  	\big|\mathbf{I}_{+}^{(\alpha_h,l)}\big| 	&\lesssim \sum_{\beta_h\leqslant \alpha_h\atop l_1\leqslant l}\Big(\underbrace{\big|\partial_h^{\alpha_h-\beta_h}\partial_3^{l-l_1}\nabla_h z_-^h\big|\cdot \big|\partial_h^{\beta_h}\partial_3^{l_1}\nabla_hz_+\big|}_{\mathbf{I}_{+,1}^{(\beta_h,l_1)}} +\underbrace{\big|\partial_h^{\alpha_h-\beta_h}\partial_3^{l-l_1}\nabla_h z_-\big|\cdot \big|\partial_h^{\beta_h}\partial_3^{l_1}\partial_3z_+\big|}_{\mathbf{I}_{+,2}^{(\beta_h,l_1)}}\\  	&\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  +\underbrace{\big|\partial_h^{\alpha_h-\beta_h}\partial_3^{l-l_1}\partial_3 z_-^h\big|\cdot \big|\partial_h^{\beta_h}\partial_3^{l_1}\nabla_hz_+\big| }_{\mathbf{I}_{+,3}^{(\beta_h,l_1)}}\Big).  In this way we obtain that   	\delta^{l+\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{I}_{+}^{(\alpha_h,l)}\big\|_{L^2_tL^2_x} 	&\lesssim \delta^{l+\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{I}_{+,1}^{(\beta_h,l_1)}\big\|_{L^2_tL^2_x}\\ 	&\ \ \ \ +\delta^{l+\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{I}_{+,2}^{(\beta_h,l_1)}\big\|_{L^2_tL^2_x}\\ 	&\ \ \ \ +\delta^{l+\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{I}_{+,3}^{(\beta_h,l_1)}\big\|_{L^2_tL^2_x}.\stepcounter{equation}\tag{\theequation}     According to the size of $|\beta_h|+l_1$, we now have  two cases: \[|\beta_h|+l_1\leqslant N-1\ \ \text{ and }\ \ N\leqslant|\beta_h|+l_1\leqslant  |\alpha_h|+l\leqslant 2N-1.\] \subsubsection*{\bf Case 1:  $|\beta_h|+l_1\leqslant N-1$} Thanks to  $(|\beta_h|+l_1+1)+2\leqslant N+2$, we can use the Sobolev lemma to bound  $L^\infty_x$ norms of $\nabla_h^{|\beta_h|+1}\partial_3^{l_1} z_{+}$ in $\mathbf{I}_{+,1}^{(\beta_h,l_1)}$ as well as in  $\mathbf{I}_{+,3}^{(\beta_h,l_1)}$ and $\nabla_h^{|\beta_h|}\partial_3^{l_1+1} z_{+}$ in $\mathbf{I}_{+,2}^{(\beta_h,l_1)}$ respectively. From this, we have   	&\ \ \ \ \delta^{l+\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{I}_{+,1}^{(\beta_h,l_1)}\big\|_{L^2_tL^2_x}\\ 	&\stackrel{\text{H\""older}}{\lesssim} \delta^{l+\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\nabla_h^{|\alpha_h-\beta_h|+1}\partial_3^{l-l_1}z_-^h\big\|_{L^\infty_tL^2_x}\cdot\Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|+1}\partial_3^{l_1}z_+\Big\|_{L^2_tL^\infty_x}\\ 	&\stackrel{\text{Lemma } \ref{lemma:sobolev}}{\lesssim}\delta^{l+\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\nabla_h^{|\alpha_h-\beta_h|+1}\partial_3^{l-l_1}z_-^h\big\|_{L^\infty_tL^2_x}\cdot \sum_{k_2+l_2\leqslant 2}\delta^{l_2-\frac{1}{2}}\Big\|\nabla_h^{k_2}\partial_3^{l_2}\Big(\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|+1}\partial_3^{l_1}z_+\Big)\Big\|_{L^2_tL^2_x} \\ 	&\stackrel{\eqref{eq:weightde}}{\lesssim}\delta^{l+\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\nabla_h^{|\alpha_h-\beta_h|+1}\partial_3^{l-l_1}z_-^h\big\|_{L^\infty_tL^2_x}\cdot  \sum_{k_2+l_2\leqslant 2}\delta^{l_2-\frac{1}{2}} \Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|+1+k_2}\partial_3^{l_1+l_2}z_+\Big\|_{L^2_tL^2_x}\\ 	&\lesssim\sum_{k_1\leqslant|\alpha_h|+1}\delta^{l-l_1-\frac{1}{2}}\big(E_-^{(k_1,l-l_1)}(z_-)\big)^{\frac{1}{2}}\cdot\sum_{k_2+l_2\leqslant N+2}\delta^{l_2-\frac{1}{2}}\big(F_+^{(k_2,l_2)}(z_+)\big)^{\frac{1}{2}} 	\stackrel{\eqref{improve2}}{\lesssim} C_1\varepsilon^2,\stepcounter{equation}\tag{\theequation}\\ 	&\ \ \ \ \delta^{l+\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{I}_{+,2}^{(\beta_h,l_1)}\big\|_{L^2_tL^2_x}\\ 	&\stackrel{\text{H\""older}}{\lesssim} \delta^{l+\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\nabla_h^{|\alpha_h-\beta_h|+1}\partial_3^{l-l_1}z_-\big\|_{L^\infty_tL^2_x}\cdot \Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|}\partial_3^{l_1+1}z_+\Big\|_{L^2_tL^\infty_x}\\ 	&\stackrel{\text{Lemma } \ref{lemma:sobolev}}{\lesssim}\delta^{l+\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\nabla_h^{|\alpha_h-\beta_h|+1}\partial_3^{l-l_1}z_-\big\|_{L^\infty_tL^2_x}\cdot\sum_{k_2+l_2\leqslant 2}\delta^{l_2-\frac{1}{2}}\Big\|\nabla_h^{k_2}\partial_3^{l_2}\Big(\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|}\partial_3^{l_1+1}z_+\Big)\Big\|_{L^2_tL^2_x}\\ 	&\stackrel{\eqref{eq:weightde}}{\lesssim} \delta^{l+\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\nabla_h^{|\alpha_h-\beta_h|+1}\partial_3^{l-l_1}z_-\big\|_{L^\infty_tL^2_x}\cdot\sum_{k_2+l_2\leqslant 2}\delta^{l_2-\frac{1}{2}}\Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|+k_2}\partial_3^{l_1+1+l_2}z_+\Big\|_{L^2_tL^2_x}\\ 	&\lesssim 	  \sum_{k_1\leqslant|\alpha_h|+1}\delta^{l-l_1-\frac{1}{2}}\big(E_-^{(k_1,l-l_1)}(z_-)\big)^{\frac{1}{2}}\cdot\sum_{k_2+l_2\leqslant N+1}\delta^{l_2+\frac{1}{2}}\big(F_+^{(k_2,l_2+1)}(z_+)\big)^{\frac{1}{2}} 	  \stackrel{\eqref{improve2}}{\lesssim} C_1\varepsilon^2,\stepcounter{equation}\tag{\theequation}\\ 	&\ \ \ \ \delta^{l+\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{I}_{+,3}^{(\beta_h,l_1)}\big\|_{L^2_tL^2_x}\\ 	&\stackrel{\text{H\""older}}{\lesssim} \delta^{l+\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\nabla_h^{|\alpha_h-\beta_h|}\partial_3^{l-l_1+1}z_-^h\big\|_{L^\infty_tL^2_x} \cdot  \Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|+1}\partial_3^{l_1}z_+\Big\|_{L^2_tL^\infty_x}\\ 	& \stackrel{\text{Lemma } \ref{lemma:sobolev}}{\lesssim}\delta^{l+\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\nabla_h^{|\alpha_h-\beta_h|}\partial_3^{l-l_1+1}z_-^h\big\|_{L^\infty_tL^2_x} \cdot \sum_{k_2+l_2\leqslant 2}\delta^{l_2-\frac{1}{2}}\Big\|\nabla_h^{k_2}\partial_3^{l_2}\Big(\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|+1}\partial_3^{l_1}z_+\Big)\Big\|_{L^2_tL^2_x}\\ 	&\stackrel{\eqref{eq:weightde}}{\lesssim} \delta^{l+\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\nabla_h^{|\alpha_h-\beta_h|}\partial_3^{l-l_1+1}z_-^h\big\|_{L^\infty_tL^2_x} \cdot \sum_{k_2+l_2\leqslant 2}\delta^{l_2-\frac{1}{2}}\Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|+1+k_2}\partial_3^{l_1+l_2}z_+\Big\|_{L^2_tL^2_x}\\ 	&\lesssim 	 \sum_{k_1\leqslant|\alpha_h|}\delta^{l-l_1+\frac{1}{2}}\big(E_-^{(k_1,l-l_1+1)}(z_-)\big)^{\frac{1}{2}}\cdot\sum_{k_2+l_2\leqslant N+2} \delta^{l_2-\frac{1}{2}}\big(F_+^{(k_2,l_2)}(z_+)\big)^{\frac{1}{2}} 	 \stackrel{\eqref{improve2}}{\lesssim} C_1\varepsilon^2.\stepcounter{equation}\tag{\theequation}  In this case, substituting \eqref{eqA5}-\eqref{eqA7} into \eqref{eqrho1} immediately gives the desired result.  \subsubsection*{\bf Case 2:  $N\leqslant|\beta_h|+l_1\leqslant|\alpha_h|+l\leqslant 2N-1$}  	However, in this case, $L^\infty_x$ estimates are not directly applicable to $\nabla_h^{|\beta_h|+1}\partial_3^{l_1} z_{+}$ in $\mathbf{I}_{+,1}^{(\beta_h,l_1)}$ as well as in $\mathbf{I}_{+,3}^{(\beta_h,l_1)}$  and $\nabla_h^{|\beta_h|}\partial_3^{l_1+1} z_{+}$ in $\mathbf{I}_{+,2}^{(\beta_h,l_1)}$ anymore. This is because $(|\beta_h|+l_1+1)+2> N+2$ and one cannot afford more than $N+2$ derivatives to close the energy estimates in flux terms.   	 Instead, we shall adapt $L^\infty_x$ estimates to $\nabla_h^{|\alpha_h-\beta_h|+1}\partial_3^{l-l_1}z_-^h$ in $\mathbf{I}_{+,1}^{(\beta_h,l_1)}$,$\nabla_h^{|\alpha_h-\beta_h|+1}\partial_3^{l-l_1}z_-$ in $\mathbf{I}_{+,2}^{(\beta_h,l_1)}$  and  $\nabla_h^{|\alpha_h-\beta_h|}\partial_3^{l-l_1+1}z_-^h$ in $\mathbf{I}_{+,3}^{(\beta_h,l_1)}$  via the Sobolev lemma as substitutes:  &\ \ \ \ \delta^{l+\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{I}_{+,1}^{(\beta_h,l_1)}\big\|_{L^2_tL^2_x}\\ &\stackrel{\text{H\""older}}{\lesssim} \delta^{l+\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\nabla_h^{|\alpha_h-\beta_h|+1}\partial_3^{l-l_1}z_-^h\big\|_{L^\infty_tL^\infty_x}\cdot \Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|+1}\partial_3^{l_1}z_+\Big\|_{L^2_tL^2_x}\\ &\stackrel{\text{Lemma } \ref{lemma:sobolev}}{\lesssim}\delta^{l+\frac{1}{2}} \sum_{k_2+l_2\leqslant 2}\delta^{l_2-\frac{1}{2}}\big\|\nabla_h^{k_2}\partial_3^{l_2}\big(\langle u_+\rangle^{1+\sigma}\nabla_h^{|\alpha_h-\beta_h|+1}\partial_3^{l-l_1}z_-^h\big)\big\|_{L^\infty_tL^2_x}\cdot \Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|+1}\partial_3^{l_1}z_+\Big\|_{L^2_tL^2_x}\\ &\stackrel{\eqref{eq:weightde}}{\lesssim}	\delta^{l+\frac{1}{2}}\sum_{k_2+l_2\leqslant 2}\delta^{l_2-\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\nabla_h^{|\alpha_h-\beta_h|+1+k_2}\partial_3^{l-l_1+l_2}z_-^h\big\|_{L^\infty_tL^2_x}\cdot \Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|+1}\partial_3^{l_1}z_+\Big\|_{L^2_tL^2_x}\\ &\lesssim \sum_{k_2+l_2\leqslant N+2}\delta^{l_2-\frac{1}{2}}\big(E_-^{(k_2,l_2)}(z_-)\big)^{\frac{1}{2}}\cdot\sum_{k_1\leqslant|\alpha_h|+1}\delta^{l_1-\frac{1}{2}}\big(F_+^{(k_1,l_1)}(z_+)\big)^{\frac{1}{2}} \stackrel{\eqref{improve2}}{\lesssim} C_1\varepsilon^2,\stepcounter{equation}\tag{\theequation}\\ &\ \ \ \ \delta^{l+\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{I}_{+,2}^{(\beta_h,l_1)}\big\|_{L^2_tL^2_x}\\ &\stackrel{\text{H\""older}}{\lesssim} \delta^{l+\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\nabla_h^{|\alpha_h-\beta_h|+1}\partial_3^{l-l_1}z_-\big\|_{L^\infty_tL^\infty_x}\cdot  \Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|}\partial_3^{l_1+1}z_+\Big\|_{L^2_tL^2_x}\\ &\stackrel{\text{Lemma } \ref{lemma:sobolev}}{\lesssim}\delta^{l+\frac{1}{2}} \sum_{k_2+l_2\leqslant 2}\delta^{l_2-\frac{1}{2}}\big\|\nabla_h^{k_2}\partial_3^{l_2}\big(\langle u_+\rangle^{1+\sigma}\nabla_h^{|\alpha_h-\beta_h|+1}\partial_3^{l-l_1}z_-\big)\big\|_{L^\infty_tL^2_x}\cdot  \Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|}\partial_3^{l_1+1}z_+\Big\|_{L^2_tL^2_x}\\ &\stackrel{\eqref{eq:weightde}}{\lesssim}\delta^{l+\frac{1}{2}}	\sum_{k_2+l_2\leqslant 2}\delta^{l_2-\frac{1}{2}} \big\|\langle u_+\rangle^{1+\sigma}\nabla_h^{|\alpha_h-\beta_h|+1+k_2}\partial_3^{l-l_1+l_2}z_-\big\|_{L^\infty_tL^2_x}\cdot  \Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|}\partial_3^{l_1+1}z_+\Big\|_{L^2_tL^2_x}\\ &\lesssim \sum_{k_2+l_2\leqslant N+2}\delta^{l_2-\frac{1}{2}}\big(E_-^{(k_2,l_2)}(z_-)\big)^{\frac{1}{2}}\cdot\sum_{k_1\leqslant|\alpha_h|}\delta^{l_1+\frac{1}{2}}\big(F_+^{(k_1,l_1+1)}(z_+)\big)^{\frac{1}{2}} \stackrel{\eqref{improve2}}{\lesssim} C_1\varepsilon^2,\stepcounter{equation}\tag{\theequation}\\ &\ \ \ \ \delta^{l+\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{I}_{+,3}^{(\beta_h,l_1)}\big\|_{L^2_tL^2_x}\\ &\stackrel{\text{H\""older}}{\lesssim} \delta^{l+\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\nabla_h^{|\alpha_h-\beta_h|}\partial_3^{l-l_1+1}z_-^h\big\|_{L^\infty_tL^\infty_x}\cdot \Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|+1}\partial_3^{l_1}z_+\Big\|_{L^2_tL^2_x}\\ &\stackrel{\text{Lemma } \ref{lemma:sobolev}}{\lesssim}\delta^{l+\frac{1}{2}} \sum_{k_2+l_2\leqslant 2}\delta^{l_2-\frac{1}{2}}\big\|\nabla_h^{k_2}\partial_3^{l_2}\big(\langle u_+\rangle^{1+\sigma}\nabla_h^{|\alpha_h-\beta_h|}\partial_3^{l-l_1+1}z_-^h\big)\big\|_{L^\infty_tL^2_x}\cdot \Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|+1}\partial_3^{l_1}z_+\Big\|_{L^2_tL^2_x}\\ &\stackrel{\eqref{eq:weightde}}{\lesssim}\delta^{l+\frac{1}{2}}\sum_{k_2+l_2\leqslant 2}\delta^{l_2-\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\nabla_h^{|\alpha_h-\beta_h|+k_2}\partial_3^{l-l_1+1+l_2}z_-^h\big\|_{L^\infty_tL^2_x}\cdot \Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|+1}\partial_3^{l_1}z_+\Big\|_{L^2_tL^2_x}\\ &\lesssim	 \sum_{k_2+l_2\leqslant N+1}\delta^{l_2+\frac{1}{2}}\big(E_-^{(k_2,l_2+1)}(z_-)\big)^{\frac{1}{2}}\cdot\sum_{k_1\leqslant|\alpha_h|+1}\delta^{l_1-\frac{1}{2}}\big(F_+^{(k_1,l_1)}(z_+)\big)^{\frac{1}{2}} \stackrel{\eqref{improve2}}{\lesssim} C_1\varepsilon^2.\stepcounter{equation}\tag{\theequation}  In this case, using \eqref{eqA8}-\eqref{eqA10} together with \eqref{eqrho1} also yields the desired result.    Finally, collecting the above two cases finishes the proof of this lemma.",2502.01139
proof,"Based on symmetry, we only need to derive bound related to $\mathbf{J}_{+}^{(\alpha_h,l)}$.  	 	Our proof starts with the observation that  	 \big|\mathbf{J}_+^{(\alpha_h,l)}\big| 		&=\big|\sum_{\beta_h\leqslant\alpha_h\atop l_1\leqslant l}\partial_h^{\alpha_h-\beta_h}\partial_3^{l-l_1}z_-\cdot \nabla\partial_h^{\beta_h}\partial_3^{l_1} z_{+}\big|\lesssim\sum_{\beta_h\leqslant\alpha_h\atop l_1\leqslant l}\big|\partial_h^{\alpha_h-\beta_h}\partial_3^{l-l_1}z_-\cdot \nabla\partial_h^{\beta_h}\partial_3^{l_1} z_{+}\big|\\ 		& 		=\sum_{\beta_h\leqslant\alpha_h\atop l_1\leqslant l}\big|\partial_h^{\alpha_h-\beta_h}\partial_3^{l-l_1}z_-^h\cdot \partial_h\partial_h^{\beta_h}\partial_3^{l_1} z_{+}+\partial_h^{\alpha_h-\beta_h}\partial_3^{l-l_1}z_-^3\cdot \partial_3\partial_h^{\beta_h}\partial_3^{l_1} z_{+}\big|\\ 		&\lesssim\sum_{\beta_h\leqslant\alpha_h\atop l_1\leqslant l}\Big(\underbrace{\big|\partial_h^{\alpha_h-\beta_h}\partial_3^{l-l_1}z_-^h\big|\cdot \big|\nabla_h^{|\beta_h|+1}\partial_3^{l_1} z_{+}\big|}_{\mathbf{J}_{+,1}^{(\beta_h,l_1)}}+\underbrace{\big|\partial_h^{\alpha_h-\beta_h}\partial_3^{l-l_1}z_-^3\big|\cdot \big|\nabla_h^{|\beta_h|}\partial_3^{l_1+1} z_{+}\big|}_{\mathbf{J}_{+,2}^{(\beta_h,l_1)}}\Big). 	 	As a result, there holds 	 		\delta^{l-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{J}_+^{(\alpha_h,l_1)}\big\|_{L^2_tL^2_x}&\lesssim \delta^{l-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{J}_{+,1}^{(\beta_h,l_1)}\big\|_{L^2_tL^2_x}\\ 		&\ \ \ \  +\delta^{l-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{J}_{+,2}^{(\beta_h,l_1)}\big\|_{L^2_tL^2_x}.\stepcounter{equation}\tag{\theequation} 	 	 Due to the number of derivatives (of $z_+$ related), we distinguish the following two cases:	 	\[|\beta_h|+l_1\leqslant N-1\ \ \text{ and }\ \ N\leqslant|\beta_h|+l_1\leqslant |\alpha_h|+l\leqslant 2N-1.\] 	\subsubsection*{\bf Case 1:  $|\beta_h|+l_1\leqslant N-1$}  	Due to $(|\beta_h|+l_1+1)+2\leqslant N+2$, we can always derive $L^\infty_x$ estimates on $\nabla_h^{|\beta_h|+1}\partial_3^{l_1} z_{+}$ in $\mathbf{J}_{+,1}^{(\beta_h,l_1)}$ and $\nabla_h^{|\beta_h|}\partial_3^{l_1+1} z_{+}$ in $\mathbf{J}_{+,2}^{(\beta_h,l_1)}$ via the Sobolev lemma. Consequently, we can  carry out the estimates as follows: 	 		&\ \ \ \ \delta^{l-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{J}_{+,1}^{(\beta_h,l_1)}\big\|_{L^2_tL^2_x}\\ 		&\stackrel{\text{H\""older}}{\lesssim}\delta^{l-\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\partial_h^{\alpha_h-\beta_h}\partial_3^{l-l_1}z_-^h\big\|_{L^\infty_tL^2_x}\Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|+1}\partial_3^{l_1} z_{+}\Big\|_{L^2_tL^\infty_x}\\ 		& \stackrel{\text{Lemma } \ref{lemma:sobolev}}{\lesssim}\delta^{l-\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\partial_h^{\alpha_h-\beta_h}\partial_3^{l-l_1}z_-^h\big\|_{L^\infty_tL^2_x} \sum_{k_2+l_2\leqslant 2}\delta^{l_2-\frac{1}{2}}\Big\|\nabla_h^{k_2}\partial_3^{l_2}\Big(\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|+1}\partial_3^{l_1} z_{+}\Big)\Big\|_{L^2_tL^2_x}\\ 		&\stackrel{\eqref{eq:weightde}}{\lesssim}\delta^{l-\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\partial_h^{\alpha_h-\beta_h}\partial_3^{l-l_1}z_-^h\big\|_{L^\infty_tL^2_x}\sum_{k_2+l_2\leqslant 2}\delta^{l_2-\frac{1}{2}}\Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|+1+k_2}\partial_3^{l_1+l_2} z_{+}\Big\|_{L^2_tL^2_x}\\ 		&\lesssim\sum_{k_1\leqslant|\alpha_h|}\delta^{l-l_1-\frac{1}{2}} \big(E_-^{(k_1,l-l_1)}(z_-^h)\big)^{\frac{1}{2}}\sum_{k_2+l_2\leqslant N+ 2}\delta^{l_2-\frac{1}{2}}\big(F_+^{(k_2,l_2)}(z_+)\big)^{\frac{1}{2}} 		\stackrel{\eqref{improve2}}{\lesssim} C_1\varepsilon^2,\stepcounter{equation}\tag{\theequation}\\ 		&\ \ \ \ \delta^{l-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{J}_{+,2}^{(\beta_h,l_1)}\big\|_{L^2_tL^2_x}\\ 		&\stackrel{\text{H\""older}}{\lesssim}\delta^{l-\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\partial_h^{\alpha_h-\beta_h}\partial_3^{l-l_1}z_-^3\big\|_{L^\infty_tL^2_x}\Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|}\partial_3^{l_1+1} z_{+}\Big\|_{L^2_tL^\infty_x}\\ 		&\stackrel{\text{Lemma } \ref{lemma:sobolev}}{\lesssim}\delta^{l-\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\partial_h^{\alpha_h-\beta_h}\partial_3^{l-l_1}z_-^3\big\|_{L^\infty_tL^2_x} \sum_{k_2+l_2\leqslant 2}\delta^{l_2-\frac{1}{2}}\Big\|\nabla_h^{k_2}\partial_3^{l_2}\Big(\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|}\partial_3^{l_1+1} z_{+}\Big)\Big\|_{L^2_tL^2_x}\\ 		&\stackrel{\eqref{eq:weightde}}{\lesssim}\delta^{l-\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\partial_h^{\alpha_h-\beta_h}\partial_3^{l-l_1}z_-^3\big\|_{L^\infty_tL^2_x}\sum_{k_2+l_2\leqslant 2}\delta^{l_2-\frac{1}{2}}\Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|+k_2}\partial_3^{l_1+1+l_2} z_{+}\Big\|_{L^2_tL^2_x}\\ 		&\lesssim\sum_{k_1\leqslant|\alpha_h|}\delta^{l-l_1-\frac{1}{2}} \big(E_-^{(k_1,l-l_1)}(z_-^3)\big)^{\frac{1}{2}}\sum_{k_2+l_2\leqslant N+ 1}\delta^{l_2-\frac{1}{2}}\big(F_+^{(k_2,l_2)}(\partial_3z_+)\big)^{\frac{1}{2}} 		\stackrel{\eqref{improve2}}{\lesssim} C_1\varepsilon^2.\stepcounter{equation}\tag{\theequation} 	 	Together with \eqref{eq:I1I2}, these two estimates \eqref{eqA1}-\eqref{eqA2} lead us to the desired result for  	this case.  	 	 	\subsubsection*{\bf Case 2:  $N\leqslant|\beta_h|+l_1\leqslant |\alpha_h|+l\leqslant 2N-1$} 	By virtue of  	$(|\beta_h|+l_1+1)+2> N+2$,  	the terms related to $z_+$ now 	cannot be controlled by the $L^\infty_x$ estimates via the  Sobolev lemma and energy flux estimates as the previous case. Likewise, we also turn our attention to $L^\infty_x$ estimates on the terms related to $z_-$ at this time: 	 		&\ \ \ \ \delta^{l-\frac{1}{2}}	\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{J}_{+,1}^{(\beta_h,l_1)}\big\|_{L^2_tL^2_x}\\ 		&\stackrel{\text{H\""older}}{\lesssim}\delta^{l-\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\partial_h^{\alpha_h-\beta_h}\partial_3^{l-l_1}z_-^h\big\|_{L^\infty_tL^\infty_x}\Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|+1}\partial_3^{l_1} z_{+}\Big\|_{L^2_tL^2_x}\\ 		& \stackrel{\text{Lemma } \ref{lemma:sobolev}}{\lesssim} \delta^{l-\frac{1}{2}}\sum_{k_2+l_2\leqslant 2}\delta^{l_2-\frac{1}{2}}\Big\|\nabla_h^{k_2}\partial_3^{l_2}\big(\langle u_+\rangle^{1+\sigma}\partial_h^{\alpha_h-\beta_h}\partial_3^{l-l_1}z_-^h\big)\Big\|_{L^\infty_tL^2_x}\Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|+1}\partial_3^{l_1} z_{+}\Big\|_{L^2_tL^2_x}\\ 		&\stackrel{\eqref{eq:weightde}}{\lesssim} \delta^{l-\frac{1}{2}}\sum_{k_2+l_2\leqslant 2}\delta^{l_2-\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\nabla_h^{|\alpha_h-\beta_h|+k_2}\partial_3^{l-l_1+l_2}z_-^h\big\|_{L^\infty_tL^2_x}\Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|+1}\partial_3^{l_1} z_{+}\Big\|_{L^2_tL^2_x}\\ 		&\lesssim \sum_{k_2+l_2\leqslant N+1}\delta^{l_2-\frac{1}{2}} \big(E_-^{(k_2,l_2)}(z_-^h)\big)^{\frac{1}{2}}\sum_{k_1\leqslant|\alpha_h|+1}\delta^{l_1-\frac{1}{2}} \big(F_+^{(k_1,l_1)}(z_+)\big)^{\frac{1}{2}} 		\stackrel{\eqref{improve2}}{\lesssim} C_1\varepsilon^2,\stepcounter{equation}\tag{\theequation}\\ 		&\ \ \ \ 	\delta^{l-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{J}_{+,2}^{(\beta_h,l_1)}\big\|_{L^2_tL^2_x}\\ 		&\stackrel{\text{H\""older}}{\lesssim}\delta^{l-\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\partial_h^{\alpha_h-\beta_h}\partial_3^{l-l_1}z_-^3\big\|_{L^\infty_tL^\infty_x}\Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|}\partial_3^{l_1+1} z_{+}\Big\|_{L^2_tL^2_x}\\ 		&\stackrel{\text{Lemma } \ref{lemma:sobolev}}{\lesssim} \delta^{l-\frac{1}{2}}\sum_{k_2+l_2\leqslant 2}\delta^{l_2-\frac{1}{2}}\Big\|\nabla_h^{k_2}\partial_3^{l_2}\big(\langle u_+\rangle^{1+\sigma}\partial_h^{\alpha_h-\beta_h}\partial_3^{l-l_1}z_-^3\big)\Big\|_{L^\infty_tL^2_x}\Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|}\partial_3^{l_1+1} z_{+}\Big\|_{L^2_tL^2_x}\\ 		&\stackrel{\eqref{eq:weightde}}{\lesssim} \delta^{l-\frac{1}{2}}\sum_{k_2+l_2\leqslant 2}\delta^{l_2-\frac{1}{2}}\big\|\langle u_+\rangle^{1+\sigma}\nabla_h^{|\alpha_h-\beta_h|+k_2}\partial_3^{l-l_1+l_2}z_-^3\big\|_{L^\infty_tL^2_x}\Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\nabla_h^{|\beta_h|}\partial_3^{l_1+1} z_{+}\Big\|_{L^2_tL^2_x}\\ 		&\lesssim\sum_{k_2+l_2\leqslant N+1}\delta^{l_2-\frac{3}{2}} \big(E_-^{(k_2,l_2)}(z_-^3)\big)^{\frac{1}{2}}\cdot\delta^{l_1+\frac{1}{2}} \big(F_+^{(|\beta_h|,l_1+1)}(z_+)\big)^{\frac{1}{2}}\\ 		&=\Big(\sum_{k_2\leqslant N+1}\delta^{-\frac{3}{2}} \big(E_-^{(k_2,0)}(z_-^3)\big)^{\frac{1}{2}}+\sum_{k_2+l_2\leqslant N+1,\ l_2-1\geqslant 0}\!\!\!\!\!\!\delta^{l_2-\frac{3}{2}} \big(E_-^{(k_2,l_2-1)}(\underbrace{\partial_3z_-^3}_{=-\partial_hz_-^h})\big)^{\frac{1}{2}}\Big)\cdot\delta^{l_1+\frac{1}{2}} \big(F_+^{(|\beta_h|,l_1+1)}(z_+)\big)^{\frac{1}{2}}\\ 		&\lesssim\Big(\sum_{k_2\leqslant N+1}\delta^{-\frac{3}{2}} \big(E_-^{(k_2,0)}(z_-^3)\big)^{\frac{1}{2}}+\sum_{k_2+1+l_2-1\leqslant N+1,\ l_2-1\geqslant 0}\!\!\!\!\!\!\delta^{l_2-\frac{3}{2}} \big(E_-^{(k_2+1,l_2-1)}(z_-^h)\big)^{\frac{1}{2}}\Big)\cdot\delta^{l_1+\frac{1}{2}} \big(F_+^{(|\beta_h|,l_1+1)}(z_+)\big)^{\frac{1}{2}}\\ 		&\lesssim\Big(\sum_{k_2\leqslant N+1}\delta^{-\frac{3}{2}} \big(E_-^{(k_2,0)}(z_-^3)\big)^{\frac{1}{2}}+\sum_{k_2+l_2\leqslant N+1}\delta^{l_2-\frac{1}{2}} \big(E_-^{(k_2,l_2)}(z_-^h)\big)^{\frac{1}{2}}\Big)\sum_{k_1\leqslant|\alpha_h|}\delta^{l_1+\frac{1}{2}} \big(F_+^{(k_1,l_1+1)}(z_+)\big)^{\frac{1}{2}} 		\stackrel{\eqref{improve2}}{\lesssim} C_1\varepsilon^2.\stepcounter{equation}\tag{\theequation} 	 	In such a case, putting the estimates \eqref{eq:I1I2} and \eqref{eqA3}-\eqref{eqA4} together also gives the desired result. 	 	 	This ends the proof in the same manner.",2502.01139
proof,"Based on symmetry, it suffices to consider $\mathbf{K}_{+}^{(\alpha_h,l)}$. We also note that  		 \big|\mathbf{K}_+^{(\alpha_h,l)}\big| 		&\lesssim\sum_{\beta_h\leqslant\alpha_h\atop l_1\leqslant l+1}\Big(\underbrace{\big|\partial_h^{\alpha_h-\beta_h}\partial_3^{l+1-l_1}z_-^h\big|\cdot \big|\nabla_h^{|\beta_h|+1}\partial_3^{l_1} z_{+}\big|}_{\mathbf{K}_{+,1}^{(\beta_h,l_1)}}+\underbrace{\big|\partial_h^{\alpha_h-\beta_h}\partial_3^{l+1-l_1}z_-^3\big|\cdot \big|\nabla_h^{|\beta_h|}\partial_3^{l_1+1} z_{+}\big|}_{\mathbf{K}_{+,2}^{(\beta_h,l_1)}}\Big). 	 Similar to \eqref{eqA3}-\eqref{eqA4}, we can infer that  	 	&\ \ \ \ \delta^{l-\frac{1}{2}}	\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{K}_{+,1}^{(\beta_h,l_1)}\big\|_{L^2_tL^2_x}\\ 	&\lesssim \sum_{k_2+l_2\leqslant N+5}\delta^{l_2-\frac{1}{2}} \big(E_-^{(k_2,l_2)}(z_-^h)\big)^{\frac{1}{2}}\sum_{k_1\leqslant|\alpha_h|+1}\delta^{l_1-\frac{1}{2}} \big(F_+^{(k_1,l_1)}(z_+)\big)^{\frac{1}{2}} 	\lesssim C_1\varepsilon^2,\\ 	&\ \ \ \ 	\delta^{l-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{K}_{+,2}^{(\beta_h,l_1)}\big\|_{L^2_tL^2_x}\\ 	&\lesssim\Big(\sum_{k_2\leqslant N+5}\delta^{-\frac{3}{2}} \big(E_-^{(k_2,0)}(z_-^3)\big)^{\frac{1}{2}}+\sum_{k_2+l_2\leqslant N+5}\delta^{l_2-\frac{1}{2}} \big(E_-^{(k_2,l_2)}(z_-^h)\big)^{\frac{1}{2}}\Big)\sum_{k_1\leqslant|\alpha_h|}\delta^{l_1-\frac{1}{2}} \big(F_+^{(k_1,l_1)}(\partial_3z_+)\big)^{\frac{1}{2}} 	\lesssim  C_1\varepsilon^2.  Therefore we can conclude from these estimates to obtain the lemma.",2502.01139
proof,"First of all, \eqref{Green1} can be rephrased as  \nabla_xG_\delta(x,y) 	&=\frac{1}{4\pi}\bigg(\sum_{k=0}+\sum_{k=1}^{\infty}+\sum_{k=-\infty}^{-1}\bigg)\nabla_x\frac{1}{\big(|x_h-y_h|^2+|(-1)^k(x_3-2k\delta)-y_3|^2\big)^{\frac{1}{2}}}\\ 	&=\frac{1}{4\pi}\bigg(\nabla_x\frac{1}{\big(|x_h-y_h|^2+|x_3-y_3|^2\big)^{\frac{1}{2}}} 	\\&\ \ \ \ \ \ \ \ \  	 +\sum_{k=1}^{\infty}\Big(\nabla_x\frac{1}{\big(|x_h-y_h|^2+|(x_{+,k})_3-y_3|^2\big)^{\frac{1}{2}}}+\nabla_x\frac{1}{\big(|x_h-y_h|^2+|(x_{-,k})_3-y_3|^2\big)^{\frac{1}{2}}}\Big)\bigg)\\ 	&=\frac{1}{4\pi}\bigg(\nabla_x\frac{1}{|x-y|}+\sum_{k=1}^{\infty}\Big(\nabla_x\frac{1}{|x_{+,k}-y|}+\nabla_x\frac{1}{|x_{-,k}-y|}\Big)\bigg),  where we denote  		x_{+,k}=\big(x_h,(-1)^k(x_3-2k\delta)\big),\ \  x_{-,k}=\big(x_h,(-1)^k(x_3+2k\delta)\big),\ \   k\in\mathbb{Z}_{\geqslant 1}.    For any $l\in\mathbb{Z}_{\geqslant 1}$,  it subsequently follows that  	  		\nabla_x^lG_\delta(x,y)=\frac{1}{4\pi}\Big(\nabla_x^l\frac{1}{|x-y|}+\sum_{k=1}^\infty\big(\nabla_x^l\frac{1}{|x_{+,k}-y|}+\nabla_x^l\frac{1}{|x_{-,k}-y|}\big)\Big). 	 By virtue of $(x,y)\in\Omega_\delta\times\Omega_\delta$, we have  $x_3,y_3\in(-\delta,\delta)$ and then  $\nabla_x^lG_\delta(x,y)$ can be bounded as follows:  	&\ \ \ \ |\nabla_x^lG_\delta(x,y)|\\ 	&\lesssim\frac{1}{4\pi}\bigg(\frac{1}{|x-y|^{l+1}}+\sum_{k=1}^\infty\Big(\frac{1}{|x_{+,k}-y|^{l+1}}+\frac{1}{|x_{-,k}-y|^{l+1}}\Big)\bigg)\\ 	&=\frac{1}{4\pi}\Bigg(\frac{1}{\big(|x_h-y_h|^2+|x_3-y_3|^2\big)^{\frac{l+1}{2}}}\\  	&\ \ \ \ \ \ \ \ +\sum_{k=1}^\infty\bigg(\frac{1}{\big(|x_h-y_h|^2+|x_3-(-1)^ky_3-2k\delta|^2\big)^{\frac{l+1}{2}}}+\frac{1}{\big(|x_h-y_h|^2+|x_3-(-1)^ky_3+2k\delta|^2\big)^{\frac{l+1}{2}}}\bigg)\Bigg)\\ 	&\leqslant\frac{1}{4\pi}\Big(\frac{1}{|x_h-y_h|^{l+1}}+\sum_{k=1}^\infty\frac{2}{\big(|x_h-y_h|^2+|(2k-1)\delta|^2\big)^{\frac{l+1}{2}}}\Big) 	\leqslant\frac{3}{4\pi}\sum_{k=0}^\infty\frac{1}{\big(|x_h-y_h|^2+|2k\delta|^2\big)^{\frac{l+1}{2}}}\\ 	&\leqslant \frac{3}{4\pi}\int_0^\infty\frac{1}{\big(|x_h-y_h|^2+|2\tau\delta|^2\big)^{\frac{l+1}{2}}}d\tau=\frac{3}{4\pi}\frac{1}{2\delta}\int_0^\infty\frac{1}{\big(|x_h-y_h|^2+|2\delta\tau|^2\big)^{\frac{l+1}{2}}}d(2\delta\tau)\\ 	&=\frac{3}{4\pi}\frac{1}{2\delta}\int_0^\infty\frac{1}{\big(|x_h-y_h|^2+(|x_h-y_h|u)^2\big)^{\frac{l+1}{2}}}d(|x_h-y_h|u)\\ 	&=\frac{3}{4\pi}\frac{1}{2\delta}\frac{1}{|x_h-y_h|^l}\int_0^\infty\frac{1}{\big(1+u^2\big)^{\frac{l+1}{2}}}du\lesssim\frac{1}{\delta}\frac{1}{|x_h-y_h|^l}.  This proves \eqref{bound of Green} for all $l\in\mathbb{Z}_{\geqslant 1}$.  Moreover, when $l=1$, this bound implies that the right hand side of \eqref{Green1} is summable, which guarantees the well-definedness of the definition  \eqref{Green1}. The proof of the lemma is now complete.",2502.01139
proof,"We start from \eqref{nabla pressure} together with the facts $\operatorname{div}z_{\pm}=0$ and the boundary conditions $z^3_{+}|_{x_3=\pm\delta}=0$, $z^3_{-}|_{x_3=\pm\delta}=0$.  	Applying derivatives $\partial_h^{\alpha_h}$ to $\nabla p$ and 	integrating by parts, we obtain 	 		\partial_h^{\alpha_h} \nabla p(\tau,x) 		&=\int_{\Omega_\delta} \partial_{x_h}^{\alpha_h} \nabla_x G_\delta(x,y)(\partial_iz_+^j\partial_jz_-^i)(\tau,y)dy 		=\int_{\Omega_\delta} \partial_i\partial_j\partial_{x_h}^{\alpha_h} \nabla_x G_\delta(x,y)(z_+^jz_-^i)(\tau,y)dy\\ 		&=(-1)^{|\alpha_h|}\int_{\Omega_\delta}\partial_i\partial_j \partial_{y_h}^{\alpha_h} \nabla_yG_\delta(x,y)(z_+^jz_-^i)(\tau,y)dy 		=-\int_{\Omega_\delta}\partial_i\partial_j G_\delta(x,y)\partial_{y_h}^{\alpha_h}\nabla_y(z_+^jz_-^i)(\tau,y)dy\\ 		&=\underbrace{-\int_{\Omega_\delta}\partial_i\partial_j G_\delta(x,y)\theta(|x_h-y_h|)\partial_{h}^{\alpha_h}\nabla(z_+^jz_-^i)(\tau,y)dy}_{\mathbf{L}_{\mathbf{1}}^{(\alpha_h,0)}(\tau,x)}\\ 		&\ \ \ \ \underbrace{-\int_{\Omega_\delta}\partial_i\partial_j G_\delta(x,y)\big(1-\theta(|x_h-y_h|)\big)\partial_{h}^{\alpha_h}\nabla(z_+^jz_-^i)(\tau,y)dy}_{\mathbf{L}_{\mathbf{2}}^{(\alpha_h,0)}(\tau,x)},\stepcounter{equation}\tag{\theequation} 	  	where the smooth cut-off function $\theta(r)$ is chosen so that 	 		\theta(r)= 			&	1,\ \ \ \ \text{for }|r|\leqslant 1,\\ 			&	0,\ \ \ \ \text{for }|r|\geqslant 2. 		 	  	In view of the property of the cut-off function $\theta(r)$, we derive  	 		\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_h^{\alpha_h}\nabla p\big\|_{L^2_tL^2_x}&\lesssim \delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{L}_{\mathbf{1}}^{(\alpha_h,0)}\big\|_{L^2_tL^2_x}\\ 		&\ \ \ \ +\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{L}_{\mathbf{2}}^{(\alpha_h,0)}\big\|_{L^2_tL^2_x}.\stepcounter{equation}\tag{\theequation} 	 	 	 	 	 	\subsubsection*{\bf Estimate of $\mathbf{L}_{\mathbf{1}}^{(\alpha_h,0)}$} 	There holds the following decomposition: 	 		\mathbf{L}_{\mathbf{1}}^{(\alpha_h,0)}(\tau,x) 		=\sum_{\beta_h\leqslant\alpha_h}C_{\alpha_h,\beta_h}\underbrace{\int_{\Omega_\delta}\partial_i\partial_j G_\delta(x,y)\theta(|x_h-y_h|)\nabla\big(\partial_{h}^{\alpha_h-\beta_h}z_+^j\partial_{h}^{\beta_h}z_-^i\big)(\tau,y)dy}_{\mathbf{L}_{\mathbf{1}}^{(\beta_h,0)}(\tau,x)}. 	 	According to the number of derivatives, we will distinguish two cases:  	\[0\leqslant|\beta_h|\leqslant N-1\ \ \text{ and }\ \ N\leqslant|\beta_h|\leqslant |\alpha_h|.\] 	\subsubsection*{\bf Case 1:  $0\leqslant|\beta_h|\leqslant N-1$} 	Thanks to the fact $\operatorname{div}z_+=0$ and the boundary condition $ z^3_{+}|_{x_3=\pm\delta}=0$, integration by parts similar to \eqref{partialp-decomposition} then yields 	 		\mathbf{L}_{\mathbf{1}}^{(\beta_h,0)}(\tau,x) 		&= \underbrace{-\int_{\Omega_\delta}\partial_i G_\delta(x,y)\theta(|x_h-y_h|)\nabla\big(\partial_{h}^{\alpha_h-\beta_h}z_+^j\partial_{h}^{\beta_h}\partial_jz_-^i\big)(\tau,y)dy}_{ \mathbf{L}_{\mathbf{11}}^{(\beta_h,0)}(\tau,x)}\\ 		&\ \ \ \   \underbrace{-\int_{\Omega_\delta}\partial_i G_\delta(x,y)\partial_j\theta(|x_h-y_h|)\nabla\big(\partial_{h}^{\alpha_h-\beta_h}z_+^j\partial_{h}^{\beta_h}z_-^i\big)(\tau,y)dy}_{ \mathbf{L}_{\mathbf{12}}^{(\beta_h,0)}(\tau,x)}.\stepcounter{equation}\tag{\theequation} 	 	Using definition, we deduce that   	 		&\ \ \ \ \delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{L}_{\mathbf{11}}^{(\beta_h,0)}(\tau,x)\big\|_{L^2_tL^2_x}\\ 		&\stackrel{\text{Lemma \ref{lemma:boundgreen}}}{\lesssim}\delta^{-\frac{1}{2}}\Big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\int_{-\delta}^{\delta}\int_{|x_h-y_h|\leqslant 2}\frac{1}{\delta}\frac{1}{|x_h-y_h|} \big|\nabla\big(\partial_{h}^{\alpha_h-\beta_h}z_+^j\partial_{h}^{\beta_h}\partial_jz_-^i\big)(\tau,y)\big|dy_hdy_3\Big\|_{L^2_tL^2_{x_h}L^2_{x_3}}\\ 		&\stackrel{\eqref{eq:weight1}}{\lesssim}\delta^{-\frac{1}{2}}\Big\|\int_{-\delta}^{\delta}\int_{|x_h-y_h|\leqslant 2}\frac{1}{\delta}\frac{1}{|x_h-y_h|} \Big(\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\big|\nabla(\partial_{h}^{\alpha_h-\beta_h}z_+^j\partial_{h}^{\beta_h}\partial_jz_-^i)\big|\Big)(\tau,y)dy_hdy_3\Big\|_{L^2_tL^2_{x_h}L^2_{x_3}}\\ 		&=\delta^{-\frac{3}{2}}\bigg(\!\int_0^t\!\int_{-\delta}^{\delta}\Big\|\!\int_{-\delta}^{\delta}\!\int_{|x_h-y_h|\leqslant 2}\!\frac{1}{|x_h-y_h|} \Big(\!\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\big|\nabla(\partial_{h}^{\alpha_h-\beta_h}z_+^j\partial_{h}^{\beta_h}\partial_jz_-^i)\big|\Big)(\tau,y)dy_hdy_3\Big\|^2_{L^2_{x_h}}\!\!dx_3d\tau\!\bigg)^{\frac{1}{2}}\\ 		&=\delta^{-\frac{3}{2}}\bigg(\int_0^t2\delta\Big\|\int_{-\delta}^{\delta}\int_{|x_h-y_h|\leqslant 2}\frac{1}{|x_h-y_h|} \Big(\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\big|\nabla(\partial_{h}^{\alpha_h-\beta_h}z_+^j\partial_{h}^{\beta_h}\partial_jz_-^i)\big|\Big)(\tau,y)dy_hdy_3\Big\|^2_{L^2_{x_h}}d\tau\bigg)^{\frac{1}{2}}\\ 		&\stackrel{\text{Minkowski}}{\lesssim}\delta^{-1}\bigg(\!\int_0^t\!\int_{-\delta}^{\delta}\Big\|\int_{|x_h-y_h|\leqslant 2}\!\frac{1}{|x_h-y_h|} \Big(\langle u_-\rangle^{1+\sigma}\!\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\big|\nabla(\partial_{h}^{\alpha_h-\beta_h}z_+^j\partial_{h}^{\beta_h}\partial_jz_-^i)\big|\Big)(\tau,y)dy_h\Big\|^2_{L^2_{x_h}}\!dy_3d\tau\!\bigg)^{\frac{1}{2}}\\ 		&\stackrel{\text{Young}}{\lesssim}\delta^{-1}\bigg(\int_0^t\int_{-\delta}^{\delta}\Big\|\frac{1}{|x_h|}\chi_{|x_h|\leqslant 2}\Big\|^2_{L^1_{x_h}} \Big\|\Big(\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\big|\nabla(\partial_{h}^{\alpha_h-\beta_h}z_+^j\partial_{h}^{\beta_h}\partial_jz_-^i)\big|\Big)(\tau,x_h,y_3)\Big\|^2_{L^2_{x_h}}dy_3d\tau\bigg)^{\frac{1}{2}}\\ 		&\lesssim\delta^{-1}\Big\|\Big(\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\big|\nabla(\partial_{h}^{\alpha_h-\beta_h}z_+^j\partial_{h}^{\beta_h}\partial_jz_-^i)\big|\Big)(\tau,x_h,y_3)\Big\|_{L^2_t L^2_{x_h}L^1_{y_3}}\\ 		&\lesssim\delta^{-1}\Big(\Big\|\Big(\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\big|\partial_{h}^{\alpha_h-\beta_h}\nabla z_+^j\partial_{h}^{\beta_h}\partial_jz_-^i\big|\Big)(\tau,x_h,y_3)\Big\|_{L^2_t L^2_{x_h}L^1_{y_3}}\\ 		&\ \ \ \ +\Big\|\Big(\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\big|\partial_{h}^{\alpha_h-\beta_h}z_+^j\partial_{h}^{\beta_h}\partial_j\nabla z_-^i\big|\Big)(\tau,x_h,y_3)\Big\|_{L^2_t L^2_{x_h}L^1_{y_3}}\Big)\\ 		&\stackrel{\text{H\""older}}{\lesssim}\delta^{-1}\Big(\big\|\langle u_+\rangle^{1+\sigma}\partial_{h}^{\beta_h}\partial_jz_-^i\big\|_{L^\infty_tL^\infty_{x_h}L^2_{x_3}}\cdot\Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\partial_{h}^{\alpha_h-\beta_h}\nabla z_+^j\Big\|_{L^2_tL^2_{x_h}L^2_{x_3}}\\ 		&\ \ \ \ +\big\|\langle u_+\rangle^{1+\sigma}\partial_{h}^{\beta_h}\partial_j\nabla z_-^i\big\|_{L^\infty_tL^\infty_{x_h}L^2_{x_3}}\cdot\Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\partial_{h}^{\alpha_h-\beta_h} z_+^j\Big\|_{L^2_tL^2_{x_h}L^2_{x_3}}\Big)\\ 		&\stackrel{\text{Sobolev (in $\mathbb{R}^2$)}}{\lesssim}\delta^{-1}\Big(\big\|\langle u_+\rangle^{1+\sigma}\partial_{h}^{\beta_h}\partial_jz_-^i\big\|_{L^\infty_tH^2_{x_h}L^2_{x_3}}\cdot\Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\partial_{h}^{\alpha_h-\beta_h}\nabla z_+^j\Big\|_{L^2_tL^2_x}\\ 		&\ \ \ \ +\big\|\langle u_+\rangle^{1+\sigma}\partial_{h}^{\beta_h}\partial_j\nabla z_-^i\big\|_{L^\infty_tH^2_{x_h}L^2_{x_3}}\cdot\Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\partial_{h}^{\alpha_h-\beta_h} z_+^j\Big\|_{L^2_tL^2_x}\Big)\\ 		&\lesssim \Big(\!\!\!\sum_{k\leqslant N+3}\!\!\!\delta^{-\frac{1}{2}}\big(E_-^{(k,0)}(z_-)\big)^{\frac{1}{2}}+\!\!\!\sum_{k\leqslant N+2}\!\!\!\delta^{-\frac{1}{2}}\big(E_-^{(k,0)}(\partial_3z_-)\big)^{\frac{1}{2}}\Big)  	 \!\!\cdot\!\!\Big(\!\!\!\sum_{k\leqslant|\alpha_h|+1}\!\!\!\delta^{-\frac{1}{2}}\big(F_+^{(k,0)}(z_+)\big)^{\frac{1}{2}}+\!\!\!\sum_{k\leqslant|\alpha_h|}\!\!\!\delta^{-\frac{1}{2}}\big(F_+^{(k,0)}(\partial_3z_+)\big)^{\frac{1}{2}}\Big)\\ 		&\stackrel{\eqref{improve2}}{\lesssim} C_1\varepsilon^2.\stepcounter{equation}\tag{\theequation} 	 	We can continue in this fashion to obtain    	 		&\ \ \ \ \delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{L}_{\mathbf{12}}^{(\beta_h,0)}(\tau,x)\big\|_{L^2_tL^2_x}\\ 		&\lesssim \Big(\!\!\!\sum_{k\leqslant N+2}\!\!\!\delta^{-\frac{1}{2}}\big(E_-^{(k,0)}(z_-)\big)^{\frac{1}{2}}+\!\!\!\sum_{k\leqslant N+1}\!\!\!\delta^{-\frac{1}{2}}\big(E_-^{(k,0)}(\partial_3z_-)\big)^{\frac{1}{2}}\Big)  		\!\! \cdot\!\!\Big(\!\!\!\sum_{k\leqslant|\alpha_h|+1}\!\!\!\delta^{-\frac{1}{2}}\big(F_+^{(k,0)}(z_+)\big)^{\frac{1}{2}}+\!\!\!\sum_{k\leqslant|\alpha_h|}\!\!\!\delta^{-\frac{1}{2}}\big(F_+^{(k,0)}(\partial_3z_+)\big)^{\frac{1}{2}}\Big)\\		&\lesssim C_1\varepsilon^2.	\stepcounter{equation}\tag{\theequation} 	 	In this case, combining \eqref{eqH1-decomposition}, \eqref{eqH11} and \eqref{eqH12}, we are able to derive 	 \delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{L}_{\mathbf{1}}^{(\beta_h,0)}(\tau,x)\big\|_{L^2_tL^2_x}\lesssim 		C_1\varepsilon^2. 	 	 	\subsubsection*{\bf Case 2: $N\leqslant|\beta_h|\leqslant |\alpha_h|$} 	By virtue of $\operatorname{div}z_-=0$ and $ z^3_{-}|_{x_3=\pm\delta}=0$,  integration by parts gives 	 		\mathbf{L}_{\mathbf{1}}^{(\beta_h,0)}(\tau,x) 		&= 		\underbrace{-\int_{\Omega_\delta}\partial_j G_\delta(x,y)\theta(|x_h-y_h|)\nabla\big(\partial_{h}^{\alpha_h-\beta_h}\partial_iz_+^j\partial_{h}^{\beta_h}z_-^i\big)(\tau,y)dy}_{\displaystyle \mathbf{L}_{\mathbf{13}}^{(\beta_h,0)}(\tau,x)}\\ 		&\ \ \ \ \underbrace{-\int_{\Omega_\delta}\partial_j G_\delta(x,y)\partial_i\theta(|x_h-y_h|)\nabla\big(\partial_{h}^{\alpha_h-\beta_h}z_+^j\partial_{h}^{\beta_h}z_-^i\big)(\tau,y)dy}_{\displaystyle \mathbf{L}_{\mathbf{14}}^{(\beta_h,0)}(\tau,x)}. 	 	In the same manner, we can see that  	 		&\ \ \ \ \delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{L}_{\mathbf{13}}^{(\beta_h,0)}(\tau,x)\big\|_{L^2_tL^2_x}\\ 		&\lesssim \Big(\!\!\!\sum_{k\leqslant |\alpha_h|+1}\!\!\!\delta^{-\frac{1}{2}}\big(E_-^{(k,0)}(z_-)\big)^{\frac{1}{2}}+\!\!\!\sum_{k\leqslant |\alpha_h|}\!\!\!\delta^{-\frac{1}{2}}\big(E_-^{(k,0)}(\partial_3z_-)\big)^{\frac{1}{2}}\Big)\!\! 		\cdot\!\!\Big(\!\sum_{k\leqslant 5}\!\delta^{-\frac{1}{2}}\big(F_+^{(k,0)}(z_+)\big)^{\frac{1}{2}}+\!\sum_{k\leqslant 4}\!\delta^{-\frac{1}{2}}\big(F_+^{(k,0)}(\partial_3z_+)\big)^{\frac{1}{2}}\Big)\\ 		&\lesssim C_1\varepsilon^2,\stepcounter{equation}\tag{\theequation} 	 	and 	 		&\ \ \ \ 	\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{L}_{\mathbf{14}}^{(\beta_h,0)}(\tau,x)\big\|_{L^2_tL^2_x}\\ 		&\lesssim \Big(\!\!\!\sum_{k\leqslant |\alpha_h|+1}\!\!\!\delta^{-\frac{1}{2}}\big(E_-^{(k,0)}(z_-)\big)^{\frac{1}{2}}+\!\!\!\sum_{k\leqslant |\alpha_h|}\delta^{-\frac{1}{2}}\big(E_-^{(k,0)}(\partial_3z_-)\big)^{\frac{1}{2}}\Big)\!\!\cdot\!\!\Big(\sum_{k\leqslant 4}\delta^{-\frac{1}{2}}\big(F_+^{(k,0)}(z_+)\big)^{\frac{1}{2}}+\sum_{k\leqslant 3}\delta^{-\frac{1}{2}}\big(F_+^{(k,0)}(\partial_3z_+)\big)^{\frac{1}{2}}\Big)\\ 		&\lesssim C_1\varepsilon^2.\stepcounter{equation}\tag{\theequation} 	 	These estimates \eqref{eqH1-decomposition}, \eqref{eqH13} and \eqref{eqH14}   	subsequently lead us to  	 		\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}	\mathbf{L}_{\mathbf{1}}^{(\beta_h,0)}(\tau,x)\big\|_{L^2_tL^2_x}\lesssim C_1\varepsilon^2. 	 	 	Thus, for all $\beta_h\leqslant\alpha_h$, by noticing $N\geqslant 5$, we conclude from \textbf{Case 1} \eqref{eqH1case1estimate} and \textbf{Case 2} \eqref{eqH1case2estimate} that  	 		\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{L}_{\mathbf{1}}^{(\beta_h,0)}(\tau,x)\big\|_{L^2_tL^2_x}  		\lesssim C_1\varepsilon^2. 	 	Summing up \eqref{eqH1estimate} for all $\beta_h\leqslant\alpha_h$, we can summarize that  	 		\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{L}_{\mathbf{1}}^{(\alpha_h,0)}(\tau,x)\big\|_{L^2_tL^2_x}  		\lesssim C_1\varepsilon^2. 	 	 	\subsubsection*{\bf Estimate of $\mathbf{L}_{\mathbf{2}}^{(\alpha_h,0)}$} 	Based on the number of derivatives, we will distinguish two cases:  	\[1\leqslant|\alpha_h|\leqslant N+2\ \ \text{ and }\ \ |\alpha_h|=0.\] 	 	\subsubsection*{\bf Case 1:  $1\leqslant |\alpha_h|\leqslant N+2$} 	 	 	We can use integration by parts to split $\mathbf{L}_{\mathbf{2}}^{(\alpha_h,0)}$ as follows:  for all $\gamma_h\leqslant\alpha_h$ with $|\gamma_h|=1$, there holds  	 		\mathbf{L}_{\mathbf{2}}^{(\alpha_h,0)}(\tau,x) 		&=-\int_{\Omega_\delta}\partial_i\partial_j G_\delta(x,y)\big(1-\theta(|x_h-y_h|)\big)\partial_{h}^{\gamma_h}\partial_{h}^{\alpha_h-\gamma_h} \nabla(z_+^jz_-^i)(\tau,y)dy\\ 		&= \underbrace{-\int_{\Omega_\delta}\partial_{h}^{\gamma_h}\partial_i\partial_j G_\delta(x,y)\big(1-\theta(|x_h-y_h|)\big)\partial_{h}^{\alpha_h-\gamma_h}\nabla(z_+^jz_-^i)(\tau,y)dy}_{\mathbf{L}_{\mathbf{21}}^{(\alpha_h-\gamma_h,0)}(\tau,x)}\\ 		&\ \ \ \ \underbrace{-\int_{\Omega_\delta}\partial_i\partial_j G_\delta(x,y)\partial_{h}^{\gamma_h}\theta(|x_h-y_h|)\partial_{h}^{\alpha_h-\gamma_h}\nabla(z_+^jz_-^i)(\tau,y)dy}_{\mathbf{L}_{\mathbf{22}}^{(\alpha_h-\gamma_h,0)}(\tau,x)}.\stepcounter{equation}\tag{\theequation} 	 	On one hand, it is evident that the integral for $y$ in  $\mathbf{L}_{\mathbf{22}}^{(\alpha_h-\gamma_h,0)}$ exists when $y\in\{|x_h-y_h|\leqslant 2\}\times(-\delta,\delta)$. We can apply the argument for $\mathbf{L}_{\mathbf{1}}^{(\alpha_h,0)}$ as \eqref{eqH1-decomposition-total}-\eqref{eqH1estimate-total} 		 again,  	with $\theta(|x_h-y_h|)$ replaced by $\partial_{y_h}^{\gamma_h}\theta(|x_h-y_h|)$ and $\alpha_h$ by $\alpha_h-\gamma_h$, to derive  	 		\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{L}_{\mathbf{22}}^{(\alpha_h-\gamma_h,0)}(\tau,x)\big\|_{L^2_tL^2_x} \lesssim C_1\varepsilon^2. 	 	On the other hand,  to evaluate  $\mathbf{L}_{\mathbf{21}}^{(\alpha_h-\gamma_h,0)}$,	we can  further decompose 	it as  	 		\mathbf{L}_{\mathbf{21}}^{(\alpha_h-\gamma_h,0)}(\tau,x) 		=\sum_{\beta_h\leqslant\alpha_h-\gamma_h}C_{\alpha_h-\gamma_h,\beta_h}\underbrace{\int_{\Omega_\delta}\partial_h^{\gamma_h}\partial_i\partial_jG_\delta(x,y)\big(1-\theta(|x_h-y_h|)\big)\nabla\big(\partial_{h}^{\alpha_h-\gamma_h-\beta_h}z_+^j\partial_{h}^{\beta_h}z_-^i\big)(\tau,y)dy}_{\mathbf{L}_{\mathbf{21}}^{(\beta_h,0)}(\tau,x)}. 	 	Every term $\mathbf{L}_{\mathbf{21}}^{(\beta_h,0)}$ therein can be handled in much the same way as $\mathbf{L}_{\mathbf{11}}^{(\beta_h,0)}$ and  $\mathbf{L}_{\mathbf{12}}^{(\beta_h,0)}$:  	 		&\ \ \ \ \delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{L}_{\mathbf{21}}^{(\beta_h,0)}(\tau,x)\big\|_{L^2_tL^2_x}\\ 		&\stackrel{\text{Lemma \ref{lemma:boundgreen}}}{\lesssim}\delta^{-\frac{1}{2}}\Big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\int_{-\delta}^{\delta}\int_{|x_h-y_h|\geqslant 1}\frac{1}{\delta}\frac{1}{|x_h-y_h|^3} \big|\nabla\big(\partial_{h}^{\alpha_h-\gamma_h-\beta_h}z_+^j\partial_{h}^{\beta_h}z_-^i\big)(\tau,y)\big|dy_hdy_3\Big\|_{L^2_tL^2_{x_h}L^2_{x_3}}\\ 		&\stackrel{\eqref{eq:weight2}}{\lesssim}\delta^{-\frac{1}{2}}\Big\|\int_{-\delta}^{\delta}\int_{|x_h-y_h|\geqslant 1}\!\frac{1}{\delta}\frac{1}{|x_h-y_h|^{3-\frac{3}{2}(1+\sigma)}} \Big(\!\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\big|\nabla\big(\partial_{h}^{\alpha_h-\gamma_h-\beta_h}z_+^j\partial_{h}^{\beta_h}z_-^i\big)\big|\Big)(\tau,y)dy_hdy_3\Big\|_{L^2_tL^2_{x_h}\!\! L^2_{x_3}}\\ 		&\stackrel{\text{Minkowski}}{\lesssim}\!\delta^{-1}\!\bigg(\!\int_0^t\!\!\int_{-\delta}^{\delta}\Big\|\!\int_{|x_h-y_h|\geqslant 1}\!\!\frac{1}{|x_h-y_h|^{3-\frac{3}{2}(1+\sigma)}} \Big(\!\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\big|\nabla\big(\partial_{h}^{\alpha_h-\gamma_h-\beta_h}\!z_+^j\partial_{h}^{\beta_h}\!z_-^i\big)\big|\Big)(\tau,y)dy_h\Big\|^2_{L^2_{x_h}}\! \! dy_3d\tau\!\!\bigg)^{\frac{1}{2}}\\ 		&\stackrel{\text{Young}}{\lesssim}\delta^{-1}\bigg(\!\!\int_0^t\!\!\int_{-\delta}^{\delta}\!\Big\|\frac{1}{|x_h|^{3-\frac{3}{2}(1+\sigma)}}\chi_{|x_h|\geqslant 1}\Big\|^2_{L^2_{x_h}}\!\!\! \Big\|\Big(\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\big|\nabla\big(\partial_{h}^{\alpha_h-\gamma_h-\beta_h}z_+^j\partial_{h}^{\beta_h}z_-^i\big)\big|\Big)(\tau,x_h,y_3)\Big\|^2_{L^1_{x_h}}\!\! dy_3d\tau\!\!\bigg)^{\frac{1}{2}}\\ 		&\lesssim \delta^{-1} \Big\|\Big(\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\big|\nabla\big(\partial_{h}^{\alpha_h-\gamma_h-\beta_h}z_+^j\partial_{h}^{\beta_h}z_-^i\big)\big|\Big)(\tau,x_h,y_3)\Big\|_{L^2_t L^1_{x_h}L^1_{y_3}}\\ 		&\stackrel{\text{H\""older}}{\lesssim}\delta^{-1}\Big(\big\|\langle u_+\rangle^{1+\sigma}\partial_{h}^{\beta_h} \nabla z_-^i\big\|_{L^\infty_tL^2_{x_h}L^2_{x_3}}\cdot\Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\partial_{h}^{\alpha_h-\gamma_h-\beta_h}z_+^j\Big\|_{L^2_tL^2_{x_h}L^2_{x_3}}\\ 		&\ \ \ \ +\big\|\langle u_+\rangle^{1+\sigma}\partial_{h}^{\beta_h} z_-^i\big\|_{L^\infty_tL^2_{x_h}L^2_{x_3}}\cdot\Big\|\frac{\langle u_-\rangle^{1+\sigma}}{\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\partial_{h}^{\alpha_h-\gamma_h-\beta_h}\nabla z_+^j\Big\|_{L^2_tL^2_{x_h}L^2_{x_3}}\Big)\\ 		&\lesssim \Big(\!\!\!\sum_{k\leqslant|\alpha_h|}\!\!\!\delta^{-\frac{1}{2}}\big(E_-^{(k,0)}(z_-)\big)^{\frac{1}{2}} +\!\!\!\sum_{k\leqslant|\alpha_h|-1}\!\!\!\delta^{-\frac{1}{2}}\big(E_-^{(k,0)}(\partial_3z_-)\big)^{\frac{1}{2}}\Big) \cdot\Big(\!\!\sum_{k\leqslant|\alpha_h|}\!\!\delta^{-\frac{1}{2}}\big(F_+^{(k,0)}(z_+)\big)^{\frac{1}{2}}+\!\!\sum_{k\leqslant|\alpha_h|-1}\!\!\delta^{-\frac{1}{2}}\big(F_+^{(k,0)}(\partial_3z_+)\big)^{\frac{1}{2}}\Big)\\ 		&\stackrel{\eqref{improve2}}{\lesssim} C_1\varepsilon^2. 	 	Consequently, we obtain  	 		\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{L}_{\mathbf{21}}^{(\alpha_h-\gamma_h,0)}(\tau,x)\big\|_{L^2_tL^2_x}\lesssim C_1\varepsilon^2. 	 	Therefore, combining \eqref{eqH2-decomposition}, \eqref{eqH22} and \eqref{eqH21} gives rise to 	 \delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{L}_{\mathbf{2}}^{(\alpha_h,0)}(\tau,x)\big\|_{L^2_tL^2_x}\lesssim C_1\varepsilon^2. 	 	 	\subsubsection*{\bf Case 2:  $|\alpha_h|=0$} 	 	Using integration by parts, we see that 	 		\mathbf{L}_{\mathbf{2}}^{(\alpha_h,0)}(\tau,x) 		&= 		\underbrace{-\int_{\Omega_\delta}\nabla\partial_i\partial_j G_\delta(x,y)\big(1-\theta(|x_h-y_h|)\big)(z_+^jz_-^i)(\tau,y)dy}_{\displaystyle \mathbf{L}_{\mathbf{23}}(\tau,x)}\\ 		&\ \ \ \ \underbrace{-\int_{\Omega_\delta}\!\!\partial_i\partial_j G_\delta(x,y)\nabla\theta(|x_h-y_h|)(z_+^jz_-^i)(\tau,y)dy}_{\displaystyle \mathbf{L}_{\mathbf{24}}(\tau,x)}. 	 	On one hand, 	by the same method used to derive  	\eqref{eqH21}, we can obtain the following estimate of $\mathbf{L}_{\mathbf{23}}$: 	 		\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{L}_{\mathbf{23}}(\tau,x)\big\|_{L^2_tL^2_x}\lesssim C_1\varepsilon^2. 	 	On the other hand, similar arguments of $\mathbf{L}_{\mathbf{1}}^{(\alpha_h,0)}$ can be applied here to $\mathbf{L}_{\mathbf{24}}$ and hence  	  		\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{L}_{\mathbf{24}}(\tau,x)\big\|_{L^2_tL^2_x}\lesssim C_1\varepsilon^2. 	 	In this case, gathering  	the above estimates together shows 	  		\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{L}_{\mathbf{2}}^{(\alpha_h,0)}(\tau,x)\big\|_{L^2_tL^2_x}\lesssim C_1\varepsilon^2. 	 	 	In consequence, for all $\alpha_h$ with $0\leqslant|\alpha_h|\leqslant N+2$, we derive from \textbf{Case 1} \eqref{eqH2estimate} and \textbf{Case 2} \eqref{eqH2estimate-case0} that  	  		\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{L}_{\mathbf{2}}^{(\alpha_h,0)}(\tau,x)\big\|_{L^2_tL^2_x}\lesssim C_1\varepsilon^2. 	 	 	 	Up to now, according to \eqref{eq:H1H2}, \eqref{eqH1estimate-total} and \eqref{eqH2estimate-total}, we obtain for all $0\leqslant|\alpha_h|\leqslant N+2$ that  	 		\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_{h}^{\alpha_h} \nabla p(\tau,x)\big\|_{L^2_tL^2_x} 		\lesssim C_1\varepsilon^2. 	 	This completes the proof of the lemma.",2502.01139
proof,"Applying the weighted div-curl lemma to  the vector field $\partial_{h}^{\alpha_h}\nabla p$ with the weight $\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}$, we have  	 		&\ \ \ \ \big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_{h}^{\alpha_h}\partial_3^l \nabla p\big\|_{L^2_x} 			\lesssim \big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\nabla^l \partial_h^{\alpha_h}\nabla p\big\|_{L^2_x}\\ 			&\stackrel{\text{Lemma \ref{lemma:divcurl}},\  \eqref{eq:weight3}}{\lesssim} 		\sum_{l_1=0}^{l-1} \big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\operatorname{div}\partial_h^{\alpha_h}\nabla^{l_1} \nabla p\big\|_{L^2_x}+\sum_{l_1=0}^{l-1} \big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\operatorname{curl}\partial_h^{\alpha_h}\nabla^{l_1} \nabla p\big\|_{L^2_x}\\ 		&\ \ \ \   		+\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_h^{\alpha_h}\nabla p\big\|_{L^2_x}\\ 		&\ \ \ \   		 +\sum_{l_1=0}^{l-1}\Big|\int_{\partial\Omega_{\delta}}\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\Big(\nabla^{l_1}\partial_h^{\alpha_h}(\nabla p)^h\cdot \nabla^{l_1}\nabla_h\partial_h^{\alpha_h}(\nabla p)^3-\nabla^{l_1}\partial_h^{\alpha_h}(\nabla p)^3\cdot \nabla^{l_1}\nabla_h\partial_h^{\alpha_h}(\nabla p)^h\Big)dx_h\Big|. 	 For the terms on the right hand side, we notice that   &\operatorname{div}\partial_h^{\alpha_h}\nabla^{l_1} \nabla p=\partial_h^{\alpha_h}\nabla^{l_1}\underbrace{\operatorname{div}\nabla p}_{=\Delta p}  \stackrel{\eqref{eqpressure-system}_1}{=}-\partial_h^{\alpha_h}\nabla^{l_1}(\nabla z_+\cdot \nabla z_-),\\ &\operatorname{curl}\partial_h^{\alpha_h}\nabla^{l_1} \nabla p=\partial_h^{\alpha_h}\nabla^{l_1}\underbrace{\operatorname{curl}\nabla p}_{=0}=0,\\ &(\nabla p)^3\big|_{\partial\Omega_{\delta}}=(\nabla p)^3\big|_{x_3=\pm\delta}\stackrel{\eqref{MHD equation}_1}{=}-\big(\partial_tz_++(z_--B_0)\cdot \nabla z_+\big)^3\big|_{x_3=\pm\delta}\stackrel{\eqref{MHD equation}_4}{=}0.  Hence we obtain  	&\ \ \ \ \big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_{h}^{\alpha_h}\partial_3^l \nabla p\big\|_{L^2_x}\\ 	&\lesssim\sum_{l_1=0}^{l-1} \big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_h^{\alpha_h}\nabla^{l_1} (\nabla z_+\cdot \nabla z_-)\big\|_{L^2_x}+\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_h^{\alpha_h}\nabla p\big\|_{L^2_x}.  It then follows that  		 			&\ \ \ \ \delta^{l-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_{h}^{\alpha_h}\partial_3^l \nabla p\big\|_{L^2_x}\\ 			&\lesssim\sum_{|\alpha_h'|+l_1\leqslant l-1}\delta^{l_1+\frac{1}{2}} \big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_h^{\alpha_h}\partial_h^{\alpha_h'}\partial_3^{l_1} (\nabla z_+\cdot \nabla z_-)\big\|_{L^2_x}+\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_h^{\alpha_h}\nabla p\big\|_{L^2_x}\\ 			&\stackrel{\text{Lemmas  \ref{lemma1} \&  \ref{lemma:H}}}{\lesssim}C_1\varepsilon^2. 	 We have thus proved this lemma.",2502.01139
proof,"The almost same reasoning used in Lemma \ref{lemma:HH} applies to this lower order coefficient case. Hence we have  	&\ \ \ \ \big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_{h}^{\alpha_h}\partial_3^l\partial_3 \nabla p\big\|_{L^2_x}\\ 	&\lesssim \sum_{l_1=0}^{l} \big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_h^{\alpha_h}\nabla^{l_1} (\nabla z_+\cdot \nabla z_-)\big\|_{L^2_x}+\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_h^{\alpha_h}\nabla p\big\|_{L^2_x},  which together with Lemma \ref{lemma1} and Lemma \ref{lemma:H}  implies that  	 	&\ \ \ \ \delta^{l-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_{h}^{\alpha_h}\partial_3^l\partial_3 \nabla p\big\|_{L^2_x}\\ 	&\lesssim\sum_{|\alpha_h'|+l_1\leqslant l}\delta^{l_1+\frac{1}{2}} \big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_h^{\alpha_h}\partial_h^{\alpha_h'}\partial_3^{l_1} (\nabla z_+\cdot \nabla z_-)\big\|_{L^2_x}+\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_h^{\alpha_h}\nabla p\big\|_{L^2_x} 	\lesssim C_1\varepsilon^2.  This proves the lemma.",2502.01139
proof,"By symmetry, it suffices to show that $\delta^{-\frac{1}{2}}z_{+}(\infty;u_-,x_2,x_3)$ is well-defined.   Using the fact $\langle u_-\rangle\geqslant 1$ and the standard Sobolev inequality in $\mathbb{R}^4$, we have   &\ \ \ \ \delta^{-\frac{1}{2}}\langle u_-\rangle^{\frac{1}{2}(1+\sigma)}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)} |\nabla p|\\ &\lesssim\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)} \nabla p\big\|_{L^\infty_{t,x}}\\ &\lesssim\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)} \nabla p\big\|_{L^2_{t,x}}+\delta^{-\frac{1}{2}}\big\|\nabla^3(\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)} \nabla p)\big\|_{L^2_{t,x}}\\ &\stackrel{\eqref{eq:weight3}}{\lesssim}\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)} \nabla p\big\|_{L^2_{t,x}}+\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)} \nabla^3 \nabla p\big\|_{L^2_{t,x}}\\ &\lesssim \sum_{0\leqslant|\alpha_h|\leqslant 3\atop 0\leqslant l\leqslant 3}\delta^{l-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_{h}^{\alpha_h}\partial_3^l \nabla p\big\|_{L^2_tL^2_x} \stackrel{\text{Lemma \ref{lemma:HH'}}}{\lesssim}C_1\varepsilon^2,\\ 	&\ \ \ \ \delta^{-\frac{1}{2}}\langle u_-\rangle^{\frac{1}{2}(1+\sigma)}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)} |z_-\cdot\nabla z_+|\\ 	&\lesssim \delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)} (z_-\cdot\nabla z_+)\big\|_{L^\infty_{t,x}}\\ 	&\lesssim\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)} (z_-\cdot\nabla z_+)\big\|_{L^2_{t,x}}+\delta^{-\frac{1}{2}}\big\|\nabla^3(\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)} (z_-\cdot\nabla z_+))\big\|_{L^2_{t,x}}\\ 	&\stackrel{\eqref{eq:weight3}}{\lesssim}\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)} (z_-\cdot\nabla z_+)\big\|_{L^2_{t,x}}+\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)} \nabla^3 (z_-\cdot\nabla z_+)\big\|_{L^2_{t,x}}\\ 	&\lesssim 	\sum_{0\leqslant|\alpha_h|\leqslant 3\atop 0\leqslant l\leqslant 3}\delta^{l-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_{h}^{\alpha_h}\partial_3^l (z_-\cdot\nabla z_+)\big\|_{L^2_tL^2_x} 	\stackrel{\text{Lemma \ref{lemma2}}}{\lesssim}C_1\varepsilon^2.  Combined with \eqref{eq:product}, these two estimates lead us to   \delta^{-\frac{1}{2}}|\nabla p+z_-\cdot \nabla z_+|\lesssim\frac{C_1\varepsilon^2}{\langle u_-\rangle^{\frac{1}{2}(1+\sigma)}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}}\lesssim\frac{C_1\varepsilon^2}{(1+|t+a|)^{1+\sigma}}\in L_t^1(\mathbb{R}).  Therefore the integral in \eqref{eq:def-sca} converges and hence $\delta^{-\frac{1}{2}}z_{+}(\infty;u_-,x_2,x_3)$ is well-defined.",2502.01139
proof,"Based on the symmetry, it suffices to derive the estimates on $z_{+}(\infty;u_-,x_2,x_3)$. 	 Firstly, by \eqref{improve2}, we note that   	&\ \ \ \ \big\|\delta^{-\frac{1}{2}}z_+(0,u_-,x_2,x_3)\big\|_{L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\ 	&	= \delta^{-\frac{1}{2}}\big\|z_+(0,u_-,x_2,x_3)\big\|_{L^2(\Omega_\delta,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)} 	=\delta^{-\frac{1}{2}}E_+^{(0,0)}(z_{+,0}) 	\lesssim  \varepsilon,  which shows    \delta^{-\frac{1}{2}}z_{+}(0,u_-,x_2,x_3)\in L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3).  We also note that for any large $T>0$, \eqref{improve2} gives  	\delta^{-\frac{1}{2}}z_{+}(\infty;u_-,x_2,x_3)-\delta^{-\frac{1}{2}}z_{+}(T,u_--T,x_2,x_3)=-\delta^{-\frac{1}{2}}\int_T^{\infty}(\nabla p+z_{-}\cdot\nabla z_{+})(\tau,u_--\tau,x_2,x_3)d\tau.   Secondly, using coordinate transformations (which allow us to perform the analysis on spacetimes) and H\""older inequality, we obtain  	&\ \ \ \ \Big\|\delta^{-\frac{1}{2}}\int_0^{\infty}  (\nabla p+z_{-}\cdot\nabla z_{+})  	(\tau,u_--\tau,x_2,x_3)d\tau\Big\|_{L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\ 	& 	\lesssim\delta^{-\frac{1}{2}}\Big\|\Big(\int_{\mathbb{R}}\frac{1}{\langle u_+\rangle^{1+\sigma}}du_+\Big)^{\frac{1}{2}}\Big(\int_{\mathbb{R}}\langle u_+\rangle^{1+\sigma} |(\nabla p+z_{-}\cdot\nabla z_{+})  	(u_+,u_-,x_2,x_3)|^2du_+\Big)^{\frac{1}{2}}\Big\|_{L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\ 	&\lesssim\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)} (\nabla p+z_{-}\cdot\nabla z_{+})  	(u_+,u_-,x_2,x_3)\big\|_{L^2(\mathbb{R}\times\Omega_\delta,du_+du_-dx_2dx_3)}\\ 	&\lesssim\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)} \nabla p\big\|_{L^2_tL^2_x}+\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}(z_-\cdot \nabla z_+)\big\|_{L^2_tL^2_x} 	\stackrel{\text{Lemmas \ref{lemma:H} \& \ref{lemma2}}}{\lesssim}C_1\varepsilon^2. 	 This implies   	\delta^{-\frac{1}{2}}\int_0^{\infty} (\nabla p+z_{-}\cdot\nabla z_{+})  	(\tau,u_--\tau,x_2,x_3)d\tau\in L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3),  and  \lim_{T\to \infty}\Big\|\delta^{-\frac{1}{2}}\int_T^{\infty}  (\nabla p+z_{-}\cdot\nabla z_{+})  (\tau,u_--\tau,x_2,x_3)d\tau\Big\|_{L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}=0.   Finally, putting \eqref{eq:def-sca}, \eqref{eq:lemma1-14} and \eqref{eq:lemma1} together yields \eqref{eq1}, while \eqref{eq:def-large} and \eqref{eq:lemma1'} give rise to  \eqref{eq2}.",2502.01139
proof,"By the symmetry considerations, we only give details for the estimates on $z_{+}(\infty;u_-,x_2,x_3)$. 		 Applying the derivative $	\partial_h^{\alpha_h}$ to 	\eqref{eq:def-sca}-\eqref{eq:def-large}, we have  	 		\delta^{-\frac{1}{2}}\partial_h^{\alpha_h} z_{+}(\infty;u_-,x_2,x_3)=\delta^{-\frac{1}{2}}\partial_h^{\alpha_h} z_{+}(0,u_-,x_2,x_3)-\delta^{-\frac{1}{2}}\partial_h^{\alpha_h}\int_0^{\infty} (\nabla p+z_{-}\cdot\nabla z_{+})  			(\tau,u_--\tau,x_2,x_3)d\tau, 	 and  	\delta^{-\frac{1}{2}}\partial_h^{\alpha_h} z_{+}(\infty;u_-,x_2,x_3)-\delta^{-\frac{1}{2}}\partial_h^{\alpha_h} z_{+}(T,u_--T,x_2,x_3)=-\delta^{-\frac{1}{2}}\partial_h^{\alpha_h}\int_T^{\infty} (\nabla p+z_{-}\cdot\nabla z_{+})  	(\tau,u_--\tau,x_2,x_3)d\tau.  It is clear from \eqref{improve2} that   &\ \ \ \ 	\big\|\delta^{-\frac{1}{2}}\partial_h^{\alpha_h}z_+(0,u_-,x_2,x_3)\big\|_{L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\ &	= \delta^{-\frac{1}{2}}\big\|\partial_h^{\alpha_h}z_+(0,u_-,x_2,x_3)\big\|_{L^2(\Omega_\delta,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)} =\delta^{-\frac{1}{2}}E_+^{(|\alpha_h|,0)}(z_{+,0}) \lesssim  	\varepsilon,  which means   \delta^{-\frac{1}{2}}\partial_h^{\alpha_h} z_{+}(0,u_-,x_2,x_3)\in L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3).  Therefore it suffices to show that   \delta^{-\frac{1}{2}}\partial_h^{\alpha_h}\int_0^{\infty} (\nabla p+z_{-}\cdot\nabla z_{+})  (\tau,u_--\tau,x_2,x_3)d\tau\in L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3),  and   	\lim_{T\to \infty}\Big\|\delta^{-\frac{1}{2}}\partial_h^{\alpha_h}\int_T^{\infty}  (\nabla p+z_{-}\cdot\nabla z_{+})  	(\tau,u_--\tau,x_2,x_3)d\tau\Big\|_{L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}=0.   The rest of this proof is divided into four steps.   \subsubsection*{\bf Step 1:} We first prove that   \delta^{-\frac{1}{2}}\int_0^{\infty} \partial_h^{\alpha_h}(\nabla p+z_{-}\cdot\nabla z_{+})  (\tau,u_--\tau,x_2,x_3)d\tau\in L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3).    In fact,  this can also be proved via coordinate transformations and H\""older inequality:  &\ \ \ \ \Big\|\delta^{-\frac{1}{2}}\int_0^{\infty} \partial_h^{\alpha_h}(\nabla p+z_{-}\cdot\nabla z_{+})  (\tau,u_--\tau,x_2,x_3)d\tau\Big\|_{L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\ & \lesssim\delta^{-\frac{1}{2}}\Big\|\Big(\!\!\int_{\mathbb{R}}\frac{1}{\langle u_+\rangle^{1+\sigma}}du_+\!\Big)^{\!\frac{1}{2}}\Big(\!\!\int_{\mathbb{R}}\langle u_+\rangle^{1+\sigma} |\partial_h^{\alpha_h}(\nabla p+z_{-}\cdot\nabla z_{+})  (u_+,u_-,x_2,x_3)|^2du_+\!\Big)^{\!\frac{1}{2}}\Big\|_{L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\ &\lesssim\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)} \partial_h^{\alpha_h}(\nabla p+z_{-}\cdot\nabla z_{+})  (u_+,u_-,x_2,x_3)\big\|_{L^2(\mathbb{R}\times\Omega_\delta,du_+du_-dx_2dx_3)}\\ &\lesssim\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_{h}^{\alpha_h} \nabla p\big\|_{L^2_tL^2_x}+\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{J}_+^{(\alpha_h,0)}\big\|_{L^2_tL^2_x}\!\!\!\!\!\!\! \stackrel{\text{Lemmas \ref{lemma:H} \&  \ref{lemma2}}}{\lesssim}\!\!\!\!\! C_1\varepsilon^2.\stepcounter{equation}\tag{\theequation} 	     \subsubsection*{\bf Step 2:} We next prove that for any $\gamma_h\leqslant\alpha_h$ with $|\gamma_h|=1$,  there holds   \delta^{-\frac{1}{2}}\partial_h^{\gamma_h}\int_0^{\infty} \partial_h^{\alpha_h-\gamma_h}(\nabla p+z_{-}\cdot\nabla z_{+})  (\tau,u_--\tau,x_2,x_3)d\tau\in L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3).     In this step,  	we only consider the case where  	the outermost derivative of the above term  	is taken as  $\partial_h^{\gamma_h}=\partial_{1}$, and the $\partial_{2}$ case can be treated in the same way.   	Now it suffices to show that  	 	\delta^{-\frac{1}{2}}\partial_{1}\int_0^{\infty} \partial_h^{\alpha_h-\gamma_h}(\nabla p+z_{-}\cdot\nabla z_{+})  	(\tau,u_--\tau,x_2,x_3)d\tau\in L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3). 	  In fact, by definition, we  deduce that  	 	&\ \ \ \ \Big\|\delta^{-\frac{1}{2}}\partial_{1} \int_0^{\infty}\partial_h^{\alpha_h-\gamma_h}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_--\tau,x_2,x_3)d\tau \Big\|_{L^2(\mathcal{C}_+,\langle u_{-}\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\ 	&=\delta^{-\frac{1}{2}}\Big\|\lim_{h\to 0} \int_0^{\infty}\frac{1}{h}\big(\partial_h^{\alpha_h-\gamma_h}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_-+h-\tau,x_2,x_3)\\ 	&\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  -\partial_h^{\alpha_h-\gamma_h}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_--\tau,x_2,x_3)\big) 	d\tau \Big\|_{L^2(\mathcal{C}_+,\langle u_{-}\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\ 	&\stackrel{\text{Fatou}}{\leqslant}\delta^{-\frac{1}{2}}\liminf_{h\to 0}\Big\| \int_0^{\infty}\frac{1}{h}\big(\partial_h^{\alpha_h-\gamma_h}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_-+h-\tau,x_2,x_3)\\ 	&\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  -\partial_h^{\alpha_h-\gamma_h}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_--\tau,x_2,x_3)\big) 	d\tau \Big\|_{L^2(\mathcal{C}_+,\langle u_{-}\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\ 	&\stackrel{\text{Newton-Leibniz}}{\leqslant}\!\!\!\!\!\delta^{-\frac{1}{2}}\liminf_{h\to 0}\Big\|\!\! \int_0^{\infty}\!\!\!\int_0^1\!\!\partial_{1}\partial_h^{\alpha_h-\gamma_h}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_-+\theta h-\tau,x_2,x_3)d\theta d\tau \Big\|_{L^2(\mathcal{C}_+,\langle u_{-}\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\ 	&\leqslant\delta^{-\frac{1}{2}}\liminf_{h\to 0}\Big\|\int_0^1 \int_0^{\infty}\partial_{1}\partial_h^{\alpha_h-\gamma_h}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_-+\theta h-\tau,x_2,x_3)d\tau d\theta  \Big\|_{L^2(\mathcal{C}_+,\langle u_{-}\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\ 	&\leqslant\delta^{-\frac{1}{2}}\liminf_{h\to 0}\int_0^1\Big\| \int_0^{\infty}\partial_{1}\partial_h^{\alpha_h-\gamma_h}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_-+\theta h-\tau,x_2,x_3)d\tau  \Big\|_{L^2(\mathcal{C}_+,\langle u_{-}\rangle^{2(1+\sigma)}du_-dx_2dx_3)}d\theta \\ 	&\stackrel{\text{set }U_-=u_-+\theta h}{\leqslant}\!\!\delta^{-\frac{1}{2}}\liminf_{h\to 0}\int_0^1\Big\|\! \int_0^{\infty}\!\!\partial_{1}\partial_h^{\alpha_h-\gamma_h}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,U_--\tau,x_2,x_3)d\tau  \Big\|_{L^2(\mathcal{C}_+,\langle u_{-}\rangle^{2(1+\sigma)}dU_-dx_2dx_3)}d\theta\\ 	&\leqslant \Big\|\delta^{-\frac{1}{2}}\int_0^{\infty} \partial_h^{\alpha_h}(\nabla p+z_{-}\cdot\nabla z_{+})  	(\tau,u_--\tau,x_2,x_3)d\tau\Big\|_{L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)} 	\stackrel{\eqref{eq:lemma1-7}}{\lesssim} C_1\varepsilon^2. 	  Hence \eqref{eq:lemma1-1} holds and therefore \eqref{eq:lemma1-8} follows.    \subsubsection*{\bf Step 3:} We turn to prove that for any $\gamma_h\leqslant\alpha_h$ with $|\gamma_h|=1$, as vector fields in $L^2(\mathcal{C}_+,\langle u_{-}\rangle^{2(1+\sigma)} du_-dx_2dx_3)$,  there holds  	 	&  	\delta^{-\frac{1}{2}}\partial_h^{\gamma_h}\int_0^{\infty} \partial_h^{\alpha_h-\gamma_h}(\nabla p+z_{-}\cdot\nabla z_{+})  	(\tau,u_--\tau,x_2,x_3)d\tau\\ 	&\stackrel{ L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}{=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=}\delta^{-\frac{1}{2}}\int_0^{\infty} \partial_h^{\alpha_h}(\nabla p+z_{-}\cdot\nabla z_{+})  	(\tau,u_--\tau,x_2,x_3)d\tau.\stepcounter{equation}\tag{\theequation}      In view of \eqref{eq:lemma1-6} and \eqref{eq:lemma1-8}, it suffices to show the following equation in the sense of distributions:  	\delta^{-\frac{1}{2}}\partial_h^{\gamma_h}\int_0^{\infty} \partial_h^{\alpha_h-\gamma_h}(\nabla p+z_{-}\cdot\nabla z_{+})  	(\tau,u_--\tau,x_2,x_3)d\tau 	\stackrel{ \mathcal{D}'(\mathcal{C}_+)}{=\joinrel=\joinrel=\joinrel=}\delta^{-\frac{1}{2}}\int_0^{\infty}  \partial_h^{\alpha_h}(\nabla p+z_{-}\cdot\nabla z_{+})  	(\tau,u_--\tau,x_2,x_3)d\tau.     Based on \eqref{eq:lemma1} and \eqref{eq:lemma1-6},   both the two time integrals in \eqref{eq:lemma1-2} are locally integrable functions.  Let us take an arbitrary vector field $\varphi\in \mathcal{D}(\mathcal{C}_+)$. It is clear that $\varphi\in \mathcal{D}(\mathcal{C}_+)\subset L^2(\mathcal{C}_+)$, which also gives  $\partial_{h}^{\gamma_h}\varphi\in \mathcal{D}(\mathcal{C}_+)\subset L^2(\mathcal{C}_+)$.  These facts enable us to infer that the following two spacetime integrals are finite:  	&\ \ \ \ 	\delta^{-\frac{1}{2}}\int_{[0,\infty)\times \mathcal{C}_+}\big| \partial_h^{\alpha_h-\gamma_h}(\nabla p+z_{-}\cdot\nabla z_{+})  	(\tau,u_--\tau,x_2,x_3)\cdot\partial_{h}^{\gamma_h}\varphi(u_-,x_2,x_3)\big|d\tau du_-dx_2dx_3\\ 	&\lesssim \delta^{-\frac{1}{2}}\int_{\mathbb{R}\times\mathcal{C}_+}\big|\partial_h^{\alpha_h-\gamma_h}(\nabla p+z_{-}\cdot\nabla z_{+})  	(u_+,u_-,x_2,x_3)\big|\cdot|\partial_{h}^{\gamma_h}\varphi(u_-,x_2,x_3)|du_+du_-dx_2dx_3\\ 	&\lesssim 	\delta^{-\frac{1}{2}}\Big(\int_{\mathbb{R}\times \mathcal{C}_+}\langle  u_+\rangle^{1+\sigma}\big|\partial_h^{\alpha_h-\gamma_h}(\nabla p+z_{-}\cdot\nabla z_{+})  	(u_+,u_-,x_2,x_3)\big|^2 \Big)^{\frac{1}{2}} 	\Big(\int_{\mathbb{R}\times \mathcal{C}_+}\frac{|\partial_{h}^{\gamma_h}\varphi(u_-,x_2,x_3)|^2}{\langle u_+\rangle^{1+\sigma}}\Big)^{\frac{1}{2}}\\ 	&\lesssim\delta^{-\frac{1}{2}}\Big(\int_{\mathbb{R}\times \mathcal{C}_+}\langle u_-\rangle^{2(1+\sigma)}\langle u_+\rangle^{1+\sigma}\big|\partial_h^{\alpha_h-\gamma_h}(\nabla p+z_{-}\cdot\nabla z_{+}) (u_+,u_-,x_2,x_3)\big|^2\Big)^{\frac{1}{2}}\\ 	&\ \ \ \ \times \Big(\int_{\mathbb{R}}\frac{1}{\langle u_+\rangle^{1+\sigma}}\Big(\int_{\mathcal{C}_+} |\partial_{h}^{\gamma_h} \varphi(u_-,x_2,x_3)|^2  du_-dx_2dx_3 \Big)du_+\Big)^{\frac{1}{2}}\\ 	&\lesssim\varepsilon^2\|\partial_{h}^{\gamma_h}\varphi\|_{L^2}<\infty,\stepcounter{equation}\tag{\theequation}\\ 	&\ \ \ \ 	\delta^{-\frac{1}{2}}\int_{[0,\infty)\times \mathcal{C}_+}\big| \partial_h^{\alpha_h}(\nabla p+z_{-}\cdot\nabla z_{+})  	(\tau,u_--\tau,x_2,x_3)\cdot\varphi(u_-,x_2,x_3)\big|d\tau du_-dx_2dx_3\\ 	&\lesssim \delta^{-\frac{1}{2}}\int_{\mathbb{R}\times\mathcal{C}_+}\big|\partial_h^{\alpha_h}(\nabla p+z_{-}\cdot\nabla z_{+})  	(u_+,u_-,x_2,x_3)\big|\cdot|\varphi(u_-,x_2,x_3)|du_+du_-dx_2dx_3\\ 	&\lesssim 	\delta^{-\frac{1}{2}}\Big(\int_{\mathbb{R}\times \mathcal{C}_+}\langle  u_+\rangle^{1+\sigma}\big|\partial_h^{\alpha_h}(\nabla p+z_{-}\cdot\nabla z_{+})  	(u_+,u_-,x_2,x_3)\big|^2 \Big)^{\frac{1}{2}} 	\Big(\int_{\mathbb{R}\times \mathcal{C}_+}\frac{|\varphi(u_-,x_2,x_3)|^2}{\langle u_+\rangle^{1+\sigma}}\Big)^{\frac{1}{2}}\\ 	&\lesssim\delta^{-\frac{1}{2}}\Big(\int_{\mathbb{R}\times \mathcal{C}_+}\langle u_-\rangle^{2(1+\sigma)}\langle u_+\rangle^{1+\sigma}\big|\partial_h^{\alpha_h}(\nabla p+z_{-}\cdot\nabla z_{+}) (u_+,u_-,x_2,x_3)\big|^2\Big)^{\frac{1}{2}}\\ 	&\ \ \ \ \times \Big(\int_{\mathbb{R}}\frac{1}{\langle u_+\rangle^{1+\sigma}}\Big(\int_{\mathcal{C}_+} \varphi(u_-,x_2,x_3)|^2  du_-dx_2dx_3 \Big)du_+\Big)^{\frac{1}{2}}\\ 	&\lesssim\varepsilon^2\|\varphi\|_{L^2}<\infty.\stepcounter{equation}\tag{\theequation}  We remark here that the estimates \eqref{eq:lemma1-3}-\eqref{eq:lemma1-4} will ensure the subsequent applications of Fubini's theorem to commute the order of integrals.       Using the above estimates, integration by parts and Fubini's theorem repeatedly, we then derive in the sense of distributions that  	 	&\ \ \ \  \Big\langle \delta^{-\frac{1}{2}}\partial_{h}^{\gamma_h}\int_0^{\infty}\partial_h^{\alpha_h-\gamma_h}(\nabla p+z_{-}\cdot\nabla z_{+})  		(\tau,u_--\tau,x_2,x_3)d\tau,\ \varphi(u_-,x_2,x_3)\Big\rangle\\ 		&=-\delta^{-\frac{1}{2}}\Big\langle\int_0^{\infty}\partial_h^{\alpha_h-\gamma_h}(\nabla p+z_{-}\cdot\nabla z_{+})  		(\tau,u_--\tau,x_2,x_3)d\tau,\  \partial_{h}^{\gamma_h} \varphi(u_-,x_2,x_3)\Big\rangle\\ 		&=-\delta^{-\frac{1}{2}}\int_{\mathcal{C}_+}\Big(\int_0^{\infty}\partial_h^{\alpha_h-\gamma_h}(\nabla p+z_{-}\cdot\nabla z_{+})  		(\tau,u_--\tau,x_2,x_3)d\tau\Big)\cdot \partial_{h}^{\gamma_h}\varphi(u_-,x_2,x_3)du_-dx_2dx_3\\ 		&\stackrel{  		\eqref{eq:lemma1-3}}{=}-\delta^{-\frac{1}{2}}\int_{[0,\infty) \times \mathcal{C}_+}\partial_h^{\alpha_h-\gamma_h}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_--\tau,x_2,x_3)\cdot \partial_{h}^{\gamma_h}\varphi(u_-,x_2,x_3)d\tau du_-dx_2dx_3\\ 		&=-\delta^{-\frac{1}{2}}\int_{[0,\infty)} \Big(\int_{\mathcal{C}_+}\partial_h^{\alpha_h-\gamma_h}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_--\tau,x_2,x_3)\cdot \partial_{h}^{\gamma_h}\varphi(u_-,x_2,x_3)du_-dx_2dx_3\Big)d\tau \\ 		&=\delta^{-\frac{1}{2}}\int_{[0,\infty)} \Big(\int_{\mathcal{C}_+}\partial_h^{\alpha_h}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_--\tau,x_2,x_3)\cdot \varphi(u_-,x_2,x_3)du_-dx_2dx_3\Big)d\tau \\ 		&=\delta^{-\frac{1}{2}}\int_{[0,\infty)\times \mathcal{C}_+}\partial_h^{\alpha_h}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_--\tau,x_2,x_3)\cdot \varphi(u_-,x_2,x_3)du_-dx_2dx_3d\tau\\ 		&\stackrel{  		\eqref{eq:lemma1-4}}{=}\delta^{-\frac{1}{2}}\int_{\mathcal{C}_+}\Big(\int_{0}^{\infty} \partial_h^{\alpha_h}(\nabla p+z_{-}\cdot\nabla z_{+})(\tau,u_--\tau,x_2,x_3)d\tau\Big)\cdot \varphi(u_-,x_2,x_3)du_-dx_2dx_3\\ 		&=\Big\langle\delta^{-\frac{1}{2}}\int_0^{\infty}  \partial_h^{\alpha_h}(\nabla p+z_{-}\cdot\nabla z_{+})(\tau,u_--\tau,x_2,x_3)d\tau,\ \varphi(u_-,x_2,x_3)\Big\rangle. 	 This implies \eqref{eq:lemma1-2} immediately. Thus we have proved \eqref{eq:lemma1-9}.      \subsubsection*{\bf Step 4:} We are now ready to show \eqref{eq:lemma1-5} and \eqref{eq:lemma1-5'}.  By induction on $\alpha_h$,  we obtain that the following equation holds in the sense of  weighted $L^2$ space $L^2(\mathcal{C}_+,\langle u_{-}\rangle^{2(1+\sigma)} du_-dx_2dx_3)$ as an immediate consequence of  \eqref{eq:lemma1-9}:  	&  	\delta^{-\frac{1}{2}}\partial_h^{\alpha_h}\int_0^{\infty}(\nabla p+z_{-}\cdot\nabla z_{+})  	(\tau,u_--\tau,x_2,x_3)d\tau\\ 	&\stackrel{ L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}{=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=}\delta^{-\frac{1}{2}}\int_0^{\infty} \partial_h^{\alpha_h}(\nabla p+z_{-}\cdot\nabla z_{+})  	(\tau,u_--\tau,x_2,x_3)d\tau.\stepcounter{equation}\tag{\theequation}  This proves \eqref{eq:lemma1-5}.   Moreover, by \eqref{eq:lemma1-10} and \eqref{eq:lemma1-7}, there holds   &\ \ \ \ \Big\|\delta^{-\frac{1}{2}}\partial_h^{\alpha_h}\int_0^{\infty} (\nabla p+z_{-}\cdot\nabla z_{+})  (\tau,u_--\tau,x_2,x_3)d\tau\Big\|_{L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\ &=\Big\|\delta^{-\frac{1}{2}}\int_0^{\infty} \partial_h^{\alpha_h}(\nabla p+z_{-}\cdot\nabla z_{+})  (\tau,u_--\tau,x_2,x_3)d\tau\Big\|_{L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)} \lesssim C_1\varepsilon^2.\stepcounter{equation}\tag{\theequation}  As a direct consequence of   \eqref{eq:lemma1-10} and  \eqref{eq:lemma1-12}, we obtain   &\ \ \ \ \lim_{T\to \infty}\Big\|\delta^{-\frac{1}{2}}\partial_h^{\alpha_h}\int_T^{\infty} (\nabla p+z_{-}\cdot\nabla z_{+})  (\tau,u_--\tau,x_2,x_3)d\tau\Big\|_{L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\ &=\lim_{T\to \infty}\Big\|\delta^{-\frac{1}{2}}\int_T^{\infty}\partial_h^{\alpha_h} (\nabla p+z_{-}\cdot\nabla z_{+})  (\tau,u_--\tau,x_2,x_3)d\tau\Big\|_{L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}=0.  Together with \eqref{eq:lemma1-11'}, this gives rise to \eqref{eq:lemma1-5'}.  The proof of this lemma is now complete.",2502.01139
proof,"By the symmetry considerations, it suffices to give details for the estimate on $z_{+}(\infty;u_-,x_2,x_3)$. 		 Applying the derivative $	\partial_h^{\alpha_h}\partial_3^l$ to 	\eqref{eq:def-sca} and \eqref{eq:def-large} gives rise to  	  	&\ \ \ \ 	\delta^{l-\frac{1}{2}}\partial_h^{\alpha_h}\partial_3^l z_{+}(\infty;u_-,x_2,x_3)\\ 	&=\delta^{l-\frac{1}{2}}\partial_h^{\alpha_h}\partial_3^l z_{+}(0,u_-,x_2,x_3)-\delta^{l-\frac{1}{2}}\partial_h^{\alpha_h}\partial_3^l\int_0^{\infty} (\nabla p+z_{-}\cdot\nabla z_{+})  		(\tau,u_--\tau,x_2,x_3)d\tau,\stepcounter{equation}\tag{\theequation} 	 and  	  &\ \ \ \ 	\delta^{l-\frac{1}{2}}\partial_h^{\alpha_h}\partial_3^l z_{+}(\infty;u_-,x_2,x_3)-\delta^{l-\frac{1}{2}}\partial_h^{\alpha_h}\partial_3^l z_{+}(T,u_--T,x_2,x_3) \\& =-\delta^{l-\frac{1}{2}}\partial_h^{\alpha_h}\partial_3^l\int_T^{\infty} (\nabla p+z_{-}\cdot\nabla z_{+})  	(\tau,u_--\tau,x_2,x_3)d\tau.\stepcounter{equation}\tag{\theequation}  According to \eqref{improve2}, we have 	 		&\ \ \ \ 	\big\|\delta^{l-\frac{1}{2}}\partial_h^{\alpha_h}\partial_3^lz_+(0,u_-,x_2,x_3)\big\|_{L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\ 		&	=\delta^{l-\frac{1}{2}} \big\|\partial_h^{\alpha_h}\partial_3^lz_+(0,u_-,x_2,x_3)\big\|_{L^2(\Omega_\delta,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}		=\delta^{l-\frac{1}{2}}E_+^{(|\alpha_h|,l)}(z_{+,0}) 		\lesssim  		\varepsilon, 	 and hence  	 		\delta^{l-\frac{1}{2}}\partial_h^{\alpha_h}\partial_3^l z_{+}(0,u_-,x_2,x_3)\in L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3). 	 By virtue of \eqref{eq:lemma1-15}, \eqref{eq:lemma1-15'} and \eqref{eq:lemma1-16}, our task is now reduced to showing that 	 	\delta^{l-\frac{1}{2}}	\partial_h^{\alpha_h}\partial_3^l\int_0^{\infty} (\nabla p+z_{-}\cdot\nabla z_{+})  		(\tau,u_--\tau,x_2,x_3)d\tau\in L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3), 	 and   	\lim_{T\to \infty}\Big\|\delta^{-\frac{1}{2}}\partial_h^{\alpha_h}\partial_3^l\int_T^{\infty}  (\nabla p+z_{-}\cdot\nabla z_{+})  	(\tau,u_--\tau,x_2,x_3)d\tau\Big\|_{L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}=0.  	 	The rest of this proof is divided into four steps.  	 	\subsubsection*{\bf Step 1:} We first prove that  	 		\delta^{l-\frac{1}{2}}\int_0^{\infty} \partial_h^{\alpha_h}\partial_3^l(\nabla p+z_{-}\cdot\nabla z_{+})  		(\tau,u_--\tau,x_2,x_3)d\tau\in L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3). 	 	 	 	In fact,  	this can be proved via coordinate transformations and H\""older inequality:  	&\ \ \ \ \Big\|\delta^{l-\frac{1}{2}}\int_0^{\infty} \partial_h^{\alpha_h}\partial_3^l(\nabla p+z_{-}\cdot\nabla z_{+})  	(\tau,u_--\tau,x_2,x_3)d\tau\Big\|_{L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\ 	& 	\lesssim\delta^{l-\frac{1}{2}}\Big\|\Big(\!\!\int_{\mathbb{R}}\!\frac{1}{\langle u_+\rangle^{1+\sigma}}du_+\!\Big)^{\!\!\frac{1}{2}}\!\Big(\!\!\int_{\mathbb{R}}\!\!\langle u_+\rangle^{1+\sigma} |\partial_h^{\alpha_h}\partial_3^l(\nabla p+z_{-}\cdot\nabla z_{+})  	(u_+,u_-,x_2,x_3)|^2du_+\!\Big)^{\!\!\frac{1}{2}}\Big\|_{L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\ 	&\lesssim\delta^{l-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)} \partial_h^{\alpha_h}\partial_3^l(\nabla p+z_{-}\cdot\nabla z_{+})  	(u_+,u_-,x_2,x_3)\big\|_{L^2(\mathbb{R}\times\Omega_\delta,du_+du_-dx_2dx_3)}\\ 	&\lesssim\delta^{l-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_{h}^{\alpha_h}\partial_3^l \nabla p\big\|_{L^2_tL^2_x}+\delta^{l-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}{\mathbf{J}_+^{(\alpha_h,l)}}\big\|_{L^2_tL^2_x}\!\!\!\!\!\!\! 	\stackrel{\text{Lemmas \ref{lemma:HH} \& \ref{lemma2}}}{\lesssim}\!\!\!\!\! C_1\varepsilon^2.\stepcounter{equation}\tag{\theequation} 	  	 	 	\subsubsection*{\bf Step 2:} We show that   	 	\delta^{l-\frac{1}{2}}\partial_h^{\gamma_h}\int_0^{\infty} \partial_h^{\alpha_h-\gamma_h}\partial_3^l(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_--\tau,x_2,x_3)d\tau\in L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3) 	 for any $\gamma_h\leqslant\alpha_h$ with $|\gamma_h|=1$, and   	\delta^{l-\frac{1}{2}}\partial_3\int_0^{\infty} \partial_h^{\alpha_h}\partial_3^{l-1}(\nabla p+z_{-}\cdot\nabla z_{+})  	(\tau,u_--\tau,x_2,x_3)d\tau\in L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3).     We note that \eqref{eq:lemma1-19} can be proved by similar methods used for  \eqref{eq:lemma1-8} and \eqref{eq:lemma1-20}. Thus it is sufficient to show \eqref{eq:lemma1-20} now.  In fact,   there holds    	&\ \ \ \ \Big\|\delta^{l-\frac{1}{2}}\partial_3\int_0^{\infty} \partial_h^{\alpha_h}\partial_3^{l-1}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_--\tau,x_2,x_3)d\tau \Big\|_{L^2(\mathcal{C}_+,\langle u_{-}\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\ 	&=\delta^{l-\frac{1}{2}}\Big\|\lim_{h\to 0} \int_0^{\infty}\frac{1}{h}\big(\partial_h^{\alpha_h}\partial_3^{l-1}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_--\tau,x_2,x_3+h)\\ 	&\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  -\partial_h^{\alpha_h}\partial_3^{l-1}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_--\tau,x_2,x_3)\big) 	d\tau \Big\|_{L^2(\mathcal{C}_+,\langle u_{-}\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\ 	&\stackrel{\text{Fatou}}{\leqslant}\delta^{l-\frac{1}{2}}\liminf_{h\to 0}\Big\| \int_0^{\infty}\frac{1}{h}\big(\partial_h^{\alpha_h}\partial_3^{l-1}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_--\tau,x_2,x_3+h)\\ 	&\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  -\partial_h^{\alpha_h}\partial_3^{l-1}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_--\tau,x_2,x_3)\big) 	d\tau \Big\|_{L^2(\mathcal{C}_+,\langle u_{-}\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\ 	&\stackrel{\text{Newton-Leibniz}}{\leqslant}\!\!\!\!\!\delta^{l-\frac{1}{2}}\liminf_{h\to 0}\Big\| \int_0^{\infty}\!\!\!\int_0^1\partial_h^{\alpha_h}\partial_3^{l}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_--\tau,x_2,x_3+\theta h)d\theta d\tau \Big\|_{L^2(\mathcal{C}_+,\langle u_{-}\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\ 	&\leqslant\delta^{l-\frac{1}{2}}\liminf_{h\to 0}\Big\|\int_0^1 \int_0^{\infty}\partial_h^{\alpha_h}\partial_3^{l}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_--\tau,x_2,x_3+\theta h)d\tau d\theta  \Big\|_{L^2(\mathcal{C}_+,\langle u_{-}\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\ 	&\leqslant\delta^{l-\frac{1}{2}}\liminf_{h\to 0}\int_0^1\Big\| \int_0^{\infty}\partial_h^{\alpha_h}\partial_3^{l}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_--\tau,x_2,x_3+\theta h)d\tau  \Big\|_{L^2(\mathcal{C}_+,\langle u_{-}\rangle^{2(1+\sigma)}du_-dx_2dx_3)}d\theta \\ 	&\stackrel{\text{set }X_3=x_3+\theta h}{\leqslant}\delta^{l-\frac{1}{2}}\liminf_{h\to 0}\int_0^1\Big\| \int_0^{\infty}\partial_h^{\alpha_h}\partial_3^{l}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_--\tau,x_2,X_3)d\tau  \Big\|_{L^2(\mathcal{C}_+,\langle u_{-}\rangle^{2(1+\sigma)}du_-dx_2dX_3)}d\theta\\ 	&\leqslant \Big\|\delta^{l-\frac{1}{2}}\int_0^{\infty} \partial_h^{\alpha_h}\partial_3^l(\nabla p+z_{-}\cdot\nabla z_{+})  	(\tau,u_--\tau,x_2,x_3)d\tau\Big\|_{L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)} 	\stackrel{\eqref{eq:lemma1-18}}{\lesssim} C_1\varepsilon^2.  The proof of this step is complete.  	   	 	 	\subsubsection*{\bf Step 3:} We prove that  as vector fields in $L^2(\mathcal{C}_+,\langle u_{-}\rangle^{2(1+\sigma)} du_-dx_2dx_3)$,  	there hold 	 		&  		\delta^{l-\frac{1}{2}}\partial_h^{\gamma_h}\int_0^{\infty} \partial_h^{\alpha_h-\gamma_h}\partial_3^l(\nabla p+z_{-}\cdot\nabla z_{+})  		(\tau,u_--\tau,x_2,x_3)d\tau\\ 		&\stackrel{ L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}{=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=}\delta^{l-\frac{1}{2}}\int_0^{\infty} \partial_h^{\alpha_h}\partial_3^l(\nabla p+z_{-}\cdot\nabla z_{+})  		(\tau,u_--\tau,x_2,x_3)d\tau\stepcounter{equation}\tag{\theequation} 	 	for any $\gamma_h\leqslant\alpha_h$ with $|\gamma_h|=1$, and  		 		&  		\delta^{l-\frac{1}{2}}\partial_3\int_0^{\infty} \partial_h^{\alpha_h}\partial_3^{l-1}(\nabla p+z_{-}\cdot\nabla z_{+})  		(\tau,u_--\tau,x_2,x_3)d\tau\\ 		&\stackrel{ L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}{=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=}\delta^{l-\frac{1}{2}}\int_0^{\infty} \partial_h^{\alpha_h}\partial_3^l(\nabla p+z_{-}\cdot\nabla z_{+})  		(\tau,u_--\tau,x_2,x_3)d\tau.\stepcounter{equation}\tag{\theequation} 	  Since \eqref{eq:lemma1-21} can be proved by similar methods used for  \eqref{eq:lemma1-9} and \eqref{eq:lemma1-22}, it is now suffices to show \eqref{eq:lemma1-22}.  By virtue of \eqref{eq:lemma1-17} and  \eqref{eq:lemma1-20}, we only need to prove in the sense of distributions that  	 		\delta^{l-\frac{1}{2}}\partial_3\int_0^{\infty}\!\! \partial_h^{\alpha_h}\partial_3^{l-1}(\nabla p+z_{-}\cdot\nabla z_{+})  		(\tau,u_--\tau,x_2,x_3)d\tau 		\stackrel{ \mathcal{D}'(\mathcal{C}_+)}{=\joinrel=\joinrel=\joinrel=}\delta^{l-\frac{1}{2}}\!\int_0^{\infty}\!\! \partial_h^{\alpha_h}\partial_3^l(\nabla p+z_{-}\cdot\nabla z_{+})  		(\tau,u_--\tau,x_2,x_3)d\tau.  	  	  	Based on \eqref{eq:lemma1} and \eqref{eq:lemma1-17},  	both the two time integrals in \eqref{eq:lemma1-23} are locally integrable functions.  For any vector field  $\varphi\in \mathcal{D}(\mathcal{C}_+)\subset L^2(\mathcal{C}_+)$, we have $\partial_3\varphi\in \mathcal{D}(\mathcal{C}_+)\subset L^2(\mathcal{C}_+)$. Hence, by the estimates in proofs of \eqref{eq:lemma1} and \eqref{eq:lemma1-17}, we can show   the following two spacetime integrals  finite to make the use of Fubini's theorem legitimate: 	 		&\ \ \ \ 		\delta^{l-\frac{1}{2}}\int_{[0,\infty)\times \mathcal{C}_+}\big|\partial_h^{\alpha_h}\partial_3^{l-1}(\nabla p+z_{-}\cdot\nabla z_{+})  		(\tau,u_--\tau,x_2,x_3)\cdot\partial_{h}^{\gamma_h}\varphi(u_-,x_2,x_3)\big|d\tau du_-dx_2dx_3\\ 		&\lesssim \delta^{l-\frac{1}{2}}\int_{\mathbb{R}\times\mathcal{C}_+}\big|\partial_h^{\alpha_h}\partial_3^{l-1}(\nabla p+z_{-}\cdot\nabla z_{+})  		(u_+,u_-,x_2,x_3)\big|\cdot|\partial_{h}^{\gamma_h}\varphi(u_-,x_2,x_3)|du_+du_-dx_2dx_3\\ 		&\lesssim 		\delta^{l-\frac{1}{2}}\Big(\int_{\mathbb{R}\times \mathcal{C}_+}\langle  u_+\rangle^{1+\sigma}\big|\partial_h^{\alpha_h}\partial_3^{l-1}(\nabla p+z_{-}\cdot\nabla z_{+})(u_+,u_-,x_2,x_3)\big|^2 \Big)^{\frac{1}{2}} 		\Big(\int_{\mathbb{R}\times \mathcal{C}_+}\frac{|\partial_3\varphi(u_-,x_2,x_3)|^2}{\langle u_+\rangle^{1+\sigma}}\Big)^{\frac{1}{2}}\\ 		&\lesssim\delta^{l-\frac{1}{2}}\Big(\int_{\mathbb{R}\times \mathcal{C}_+}\langle u_-\rangle^{2(1+\sigma)}\langle u_+\rangle^{1+\sigma}\big|\partial_h^{\alpha_h}\partial_3^{l-1}(\nabla p+z_{-}\cdot\nabla z_{+}) (u_+,u_-,x_2,x_3)\big|^2\Big)^{\frac{1}{2}}\\ 		&\ \ \ \ \times \Big(\int_{\mathbb{R}}\frac{1}{\langle u_+\rangle^{1+\sigma}}\Big(\int_{\mathcal{C}_+} |\partial_3 \varphi(u_-,x_2,x_3)|^2  du_-dx_2dx_3 \Big)du_+\Big)^{\frac{1}{2}}\\ 		&\lesssim\varepsilon^2\|\partial_3\varphi\|_{L^2}<\infty,\stepcounter{equation}\tag{\theequation}\\ 		&\ \ \ \ 		\delta^{l-\frac{1}{2}}\int_{[0,\infty)\times \mathcal{C}_+}\big|\partial_h^{\alpha_h}\partial_3^l(\nabla p+z_{-}\cdot\nabla z_{+})  		(\tau,u_--\tau,x_2,x_3)\cdot\varphi(u_-,x_2,x_3)\big|d\tau du_-dx_2dx_3\\ 		&\lesssim \delta^{l-\frac{1}{2}}\int_{\mathbb{R}\times\mathcal{C}_+}\big|\partial_h^{\alpha_h}\partial_3^l(\nabla p+z_{-}\cdot\nabla z_{+})  		(u_+,u_-,x_2,x_3)\big|\cdot|\varphi(u_-,x_2,x_3)|du_+du_-dx_2dx_3\\ 		&\lesssim 		\delta^{l-\frac{1}{2}}\Big(\int_{\mathbb{R}\times \mathcal{C}_+}\langle  u_+\rangle^{1+\sigma}\big|\partial_h^{\alpha_h}\partial_3^l(\nabla p+z_{-}\cdot\nabla z_{+})  		(u_+,u_-,x_2,x_3)\big|^2 \Big)^{\frac{1}{2}} 		\Big(\int_{\mathbb{R}\times \mathcal{C}_+}\frac{|\varphi(u_-,x_2,x_3)|^2}{\langle u_+\rangle^{1+\sigma}}\Big)^{\frac{1}{2}}\\ 		&\lesssim\delta^{l-\frac{1}{2}}\Big(\int_{\mathbb{R}\times \mathcal{C}_+}\langle u_-\rangle^{2(1+\sigma)}\langle u_+\rangle^{1+\sigma}\big|\partial_h^{\alpha_h}\partial_3^l(\nabla p+z_{-}\cdot\nabla z_{+}) (u_+,u_-,x_2,x_3)\big|^2\Big)^{\frac{1}{2}}\\ 		&\ \ \ \ \times \Big(\int_{\mathbb{R}}\frac{1}{\langle u_+\rangle^{1+\sigma}}\Big(\int_{\mathcal{C}_+} \varphi(u_-,x_2,x_3)|^2  du_-dx_2dx_3 \Big)du_+\Big)^{\frac{1}{2}}\\ 		&\lesssim\varepsilon^2\|\varphi\|_{L^2}<\infty.\stepcounter{equation}\tag{\theequation} 	      Applying \eqref{eq:lemma1-24}-\eqref{eq:lemma1-25}, integration by parts and Fubini's theorem repeatedly then gives in the sense of distributions that  	 		&\ \ \ \  \Big\langle\delta^{l-\frac{1}{2}} \partial_3\int_0^{\infty} \partial_h^{\alpha_h}\partial_3^{l-1}(\nabla p+z_{-}\cdot\nabla z_{+})  		(\tau,u_--\tau,x_2,x_3)d\tau,\ \varphi(u_-,x_2,x_3)\Big\rangle\\ 		&=-\delta^{l-\frac{1}{2}}\Big\langle\int_0^{\infty}\partial_h^{\alpha_h}\partial_3^{l-1}(\nabla p+z_{-}\cdot\nabla z_{+})  		(\tau,u_--\tau,x_2,x_3)d\tau,\  \partial_3 \varphi(u_-,x_2,x_3)\Big\rangle\\ 		&=-\delta^{l-\frac{1}{2}}\int_{\mathcal{C}_+}\Big(\int_0^{\infty}\partial_h^{\alpha_h}\partial_3^{l-1}(\nabla p+z_{-}\cdot\nabla z_{+})  		(\tau,u_--\tau,x_2,x_3)d\tau\Big)\cdot \partial_3\varphi(u_-,x_2,x_3)du_-dx_2dx_3\\ 		&\stackrel{  			\eqref{eq:lemma1-24}}{=}-\delta^{l-\frac{1}{2}}\int_{[0,\infty) \times \mathcal{C}_+}\partial_h^{\alpha_h}\partial_3^{l-1}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_--\tau,x_2,x_3)\cdot \partial_3\varphi(u_-,x_2,x_3)d\tau du_-dx_2dx_3\\ 		&=-\delta^{l-\frac{1}{2}}\int_{[0,\infty)} \Big(\int_{\mathcal{C}_+}\partial_h^{\alpha_h}\partial_3^{l-1}(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_--\tau,x_2,x_3)\cdot \partial_3\varphi(u_-,x_2,x_3)du_-dx_2dx_3\Big)d\tau \\ 		&=\delta^{l-\frac{1}{2}}\int_{[0,\infty)} \Big(\int_{\mathcal{C}_+}\partial_h^{\alpha_h}\partial_3^l(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_--\tau,x_2,x_3)\cdot \varphi(u_-,x_2,x_3)du_-dx_2dx_3\Big)d\tau \\ 		&=\delta^{l-\frac{1}{2}}\int_{[0,\infty)\times \mathcal{C}_+}\partial_h^{\alpha_h}\partial_3^l(\nabla p+z_{-}\cdot\nabla z_{+}) (\tau,u_--\tau,x_2,x_3)\cdot \varphi(u_-,x_2,x_3)du_-dx_2dx_3d\tau\\ 		&\stackrel{   		\eqref{eq:lemma1-25}}{=}\delta^{l-\frac{1}{2}}\int_{\mathcal{C}_+}\Big(\int_{0}^{\infty} \partial_h^{\alpha_h}\partial_3^l(\nabla p+z_{-}\cdot\nabla z_{+})(\tau,u_--\tau,x_2,x_3)d\tau\Big)\cdot \varphi(u_-,x_2,x_3)du_-dx_2dx_3\\ 		&=\Big\langle\delta^{l-\frac{1}{2}}\int_0^{\infty}  \partial_h^{\alpha_h}\partial_3^l(\nabla p+z_{-}\cdot\nabla z_{+})(\tau,u_--\tau,x_2,x_3)d\tau,\ \varphi(u_-,x_2,x_3)\Big\rangle. 	 which yields \eqref{eq:lemma1-23}. Thus we have finished this step.    	 	 	\subsubsection*{\bf Step 4:} Finally, we  prove \eqref{eq:lemma1-26} and \eqref{eq:lemma1-26'}.  	 	By induction on $\alpha_h$ and $l$, we can apply \eqref{eq:lemma1-21} and \eqref{eq:lemma1-22} repeatedly to get  the following equation  in the sense of weighted $L^2$ space $L^2(\mathcal{C}_+,\langle u_{-}\rangle^{2(1+\sigma)} du_-dx_2dx_3)$: 	 		&  		\delta^{l-\frac{1}{2}}\partial_h^{\alpha_h}\partial_3^l\int_0^{\infty}(\nabla p+z_{-}\cdot\nabla z_{+})  		(\tau,u_--\tau,x_2,x_3)d\tau\\ 		&\stackrel{ L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}{=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=\joinrel=}\delta^{l-\frac{1}{2}}\int_0^{\infty} \partial_h^{\alpha_h}\partial_3^l(\nabla p+z_{-}\cdot\nabla z_{+})  		(\tau,u_--\tau,x_2,x_3)d\tau,\stepcounter{equation}\tag{\theequation} 	 which together with \eqref{eq:lemma1-17} leads us to  \eqref{eq:lemma1-26}.  Moreover, we can derive from \eqref{eq:lemma1-27} and  \eqref{eq:lemma1-18}  that  	 		&\ \ \ \ \Big\|\delta^{l-\frac{1}{2}}\partial_h^{\alpha_h}\partial_3^l\int_0^{\infty} (\nabla p+z_{-}\cdot\nabla z_{+})  		(\tau,u_--\tau,x_2,x_3)d\tau\Big\|_{L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\ 		&=\Big\|\delta^{l-\frac{1}{2}}\int_0^{\infty} \partial_h^{\alpha_h}\partial_3^l(\nabla p+z_{-}\cdot\nabla z_{+})  		(\tau,u_--\tau,x_2,x_3)d\tau\Big\|_{L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)} 		\lesssim C_1\varepsilon^2,  	 which leads us to \eqref{eq:lemma1-26'} immediately.   Therefore we have ended the proof of this lemma.",2502.01139
proof,"By the symmetry considerations, we only need to consider   the scattering field  $z_{+}(\infty;u_-,x_2,x_3)$. Similar arguments    in Lemma \ref{lemma6} remain valid for this lemma. The only difference lies in the  \textbf{Step 1}, which can be modified as follows:    	&\ \ \ \ \Big\|\delta^{l-\frac{1}{2}}\int_0^{\infty} \partial_h^{\alpha_h}\partial_3^l\partial_3(\nabla p+z_{-}\cdot\nabla z_{+})   	(\tau,u_--\tau,x_2,x_3)d\tau\Big\|_{L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\  	&   	\lesssim\!\delta^{l\!-\!\frac{1}{2}\!}\Big\|\Big(\!\!\int_{\mathbb{R}}\!\!\frac{1}{\langle u_+\rangle^{1+\sigma}}du_+\!\!\Big)^{\!\!\frac{1}{2}}\Big(\!\!\int_{\mathbb{R}}\!\!\langle u_+\rangle^{1+\sigma}\! |\partial_h^{\alpha_h}\partial_3^l\partial_3(\nabla p+z_{-}\cdot\nabla z_{+})   	(u_+,u_-,x_2,x_3)|^2du_+\!\!\Big)^{\!\!\frac{1}{2}}\!\Big\|_{L^2(\mathcal{C}_+,\langle u_-\rangle^{2(1+\sigma)}du_-dx_2dx_3)}\\  	&\lesssim\delta^{l-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)} \partial_h^{\alpha_h}\partial_3^l\partial_3(\nabla p+z_{-}\cdot\nabla z_{+})   	(u_+,u_-,x_2,x_3)\big\|_{L^2(\mathbb{R}\times\Omega_\delta,du_+du_-dx_2dx_3)}\\  	&\lesssim\delta^{l-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_{h}^{\alpha_h}\partial_3^l\partial_3 \nabla p\big\|_{L^2_tL^2_x}+\delta^{l-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}{\mathbf{K}_+^{(\alpha_h,l)}}\big\|_{L^2_tL^2_x}  	\stackrel{\text{Lemmas \ref{lemma:HHH} \& \ref{lemma3}}}{\lesssim} C_1\varepsilon^2.   	 We have thus proved this lemma.",2502.01139
proof,"Similar arguments used in the proof of Lemma \ref{welldefined}  enable us to derive that   &	 \langle u_\mp\rangle^{\frac{1}{2}(1+\sigma)}\langle u_\pm\rangle^{\frac{1}{2}(1+\sigma)} |\nabla_\delta p_{(\delta)}| 	\lesssim  	\sum_{0\leqslant|\alpha_h|\leqslant 3\atop 0\leqslant l\leqslant 3}\big\|\langle u_\mp\rangle^{1+\sigma}\langle u_\pm\rangle^{\frac{1}{2}(1+\sigma)}\partial_{h}^{\alpha_h}\partial_3^l \nabla_\delta p_{(\delta)}\big\|_{L^2_tL^2_x} 	\stackrel{\text{Corollary \ref{remarkp}}}{\lesssim}C_1\varepsilon^2,\\ &	\langle u_\mp\rangle^{\frac{1}{2}(1+\sigma)}\langle u_\pm\rangle^{\frac{1}{2}(1+\sigma)} |z_{\mp(\delta)}\cdot\nabla z_{\pm(\delta)}| 	\lesssim\!\!\!  	\sum_{0\leqslant|\alpha_h|\leqslant 3\atop 0\leqslant l\leqslant 3}\big\|\langle u_\mp\rangle^{1+\sigma}\langle u_\pm\rangle^{\frac{1}{2}(1+\sigma)}\partial_{h}^{\alpha_h}\partial_3^l (z_{\mp(\delta)}\cdot\nabla z_{\pm(\delta)})\big\|_{L^2_tL^2_x} \!\!\!	\stackrel{\text{Remark \ref{remarkJ}}}{\lesssim}\!\!\! C_1\varepsilon^2.  In view of \eqref{eq:product}, these two estimates then yield  	|\nabla_\delta p_{(\delta)}+z_{\mp(\delta)}\cdot \nabla z_{\pm(\delta)}|\lesssim\frac{C_1\varepsilon^2}{\langle u_\mp\rangle^{\frac{1}{2}(1+\sigma)}\langle u_\pm\rangle^{\frac{1}{2}(1+\sigma)}}\lesssim\frac{C_1\varepsilon^2}{(1+|t+a|)^{1+\sigma}}\in L_t^1(\mathbb{R}).  This means that the two integrands in \eqref{eq:def-sca2} are uniformly integrable.    Therefore,  by the Lebesgue's dominated convergence theorem and Theorem \ref{lemma:approx}, we infer that   \lim_{\delta\to 0}\int_0^\infty(\nabla_\delta p_{(\delta)}+z_{\mp(\delta)}\cdot\nabla z_{\pm(\delta)})(\tau,u_\mp\mp\tau,x_2,x_3)d\tau &=\int_0^\infty\lim_{\delta\to 0}(\nabla_\delta p_{(\delta)}+z_{\mp(\delta)}\cdot\nabla z_{\pm(\delta)})(\tau,u_\mp\mp\tau,x_2,x_3)d\tau\\ &=\int_0^\infty(\nabla p_{(0)}+z_{\mp(0)}\cdot\nabla z_{\pm(0)})(\tau,u_\mp\mp\tau,x_2)d\tau,  where the limit holds in $H^N(\mathbb{R}^2)$ for  the horizontal component  and in $H^{N-1}(\mathbb{R}^2)$ for  the vertical component.  Together with \eqref{eq:def-sca2}, Theorem \ref{lemma:approx} and Remark \ref{remark2D}, this gives rise to   \lim_{\delta\to 0}z_{\pm(\delta)}(\infty;u_\mp,x_2,x_3) &= \lim_{\delta\to 0}z_{\pm(\delta)}(0,u_\mp,x_2,x_3)- \lim_{\delta\to 0}\int_0^{\infty}(\nabla_\delta p_{(\delta)}+z_{\mp(\delta)}\cdot\nabla z_{\pm(\delta)})(\tau,u_\mp\mp\tau,x_2,x_3)d\tau\\ &=z_{\pm(0)}(0,u_\mp,x_2)-\int_0^\infty(\nabla p_{(0)}+z_{\mp(0)}\cdot\nabla z_{\pm(0)})(\tau,u_\mp\mp\tau,x_2)d\tau =z_{\pm(0)}(\infty;u_\mp,x_2),  where the limit holds in $H^N(\mathbb{R}^2)$  for the horizontal   component and in $H^{N-1}(\mathbb{R}^2)$ for   the vertical component.  Precisely, we obtain \eqref{eq:approx} as asserted.   By virtue of Corollary \ref{coro3}, it now follows that   	if the scattering fields constructed in Remark \ref{remark2D}  vanish on the infinities, i.e. \[ 	&z_{+(0)}(\infty;u_-,x_2)\equiv 0 \ \ \text{on} \ \ \mathcal{C}_+,\\ 	&z_{-(0)}(\infty;u_+,x_2)\equiv 0 \ \ \text{on} \ \ \mathcal{C}_-,  \] then the initial Alfv\'en waves governed by the rescaled system  \eqref{eq:rescale} vanish identically, i.e.  \[\big(z_{+(0),0}(x),z_{-(0),0}(x)\big)\equiv(0,0)\ \text{ for all }x\in\mathbb{R}^2,\] and hence the Alfv\'en waves governed by the rescaled system  \eqref{eq:rescale}  vanish identically, i.e.,  \[\big(z_{+(0)}(t,x),z_{-(0)}(t,x)\big)\equiv(0,0)\  \text{ for all }(t,x)\in \mathbb{R}\times \mathbb{R}^2.\]  We note that the scattering fields  $z_{+(0)}^h(\infty;u_-,x_2)$ and $z_{-(0)}^h(\infty;u_+,x_2)$ are the 2D version of the scattering fields $z_{+(0)}(\infty;u_-,x_2)$ and $z_{-(0)}(\infty;u_+,x_2)$; the initial data $\big(z^h_{+(0),0}(x),z^h_{-(0),0}(x)\big)$ are the 2D version of the initial data $\big(z_{+(0),0}(x),z_{-(0),0}(x)\big)$; and the Alfv\'en waves $\big(z^h_{+(0)}(t,x),z^h_{-(0)}(t,x)\big)$ are the 2D version of the Alfv\'en waves $\big(z_{+(0)}(t,x),z_{-(0)}(t,x)\big)$. Consequently, the rigidity part of Corollary \ref{thm3} follows immediately.   Up to now, we have finished the proof of Corollary \ref{thm3}.",2502.01139
proof,"For $l=1$, we will estimate $\nabla p$ by using \eqref{decomposition of nabla p 2d}. Next, we will bound $\mathbf{A_1}$, $\mathbf{A_2}$ and $\mathbf{A_3}$ one by one. For $\mathbf{A_1}$, we can also infer 	 		\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{{1+\sigma}}\left|\mathbf{A_1}\right| 		&=\int_{|x-y|\leqslant 2}\frac{\left(\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{{1+\sigma}}\right)(\tau,x)\left|\left(\nabla z_{-}\cdot\nabla z_{+}\right)(\tau,y)\right|}{|x-y|}dy\\ 		&\stackrel{\eqref{eq:xgeqleq}}{\lesssim}\! 		\int_{|x-y|\leqslant 2}\frac{\left(\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{ {1+\sigma}}\right)(\tau,y)\left|\left(\nabla z_{-}\cdot\nabla z_{+}\right)(\tau,y)\right|}{|x-y|}dy 		\stackrel{\eqref{eq:Sobolev}}{\lesssim}\! 		\int_{|x-y|\leqslant 2}\frac{\varepsilon^2}{|x-y|}dy\lesssim \varepsilon^2. 	 	We repeat the estimate on $\mathbf{A_1}$ to the estimate on $\mathbf{A_3}$. It then follows that  	 		\langle u_+\rangle^{1+\sigma}\langle u_-\rangle^{1+\sigma}\left|\mathbf{A_3}\right| 		\lesssim\varepsilon^2. 	 	For $\mathbf{A_2}$, we can similarly use \eqref{eq:product} to obtain $1+|\tau+a| \lesssim \langle u_{+}\rangle\langle u_{-}\rangle$, and hence there holds  	 		\left(1+|\tau+a|\right)^{{{1+\sigma}}}\left|\mathbf{A_2}\right|&\lesssim\int_{|x-y|\geqslant 1}\frac{\langle u_+\rangle^{1+\sigma}(\tau,y)\langle u_-\rangle^{1+\sigma}(\tau,y)\left| z_{-}(\tau,y)\right|\left|z_{+}(\tau,y)\right|}{|x-y|^3}dy 		\lesssim \int_{|x-y|\geqslant 1}\frac{\varepsilon^2}{|x-y|^3}dy 		\lesssim \varepsilon^2. 	 	Putting all the estimates on $\mathbf{A_i}$ together, we conclude that  	 		|\nabla p(\tau,x)|\lesssim\frac{\varepsilon^2}{\left(1+\left|\tau+a\right|\right)^{1+\sigma}}. 	 	 	 	In order to bound $\nabla^2 p$, we take $\nabla$ on both sides of \eqref{eq:nabla p 2d}. Similar to the derivation of \eqref{decomposition of nabla p 2d}, we can derive 	 		|\nabla^2 p(\tau,x)| 		\lesssim 		& \underbrace{\sum_{l_{1},l_{2}=1}^2 \int_{|x-y|\leqslant 2}\frac{1}{|x-y|}\left|\left(\nabla^{l_1} z_{-}\cdot\nabla^{l_2} z_{+}\right)(\tau,y)\right|dy}_{\mathbf{B_1}}\\ 		&+\underbrace{\int_{|x-y|\geqslant 1}\frac{1}{|x-y|^3}\left| \left(z_{-}\cdot\nabla z_{+}\right)(\tau,y)\right|dy}_{\mathbf{B_2}}	+\underbrace{\int_{1\leqslant |x-y|\leqslant 2}\frac{1}{|x-y|^2}\left|\left(z_{-}\cdot\nabla z_{+}\right)(\tau,y)\right|dy}_{\mathbf{B_3}}, 	 	where  $(l_1,l_2)=(1,1),$ $(1,2)$ or $(2,1)$. We can repeat the above estimate on $\mathbf{A_i}$ to give the estimate on $\mathbf{B_i}$, and thus imply the estimate on $\nabla^2 p$.",2502.01139
lemma,"[Sobolev lemma] 	For any $f(x)\in H^2(\Omega_{\delta})$, we have  	\[\|f\|_{L^\infty_x}\leqslant C\sum_{k+l\leqslant 2}\delta^{l-\frac{1}{2}}\|\nabla^k_h\partial_3^lf\|_{L^2_x}.\]",2502.01139
lemma,"[Properties of weights] For any    $\sigma\in (0,\frac{1}{3})$, there  hold: [(i)] \item For $|x_h-y_h|\leqslant 2$, we have   	\left(\langle u_\mp\rangle^{1+\sigma}\langle u_\pm\rangle^{\frac{1}{2}(1+\sigma)}\right)(t,x)\lesssim\left(\langle u_\mp\rangle^{1+\sigma}\langle u_\pm\rangle^{\frac{1}{2}(1+\sigma)}\right)(t,y).  \item For $|x_h-y_h|\geqslant 1$, we have  \left(\langle u_\mp\rangle^{1+\sigma}\langle u_\pm\rangle^{\frac{1}{2}(1+\sigma)}\right)(t,x)\lesssim |x_h-y_h|^{\frac{3}{2}(1+\sigma)}\left(\langle u_\mp\rangle^{1+\sigma}\langle u_\pm\rangle^{\frac{1}{2}(1+\sigma)}\right)(t,y).  \item For all $k\in\mathbb{Z}_{\geqslant 0}$ with $k\leqslant 3$, we have   \left|\nabla^k\left(\langle u_\mp\rangle^{1+\sigma}\langle u_\pm\rangle^{\frac{1}{2}(1+\sigma)}\right)\right|\lesssim\langle u_\mp\rangle^{1+\sigma}\langle u_\pm\rangle^{\frac{1}{2}(1+\sigma)}.  \item For all $k,l\in\mathbb{Z}_{\geqslant 0}$ with $k+l\leqslant 2$, we have   \left|\nabla_h^k\partial_3^l\left(\frac{\langle u_\pm\rangle^{1+\sigma}}{\langle u_\mp\rangle^{\frac{1}{2}(1+\sigma)}}\right)\right|\lesssim\frac{\langle u_\pm\rangle^{1+\sigma}}{\langle u_\mp\rangle^{\frac{1}{2}(1+\sigma)}}.  \item For the product of $\langle u_+\rangle$ and $\langle u_-\rangle$, we have   \langle u_+\rangle\langle u_-\rangle\gtrsim 1+|t+a|.   Here, the notation $A\lesssim B$ means that there is a universal constant $C$ (independent of $a$)  such that $A\leqslant CB$; the notation $A\gtrsim B$ means that there is a universal constant $C$ (independent of $a$) such that $A\geqslant CB$.",2502.01139
lemma,"[Weighted div-curl lemma] 	Let $\lambda(x)\geqslant 1$  	be a smooth positive function on $\Omega_\delta$ with the additional property $|\nabla\lambda|\lesssim \lambda$. For any smooth vector field $v(x)\in H^1(\Omega_\delta)$, we have  	 		\big\|\sqrt\lambda\nabla v\big\|_{L^2(\Omega_\delta)}^2 \lesssim \big\|\sqrt\lambda\operatorname{div }\nabla v\big\|_{L^2(\Omega_\delta)}^2+  \big\|\sqrt{\lambda}\operatorname{curl }\nabla v\big\|_{L^2(\Omega_\delta)}^2+ \big\|\sqrt\lambda v\big\|_{L^2(\Omega_\delta)}^2+\Big|\int_{\partial\Omega_\delta} \lambda (v^h\cdot\nabla_h v^3-v^3\nabla_hv^h)dx_h\Big|, 	 	provided $\sqrt{\lambda}v\in L^2({\Omega_\delta})$ and $\sqrt{\lambda}\nabla v\in L^2({\Omega_\delta})$.",2502.01139
lemma,"[Weighted div-curl lemma with higher order derivatives] 	Let $\lambda(x)\geqslant 1$  be a smooth positive function on $\Omega_\delta$ with the additional property $|\nabla\lambda|\lesssim \lambda$. For any smooth vector field $v(x)\in H^m(\Omega_\delta)$ $(m\in \mathbb{Z}_{\geqslant 1})$, we have   	\big\|\sqrt\lambda\nabla^k v\big\|_{L^2(\Omega_\delta)}^2 &\lesssim\sum_{l=0}^{k-1}\big\|\sqrt\lambda\operatorname{div }\nabla^lv\big\|_{L^2(\Omega_\delta)}^2+\sum_{l=0}^{k-1} \big\|\sqrt{\lambda}\operatorname{curl }\nabla^lv\big\|_{L^2(\Omega_\delta)}^2+ \big\|\sqrt\lambda v\big\|_{L^2(\Omega_\delta)}^2\\ 	&\ \ \ \ +\sum_{l=0}^{k-1}\Big|\int_{\partial\Omega_\delta} \lambda (\nabla^{l}v^h\cdot\nabla^{l}\nabla_h v^3-\nabla^{l}v^3\cdot\nabla^{l}\nabla_hv^h)dx_h\Big|,\stepcounter{equation}\tag{\theequation}  provided $\sqrt{\lambda}v\in L^2(\Omega_\delta)$ and $\sqrt{\lambda}\nabla^k v\in L^2(\Omega_\delta)$, where $1\leqslant k\leqslant m$.",2502.01139
lemma,"[Estimate for $\mathbf{I}_{\pm}^{(\alpha_h,l)}$] For any $\alpha_h\in(\mathbb{Z}_{\geqslant 0})^2$ and $l\in\mathbb{Z}_{\geqslant 0}$ with $|\alpha_h|+l\leqslant 2N-1$, there holds   \[\delta^{l+\frac{1}{2}}\big\|\langle u_\mp\rangle^{1+\sigma}\langle u_\pm\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{I}_{\pm}^{(\alpha_h,l)}\big\|_{L^2_tL^2_x}\lesssim C_1\varepsilon^2,\] where \[\mathbf{I}_{\pm}^{(\alpha_h,l)}:=-\partial_h^{\alpha_h}\partial_3^l(\nabla z_\mp\cdot\nabla z_\pm).\] We remark that given $N\in\mathbb{Z}_{\geqslant 5}$, this result also holds for any $\alpha_h\in(\mathbb{Z}_{\geqslant 0})^2$ and any  $l\in\mathbb{Z}_{\geqslant 0}$ with $0\leqslant|\alpha_h|+l\leqslant N+2$.",2502.01139
lemma,"[Estimate for $\mathbf{J}_\pm^{(\alpha_h,l)}$] 	For any $\alpha_h\in(\mathbb{Z}_{\geqslant 0})^2$ and any $l\in\mathbb{Z}_{\geqslant 0}$ with $0\leqslant|\alpha_h|+l\leqslant 2N-1$,  	there holds 	\[\delta^{l-\frac{1}{2}}\big\|\langle u_\mp\rangle^{1+\sigma}\langle u_\pm\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{J}_\pm^{(\alpha_h,l)}\big\|_{L^2_tL^2_x} 	\lesssim C_1\varepsilon^2,\] 	where  	\[\mathbf{J}_\pm^{(\alpha_h,l)}:=\partial_h^{\alpha_h}\partial_3^{l}(z_\mp\cdot \nabla z_\pm).\] 	We remark that given $N\in\mathbb{Z}_{\geqslant 5}$, this result also holds for any $\alpha_h\in(\mathbb{Z}_{\geqslant 0})^2$ and any $l\in\mathbb{Z}_{\geqslant 0}$ with $0\leqslant|\alpha_h|+l\leqslant N+2$.",2502.01139
lemma,"[Estimate for $\mathbf{K}_\pm^{(\alpha_h,l)}$] 	For any $\alpha_h\in(\mathbb{Z}_{\geqslant 0})^2$ and any $l\in\mathbb{Z}_{\geqslant 0}$ with $0\leqslant|\alpha_h|+l\leqslant N+2$,  	there holds 	\[\delta^{l-\frac{1}{2}}\big\|\langle u_\mp\rangle^{1+\sigma}\langle u_\pm\rangle^{\frac{1}{2}(1+\sigma)}\mathbf{K}_\pm^{(\alpha_h,l)}\big\|_{L^2_tL^2_x} 	\lesssim C_1\varepsilon^2,\] 	where  	\[\mathbf{K}_\pm^{(\alpha_h,l)}:=\partial_h^{\alpha_h}\partial_3^{l}\partial_3(z_\mp\cdot \nabla z_\pm).\]",2502.01139
lemma,"For any $l\in\mathbb{Z}_{\geqslant 1}$, there holds 	 		\nabla_x^lG_\delta(x,y)\lesssim\frac{1}{\delta}\frac{1}{|x_h-y_h|^l}.",2502.01139
lemma,"For any $\alpha_h\in(\mathbb{Z}_{\geqslant 0})^2$ with  	$0\leqslant|\alpha_h|\leqslant N+2$, there holds  	 		\delta^{-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_{h}^{\alpha_h} \nabla p\big\|_{L^2_tL^2_x} 		\lesssim C_1\varepsilon^2.",2502.01139
lemma,"For any $\alpha_h\in(\mathbb{Z}_{\geqslant 0})^2$ and any $l\in\mathbb{Z}_{\geqslant 1}$ with  	$1\leqslant 	|\alpha_h|+l\leqslant N+2$, there holds  	 		\delta^{l-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_{h}^{\alpha_h}\partial_3^l \nabla p\big\|_{L^2_tL^2_x} 		\lesssim C_1\varepsilon^2.",2502.01139
lemma,"For any $\alpha_h\in(\mathbb{Z}_{\geqslant 0})^2$ and any $l\in\mathbb{Z}_{\geqslant 0}$ with 	$0\leqslant 	|\alpha_h|+l\leqslant N+2$, there holds  	 		\delta^{l-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_{h}^{\alpha_h}\partial_3^l \nabla p\big\|_{L^2_tL^2_x} 		\lesssim C_1\varepsilon^2.",2502.01139
lemma,"For any $\alpha_h\in(\mathbb{Z}_{\geqslant 0})^2$ and any $l\in\mathbb{Z}_{\geqslant 0}$ with  $0\leqslant |\alpha_h|+l\leqslant N+2$, there holds  	 		\delta^{l-\frac{1}{2}}\big\|\langle u_-\rangle^{1+\sigma}\langle u_+\rangle^{\frac{1}{2}(1+\sigma)}\partial_{h}^{\alpha_h}\partial_3^l\partial_3 \nabla p\big\|_{L^2_tL^2_x} 		\lesssim C_1\varepsilon^2.",2502.01139
lemma,"The scattering fields $\delta^{-\frac{1}{2}}z_{\pm}(\infty;u_\mp,x_2,x_3)$ in \eqref{eq:def-sca} are well-defined.",2502.01139
lemma,"There hold 	 		 \delta^{-\frac{1}{2}}z_{\pm}(\infty;u_\mp,x_2,x_3)\in L^2(\mathcal{C}_\pm,\langle u_\mp\rangle^{2(1+\sigma)}du_\mp dx_2dx_3), 	 and   \lim_{T\to\infty}\Big\|\delta^{-\frac{1}{2}}z_{\pm}(\infty;u_\mp,x_2,x_3)-\delta^{-\frac{1}{2}}z_{\pm}(T,u_\mp\mp T,x_2,x_3)\Big\|_{L^2(\mathcal{C}_\pm,\langle u_\mp\rangle^{2(1+\sigma)}du_\mp dx_2dx_3)}=0.",2502.01139
lemma,"For any $\alpha_h\in(\mathbb{Z}_{\geqslant 0})^2$ with  $1\leqslant|\alpha_h|\leqslant N+2$, there hold   \delta^{-\frac{1}{2}}\partial_h^{\alpha_h} z_{\pm}(\infty;u_\mp,x_2,x_3)\in L^2(\mathcal{C}_\pm,\langle u_\mp\rangle^{2(1+\sigma)}du_\mp dx_2dx_3),  and    	\lim_{T\to\infty}\Big\|\delta^{-\frac{1}{2}}\partial_h^{\alpha_h}z_{\pm}(\infty;u_\mp,x_2,x_3)-\delta^{-\frac{1}{2}}\partial_h^{\alpha_h}z_{\pm}(T,u_\mp\mp T,x_2,x_3)\Big\|_{L^2(\mathcal{C}_\pm,\langle u_\mp\rangle^{2(1+\sigma)}du_\mp dx_2dx_3)}=0.",2502.01139
lemma,"For any $\alpha_h\in(\mathbb{Z}_{\geqslant 0})^2$  with  	$0\leqslant|\alpha_h|\leqslant N+2$, there hold 	 		\delta^{-\frac{3}{2}}\partial_h^{\alpha_h}z^3_{\pm}(\infty;u_\mp,x_2,x_3)\in L^2(\mathcal{C}_\pm,\langle u_\mp\rangle^{2(1+\sigma)}du_\mp dx_2dx_3), 	 	and  	  		\lim_{T\to\infty}\Big\|\delta^{-\frac{3}{2}}\partial_h^{\alpha_h}z^3_{\pm}(\infty;u_\mp,x_2,x_3)-\delta^{-\frac{3}{2}}\partial_h^{\alpha_h}z^3_{\pm}(T,u_\mp\mp T,x_2,x_3)\Big\|_{L^2(\mathcal{C}_\pm,\langle u_\mp\rangle^{2(1+\sigma)}du_\mp dx_2dx_3)}=0.",2502.01139
lemma,"For any $\alpha_h\in(\mathbb{Z}_{\geqslant 0})^2$ and $l\in\mathbb{Z}_{\geqslant 1}$ with  	$1\leqslant|\alpha_h|+l\leqslant N+2$, there hold 	 \delta^{l-\frac{1}{2}} 	\partial_h^{\alpha_h}\partial_3^l z_{\pm}(\infty;u_\mp,x_2,x_3)\in L^2(\mathcal{C}_\pm,\langle u_\mp\rangle^{2(1+\sigma)}du_\mp dx_2dx_3), and    	\lim_{T\to\infty}\Big\|\delta^{l-\frac{1}{2}}\partial_h^{\alpha_h}\partial_3^lz_{\pm}(\infty;u_\mp,x_2,x_3)-\delta^{l-\frac{1}{2}}\partial_h^{\alpha_h}\partial_3^lz_{\pm}(T,u_\mp\mp T,x_2,x_3)\Big\|_{L^2(\mathcal{C}_\pm,\langle u_\mp\rangle^{2(1+\sigma)}du_\mp dx_2dx_3)}=0.",2502.01139
lemma,"For any $\alpha_h\in(\mathbb{Z}_{\geqslant 0})^2$ and $l\in\mathbb{Z}_{\geqslant 0}$ with  	$0\leqslant|\alpha_h|+l\leqslant N+2$, there holds  	 		\delta^{l-\frac{1}{2}} 		\partial_h^{\alpha_h}\partial_3^l (\partial_3z_{\pm})(\infty;u_\mp,x_2,x_3)\in L^2(\mathcal{C}_\pm,\langle u_\mp\rangle^{2(1+\sigma)}du_\mp dx_2dx_3), 	 and    	\lim_{T\to\infty}\Big\|\delta^{l-\frac{1}{2}}\partial_h^{\alpha_h}\partial_3^l(\partial_3z_{\pm})(\infty;u_\mp,x_2,x_3)-\delta^{l-\frac{1}{2}}\partial_h^{\alpha_h}\partial_3^l(\partial_3z_{\pm})(T,u_\mp\mp T,x_2,x_3)\Big\|_{L^2(\mathcal{C}_\pm,\langle u_\mp\rangle^{2(1+\sigma)}du_\mp dx_2dx_3)}=0.",2502.01139
proof,"Notice that $\phi(t) \leq 1/2$ for all $ t \in \R$. Choose an arbitrary $x \in [0,1]$, we have $$  	\big|f_{\bfc,b}(x)-H_{n}(x)\big| 	=\bigg|\sum_{k=n}^\infty  c_k \phi(b^k x)\bigg| 	\leq \sum_{k=n}^\infty \frac{|c_k|}{2} 	\leq \sum_{k=n}^\infty \frac{\eta}{2b^k} 	= \frac{\eta \cdot b^{-n}}{2(1-\frac{1}{b})} 	 \leq \eta \cdot  b^{-n}.  $$ Thus, $(x,f_{\bfc,b}(x)) \in S_{n}$. For the arbitrariness of $x$, we have completed the proof.",2502.01140
proof,"Let $x_1=( i-1)/(2b^n)$ and $x_2=i/(2b^n)$. Fix integer $0 \leq k \leq n-1$. From \[   b^k x_1=\frac{i-1}{2b^{n-k}} \mbox{ and } b^k x_2=\frac{i}{2b^{n-k}}, \] we observe that there is no point $x \in (x_1,x_2)$ such that $b^k x=j/(2b^{n-k})$ for some $j\in \Z$.  Combining this with $n-k \geq 1$, we find that $0<\phi(b^k x) < 1/2$ for all $x\in (x_1,x_2)$.  Summing over $k$ from $0$ to $n-1$, $$ 	H_n(x)=\sum_{k=0}^{n-1} c_k \phi(b^k x), $$ is linear on the interval   $[x_1,x_2]$.   Thus, the proof is complete.",2502.01140
proof,"For any $t_1,t_2 \in \R$, we have  $$ 	\big|\phi(t_1)-\phi(t_2)\big| =\big|\dist(t_1,\Z)-\dist(t_2,\Z)\big| \leq \big|\dist(t_1,t_2)\big|=|t_1-t_2|. $$ Hence, for any $k \in \Z^+$ and $x_1,x_2 \in [0,1]$, we have  	\big| c_k\phi ( b^k x_1 )-c_k\phi ( b^k x_2)    \big|  	 \leq \big| c_k b^k (x_1 - x_2 )    \big| 	 \leq  \eta |x_1-x_2|   .  Summing over $k$ from $0$ to $n-1$, $$ 	\big| H_n(x_1)-H_n(x_2)\big| 	=\bigg|\sum_{k=0}^{n-1} c_k \phi(b^k x)- c_k \phi(b^k x)\bigg| 	\leq \sum_{k=0}^{n-1} \big| c_k b^k (x_1 - x_2 )    \big| 	\leq n \eta |x_1 - x_2 |. $$ Similarly, summing over $k$ from $n$ to $n+m-1$, $$ 	\big| H_{n,m}(x_1)-H_{n,m}(x_2)\big| 	\leq \sum_{k=n}^{n+m-1} \big| c_k b^k (x_1 - x_2 )    \big| 	\leq m \eta |x_1 - x_2 |. $$",2502.01140
proof,"Fix $n \in \mathbb{Z}^+\cup \{0 \}$, $m \in \Z^+$, and $1 \leq i \leq b^n$. For each $1 \leq j\leq b^m$, we write  $$ 	I_{j}=\Big[\frac{i-1}{b^n}+\frac{j-1}{b^{n+m}}    ,\frac{i-1}{b^n}+\frac{j}{b^{n+m}}   \Big]. $$ Define $$  	R_j=I_{j} \times [y  -  \eta  \cdot  b^{-n},y+ \eta  \cdot  b^{-n}]. $$ By the definition of $S_{n+m}$, we can see that if  $$   \g H_{n+m}\cap R_j \subset I_{j}\times \Big[ \frac{p}{b^{n+m}}, \frac{q}{b^{n+m}}\Big] $$ for some $p,q\in \R$, then  $$   S_{n+m}\cap R_j \subset I_{j}    \times \Big[ \frac{p-\eta}{b^{n+m}}, \frac{q+\eta}{b^{n+m}}\Big]. $$ Hence,   $$ 	\N_{b^{-n-m}}(S_{n+m}\cap R_j) \leq 2+2\eta+ \N_{b^{-n-m}}(\g H_{n+m} \cap R_j). $$ Let $I=[\frac{i-1}{b^n}    ,\frac{i-1}{b^n}] $ and $\wdt{R}=I \times [y-b^{-n},y+b^{-n}]$. By summing $j$ over $1$ to $b^m$,    \N_{b^{-n-m}}(S_{n+m}\cap \wdt{R}) \leq (2+2\eta)b^m+ \sum_{j=1}^{b^m} \N_{b^{-n-m}}(\g H_{n+m} \cap R_j).     Fix $y \in \R$. We write  $$D:=D(y,n)=\big\{x\in I:  |H_{n}(x)-y| \leq 2\eta\cdot b^{-n}  \big\}.$$ Let $J_1=[\frac{i-1}{b^n}    ,\frac{2i-1}{2b^n}] $ and $J_2=[\frac{2i-1}{2b^n}    ,\frac{i}{b^n}] $.  It is clear that  $$I=J_1 \cup J_2 =\bigcup_{j=1}^{b^m}  I_j.    $$ From Lemma~\ref{lem:linear}, $H_{n}$ is linear on both $J_1$ and $J_2$. Thus, we have  	&\sum_{j=1}^{b^m} O\big(H_{n}, I_{j} \cap D \big)   \\ 	\leq&\Var\big(H_{n},J_1\cap D\big)+\Var\big(H_{n}, J_2 \cap D\big)\\ 	\leq & 4\eta\cdot b^{-n}+ 4\eta\cdot b^{-n} = 8\eta\cdot b^{-n},  where $\Var(g,E)$ represents the variation of $g$ on $E$. From Lemma~\ref{lem:lips}, $H_{n,m}$ is Lipschitz on $I$. Moreover, we have  	\sum_{j=1}^{b^m} O\big(H_{n,m}, I_{j}  \big) 	\leq \sum_{j=1}^{b^m} m  \eta   \cdot  | I_{j} | 	=m\eta  \cdot  |I|=  m \eta \cdot b^{-n}.             %Fix $n \in \mathbb{Z}^+\cup \{0 \}$, $m \in \Z^+$, and $y\in \R$.   From Lemma~\ref{lem:cover}, for any $ x \notin D$, we have  $$ 	\big| H_{n+m}(x) -y\big|\geq \big| H_{n}(x)-y \big|-\big| H_{n}-H_{n-m}(x) \big| > 2\eta \cdot b^{-n}-\eta \cdot b^{-n}=\eta \cdot b^{-n}, $$ which implies that $	 	H_{n+m}(x) \notin [y-\eta \cdot b^{-n},y+ \eta \cdot b^{-n}]. $ Hence, we have $$ 	\g H_{n+m} \cap R_j \subset   \g H_{n+m} \cap \big( ( I_j\cap D)\times \R\big)    $$ Combining with Lemma~\ref{lem:osci}, we have  	& \N_{b^{-n-m}}(\g H_{n+m} \cap R_j)  \\ 	%\leq &  \N_{b^{-n-m}}\big(\g T_{n+m} \cap \big( ( I_j\cap D(y,n))\times \R\big)   \big) \\  	\leq & O( H_{n+m},I_j\cap D)/b^{-n-m}+2   \\  	\leq &b^{n+m} \big( O( H_{n},I_j\cap D)+O( H_{n,m},I_j\cap D)\big)+2  .  Combining with Eq.~\eqref{eq:count-1} and Eq.~\eqref{eq:count-2}, by summing $j$ over $1$ to $b^m$, we have   &\sum_{j=1}^{b^m} \N_{b^{-n-m}}(S_{n+m} \cap R_j) \\   \leq & (2\eta+2)  b^m+2b^m+ \sum_{j=1}^{b^m} b^{n+m}\Big(  O (H_{n}, I_{j} \cap D ) + O(H_{n,m}, I_j \cap D ) \Big) \\   \leq & (2\eta+4) b^m+  b^{n+m}(  8\eta \cdot b^{-n}+m\eta \cdot b^{-n})\\   =&(10\eta +m \eta +4  )b^m.  This completes the proof of the lemma.",2502.01140
proof,"[Proof of Theorem~\ref{thm:assouad}]    For any $x_0 \in [0,1]$ and $n \in \mathbb{Z}^+$, there exists $0 \leq i \leq b^n$ such that $$\Big[x_0-\frac{1}{b^n},x_0+\frac{1}{b^n}\Big]  \subset \Big[ \frac{i-1}{b^n},\frac{i+2}{ b^n} \Big]. $$ Let $y_0=f_\bfc(x_0)$, then we have $$ 	Q\big((x_0,y_0),b^{-n}\big)  	%=\Big[x_0-\frac{1}{b^n},x_0+\frac{1}{b^n}\Big] \times \Big[y_0-\frac{1}{b^n},y_0+\frac{1}{b^n}\Big] 	\subset \Big[ \frac{i-1}{b^n},\frac{i+2}{ b^n} \Big] \times  \Big[y_0- \frac{\eta}{b^n},y_0+\frac{\eta}{ b^n} \Big]. $$          %Therefore,  From Lemma~\ref{lem:tkey-new}, for any $m \in \mathbb{Z}^+$, we have  	&\N_{b^{-n-m}} \Big( \g f_{\bfc,b} \cap Q\big((x_0,y_0),b^{-n}\big) \Big) \\ 	\leq& \sum_{\ell=i}^{i+2} \N_{b^{-n-m}} \bigg( S_{n+m} \cap \Big(\Big[\frac{\ell-1}{b^n},\frac{\ell}{b^n}\Big] \times \Big[y_0- \frac{\eta}{b^n},y_0+\frac{\eta}{b^n} \Big] \Big) \bigg) \\ 	%\leq &\sum_{\ell=i+1}^{i+3}  (m+8)b^m\\ 	\leq &  3(10\eta +m \eta +4  )  b^m.   For any $\vep>0$, there exists a constant that $C_\vep>0$ such that  $$C_\vep b^{m\vep} \geq 3(10\eta +m \eta +4  )  ,\quad \forall m \in \Z^+.$$  Thus, $$\N_{b^{-n-m}} \Big( \g f_{\bfc,b} \cap Q\big( x,b^{-n}\big) \Big) \leq C_\vep b^{(1+\vep)m},$$ for all $x \in \g T_{a,b}$ and $n,m \in \Z^+$. This implies $1+\vep$ lies in the following set: $$ 	\big\{ \alpha:  \mbox{ for all } n,m \in \Z^+ \mbox{ and } x \in \g f_{\bfc,b} , \N_{b^{-n-m}}\big(Q(x,b^{-n})\cap  \g f_{\bfc,b}  \big) \lesssim  b^{\alpha m}  \big\}. $$ Therefore, we have $ \dim_A \g  f_{\bfc,b} \leq  1 +\vep$. For the arbitrariness of $\vep$, it follows that $$\dim_A \g f_{\bfc,b}  \leq 1.$$ On the other hand, it is clear that $\dim_A \g  f_{\bfc,b} \geq \underline\dim_B \g  f_{\bfc,b} \geq 1$. Thus, $$\dim_A \g  f_{\bfc,b}=1.$$",2502.01140
theorem,"[Consistency] The IPDG scheme \eqref{eqn1.18} is consistent, i.e., for the solution $\Eb\in\Vb \cap\Hb^2(\Omega)$ of the problem \eqref{eqn1.1}--\eqref{eqn1.2},   a_h(\Eb,\vb_h)+\int_\Omega\psi^0(\Eb;\vb_h)\mathrm{d}\xb\ge\langle\fb,\vb_h\rangle\quad\forall\,\vb_h\in\Vb_h.",2502.01148
theorem,"Assume \eqref{eqn1.other}, $m<\epsilon_0$ and $\eta > \max\{1,\mu_1^2\}\,\tilde{C}^2/(2\,\mu_0^2)$. Then for any $\fb\in \Vb^*$, the problem \eqref{eqn1.18} has a unique solution $\Eb_h\in\Vb_h$, which is also the unique solution of the minimization problem \eqref{minimization problem}.",2502.01148
theorem,"Assume $\{\mathcal{T}_h\}$ is a shape-regular family of tetrahedral or hexahedral mesh partitions of the domain $\overline{\Omega}$.  Let $\Eb$ and $\Eb_h$ be the solutions of \eqref{eqn1.1} and \eqref{eqn1.18}, respectively. Assume $\Eb \in \Hb_0(\curlb; \Omega) \cap \Hb^{s+1/2}(\Omega)$ and $\nabla\times \Eb \in \Hb^s(\Omega)$, $s > 1/2$. Choose the penalty constant $\eta > \max\{1,\mu_1^2\}\,\tilde{C}^2/(2\,\mu_0^2)$.  Then,   \| \Eb-\Eb_h\|_h \leq Ch^{(\min\{s,l\}+1)/2}.",2502.01148
definition,"Assume $\varphi: V\rightarrow \mathbb{R}\cup \{+\infty\}$ %we call $\rm{dom} \varphi = \{v\in V: \varphi(v) < +\infty\}$ the effective domain of function $\varphi$.  % %    \item If $\rm{dom} \varphi \neq \emptyset$, then $\varphi$ is called a proper function on $V$. %    \item $\varphi$ is a convex function on $V$ if, for all $u,v \in \text{dom}\varphi$ and $\lambda \in(0,1)$, it satisfies: %    \[ %    \varphi(\lambda u +(1-\lambda)v) \leq \lambda \varphi(u)+(1-\lambda) \varphi(v). %    \] %    \item $\varphi$ is called lower semicontinuous on $V$ if, for all $u\in V$ and any sequence $\{u_n\}\subset V$ satisfying $u_n\rightarrow u$, the following holds: %    \[ %    \liminf_{n\rightarrow \infty}\varphi(u_n) \geq \varphi(u). %    \] % %Now,  is a proper, convex, and lower semicontinuous function on $V$. The set \[ \partial_c\varphi(u)=\{\xi\in V^*:\varphi(v)-\varphi(u)\geq \langle\xi, v-u\rangle\ \forall\, v \in V\} \] is called the convex subdifferential of the function $\varphi$ at $u\in V$. If $\partial_c\varphi(u)\neq \emptyset$, any element $\xi \in \partial_c\varphi(u)$ is called a subgradient of $\varphi$ at $u$.",2502.01148
definition,"%Let $\psi: V\rightarrow \mathbb{R}$. (1) If there exists a constant $L>0$ such that %\[ %|\psi(u)-\psi(v)|\leq L\| u-v\|_V \quad \forall u,v\in V %\] %holds, then the function $\psi$ is said to be Lipschitz continuous on $V$. (2) If for every $w\in V$, there exists a neighborhood $N_w$ of $w$ and a constant $L_w>0$ such that %\[ %|\psi(u)-\psi(v)| \leq L_w\| u-v\|_V \quad \forall u,v\in N_w, %\] %then the function $\psi$ is  said to be locally Lipschitz continuous on $V$. %",2502.01148
definition,"Assume $\psi: V\rightarrow\mathbb{R}$ is a locally Lipschitz continuous function. The generalized directional derivative of $\psi$ at $u\in V$ in the direction $v\in V$ is defined as \[ \psi^0(u;v)=\limsup_{w\rightarrow u,\lambda \downarrow 0}\frac{\psi(w+\lambda v)-\psi(w)}{\lambda}, \] and the Clarke subdifferential of $\psi$ at $u\in V$ is defined as \[ \partial \psi(u)=\{\xi \in V^*: \psi^0(u;v)\geq \langle\xi,v\rangle\text{ } \forall  v\in V \}. \]",2502.01148
definition,"[Sobolev space] %Fix $1\leq p\leq \infty$ and let $k$ be a nonnegative integer, $\Omega \subset \mathbb{R}^n$ is open. Define Sobolev space: %\[ %W^{k,p}(\Omega)= \{u\in L^p(\Omega):D^\alpha u \in L^p(\Omega) \quad \forall |\alpha|\leq m\}. %\] %If $u\in W^{k,p}(\Omega)$, we define its norm to be  % % %\|u\|_{W^{k,p}(\Omega)}= % %\left(\sum_{|\alpha|\leq k}\int_{\Omega}|D^\alpha|^p \mathrm{d}x\right)^{1/p} \quad (1\leq p<\infty) \\ %\sum_{|\alpha|\leq k} \textnormal{ess }\sup_{\Omega} |D^\alpha u| \quad (p=\infty). % % % %If $p=2$, we usually write $H^k(\Omega)=W^{k,2}(\Omega)$, and their corresponding norm are denoted by $\|\cdot\|_{k,\Omega}$. Particularly, when $k=0$, $H^0(\Omega)=L^2(\Omega)$, and its corresponding norm is written as $\|\cdot\|_{0,\Omega}$. %",2502.01148
definition,"%Let $\Omega\subset\mathbb{R}^3$, in our paper, we use bold font $\Lb^s(\Omega)$, $\Hb^s(\Omega)$ and $\boldsymbol{P}^s(\Omega)$ to represent the sets of those three-dimensional vector functions, each of whose components is an $L^s(\Omega)$ function, $H^s(\Omega)$ function and a polynomial of degree no higher than $s$ on $\Omega$ respectively. That is %\[ %\Lb^s(\Omega) = \{\ub=(u_1(\xb), u_2(\xb), u_3(\xb))| u_i(\xb)\in L^s(\Omega), i=1,2,3\}, %\] %\[ %\Hb^s(\Omega) = \{\ub=(u_1(\xb), u_2(\xb), u_3(\xb))| u_i(\xb)\in H^s(\Omega), i=1,2,3\}. %\] %\[ %\boldsymbol{P}^s(\Omega) = \{\ub=(u_1(\xb), u_2(\xb), u_3(\xb))| u_i(\xb)\in P^s(\Omega), i=1,2,3\}. %\] %And we also use normal font $u$ and bold font $\ub$ to distinguish scalar function and vector function. %",2502.01148
definition,"%Let $\Omega \subset \mathbb{R}^3$, define the space %\[ %\Hb(\curlb,\Omega)=\left\{\vb\in\Lb^2(\Omega):\nabla\times \vb\in \Lb^2(\Omega)\right\}, %\] %where the curl operator $\nabla\times$ is defined as %\[ %\nabla\times \vb=\left(\frac{\partial v_3}{\partial x_2}-\frac{\partial v_2}{\partial x_3},\frac{\partial v_1}{\partial x_3}-\frac{\partial v_3}{\partial x_1},\frac{\partial v_2}{\partial x_1}-\frac{\partial v_1}{\partial x_2}\right)^T. %\] % %We introduce the norm %\[ %\| \boldsymbol{v}\|_{\curlb,\Omega}=\left(\|\boldsymbol{v} \|_{0,\Omega}^2+\|\nabla\times\boldsymbol{v}\|_{0,\Omega}^2\right)^{1/2}. %\] %",2502.01148
definition,"%We denote the closure of $\boldsymbol{C}^\infty_0(\Omega)$ in $\Hb(\curlb,\Omega)$ by $\Hb_0(\curlb,\Omega)$. It can be verified that %\[ %\Hb_0(\curlb,\Omega)=\left\{\vb\in\Hb(\curlb,\Omega): \nb\times \vb=\zerob \quad \text{on }\partial\Omega\right\}, %\] %where $\nb$ is the unit outward normal vector on $\partial\Omega$. %",2502.01148
proof,"The discrete bilinear form (\ref{eqn1.17}) is defined with $\Eb_h$ replaced by $\Eb$.  Applying equation (\ref{eqn1.11}), we notice that the fourth term of $a_h(\Eb,\vb_h)$ is         -\sum_{f\in\mathcal{F}_h}\int_f\llbracket\vb_h\rrbracket\cdot\{\mu^{-1}\nabla\times\Eb\}\mathrm{d}S=&-\sum_{K\in\mathcal{T}_h}\int_{\partial K}\mu^{-1}(\vb_h\times\nabla\times\Eb)\cdot \nb_K\mathrm{d}S     \\      &-\sum_{f\in\mathcal{F}_h^{\mathcal{I}}}\int_f\llbracket\mu^{-1}\nabla\times\Eb\rrbracket\cdot\{\vb_h\}\mathrm{d}S.      Moreover, $\llbracket \Eb \rrbracket = \zerob$ on $\mathcal{F}_h$ and $\llbracket \nabla\times \Eb \rrbracket = \zerob$ on $\mathcal{F}_h^{\mathcal{I}}$. Therefore,   a_h(\Eb,\vb_h) & =\int_\Omega\epsilon \Eb\cdot\vb_h\mathrm{d}\xb+\int_\Omega\mu^{-1}(\nabla\times\Eb)\cdot(\nabla_h\times\vb_h)\mathrm{d}\xb\\ &\quad{} -\sum_{K\in\mathcal{T}_h}\int_{\partial K}\mu^{-1}(\vb_h\times\nabla\times\Eb)\cdot \nb_K\mathrm{d}S.  Applying the integration by parts formula (\ref{eqnpar}) on the integration region $K\in\mathcal{T}_h$, we have  \int_K\mu^{-1}(\nabla\times\Eb)\cdot(\nabla\times\vb_h)\mathrm{d}\xb & =\int_K\nabla\times(\mu^{-1}\nabla\times\Eb)\cdot\vb_h\mathrm{d}\xb\\ &\quad{} -\int_{\partial K}\mu^{-1}((\nabla\times\Eb)\times\vb_h)\cdot\nb_K\mathrm{d}S.  Thus,  	a_h(\Eb,\vb_h)=\int_\Omega\epsilon \Eb\cdot\vb_h\mathrm{d}\xb+\int_\Omega\nabla\times(\mu^{-1}\nabla\times\Eb)\cdot\vb_h\mathrm{d}\xb.  Multiplying both sides of equation (\ref{eqn1.1}) by a function $\vb_h \in \Vb_h$ and integrating over $\Omega$, we obtain \[ \int_\Omega\epsilon\Eb\cdot\vb_h\mathrm{d}\xb+\int_\Omega\nabla\times(\mu^{-1}\nabla\times\Eb)\cdot\vb_h\mathrm{d}\xb+\int_\Omega \Jb \cdot \vb_h\mathrm{d}\xb=\int_\Omega\tilde{\lb}\cdot \vb_h\mathrm{d}\xb. \] Since $\Jb \in \partial \psi(\Eb)$ and by the definition of the functional $\fb \in \Vb^*$, \eqref{eq:cons} follows.",2502.01148
proof,"Using H\""{o}lder's inequality, we can get     			   		 \int_K\mu^{-1}(\nabla\times\Eb)\cdot(\nabla\times\vb)\mathrm{d}\xb  &\leq \mu_0^{-1}\int_K|\nabla\times\Eb|\cdot|\nabla\times\vb|\mathrm{d}\xb\\ &\leq \mu_0^{-1}\|\nabla_h\times \Eb \|_{0,K}\|\nabla_h\times \vb \|_{0,K}.   Similarly,  \int_f \alpha\llbracket \Eb \rrbracket \cdot \llbracket \vb \rrbracket \mathrm{d}S  &\leq  \| \alpha^{1/2}\llbracket\Eb\rrbracket\|_{0,f}\| \alpha^{1/2}\llbracket\vb\rrbracket\|_{0,f},\\ \int_\Omega\epsilon \Eb\cdot \vb \mathrm{d}\xb & \leq\epsilon_1\|\Eb\|_{0,\Omega}\|\vb\|_{0,\Omega}.  Now let us bound the third term of the bilinear form $\tilde{a}_h(\cdot,\cdot) $ which is a modification of the proof of \cite[Lemma 4]{grote2007interior}.   &\sum_{f\in\mathcal{F}_h}\int_f\llbracket\Eb\rrbracket\cdot\{\mu^{-1}\Pib_h(\nabla_h\times\vb)\}\mathrm{d}S \\ \leq &\mu_0^{-1}\sum_{f\in\mathcal{F}_h}\int_f\left|\alpha^{1/2}\llbracket\Eb\rrbracket\right|\cdot\left|\alpha^{-1/2}\{\Pib_h(\nabla_h\times\vb)\}\right|\mathrm{d}S   \\ \leq &\mu_0^{-1}\sum_{f\in\mathcal{F}_h} \|\alpha^{1/2}\llbracket\Eb\rrbracket\|_{0,f} \cdot \|\alpha^{-1/2}\{\Pib_h(\nabla_h\times\vb)\}\|_{0,f}  \\ \leq &\mu_0^{-1}\left(\sum_{f\in\mathcal{F}_h} \int_f\alpha\left|\llbracket\Eb\rrbracket\right|^2 \mathrm{d}S\right)^{1/2} \cdot \left(\sum_{f\in\mathcal{F}_h} \int_f\alpha^{-1} \left| \{\Pib_h(\nabla_h\times\vb)\} \right|^2 \mathrm{d}S\right)^{1/2} \\ = &  \mu_0^{-1}\eta^{-1/2}\left(\sum_{f\in\mathcal{F}_h} \|\alpha^{1/2}\llbracket\Eb\rrbracket\|^2_{0,f}\right)^{1/2} \cdot\left(\sum_{f\in\mathcal{F}_h} \int_f  h_f\left| \{\Pib_h(\nabla_h\times\vb)\} \right|^2 \mathrm{d}S\right)^{1/2}.   Using the definition of $h_f$, we can get   \sum_{f\in\mathcal{F}_h} \int_f  h_f \left| \{\Pib_h(\nabla_h\times\vb)\} \right|^2 \mathrm{d}S&\leq \frac{1}{2}\sum_{K\in\mathcal{T}_h}\int_{\partial K}h_K  |\Pib_h(\nabla\times \vb)|^2 \mathrm{d}S \\ & \leq \frac{1}{2}\sum_{K\in\mathcal{T}_h}h_K\| \Pib_h(\nabla\times \vb)\|^2_{0,\partial K}.    Recalling the trace theorem\textsuperscript{\cite[Chapter 5.5, Theorem 1]{evans2022partial}} and inverse inequality\textsuperscript{\cite[Lemma (4.5.3)]{brenner2008mathematical}}  \[ \| \wb \|^2_{0,\partial K} \leq C_{tr}^2 \|\wb\|^2_{W^{1,2}(K)} \leq C_{tr}^2C_{inv}^2 h^{-1}_K \| \wb\|_{0,K}^2 \quad \forall\, \wb\in\boldsymbol{P}^l(K),\ \forall\, K\in\mathcal{T}_h, \] where the positive constants $C_{tr}$ and $C_{inv}$ depend only on the regularity of the mesh and the polynomial degree $l$ of the finite element space. Henceforth, we use $\tilde{C}$ to replace $C_{tr}C_{inv}$. From the $L^2$-projection property, \[ \| \Pib_h \wb \|_{0,K} \leq \|\wb \|_{0,K} \quad \forall\, \wb \in \Lb^2(K). \] Then, combining the above result, we can obtain   \frac{1}{2}\sum_{K\in\mathcal{T}_h}h_K\|  \Pib_h(\nabla\times \vb)\|^2_{0,\partial K}\leq \frac{1}{2}\tilde{C}^2\sum_{K\in\mathcal{T}_h} \|\nabla\times \vb\|^2_{0,K}.  Finally, we obtain the bound   \sum_{f\in\mathcal{F}_h}\int_f\llbracket\Eb\rrbracket\cdot\{\mu^{-1}\Pib_h(\nabla_h\times\vb)\}\mathrm{d}S  \leq & \mu_0^{-1}(2\eta)^{-1/2}\tilde{C} \left(\sum_{f\in\mathcal{F}_h} \|\alpha^{1/2}\llbracket\Eb\rrbracket\|^2_{0,f}\right)^{1/2}  \\ &  \cdot \left(\sum_{K\in\mathcal{T}_h} \|\nabla\times \vb\|^2_{0,K} \right)^{1/2}    Similarly, we can bound the fourth term of the bilinear form as    \sum_{f\in\mathcal{F}_h}\int_f\llbracket\vb\rrbracket\cdot\{\mu^{-1}\nabla_h\times\Eb\}\mathrm{d}S \leq & \mu_0^{-1}(2\eta)^{-1/2}\tilde{C} \left(\sum_{f\in\mathcal{F}_h} \|\alpha^{1/2}\llbracket\vb\rrbracket\|^2_{0,f}\right)^{1/2}  \\ &  \cdot \left(\sum_{K\in\mathcal{T}_h} \| \nabla\times \Eb\|^2_{0,K} \right)^{1/2}.   Combining these results, we get \eqref{ah:bd}.",2502.01148
proof,"\[ \int_\Omega\epsilon \Eb\cdot \Eb \mathrm{d}\xb \geq \epsilon_0\|  \Eb\|_{0,\Omega}^2 , \] \[	\sum_{K\in\mathcal{T}_h}\int_K\mu^{-1}(\nabla\times\Eb)\cdot(\nabla\times\Eb)\mathrm{d}\xb \geq\mu_1^{-1}\sum_{K\in\mathcal{T}_h} \|\nabla_h\times \Eb \|_{0,K}^2, \] \[ \sum_{f\in\mathcal{F}_h}\int_f \alpha\llbracket\Eb\rrbracket\cdot\llbracket\Eb\rrbracket\mathrm{d}S=\sum_{f\in\mathcal{F}_h}\| \alpha^{1/2}\llbracket\Eb\rrbracket\|_{0,f}^2. \] Similar to the proof of Lemma \ref{lemma:boundeness}, we have  &-2\sum_{f\in\mathcal{F}_h}\int_f\llbracket\Eb\rrbracket\cdot\{\mu^{-1}\Pib_h(\nabla\times\Eb)\}\mathrm{d}S \\ \geq&-2\mu_0^{-1}(2\eta)^{-1/2}\tilde{C}\left(\sum_{f\in\mathcal{F}_h}\| \alpha^{1/2}\llbracket\Eb\rrbracket\|_{0,f}^2\right)^{1/2} \cdot \left( \sum_{K\in\mathcal{T}_h}\|\nabla\times \Eb\|_{0,K}^2 \right)^{1/2} \\ \geq&-\mu_0^{-1}(2\eta)^{-1/2}\tilde{C}\left(\sum_{f\in\mathcal{F}_h}\| \alpha^{1/2}\llbracket\Eb\rrbracket\|_{0,f}^2+\sum_{K\in\mathcal{T}_h}\|\nabla\times \Eb\|_{0,K}^2 \right).  Therefore, when $\eta > \max\{1,\mu_1^2\}\,\tilde{C}^2/(2\,\mu_0^2)$, $\tilde{a}_h(\Eb,\Eb)$ is bounded from below by }  &\epsilon_0\|  \Eb\|_{0,\Omega}^2 + \left(1-\mu_0^{-1}(2\eta)^{-1/2}\tilde{C}\right)\sum_{f\in\mathcal{F}_h}\| \alpha^{1/2}\llbracket\Eb\rrbracket\|_{0,f}^2 \\ &+\left(\mu_1^{-1}-\mu_0^{-1}(2\eta)^{-1/2}\tilde{C}\right)\sum_{K\in\mathcal{T}_h}\|\nabla\times \Eb\|_{0,K}^2.   Denote $C_0 = 1-\mu_0^{-1}(2\eta)^{-1/2}\tilde{C}$, $C_1 = \mu_1^{-1}-\mu_0^{-1}(2\eta)^{-1/2}\tilde{C}$.  Then, \[ \tilde{a}_h(\Eb,\Eb) \geq C_s\left(\sum_{f\in\mathcal{F}_h}\| \alpha^{1/2}\llbracket\Eb\rrbracket\|_{0,f}^2+\sum_{K\in\mathcal{T}_h}\|\nabla\times \Eb\|_{0,K}^2+\| \Eb\|_{0,\Omega}^2 \right) \] holds, where $C_s = \min\{\epsilon_0, C_0, C_1\}$.",2502.01148
proof,"By setting $\vb_h=-\Eb_h$ in (\ref{eqn1.18}), we obtain  	a_h(\Eb_h,\Eb_h) \leq \int_\Omega\psi^0(\Eb_h;-\Eb_h) \mathrm{d}\xb +\langle \fb,\Eb_h \rangle.  From assumption (\ref{eqn1.other})\,(d), we have  	\psi^0(\Eb_h;\zerob-\Eb_h) + \psi^0(\zerob;\Eb_h-\zerob) \leq m|\Eb_h|^2,  Using (\ref{eqn1.other2}) to get \[  -\psi^0(\zerob;\Eb_h)\leq c_0|\Eb_h|; \] hence,  \int_\Omega\psi^0(\Eb_h;-\Eb_h) \mathrm{d}\xb \leq m\|\Eb_h\|_{0,\Omega}^2 + \int_\Omega c_0|\Eb_h| \mathrm{d}\xb.  Moreover, \[ \langle \fb,\Eb_h\rangle\leq\| \fb \|_{\Vb^*}\| \Eb_h\|_{\curlb,\Omega}\leq \| \fb \|_{\Vb^*} \|\Eb_h\|_h.\] By the Cauchy-Schwarz inequality,  \[ \int_\Omega c_0 |\Eb_h|\mathrm{d}\xb \leq c_0 |\Omega|^{1/2}\| \Eb_h \|_{0,\Omega}, \] where $|\Omega|$ means the Lebesgue measurement of the bounded domain $\Omega$. Combine these inequalities with the lower bound (\ref{lower bound of tiled{a}}) of $\tilde{a}(\Eb_h, \Eb_h)$ to get  &(\epsilon_0-m)\|  \Eb\|_{0,\Omega}^2 + C_0\sum_{f\in\mathcal{F}_h}\| \alpha^{1/2}\llbracket\Eb\rrbracket\|_{0,f}^2 + C_1 \sum_{K\in\mathcal{T}_h}\|\nabla\times \Eb\|_{0,K}^2	\\ &\leq \left(c_0|\Omega|^{-1/2}+\|\fb\|_{\Vb^*}  \right)\|\Eb_h\|_h .  Since $\epsilon_0-m>0$ and $\eta > \max\{1,\mu_1^2\}\,\tilde{C}^2/(2\,\mu_0^2)$, then  \|\Eb_h\|_h \leq \frac{c_0|\Omega|^{-1/2}+\|\fb\|_{\Vb^*}}{\min\{\epsilon_0-m, C_0, C_1\}}.  Therefore, $\|\Eb_h\|_h$ is bounded by a constant independent of $h$.",2502.01148
proof,"The local Lipschitz continuity of $\mathcal{E}(\cdot)$ is obvious. Let us prove the strong convexity. For this purpose, define a linear operator $A_h \colon \Vb_h \to \Vb_h^*$ by   \langle A_h \ub_h, \vb_h\rangle \;=\; a_h(\ub_h,\vb_h) \quad \forall\,\ub_h,\vb_h \in \Vb_h.  Applying Lemma~\ref{lemma:boundeness}, we obtain   \|A_h\ub_h\|_{\Vb_h^*} = \sup_{\|\vb_h\|_h \ne 0} \frac{|\langle A_h\ub_h, \vb_h\rangle|}{\|\vb_h\|_h} = \sup_{\|\vb_h\|_h \ne 0} \frac{|a_h(\ub_h, \vb_h)|}{\|\vb_h\|_h} \leq C_b \|\ub_h\|_h \quad \forall \ub_h \in \Vb_h.  By Lemma~\ref{lemma:stability},    \langle A_h\ub_h - A_h\vb_h, \ub_h - \vb_h \rangle = a_h(\ub_h - \vb_h, \ub_h - \vb_h) \geq C_s \|\ub_h-\vb_h\|_h^2 \quad \forall  \ub_h, \vb_h \in \Vb_h.   So $A_h \in \mathcal{L}(\Vb_h, \Vb_h^*)$ and it is strongly monotone. Define a functional $\Psi : \Lb^2(\Omega) \to \mathbb{R}$ by \[ \Psi(\vb) \;=\; \int_\Omega \psi(\vb)\,\mathrm{d}\xb \quad \forall\,\vb \in \Lb^2(\Omega). \] Then, by \cite[Theorem~3.47]{migorski2013nonlinear}, under assumption (\ref{eqn1.other}), $\Psi$ is well defined, locally Lipschitz continuous on $\Lb^2(\Omega)$, and   \partial \Psi(\vb) \;\subset\; \int_\Omega \partial \psi\bigl(\vb)\,\mathrm{d}\xb  in the sense that for any $\xib \in \partial \Psi(\vb)$, there exists a function $\zetab \in \Lb^2(\Omega)$ such that $\zetab(\xb) \in \partial \psi\bigl(\xb,\vb(\xb)\bigr)$ for a.e.\ $\xb \in \Omega$ and \[ \langle \xib,\,\wb\rangle_{\Lb^2(\Omega)\times \Lb^2(\Omega)} \;=\; \int_\Omega \zetab(\xb) \cdot \wb(\xb)\,\mathrm{d}\xb \quad \forall\,\wb \in \Lb^2(\Omega). \] For $\vb_h \in \Vb_h$ and $\etab \in \partial \mathcal{E}(\vb_h)$, by (\ref{subaddition of Clarke}) we can write   \etab = A_h \vb_h + \xib - \fb, \quad \xib \in \partial \Psi(\vb_h).  Thus, for $i=1,2$, with $\vb_{h,i} \in \Vb_h$ and $\etab_i \in \partial \mathcal{E}(\vb_{h,i})$, by \eqref{eq:4.4} we have $\zetab_i \in \Lb^2(\Omega)$ such that $\zetab_i(x) \in \partial \psi\bigl(\xb,\vb_{h,i}(x)\bigr)$ for a.e.\ $\xb \in \Omega$ and \[ \langle \etab_i, \wb\rangle \;=\; \langle A_h \vb_{h,i}, \wb\rangle \;+\; \int_\Omega \zetab_i(\xb)\cdot \wb(\xb)\,\mathrm{d}\xb \;-\; \langle \fb, \wb\rangle \quad \forall\,\wb \in \Lb^2(\Omega). \] Thus, from (\ref{property of psi 5}) and Lemma~\ref{lemma:stability},   \langle \etab_1 - \etab_2,\; \vb_{h,1} - \vb_{h,2}\rangle = &\langle A_h \vb_{h,1} - A_h\vb_{h,2}, \vb_{h,1} - \vb_{h,2}\rangle+\int_\Omega \bigl(\zetab_1 - \zetab_2\bigr)\cdot (\vb_1 - \vb_2)\,\mathrm{d}\xb \\ \geq  &(\epsilon_0-m)\|  \vb_{h,1} - \vb_{h,2}\|_{0,\Omega}^2 + C_0\sum_{f\in\mathcal{F}_h}\| \alpha^{1/2}\llbracket\vb_{h,1} - \vb_{h,2}\rrbracket\|_{0,f}^2 \\ &+C_1\sum_{K\in\mathcal{T}_h}\|\nabla\times (\vb_{h,1} - \vb_{h,2})\|_{0,K}^2 \\ \geq& \min\{\epsilon_0-m, C_0, C_1\} \| \vb_{h,1} - \vb_{h,2}\|_h.   Thus, by Lemma~\ref{lem:2.2}, $\mathcal{E}(\cdot)$ is strongly convex. Moreover, by Proposition~\ref{prop:2.3}, $\mathcal{E}(\cdot)$ is coercive on~$\Vb_h$.",2502.01148
proof,"Since $\mathcal{E}(\cdot)$ is continuous, strictly convex and coercive on $\Vb_h$, from \cite[\S3.3.2]{han2009theoretical} the minimization problem (\ref{minimization problem}) has a unique solution.",2502.01148
proof,"For the solution $\Eb_h\in\Vb_h$ of the minimization problem (\ref{minimization problem}), we apply (\ref{eqn eta}) to get \[ \langle A_h\Eb_h, \vb_h \rangle + \int_\Omega \zetab(\xb)\cdot \vb_h(\xb) \mathrm{d}\xb - \langle \fb, \vb_h \rangle \geq 0, \] where $\zetab \in L^2(\Omega)$ such that $\zetab(\xb) \in \partial \psi\bigl(\xb,\vb_h(\xb)\bigr)$ for a.e.\ $\xb \in \Omega$. Using the property of the Clarke subdifferential (\ref{eqnclarke1}) we have \[ \psi^0(\Eb_h(\xb); \vb_h(\xb)) \geq \zetab(\xb)\cdot \vb_h(\xb_h) \quad \text{a.e. } \xb \in \Omega. \] Combining the above two inequalities, we can see that $\Eb_h$ is a solution of the problem (\ref{eqn1.18}).   Now, let's prove uniqueness of the solution. Assume, $\Eb_h, \tilde{\Eb}_h\in\Vb_h$ are two solutions of the problem (\ref{eqn1.18}). Then we have   a_h(\tilde{\Eb}_h,\vb_h)+\int_\Omega\psi^0(\tilde{\Eb}_h;\vb_h)\mathrm{d}\xb \geq\langle \fb,\vb_h\rangle\quad \forall \vb_h\in\Vb_h.  Take $\vb_h = \tilde{\Eb}_h-\Eb_h$ in (\ref{eqn1.18}) and $\vb_h = \Eb_h-\tilde{\Eb}_h$ in (\ref{finite element problem 2}). Add the two resulting inequalities, combining it with Lemma \ref{lemma:stability} to get    &\epsilon_0\|  \tilde{\Eb}_h - \Eb_h\|_{0,\Omega}^2 + C_0\sum_{f\in\mathcal{F}_h}\| \alpha^{1/2}\llbracket\tilde{\Eb}_h - \Eb_h\rrbracket\|_{0,f}^2 +C_1\sum_{K\in\mathcal{T}_h}\|\nabla\times (\tilde{\Eb}_h - \Eb_h)\|_{0,K}^2  \\  & \leq a_h(\tilde{\Eb}_h-\Eb_h,\tilde{\Eb}_h-\Eb_h) \leq \int_{\Omega} \left(\psi^0(\Eb_h;\tilde{\Eb}_h - \Eb_h) + \psi^0(\tilde{\Eb}_h; \Eb_h-\tilde{\Eb}_h) \right) \mathrm{d}\xb  \\ & \leq m \| \tilde{\Eb}_h - \Eb_h \|_{0,\Omega}^2.   By the smallness condition $m<\epsilon_0$, we deduce that $\tilde{\Eb}_h = \Eb_h$.",2502.01148
proof,"Denote $\Eb_I=\Pib_N\Eb$ and write  \tilde{a}_h(\Eb_I-\Eb_h,\Eb_I-\Eb_h)=T_1+T_2,  where $T_1=\tilde{a}_h(\Eb_I-\Eb,\Eb_I-\Eb_h)$ and $T_2=\tilde{a}_h(\Eb-\Eb_h,\Eb_I-\Eb_h)$. Using the modified Cauchy-Schwarz inequality with $\varepsilon$ \eqref{mCS} and the boundeness result (Lemma \ref{lemma:boundeness}), we have, for any small $\varepsilon>0$  T_1\leq C_b\|\Eb_I-\Eb\|_h \|\Eb_I-\Eb_h\|_h  \leq \frac{\varepsilon}{4}\|\Eb_I-\Eb_h\|_h^2+\frac{C_b^2}{\varepsilon}\|\Eb_I-\Eb\|_h^2.  Note that on $\mathcal{F}_h$, $\llbracket\Eb\rrbracket=\zerob$, $\{\Eb\}=\Eb$, and $ \llbracket\nabla\times\Eb\rrbracket=\zerob$.  Thus, \notag \tilde{a}_h(\Eb,\Eb_I-\Eb_h)=&\int_\Omega\epsilon \Eb \cdot (\Eb_I-\Eb_h) \mathrm{d}\xb+\sum_{K\in\mathcal{T}_h}\int_K\mu^{-1} (\nabla\times \Eb) \cdot (\nabla\times(\Eb_I-\Eb_h))\mathrm{d}\xb \\\notag &-\sum_{f\in\mathcal{F}_h}\int_f\llbracket\Eb_I-\Eb_h\rrbracket\cdot \{\mu^{-1}\Pib_h(\nabla\times\Eb)\}\mathrm{d}S \\\notag =&\sum_{K\in\mathcal{T}_h}\int_K\left(\epsilon\Eb+\nabla\times\left(\mu^{-1}\nabla\times\Eb\right)\right)\cdot (\Eb_I-\Eb_h)\mathrm{d}\xb 	\\\notag 	&-\sum_{K\in\mathcal{T}_h}\int_{\partial K} \left(\left(\mu^{-1}\nabla\times\Eb\right)\times(\Eb_I-\Eb_h)\right)\cdot \nb_K\mathrm{d}S 	\\\notag 	&-\sum_{f\in\mathcal{F}_h}\int_f\llbracket\Eb_I-\Eb_h\rrbracket\cdot \left\{\mu^{-1}\Pib_h(\nabla\times\Eb)\right\}\mathrm{d}S 	\\\notag 	=&\sum_{K\in\mathcal{T}_h}\int_K\left(\tilde{\lb}-\Jb\right)\cdot (\Eb_I-\Eb_h)\mathrm{d}\xb     \\\notag 	&+\sum_{f\in\mathcal{F}_h}\int_f\llbracket\Eb_I-\Eb_h\rrbracket \cdot \left\{\mu^{-1}\nabla\times\Eb-\mu^{-1}\Pib_h(\nabla\times\Eb)\right\}\mathrm{d}S 	\\  	\leq&\langle\fb,\Eb_I-\Eb_h\rangle + \int_\Omega \psi^0(\Eb;\Eb_h-\Eb_I)\mathrm{d}\xb+r_h(\Eb;\Eb_I-\Eb_h).  Letting $\vb_h=\Eb_I-\Eb_h$ in (\ref{eqn1.18}), we get  	-\tilde{a}_h(\Eb_h,\Eb_I-\Eb_h)=-a_h(\Eb_h,\Eb_I-\Eb_h)\leq \int_\Omega\psi^0(\Eb_h;\Eb_I-\Eb_h)\mathrm{d}\xb-\langle\fb,\Eb_I-\Eb_h\rangle.  Combining (\ref{eqn2.12}) and (\ref{eqn2.13}), using the subadditivity of Clarke subdifferentials, we obtain   T_2 \leq&  \int_\Omega \psi^0(\Eb;\Eb_h-\Eb_I)\mathrm{d}\xb +\int_\Omega\psi^0(\Eb_h;\Eb_I-\Eb_h)\mathrm{d}\xb + r_h(\Eb;\Eb_I-\Eb_h) \\ \leq  &\int_\Omega \psi^0(\Eb;\Eb_h-\Eb)\mathrm{d}\xb+\int_\Omega \psi^0(\Eb;\Eb-\Eb_I)\mathrm{d}\xb \\ &+\int_\Omega\psi^0(\Eb_h;\Eb_I-\Eb)\mathrm{d}\xb+\int_\Omega\psi^0(\Eb_h;\Eb-\Eb_h)\mathrm{d}\xb+r_h(\Eb;\Eb_I-\Eb_h).   Using (\ref{eqn1.other})\,(d), we obtain \notag \int_\Omega \psi^0(\Eb;\Eb_h-\Eb)\mathrm{d}\xb+\int_\Omega\psi^0(\Eb_h;\Eb-\Eb_h)\mathrm{d}\xb\leq m\|\Eb-\Eb_h\|^2_{0,\Omega}.  By the triangle inequality $\|\Eb-\Eb_h\|_{0,\Omega}\le\|\Eb-\Eb_I\|_{0,\Omega}+\|\Eb_I-\Eb_h\|_{0,\Omega}$ and the modified Cauchy-Schwarz inequality \eqref{mCS}, \[ \|\Eb-\Eb_h\|^2_{0,\Omega}\le (1+\varepsilon)\|\Eb_I-\Eb_h\|_{0,\Omega}^2+(1+1/\varepsilon)\|\Eb-\Eb_I\|_{0,\Omega}^2.\] Therefore,   &\int_\Omega \psi^0(\Eb;\Eb_h-\Eb)\mathrm{d}\xb+\int_\Omega\psi^0(\Eb_h;\Eb-\Eb_h)\mathrm{d}\xb \\ \leq&(1+\varepsilon) m\|\Eb_I-\Eb_h\|_{0,\Omega}^2+(1+1/\varepsilon)m\|\Eb-\Eb_I\|_{0,\Omega}^2.   Using (\ref{eqn1.other2}), we have  \int_\Omega \psi^0(\Eb;\Eb-\Eb_I)\mathrm{d}\xb \leq\int_\Omega(c_0+c_1|\Eb|)|\Eb-\Eb_I|\mathrm{d}\xb,	\\ \int_\Omega \psi^0(\Eb_h;\Eb_I-\Eb)\mathrm{d}\xb \leq\int_\Omega(c_0+c_1|\Eb_h|)|\Eb-\Eb_I|\mathrm{d}\xb.  Since $\Omega$ is a bounded domain, using the uniform boundedness of $\Eb_h$ and the Cauchy-Schwarz inequality, we have constants $C_{Eb},C_{Ehb}>0$ such that  \int_\Omega(c_0+c_1|\Eb|)|\Eb-\Eb_I|\mathrm{d}\xb \leq \left(\int_\Omega(c_0+c_1|\Eb|)^2\mathrm{d}\xb\right)^{1/2} \| \Eb-\Eb_I\|_{0,\Omega}= C_{Eb} \| \Eb-\Eb_I\|_{0,\Omega},   \int_\Omega(c_0+c_1|\Eb_h|)|\Eb-\Eb_I|\mathrm{d}\xb \leq \left(\int_\Omega(c_0+c_1|\Eb_h|)^2\mathrm{d}\xb\right)^{1/2} \| \Eb-\Eb_I\|_{0,\Omega}\le C_{Ehb} \| \Eb-\Eb_I\|_{0,\Omega}.  Therefore,  T_2&\leq (C_{Eb}+C_{Ehb})\|\Eb-\Eb_I\|_{0,\Omega}+(1+\varepsilon)m\|\Eb_I-\Eb_h\|_{0,\Omega}^2+(1+1/\varepsilon)m\|\Eb-\Eb_I\|_{0,\Omega}^2 \nonumber\\ &\quad{} +r_h(\Eb;\Eb_I-\Eb_h).  Combining (\ref{eqn2.10}), (\ref{eqn2.11}), (\ref{eqn2.20}), Lemma \ref{lemma:stability} and Lemma \ref{lemma2.6}, we obtain   &\epsilon_0\|  \Eb_I-\Eb_h\|_{0,\Omega}^2 + C_0\sum_{f\in\mathcal{F}_h}\| \alpha^{1/2}\llbracket\Eb_I-\Eb_h\rrbracket\|_{0,f}^2 + C_1 \sum_{K\in\mathcal{T}_h}\|\nabla\times (\Eb_I-\Eb_h)\|_{0,K}^2  \\ & \leq  (C_{Eb}+C_{Ehb})\|\Eb-\Eb_I\|_{0,\Omega}+(1+\varepsilon)m \|\Eb_I-\Eb_h\|_{0,\Omega}^2+(1+1/\varepsilon)m\|\Eb-\Eb_I\|_{0,\Omega}^2 \\ & \quad +\frac{\varepsilon}{4}\|\Eb_I-\Eb_h\|_h^2+\frac{C_b^2}{\varepsilon}\|\Eb_I-\Eb\|_h^2+C_R h^{\min\{s,l+1\}}|\Eb_I-\Eb_h|_h\|\nabla\times \Eb\|_{s,\Omega}.   Using the modified Cauchy-Schwarz inequality \eqref{mCS}, we have, for any $\varepsilon>0$,  	C_R h^{\min\{s,l+1\}}|\Eb_I-\Eb_h|_h \|\nabla\times\Eb\|_{s,\Omega} \leq \frac{\varepsilon}{4}\|\Eb_I-\Eb_h\|_h^2+\frac{C_R^2 h^{2\min\{s,l+1\}}}{\varepsilon}\|\nabla\times\Eb\|_{s,\Omega}^2.  Since $m<\epsilon_0$, we can choose a sufficiently small $\varepsilon>0$ such that $\epsilon_0 - m - (m+1/4)\varepsilon>0$ and $\min\{C_0, C_1\} > \varepsilon/4$. Applying the error bounds \eqref{energy norm estimate} and \eqref{eqn:lemma4-3}, we derive from \eqref{eqn:error bound} that \[ \|\Eb_I-\Eb_h\|_h\leq C\,h^{(\min\{s,l\}+1)/2}.   \] Finally, we use the triangle inequality $\|\Eb-\Eb_h\|_h\le\|\Eb-\Eb_I\|_h +\|\Eb_I-\Eb_h\|_h$ to conclude the error bound \eqref{error_bd}.",2502.01148
proposition,"[{\cite[Proposition~2.5]{han2020minimization}}]  Let $V$ be a real Hilbert space, and let $g\colon V \to \mathbb{R}$ be a locally Lipschitz continuous  and strongly convex functional on $V$ with a constant $\alpha>0$. Then there exist two constants  $\overline{c}_0$ and $\overline{c}_1$ such that   g(v) \;\ge\; \alpha\,\|v\|_{V}^2 \;+\; \overline{c}_0 \;+\; \overline{c}_1\,\|v\|_{V} \quad \forall\,v\in V.  Consequently, $g(\cdot)$ is coercive on $V$.",2502.01148
proposition,"Under the assumptions \eqref{eqn1.other}, $m<\epsilon_0$ and $\eta > \max\{1,\mu_1^2\}\,\tilde{C}^2/(2\,\mu_0^2)$, the minimization problem \eqref{minimization problem} has a unique solution $\Eb_h \in \Vb_h$",2502.01148
lemma,"[{\cite[Theorem~3.4]{fan2003generalized}}]  Let $V$ be a real Banach space, and let $g\colon V \to \mathbb{R}$ be locally Lipschitz continuous. Then $g$ is strongly convex on $V$ with a constant $\alpha>0$ if and only if $\partial g$  is strongly monotone on $V$ with a constant $2\alpha$, i.e., \[ \langle \xi - \eta,\, u - v\rangle \;\ge\; 2\,\alpha \,\|u - v\|_{V}^2  \quad \forall\,u,v\in V,\;\xi\in \partial g(u),\;\eta\in \partial g(v). \]",2502.01148
lemma,"[Boundedness] There is a constant $C_b>0$ such that  \tilde{a}_h(\Eb,\vb)\leq C_b\|\Eb\|_h \|\vb\|_h\quad \forall\,\Eb,\vb\in\Vb(h).",2502.01148
lemma,"[Stability] Assume $\eta > \max\{1,\mu_1^2\}\,\tilde{C}^2/(2\,\mu_0^2)$.  There is a constant $C_s>0$ such that  \tilde{a}_h(\Eb,\Eb)\geq C_s \|\Eb\|_h^2, \quad \forall \Eb\in\Vb(h).",2502.01148
lemma,"Assume \eqref{eqn1.other}, $m<\epsilon_0$ and $\eta > \max\{1,\mu_1^2\}\,\tilde{C}^2/(2\,\mu_0^2)$. If $\Eb_h\in \Vb_h$ is a solution of the problem \eqref{eqn1.18}, then $\|\Eb_h\|_h$ is uniformly bounded with respect to the mesh size $h$.",2502.01148
lemma,"Assume \eqref{eqn1.other}, $m<\epsilon_0$ and $\eta > \max\{1,\mu_1^2\}\,\tilde{C}^2/(2\,\mu_0^2)$. Then the functional $\mathcal{E}(\cdot)$ is locally Lipschitz continuous, strongly convex and coercive on $\Vb_h$.",2502.01148
lemma,"Assume $\{\mathcal{T}_h\}$ is a shape-regular family of tetrahedral or hexahedral mesh partitions of the domain $\overline{\Omega}$, and assume $\Eb \in \Hb_0(\curlb; \Omega) \cap \Hb^s(\Omega)$ with $ \nabla\times \Eb \in \Hb^s(\Omega)$, where $s > 1/2$. Then the following error estimates hold:  \|\Eb - \Pib_N \Eb\|_{\curlb,\Omega} & \leq C_N h^{\min\{s, l\}} (\|\Eb\|_{s, \Omega} + \|\nabla\times \Eb\|_{s, \Omega}),  \\ \|\Eb - \Pib_N \Eb\|_{h} & \leq C_N h^{\min\{s, l\}} (\|\Eb\|_{s, \Omega} + \|\nabla\times \Eb\|_{s, \Omega}),   where $C_N > 0$ is a constant depending on the mesh regularity and the polynomial degree $l$ but independent of $h$, and for \eqref{energy norm estimate}, $C_N$ also depends on the upper and lower bounds of the coefficients $\mu$ and $\epsilon$.   Moreover, if $\Eb \in \Hb_0(\curlb; \Omega) \cap \Hb^{s+1}(\Omega)$ for some number $s > 0$, then   \|\Eb - \Pib_N \Eb\|_{0, \Omega} \leq C_N h^{\min\{s, l\}+1} \|\Eb\|_{s+1, \Omega}.",2502.01148
lemma,"Assume $\nabla\times \Eb \in \Hb^s(\Omega)$, $s > 1/2$.  Then,  \[ |r_h(\Eb;\vb)|\leq C_R h^{\min\{s,l+1\}}|\vb|_h\|\nabla\times\Eb\|_{s,\Omega}\quad\forall\,\vb \in \Vb(h),\] where the constant $C_R$ is independent of the mesh size but is dependent on $\eta$, the upper and lower bounds of the coefficient $\mu$, the mesh regularity, and the polynomial order $l$.",2502.01148
theorem,"[Previous bound from \cite{gonon2023approximation}] 		For any architecture \( (L,\mathbf{N}) \), and any \( r \geq 1 \), denoting  \( N := \max_{l=0,\ldots,L} N_l \), for any $\theta,\theta' \in \Theta_{L,\mathbf{N}}(r) $, we have : 		 			 			\sup_{x \in \Omega}\| R_{\theta}(x) - R_{\theta'}(x) \|_{\infty} \leq (D+1) N L^2 r^{L-1} \| \theta - \theta' \|_\infty.",2502.01156
theorem,"[General approximation bound] For any architecture \((L,\mathbf{N})\),  define the parameters \(\theta = (\tilde{W}_1, \ldots, \tilde{W}_L)\) and \(\theta' = (\tilde{W}'_1, \ldots, \tilde{W}'_L)\), where $\tilde{W}_\ell$ and $\tilde{W}'_\ell$ are weight matrices with included bias. Assume that the two networks have same biases. Assume besides that $ \forall \ell = 1, \ldots, L$:  \quad \| \tilde{W}_\ell \|_{\mathrm{op}, \infty} \leq r_\ell \quad \text{and} \quad \| \tilde{W}'_\ell \|_{\mathrm{op}, \infty} \leq r_\ell.  		Then:  &\sup_{x \in \Omega}\| R_{\theta}(\tilde{x}) - R_{\theta'}(\tilde{x}) \|_{\infty}  \\ &\leq \max(D,1) \sum_{\ell=1}^{L} N_{\ell-1} \times r_{mean}^{L-1} \|\theta - \theta'\|_\infty,\\  where  we define the mean norm parameter  r_{mean} := \sqrt[L-1]{\max_{l=1, \dots, L} \max_{i=1, \dots, l-1} \prod_{\substack{j=i \\ j \neq l}}^{L} r_j}.",2502.01156
theorem,"[Approximation bound for  CNN] 		With the same settings as in Theorem \ref{Th:my_bound_extend_new} 		and for a purely convolutional network without biases, where each layer applies \( c_l \) filters of size \( p_l \times p_l \), we have: 		 		  			 				&\sup_{x \in \Omega}\| R_{\theta}(x) - R_{\theta'}(x) \|_{\infty} \\ 				&\leq D \times \sum_{l=1}^{L} p_{l}^2 c_{l-1} \times r_{conv}^{L-1} \|\theta - \theta'\|_\infty 			 		 		where we define 		 			r_{conv} := \sqrt[L-1]{\max_{l=1, \dots, L}\prod\limits_{\substack{k=1 \\ k \neq l}}^{L} r^{\text{conv}}_k} 		 		 		with $r^{conv}_k$  a bound on the norm of the convolutional matrix of layer $k$ without bias (i.e. $r^{conv}_k \geq  \|\mathcal{H}_k\|_{op,\infty}$).",2502.01156
theorem,"[Bound for neural networks without bias] 			With the same settings as in Theorem \ref{Th:my_bound_extend_new}, with $(b_1, \dots, b_L) = (b'_1, \dots, b'_L) = (0, \dots, 0)$ 			(i.e $\forall l, \text{ we can take}\; \tilde{W}_l = W_l$ and $\tilde{W}'_l = W'_l$, the standard weight matrices without included bias). For all $x \in \Omega$ the following bound holds. 			 			 				\sup_{x \in \Omega} \left\| R_{\theta} (x) - R_{\theta'} (x) \right\|_{\infty} \leq D \left(\sqrt[L-1]{\max_{l=1, \dots, L}\prod\limits_{\substack{k=1 \\ k \neq l}}^{L} r_k}\right)^{L-1} \sum_{\ell=1}^{L} N_{l-1} \|\theta-\theta'\|_\infty.",2502.01156
definition,"\textbf{Neural network architecture.}  The architecture of a neural network is defined by the tuple \((L,  \mathbf{N})\), where \( L \in \mathbb{N} \) represents the depth of the network, and \( \mathbf{N} = (N_0, \ldots, N_L) \in \mathbb{N}^{L+1} \) is a sequence specifying the number of neurons in each layer (the width of each). We call $N_\ell$ the width of the \(\ell\)-th layer. The width of the network is defined as \( N := \max_{\ell=0,\ldots,L} N_\ell \).",2502.01156
definition,"\textbf{Parameters associated with an architecture.} Given an architecture \((L, \mathbf{N})\),  parameters associated with this architecture are  \(\theta = (\tilde{W}_1, \ldots, \tilde{W}_L)\), where \( \tilde{W}_\ell \in \mathbb{R}^{N_\ell \times ( N_{\ell-1}+1)} \) is the weight matrix for layer \(\ell=1, \dots,L\) with included bias, i.e.  the concatenation of a base weight matrix $W_\ell\in \mathbb{R}^{N_\ell \times N_{\ell-1}}$ with  associated bias \( b_\ell \in \mathbb{R}^{N_\ell} \), for layer \(\ell\). We have that $ \theta \in 	\Theta_{L,\mathbf{N}} := \mathbb{R}^{d(L,\mathbf{N})}$, 	where the dimension $d(L,\mathbf{N})$ is  defined by $d(L,\mathbf{N}) := \sum_{\ell=1}^L N_\ell(N_{\ell-1} + 1)$.",2502.01156
definition,"\textbf{ReLU Network.} For any vector $x$, we write $\tilde{x}= x \\ 1  $. Given an architecture \((L, \mathbf{N})\) and parameter vector \(\theta = (\tilde{W}_1, \ldots, \tilde{W}_L)\), we associate the function \( R_\theta : \mathbb{R}^{N_0 + 1} \rightarrow \mathbb{R}^{N_L} \), which is recursively defined for $\ell = 0,\ldots,L$ as follows: 	 	 		y_0 = x, \; y_\ell =  \sigma \left(\tilde{W}_\ell  \tilde{y}_{l-1}\right) \; \text{and} \; R_\theta(\tilde{x}) = y_L  	 	 	where \(\sigma(x) = \mathrm{max}(0, x)\) is the ReLU activation function.",2502.01156
definition,"\textbf{Domains for parameters and input vectors.} Given an architecture \((L, \mathbf{N})\) and a parameter space \(\Theta_{L,\mathbf{N}}\), for any \(r \geq 0\), we define the set of admissible parameters: 	\[ 	\Theta_{L,\mathbf{N}}(r) := \left\{(\tilde{W}_1, \ldots, \tilde{W}_L) \in \Theta_{L,\mathbf{N}} :  \right. 	\] 	\[ 	\left.  \| \tilde{W}_\ell \|_{\mathrm{op},\infty} \leq r, \; \ell = 1,\ldots,L\right\}. 	\] 	where \(\|\cdot\|_{\mathrm{op},\infty}\) denotes the infinity operator norm, defined as follows, for every matrix $W$ in $\mathbb{R}^{m\times n}$: 	 		\| W \|_{\mathrm{op},\infty} := \sup_{x \in \mathbb{R}^{n}, \; \|x\|_\infty = 1} \| Wx \|_\infty.",2502.01156
proof,"Let $A \in \mathbb R^{m\times n}$ and $x \in \mathbb R^{n}$ with $\|x\|_\infty = 1$, then 			 			 				\|Ax\|_\infty &= \max_{1 \leq i \leq m} \left| (Ax)_i \right| = \max_{1 \leq i \leq m} \left| \sum_{j=1}^n a_{i,j} x_j \right|\leq \max_{1 \leq i \leq m}  \sum_{j=1}^n \left| a_{i,j} \right| \|x\|_\infty = \max_{1 \leq i \leq m}  \sum_{j=1}^n \left|a_{i,j} \right| 			 			 			 			To show that equality holds, let \( x \) such that \( x_j = \mathrm{sign}(a_{i^\star,j})\) where $i^\star \in  \arg \max_i \sum_{j=1}^n \left|a_{i,j} \right|$.  Then \( \|x\|_\infty = 1 \) and: 			 				\|Ax\|_\infty =  \sum_{j=1}^n a_{i^\star j}\cdot \mathrm{sign}(a_{i^\star j}) =  \sum_{j=1}^n |a_{i^\star j} | =  \max_i \sum_{j=1}^n \left|a_{i,j} \right|. 			 			 			This shows that: 			 				\|A\|_{\mathrm{op},\infty}= \max_{1 \leq i \leq m} \sum_{j=1}^n |a_{ij}|.",2502.01156
proof,"The proof of Inequality \eqref{inequality_lemmeC} follows by induction on $L \in \mathbb{N}$. For \( L = 1 \), with the Lipschitz condition and the definition of $\|\cdot\|_{\mathrm{op},\infty}$, using the fact that the last columns of $\tilde{W}_1$ and $\tilde{W}_1'$ are equal, we have $ \| \tilde{W}_1 \tilde{x} - \tilde{W}'_1 \tilde{x} \|_{\infty} = \| W_1 x - W'_1x \|_{\infty}$ and: 			 			 				\left\|R_{\theta_L} (\tilde{x})  -  R_{\theta_L'} (\tilde{x}) \right\|_{ \infty} = \left\| \sigma(\tilde{W}_1 \tilde{x}) - \sigma(\tilde{W}'_1 \tilde{x}) \right\|_{\infty} \leq \left\| \tilde{W}_1 \tilde{x} - \tilde{W}'_1 \tilde{x} \right\|_{\infty} = \left\| W_1 \tilde{x} - W'_1 x \right\|_{\infty} 				\leq \|W_1 - W'_1\|_{\mathrm{op}, \infty} \left\| x\right\|_\infty. 			 			 			Now assume that  property \eqref{inequality_lemmeC} holds for \( L \geq 1 \). At rank \( L+1 \), using the fact that the activation function \( \sigma \) is 1-Lipschitz and satisfies \( \sigma(0) = 0 \), we have : 			 				&\left\| R_{\theta_{L+1}} (\tilde{x}) - R_{\theta_{L+1}'} (\tilde{x}) \right\|_{\infty}\\ 				&= \left\| \sigma\left( \tilde{W}_{L+1}  R_{\theta_L} (\tilde{x})  \\ 1 \right) 				-  \sigma\left( \tilde{W}'_{L+1}  R_{\theta'_L} (\tilde{x})  \\ 1 \right) \right\|_{ \infty}\Arrow{$\sigma$ is 1-Lipschitz} \\ 				&\leq \left\| \tilde{W}_{L+1}  R_{\theta_L} (\tilde{x}) \\ 1  				-  \tilde{W}'_{L+1}   R_{\theta'_L} (\tilde{x})  \\ 1  \right\|_{ \infty}\\ 				&= \left\| \tilde{W}_{L+1} \left(  R_{\theta_L} (\tilde{x})\\ 1  				-   R_{\theta'_L} (\tilde{x})  \\ 1    \right)+  \left(\tilde{W}_{L+1} - \tilde{W}'_{L+1} \right)  R_{\theta'_L} (\tilde{x})  \\ 1  \right\|_{ \infty} \Arrow{triangle inequality} \\ 				&\leq \left\| \tilde{W}_{L+1}    R_{\theta_L} (\tilde{x}) 					-  R_{\theta'_L} (\tilde{x})  \\ 0   \right\|_{ \infty} + \left\| \left(\tilde{W}_{L+1} - \tilde{W}'_{L+1}\right)   R_{\theta'_L} (\tilde{x})  \\ 1  \right\|_{ \infty} \Arrow{ same last column \\ for $\tilde{W}_{L+1}$ and $\tilde{W}'_{L+1}$} \\ 				&= \left\| W_{L+1} \left( R_{\theta_L} (\tilde{x}) 				-  R_{\theta'_L} (\tilde{x}) \right)  \right\|_{ \infty} + \left\| \left(W_{L+1} - W'_{L+1}\right) R_{\theta'_L} (\tilde{x})\right\|_{ \infty} 				\Arrow{Sub-multiplicativity} \\ 				&\leq \|W_{L+1}\|_{\mathrm{op}, \infty} \left\|  R_{\theta_L} (\tilde{x}) 				-  R_{\theta'_L} (\tilde{x}) \right\|_\infty + \|W_{L+1} - W'_{L+1}\|_{\mathrm{op}, \infty} \left\| R_{\theta'_L} (\tilde{x}) \right\|_ \infty . 			 			 			Applying the induction hypothesis (Inequality~\eqref{inequality_lemmeC}) to the term \( \left\| R_{\theta_L} (\tilde{x}) - R_{\theta'_L} (\tilde{x}) \right\|_\infty \), we have: 			 			 				\left\| R_{\theta_L} (\tilde{x}) - R_{\theta'_L} (\tilde{x})  \right\|_\infty 				\leq \sum_{\ell=1}^{L} \left( \prod_{k=\ell+1}^{L} \|W_k\|_{\mathrm{op}, \infty} \right) 				\|W_\ell - W'_\ell\|_{\mathrm{op}, \infty} 				\left\|  R_{\theta'_{\ell-1}} (\tilde{x}) \right\|_\infty. 			 			 			 			 			Substituting this bound back into the previous inequality and using that we  have \( \prod_{k=L+2}^{L=1} \|W_k\|_{\mathrm{op}, \infty} = 1 \) by convention, we get: 			 				 					\left\| R_{\theta_{L+1}} (\tilde{x}) - R_{\theta_{L+1}'} (\tilde{x}) \right\|_{ \infty} 					&\leq \|W_{L+1}\|_{\mathrm{op}, \infty} \sum_{\ell=1}^{L} 					\left( \prod_{k=\ell+1}^{L} \|W_k\|_{\mathrm{op}, \infty} \right) 					\|W_\ell - W'_\ell\|_{\mathrm{op}, \infty} 					\left\|  R_{\theta'_{\ell-1}} (\tilde{x}) \right\|_\infty \\ 					&\quad + \|W_{L+1} - W'_{L+1}\|_{\mathrm{op}, \infty} 					\left\| R_{\theta'_L} (\tilde{x}) \right\|_\infty \\ 					&= \sum_{\ell=1}^{L} 					\left( \prod_{k=\ell+1}^{L+1} \|W_k\|_{\mathrm{op}, \infty} \right) 					\|W_\ell - W'_\ell\|_{\mathrm{op}, \infty} 					\left\| R_{\theta'_{\ell-1}} (\tilde{x}) \right\|_\infty \\ 					&\quad + \left(\prod_{k=L+1+1}^{L+1} \|W_k\|_{\mathrm{op}, \infty}\right)\|W_{L+1} - W'_{L+1}\|_{\mathrm{op}, \infty} 					\left\| R_{\theta'_L} (\tilde{x}) \right\|_\infty. 				 			 			 			We deduce 			 				 					\left\| R_{\theta_{L+1}} (\tilde{x}) - R_{\theta_{L+1}'} (\tilde{x}) \right\|_{\infty} 					&\leq \sum_{\ell=1}^{L+1} \left( \prod_{k=\ell+1}^{L+1} \|W_k\|_{\mathrm{op}, \infty} \right) 					\|W_\ell - W'_\ell\|_{\mathrm{op}, \infty} \left\| R_{\theta'_{\ell-1}} (\tilde{x}) \right\|_\infty. 				 			 			This concludes the induction and proves the lemma.",2502.01156
proof,"We prove~\eqref{inequality_lemmeMax}  by induction on $L \in \mathbb{N}$. For $L=1$, we have: 			 			 				\|R_{\theta_L} (\tilde{x})\|_{\infty} = \|\sigma(\tilde{W}_1\tilde{x})\|_{\infty} \leq \| \tilde{W}_1\tilde{x}\|_{\infty} \leq \| \tilde{W}_1\|_{\mathrm{op}, \infty} \| \tilde{x} \|_\infty 			 			 			Then by convention for $L=1$ (as in Lemma~\ref{Lemma_article}), 			 			 				\max_{l=2, \dots, L} \prod_{s=\ell}^{L} \|\tilde{W}_s\|_{\mathrm{op}, \infty} = 1 . 			 			 			We deduce: 			 				\|R_{\theta_L} (\tilde{x})\|_{\infty} \leq \| \tilde{W}_1\|_{\mathrm{op}, \infty} \| \tilde{x} \|_\infty \leq \max(1 ; \| \tilde{W}_1\|_{\mathrm{op}, \infty} \| \tilde{x} \|_\infty) . 			 			 			Now assume that the property holds for \( L \geq 1 \). At rank \( L+1 \), using  that operator norm is sub-multiplicative and the fact that $ \sigma$ is 1-Lipschitz, we have: 			 			 				\|R_{\theta_{L+1}} (\tilde{x})\|_{\infty} &= \left\| \sigma \left( \tilde{W}_{L+1}  R_{\theta_L} (\tilde{x}) \\ 1 \right) \right\|_\infty \nonumber \\ 				&\leq \| \tilde{W}_{L+1}\|_{\mathrm{op}, \infty} \left\|  R_{\theta_{L}} (\tilde{x})\\ 1  \right\|_\infty \nonumber \\ 				&=\left\|  \| \tilde{W}_{L+1}\|_{\mathrm{op}, \infty} \|R_{\theta_{L}} (\tilde{x})\|_{\infty} \\ \| \tilde{W}_{L+1}\|_{\mathrm{op}, \infty}   \right\|_\infty 			 			 			 			Then, applying the induction hypothesis to the term $\|R_{\theta_{L}} (\tilde{x})\|_{\infty}$, it comes: 			 			 				\left\|  \| \tilde{W}_{L+1}\|_{\mathrm{op}, \infty} \|R_{\theta_{L}} (\tilde{x})\|_{\infty} \\ \| \tilde{W}_{L+1}\|_{\mathrm{op}, \infty}   \right\|_\infty &= \max( \|\tilde{W}_{L+1}\|_{\mathrm{op}, \infty} \|R_{\theta_{L}} (\tilde{x})\|_{\infty} ; \| \tilde{W}_{L+1}\|_{\mathrm{op}, \infty}) \nonumber \\ 				&\leq \max\left(\| \tilde{W}_{L+1}\|_{\mathrm{op}, \infty} \max\left[\max_{l=2, \dots, L}\left(\prod_{s=l}^{L} \| \tilde{W}_s\|_{\mathrm{op}, \infty}\right) ; \prod_{s=1}^{L} \| \tilde{W}_s\|_{\mathrm{op}, \infty} \| \tilde{x} \|_\infty \right]; \| \tilde{W}_{L+1}\|_{\mathrm{op}, \infty}\right)  \nonumber \\ 				&= \max\left( \max\left[ \max_{l=2, \dots, L}\left(\prod_{s=l}^{L+1} \| \tilde{W}_s\|_{\mathrm{op}, \infty}\right) ; \prod_{s=1}^{L+1} \| \tilde{W}_s\|_{\mathrm{op}, \infty} \| \tilde{x} \|_\infty \right]; \| \tilde{W}_{L+1}\|_{\mathrm{op}, \infty} \right) \nonumber\\ 				&=  \max \left[ \max_{l=2, \dots, L}\left(\prod_{s=l}^{L+1} \| \tilde{W}_s\|_{\mathrm{op}, \infty}\right) ; \prod_{s=1}^{L+1} \| \tilde{W}_s\|_{\mathrm{op}, \infty} \| \tilde{x} \|_\infty ; \| \tilde{W}_{L+1}\|_{\mathrm{op}, \infty}\right] 			 			 			 			Then, noticing that the term $\| \tilde{W}_{L+1}\|_{\mathrm{op}, \infty}$ can be included in $\max_{l=2, \dots, L}\left(\prod_{s=l}^{L+1} \| \tilde{W}_s\|_{\mathrm{op}, \infty}\right)$ by adding index $\ell = L+1$, we have 			 				\|R_{\theta_{L+1}} (\tilde{x})\|_{\infty} \leq \max\left[ \max_{l=2, \dots, L+1}\left(\prod_{s=l}^{L+1} \| \tilde{W}_s\|_{\mathrm{op}, \infty}\right) ; \prod_{s=1}^{L+1} \| \tilde{W}_s\|_{\mathrm{op}, \infty} \| \tilde{x} \|_\infty \right]. 			 			 			This concludes the induction and proves the lemma.",2502.01156
proof,"[Proof of Theorem~\ref{Th:my_bound_extend_new}] 			 			We recall that $\theta'_\ell$ is defined as the parameter deduced from $\theta'$, associated with the architecture $(\ell, (N_0, \dots, N_\ell))$. 			 			With the convention that 			 			 				 					 						R_{\theta'_{l-1}}(\tilde{x}) = \tilde{x} 						& \text{if } l = 1, \\ 						\prod_{k=\ell+1}^{L} \|W_k\|_{\mathrm{op},q} = 1 						& \text{if} \; l = L, 					 				 			 			 			 			we have, with Lemma \ref{Lemma_article}: 			 			  				\|R_\theta (\tilde{x}) - R_{\theta'} (\tilde{x})\|_{\infty} \leq \sum_{\ell=1}^{L}  \left( \prod_{k=\ell+1}^{L} \|W_k\|_{\mathrm{op}, \infty} \right) \|W_\ell - W'_\ell\|_{\mathrm{op}, \infty} \| R_{\theta'_{\ell-1}} (\tilde{x}) \|_\infty. 			 			 			Thus, using Lemma \ref{Lemma_max} we can bound $\| R_{\theta'_{\ell-1}} (\tilde{x}) \|_\infty$, with the convention that an empty product is equal to 1, it follows:  			 			 				\| R_{\theta'_{\ell-1}} (\tilde{x}) \|_\infty \leq \max\left[ \max_{i=2, \dots, l-1}\left(\prod_{s=i}^{l-1} \| \tilde{W}'_s\|_{\mathrm{op}, \infty}\right) ; \prod_{s=1}^{l-1} \| \tilde{W}'_s\|_{\mathrm{op}, \infty} \| \tilde{x} \|_\infty \right] 			 			 			Then, noticing that $\|\tilde{x}\|_\infty \geq 1$, and re-indexing the second $\max$ to include $\prod_{s=1}^{l-1} \| \tilde{W}'_s\|_{\mathrm{op}, \infty}$, we have: 			 			 				\| R_{\theta'_{\ell-1}} (\tilde{x}) \|_\infty &\leq \max\left[\max_{i=2, \dots, l-1}\left(\prod_{s=i}^{l-1} \| \tilde{W}'_s\|_{\mathrm{op}, \infty}\right) \| \tilde{x} \|_\infty ; \prod_{s=1}^{l-1} \| \tilde{W}'_s\|_{\mathrm{op}, \infty} \| \tilde{x} \|_\infty \right]\nonumber \\ 				&= \| \tilde{x} \|_\infty \max\left[ \max_{i=2, \dots, l-1}\left(\prod_{s=i}^{l-1} \| \tilde{W}'_s\|_{\mathrm{op}, \infty}\right) ; \prod_{s=1}^{l-1} \| \tilde{W}'_s\|_{\mathrm{op}, \infty} \right] \nonumber \\ 				& = \| \tilde{x} \|_\infty  \max_{i=1, \dots, l-1}\left(\prod_{s=i}^{l-1} \| \tilde{W}'_s\|_{\mathrm{op}, \infty}\right). 			 			 			Using this bound in Equation \eqref{eq:proof_main1}, we get: 			 			 				\|R_\theta (\tilde{x}) - R_{\theta'} (\tilde{x})\|_{\infty} \leq \| \tilde{x} \|_\infty \sum_{\ell=1}^{L}  \left( \prod_{k=\ell+1}^{L} \|W_k\|_{\mathrm{op}, \infty} \right) \|W_\ell - W'_\ell\|_{\mathrm{op}, \infty}  \max_{i=1, \dots, l-1}\left(\prod_{s=i}^{l-1} \| \tilde{W}'_s\|_ 				{\mathrm{op}, \infty}\right). 			 			 			Then, recalling that $\tilde{x} =  				x \\ 1 			$ with $x \in [-D,D]^d$, we have 			 				\| \tilde{x} \|_\infty \leq \max(D;1) 			 			 			 			Then, we know by Lemma \ref{lem:matrices} that for every matrix in $\mathbb{R}^{m\times n}$: 			 			 				\|W\|_{\mathrm{op},\infty} = \max_{1 \leq i \leq m} \sum_{j=1}^{n} |w_{ij}| 			 			 			Thus, recalling that $\theta = (\tilde{W}_1, \dots, \tilde{W}_L)$ and because for all $l$, $ dim(W_l) = N_l \times N_{l-1}$, we can write: 			 			 				 					\|W_l\|_{\mathrm{op}, \infty} \leq N_{l-1} \max_{i,j} |(W_l)_{ij}| 					& \leq N_{l-1} \|\theta\|_\infty 				 			 			 			 			Using the previous inequality on $\|W_l - W'_l\|_{\mathrm{op},\infty}$ and replacing it in Inequality \eqref{eq:proof_main2}, we deduce that: 			 			 				\|R_\theta (\tilde{x}) - R_{\theta'} (\tilde{x})\|_{\infty} &\leq \max(D;1) \sum_{\ell=1}^{L} N_{l-1} \left( \prod_{k=\ell+1}^{L} \|W_k\|_{\mathrm{op}, \infty} \right) \max_{i=1, \dots, l-1}\left(\prod_{s=i}^{l-1} \| \tilde{W}'_s\|_ 				{\mathrm{op}, \infty}\right)  \|\theta-\theta'\|_\infty 			 			 			Thus, recalling that for all $l$,  			 			 				\|\tilde{W}_l\|_{\mathrm{op}, \infty} \leq r_l \quad \text{and} \quad \|\tilde{W}'_l\|_{\mathrm{op}, \infty} \leq r_l 			 			 			Equation \eqref{eq:proof_main3} becomes:  			 			 				\|R_\theta (\tilde{x}) - R_{\theta'} (\tilde{x})\|_{\infty} &\leq \max(D;1) \sum_{\ell=1}^{L} N_{l-1} \left( \prod_{k=\ell+1}^{L} r_k \right) \max_{i=1, \dots, l-1}\left(\prod_{s=i}^{l-1} r_s\right)  \|\theta-\theta'\|_\infty \nonumber\\ 				& \leq \max(D;1) \sum_{\ell=1}^{L}\left( N_{l-1} \max_{i=1, \dots, l-1} \prod\limits_{\substack{j=i \\ j \neq l}}^{L} r_j\right) \|\theta-\theta'\|_\infty 			 			 			Then taking the maximum over all layers, we finally have:  			 			 				\|R_\theta (\tilde{x}) - R_{\theta'} (\tilde{x})\|_{\infty} \leq \max(D;1) \left(\max_{l=1, \dots, L} \max_{i=1, \dots, l-1}\prod\limits_{\substack{j=i \\ j \neq l}}^{L} r_j\right) \sum_{\ell=1}^{L} N_{l-1}  \|\theta-\theta'\|_\infty 			 			 			Then, we can rewrite this to show the geometric mean for partial products: 			 			 				\|R_\theta (\tilde{x}) - R_{\theta'} (\tilde{x})\|_{\infty} \leq \max(D;1) \left(\sqrt[L-1]{\max_{l=1, \dots, L}  					\left( \max_{i=1, \dots, l-1}  					\prod_{\substack{j=i \\ j \neq l}}^{L} r_j \right)}\right)^{L-1} \sum_{\ell=1}^{L} N_{\ell-1} \|\theta - \theta'\|_\infty 			 			 			 			 			 			 			 			 			 			Finally, taking the supremum  of both sides we obtain: 			 			 				\sup_{x \in \Omega} \|R_\theta (\tilde{x}) - R_{\theta'} (\tilde{x})\|_{\infty} \leq \max(D;1) \left(\sqrt[L-1]{\max_{l=1, \dots, L} \left( \max_{i=1, \dots, l-1}  					\prod_{\substack{j=i \\ j \neq l}}^{L} r_j \right)}\right)^{L-1} \sum_{\ell=1}^{L} N_{\ell-1} \|\theta - \theta'\|_\infty",2502.01156
proof,"By analogy of the previous proof, we use Equation \eqref{inequality_lemmeC_no_bias} (which corresponds to Lemma \ref{Lemma_article} but without bias), and it comes: 			 			 				\left\| R_{\theta} (x) - R_{\theta'} (x) \right\|_{\infty} \leq \sum_{\ell=1}^{L} \left( \prod_{k=\ell+1}^{L} \|W_k\|_{\mathrm{op}, \infty} \right)\|W_\ell - W'_\ell\|_{\mathrm{op}, \infty} \left\| R_{\theta'_{\ell-1}} (x) \right\|_\infty 			 			 			Now we want to bound the term $\left\| R_{\theta'_{\ell-1}} (x) \right\|_\infty$ by using \eqref{inequality_lemmeC_no_bias}. Thus, for any $\theta$ and with $\theta' = (0, \dots, 0)$, noticing that: 			 				 					&\forall l \geq  2, \; \|R_{\theta'_{\ell-1}} (x)\|_\infty = 0, \\ 					& \text{if} \; l =1  , \; \|R_{\theta'_{\ell-1}} (x)\|_\infty = \|x\|_\infty, \text{by convention} 				 			 			 			We have: 			 			 				\|R_{\theta_{l-1}} (x) \|_{\infty} \leq \prod_{k=2}^{l-1} \|W_k\|_{\mathrm{op}, \infty} \|W_1 - 0 \|_{\mathrm{op}, \infty} \|x \|_\infty = \prod_{k=1}^{l-1} \|W_k\|_{\mathrm{op}, \infty} \|x \|_\infty 			 			% 			%     We could use Lemma \ref{Lemma_max} as well, but we would get: 			%      				%         \|R_{\theta_{l-1}} (x) \|_{\infty} \leq \max[ \max_{j=2, \dots, l-1}(\prod_{s=j}^{l-1} \| W_s\|_{\mathrm{op}, \infty}) ; \prod_{s=1}^{l-1} \| W_s\|_{\mathrm{op}, \infty} \| \tilde{x} \|_\infty ] 				%      			% 			%     Wich is larger than simply $\prod_{k=1}^{l-1} \|W_k\|_{\mathrm{op}, \infty} \|x \|_\infty$. 			% 			% 			 			 			Now for any $\theta, \theta'$ without bias, we can bound $\left\| R_{\theta'_{\ell-1}} (x) \right\|_\infty$ in \eqref{inequality_lemmeC_no_bias} , and it comes: 			 			  				\left\| R_{\theta} (x) - R_{\theta'} (x) \right\|_{\infty} \leq \|x \|_\infty \sum_{\ell=1}^{L} \left( \prod_{k=\ell+1}^{L} \|W_k\|_{\mathrm{op}, \infty} \right) \prod_{k=1}^{l-1} \|W'_k\|_{\mathrm{op},\infty} \|W_\ell - W'_\ell\|_{\mathrm{op}, \infty} 			 			 			Then, we use Lemma \ref{lem:matrices} to get:  			 				 					\|W_l\|_{\mathrm{op}, \infty} \leq N_{l-1} \max_{i,j} |(W_l)_{ij}| 					& \leq N_{l-1} \|\theta\|_\infty 				 			 			 			Hence recalling that for all $k$ we have $\|W_k\|_{\mathrm{op}, \infty} \leq r_k \quad \text{and} \quad \|W'_k\|_{\mathrm{op}, \infty} \leq r_k$, it comes: 			 			 				\left\| R_{\theta} (x) - R_{\theta'} (x) \right\|_{\infty} &\leq \|x \|_\infty \sum_{\ell=1}^{L} N_{l-1} \left( \prod_{k=\ell+1}^{L} \|W_k\|_{\mathrm{op}, \infty} \right) \prod_{k=1}^{l-1} \|W'_k\|_{\mathrm{op},\infty} \|\theta - \theta'\|_{ \infty} \nonumber \\ 				&\leq D \sum_{\ell=1}^{L} N_{l-1} \prod\limits_{\substack{k=1 \\ k \neq l}}^{L} r_k \|\theta-\theta'\|_\infty  			 			 			Thus taking the maximum over all layers, we can rewrite the bound in terms of the geometric mean:  			 			 				\left\| R_{\theta} (x) - R_{\theta'} (x) \right\|_{\infty} \leq D \left(\sqrt[L-1]{\max_{l=1, \dots, L}\prod\limits_{\substack{k=1 \\ k \neq l}}^{L} r_k}\right)^{L-1} \sum_{\ell=1}^{L} N_{l-1} \|\theta-\theta'\|_\infty 			 			 			Finally, taking the supremum gives the desired result:  			 			 				\sup_{x \in \Omega} \left\| R_{\theta} (x) - R_{\theta'} (x) \right\|_{\infty} \leq D \left(\sqrt[L-1]{\max_{l=1, \dots, L}\prod\limits_{\substack{k=1 \\ k \neq l}}^{L} r_k}\right)^{L-1} \sum_{\ell=1}^{L} N_{l-1} \|\theta-\theta'\|_\infty.",2502.01156
proof,"[Proof of Theorem~\ref{Th:my_bound_extend_new_conv}] 			 			Let \( \theta = (\mathcal{H}_1, \dots, \mathcal{H}_L)\) the vector of parameters where each $\mathcal{H_\ell}$ represent the convolution matrix of layer $l$. 			 			With the convention that 			 			 				 					 						R_{\theta'_{l-1}}(x) = x 						& \text{if } l = 1, \\ 						\prod_{k=\ell+1}^{L} \|\mathcal{H}_k\|_{\mathrm{op},\infty} = 1 						& \text{if} \; l = L 					 				 			 			 			We can start the proof using the same line of reasoning. Thus we can use directly Equation \eqref{eq1_proof_no_bias} that becomes for the convolutional case:  			 			 				\|R_\theta(x) - R_{\theta'}(x)\|_\infty 				\leq \|x\|_\infty \sum_{l=1}^{L} \prod_{k=\ell+1}^{L} \|\mathcal{H}_k\|_{\mathrm{op}, \infty} \prod_{k=1}^{l-1} \|\mathcal{H}'_k\|_{\mathrm{op},\infty}   \times \|\mathcal{H}_l - \mathcal{H}'_l\|_{\mathrm{op},\infty} 			 			 			Then by analogy we can write: 			 			 				 					\|R_\theta(x) - R_{\theta'}(x)\|_\infty 					&\leq \|x\|_\infty \sum_{l=1}^{L} \prod_{k=\ell+1}^{L} \|\mathcal{H}_k\|_{\mathrm{op}, \infty} \prod_{k=1}^{l-1} \|\mathcal{H}'_k\|_{\mathrm{op},\infty}   \times \|\mathcal{H}_l - \mathcal{H}'_l\|_{\mathrm{op},\infty} \\ 					& \leq D \sum_{l=1}^{L} \prod_{k=\ell+1}^{L} r_k \prod_{k=1}^{l-1} r_k   \times \|\mathcal{H}_l - \mathcal{H}'_l\|_{\mathrm{op},\infty} \\ 					&= D \sum_{l=1}^{L} \prod\limits_{\substack{k=1 \\ k \neq l}}^{L} r_k   \times \|\mathcal{H}_l - \mathcal{H}'_l\|_{\mathrm{op},\infty} 				 			 			 			Then, we know by lemma \ref{lem:matrices} that for every matrix in $\mathbb{R}^{m\times n}$ it holds : 			 			 				\|W\|_{\mathrm{op},\infty} = \max_{1 \leq i \leq m} \sum_{j=1}^{n} |w_{ij}| 			 			 			 			Thanks to the convolutional structure, we improve the bound on $\|\mathcal{H}_l\|_{\mathrm{op},\infty}$ given by Lemma~\ref{lem:matrices}. 			Let us note the output of the previous layer as $y_{l-1}$. This output is a set of feature maps with dimensions $(n_{l-1} \times m_{l-1}) \times c_{l-1}$, where $c_{l-1}$ is the number of feature maps (i.e., the number of filters) in the previous layer. 			 			Next, recalling that,we want to express the convolution at layer $l$ as a matrix multiplication: $\mathcal{H}_l \text{vec}(y_{l-1})$. 			 			Then we write $\mathcal{H}_l$ as a block-Toeplitz matrix: 			 			 				\mathcal{H}_l = 				 H_{l,1}\\ \vdots \\ H_{l,c_{l}} 			 			 			 			where each block $H_{l,i}$ is a Toeplitz matrix of size $(n_l m_l) \times (n_{l-1} m_{l-1}c_{l-1})$. These matrices are highly sparse, with each row composed of coefficients of the filters arranged in a specific pattern, while the remaining entries are zeros. 			 			Thus, each block $H_{l,i}$ in $\mathcal{H}_l$ represents the convolution operation between the $i$-th filter and the feature maps of the previous layer. 			 			Hence, the overall dimensions of $\mathcal{H}_l$ are: 			 			 				\dim(\mathcal{H}_l) = (n_l m_l c_l) \times  (n_{l-1} m_{l-1} c_{l-1}). 			 			 			Then to bound the norm of $\mathcal{H}_l$, we consider only the non-zero coefficients in its rows, which are $p_l^2 \times c_{l-1}$, where $p_l^2$ denotes the size of the filters at layer $l$. 			 			Thus, recalling that $\theta = (\mathcal{H}_1, \dots, \mathcal{H}_L)$ we have: 			 			 				 					\|\mathcal{H}_l\|_{\mathrm{op}, \infty} \leq c_{l-1}\times p_l^2 \max_{i,j} |(\mathcal{H}_l)_{ij}| 					& \leq c_{l-1} \times p_l^2 \|\theta\|_\infty 				 			 			 			Using the previous inequality on $\|\mathcal{H}_l - \mathcal{H}'_l\|_{\mathrm{op},\infty}$ we can  bound the quantity $\|R_\theta(x) - R_{\theta'}(x)\|_\infty$, by: 			 			 			 				 					\|R_\theta(x) - R_{\theta'}(x)\|_\infty 					&\leq D \sum_{l=1}^{L} \prod\limits_{\substack{k=1 \\ k \neq l}}^{L} r_k   \times \|\mathcal{H}_l - \mathcal{H}'_l\|_{\mathrm{op},\infty} \\ 					& \leq D \sum_{l=1}^{L} c_{l-1}\times p_l^2\prod\limits_{\substack{k=1 \\ k \neq l}}^{L} r_k  \|\theta-\theta'\|_\infty 				 			 			 			Thus taking the maximum over all layers, we can rewrite the bound in terms of the geometric mean:  			 			 				\left\| R_{\theta} (x) - R_{\theta'} (x) \right\|_{\infty} \leq D \left(\sqrt[L-1]{\max_{l=1, \dots, L}\prod\limits_{\substack{k=1 \\ k \neq l}}^{L} r_k}\right)^{L-1} \sum_{\ell=1}^{L} c_{l-1} \times p_l^2 \|\theta-\theta'\|_\infty 			 			 			 			Hence, we can conclude that: 			 			 				 					&\sup_{x \in \Omega}\| R_{\theta}(x) - R_{\theta'}(x) \|_{\infty} \leq D \left(\sqrt[L-1]{\max_{l=1, \dots, L}\prod\limits_{\substack{k=1 \\ k \neq l}}^{L} r_k}\right)^{L-1} \sum_{\ell=1}^{L} c_{l-1} \times p_l^2 \|\theta-\theta'\|_\infty.",2502.01156
proof,"The residual block computes the output $ y$ as: 			 				y = \sigma\left(\text{BN}_2\left(\text{Conv}_2\left(\text{ReLU}\left(\text{BN}_1\left(\text{Conv}_1(f)\right)\right)\right)\right) + W_s f\right), 			 			where: $\text{Conv}_1$ and $\text{Conv}_2$ represent the convolutional layers with weight matrices $W_1$ and $W_2$, respectively, $\text{BN}_1$ and $\text{BN}_2$ are batch normalization layers (omitted in the matrix formulation because we removed them in our experiments). 			 			The first convolutional layer computes: 			 				x_1 = \text{Conv}_1(f) = W_1 \cdot f, 			 			where $W_1 \in \mathbb{R}^{d \times n}$. This result is passed through $\text{BN}_1$ and $\sigma$, yielding: 			 			 				\tilde{x}_1 = \sigma\left(\text{BN}_1(x_1)\right). 			 			In our matrix representation, we express this as: 			 				\tilde{x}_1 = \tilde{\sigma}_1\left(V_1 \cdot f\right), 			 			where \(V_1 =  W_1 \\ I  \in \mathbb{R}^{(d + n) \times n}\). The expanded computation is: 			 				V_1 \cdot f =  W_1 \cdot f \\ I \cdot f  =  W_1 \cdot f \\ f_1 \\ \vdots \\ f_n . 			 			Thus: 			 				\tilde{\sigma}_1\left(V_1 \cdot f\right) =  \sigma(W_1 \cdot f) \\ f_1 \\ \vdots \\ f_n . 			 			 			 			Then the second convolutional layer computes: 			 				x_2 = \text{Conv}_2\left(\sigma\left(\text{BN}_1(x_1)\right)\right) = W_2 \cdot \tilde{x}_1, 			 			where \(W_2 \in \mathbb{R}^{m \times d}\). Combining the result with the shortcut connection $W_sf$, we obtain: 			 				y = \sigma\left(x_2 + W_sf\right). 			 			 			Using our matrix representation for $V_2$, where $V_2 =  W_2 & W_s  \in \mathbb{R}^{m \times (d + n)}$, the computation expands as: 			 				V_2 \cdot  \sigma(W_1 \cdot f) \\ f_1 \\ \vdots \\ f_n  =  W_2 & W_s  \cdot  \sigma(W_1 \cdot f) \\ f_1 \\ \vdots \\ f_n  =  W_2 \cdot \sigma(W_1 \cdot f) + W_s \cdot f = x_2 + W_sf. 			 			 			So the final output of the block is: 			 				y = \sigma\left(V_2 \cdot \tilde{\sigma}_1\left(V_1 \cdot f\right)\right), 			 			 			Thus, the residual block's output is equivalent to our matrix representation.",2502.01156
proof,"The bottleneck block computes the output $ y $ as: 			 				y = \sigma\left(\text{BN}_3\left(\text{Conv}_3\left(\text{ReLU}\left(\text{BN}_2\left(\text{Conv}_2\left(\text{ReLU}\left(\text{BN}_1\left(\text{Conv}_1(f)\right)\right)\right)\right)\right)\right)\right) + W_sf\right), 			 			where $\text{Conv}_1$, $\text{Conv}_2$, and $\text{Conv}_3$ represent the three convolutional layers with weight matrices $W_1$, $W_2$, and $W_3$, respectively, $\text{BN}_1$, $\text{BN}_2$, and $\text{BN}_3$ are batch normalization layers (omitted in the matrix formulation because we removed them in our experiments). 			 			The first convolutional layer computes: 			 				x_1 = \text{Conv}_1(f) = W_1 \cdot f, 			 			where \(W_1 \in \mathbb{R}^{d_1 \times n}\). This result is passed through \(\text{BN}_1\) and \(\sigma\), yielding: 			 				\tilde{x}_1 = \sigma\left(\text{BN}_1(x_1)\right). 			 			In our matrix representation, we express this as: 			 				\tilde{x}_1 = \tilde{\sigma}_1\left(V_1 \cdot f\right), 			 			 			where $V_1 =  W_1 \\ I  \in \mathbb{R}^{(d_1 + n) \times n}$. The expanded computation is: 			 			 				V_1 \cdot f =  W_1 \cdot f \\ I \cdot f  =  W_1 \cdot f \\ f_1 \\ \vdots \\ f_n . 			 			Thus: 			 			 				\tilde{\sigma}_1\left(V_1 \cdot f\right) =  \sigma(W_1 \cdot f) \\ f_1 \\ \vdots \\ f_n . 			 			 			The second convolutional layer computes: 			 				\tilde{x}_2 = \sigma(\text{Conv}_2(\tilde{x}_1)) = \sigma(W_2 \cdot \tilde{x}_1), 			 			where $W_2 \in \mathbb{R}^{d_2 \times d_1}$. Using $V_2$, the expanded computation is: 			 			 				V_2 \cdot  \sigma(W_1 \cdot f) \\ f_1 \\ \vdots \\ f_n  =  					W_2 & 0 \\ 					0 & I 				  \cdot  \sigma(W_1 \cdot f) \\ f_1 \\ \vdots \\ f_n  = 				 					W_2 \cdot \sigma(W_1 \cdot f) \\ 					f_1 \\ 					\vdots \\ 					f_n 				. 			 			 			So the output of this layer with our matrix representation is: $ 				\sigma(W_2 \cdot \sigma(W_1 \cdot f)) \\ 				f_1 \\ 				\vdots \\ 				f_n 			.$  			 			The third convolutional layer combines the outputs of the second layer and the shortcut connection: 			 			 				x_3 = \text{Conv}_3(\tilde{x}_2) = W_3 \cdot \tilde{x}_2 + W_sf, 			 			 			and the final original output of the block is $y = \sigma(x_3)$ 			 			Using $V_3$, this becomes: 			 				V_3 \cdot  \sigma(W_2 \cdot \sigma(W_1 \cdot f)) \\ f_1 \\ \vdots \\ f_n  =  W_3 & W_s  \cdot  \sigma(W_2 \cdot \sigma(W_1 \cdot f)) \\ f_1 \\ \vdots \\ f_n  = W_3 \cdot \sigma( W_2 \cdot \sigma(W_1 \cdot f)) + W_sf. 			 			 			Then the final output is: 			 				y = \sigma\left(V_3 \cdot \tilde{\sigma}_2\left(V_2 \cdot \tilde{\sigma}_1\left(V_1 \cdot f\right)\right)\right), 			 			ending the proof of the matrix representation.",2502.01156
lemma,"For all matrices $A \in \mathbb R^{m\times n}$ and all $x \in \mathbb{R}^n$ we have: 			 				\| A \|_{\mathrm{op},\infty} := \sup_{x \in \mathbb{R}^{n}, \; \|x\|_\infty = 1} \| Wx \|_\infty = \max_{1 \leq i \leq m} \sum_{j=1}^n |a_{i,j}|",2502.01156
lemma,"Let $(L, \mathbf{N})$ be an architecture with  $L \geq 1$, denoting 			$\theta = (\tilde{W}_1, \dots, \tilde{W}_L)$, 			$\theta' = (\tilde{W}'_1, \dots, \tilde{W}'_L) \in \Theta_{L, \mathbf{N}}$ as two  sets of parameters associated with this architecture, with each last column of the matrices composed by biases of the corresponding layer. We assume that the two networks have same biases (i.e. we do not quantize the bias) For every $\ell = 1, \dots, L-1$, define $\theta'_\ell$ as the parameter deduced from $\theta'$, associated with the architecture $(\ell, (N_0, \dots, N_\ell))$: 			\[ 			\theta'_\ell = (\tilde{W}'_1, \dots, \tilde{W}'_\ell). 			\] 			Then for every $\tilde{x} =  				x \\ 1  \; \text{with} \; x \in \mathbb{R}^{N_0}$, denoting by $W_k$ and $W'_k$ the  weight matrices without biases (i.e. $\tilde{W}_k$ and $\tilde{W}'_k$ with last column removed), then, for any $1$-Lipschitz activation function $\sigma$ such that $\sigma(0) = 0$, we have: 			 			  				\|R_\theta (\tilde{x}) - R_{\theta'} (\tilde{x})\|_{\infty} \leq 				\sum_{\ell=1}^{L} 				\left( \prod_{k=\ell+1}^{L} \|W_k\|_{\mathrm{op}, \infty} \right) 				\|W_\ell - W'_\ell\|_{\mathrm{op}, \infty} \| R_{\theta'_{\ell-1}} (\tilde{x}) \|_\infty, 			 			 			where we set by convention $R_{\theta'_{\ell-1}} (\tilde{x}) = x $ for $\ell = 1$, and $\prod_{k=\ell+1}^{L} \|W_k\|_{\mathrm{op}, \infty} = 1$ for $\ell = L$.",2502.01156
lemma,"Let $(L, \mathbf{N})$ be an architecture with  $L \geq 1$, denoting 			$\theta = (\tilde{W}_1, \dots, \tilde{W}_L) \in \Theta_{L, \mathbf{N}}$ a  set of parameters associated with this architecture. 			Then for every $\tilde{x} =  				x \\ 1 			$ where $x \in \mathbb{R}^{N_0}$, we have: 			 			  				\|R_{\theta_L} (\tilde{x})\|_{\infty} \leq \max \left( \max_{l=2, \dots, L} \prod_{s=\ell}^{L} \|\tilde{W}_s\|_{\mathrm{op}, \infty} ; \prod_{s=1}^{L} \| \tilde{W}_s\|_{\mathrm{op}, \infty} \| \tilde{x} \|_\infty \right).",2502.01156
lemma,"[Matrix Representation of a Residual Block in ResNet-18] 			The output $ y \in \mathbb{R}^n $ of a residual block in ResNet-18, as illustrated in Figure~\ref{fig:Residual_Block_of_ResNet18}, can be expressed as: 			 				y = \sigma \left( V_2 \cdot \tilde{\sigma}_1 \left( V_1 \cdot f \right) \right), 			 			 			where $f \in \mathbb{R}^n$ is the input, and $V_1$ and $V_2$ are defined as: 			 			 				V_1 =  W_1 \\ I  \in \mathbb{R}^{(d + n) \times n}, \quad  				V_2 =  W_2 & W_s  \in \mathbb{R}^{m \times (d + n)}, 			 			 			with $W_1 \in \mathbb{R}^{d \times n}$ and $W_2 \in \mathbb{R}^{m \times d}$ as the convolutional weight matrices, $I \in \mathbb{R}^{n \times n}$ as the identity matrix and $W_s \in \mathbb{R}^{m \times n}$ represents the shortcut weight matrix. Note that, if the input and output of the block have the same dimension $W_s = I$. The function $\tilde{\sigma}_1$ applies the non-linearity $\sigma$ only to the term $W_1 \cdot f$, leaving the shortcut component $I \cdot f$ unchanged.",2502.01156
lemma,"[Matrix Representation of a Bottleneck Block in ResNet-50] 			The output $ y \in \mathbb{R}^n $ of a bottleneck block in ResNet-50, as illustrated in Figure~\ref{fig:Residual_Block_of_ResNet50}, can be expressed as: 			 			 				y = \sigma \left( V_3 \cdot \tilde{\sigma}_2 \left( V_2 \cdot \tilde{\sigma}_1 \left( V_1 \cdot f \right) \right) \right), 			 			 			where $f \in \mathbb{R}^n$ is the input, and the matrices $V_1$, $V_2$, and $V_3$ are defined as follows: 			 				V_1 =  W_1 \\ I  \in \mathbb{R}^{(d_1 + n) \times n}, \quad 				V_2 =  				 					W_2 & 0 \\ 					0 & I 				 \in \mathbb{R}^{(d_2 + n) \times (d_1 + n)}, \quad 				V_3 =  W_3 & W_s  \in \mathbb{R}^{m \times (d_2 + n)}. 			 			 			Here: $W_1 \in \mathbb{R}^{d_1 \times n}$, $W_2 \in \mathbb{R}^{d_2 \times d_1}$, and $W_3 \in \mathbb{R}^{m \times d_2}$ are the weight matrices of the three convolutional layers in the bottleneck block, $W_s$ is the weight matrix associated with the shortcut, $I \in \mathbb{R}^{n \times n}$ is the identity, and $0$ denotes zero matrices of appropriate dimensions. 			 			The functions $\tilde{\sigma}_1$ and $\tilde{\sigma}_2$ apply the non-linearity $\sigma$ only to specific components, leaving the shortcut components unchanged.",2502.01156
theorem,"[{Th. 2 of \cite{hutter2021minimax}}]     For any $\alpha>1$, the minimax rate of smooth optimal transport map estimation is               \inf_{\hat{T}} \sup_{P\in\mathcal{M},T_0\in\mathcal{T}_\alpha} \E_{X_{1:n}, Y_{1:n}} &\p{d(\hat{T, T_0)^2}} \gtrsim \frac{1}{n} \vee n^{- \frac{2 \alpha}{2 \alpha - 2 + d}} \, .            Moreover, if $P\in\mathcal{M}$ and $T_0\in\mathcal{T}_{\alpha}$, the estimator $\hat{T}_J \eqdef \nabla \hat{f}_J$ defined above achieves this rate up to polylogarithmic factors. Here, the constants also hide a dependence on $R$.",2502.01168
theorem,"[Privacy of the noisy semi-dual estimator]     The mechanism returning the pair           (\hat{f}_{\text{\normalshape priv}} \eqdef f_{\hat{i}_{\text{\normalshape priv}}}, \hat{T}_{\text{\normalshape priv}} \eqdef \nabla \hat{f}_{\text{\normalshape priv}})  is $\epsilon$-DP.",2502.01168
theorem,"Let $P\in\mathcal{M},T_0\in\mathcal{T}_\alpha$.      By choosing $\delta$ appropriately, the estimator $\hat{T}_{\text{\normalshape priv}}$ has a utility satisfying                   \E &\p{\int \| T_0 - \hat{T}_{\text{\normalshape priv}}  \|^2 dP} \\         &\lesssim R^2 2^{-2 J \alpha} + \frac{J 2^{J (d-2)}\ln(n)}{n}+ \frac{1}{n} +  \frac{2^{Jd} \ln (n \epsilon) }{n \epsilon}             for $J$ larger than a sufficiently large constant that also depend on $R$.",2502.01168
theorem,"[Lower Bound]  Asymptotically,       \inf_{\hat{T}_{\text{\normalshape priv}}} \sup_{P \in \mathcal{M}, T_0 \in \mathcal{T}_{\alpha}}    &\E\p{\int \| T_0 - \hat{T}_{\text{\normalshape priv}}  \|^2 dP} \\    &\gtrsim  \frac{1}{n} \vee n^{- \frac{2 \alpha}{2 \alpha - 2 + d}} \vee (n\epsilon)^{- \frac{2 \alpha}{\alpha - 1 + d}}       where the infimum is taken over all estimators $\hat{T}_{\text{\normalshape priv}}$'s that are $\epsilon$-DP.",2502.01168
definition,"[Admissible source distributions]     We denote by $\mathcal{M}$ the set of probability measures $P$ on $\R^d$ that are supported on $\Omega$, that are absolutely continuous w.r.t. Lebesgue's measure and whose density $\rho_P$ verifies $\frac{1}{M} \leq \rho_P(x) \leq M$ for almost all $x$ in $\Omega$.",2502.01168
definition,"[Admissible smooth transport maps]     We denote by $\mathcal{T}$ the set of differentiable mappings $T: \tilde{\Omega} \rightarrow \R^d$ such that $T = \nabla f$ for some differentiable convex function $f: \tilde{\Omega} \rightarrow \R^d$ and               \item % (Bounded transport map)          $\forall x \in \tilde{\Omega}, \quad \|T(x)\| \leq M$,         \item  $\forall x \in \tilde{\Omega}, \frac{1}{M} \preceq \nabla^2 f (x) \preceq M$,         \item ${P_{\# T}}(\Omega) = 1$.          Furthermore, for $\alpha > 1$ and $R > 1$,  we define %the class of admissible transport maps as              \set{T}_{\alpha}(R) = \left\{ T \in \set{T}:                    T \text{ is } \floor{\alpha}  \text{ times differentiable,}\\         \text{and } \| T \|_{C^{\alpha}(\tilde{\Omega})} \leq R             \right\} \;.",2502.01168
definition,"[Admissible potentials]     We denote by $\mathcal{X}(M)$ the set of twice continuously differentiable functions $f: \tilde{\Omega} \rightarrow \R$ such that $\forall x \in \tilde{\Omega} $              \item $\quad |f(x)| \leq 2M^2$,         \item $ \quad \| \nabla f(x) \| \leq M$,         \item $\frac{1}{M} \preceq \nabla^2 f (x) \preceq M$.",2502.01168
definition,"[Differential Privacy \cite{dwork2006calibrating}]      Given $\epsilon \geq 0$, a randomized mechanism $\mech{M}: \dom{\mech{M}} \rightarrow \codom{\mech{M}}$ is $\epsilon$-differentially private (or $\epsilon$-DP) if for all $D \sim D' \in \dom{M}$ and all measurable $S \subset \codom{\mech{M}}$ we have       \Prob_{\mech{M}}\p{\mech{M}(D) \in S} \leq e^\epsilon \Prob_{\mech{M}}\p{\mech{M}(D') \in S} \;.",2502.01168
proof,See \Cref{proof_of_risk_decomposition}.,2502.01168
proof,See \Cref{sec:proof_of_sensitivitysemidual}.,2502.01168
proof,"It follows as a direct consequence of \Cref{lemma:report_noisy_max} and of \Cref{lemma:sensitivitysemidual} that $\hat{i}_{\text{\normalshape priv}}$ is $\epsilon$-DP.      Hence, $(\hat{f}_{\text{\normalshape priv}}, \hat{T}_{\text{\normalshape priv}})$ is $\epsilon$-DP by the post-processing property of differential privacy \cite{dwork2014algorithmic}.",2502.01168
proof,See \Cref{proof_of_from_semidual_to_infty},2502.01168
proof,See \Cref{proof_of_covering_cardinality},2502.01168
proof,See \Cref{proof_of_bias_variance_tradeoff},2502.01168
proof,See \Cref{sec:proof_of_lowerbound},2502.01168
proof,"By computing the partial derivatives of $M \mapsto \det(I_q + M)$ in the canonical basis of $\R^{q \times q}$, we immediately see that the gradient of $M \mapsto \det(I_q + M)$ at $0$ for the Euclidean structure induced by the Frobenius inner product is $I_d$. Consequently, since $M \mapsto \det(I_q + M)$ is $\mathcal{C}^1$ (it has a polynomial expression in the coefficients of $M$),               \det(I_q + M) = 1 + \tr(M) + o(\| M \|) \;.          The equivalence of norms in finite dimension allows us to conclude.",2502.01168
proof,"Let $\delta \geq 0$, by independence,       \Prob \p{\max_{i = 1 , \dots, N} |L_i| \leq \delta }      &= \Prob \p{\bigcap_{i = 1 , \dots, N} (|L_i| \leq \delta) } \\     &= \prod_{i = 1}^N \Prob \p{ (|L_i| \leq \delta) } \\     &= \p{1 - e^{-\delta}}^N \;.   Thus,                \E \p{\max_{i = 1 , \dots, N} |L_i|  }         &= \int_{[0, +\infty)} \Prob \p{\max_{i = 1 , \dots, N} |L_i| > \delta } d\delta \\         &= \int_{(0, +\infty)} \p{1 - \p{1 - e^{-\delta}}^N} d\delta \\         &\stackrel{u = e^{- \delta}}{=} \int_{(0, 1)} \p{1 - \p{1 - u}^N} \frac{du}{u} \\         &\stackrel{\p{1 - u}^N \geq \max(0, 1 - Nu)}{=} \int_{(0, 1)} \p{1 - \max(0, 1 - Nu)} \frac{du}{u} \\         &\stackrel{}{=} \int_0^{\frac{1}{N}} \p{1 - \max(0, 1 - Nu)} \frac{du}{u} + \int_{\frac{1}{N}}^1 \p{1 - \max(0, 1 - Nu)} \frac{du}{u} \\         &\leq 1 + \ln \p{N} \;.",2502.01168
proof,"\| f\|_{\infty}              &= \sqrt{\| f^2\|_{\infty} } \\             &\geq \sqrt{ \frac{1}{\vol \p{\tilde{\Omega}}}  \int_{\tilde{\Omega}} f^2 } \\             &\stackrel{\text{Parseval}}{=} {\sqrt{ \frac{1}{\vol \p{\tilde{\Omega}}}  \| (\gamma_k^{j, g})_{k, j, g}\|_{2}^2 }} \\             &\gtrsim \| (\gamma_k^{j, g})_{k, j, g}\|_{2} \\             &\geq \| (\gamma_k^{j, g})_{k, j, g}\|_{\infty} \;.                The inequality       \| f\|_{\infty}           \lesssim            2^{\frac{J d}{2}} \| (\gamma_k^{j, g})_{k, j, g}\|_{\infty}  comes from Lemma 24 in \cite{hutter2021minimax}.",2502.01168
proof,"Let $\theta_1, \theta_2\in \{0, 1 \}^{N}$, then        \int_{[0, 1]^d} \| \nabla \phi_{\theta_1} - \nabla \phi_{\theta_2}  \|^2      &\stackrel{\text{Disjoint supports}}{=}     \sum_{i=1}^{N} \int_{[0, 1]^d}     \left\|(\theta_1^i-\theta_2^i) h^{\alpha } \nabla \psi\p{\frac{x-p_i }{h}} \right\|^2 dx \\     &\stackrel{\text{Change of variables}}{=}     \ham{\theta_1}{\theta_2} h^{2 \alpha + d} \underbrace{\int \|\nabla \psi\|^2}_{> 0} \\     &\gtrsim \ham{\theta_1}{\theta_2} h^{2 \alpha + d} \;.",2502.01168
proof,"By the change of variables formula, for any $\theta \in \{0, 1 \}^{N}$, the density of $Q_{\theta}$  with respect to $P$ is      \frac{d Q_{\theta}}{dP}(y) = \frac{\Ind_{[0, 1]^d} ((\nabla \phi_{\theta})^{-1}(y))}{\det(\nabla^2 \phi_{\theta}((\nabla \phi_{\theta})^{-1}(y)))}  for $P$-almost all $y$.  Let $\theta_1, \theta_2\in \{0, 1 \}^{N}$,               &\tv{Q_{\theta_1}}{Q_{\theta_2}}         =          \frac{1}{2} \int_{(-1,2)^d} \left| \frac{d Q_{\theta_1}}{dP}(y) - \frac{d Q_{\theta_2}}{dP}(y) \right| dP(y) \\         &\quad\quad=          \frac{1}{2} \int_{[0, 1]^d} \left| \frac{\Ind_{[0, 1]^d} ((\nabla \phi_{\theta_1})^{-1}(y))}{\det(\nabla^2 \phi_{\theta_1}((\nabla \phi_{\theta_1})^{-1}(y)))} - \frac{\Ind_{[0, 1]^d} ((\nabla \phi_{\theta_2})^{-1}(y))}{\det(\nabla^2 \phi_{\theta_2}((\nabla \phi_{\theta_2})^{-1}(y)))} \right| dy \;,       and by stability of $[0, 1]^d$ and of its complement by either $\nabla \phi_{\theta_1}$ or $\nabla \phi_{\theta_2}$, this expression can be further simplified as                &\tv{Q_{\theta_1}}{Q_{\theta_2}}          = \frac{1}{2} \int \displaylimits_{[0, 1]^d} \left| \frac{1}{\det(\nabla^2 \phi_{\theta_1}((\nabla \phi_{\theta_1})^{-1}(y)))} - \frac{1}{\det(\nabla^2 \phi_{\theta_2}((\nabla \phi_{\theta_2})^{-1}(y)))} \right| dy \;.       Then, since both $\nabla \phi_{\theta_1}$ and $\nabla \phi_{\theta_2}$ are the identity outside balls of the form $B_{\infty}(p_i, h)$, and since these balls and their complements are stable by $\nabla \phi_{\theta_1}$ and by $\nabla \phi_{\theta_2}$, this can be rewritten as               &\tv{Q_{\theta_1}}{Q_{\theta_2}}          = \frac{1}{2} \sum_{i=1}^{N} \int \displaylimits_{B_{\infty}(p_i, h)} \left| \frac{1}{\det(\nabla^2 \phi_{\theta_1}((\nabla \phi_{\theta_1})^{-1}(y)))} - \frac{1}{\det(\nabla^2 \phi_{\theta_2}((\nabla \phi_{\theta_2})^{-1}(y)))} \right| dy         \;.       This expression finally further simplifies as                &\tv{Q_{\theta_1}}{Q_{\theta_2}}          = \\         &\quad\quad \frac{1}{2} \sum_{i=1}^{N} \Ind_{\theta_1^{(i)} \neq \theta_2^{(i)}} \underbrace{\int \displaylimits_{B_{\infty}(p_i, h)} \left| \frac{1}{\det(\nabla^2 \phi_{\theta_1}((\nabla \phi_{\theta_1})^{-1}(y)))} - \frac{1}{\det(\nabla^2 \phi_{\theta_2}((\nabla \phi_{\theta_2})^{-1}(y)))} \right| dy}_{\eqdef \Delta_i}         \;.       We treat the case $\theta_1^{(i)}=0$, $\theta_2^{(i)}=1$, the other case being treated similarly. In this case,                \Delta_i &= \int_{B_{\infty}(p_i, h)} \left| 1 - \frac{1}{\det(\nabla^2 \phi_{\theta_2}((\nabla \phi_{\theta_2})^{-1}(y)))} \right| dy \\         &= \int_{B_{\infty}(p_i, h)} \left| 1 - \frac{1}{\det(\nabla^2 \phi_{\theta_2}(x))} \right| |\det(\nabla^2 \phi_{\theta_2}(x))| dx \;,          where the last line comes from a change of variables and from the stability of $B_{\infty}(p_i, h)$ and of its complement.      For any $x \in B_{\infty}(p_i, h)$,            \nabla^2 \phi_{\theta_2}(x) = I_d + h^{\alpha-1} \nabla^2 \psi \p{\frac{x-p_i}{h}} \;.        By \Cref{lemma:linearizationdeterminant}, we see that if $a$ is chosen small enough, then we have $|\det(\nabla^2 \phi_{\theta_2}(\cdot))| \leq 2$ uniformly over $B_{\infty}(p_i, h)$.    Finally, and again by \Cref{lemma:linearizationdeterminant}, if $a$ is chosen small enough, $\forall x \in B_{\infty}(p_i, h)$,            \left| 1 - \frac{1}{\det(\nabla^2 \phi_{\theta_2}(x))} \right| \leq h^{\alpha - 1} \p{ \left| \tr \p{\nabla^2\psi \p{\frac{x-p_i}{h}}} \right| + \left\| \nabla^2\psi \p{\frac{x-p_i}{h}} \right\|} \;,        which entails, by a change of variables,            \Delta_i \leq \frac{h^{\alpha - 1 + d}}{2} \int \p{ \left| \tr \p{\nabla^2 \psi} \right| + \left\| \nabla^2\psi  \right\|} \lesssim h^{\alpha - 1 + d} \;.        Plugging this result back into \eqref{eq:ojhkfjqhsdlkjblkjqsdg} yields                     \tv{Q_{\theta_1}}{Q_{\theta_2}}          &\lesssim h^{\alpha - 1 + d} \sum_{i=1}^{N} \Ind_{\theta_1^{(i)} \neq \theta_2^{(i)}} \\         &= \ham{\theta_1}{\theta_2}  h^{\alpha - 1 + d} \;.",2502.01168
proof,The proof can be directly adapted from \cite{acharya2021differentially} by substituting the notation with that used in the present paper.,2502.01168
proof,"This proof builds on coupling arguments from \cite{acharya2018differentially,acharya2021differentially,lalanne2022statistical}.     Let us consider the coupling $\mathcal{C}$ that selects $\theta^1, \dots, \theta^{i-1}, \theta^{i+1} \dots, \theta^{N} \in \{0, 1 \}$ uniformly at random, and then      samples accordingly              X_1, \dots, X_n \sim P          and              (Y_1, Y_1'), \dots, (Y_n, Y_n') \sim Q          where $Q$ is the optimal coupling between $Q_{(\theta^1, \dots, \theta^{i-1}, 0, \theta^{i+1} \dots, \theta^{N})}$ and $Q_{(\theta^1, \dots, \theta^{i-1}, 1, \theta^{i+1} \dots, \theta^{N})}$. Here, the optimality means that if $(Y, Y') \sim Q$, then               \Prob(Y = Y') = 1 -\tv{Q_{(\theta^1, \dots, \theta^{i-1}, 0, \theta^{i+1} \dots, \theta^{N})}}{Q_{(\theta^1, \dots, \theta^{i-1}, 1, \theta^{i+1} \dots, \theta^{N})}} \;.          The existence of such a coupling is well known (see, \textit{e.g.} \cite{lindvall2002lectures}).     Furthermore, we let $X_1', \dots, X_n'$ be copies of $X_1, \dots, X_n$.      Then $\p{(X_1, \dots, X_n, Y_1, \dots, Y_n), (X_1', \dots, X_n', Y_1', \dots, Y_n')}$ (whose distribution is $\mathcal C$) is a coupling between $\Prob_{{{\theta_{+i}}}}$ and $\Prob_{{{\theta_{-i}}}}$.      Thus, we may write                           &\Prob_{{{\theta_{-i}}}} (\hat{\theta}^i \neq 0) + \Prob_{{{\theta_{+i}}}} (\hat{\theta}^i \neq 1) = \\             &\quad\quad             \E_{\mathcal{C}} \p{\Prob (\hat{\theta}^i \neq 0 | X_1, \dots, X_n, Y_1, \dots, Y_n) + \Prob (\hat{\theta}^i \neq 1 | X_1', \dots, X_n', Y_1', \dots, Y_n')}                   where the inner randomness (i.e. inside the expectation) is only w.r.t. $\hat{\theta}^i$. Since $\hat{T}$ is $\epsilon$-DP, then so is $\hat{\theta}^i$ by post-processing. Thus, by group privacy and the characteristic property of differential privacy,                           &\Prob_{{{\theta_{-i}}}} (\hat{\theta}^i \neq 0) + \Prob_{{{\theta_{+i}}}} (\hat{\theta}^i \neq 1) = \\             &\quad\quad \E_{\mathcal{C}} \p{\Prob (\hat{\theta}^i((X_1, \dots, X_n, Y_1, \dots, Y_n)) \neq 0) + \Prob (\hat{\theta}^i((X_1', \dots, X_n', Y_1', \dots, Y_n')) \neq 1)} \\             &\quad\quad \geq \E_{\mathcal{C}} \Bigg(e^{- \epsilon \ham{(X_1, \dots, X_n, Y_1, \dots, Y_n)}{(X_1', \dots, X_n', Y_1', \dots, Y_n')}}\Prob (\hat{\theta}^i((X_1', \dots, X_n', Y_1', \dots, Y_n')) \neq 0) \\             &\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad+ \Prob (\hat{\theta}^i((X_1', \dots, X_n', Y_1', \dots, Y_n')) \neq 1)\Bigg) \\             &\quad\quad \geq \E_{\mathcal{C}} \Bigg(e^{- \epsilon \ham{(X_1, \dots, X_n, Y_1, \dots, Y_n)}{(X_1', \dots, X_n', Y_1', \dots, Y_n')}} \\             &\qquad\qquad\qquad\qquad\qquad              \underbrace{\p{\Prob (\hat{\theta}^i((X_1', \dots, X_n', Y_1', \dots, Y_n')) \neq 0)+ \Prob (\hat{\theta}^i((X_1', \dots, X_n', Y_1', \dots, Y_n')) \neq 1)}}_{=1}\Bigg) \\             &\quad\quad = \E_{\mathcal{C}} \p{e^{- \epsilon \ham{(X_1, \dots, X_n, Y_1, \dots, Y_n)}{(X_1', \dots, X_n', Y_1', \dots, Y_n')}}} \\             &\quad\quad = \E_{\theta^1, \dots, \theta^{i-1}, \theta^{i+1} \dots, \theta^{N}} \Bigg(  \\             &\quad\quad\quad\quad\quad\quad\E_{{(X_1, \dots, X_n, Y_1, \dots, Y_n)}{(X_1', \dots, X_n', Y_1', \dots, Y_n')}} \p{e^{- \epsilon \ham{(X_1, \dots, X_n, Y_1, \dots, Y_n)}{(X_1', \dots, X_n', Y_1', \dots, Y_n')}}} \Bigg)\\             &\quad\quad \stackrel{\text{Jensen}}{\geq}             \E_{\theta^1, \dots, \theta^{i-1}, \theta^{i+1} \dots, \theta^{N}} \Bigg( \\             &\quad\quad\quad\quad\quad\quad e^{- \epsilon  \E_{{(X_1, \dots, X_n, Y_1, \dots, Y_n)}{(X_1', \dots, X_n', Y_1', \dots, Y_n')}} \p{\ham{(X_1, \dots, X_n, Y_1, \dots, Y_n)}{(X_1', \dots, X_n', Y_1', \dots, Y_n')}}}\bigg) \\             &\quad\quad =\frac{1}{2^{N-1}}\sum_{\theta^1, \dots, \theta^{i-1}, \theta^{i+1} \dots, \theta^{N} \in \{0, 1 \}} e^{- n \epsilon \tv{Q_{(\theta^1, \dots, \theta^{i-1}, 0, \theta^{i+1} \dots, \theta^{N})}}{Q_{(\theta^1, \dots, \theta^{i-1}, 1, \theta^{i+1} \dots, \theta^{N})}}} \;,                   where the last line comes from a simple computation.",2502.01168
lemma,"Suppose that there exists a random variable $\Priv $ independent of all the other sources of randomness such that $\hat{f}_{\text{\normalshape priv}}$ is $( X_{1:n}, Y_{1:n}, \Priv )$-measurable and there exists $U \geq 0$ that is $\Priv $-measurable such that       \underbrace{\hat{S}(\hat{f}_{\text{\normalshape priv}} | X_{1:n}, Y_{1:n}) - \hat{S}(\hat{f}_{J} | X_{1:n}, Y_{1:n})}_{\text{Suboptimality on the semi-dual}} \leq U  almost surely. If $\hat{f}_{\text{\normalshape priv}} \in V_J \cap \mathcal{X}(2M)$ almost surely, then                    \E_{X_{1:n}, Y_{1:n}} &\p{d(\hat{T}_{\text{\normalshape priv}}, T_0)^2} \\         &\lesssim          U + \frac{J 2^{J (d-2)}\ln(1 + C n)}{n}+ \frac{1}{n} \\         &\qquad\qquad\qquad + \inf_{T \in V_J \cap \mathcal{X}(2M)} d(T, T_0)^2               $\Priv $-almost surely for some positive constant $C$.      Here, $\E_{X_{1:n}, Y_{1:n}}$ denotes the expectation w.r.t. the data, i.e. conditional on $\Priv $.",2502.01168
lemma,"[Report Noisy Argmin with Laplace Noise]      Let $f_1, \dots, f_N$ be queries with sensitivities that are uniformly bounded by $\Delta$, that is, for any of neighboring datasets $D \sim D'$ and for any $i \in \{1,\dots,n\}$,                    |f_i(D) - f_i(D')| \leq \Delta \;.          Then, if $L_1, \dots, L_N$ are independent and identically distributed random variables with standard Laplace distribution, the mechanism $\hat{i}$ defined as              \hat{i}(D) \in \argmin \left\{ f_i(D) + \frac{2 \Delta}{\epsilon} L_i \right\}          is $\epsilon$-DP,  with the convention that we return a random index in the $\argmin$ when it is not unique.",2502.01168
lemma,"[Sensitivity of the semi-dual objective]      For any $f\in\mathcal{X}(2M)$, it holds that                   \sup_{(X_{1:n}, Y_{1:n}) \sim (X_{1:n}', Y_{1:n}')} &\left| \hat{S}(f | X_{1:n}, Y_{1:n}) - \hat{S}(f | X_{1:n}', Y_{1:n}') \right|          \\          &\qquad\qquad\leq          \frac{2 \| f \|_{\infty} \vee 2 | \tilde{\Omega} |^2}{n} \;.",2502.01168
lemma,"For any $f_1, f_2 \in \mathcal{X}(2M)$,               \left| \hat{S}(f_1 | X_{1:n}, Y_{1:n}) - \hat{S}(f_2 | X_{1:n}, Y_{1:n}) \right| \leq 2 \| f_1 - f_2\|_{\infty}          for any dataset $(X_{1:n}, Y_{1:n})$.",2502.01168
lemma,There exists a $\delta$-covering of $V_J \cap \mathcal{X}(2M)$ for $\| \cdot\|_{\infty}$ of cardinality at most $N$ where               \ln(N) \lesssim 2^{Jd} \ln \p{\frac{C 2^{J d / 2} }{\delta} + 1}          for some constant $C$ that does not depend on $J$ or $\delta$,2502.01168
lemma,"There exists an open neighborhood $O$ of $0$ in $\R^{q \times q}$ such that               M \in O \quad \implies \quad | \det(I_q + M) - 1 - \tr(M)| \leq \| M \| \;,          where $O$ is only affected by the choice of $\| \cdot \|$.",2502.01168
lemma,"Let $L_1, \dots, L_{M}$ be $M$ independent random variables with Laplace distribution (that is, with pdf $t \mapsto \frac{1}{2} e^{- |t|}$ w.r.t. Lebesgue's measure). Then               \E \p{\max_{i = 1 , \dots, N} |L_i|  } \leq  1 + \ln \p{N} \;.",2502.01168
lemma,"Let $f \in V_J$, and denote by $(\gamma_k^{j, g})_{k, j, g}$ its wavelet coefficients for compactly supported mother and father wavelets, and with support adequation to $\tilde{\Omega}$ as described in \Cref{sec:details_wavelet_decomposition}.      Then               \| (\gamma_k^{j, g})_{k, j, g}\|_{\infty}         \leq           \| (\gamma_k^{j, g})_{k, j, g}\|_{2}          \lesssim            \| f\|_{\infty}           \lesssim            2^{\frac{J d}{2}} \| (\gamma_k^{j, g})_{k, j, g}\|_{\infty} \;.",2502.01168
lemma,"For any $\theta_1, \theta_2 \in \{0, 1 \}^{N}$,               d(S_{\theta_1}, S_{\theta_2})^2         \gtrsim \ham{\theta_1}{\theta_2} h^{2 \alpha + d} \;.",2502.01168
lemma,"For any $\theta_1, \theta_2 \in \{0, 1 \}^{N}$, it holds that              \tv{Q_{\theta_1}}{Q_{\theta_2}}         \lesssim \ham{\theta_1}{\theta_2} h^{\alpha - 1 + d} \;.",2502.01168
lemma,"[Assouad's Lemma]      Assume that there exists $\tau > 0$ such that for any $\theta_1, \theta_2 \in \{0, 1 \}^{N}$,               d(S_{\theta_1}, S_{\theta_2})^2         \gtrsim \ham{\theta_1}{\theta_2} \tau.          Let $\hat{T}$ be any estimator and define $\hat{\theta} = \argmin_{\theta \in \{0,1\}^N} d(\hat T, \nabla \phi_\theta)$.      Then it holds that                   \sup_{\theta \in \{0, 1 \}^{N}} \E_{S_{\theta}} \p{\int \| \nabla \phi_{\theta} - \hat{T}  \|^2 dP}         \gtrsim \tau \sum_{i=1}^{N} \p{\Prob_{{{\theta_{-i}}}} (\hat{\theta}^i \neq 0) + \Prob_{{{\theta_{+i}}}} (\hat{\theta}^i \neq 1)},          where $\Prob_{{{\theta_{+i}}}}$ and $\Prob_{{{\theta_{-i}}}}$ are the mixture distributions              \Prob_{{{\theta_{+i}}}} \eqdef \frac{1}{2^{N-1}} \sum_{\theta: \theta^{(i)} = 1} S_{\theta}, \quad \text{ and } \quad \Prob_{{{\theta_{-i}}}} \eqdef \frac{1}{2^{N-1}} \sum_{\theta: \theta^{(i)} = 0} S_{\theta}\;.          Note that in \eqref{jhbkqjshdf} there is a second layer or randomness that is implicit, and that is w.r.t. the estimator itself (for privacy for instance).",2502.01168
lemma,"If $\hat{T}$ satisfies $\epsilon$-DP, then for any $i$,               &\Prob_{{{\theta_{-i}}}} (\hat{\theta}^i \neq 0) + \Prob_{{{\theta_{+i}}}} (\hat{\theta}^i \neq 1)     \geq \\     &\quad\quad     \frac{1}{2^{N-1}}\sum_{\theta^1, \dots, \theta^{i-1}, \theta^{i+1} \dots, \theta^{N} \in \{0, 1 \}} e^{-n \epsilon \tv{Q_{(\theta^1, \dots, \theta^{i-1}, 0, \theta^{i+1} \dots, \theta^{N})}}{Q_{(\theta^1, \dots, \theta^{i-1}, 1, \theta^{i+1} \dots, \theta^{N})}}} \;,       where $\hat{\theta}$ is built from $\hat{T}$ as in \Cref{lemma:Assouad}.",2502.01168
theorem,"Let $a\in(0,1)$. If $Y_0=\lfloor aN\rfloor$, then for any $c\in\mathbb{R}_+$,      \sup_{0\leq t\leq c}\|Z_{\lfloor Nt\rfloor}-z_t\|\longrightarrow_{N\rightarrow\infty}0  in probability.",2502.01178
theorem,\mathbb{E}(\Xi^A_{T^Y_N}\mathbf{1}_{T^Y_N<\infty}|Y_0=\lfloor aN\rfloor)&\underset{N\rightarrow\infty}{\longrightarrow}\frac{a^{\frac{1+s}{2s}}}{(1-a)^{\frac{1}{2s}}}\left(\int_{a}^{1}\frac{(1-u)^{\frac{1}{2s}}}{u^{\frac{1+s}{2s}}}\left[\frac{1}{2}+\frac{1}{2s}\frac{1}{1-u}\right]du\right).,2502.01178
theorem,\textcolor{red}{Theoreme de convergence vers le systeme dynamique limite},2502.01178
proof,"If the mother is chosen among advantaged individuals then by the definition of the model described in Section \ref{sec:model}, the site $\kappa_n$ is added to (or remains in) the set of advantaged individuals. If the mother is chosen among non advantaged individuals then the site $\kappa_n$ is removed from the set of advantaged individuals, if it was present in this set.",2502.01178
proof,"As summarized in Proposition \ref{prop:Avantages}, the number of advantaged individuals is increased by $1$ if the mother is advantaged while the dying individual is disadvantaged, which gives that $\mathbb{P}(Y_{n+1}=k+1|Y_n=k)=k/N\times\frac{(1+s)(N-k)}{k+(1+s)(N-k)}=\frac{1+s}{2+s}\times \frac{k(N-k)}{N(\frac{1}{2+s}k+\frac{1+s}{2+s}(N-k))}$. Similarly, the number of advantaged individuals is decreased by $1$ if the mother is disadvantaged while the dying individual is advantaged, which gives that $\mathbb{P}(Y_{n+1}=k-1|Y_n=k)=(N-k)/N\times\frac{k}{k+(1+s)(N-k)}=\frac{1}{2+s}\times \frac{k(N-k)}{N(\frac{1}{2+s}k+\frac{1+s}{2+s}(N-k))}$. Finally, the number of advantaged individuals remains the same if the mother and replaced individual have the same advantage status, which gives that $\mathbb{P}(Y_{n+1}=k|Y_n=k)=\frac{k}{N}\frac{k}{k+(1+s)(N-k)}+\frac{N-k}{N}\frac{(1+s)(N-k)}{k+(1+s)(N-k)}=\frac{k^2+(1+s)(N-k)^2}{N(k+(1+s)(N-k))}=1-\frac{(2+s)k(N-k)}{N(k+(1+s)(N-k))}=1-p_k$. As $p_0=p_N=0$, this gives that the states $0$ and $N$ are absorbing.",2502.01178
proof,"Result $(i)$ falls from Proposition \ref{prop-biasedRW} and from a classical result on ""gambler's ruin""  (see for example 3.9 (6) p. 74 in \cite{GrimmettStirzaker}). Note that $T_N<T_0$  iff $T_N<\infty$, iff $T_0=\infty$. We recall that $S_k$ is the hitting time of $k\in\{0,1,...,N\}$ by the random walk $H$. Remark that $T_{\lfloor bN\rfloor}<T_0$ iff $S_{\lfloor bN\rfloor}<S_0$, iff $S_{\lfloor bN\rfloor}<\infty$.  \\ Now, let us turn our attention to (ii).  For any $\epsilon<a$ and any $K>\frac{2+s}{s}$, $\mathbb P(S_{\lfloor bN\rfloor}<S_{\lfloor \epsilon N\rfloor})=\frac{(1+s)^{\lfloor aN\rfloor-\lfloor \epsilon N\rfloor}-1}{(1+s)^{\lfloor bN\rfloor-\lfloor \epsilon N\rfloor}-1}\rightarrow 0$ as $N\uparrow\infty$ and for any $K>\frac{2+s}{s}$ (which is the inverse of the drift of the random walk $H$), \mathbb P(S_{\lfloor bN\rfloor}>KbN)&<\mathbb P(H_{\lfloor KbN\rfloor}<\lfloor bN\rfloor)\\&<\mathbb{P}\Big(H_{\lfloor KbN\rfloor}-(\lfloor aN\rfloor+\frac{s}{2+s}\lfloor KbN\rfloor)<\lfloor bN\rfloor-(\lfloor aN\rfloor+\frac{s}{2+s}\lfloor KbN\rfloor)\Big)\\&<\mathbb{P}\Big(H_{\lfloor KbN\rfloor}-(\lfloor aN\rfloor+\frac{s}{2+s}\lfloor KbN\rfloor)<\lfloor bN\rfloor-(\frac{s}{2+s}\lfloor KbN\rfloor)\Big)\\&<\mathbb{P}\Big(\big|H_{KbN}-(\lfloor aN\rfloor+\frac{s}{2+s}\lfloor KbN\rfloor)\big|<\frac{s}{2+s}\lfloor KbN\rfloor-\lfloor bN\rfloor\Big) since $K>\frac{2+s}{s}$. Therefore $\mathbb P(S_{\lfloor bN\rfloor}>KbN)\rightarrow 0$ as $N\rightarrow\infty$ from Cebishev inequality. On $T_k<\infty$, $T_k=\sum_0^{S_k-1}L_i $, with the $L_i$'s being, conditionally to $H$, independent geometric random variables with parameter $p_{H_i}$. From the expression of $p_k=\frac{1}{\left(\frac{1}{2+s}\frac{N}{N-k}+\frac{1+s}{2+s}\frac{N}{k}\right)}$, we check that by taking $\epsilon$ small enough we can assume that $p_{\lfloor \epsilon N\rfloor}\leq p_k$ for all $\lfloor \epsilon N\rfloor\leq k\leq \lfloor  bN\rfloor$. Note that $\epsilon$ depends on $b$ since $p_{\lfloor \epsilon N\rfloor}$ must be smaller that $p_{\lfloor bN\rfloor}$. On $\{S_{\lfloor bN\rfloor}<S_{\lfloor \epsilon N\rfloor}\}$, using that the infimum of two independent geometric random variables is geometric, we can  define pairs of new  independent random variables $(D_i, E_i)$ such that $L_i=\min(E_i,D_i)$, the $D_i$'s are independent geometric random variables with parameter $p_{\lfloor \epsilon N\rfloor}$, and conditionally to $H$, the $E_i$'s are also independent geometric random variables with parameter $1-\frac{1-p_{H_i}}{1-p_{\lfloor \epsilon N\rfloor}}\in[0,1]$. Hence, on $\{S_{\lfloor bN\rfloor}<KN\}\cap\{S_{\lfloor bN\rfloor}<S_{\lfloor \epsilon N\rfloor} \}$,  $T_{\lfloor bN\rfloor}=\sum_{i=0}^{S_k-1}L_i\leq\sum_{i=0}^{S_k-1}D_i$. Now $p_{\lfloor \epsilon N\rfloor}<\frac{1}{\left(\frac{1}{2+s}\frac{1}{1-\epsilon+\frac{1}{N}}+\frac{1+s}{2+s}\frac{1}{\epsilon}\right)}=\epsilon\frac{(2+s)(1-\epsilon+1/N)}{(1+s)(1-\epsilon+1/N)+\epsilon}<2\epsilon$ if $N$ is large enough. Therefore, the expectation and the variance of $T_{\lfloor bN\rfloor}$ are respectively smaller than $\frac{KN}{2\epsilon}$ and $\frac{KN}{4\epsilon^2}$ which allows to conclude immediately by Cebishev inequality if we take $C$ larger than $\frac{K}{2\epsilon}$.\\  %%Hence, on $S_{\lfloor bN\rfloor<\infty}$, \mathbb E(T_{\lfloor bN\rfloor}|H)=\sum_{i=0}^{S_{\lfloor bN\rfloor}-1}\frac{1}{p_{H_i}}\quad\text{ and }\quad Var(T_{\lfloor bN\rfloor}|H)=\sum_{i=0}^{S_{\lfloor bN\rfloor}-1}\frac{1-p_{H_i}}{p_{H_i}}\leq \sum_{i=0}^{S_{\lfloor bN\rfloor}-1} \frac{1}{p_{H_i}}.  Moreover, \sum_{i=0}^{S_{\lfloor bN\rfloor}-1}\frac{1}{p_{H_i}}\leq\frac{S_{\lfloor bN\rfloor}}{p_{\min_b H}} with $\min_b H=\min_{0\leq i <S_{\lfloor bN\rfloor} }(H_i)$. \\ %%To prove $(ii)$, by Cebishev inequality, it is enough to show that for some positive $C$ (whose value is allowed to change at each step in what follows), $\mathbb E(T_{\lfloor bN\rfloor}|S_{\lfloor bN\rfloor}<\infty)<CN$ and $Var(T_{\lfloor bN\rfloor}| S_{\lfloor bN\rfloor}<\infty)<CN$.  We will now prove \\1.  $\mathbb E(S_{\lfloor bN\rfloor}|S_{\lfloor bN\rfloor}<\infty)<CN$ and $Var(S_{\lfloor bN\rfloor}| S_{\lfloor bN\rfloor}<\infty)<CN$, \\ %%2. $\mathbb E(\frac{S_{\lfloor bN\rfloor}}{p_{\min H_b}}|S_{\lfloor bN\rfloor}<\infty)<CN$.\\ %%Indeed from Equations \eqref{eq-exp-Tk} and \eqref{eq-control-1/p}, 2. will imply that $\mathbb E(T_{\lfloor bN\rfloor}|S_{\lfloor bN\rfloor}<\infty)<CN$ and that $\mathbb{E}(Var(T_{\lfloor bN\rfloor}|H))<CN$, and \textcolor{red}{1. will imply that $Var(\mathbb{E}(T_{\lfloor bN\rfloor}|H))<CN$ ?} %% %\textcolor{green}{ %1. results from (i) and from the fact that on $\{S_{\lfloor bN\rfloor}<\infty\}$, $S_{\lfloor bN\rfloor}$ can be bounded by the hitting time of the non absorbed random walk which is the sum of  $\lfloor bN\rfloor-\lfloor aN\rfloor$ i.i.d. random times with moments of all orders.\\ %As for any $1\leq k\leq \lfloor bN\rfloor$, $p_k<\frac{CN}{k}$, by Cauchy Schwartz inequality, 2. results from 1. and from the bounds: $\mathbb E(\frac{1}{\min H_b^2}1_{S_{\lfloor bN\rfloor}<\infty} ) % <C\sum_{k=1}^{\lfloor aN\rfloor}(\frac{N^2}{k^2}-\frac{N^2}{(k+1)^2})\mathbb P(\min H_b\leq k, S_{\lfloor bN\rfloor}<\infty)$\\ %$ <C\sum_{k=1}^{\lfloor aN\rfloor} \frac{N^2}{k^3}\mathbb P(S_k<S_{\lfloor bN\rfloor}<\infty)$ which stays bounded as $N\uparrow \infty$ since for any $x\leq a$, $\mathbb P(S_{\lfloor xN\rfloor}<S_{\lfloor bN\rfloor})$ is equivalent to $(1+s)^{(x-b)N}$. % }",2502.01178
proof,Equation \eqref{eq-Y} is equivalent to the result stated in Proposition \ref{prop:Y} and Equation \eqref{eq-W} is a consequence of the model presented in Section \ref{sec:model} and the definition \eqref{eq:defA}.,2502.01178
proof,"Equation \eqref{eq-dynamiqueZ} follows from the model described in Section \ref{sec:model} (i.e. from Lemma \ref{prop-WY}), and Equation \eqref{eq-ExpDZ} follows from the fact that $\mu_n$ and $\pi_n$ are uniformly chosen in $\{1,...,N\}$ and $\kappa_n\in\mathcal{Y}_n$ with probability $\frac{Y_n}{Y_n+(1+s)(N-Y_n)}$.",2502.01178
proof,"Let us first focus on the first differential equation of \eqref{eq:dyn-system} which happens to be closed : \frac{dy_t}{dt}=\frac{sy_t(1-y_t)}{y_t+(1+s)(1-y_t)}=\frac{sy_t(1-y_t)}{1+s(1-y_t)}=:m(y_t), with $y_0=a$. Since the function $m$ is Lipschitz continuous on $[0,1]$, from Cauchy-Lipschitz theorem, this ordinary differental equation admits a unique solution starting at $a\in[0,1]$. Since $m(0)=m(1)=0$, this solution is simply constant if $a\in\{0,1\}$, and if $a\in(0,1)$, then this solution is such that $y_t\in(0,1)$ for all $t$, and the differential equation \eqref{eq-dydt} can then also be written as: $$\frac{dy_t}{dt}\left[\frac{1+s}{y_t}+\frac{1}{1-y_t}\right]=s.$$ Noting that $\frac{1+s}{y}$ and $\frac{1}{1-y}$ are respectively the derivative of $y\rightarrow(1+s)\ln(y)$ and $y\rightarrow-\ln(1-y)$ gives that the solution to this equation starting from $a$ satisfies  \frac{y_t^{1+s}}{1-y_t}=\frac{a^{1+s}}{1-a}\exp(st)\in[0,\infty) \quad\text{for all $t\geq0$}. Let $F$ be the function such that $F(x)=\frac{x^{1+s}}{1-x}$ for all $x\in[0,1)$. The function $F$ is strictly increasing on $[0,1)$ and sends $[0,1)$ onto $[0,+\infty)$. Therefore, since $a\in[0,1)$, Equation \eqref{eq-y^1+s} gives that $y_t= F^{-1}\left(\frac{a^{1+s}}{1-a}\exp(st)\right)$ for all $t\geq0$, which is the first equation of \eqref{eq-sol-syst}.   \medskip Note that it gives in particular that   \exp(t/2)=\exp(st)^{\frac{1}{2s}}=\left(F(y_t)\frac{1-a}{a^{1+s}}\right)^{\frac{1}{2s}}=\frac{y_t^{\frac{1+s}{2s}}}{(1-y_t)^{\frac{1}{2s}}}\frac{(1-a)^{\frac{1}{2s}}}{a^{\frac{1+s}{2s}}}.   Let us now come back to the whole differential equation \eqref{eq:dyn-system}. The existence and uniqueness of the solution starting from the initial condition $(a,a,0)$ falls from Cauchy-Lipschitz theorem again. This solution $(z_t)_{t\geq0}$ belongs to $[0,1]^3$.  Now considering the quantity $D_t=\frac{u_te^{t/2}}{y_t}-\frac{v_te^{t/2}}{1-y_t}$, one finds out (see below) that \frac{dD_t}{dt}=0 \qquad \text{therefore}\qquad D_t=D_0=1 \qquad\text{for all $t\geq0$.} Note that this property is a fundamental characteristic of our model. An analogous version of it was given in \cite{CoronLeJan22} (Equation (1.7)) in a discrete setting and for infinite selection, which was extended for the finite selection case in \cite{coronLeJan2024}, Proposition 2.6. Equation \eqref{EquationD} is proved as follows :        \left(\frac{u}{y}\right)'&=\frac{u'}{y}-u\frac{y'}{y^2}=\frac{u}{2y}+\frac{u+v}{2}-\frac{u}{y[y+(1+s)(1-y)]}-\frac{usy(1-y)}{y^2[y+(1+s)(1-y)]}\\&=\frac{u+v}{2}-\frac{u}{2y},   therefore      \left(\frac{ue^{t/2}}{y}\right)'&=\frac{u+v}{2}e^{t/2},   and similarly      \left(\frac{v}{1-y}\right)'&=\frac{v'}{1-y}+v\frac{y'}{(1-y)^2}\\&=\frac{v}{2(1-y)}+\frac{u+v}{2}-\frac{(1+s) v}{(1-y)[y+(1+s)(1-y)]}+\frac{vsy(1-y)}{(1-y)^2[y+(1+s)(1-y)]}\\&=\frac{u+v}{2}-\frac{v}{2(1-y)}.  therefore       \left(\frac{ve^{t/2}}{1-y}\right)'&=\frac{u+v}{2}e^{t/2}.   In particular Equation \eqref{EquationD} gives that $u_te^{t/2}=y_t\left(1+\frac{v_t}{1-y_t}e^{t/2}\right)$ for all $t\geq0$. Finally, let us set $\beta_t=\frac{v_t}{1-y_t}e^{t/2}$. Then  \frac{d\beta_t}{dy_t}&=\frac{\frac{d\beta_t}{dt}}{\frac{dy_t}{dt}}=\frac{\frac{u_t+v_t}{2}e^{t/2}}{\frac{sy_t(1-y_t)}{y_t+(1+s)(1-y_t)}} \qquad\text{from Equation \eqref{eq-deriv-v}}\\&=\frac{y_t\left[1+\frac{v_t}{1-y_t}e^{t/2}\right]+v_te^{t/2}}{\frac{2sy_t(1-y_t)}{y_t+(1+s)(1-y_t)}}\\&=\frac{y_t+\beta_t}{\frac{2sy_t(1-y_t)}{y_t+(1+s)(1-y_t)}}. Therefore \frac{d\beta_t}{dy_t}=\frac{\beta_t}{\frac{2sy_t(1-y_t)}{y_t+(1+s)(1-y_t)}}+\frac{y_t+(1+s)(1-y_t)}{2s(1-y_t)}  and this differential equation can be solved using the variation of constant method. Let us to that purpose introduce a function $C$ defined on $(0,1)$ such that  \beta_t=C(y_t)\frac{y_t^{\frac{1+s}{2s}}}{(1-y_t)^{\frac{1}{2s}}}\quad\text{for all $t\geq0$}. Then from Equations \eqref{eq-diff-beta} and \eqref{eq-dydt} \frac{dC}{dy}\frac{y^{\frac{1+s}{2s}}}{(1-y)^{\frac{1}{2s}}}=\frac{y+(1+s)(1-y)}{2s(1-y)}=\frac{y}{2s(1-y)}+\frac{1+s}{2s}, therefore \frac{dC}{dy}=\frac{(1-y)^{\frac{1}{2s}-1}}{2sy^{\frac{1+s}{2s}-1}}+\frac{1+s}{2s}\frac{(1-y)^{\frac{1}{2s}}}{y^{\frac{1+s}{2s}}},  which gives that since $\beta_0=0$ and $y_0=a$,  C(y)&=\frac{1}{2s}\int_a^{y}\frac{(1-x)^{\frac{1}{2s}}}{x^{\frac{1+s}{2s}}}\left[\frac{x}{1-x}+1+s\right]dx\\&=\frac{1}{2s}\int_a^{y}\frac{(1-x)^{\frac{1}{2s}}}{x^{\frac{1+s}{2s}}}\left[\frac{1}{1-x}+s\right]dx\\&=\int_a^{y}\frac{(1-x)^{\frac{1}{2s}}}{x^{\frac{1+s}{2s}}}\left[\frac{1}{2}+\frac{1}{2s}\frac{1}{1-x}\right]dx,  Therefore from Equation \eqref{eq-yt}, \frac{v_t}{1-y_t}&=e^{-\frac{t}{2}}\beta_t=\frac{a^{\frac{1+s}{2s}}}{(1-a)^{\frac{1}{2s}}}\int_a^{y_t}\frac{(1-x)^{\frac{1}{2s}}}{x^{\frac{1+s}{2s}}}\left[\frac{1}{2}+\frac{1}{2s}\frac{1}{1-x}\right]dx which gives the second equation of \eqref{eq-sol-syst}.  Finally from Equation \eqref{EquationD},  \frac{u_t}{y_t}&=e^{-\frac{t}{2}}(1+\beta_t)=\frac{a^{\frac{1+s}{2s}}}{(1-a)^{\frac{1}{2s}}}\left[\frac{(1-y_t)^{\frac{1}{2s}}}{y_t^{\frac{1+s}{2s}}}+\int_a^{y_t}\frac{(1-x)^{\frac{1}{2s}}}{x^{\frac{1+s}{2s}}}\left[\frac{1}{2}+\frac{1}{2s}\frac{1}{1-x}\right]dx\right] which gives the third equation of \eqref{eq-sol-syst}.",2502.01178
proof,"The first point is the application of Equation \eqref{eq-sol-syst} in $t=r_b$, therefore with $y_t=b$.   The convergence stated in $(ii)$ is immediate from Equation \eqref{eq-sol-syst} and notably the already mentioned fact that $(y_t)_{t\geq0}$ is strictly increasing and converges to $1$ when $t$ goes to infinity.",2502.01178
proof,"From Proposition \ref{prop-Z}, we can decompose : $$Z_{n+1}-Z_n=A_{n+1}+g(Z_n)$$ where $g(Z_n)=\mathbb{E}(Z_{n+1}-Z_n|\mathcal{F}^Z_n)$ is such that      g(y,u,v)=\Big(\frac{y(1-y)s}{y+(1+s)(1-y)},&\frac{u}{2}+\frac{u+v}{2}y-\frac{u}{y+(1+s)(1-y)},\\&\frac{v}{2}+\frac{u+v}{2}(1-y)-\frac{(1+s)v}{y+(1+s)(1-y)}\Big) for all $(y,u,v)\in[0,1]^3$, and $A_{n+1}=Z_{n+1}-Z_n-\mathbb{E}(Z_{n+1}-Z_n|\mathcal{F}^Z_n)=Z_{n+1}-\mathbb{E}(Z_{n+1}|\mathcal{F}^Z_n)$. Therefore      Z_n=Z_0+\sum_{k=1}^n A_k+\frac{1}{N}\sum_{k=1}^{n-1} g(Z_k)  and the variables $(A_k)_{1\leq k\leq n}$ are the increments of a $\mathcal{F}^Z$-martingale $(M_n)_{n\geq 0}=(\sum_{k=1}^nA_k)_{n\geq 0}$.  Now from Doob's martingale inequality, for all $c>0$,  $$\mathbb{E}\left(\sup_{0\leq n\leq \lfloor c N\rfloor} (M_n)^2\right)\leq  4\mathbb{E}\left(M_{\lfloor cN\rfloor}^2\right).$$  Besides, $$\mathbb{E}(M_{\lfloor cN\rfloor}^2)=\mathbb{E}\left(\Big(\sum_{k=1}^{\lfloor cN\rfloor}A_k\Big)^2\right)=\mathbb{E}\left(\sum_{k=1}^{\lfloor cN\rfloor}(A_k)^2\right)\leq \frac{12c}{N}\quad\text{as $\|Z_{n+1}-Z_n\|^2\leq 3$,}$$ which gives that  $$\sup_{0\leq t\leq c}\left\|\sum_{k=1}^{\lfloor Nt\rfloor} A_k \right\|\longrightarrow 0 \quad\quad \text{in probability when $N$ goes to infinity.}$$  Now from Proposition \ref{prop-z},      z_t=(a,a,0)+\int_{0}^{t}g(z_s)ds  for all $t\in[0,c]$. Therefore       Z_{\lfloor Nt\rfloor}-z_t=(Y_0/N,Y_0/N,0)-(a,a,0)+\frac{1}{N}\sum_{k=1}^{\lfloor Nt\rfloor}A_k+\int_0^t g(Z_{\lfloor Ns\rfloor})-g(z_s)ds  and since the function Jacobian matrix of the function $g$ is bounded, there exists $K\in\mathbb{R}_+$ such that $\|g(z)-g(z')\|\leq K\|z-z'\|$ for all $z,z'\in[0,1]^3$, and then      \left\|Z_{\lfloor Nt\rfloor}-z_t\right\|\leq\|(Y_0/N,Y_0/N,0)-(a,a,0)\|+\|\frac{1}{N}\sum_{k=1}^{\lfloor Nt\rfloor}A_k\|+\int_0^t K\|Z_{\lfloor Ns\rfloor}-z_s)\|ds   therefore by Gronwall's inequality, for any $t\in[0,c]$,      \|Z_{\lfloor Nt\rfloor}-z_t\|\leq\left(\|(Y_0/N,Y_0/N,0)-(a,a,0)\|+\left\|\frac{1}{N}\sum_{k=1}^{\lfloor Nt\rfloor}A_k\right\|\right)e^{Kt}  which gives the result.",2502.01178
proof,%    Argument de suites adjacentes ? %,2502.01178
proof,"This results from Theorem \ref{thmCvceDeterministe}, Proposition \ref{prop-Y-TN} (ii) and Corollary \ref{cor-zb} (i).",2502.01178
proof,"Define for any $k\in[\![1,\lfloor bN\rfloor]\!]$, $$\phi_D(k)=\mathbb{E}(D_{T^Z_{\lfloor bN\rfloor}}\mathbf{1}_{T^Z_{\lfloor bN\rfloor}<\infty}| Z_0=k) \quad\text{ and }\quad \psi_D(k)=\frac{\left(\frac{k}{N}\right)^{\frac{1+s}{2s}}}{\left(1-\frac{k}{N}\right)^{\frac{1}{2s}}}\times \frac{(1-b)^{\frac{1}{2s}}}{b^{\frac{1+s}{2s}}}.$$ Our aim is to prove that the functions $\phi_D$ and $\psi_D$ are close to each other on $[\lfloor aN\rfloor,\lfloor bN\rfloor]$ for large $N$.  Let us define the infinitesimal generator $\mathcal{L}$ on the set of real valued functions $g$ on $[\![0,N]\!]$ vanishing in $0$ and $N $ by $$\mathcal{L}g(k)=\frac{1+s}{2+s}\lambda_+(k)g(k+1)+\frac{1}{2+s}\lambda_-(k)g(k-1)-g(k)$$ for any $k\in[\![1,N-1]\!]$. Recall that $\lambda_+(k)=1-\frac{N+1}{(k+1)(2N+1)}$ and $\lambda_-(k)=1-\frac{N+1}{(N-k+1)(2N+1)}$. Therefore  \mathcal{L}g(k)&=\frac{1+s}{2+s}\left(g(k+1)-g(k)\right)+\frac{1}{2+s}\left(g(k-1)-g(k)\right)\\&-\frac{1+s}{2+s}\frac{N+1}{(k+1)(2N+1)}g(k+1)-\frac{1}{2+s}\frac{N+1}{(N-k+1)(2N+1)}g(k-1).  By definition, the function $\phi_D$ is such that for any $k\in[\![1,\lfloor bN\rfloor-1]\!]$, $$\mathcal{L}\phi_D(k)=0,$$  and $\phi_D(\lfloor bN\rfloor)=1$.   Now the function $\psi_D$ is such that $\psi_D(\lfloor bN\rfloor)=1$. What is more,  for any $1\leq k \leq \lfloor bN\rfloor$, $$\psi_D(k)=f_D\left(\frac{k}{N}\right)$$ where $f_D(x)=C_b\frac{x^{\frac{1+s}{2s}}}{(1-x)^{\frac{1}{2s}}}$, where $C_b=\frac{(1-b)^{\frac{1}{2s}}}{(b^{\frac{1+s}{2s}}}$ for all $x\in[0,b]$. One has for all $x\in[0,b]$,  f'_D(x)&=f_D(x)\left[\frac{1+s}{2s}\frac{1}{x}+\frac{1}{2s}\frac{1}{1-x}\right]\quad\text{and}\\f''_D(x)&=f_D(x)\left[\left(\frac{1+s}{2s}\frac{1}{x}+\frac{1}{2s}\frac{1}{1-x}\right)^2-\frac{1+s}{2s}\frac{1}{x^2}+\frac{1}{2s}\frac{1}{(1-x)^2}\right].    Hence $$\psi_D(k\pm1)=\psi_D(k)\pm\psi_D(k)\left[\frac{1+s}{2s}\frac{1}{k}+\frac{1}{2s}\frac{1}{N-k}\right]+R\left(\frac{k}{N}\right)$$ where the function $R$ is such that there exists a positive constant $C$ such that $|R(x)|\leq \frac{C}{N^2}$ for all $x\in[a,b]$.  %$$R\left(\frac{k}{N}\right)=\frac{1}{2}\int_{\frac{k}{N}}^{\frac{k+1}{N}}\left(\frac{k+1}{N}-t\right)^2f''(t)dt.$$    Therefore  for any $1\leq k \leq \lfloor bN\rfloor-1$  \mathcal{L}\psi_D(k)&=\frac{1}{2+s}\frac{1}{2N}\psi_D(k)\left[\frac{1+s}{\frac{k}{N}}+\frac{1}{1-\frac{k}{N}}\right]-\frac{1}{2+s}\psi_D(k)\left(\frac{1+s}{2(k+1)}+\frac{1}{2(N-k+1)}\right)+\widetilde{R}\left(\frac{k}{N}\right)\\&=\frac{1}{2+s}\psi_D(k)\left[\frac{1+s}{2}\left(\frac{1}{k}-\frac{1}{k+1}\right)+\frac{1}{2}\left(\frac{1}{N-k}-\frac{1}{N-k+1}\right)\right]+\widetilde{R}\left(\frac{k}{N}\right)  where the function $\widetilde{R}$  is such that there exists a positive constant $\widetilde{C}$ such that $|\widetilde{R}(x)|\leq \frac{C}{N^2}$ for all $x\in[a,b]$. Hence there exists a positive constant $C'$ such that for all $k\in[\lfloor aN\rfloor,\lfloor bN\rfloor]$, $$|\mathcal{L}\psi(k)|\leq \frac{C}{N^2}.$$  Let us  now define the function $\bar{\psi}$ by $\bar{\psi}_D(k)=\psi_D(k)$ for all $k\in[\lfloor aN/2\rfloor,\lfloor bN\rfloor]$ and $\bar{\psi}_D(k)=\phi_D(k)$ for all $k\in[0,\lfloor aN/2\rfloor[$. Our aim from now is to prove that the functions $\phi_D$ and $\bar{\psi}_D$ are close to each other on $[\lfloor aN\rfloor, \lfloor bN\rfloor]$.  Note that since $\bar{\psi_D}-\phi_D$ vanishes in $0$ and $N$,  $$-(\bar{\psi}_D-\phi_D)=((-\mathcal{L})^{-1})\mathcal{L})(\bar{\psi}_D-\phi_D),$$  where $(-\mathcal{L})^{-1}=\sum_{n\geq 0} (I+\mathcal{L})^n=\sum_{n\geq 0} Q^n$ where $Q=(Q_{ij})_{1\leq i,j\leq \lfloor bN\rfloor-1}$ is defined by Q_{k,k+1}&=\frac{1+s}{2+s}\lambda_+(k), \quad\quad\text{for all $k\in[1,\lfloor bN-2\rfloor]$}\\Q_{k,k-1}&=\frac{1}{2+s}\lambda_-(k) \quad\quad\text{for all $k\in[2,\lfloor bN\rfloor-1]$}\\ Q_{k,l}&=0 \quad \text{elsewhere.}   We know that \left\{&\mathcal{L}(\bar{\psi}_D-\phi_D)(k)=O\left(\frac{1}{N^2}\right) \quad\text{ uniformly for $k\in[\![1,N]\!]\setminus\{\lfloor a N/2\rfloor-1,\lfloor a N/2\rfloor,\lfloor a N/2\rfloor +1\}$, and}\\&\mathcal{L}(\bar{\psi}_D-\phi_D)(k)\leq 1 \text{  for $k\in\{\lfloor a N/2\rfloor-1,\lfloor a N/2\rfloor,\lfloor aN/2\rfloor +1\}$.}\right.  Note now that since $\lambda_+(k)$ and $\lambda_-(k)$ are in $[0,1]$,  $$\big(\sum_{n\geq 0} Q^n\big)(x,y)\leq\mathbb{E}\big(\sum_{n\geq0} \mathbf{1}_{Z_n=y}|Z_0=x\big),$$ and from Markov property,  $$\mathbb{E}\big(\sum_{n\geq0} \mathbf{1}_{Z_n=y}|Z_0=x\big)=\mathbb{P}(T^Z_y<\infty|Z_0=x)\mathbb{E}(\sum_{n\geq0}  \mathbf{1}_{Z_n=y}|Z_0=y)<C(s) \mathbb{P}_x(T^Z_y<\infty)$$ as $s>0$.   Besides, recall from Proposition \ref{prop-Z} that $\mathbb{P}(T^Z_{ a N/2}<\infty|Z_0= a N)$ decreases exponentially with $N$, when $ a$ is fixed.    Therefore  \left|\bar{\psi}_D-\phi_D\right|(k)&=\big|\big(\sum_{n\geq 0} Q^n\big)\big(\mathcal{L}(\bar{\psi}_D-\phi_D)\big)\big|(k)\\&\leq\big(\sum_{n\geq 0} Q^n\big)\big|\mathcal{L}(\bar{\psi}_D-\phi_D)\big|(k)\\&\leq\sum_{j\in[\![0,N]\!]}\sum_{n\geq 0} Q^n_{kj}\big|\big(\mathcal{L}(\bar{\psi}_D-\phi_D)\big)(j)\big|\\&=\sum_{j\in\{\lfloor  a N/2\rfloor-1,\lfloor a N/2\rfloor,\lfloor a N/2\rfloor +1\}}\sum_{n\geq 0} Q^n_{kj}\big|\big(\mathcal{L}(\bar{\psi}_D-\phi_D)\big)(j)\big|\\&+\quad\sum_{j\notin\{\lfloor  a N/2\rfloor-1,\lfloor a N/2\rfloor,\lfloor a N/2\rfloor +1\}}\sum_{n\geq 0} Q^n_{kj}\big|\big(\mathcal{L}(\bar{\psi}_D-\phi_D)\big)(j)\big|.  The first quantity has an exponential bound from Proposition \ref{prop-Z}. The second quantity is bounded by $C/N$, from Equation \ref{eq-Ldiff} and since $\sum_j \sum_n Q^n_{kj}= \mathbb{E}(T_{0,N}^Z|Z_0=k)\leq C(s) N$. Therefore there exists a constant $C$ such that $\left|\bar{\psi}_D-\phi_D\right|(k)\leq C/N$ for all $k \in[ a N, bN]$.",2502.01178
proof,"For any $k\in[a N, b N]$ let us denote $\phi_{\widetilde{V}}(k)=\mathbb{E}(\widetilde{V}_{T_{0,b N}}|Z_0=k)$.  The function $\phi_{\widetilde{V}}$ now satisfies for any $k\in]\!]1, bN[\![$, $$\mathcal{L}\phi_{\widetilde{V}}(k)=-\frac{1+s}{2+s}\beta_+(k)-\frac{1}{2+s}\beta_-(k).$$ Moreover, when $N$ is large, $\beta_+(k)\sim\frac{1+s}{2N(2+s)}$ and $\beta_-(k)\sim\frac{1+s}{2N(2+s)}+\frac{k}{2N(N-k)}$. Therefore  \mathcal{L}\phi_{V}(k)=-\frac{1+s}{2N(2+s)}-\frac{1}{2+s}\frac{k}{2N(N-k)}+O(1/N^2)=-\frac{1}{2N(2+s)}\frac{N+s(N-k)}{N-k}+O(1/N^2) for all $k\in[\![1,bN]\!]$.   Now let $$\psi_{\widetilde{V}}(k)=\left(\int_{k/N}^{b}\frac{(1-u)^{\frac{1}{2s}}}{u^{\frac{1+s}{2s}}}\left[\frac{1}{2}+\frac{1}{2s}\frac{1}{1-u}\right]du\right)\times \frac{\left(\frac{k}{N}\right)^{\frac{1+s}{2s}}}{(1-\frac{k}{N})^{\frac{1}{2s}}}.$$  Our aim from here is to prove that the functions $\phi_{V}$ and $\psi_{V}$ are close to each other.   Setting $\psi_{\widetilde{V}}(k)=f_{\widetilde{V}}(k/N)$, we have  $$f_{V}(t)=\left(\int_{t}^{b}\frac{(1-u)^{\frac{1}{2s}}}{u^{\frac{1+s}{2s}}}\left[\frac{1}{2}+\frac{1}{2s}\frac{1}{1-u}\right]du\right)\times \frac{t^{\frac{1+s}{2s}}}{(1-t)^{\frac{1}{2s}}}$$  hence  $$f_{\widetilde{V}}'(t)=f_{\widetilde{V}}(t)\left[\frac{1+s}{2s}\frac{1}{t}+\frac{1}{2s}\frac{1}{2(1-t)}\right]-\frac{1}{2}-\frac{1}{2s}\frac{1}{1-t}$$ and  $$f_{\widetilde{V}}''(t)=f_{\widetilde{V}}(t)\left[\frac{1+s}{2s}\frac{1}{t}+\frac{1}{2s}\frac{1}{1-t}\right]-\frac{1+s}{2(2+s)}-\frac{1}{2+s}\frac{t}{2(1-t)}.$$  Therefore $$\psi_{\widetilde{V}}(k\pm1)=\psi_{\widetilde{V}}(k)\pm\frac{1}{N}\left[\psi_{\widetilde{V}}(k)\left[\frac{1+s}{2+s}\frac{1}{2\frac{k}{N}}+\frac{1}{2+s}\frac{1}{2(1-\frac{k}{N})}\right]-\frac{1+s}{2(2+s)}-\frac{1}{2+s}\frac{\frac{k}{N}}{2(1-\frac{k}{N})}\right]+R(k/N)$$ where the function $R$ is such that there exists a positive constant $C$ such that $|R(x)|\leq \frac{C}{N^2}$. Hence, since $\psi_{\widetilde{V}}$ is bounded,   \mathcal{L}\psi_{\widetilde{V}}(k)=-\frac{1}{2+s}\left[\frac{s}{2N}+\frac{1}{2(N-k)}\right]+O\left(\frac{1}{N^2}\right)=-\frac{1}{2+s}\frac{s(N-k)+N}{2N(N-k)}+O\left(\frac{1}{N^2}\right). for all $k\in[\![1,bN]\!]$.  Therefore $$\mathcal{L}(\psi_{\widetilde{V}}-\phi_{\widetilde{V}})(k)=O\left(\frac{1}{N^2}\right)$$ for all $k\in[\![1,bN]\!]$.  Now as in the proof of Proposition \ref{prop-X}, one can introduce a function $\bar{\psi}_{\tilde{V}}$ which coincides with $\psi_{\tilde{V}}$ above $\lfloor aN/2\rfloor$ and with $\phi_{\tilde{V}}$ below. Next, reasoning exactly as in the proof of Proposition \ref{prop-X}, the fact that $\mathbb{P}(T^Z_{aN.2}|Z_0=aN)$ decreases exponentially with $N$ when $a$ is fixed gives that there exists a constant $C$ such that $\left|\bar{\psi}_V-\phi_V\right|(k)\leq C/N$ for all $k \in[\![aN,bN]\!]$ which gives the result for $\tilde{V}$. The expression for $\tilde{U}$ then follows by Proposition \ref{prop-X}.",2502.01178
proof,"First, by definition of $\tilde U$, $\mathbb{E}(\Xi^A_{T^Y_N}\mathbf{1}_{T^Y_N<\infty}|Y_0=\lfloor aN\rfloor)=\mathbb{E}(\tilde U_{T^Z_N}\mathbf{1}_{T^Z_N<\infty}|Y_0=\lfloor aN\rfloor)$.\\ Note that from Equation \eqref{eq-UV}, the sequences $(\widetilde{U}_n)_{n\in\mathbb{Z}_+}$ and $(\widetilde{V}_n)_{n\in\mathbb{Z}_+}$ are respectively  decreasing and increasing. In particular for any $\epsilon>0$, if $T^Z_N<\infty$, $$\widetilde{V}_{T^Z_{\lfloor N(1-\epsilon)\rfloor}}\leq \widetilde{V}_{T^Z_{N-1}}\leq\tilde{U}_{T^Z_{N-1}}=\tilde{U}_{T^Z_N}\leq \tilde{U}_{T^Z_N}.$$  Therefore  $$\mathbb{E}\left(\widetilde{V}_{T^Z_{\lfloor N(1-\epsilon)\rfloor}}\mathbf{1}_{T^Z_N<\infty}\right)\leq \mathbb{E}\left(\tilde{U}_{T^Z_{N-1}}\mathbf{1}_{T^Z_N<\infty}\right)=\mathbb{E}\left(\tilde{U}_{T^Z_N}\mathbf{1}_{T^Z_N<\infty}\right)\leq \mathbb{E}\left(\tilde{U}_{T^Z_{\lfloor N(1-\epsilon)\rfloor}}\mathbf{1}_{T^Z_N<\infty}\right).$$  What is more, $$\mathbb{E}\left(\widetilde{V}_{T^Z_{\lfloor N(1-\epsilon)\rfloor}}\mathbf{1}_{T^Z_N<\infty}\right)\geq \mathbb{E}\left(\widetilde{V}_{T^Z_{\lfloor N(1-\epsilon)\rfloor}}\mathbf{1}_{T^Z_{\lfloor N(1-\epsilon)\rfloor}<\infty}\right)-\mathbb{P}(T^Z_N=\infty,T^Z_{\lfloor N(1-\epsilon)\rfloor}<\infty),$$ while $$\mathbb{E}\left(\tilde{U}_{T^Z_{\lfloor N(1-\epsilon)\rfloor}}\mathbf{1}_{T^Z_N<\infty}\right)\leq \mathbb{E}\left(\tilde{U}_{T^Z_{\lfloor N(1-\epsilon)\rfloor}}\mathbf{1}_{T^Z_{\lfloor N(1-\epsilon)\rfloor}<\infty}\right).$$  Therefore since $\mathbb{P}(T^Z_N=\infty,T^Z_{\lfloor N(1-\epsilon)\rfloor}<\infty)$ goes to $0$ when  $N$ goes to infinity, from Proposition \ref{prop-main}, $$\limsup_{N\rightarrow\infty} \mathbb{E}\left(\tilde{U}_{T^Z_{N}}\mathbf{1}_{T^Z_N<\infty}\right)\leq \frac{\left(\frac{a}{(1-\epsilon)}\right)^{\frac{1+s}{2s}}}{\left(\frac{1-a}{\epsilon}\right)^{\frac{1}{2s}}}+\left(\int_{a}^{1-\epsilon}\frac{(1-u)^{\frac{1}{2s}}}{u^{\frac{1+s}{2s}}}\left[\frac{1}{2}+\frac{1}{2s}\frac{1}{1-u}\right]du\right)\times \frac{a^{\frac{1+s}{2s}}}{(1-a)^{\frac{1}{2s}}}$$  and $$\liminf_{N\rightarrow\infty} \mathbb{E}\left(\tilde{U}_{T^Z_{N}}\mathbf{1}_{T^Z_N<\infty}\right)\geq \left(\int_{a}^{1-\epsilon}\frac{(1-u)^{\frac{1}{2s}}}{u^{\frac{1+s}{2s}}}\left[\frac{1}{2}+\frac{1}{2s}\frac{1}{1-u}\right]du\right)\times \frac{a^{\frac{1+s}{2s}}}{(1-a)^{\frac{1}{2s}}}.$$  Letting $\epsilon$ go to $0$ gives the result.",2502.01178
proof,"Let $f\in\mathcal{C}^2_b([0,1]^3)$. The sequence $(U_n,V_n,Y_n)_{n\in\mathbb{Z}_+}$ (which is not Markovian) is such that for any function $f$ in $\mathcal{C}^2_b(\mathbb{R}_+^3,\mathbb{R})$, f(Z_{n+1})-f(Z_n)&=\mathbb{E}(f(Z_{n+1})-f(Z_n)|\mathcal{F}^Z_n)+f(Z_{n+1})-\mathbb{E}(f(Z_{n+1})|\mathcal{F}^Z_n)\\&=\mathbb{E}(f(Z_{n+1})-f(Z_n)|\mathcal{F}^Z_n)+M^f_{n+1}-M^f_n  where $(M^f_n)$ is a martingale.  Now \mathbb{E}(f(Z_{n+1})-f(Z_n)|\mathcal{F}^Z_n)&=\frac{1}{N}\frac{\partial f}{\partial U}(U_n,V_n,Y_n)\times \left[\frac{U_n}{2}+\frac{U_n+V_n}{2}Y_n-\frac{U_n}{Y_n+(1+s)(1-Y_n)}\right]\\&+\frac{1}{N}\frac{\partial f}{\partial V}(U_n,V_n,Y_n)\times\left[\frac{V_n}{2}+\frac{U_n+V_n}{2}(1-Y_n)-\frac{V_n(1+s)}{Y_n+(1+s)(1-Y_n)}\right] \\&+\frac{1}{N}\frac{\partial f}{\partial Y}(U_n,V_n,Y_n)\times\left[\frac{sY_n(1-Y_n)}{Y_n+(1+s)(1-Y_n)}\right]\\&+\frac{1}{N^2}R(U_n,V_n,Y_n) where $R$ is bounded.   Now      \mathbb{E}((f(Z_{n+1})-f(Z_n))^2)=",2502.01178
proof,"We look at the triplet $(\frac{U_n}{Y_n},\frac{V_n}{Y_n},\frac{Y_n}{N})\in[0,1]^3=\xi_n$ for all $n\geq 0$.       Look at the limiting flow $\phi_{s,t}$ solution of the dynamical system :      $$f\circ \phi_{\frac{k}{n},\frac{k+1}{n}}=f+\frac{1}{N}Lf+O\left(\frac{1}{N^2}\right)$$      $$\mathbb{E}(\mathbf{1}_{T_b>n}\left|f_N(\xi_n)-f(u_n,v_n,y_n)\right|)$$      $$\xi_{\lfloor \frac{t}{N}\rfloor}$$",2502.01178
proposition,"The stochastic process $(\mathcal{Y}_n)_{n\in\mathbb{Z}_+}$ is a Markov chain, such that $$\mathcal{Y}_{n+1}=   \mathcal{Y}_n\cup\{\kappa_n\} \qquad \text{ if $\mu_n\in\mathcal{Y}_n$} \\   \mathcal{Y}_n\setminus\{\kappa_n\}\qquad \text{if $\mu_n\notin\mathcal{Y}_n$ and $\kappa_n\in\mathcal{Y}_n$}\\   \mathcal{Y}_n \qquad \text{if $\mu_n,\kappa_n\notin\mathcal{Y}_n$.} $$",2502.01178
proposition,"The stochastic process  $(Y_n)_{n\in\mathbb{Z}_+}$ is a Markov chain such that if $Y_n=k\in \{0,1,...,N\}$ then $Y_{n+1}\in\{k-1,k,k+1\}$, and \mathbb{P}(Y_{n+1}=k-1|Y_n=k)&=p_k\times\frac{1}{2+s},\\\mathbb{P}(Y_{n+1}=k+1|Y_n=k)&=p_k\times\frac{1+s}{2+s},\quad\text{and}\\\mathbb{P}(Y_{n+1}=k|Y_n=k)&=1-p_k, where $p_k=\frac{k(N-k)}{N\left(\frac{1}{2+s}k+\frac{1+s}{2+s}(N-k)\right)}=\frac{1}{\left(\frac{1}{2+s}\frac{N}{N-k}+\frac{1+s}{2+s}\frac{N}{k}\right)}.$ This Markov chain is absorbed in $0$ and in $N$.",2502.01178
proposition,"The stochastic process $(H_l)_{l\in\mathbb{Z}_+}$ is a simple random walk absorbed in $\{0,N\}$ : For any $l\in\mathbb{Z}_+$ such that $H_l\notin\{0,N\}$, \mathbb{P}(H_{l+1}&=H_{l}+1)=\frac{1+s}{2+s}\\\mathbb{P}(H_{l+1}&=H_{l}-1)=\frac{1}{2+s}, and if $H_l\in\{0,N\}$, $H_{l+1}=H_l$. We denote by $S_k$ the hitting time of $k\in\{0,1,...,N\}$ by the random walk $H$.",2502.01178
proposition,"Let $a\in(0,1)$. If $Y_0=\lfloor aN\rfloor$, then   \item[$(i)$] The fixation probability of advantaged individuals satisfies \mathbb{P}(T_N<T_0)\underset{N\rightarrow\infty}{\longrightarrow} 1.   \item[$(ii)$] Let $b\in [a,1)$. There exists $C>0$ (depending on $b$) such that $\mathbb{P}(T_{\lfloor bN\rfloor}> N C)\rightarrow 0$ when $N$ goes to infinity. \\ %\item[$(iii)$] For any $b\in[a,1)$, let $T_{bN}=\inf\{n:Y_n\geq bN\}$.  %\textcolor{red}{Contrle sur $\mathbb{E}(T_N-T_{bN})$ quand $b$ tend vers $1$ et $N$ tend vers l'infini ? Voir tome 1 de Feller} %\item[$(iv)$] \textcolor{red}{Introduire la marche changee de temps pour avoir une information sur le temps qu'il faut pour aller de $\alpha N$ a $\beta N$}",2502.01178
proposition,"The sequence $(Z_n)_{n\in\mathbb{Z}_+}=\left(\frac{Y_n}{N},\frac{U_n}{N},\frac{V_n}{N}\right)_{n\in\mathbb{Z}_+}$ (which is not Markovian) is such that  Z_{n+1}=Z_n+\frac{1}{N}&\left[\left(1,\sum_{l'\in\mathcal{Y}_0}\frac{W_n(\mu_n,l')+W_n(\pi_n,l')}{2},\sum_{l'\in\mathcal{Y}_0}-W_n(\kappa_n,l')\right)\mathbf{1}_{\mu_n\in\mathcal{Y}_n,\kappa_n\notin\mathcal{Y}_n}\right.\\&+\left(-1,-\sum_{l'\in\mathcal{Y}_0}W_n(\kappa_n,l'),\sum_{l'\in\mathcal{Y}_0}\frac{W_n(\mu_n,l')+W_n(\pi_n,l')}{2}\right)\mathbf{1}_{\mu_n\notin\mathcal{Y}_n,\kappa_n\in\mathcal{Y}_n}\\&+\left(0,\sum_{l'\in\mathcal{Y}_0}\frac{W_n(\mu_n,l')+W_n(\pi_n,l')}{2}-\sum_{l'\in\mathcal{Y}_0}W_n(\kappa_n,l'),0\right)\mathbf{1}_{\mu_n\in\mathcal{Y}_n,\kappa_n\in\mathcal{Y}_n}\\&+\left.\left(0,0,\sum_{l'\in\mathcal{Y}_0}\frac{W_n(\mu_n,l')+W_n(\pi_n,l')}{2}-\sum_{l'\in\mathcal{Y}_0}W_n(\kappa_n,l')\right)\mathbf{1}_{\mu_n\notin\mathcal{Y}_n,\kappa_n\notin\mathcal{Y}_n}\right].  In particular $\|Z_{n+1}-Z_n\|\leq \sqrt{3}/N$ for all $n\geq0$, and  \mathbb{E}\left(Z_{n+1}-Z_n|\mathcal{F}^Z_n\right)=\frac{1}{N}\Big(&\frac{sY_n/N(1-Y_n/N)}{Y_n/N+(1+s)(1-Y_n/N)},\\&\frac{U_n}{2N}+\frac{U_n+V_n}{2N}\frac{Y_n}{N}-\frac{U_n/N}{Y_n/N+(1+s)(1-Y_n/N)},\\&\frac{V_n}{2N}+\frac{U_n+V_n}{2N}\left(1-\frac{Y_n}{N}\right)-\frac{(1+s)V_n/N}{Y_n/N+(1+s)(1-Y_n/N)}\Big).",2502.01178
proposition,"Let $f\in\mathcal{C}^2_b([0,1]^3)$. %f(Z_{n+1})=f(Z_n)&+\frac{1}{N}\frac{\partial f}{\partial U}(Z_n)\left[\sum_{l'\in\mathcal{Y}_0}\frac{W_n(\mu_n,l')+W_n(\pi_n,l')}{2}\mathbf{1}_{\mu_n\in\mathcal{Y}_n}-W_n(\kappa_n,l')\mathbf{1}_{\kappa_n\in\mathcal{Y}_n}\right]\\& %+\frac{1}{N}\frac{\partial f}{\partial V}(Z_n)\left[\sum_{l'\in\mathcal{Y}_0}\frac{W_n(\mu_n,l')+W_n(\pi_n,l')}{2}\mathbf{1}_{\mu_n\notin\mathcal{Y}_n}-W_n(\kappa_n,l')\mathbf{1}_{\kappa_n\notin\mathcal{Y}_n}\right]\\& %+\frac{1}{N}\frac{\partial f}{\partial Y}(Z_n)\left[\mathbf{1}_{\mu_n\in\mathcal{Y}_n,\kappa_n\notin\mathcal{Y}_n}-\mathbf{1}_{\mu_n\notin\mathcal{Y}_n,\kappa_n\in\mathcal{Y}_n}\right]\\& %+\frac{1}{N^2}R^f, where $R^f=3\sup_z\|Hess(f)(z)\|$. %",2502.01178
proposition,"The differential equation  y'=\frac{sy(1-y)}{y+(1+s)(1-y)}\\u'=\left[\frac{u}{2}+\frac{u+v}{2}y-\frac{u}{y+(1+s)(1-y)}\right]\\ v'=\left[\frac{v}{2}+\frac{u+v}{2}(1-y)-\frac{(1+s)v}{y+(1+s)(1-y)}\right] admits a unique solution $z_t:=(y_t,u_t,v_t)_{t\geq0}$ starting from $(a,a,0)$ with $a\in(0,1)$. This solution satisfies : \left\{       y_t&= F^{-1}\left(\frac{a^{1+s}}{1-a}\exp(st)\right) \qquad\text{where $F:x\rightarrow\frac{x^{1+s}}{1-x}$ maps $[0,1)$ onto $[0,\infty)$}\\       u_t&= y_t\frac{a^{\frac{1+s}{2s}}}{(1-a)^{\frac{1}{2s}}}\left[\frac{(1-y_t)^{\frac{1}{2s}}}{y_t^{\frac{1+s}{2s}}}+\int_a^{y_t}\frac{(1-x)^{\frac{1}{2s}}}{x^{\frac{1+s}{2s}}}\left[\frac{1}{2}+\frac{1}{2s}\frac{1}{1-x}\right]dx\right] \\       v_t&= (1-y_t)\frac{a^{\frac{1+s}{2s}}}{(1-a)^{\frac{1}{2s}}}\int_a^{y_t}\frac{(1-x)^{\frac{1}{2s}}}{x^{\frac{1+s}{2s}}}\left[\frac{1}{2}+\frac{1}{2s}\frac{1}{1-x}\right]dx. \\     \right.",2502.01178
proposition,"Recall from Proposition \ref{prop:Y} that if $Y_0/N$ converges to $a\in(0,1]$ when $N$ goes to infinity, $\mathbb{P}(T_N<\infty)\longrightarrow 1$ when $N$ goes to infinity. Now $$\mathbb{E}(\|Z_{T_N}\mathbf{1}_{T_N<\infty}-z_{\infty}\|)\longrightarrow 0.$$ %",2502.01178
proposition,"For any $0<a<b<1$,  $$\mathbb{E}(D_{T^Z_{\lfloor bN\rfloor}}\mathbf{1}_{T^Z_{\lfloor bN\rfloor}<\infty}| Z_0=\lfloor aN\rfloor)\rightarrow_{N\rightarrow\infty}\frac{\left(\frac{a}{b}\right)^{\frac{1+s}{2s}}}{\left(\frac{1-a}{1-b}\right)^{\frac{1}{2s}}}$$ when $N$ goes to infinity.",2502.01178
proposition,"For any $0<a<b<1$, \mathbb{E}(\widetilde{U}_{T_{0,b N}}\mathbf{1}_{T^Z_{\lfloor bN\rfloor}<\infty}|Z_0=\lfloor aN\rfloor)&\rightarrow_{N\rightarrow\infty} \frac{\left(\frac{a}{b}\right)^{\frac{1+s}{2s}}}{\left(\frac{1-a}{1-b}\right)^{\frac{1}{2s}}}+\left(\int_{a}^{b}\frac{(1-u)^{\frac{1}{2s}}}{u^{\frac{1+s}{2s}}}\left[\frac{1}{2}+\frac{1}{2s}\frac{1}{1-u}\right]du\right)\times \frac{a^{\frac{1+s}{2s}}}{(1-a)^{\frac{1}{2s}}}  \mathbb{E}(\widetilde{V}_{T_{0,b N}}\mathbf{1}_{T^Z_{\lfloor bN\rfloor}<\infty}|Z_0=\lfloor aN\rfloor)\rightarrow_{N\rightarrow\infty}\left(\int_{a}^{b}\frac{(1-u)^{\frac{1}{2s}}}{u^{\frac{1+s}{2s}}}\left[\frac{1}{2}+\frac{1}{2s}\frac{1}{1-u}\right]du\right)\times \frac{a^{\frac{1+s}{2s}}}{(1-a)^{\frac{1}{2s}}}",2502.01178
proposition,"Let $c>0$. There exists a constant $C$ such that for any $n\leq cN$, the difference $R_n=Z_n-\phi_{\frac{1}{N}}^n(a,0,a)$ satisfies     $$\mathbb{E}(R_n^2)\leq \frac{C}{N}.$$",2502.01178
proposition,"$$f(Z_{n})=f(Z_0)+M^f_n+\sum_{k=0}^{n-1}L^{f,N}(Z_k)+\frac{1}{N^2}\tilde{R}^f(Z_n)$$  where $(M^f_n)_{n\geq0}$ is a martingale such that $$\mathbb{E}((M^f_n)^2)\leq \frac{Cn}{N^2},$$ $\tilde{R}^f$ is a bounded function on $[0,1]^3$, and  L^{f,N}(U,V,Y)&=\frac{1}{N}\frac{\partial f}{\partial U}(U,V,Y)\times \left[\frac{U}{2}+\frac{Y(U+V)}{2}-\frac{U}{Y+(1+s)(1-Y)}\right]\\&+\frac{1}{N}\frac{\partial f}{\partial V}(U,V,Y)\times\left[\frac{V}{2}+\frac{(1-Y)(U+V)}{2}-\frac{(1+s)V}{Y+(1+s)(1-Y)}\right] \\&+\frac{1}{N}\frac{\partial f}{\partial Y}(U,V,Y)\times\left[\frac{sY(1-Y)}{Y+(1+s)(1-Y)}\right].",2502.01178
lemma,"The sequence $(W_n,\mathcal{Y}_n)_{n\in\mathbb{Z}_+}$ is a Markov chain, with transition \mathcal{Y}_{n+1}&=   \mathcal{Y}_n\cup\{\kappa_n\} \qquad \text{ if $\mu_n\in\mathcal{Y}_n$ and  $\kappa_n\notin\mathcal{Y}_n$ } \\   \mathcal{Y}_n\setminus\{\kappa_n\}\qquad \text{if $\mu_n\notin\mathcal{Y}_n$ and $\kappa_n\in\mathcal{Y}_n$}\\   \mathcal{Y}_n \qquad \text{if $\mu_n,\kappa_n\notin\mathcal{Y}_n$ or $\mu_n,\kappa_n\in\mathcal{Y}_n$, \quad and} \\ W_{n+1}(i,j)&=W_n(i,j) \quad\text{if $i\neq \kappa_n$}\\     \frac{W_n(\mu_n,j)+W_n(\pi_n,j)}{2} \quad\text{if $i=\kappa_n$,} where $\mu_n$ and $\pi_n$ are drawn uniformly in $1,...,N$, and $\kappa_n$ is such that $\mathbb{P}(\kappa_n=i)=\frac{1+s\mathbf{1}_{i\notin\mathcal{Y}_n}}{Y_n+(1+s)(N-Y_n)}$ for all $i\in\{1,..,N\}$.",2502.01178
example,"Consider the MILP's constraint $Ax \le b, x \ge 0$ as follows: 		 			 			 				1/3x_1 +  x_2 - 2/3x_3\le& 1,  \\ 				2/3x_1 - 1/3 x_2 - 4/3 x_3 + x_4\le& 1,  \\ 				-1/3 x_2 + x_3\le& 1,  			 		 		where all rows are useful,  and $x_2$ and $x_3$ are bad variables. A vector $\lambda = (1,1,2)$ exists such that the corresponding aggregated inequality $x_1  + x_4\le 4$ eliminates all bad variables. However, the MW heuristic cannot find a projected inequality starting from any row. For example, starting from the first row \eqref{eq.example1},  assume that the MW heuristic chooses the second row \eqref{eq.example2} to eliminate $x_2$. In this case, the heuristic greedily select the factor $3$ for \eqref{eq.example2} and does not select any factor for \eqref{eq.example3}, then  we obtain the aggregated inequality $7/3x_1 -14/3 x_3 + 3x_4 \le 4$ using $\lambda=(1,3,0)$.",2502.01192
example,"We revise \Cref{example.1} and apply the LP-based aggregation algorithm instead of the MW heuristic. Assume that the value of the point $(x_1,x_2,x_3)$ in \eqref{eq.example} is zero, and the slacks of all constraints in \eqref{eq.example}  are zero. Recall that $x_2$ and $x_3$ are bad variables. We can express the corresponding lasso approximation as: 		 			\min_{\lambda \in \bR^3_+, \lambda_{i_0} \ge 1} w_2|\lambda_1 - 1/3 \lambda_2  - 1/3 \lambda_3 | + w_3 |-2/3\lambda_1 - 4/3 \lambda_2  + \lambda_3 |, 		 		where $w_2$ and $w_3$ are non-negative weights (set to be equal to bound distances), and $i_0 \in \{1,2,3\}$. Note that the term $\sum_{i \in I}\lambda^\top_i (b_i - A_{i,J}^\top \relx{x}_J)$  is null due to the slacks being zero. The solution $(1,1,2)$ is optimal with objective value zero regardless of values of $w_2,w_3$, and this solution eliminates all bad variables. Thus, the LP approach finds a suitable aggregation, and it is stable under the perturbation of weights.",2502.01192
proof,"We lift $ I \subset k[[\x]][z,u_{1},\ldots,u_{g-1}] $ to 	\[ 		\cI := I \cdot \cO[[\x]][z,\u_{1},\ldots,u_{g-1}]. 	\] 	Let $ \cX $ be the scheme defined by $ \cI $, 	\[ 		\cX := \Spec (R), 		\ \ \  		\mbox{ where }  		R := \cO[[\x]][z,\u_{1},\ldots,u_{g-1}]/ \cI, 	\]  	and let $ \psi \colon \cX \to \cT $ be the natural projection. 	Since $ p $ is not a zero divisor in $ R $, 	%(this follows fro mthe shape of $ I $)  	the morphism $ \psi $ is flat.  	%%  	% Since $ \cO_\kk $ is a DVR, it is a Dedekind ring and hence any torsion-free module is flat. 	% 	% 	% 	By construction, we have $ \cX_0=\psi^{-1}(0) \cong X $  	and moreover, by \cite{MS}, the generic fiber $ \cX_\eta:=\psi^{-1}(\eta) $ is isomorphic to a quasi-ordinary hypersurface singularity.",2502.01239
proof,The monotonicity in $y$ follows from \Cref{lemma:monotonic} and the fact that $f$ is non-decreasing in $y$. The monotonicity in $C$ is obvious.\qed,2502.01244
proof,"For $y_1,y_2\in [0,1]$, we let $\rho_{y_1,y_2}$ denote the uniform distribution on $[y_1,y_2]$ (a Dirac mass if $y_1=y_2$). In what follows we adopt the convention $1/0=+\infty$ and $\log0=-\infty$.          Fix $y_0\in\Y$ and $y_+\in[y_0,1]$. There exists $\hat y\in[y_0,y_+]$ such that $\psi_T(\hat y, F(\hat y))\leq\int_{0}^{1}\psi_T(y, F(y))\dd\rho_{y_0,y_+}(y)$. When using the KT forecaster, since $\KL(\rho_{y_0,y_+}|\rho_{0,1}) = -\log(y_+-y_0)$, from \eqref{eq:psinv} and \eqref{eq:bound} we obtain     $$F(\hat y) \leq \psi_{T,+}^{-1}\left(\hat y, \log\tfrac{2\sqrt T}{y_+-y_0} + \textstyle\int_0^1M_T(y)\dd y\right)\,.$$     From the monotonicity of $F$ and \Cref{lemma:monul}, it follows that     $$F(y_0) \leq \psi_{T,+}^{-1}\left(y_+, \log\tfrac{2\sqrt T}{y_+-y_0} + \textstyle\int_0^1M_T(y)\dd y\right)\,.$$     Similar arguments yield that, for any $y_-\in[0,y_0]$, we have     $$F(y_0) \geq \psi_{T,-}^{-1}\left(y_-, \log\tfrac{2\sqrt T}{y_0-y_-} + \textstyle\int_0^1M_T(y)\dd y\right)\,.$$     Thus, for all $y_0\in\Y$,     $$\sup_{y_-\in[0,y_0]}\psi_{T,-}^{-1}\left(y_-, \log\tfrac{2\sqrt T}{y_0-y_-} + \textstyle\int_0^1M_T(y)\dd y\right)\leq F(y_0)\leq \inf_{y_+\in[y_0,1]}\psi_{T,+}^{-1}\left(y_+, \log\tfrac{2\sqrt T}{y_+-y_0} + \textstyle\int_0^1M_T(y)\dd y\right)\,.$$     From \Cref{lemma:monul}, the above upper and lower bounds are respectively non-decreasing and non-increasing in $\int_0^1M_T(y)\dd y$. The conclusion follows from Ville's inequality as $\int_0^1M_T(y)\dd y$ is a non-negative martingale.\qed",2502.01244
proof,"We prove the first statement, the second follows similarly. Let $\mu\geq\mu_z$. From Jensen's inequality, $\frac1T\sum_{t=1}^{T}\log\big(1+\alpha(z_t-\mu)\big)\leq \log\left(1+\alpha (\mu_z-\mu)\right)\leq\log 1 = 0$,     for any $\alpha>0$. In particular, we obtain that     $\Psi(z,\mu) = \sup_{\alpha\in[-\frac{1}{1-\mu},0]}\frac1T\sum_{t=1}^{T}\log\big(1+\alpha(z_t-\mu)\big)$. If $\alpha\in[-\frac{1}{1-\mu},0]$, $\log\big(1+\alpha(z_t-\mu)\big)\leq\log\big(1+\alpha(z'_t-\mu)\big)$, since $z\succeq z'$. Therefore,     $$\Psi(z,\mu) = \sup_{\alpha\in[-\frac{1}{1-\mu},0]}\frac1T\sum_{t=1}^{T}\log\big(1+\alpha(z_t-\mu)\big)\leq \sup_{\alpha\in[-\frac{1}{1-\mu},0]}\frac1T\sum_{t=1}^{T}\log\big(1+\alpha(z'_t-\mu)\big)\leq\Psi(z',\mu)\,,$$ and so we conclude.\qed",2502.01244
proof,"We prove that $\Psi^{-1}_+(\cdot,C)$ is non-decreasing, as the proof for $\Psi^{-1}_-(\cdot,C)$ is analogous. Fix $z$ and $z'$, with $z\succeq z'$. For any $\mu\geq\mu_z$ we have that $\Psi(z,\mu)\leq\Psi(z',\mu)$ by \Cref{lemma:Psi}. Thus, $$\big\{\mu\geq\mu_z\,:\,\Psi(z,\mu)\leq C\big\} \supseteq \big\{\mu\geq\mu_z\,:\,\Psi(z',\mu)\leq C\big\}\,.$$ As $\{\mu\geq\mu_z\,:\,\Psi(z,\mu)\leq C\}$ is non-empty ($\mu_z$ belongs to it), the conclusion follows.\qed",2502.01244
proposition,"Let $\Y=[0,1]$. With probability at least $1-\delta$, uniformly on $T\geq1$ and on $y_0\in\Y$, we have      $$F(y_0)\in\left[\sup_{y_-\in[0,y_0]}\psi_{T,-}^{-1}\Big(y_-, \log\tfrac{2\sqrt T}{(y_0-y_-)\delta}\Big),\inf_{y_+\in[y_0,1]}\psi_{T,+}^{-1}\Big(y_+,\log\tfrac{2\sqrt T}{(y_+-y_0)\delta}\Big)\right]\,.$$",2502.01244
lemma,"For any fixed $C\geq 0$ and any $T$, both $y\mapsto\psi_{T,+}^{-1}(y,C)$ and $y\mapsto\psi_{T,-}^{-1}(y,C)$ are non-decreasing. For any fixed $y\in\Y$ and any $T$, $C\mapsto\psi_{T,+}^{-1}(y,C)$ is non-decreasing and $C\mapsto\psi_{T,-}^{-1}(y,C)$ is non-increasing.",2502.01244
lemma,"Fix $z$ and $z'$, such that $z\succeq z'$.  Let $\mu\in [0,1]$. If $\mu\geq\mu_z$, then     $\Psi(z,\mu)\leq\Psi(z',\mu)$.     Conversely, if $\mu\leq\mu_{z'}$, we have $\Psi(z,\mu)\geq\Psi(z',\mu)$.",2502.01244
lemma,"For any fixed $C\geq 0$, the mappings $z\mapsto\Psi^{-1}_+(z,C)$ and $z\mapsto\Psi^{-1}_-(z,C)$ are non-decreasing (with respect to the partial ordering $\succeq$).",2502.01244
theorem,"Scalable variance-preserving coefficient initialization of Hermite activation. Let $p > 1$, and       \forall k \in \llbracket 1,n \rrbracket \ a_k = \frac{1}{k^p} \ \text{and}\ a_0 = \sqrt{\zeta(2p-1) - \zeta(2p)}   with $\zeta$ the Riemann function $\forall x \in [1,+\infty] \colon \zeta(x) = {\sum_{k=1}^{\infty} \frac{1}{k^x}}$. Then in the limit case $n \to +\infty$, the gain for the activation and its derivative becomes the same and equals:      \alpha = \alpha' = \frac{1}{\zeta(2p-1)}       In the limit case, by a simple injection of $a_k = \frac{1}{k^p}$ in Prop.~\ref{prop:hermite_equality} and then in Prop.~\ref{prop:hermite_backward_gain}, we obtain the result.",2502.01247
theorem,"(\citet{arnold2009representation, arnold2009functions}) Let $f: \mathbb{I}^n:=[0,1]^n \rightarrow \mathbb{R}$ be an arbitrary multivariate continuous function. Then it can be represented as follows:       f\left(x_1, \ldots, x_n\right)=\sum_{q=0}^{2 n} \Phi_q\left(\sum_{p=1}^n \psi_{qp}\left(x_p\right)\right)  with continuous one-dimensional functions $\Phi_q \colon \mathbb {R} \to \mathbb {R}$ and $\psi_{q, p} \colon [0,1] \to \mathbb {R}$. $\Phi_q$ are called outer funcions and $\psi_{q, p}$ are called inner functions. The inner functions $\psi_{q, p}$ are independent of the function $f$.",2502.01247
definition,"Let  \( x \) be the input vector of the MLP, $W$ the learnable weight tensor of inner dimension $C_{in} \in \mathbb{N}^*$, and $F$ an activation function, and $\cdot$ the usual inner product in $\mathbb{R}^{C_{in}}$, an MLP block is defined by % % %    \texttt{MLP}(x) = W \cdot F(x) % %",2502.01247
definition,The forward gain of the MLP layer is:      \alpha =  \frac{\operatorname{Var}[x]}{\mathbb{E}\left[F(x)^2\right]},2502.01247
definition,The backward gain is the gain  of the derivative of the activation with respect to $x$ and is defined as:      \alpha' =  \frac{\operatorname{Var}[x]}{\mathbb{E}\left[F'(x)^2\right]},2502.01247
definition,"$\forall n \in \mathbb{N}$, the probabilist Hermite polynomials can be defined as follows:        \operatorname{He}_n(x)=(-1)^n e^{\frac{x^2}{2}} \frac{d^n}{d x^n} e^{-\frac{x^2}{2}}",2502.01247
definition,"We define the Hermite activation $F \colon \mathbb{R}\to\mathbb{R}$ with its learnable coefficients $\forall k \in \llbracket 0, n \rrbracket$ $a_k \in \mathbb{R}$ as:        x \mapsto F(x)=\sum^{n}_{k=0} \frac{a_k}{\sqrt{k!}}\operatorname{He}_k(x)",2502.01247
definition,We consider the following Fourier activation $F \colon  \mathbb{R} \to \mathbb{R}$:       F(x) \mapsto a_0 +     \sum_{k=1}^{n} \left(a_k \cos(k x) + b_k \sin(k x)\right)  where \( (a_k)_{k \in \mathbb{N}} \) and \( (b_k)_{k \in \mathbb{N}^*} \) are real learnable coefficients.,2502.01247
definition,"The max-tropical semiring  $\mathbb{T}$ is the semiring  $\mathbb{T}=(\mathbb{R} \cup\{+\infty\}, \oplus, \otimes)$, with the operations, $\forall x,y \in {\mathbb{R}\cup\{+\infty\}}^2$:   x \oplus y:=\max \{x, y\} \quad\text{and}\quad x \otimes y:=x+y  Equivalently, we could define the min-tropical semiring by substituting the max operation in $\oplus$ with a $\min$ operation. By extension, we define for all $a \in \mathbb{N}$ the tropical power of $x$ raised to $a$ as multiplying $x$ to itself $a$ times:  x^{\otimes a}:=x \otimes \cdots \otimes x=a \cdot x",2502.01247
definition,"The \emph{tropical polynomial activation} $F$ is defined as the \emph{tropicalization} of a polynomial of degree $n \in \mathbb{N}$ with $\forall k \in \llbracket 0, n \rrbracket$ $a_k \in \mathbb{R}$ the learnable coefficients:          F \colon & \mathbb{R} \to \mathbb{R}  \nonumber \\     F(x)  &\mapsto  \bigoplus_{k=0}^n a_k \otimes x^{\otimes k} := \max_{k=0}^{n} \left\{ a_k + kx \right\}  With $\max\limits_{k=0}^{n} \left\{ a_k + kx \right\}:= \max ( a_0, a_1 + x, \cdots,$ $ a_n + nx )$.",2502.01247
definition,"Let $n, m \in \mathbb{N}$. A function $F: \mathbb{R}^n \to \mathbb{R}^m$ is called a \emph{polynomial mapping} if each component function $F_i: \mathbb{R}^n \to \mathbb{R}$, for $i = 1, \dots, m$, is a polynomial in $n$ variables. Explicitly, this means that for each $i$, $F_i$ has the form:     \[         F_i(x_1, \dots, x_n) = \sum_{|\alpha| \leq d_i} c_{i, \alpha} x_1^{\alpha_1} x_2^{\alpha_2} \cdots x_n^{\alpha_n},     \]     where the sum is taken over all multi-indices $\alpha = (\alpha_1, \dots, \alpha_n) \in \mathbb{N}^n$ such that $|\alpha| = \alpha_1 + \alpha_2 + \dots + \alpha_n \leq d_i$, $c_{i, \alpha} \in \mathbb{R}$ are real coefficients, and $d_i \in \mathbb{N}^n$.",2502.01247
definition,"A \emph{deep neural network} with $L$ layers, input dimension $n$, and output dimension $m$ is a function $F: \mathbb{R}^n \to \mathbb{R}^m$ of the form:     \[         F(x) = W_L \sigma ( W_{L-1} \sigma ( \cdots \sigma(W_1 x + b_1) \cdots ) + b_{L-1}) + b_L,     \]     where $\forall i \in \llbracket 1, L \rrbracket$ $C_i \in \mathbb{N}^*$. Each $W_i \in \mathbb{R}^{C_i \times C_{i-1}}$ is a weight matrix, $b_i \in \mathbb{R}^{C_i}$ is a bias vector, and $\sigma$ is an activation function applied element-wise.",2502.01247
definition,The tropical quotient $\oslash$ of $x$ over $y$ is defined as:      x \oslash y:=x-y,2502.01247
definition,"The \emph{tropical rational activation} $F$ is defined as the \emph{quotient} of two tropical polynomials $F_1$ and $F_2$ of degree $m,n \in \mathbb{N}^2$ respectively.          F \colon & \mathbb{R} \to \mathbb{R}  \nonumber \\     F(x)  &\mapsto  F_1(x) \oslash F_2(x) :=  F_1(x) - F_2(x)",2502.01247
proof,The proof relies on the orthonormality property \ref{property:orthonormal} and is detailed in Appendix \ref{appendix:hermite}.,2502.01247
proof,"an orthonormality argument as for the proof in Appendix \ref{appendix:hermite} suffices, we conclude by noticing that:       \mathbb{E}\left[F^\prime(x)^2\right]=\sum^{n}_{k=1} k^2a_k^2\int_{-\infty}^{+\infty}\frac{\operatorname{He}_{k-1}(x)^2}{k(k-1)!}\frac{e^{-\frac{x^2}{2}}}{\sqrt{2\pi}} d x",2502.01247
proof,"In the limit case, by a simple injection of $a_k = \frac{1}{k^p}$ in Prop.~\ref{prop:hermite_equality} and then in Prop.~\ref{prop:hermite_backward_gain}, we obtain the result.",2502.01247
proof,The proof relies on the orthonormality property \ref{property:fourier_ortho} and is detailed in Appendix \ref{appendix:fourier}.,2502.01247
proof,an orthonormality argument as for the proof in Appendix \ref{appendix:fourier} suffices.,2502.01247
proof,The proof proceeds by induction on the number of layers $L$ and is detailed in appendix~\ref{appendix:mapping}.,2502.01247
proposition,The second moment of this activation is:   \mathbb{E}\left[F(x)^2\right]=&\sum^{n}_{k=0} a_k^2       The proof relies on the orthonormality property \ref{property:orthonormal} and is detailed in Appendix \ref{appendix:hermite}.,2502.01247
proposition,"Using the last property and by the linearity of the integral, the derivative of $F$ (Eq.~\ref{eq:hermite}), $F^\prime \colon  \mathbb{R} \to \mathbb{R} $ is written as follows:       x \mapsto F^\prime(x)=\sum^{n}_{k=1} \frac{ka_k} {\sqrt{k!}}\operatorname{He}_{k-1}(x)",2502.01247
proposition,"The second moment of the derivative of the Hermite activation is:       \mathbb{E}\left[F^\prime(x)^2\right]=\sum^{n}_{k=1}ka_k^2       an orthonormality argument as for the proof in Appendix \ref{appendix:hermite} suffices, we conclude by noticing that:       \mathbb{E}\left[F^\prime(x)^2\right]=\sum^{n}_{k=1} k^2a_k^2\int_{-\infty}^{+\infty}\frac{\operatorname{He}_{k-1}(x)^2}{k(k-1)!}\frac{e^{-\frac{x^2}{2}}}{\sqrt{2\pi}} d x",2502.01247
proposition,Equality between propositions~\ref{prop:hermite_forward_gain} and \ref{prop:hermite_backward_gain} imposes that:      a_0^2 = \sum^{n}_{k=1} (k-1)a_k^2,2502.01247
proposition,The second moment of this activation is:   \mathbb{E}[F(x)^2] = a_0^2 +  \frac{1}{2}\sum_{k=1}^{n} \left( a_k^2 + b_k^2 \right)       The proof relies on the orthonormality property \ref{property:fourier_ortho} and is detailed in Appendix \ref{appendix:fourier}.,2502.01247
proposition,The derivative of the Fourier activation \( F^\prime \colon  \mathbb{R} \to \mathbb{R} \) from its definition in Eq.~\ref{eq:fourier_final} is given by:      F^\prime(x) \mapsto \sum_{k=1}^{n} k\frac{\pi}{\sqrt{3}}\left(-a_k \sin(k\frac{\pi}{\sqrt{3}} x) + b_k \cos(k\frac{\pi}{\sqrt{3}} x)\right),2502.01247
proposition,The second moment of the derivative of the Fourier activation is:       \mathbb{E}\left[F^\prime(x)^2\right]=\sum^{n}_{k=1}\frac{\pi^2}{6}k^2(a_k^2 + b_k^2)       an orthonormality argument as for the proof in Appendix \ref{appendix:fourier} suffices.,2502.01247
proposition,Equality between \ref{prop:fourier_forward_gain} and \ref{prop:fourier_backward_gain} imposes that:      a_0^2 = \frac{1}{2}\sum^{n}_{k=1} \left(\frac{\pi^2}{3}k^2-1\right)(a_k^2 + b_k^2),2502.01247
proposition,Let $F: \mathbb{R}^n \to \mathbb{R}^m$ be a deep neural network with polynomial activation functions of degree $d$. Then $F$ is a polynomial mapping of degree at most $d^L$.,2502.01247
example,"If we take $p=\frac{3}{2}$, by the corollary \ref{coro:hermite} we have:       \forall k \in \llbracket 1,n \rrbracket \ a_k = \sqrt{\frac{6}{\pi^2 k^{3}}} \ \text{and}\ a_0 = \sqrt{1 - \frac{6\zeta(3)}{\pi^2}} \approx 0.519  In practice, we will use $p=\frac{3}{2}$ in all our subsequent experiments where Hermite activations are involved.",2502.01247
theorem,"For a continuous non-negative random variable X distributed as (1.8), with real $m,k$,  $m\ge-1$, $k\ge1$",2502.01255
theorem,"For integers $r\ge1$, $p\ge1$ and under the assumption of Theorem \ref{theo1}, the given recurrence relation is satisfied.  		  			M_{r,n,m,k}^{p}(t)=\dfrac{{\gamma_{r}}}{(p+1)}\left[M_{r,n,m,k}^{p+1}(t)-M_{r-1,n,m,k}^{p+1}(t)\right]-\left(\dfrac{2}{2-\theta}\right)\dfrac{\gamma_{r}^{n+1,k-m}}{(p+1)}\nonumber \\ \,\,\,\,\,\, \times \left[M_{r,n+1,m,k-m}^{p+1}(t)-M_{r-1,n+1,m,k-m}^{p+1}(t)\right]- \dfrac{t}{(p+1)}M_{r,n,m,k}^{p+1}(t),\,\,\,\,\,\,\, m\ne-1\",2502.01255
theorem,"For $1\leq r<s\leq n$, $n \in{N}$, $m \in {R}$, and a fixed positive integer $k\ge 1$",2502.01255
theorem,"For the distribution given in (1.8) and under the assumptions of Theorem \ref{mgf.theo}, the following recurrence relation is satisfied  		  			M_{r,s,n,m,k}^{p,q}(t_{1},t_{2})=\dfrac{\gamma_{s}}{(q+1)}\left[M_{r,s,n,m,k}^{p,q+1}(t_{1},t_{2})-M_{r,s-1,n,m,k}^{p,q+1}(t_{1},t_{2})\right]-\left(\dfrac{2-\theta}{2}\right)\dfrac{\gamma_{s}^{k-m,n+1}C^{*}}{(q+1)}\nonumber \\ \,\,\,\,\,\,  			\times\left[M_{r,s,n+1,m,k-m}^{p,q+1}(t_{1},t_{2})-M_{r,s-1,n+1,m,k-m}^{p,q+1}(t_{1},t_{2})\right]- \dfrac{t_{2}}{(q+1)}M_{r,n,m,k}^{p,q+1}(t_{1},t_{2}),\,\, m\ne-1\,\,\",2502.01255
proof,"By using \eqref{gos.cdf} the \textit{mgf} of \textit{gos} can be seen as  		   			M_{(r,n,m,k)}(t)=\frac{c_{r-1}}{(r-1)!}\int_{0}^\infty e^{tx}\left[\bar{F}\left(x\right)\right]^{\gamma _{r} -1} g_{m}^{r-1} \left(F\left(x\right)\right)f\left(x\right)dx.  		  		Expanding $g_{m}^{r-1}[F(x)]$ binomially in (2.3), we get  		   			M_{r:n,m,k} =\frac{C_{r-1} }{\left(r-1\right)!(m+1)^{r-1} }  \sum_{u=0}^{r-1}\binom{r-1}{u}(-1)^{u} \int _{0}^{\infty }e^{tx} \left[\bar{F}\left(x\right)\right]^{\gamma _{r-u} -1} f\left(x\right)dx  .    		  		Making appropriate substitution by considering \eqref{cdf.hlg} and \eqref{pdf.hlg}, and after simplification, we get \eqref{mgf.gos}. To show the existence of $\mu_{(r,n,m,k)}=E\left(X_{r,n,n,k}\right)$, we proceed as  		  			\mu_{(r,n,m,k)}=\frac{d}{dt}M_{(r,n,m,k)}(t)\Bigg|_{t=0}\nonumber  		  		  			\mu_{(r,n,m,k)}=\dfrac{C_{r-1}}{(r-1)!(m+1)^{r-1}}\sum_{u=0}^{r-1}(-1)^{u}\binom{r-1}{u}\left(\dfrac{2}{2-\theta}\right) \left[ln\left(\dfrac{\theta}{2-\theta}\right)-\mathcal{A}^{'}\right],  		   		where,  		  			\mathcal{A}^{'}={\frac{d}{dt}}B\left[1-\frac{1}{\theta},\gamma_{r-u}-t,1+t\right]\Bigg|_{t=0}\nonumber  		  		Similarly, the second moment of \textit{gos} from HLG distribution can be obtained as  		  			\mu_{(r,n,m,k)}^{2}=\frac{d^{2}}{dt^{2}}M_{(r,n,m,k)}(t)\Bigg|_{t=0}\nonumber  		  		  			\mu_{(r,n,m,k)}^{2}=\dfrac{C_{r-1}}{(r-1)!(m+1)^{r-1}}\sum_{u=0}^{r-1}(-1)^{u}\binom{r-1}{u}\left(\dfrac{2}{2-\theta}\right)\nonumber\\  			\times\left[ln\left(\dfrac{\theta}{2-\theta}\right)^{2}B\left(1-\frac{1}{\theta},\gamma_{r-u}-t,1+t\right)-2ln\left(\dfrac{\theta}{2-\theta}\right)\mathcal{A}^{'}-\mathcal{A}^{''}\right],  		  		where,   		  			\mathcal{A}^{''}={\frac{d^{2}}{dt^{2}}}B\left[1-\frac{1}{\theta},\gamma_{r-u}-t,1+t\right]\Bigg|_{t=0}\nonumber  		  		Proceeding in similar way, \eqref{mgf.gos} can produce $p$-th moment of HLG distribution based on \textit{gos}.",2502.01255
proof,"In view of \eqref{gos.cdf}, we have   		  			M_{r,n,m,k}(t)=\dfrac{c_{r-1}}{(r-1)!}\int_{0}^\infty{e^{tx}}\left[\bar{F}\left(x\right)\right]^{\gamma _{r} -1}g_{m}^{r-1}\left(F(x)\right) f\left(x\right)dx.  		  		Making use of \eqref{rel.pc} in \eqref{2.7}, we have  		  			M_{r,n,m,k}(t)&=\dfrac{c_{r-1}}{(r-1)!}\int_{0}^\infty{e^{tx}}\left[\bar{F}\left(x\right)\right]^{\gamma _{r}}g_{m}^{r-1}\left(F(x)\right)dx  			-{\left(\dfrac{2-\theta}{2}\right)}\dfrac{c_{r-1}}{(r-1)!}\nonumber\\  			&\times\int_{0}^\infty{e^{tx}}\left[\bar{F}\left(x\right)\right]^{\gamma _{r} +1}g_{m}^{r-1}\left(F(x)\right)dx.\nonumber \\  			&=Z(x)-{\left(\dfrac{2-\theta}{2}\right)}Z^{*}(x)  		  		where,  		  			Z(x)=\dfrac{c_{r-1}}{(r-1)!}\int_{0}^\infty{e^{tx}}\left[\bar{F}\left(x\right)\right]^{\gamma _{r}}g_{m}^{r-1}(F(x)dx\nonumber  		  		and   		  			Z^{*}(x)=\dfrac{c_{r-1}}{(r-1)! }\int_{0}^\infty{e^{tx}}\left[\bar{F}\left(x\right)\right]^{\gamma _{r}+1}g_{m}^{r-1}F(x)dx\nonumber  		  		After integrating $Z(x)$ by parts, we obtain  		  		  			Z(x)=\dfrac{\gamma_{r}}{t}\left[M_{r,n,m,k}(t)-M_{r-1,n,m,k}(t)\right]\nonumber  		  		In similar way, integrating $Z^{*}(x)$, we obtain  		  			Z^{*}(x)=\dfrac{\gamma_{r}^{n+1,k-m}C^{*}}{t}\left[M_{r,n+1,m,k-m}(t)-M_{r-1,n+1,m,k-m}(t)\right]\nonumber  		  		where $C^{*}=\dfrac{c_{r-1}}{c_{r-1}^{n+1,k-m}}.$\\  		Substituting $Z(x)$ and $Z^{*}(x)$ in \eqref{2.8}, we obtain\\  		  			tM_{r,n,m,k}(t)={\gamma_{r}}\left[M_{r,n,m,k}(t)-M_{r-1,n,m,k}(t)\right]-\left(\dfrac{2-\theta}{2}\right){\gamma_{r}^{n+1,k-m}C^{*}}\nonumber \\ \,\,\,\,\,\, \times \left[M_{r,n+1,m,k-m}{(t)}-M_{r-1,n+1,m,k-m}(t)\right].  		  		Differentiating \eqref{mgf.reccr} $(p+1)$ times w.r.t. $t$, we obtain \eqref{reccr.mgf}.\\  		We get the recurrence relation for single moments from HLG distribution based on $\textit{gos}$ by taking $t=0$ in \eqref{reccr.mgf}, as  		  			\mu_{r,n+1,m,k-m}^{p+1}=-{\left(\dfrac{2}{2-\theta}\right)}\dfrac{\gamma_{r}}{C^{*}\gamma_{r}^{k-m,n+1}}\left[\dfrac{(p+1)}{\gamma_{r}}\mu_{r,n,m,k}^{p}-\mu_{r,n,m,k}^{p+1}+\mu_{r-1,n,m,k}^{p+1}\right]\nonumber\\  			+\mu_{r-1,n+1,m,k-m}^{p+1},\,\,\,\,\,\,\, m\ne-1.\",2502.01255
proof,"Making use of \eqref{jointpdf.gos}, we obtain the joint mgf from \textit{gos} as  		    			M_{\left(r,s,n,m,k\right)}({t_{1},t_{2}}) =\frac{C_{s-1} }{\left(r-1\right)!\left(s-r-1\right)!}\int_{0}^{\infty}\int_{x}^{\infty} e^{t_{1}x+t_{2}y  }\left[\bar{F}\left(x\right)\right]^{m} f\left(x\right)g_{m}^{r-1} \left(F\left(x\right)\right) \nonumber \nonumber \\  			\times \left[h_{m} F\left(y\right)-h_{m} F\left(x\right)\right]^{s-r-1}\left[\bar{F}\left(y\right)\right]^{\gamma _{s} -1} f\left(y\right)dydx.\nonumber  		  		Simplifying above expression by using binomial expansion of $g_{m}^{r-1}   \left(F\left(x\right)\right)$ \text{and} $\left[h_{m} F\left(y\right)-h_{m} F\left(x\right)\right]^{s-r-1}$, we obtain  		  			M_{\left(r,s,n,m,k\right)}({t_{1},t_{2}}) =\frac{C_{s-1} }{\left(r-1\right)!\left(s-r-1\right)!(m+1)^s-2}\sum_{c=0}^{\infty}\sum_{u=0}^{r-1}\sum_{v=0}^{s-r-1}\binom{s-r-1}{v}\binom{r-1}{u}\nonumber\\  			\times\int_{0}^{\infty} e^{t_{1}x}\left[\bar{F}\left(x\right)\right]^{(s-r+u-v)(m+1)-1}f(x)I(x)dx.  		  		where,  		  			I(x)=\int_{x}^{\infty}e^{t_{2}y}\left[\bar{F}\left(y\right)\right]^{\gamma _{s-v} -1} f\left(y\right)dy.\nonumber  		  		In view of \eqref{cdf.hlg} and \eqref{pdf.hlg} and making appropriate substitution in $I(x)$, we obtain  		  			I(x)=\theta^{-t_{2}}2^{t_{2}}\left(\dfrac{2}{2-\theta}\right)^{\gamma_{s-v}-t_{2}}\int_{0}^{\left(\dfrac{2-\theta}{2}\right)\bar{F}\left(x\right)}  			{z^{\gamma_{s-v}-t_{2}-1}}(1-z)^{t_{2}}dz.  		  		In view of the following integral used by \cite{dutka1981incomplete},  		  			\int_{0}^{x}u^{a-1}(1-u)^{b-1}du=\dfrac{x^{a}(1-x)^b}{a}{}_{2}F_{1}(a+b,1;a+1;x)  		  		Here, $ {}_{2}F_{1}\left(\alpha,\beta,\gamma,z\right)$ is Gauss Hypergeometric function defined as  		  			{}_{2}F_{1}\left(\alpha,\beta,\gamma,x\right)=\sum_{z=0}^{\infty}\dfrac{(\alpha)_{z}(\beta)_{z}}{(\gamma)_{z}}\frac{x^{z}}{z!}.\nonumber  		  		simplifying $I(x)$ by using (3.4) and we reduce (3.2) as  		    			M_{\left(r,s,n,m,k\right)}({t_{1},t_{2}})= \dfrac{C_{s-1} }{\left(r-1\right)!\left(s-r-1\right)!(m+1)^{s-2}}\sum_{c=0}^{\infty}\sum_{u=0}^{r-1}\sum_{v=0}^{s-r-1}\binom{s-r-1}{v}\nonumber\\  			\times\binom{r-1}{u}(-1)^{u+v}\dfrac{\theta^{-t_{2}}2^{t_{2}}}{\left(\gamma_{s-v}-t_{2}\right)}\int_{0}^{\infty}e^{t_{1}x}\left[\bar{F}\left(x\right)\right]^{\gamma_{s-v}-t_{2}+(s-r+u-v)(m+1)-1}\nonumber\\  			\left[1-\left(\frac{2-\theta}{2}\right)\bar{F}\left(x\right)\right]^{t_{2}+1}{}_{2}F_{1}\left(\gamma_{s-v}+1,1;\gamma_{s-v}-t_{2}+1;\left(\dfrac{2-\theta}{2}\right)\bar{F}\left(x\right)\right)  		  		Solving (3.5) by expanding ${}_{2}F_{1}\left(\gamma_{s-v}+1,1;\gamma_{s-v}-t_{2}+1;\left(\dfrac{2-\theta}{2}\right)\bar{F}\left(x\right)\right)$and simplifying the resultant, we obtain \eqref{mgf.joint}.",2502.01255
proof,"In view of (1.3), the joint \textit{mgf} based on  \textit{gos} is  		  			M_{\left(r,s,n,m,k\right)}({t_{1},t_{2}}) =\frac{C_{s-1} }{\left(r-1\right)!\left(s-r-1\right)!}\int_{0}^{\infty} e^{t_{1}x }\left[\bar{F}\left(x\right)\right]^{m} f\left(x\right)\nonumber \\  			\times g_{m}^{r-1} \left(F\left(x\right)\right)I(x)dx.  		  		  			I(x)=\int_{x}^{\infty}e^{t_{2}y}\left[h_{m} F\left(y\right)-h_{m} F\left(x\right)\right]^{s-r-1}\left[\bar{F}\left(y\right)\right]^{\gamma _{s} -1} f\left(y\right)dy\nonumber  		  		or, making use of (1.9) in $I(x)$,  		  			I(x)=W(x)-{\left(\dfrac{2-\theta}{2}\right)}W^{*}(x)  		  		where,  		  			W(x)= \int_{x}^{\infty}e^{t_{2}y}\left[h_{m} F\left(y\right)-h_{m} F\left(x\right)\right]^{s-r-1}\left[\bar{F}\left(y\right)\right]^{\gamma _{s}}dy\nonumber  		  		Integrating by parts , we have $s\ge r+1$   		  			W(x)= \dfrac{\gamma_{s}}{t_{2}}\int_{x}^{\infty}e^{t_{2}y}\left[h_{m} F\left(y\right)-h_{m} F\left(x\right)\right]^{s-r-1}\left[\bar{F}\left(y\right)\right]^{\gamma _{s}-1}f(y)dy\nonumber\\  			-\dfrac{(s-r-1)}{t_{2}}\int_{x}^{\infty}e^{t_{2}y}\left[h_{m} F\left(y\right)-h_{m} F\left(x\right)\right]^{s-r-2}\left[\bar{F}\left(y\right)\right]^{\gamma _{s}-1}f(y)dy\nonumber  		  		Proceeding in the same way for $W^{*}(x)$  		  			W^{*}(x)= \dfrac{\gamma_{s}+1}{t_{2}}\int_{x}^{\infty}e^{t_{2}y}\left[h_{m} F\left(y\right)-h_{m} F\left(x\right)\right]^{s-r-1}\left[\bar{F}\left(y\right)\right]^{\gamma _{s}}f(y)dy\nonumber\\  			-\dfrac{(s-r-1)}{t_{2}}\int_{x}^{\infty}e^{t_{2}y}\left[h_{m} F\left(y\right)-h_{m} F\left(x\right)\right]^{s-r-2}\left[\bar{F}\left(y\right)\right]^{\gamma _{s}+m+1}f(y)dy\nonumber  		  		substituting $W(x)$ and $W^{*}(x)$ in (3.8) and then substitute the $I(x)$ in (3.7), we get after simplification   		  			t_{2}M_{r,s,n,m,k}(t_{1},t_{2})={\gamma_{s}}\left[M_{r,s,n,m,k}(t_{1},t_{2})-M_{r,s-1,n,m,k}(t_{1},t_{2})\right]\nonumber\\  			-\left(\dfrac{2-\theta}{2}\right){\left(\gamma_{s}+1\right)C^{*}}\left[M_{r,s,n+1,m,k-m}(t_{1},t_{2})-M_{r,s-1,n+1,m,k-m}(t_{1},t_{2})\right]  		  		Differentiating (3.9) $p$ times w.r.t. $t_{1}$ and $(q+1)$ times w.r.t. $t_{2}$, we obtain (3.6).  		We proceed to obtain the recurrence relation for joint moments of \textit{gos} from HLG distribution by setting $t_{1}$, $t_{2}=0$ in (3.6) as  		  			\mu_{r,n,m,k}^{p,q}=\dfrac{\gamma_{s}}{(q+1)}\left[\mu_{r,s,n,m,k}^{p,q+1}-\mu_{r,s-1,n,m,k}^{p,q+1}\right]\nonumber \\  		-\left(\dfrac{2-\theta}{2}\right)\dfrac{(\gamma_{s}+1)C^{*}}{(q+1)}\left[\mu_{r,s,n+1,m,k-m}^{p,q+1}-\mu_{r,s-1,n+1,m,k-m}^{p,q+1}\right]",2502.01255
example,"\em      As a particular example of the alternating processes that satisfy the assumptions of \neprop{example}, we can consider a stationary alternating renewal process with exponential on- and off-times. This concretely means that $\xi_{N,x,i}$ has an exponential distribution with parameter $\lambda_{N, {\rm off}}$ if $x+i$ is even and with parameter $\lambda_{N, {\rm on}}$ if $x+i$ is odd, and $p_{N}(0) = \lambda_{N, {\rm off}} / (\lambda_{N, {\rm on}}+\lambda_{N, {\rm off}})$. In this case we have for any $t\in[0,T]$              p_N(t) = \frac{\lambda_{N, {\rm off}}}{\lambda_{N, {\rm on}}+\lambda_{N, {\rm off}}}.          When considering the specific parametrization $\lambda_{N, {\rm off}}= N^{-\alpha}\lambda_{{\rm off}}$ and $\lambda_{N, {\rm on}}\equiv \lambda_{{\rm on}}$ for some parameters $\lambda_{\rm on},\lambda_{\rm off},\alpha>0$, we obtain that the process {$a_N(\cdot)$} satisfies Assumption \ref{ass:ass1} and \ref{ass:ass2} with $\varrho_N = N^{-\alpha}$,               \kappa_{\star}(s,t) = \frac{\lambda_{\rm off}}{\lambda_{\rm on}}e^{-\lambda_{\rm on}\abs{s-t}},          and $p^{\star}(t) \equiv \lambda_{\rm off}/\lambda_{\rm on}$. \hfill$\clubsuit$",2502.01259
example,"\em To get an impression of a typical application of Theorem \ref{main}, consider the case of $m=2$, with the subgraphs corresponding to wedges and triangles. Consider the edge processes defined in Example~\ref{ex:process} with $\alpha\in(0,1)$. Then one can check that both wedge graph (denoted by ${H}_1$) and triangle graph (denoted by ${H}_2$) satisfy \eqref{graph_assumption}, and      &\mathcal{F}_N({H}_1) = N^{2\alpha - 3},\qquad \mathcal{F}_N({H}_2) = N^{3\alpha - 3},\\     &\mathcal{F}^{\rm opt}_N({H}_1) = N^{\alpha - 2},\qquad \mathcal{F}^{\rm opt}_N({H}_2) = N^{\max(\alpha - 2, 3\alpha - 3)}.  {The next step is to describe the sets ${\tt OCS(H_1)}$ and ${\tt OCS(H_2)}$. The first one is easy to find: ${\tt OCS(H_1)} = \{g_1\}$, where $g_1$ is an edge. However, for the second one we need to distinguish three cases:}      \item[$\circ$]{If $\alpha\in(0,1/2)$ then ${\tt OCS}({H}_2) = \{g_1\}$},     \item[$\circ$]{If $\alpha=1/2$ then ${\tt OCS}({H}_2) = \{g_1,g_2\}$},     \item[$\circ$]{If $\alpha\in(1/2,1)$ then ${\tt OCS}({H}_2) = \{g_2\}$},  where $g_2$ is a triangle. It is readily verified  that      \mathcal{A}({H}_1) = 2,\qquad \mathcal{A}({H}_2) = 6,\qquad \mathcal{A}(g_1) = 2,\qquad \mathcal{A}(g_2) = 6,\\     \mathcal{S}({H}_1,g_1) = 2,\qquad \mathcal{S}({H}_2,g_1) = 3,\qquad \mathcal{S}({H}_2,g_2) = 1.  Applying \netheo{main} we obtain that, as $N\to\infty$,      \left(\frac{X_{N,1}(t) - \E{X_{N,1}(t)}}{N^{ 2 - 3\alpha/2}} , \frac{X_{N,2}(t) - \E{X_{N,2}(t)}}{N^{\max(2-5\alpha/2,\, 3/2 - 3\alpha/2)}}\right)^{\top}\to (X_1(t),X_2(t))^{\top},  where      X_1(t) &= \frac{2\sqrt{2}}{2}\frac{\lambda_{\rm off}}{\lambda_{\rm on}}X_1^{\star}(t),\\     X_2(t) &= \mathbb{I}\{\alpha\leqslant 1/2\}\frac{3\sqrt{2}}{6}\left(\frac{\lambda_{\rm off}}{\lambda_{\rm on}}\right)^2X_1^{\star}(t) + \mathbb{I}\{\alpha\geqslant 1/2\}\frac{\sqrt{6}}{6}X^{\star}_2(t);  the coefficients in these expressions can be simplified in the obvious manner, and $X_1^{\star}(\cdot)$ and $X_2^{\star}(\cdot)$ are two independent centered Gaussian processes, characterized via the covariance functions      \operatorname{Cov}(X_1^{\star}(s),X_{1}^{\star}(t)) &= \frac{\lambda_{\rm off}}{\lambda_{\rm on}}e^{-\lambda_{\rm on}\abs{s-t}},\\     \operatorname{Cov}(X_2^{\star}(s),X_{2}^{\star}(t)) &= \left(\frac{\lambda_{\rm off}}{\lambda_{\rm on}}\right)^{3}e^{-3\lambda_{\rm on}\abs{s-t}},  respectively. In particular, for $\alpha<1/2$ we have that processes {$X_1(\cdot)$} and {$X_2(\cdot)$} are perfectly correlated, whereas for $\alpha>1/2$ they are independent. {In case $\alpha=1/2$, the processes {$X_1(\cdot)$} and {$X_2(\cdot)$} are positively but not perfectly correlated.} \hfill$\clubsuit$",2502.01259
theorem,"[Feedback NOC]     Assume that \( \bar{u} \) is optimal for \( (\bm{LP}') \) {\rm (}respectively, for \( (\widetilde{P}) \){\rm )}. Then, the relations \eqref{clFBM} (resp., \eqref{lfbm}) hold for any \( u \in \mathcal{U} \) satisfying \eqref{clucomp} {\rm (}resp., \eqref{lu-com}\textrm{)} for a.a. \( t \in I \), and \( \mathcal{J}[u] = \mathcal{J}[\bar{u}] \) {\rm (}resp., \( \widetilde{\mathcal{I}}[u] = \widetilde{\mathcal{I}}[\bar{u}] \){\rm )}.",2502.01274
theorem,"[PMP]      Suppose that Assumptions~\ref{a3} hold. If \( \bar{u} \) is optimal in~\eqref{eq:PDE}, then there exists a solution \( \bar{\gamma} \) to the Hamiltonian system~\eqref{eq:ham} associated to the vector field \( F_t(\cdot,\bar{u}_t) \) such that the identities   \[   \left<\bar{p}_t, F_t(\bar{\mu}_t,\bar{u}_t)\right>_{\bar{\mu}_t} = \min_{\omega\in U} \left<\bar{p}_t,F_t(\bar{\mu}_t,\delta_{\omega}) \right>_{\bar{\mu}_t}   \]   hold for a.a. \( t\in I \), where \( \bar{p}_t = \mathcal{B}(\bar{\gamma}_t) \) and \( \bar{\mu}_t=\pi^1_\sharp\bar{\gamma}_t \).",2502.01274
theorem,"[Feedback NOC]      Suppose that Assumptions~\ref{a3} hold. Let \( \bar{u} \) be optimal in~\eqref{eq:PDE}. Denote by \( \bar{\mu} \) and \( \mathbf{\bar{p}} \) the corresponding trajectory and super-adjoint. Let a control \( u \) and the corresponding trajectory \( \mu \) satisfy \[   \left<\mathbf{\nabla}\bar{\mathbf{p}}_t(\mu_t), F_t({\mu}_t,{u}_t)\right>_{{\mu}_t}  = \min_{\omega\in U} \left<\mathbf{\nabla}\bar{\mathbf{p}}_t(\mu_t),F_t(\mu_t,\delta_{\omega}) \right>_{\mu_t}, \] for a.a. \( t\in I \). Then, the relation  \[ \left<\mathbf{\nabla}\bar{\mathbf{p}}_t(\mu_t), F_t({\mu}_t,{u}_t)\right>_{{\mu}_t} =    \left<\mathbf{\nabla}\bar{\mathbf{p}}_t(\mu_t), F_t({\mu}_t,\bar{u}_t)\right>_{{\mu}_t} \] holds for a.a. \( t\in I \). Moreover, \( \mathcal I[u] = \mathcal I[\bar{u}] \).",2502.01274
theorem,"[PMP for problem $(\bm{LP}')$]     Assume that hypotheses \ref{a6}--\ref{a8} hold, and let $\bar u$ be optimal for $(\bm{LP}')$. Then, the following relation holds for a.a. $t\in I$:     \min_{\mathrm u \in U}\bm H_t(\bar{{\bm x}}_t,  \bar{\bm p}_t, \bar u_t-\mathrm u) = 0.",2502.01274
theorem,"The operator equation \eqref{ucomp} has at least one solution $u \in {\mathcal U}$ for any $\bar u \in \mathcal U$, i.e., \(\bar{\mathcal U}_{ext}\neq \emptyset\).",2502.01274
theorem,"[FNOC for problem $(\bm{LP}')$]     Under the premise of Theorem~\ref{PMP1}, the relations      \bm H_t(\bm x_t,  \bar{\bm p}_t, \bar u_t) = \bm H_t(\bm x_t,  \bar{\bm p}_t, u_t)\doteq \min_{\mathrm u \in U}\bm H_t(\bm x_t^{u},  \bar{\bm p}_t, \mathrm u)      hold for any $u \in \bar{\mathcal U}_{ext}$ and a.e. $t \in I$. Moreover, $\mathcal J[u] = \mathcal J[\bar u]$.",2502.01274
definition,"[Differentiable functions] ~%        \item (\emph{Differentiability}) A function \( \phi\colon \mathcal{P}_2\to \mathbb{R} \) is called \emph{differentiable} at \( \mu\in \mathcal{P}_2 \) if there exists a linear bounded map \( \mathbf{d}\phi_{\mu} \colon {L}^2_{\mu}\to \mathbb{R}\) such that for any \( v\in L^2_{\mu} \) it holds \[   \lim_{\varepsilon\to 0+}\frac{1}{\varepsilon}\left|\phi\left((\id+\varepsilon v)_\sharp \mu\right)- \phi(\mu)- \varepsilon\, \mathbf{d}\phi_{\mu}(v) \right| = 0. \] The map \( \mathbf{d}\phi_{\mu} \) is termed the \emph{differential} (or \emph{derivative}) of \( \phi \) at \( \mu \).  Since \( {L}^2_{\mu} \) is a Hilbert space, for any \( v\in {L}^2_{\mu} \), there exists a unique element \( w\in {L}^2_{\mu} \) such that \( \mathbf{d}\phi_{\mu}(v) = \left< v,w \right>_{\mu} \). This element \( w \) is called the \emph{gradient} of \( \phi \) at \( \mu \), and is denoted by \( \bm \nabla \phi(\mu) \).   \item (\emph{Uniform differentiability}) We say that a function \( \phi\colon \mathcal{P}_2\to \mathbb{R} \) is \emph{uniformly differentiable} if it is differentiable at every \( \mu\in \mathcal{P}_2 \), and there exists \( C>0 \) such that   \[     \left|\phi\left((\id +\varepsilon v)_{\sharp}\mu\right) - \phi(\mu) - \varepsilon\mathbf{d}\phi_{\mu} (v)\right|\le C\|v\|^{2}_{\mu} \varepsilon^2,   \]   for all \( \mu\in \mathcal{P}_2 \), \( v\in {L}^2_{\mu} \) and \( \varepsilon\in \mathbb{R} \).     \item (\emph{Uniformly equidifferentiable families}) A family $(\phi_\alpha)_{\alpha\in \mathcal A}$ of functions \( \phi_\alpha\colon \mathcal{P}_2\to \mathbb{R} \) is called uniformly equidifferentiable if all $\phi_\alpha$ are uniformly differentiable with a common constant $C>0$, independent of $\alpha$.",2502.01274
definition,"[Differentiability of maps]  \quad              \item (\emph{Differentiability}) A map \( \Phi \colon \mathcal{P}_2 \to \mathcal{P}_2 \) is called \emph{differentiable} if, for any point $\mu\in \mathcal{P}_2$, there exists a linear bounded map \(\Phi_{\star,\mu} \colon {L}^2_{\mu} \to L^2_{\Phi(\mu)} \) such that for any \( v \in {L}^2_{\mu} \) the function \( w = \Phi_{\star,\mu}v \) satisfies the relation: \[   \lim_{\varepsilon\to 0+}\frac{1}{\varepsilon}W_1\left(\Phi\left((\id+\varepsilon v)_\sharp \mu\right), (\id +\varepsilon w)_\sharp \Phi(\mu)\right) = 0. \] The map \(\Phi_{\star,\mu} \) is called the \emph{derivative} of \( \Phi \) at \( \mu \).  \item (\emph{Uniform differentiability}) A map \( \Phi\colon \mathcal{P}_2\to \mathcal{P}_{2} \) is \emph{uniformly differentiable} if it is differentiable at any \( \mu\in \mathcal{P}_2 \), and there exists \( C>0 \) such that   \[     \|v\|_{\Phi(\mu)}\le C\|w\|_{\mu}\quad \mbox{ and }\quad     W_1\left(\Phi\left((\id+\varepsilon v)_{\sharp}\mu\right),(\id+\varepsilon w)_{\sharp}\Phi(\mu)\right)\le C\|v\|^{2}_{\mu}\varepsilon^2,   \]   for all \( \mu\in \mathcal{P}_2 \), \( v\in {L}^2_{\mu} \), and \( \varepsilon\in \mathbb{R} \), where \( w \doteq \Phi_{\star,\mu} v \).    \item (\emph{Uniformly equidifferentiable families}) A family $(\Phi_\alpha)_{\alpha\in \mathcal A}$ of maps \( \Phi_\alpha\colon \mathcal{P}_2\to \mathcal{P}_2 \) is called uniformly equidifferentiable if all $\Phi_\alpha$ are uniformly differentiable with a common constant $C>0$, independent of $\alpha$.",2502.01274
definition,"We say that a function \( \phi\colon \mathcal{P}_2\to \mathbb{R} \) belongs to the class \( \bm{\mathcal D} \) if it satisfies the following properties: [(i)]   \item There exists a map \( \frac{\delta \phi}{\delta \mu}\colon \mathcal{P}_2 \times \mathbb{R}^n\to \mathbb{R} \), called the flat derivative of \( \phi \), such that \[   \phi(\mu_{1}) - \phi(\mu_{0}) = \int_0^1\int \frac{\delta \phi}{\delta\mu}\left((1-t)\mu_0 + t\mu_1,\mathrm{x}\right)\d (\mu_1-\mu_0)(\mathrm{x})\d t \] and     \[     \int \frac{\delta \phi}{\delta \mu}(\mu,\mathrm{x})\d \mu(\mathrm{x}) = 0         \]         for all \( \mu_0,\mu_1\in \mathcal{P}_c \).  \smallskip                \item The map \( \frac{\delta \phi}{\delta \mu} \) is continuous, bounded, and differentiable in \( \mathrm{x} \).  \smallskip        \item The map \( \nabla\frac{\delta \phi}{\delta \mu} \colon \mathcal{P}_2 \times \mathbb{R}^n\to \mathbb{R}^n\) (the gradient of \( \frac{\delta \phi}{\delta \mu} \) in \( \mathrm{x} \)) is Lipschitz continuous and bounded.",2502.01274
definition,"[Differentiability w.r.t. the flow] ~      \item A function $\phi\colon \mathcal{X} \to \mathbb{F}$ is said to be differentiable w.r.t. the flow $\Phi$ (\emph{$\Phi$-differentiable}, for short) at a point $\mathrm{x} \in \mathcal{X}$ if the following limit exists for a.e. $t \in [0,T)$:              ({\mathfrak{L}_t{\phi}})(\mathrm{x}) \doteq \partial_h \big|_{h=0}  \left(\bm{\Psi}_{t+h, t} \phi\right)(\mathrm{x}) = \lim_{h \to 0+}\frac{\phi\big(\Phi_{t, t+h}(\mathrm{x})\big) - \phi(\mathrm{x})}{h}.          If there exists a subset $J \subseteq I$ of full Lebesgue measure such that the condition \eqref{L} holds for all $t \in J$ and  $\mathrm{x} \in \mathcal{X}$, the function $\phi$ is said to be $\Phi$-differentiable on $\mathcal{X}$.      \item A function $\phi \in \bm{X}$ that is $\Phi$-differentiable on $\mathcal{X}$ is called \emph{continuously $\Phi$-differentiable} on the same set if $\mathfrak{L}_t{\phi} \in \bm{X}$ for all $t \in J$.      \item Let $\mathcal{A}$ be an index set. A family $(\phi_\alpha)_{\alpha \in \mathcal{A}}$ of functions $\phi_\alpha \in \bm{X}$ is \emph{uniformly equidifferentiable with respect to $\Phi$} if the relation              \lim_{h \to 0+}\sup_{\alpha \in \mathcal{A}}\frac{1}{h}\Big\|\left[\bm{\Psi}_{t+h, t}-\id - h\mathfrak{L}_t\right]\phi_\alpha\Big\|_{\bm{X}} = 0          holds for a.a. $t \in [0,T)$. If $\mathcal{A}$ is a singleton, the function $\phi_\alpha \equiv \phi$ is called \emph{uniformly $\Phi$-differentiable}.",2502.01274
definition,"%     We call the control $\bar u \in \mathcal U$ and the corresponding process $(\bar {\bm x}, \bar u)$ \emph{feedback extremal} in the problem $(\bm{LP}')$ if, for any absolutely continuous (a.c.) curve $\gamma\colon I \to \mathcal R_T(\vartheta)$ such that  %     [(i)] %         \item $\gamma_0 = \bar {\bm x}_T$, and  %         \item the map $s \mapsto \ell(\gamma_s)$ is non-decreasing,  %      %     it holds that  %     \[ %     \frac{\d}{\d s} (\ell \circ \gamma) = 0 \quad \text{for a.a. } s \in I, %     \] %     i.e., the map $s \mapsto \ell(\gamma_s)$ is, in fact, constant. In other words, there are no monotone a.c.\ curves inside the reachable set with the descent property: $\ell(\gamma_T) < \ell(\gamma_0) = \ell(\bar {\bm x}_T)$.   %     Similarly, the control $\bar u \in \mathcal U$ (the process $(\bar {\bm x}, \bar u)$) is said to be \emph{feedback extremal} in the problem $(P)$ if it is such in the linear super-problem $(\bm{LP}'|P)$. %",2502.01274
definition,"By a \emph{feedback control} of system $\Phi$ we mean a family $\mathfrak{u} \doteq (u^{\rm x})_{\mathrm x \in \mathcal X}$ of admissible controls $u^{\rm x} \in \mathcal U$, parameterized by the points of the state space $\mathcal X$.",2502.01274
proof,"By plugging \( u^{\varepsilon} \) into \eqref{eq:LCexact} and abbreviating \( x^{\varepsilon} = x^{u^{\varepsilon}} \), we obtain:   \[    \widetilde{\mathcal I}[u^{\varepsilon}] - \widetilde{\mathcal I}[\bar{u}]    = \epsilon\int_I \nabla \bar{\bm p}_t(x^{\varepsilon}(t))\cdot f_t\left(x^{\varepsilon}(t), u^{\varepsilon}_t - \bar{u}_t\right) \d t.  \]  Our regularity assumptions on \( f \) and \( \ell \), together with the representation~\eqref{LCadj}, imply that \( \mathrm x \mapsto \nabla \bm p_t(\rm x) \) is $C^\infty$, and therefore,   \[     \nabla \bar{\bm p}_t(x^{\varepsilon}(t)) = \nabla \bar{\bm p}_t(\bar{x}(t)) + D^2 \bar{\bm p}_t(\bar{x}(t)) \left[x^{\varepsilon}(t) - \bar{x}(t)\right] + O \left( \left|x^{\varepsilon}(t) - \bar{x}(t) \right|^2 \right).   \]   On the other hand, from the variational formula, established, e.g., in~\cite[Section~2.7]{agrachevControlTheoryGeometric2004}, it follows that \[   x^{\varepsilon}(t) - \bar{x}(t) = \varepsilon \bar{y}(t) + o(\varepsilon).   \]   Therefore,   \[     \nabla \bar{\bm p}_t(x^{\varepsilon}(t)) = \nabla\bar{\bm p}_t(\bar{x}(t)) + \varepsilon D^2 \bar{\bm p}_t(\bar{x}(t)) \, \bar{y}(t) + O(\varepsilon^2).   \]   Similarly,         f_t(x^{\varepsilon}(t), u^{\varepsilon}_t - \bar{u}_t) = & \     \varepsilon f_t(x^{\varepsilon}(t), u_t - \bar{u}_t)\\ = & \      \varepsilon f_t(\bar{x}(t), u_t - \bar{u}_t) + \varepsilon^2 Df_t(\bar{x}(t), u_t - \bar{u}_t) \, \bar{y}(t) + O(\varepsilon^3).     Combining these expansions, we conclude that the first-order term is equal to   \[     \nabla \bar{\bm p}_t(\bar{x}(t)) \cdot f_t(x^{\varepsilon}(t), u^{\varepsilon}_t - \bar{u}_t)   \]   and the second-order term to   \[     f_t(\bar{x}(t), u_t - \bar{u}_t) \cdot D^2 \bar{\bm p}_t(\bar{x}(t)) \, \bar{y}(t) + \nabla \bar{\bm p}_t(\bar{x}(t)) \cdot Df_t(\bar{x}(t), u_t - \bar{u}_t) \, \bar{y}(t).   \]    By Proposition~\ref{prop:NLdiff}, we have \( \nabla \bar{\bm p}_t(\bar{x}(t)) = \bar{p}(t) \), and to complete the proof it remains to verify that the map   \[     t \mapsto P(t) \doteq D^2 \bar{\bm p}_t(\bar{x}(t))   \]   satisfies the Riccati equation~\eqref{eq:riccati}. This can be checked by direct computation.  Indeed, \( P \) obviously satisfies the terminal condition. Let us compute the time derivative of \( P(t) \). To that end, we will use a tensor partial derivative notation \( \frac{\partial}{\partial x^{j}} T = T_{,j} \) and adopt the Einstein summation convention, summing over terms with the same upper and lower indices.  With this notation, the coordinates of \( P(t) \) are given by \( P_{ij}(t) = \bar{\bm p}_{,ij}(t,\bar x(t)) \). Hence       \frac{d}{dt} P_{ij}(t) = \left(\partial_t \bar{\bm p}_{,ij} + \bar{\bm p}_{,kij} f^k\right)(t,\bar x(t)) \doteq a_{ij}(t),  for a.e. \( t \in I \).   On the other hand, we know from~\eqref{eq:strong} that the equality \[ \partial_t \bar{\bm p}_t + \nabla \bar{\bm p}_t \cdot f_t(\cdot,\bar{u}_t) = 0 \] holds on $\R^n$ for a.a. \( t \in I \). In coordinates, this reads: \[ b \doteq \partial_t \bar{\bm p} + \bar{\bm p}_{,k} f^{k} = 0. \] Let us compute \( b_{,ij} \). For the first derivative, we have \[ b_{,i} = (\partial_t \bar{\bm p})_{,i} + \bar{\bm p}_{,ki} f^{k} + \bar{\bm p}_{,k} f^k_{,i}. \] Now, for the second derivative \[ b_{,ij} = (\partial_t \bar{\bm p})_{,ij} + \bar{\bm p}_{,kij} f^{k} + \bar{\bm p}_{,ki} f^k_{,j} + \bar{\bm p}_{,kj} f^k_{,i} + \bar{\bm p}_{,k} f^k_{,ij} = 0. \] Along the trajectory \(\bar x \), this reads:  b_{,ij}\big|_{(t,\bar x(t))}  = & \left((\partial_t \bar{\bm p})_{,ij} + \bar{\bm p}_{,kij} f^{k}\right)\big|_{(t,\bar x(t))}\\ & + P_{ki} f^k_{,j}\big|_{(t,\bar x(t))} + P_{kj} f^k_{,i}\big|_{(t,\bar x(t))} + \bar{p}_{k}(t) f^k_{,ij}\big|_{(t,\bar x(t))}\\   = & 0,  where we use the notation \( P_{ij}(t) = \bar{\bm p}_{,ij}\big|_{(t,\bar x(t))} \) and the established identity  \[     \bar{p}_k(t) = \bar{\bm p}_{,k}\big|_{(t,\bar x(t))}. \] Therefore,    a_{ij}(t) & = a_{ij}(t) - b_{,ij}\big|_{(t,\bar x(t))}\\   & = \left(\partial_t \bm p_{,ij} - (\partial_t \bm p)_{,ij}\right)\big|_{(t,\bar x(t))} - \left(P_{ki} f^k_{,j} + P_{kj}f^k_{,i} + p_{k}f^k_{,ij}\right)\big|_{(t,\bar{x}(t))}.  It follows from~\eqref{eq:commute} that  \[     \left(\partial_t \bm p_{,ij} - (\partial_t \bm p)_{,ij}\right)\big|_{(t,\bar x(t))} = 0. \]  Thus, \eqref{eq:P1} can be rewritten as \[ \dot P = - (D f_t(\bar x))^{\T} P - P Df_t(\bar x) - D^2 H_t(\bar x,\bar p, \bar u_t) \] in the matrix notation. This observation finishes the proof.",2502.01274
proof,"\textbf{1.} The Lipschitz continuity of \( \phi \) with respect to the distance \( W_1 \) implies that    \[      \left|\phi\left(\Phi((\id + \varepsilon v)_\sharp\mu)\right)-\phi\left((\id + \varepsilon w)_\sharp \Phi(\mu)\right)\right|\le      \Lip_{W_1}(\phi) W_1 \left(\Phi((\id + \varepsilon v)_\sharp\mu),(\id + \varepsilon w)_\sharp \Phi(\mu)\right),    \]    for any \( v\in {L}^2_{\mu} \) and \( w\in L_{\Phi(\mu)}^2 \).    If \( w = \Phi_{\star,\mu}(v) \), the uniform differentiability of \( \Phi \) implies that    \[      \|w\|_{\Phi(\mu)}\le C_1\|v\|_{\mu}\quad \text{ and }\quad     W_1 \left(\Phi((\id + \varepsilon v)_\sharp\mu),(\id + \varepsilon w)_\sharp \Phi(\mu)\right)\le C_1\|v\|^2_{\mu}\varepsilon^2,   \]   for some \( C_1>0 \), and all \( \mu\in \mathcal{P}_2\),  \(v\in {L}^2_{\mu}\), and \(\varepsilon\in \mathbb{R}\).    In particular,   \[     \left|\phi\left(\Phi((\id + \varepsilon v)_\sharp\mu)\right)-\phi\left((\id + \varepsilon w)_\sharp \Phi(\mu)\right)\right|\le \Lip_{W_1}(\phi) \, C_1 \|v\|^2_{\mu}\varepsilon^{2},   \]   for all \( \mu\in \mathcal{P}_2\),  \(v\in {L}^2_{\mu}\), and \(\varepsilon\in \mathbb{R}\). Since \( \phi \) is also uniformly differentiable, it holds   \[     \left| \phi\left((\id + \varepsilon w)_\sharp \Phi(\mu)\right) - \phi(\Phi(\mu)) - \varepsilon (\mathbf{d}\phi)_{\Phi(\mu)}(w)\right| \le C_2\|w\|^2_{\Phi(\mu)}\varepsilon^{2},   \]   for each \( \mu\in \mathcal{P}_2\),  \(w\in L^2_{\Phi(\mu)}\), and \(\varepsilon\in \mathbb{R}\).   Taking \( w = \Phi_{\star,\mu}(v) \), and combining the above inequalities, we get   \[     \left| \phi\left(\Phi((\id + \varepsilon v)_\sharp\mu)\right) - \phi(\Phi(\mu)) - \varepsilon (\mathbf{d}\phi)_{\Phi(\mu)}(w)\right| \le \left(\Lip_{W_1}(\phi )C_1 + C_1^2C_2\right)\|v\|^2_{\mu}\varepsilon^{2}. \] Thus, \( v \mapsto (\mathbf{d}\phi )_{\Phi(\mu)}(\Phi_{\star,\mu}(v))\) satisfies the approximation property of the derivative of \( \Phi^{\star}\phi \) at \( \mu \).   It remains to note that this map is linear and bounded as the composition of linear bounded maps.    \textbf{2.} Due to the uniformity of the constants $C_1$ and $C_2$ w.r.t. $t \in I$, all previous estimates remain intact, leading to the second assertion.",2502.01274
proof,"\textbf{1.} Recall that  \[   \phi(\mu_{1}) - \phi(\mu_{0}) = \int_0^1\int \frac{\delta \phi}{\delta\mu}\left((1-t)\mu_0 + t\mu_1,x\right)\d (\mu_1-\mu_0)(x)\d t. \] By the third property of test functions, \( \nabla\frac{\delta \phi}{\delta \mu} \) is bounded. Therefore, \( \mathrm{x} \mapsto \frac{\delta \phi}{\delta\mu}\left(\mu,\mathrm{x}\right)  \) is Lipschitz, uniformly for all \( \mu\in \mathcal{P}_2 \). Now the \( W_1 \)-Lipschitz continuity of \( \phi \) follows from the dual representation of \( W_1 \): \[   W_1(\mu_1,\mu_2) = \sup\left\{\int \phi\d(\mu_1-\mu_2)\;\colon\;\phi\in C(\mathbb{R}^n;\mathbb{R}),\;\Lip(\phi)\le 1 \right\}. \] Since \( W_1(\mu_0,\mu_1)\le W_2(\mu_1,\mu_2) \), the function \( \phi \) is Lipschitz w.r.t. \( W_2 \) as well.   \textbf{2.}  Differentiability (assertion (2)) follows from~\cite[Proposition 2.1]{chertovskihOptimalControlNonlocal2023}.    The proof of assertion (3) is similar to that of Lemma~\ref{lem:O2vf} below.  %    \textbf{3.} It remains to prove Assertion (4). The map \( t\mapsto \phi(\mu_t) \) is absolutely continuous as a composition of a Lipschitz and an absolutely continuous function. Let \( v_t\doteq\dot \mu_t \). Thanks to~\cite[Proposition 8.4.6]{ambrosioGradientFlowsMetric2005}, for a.e. \( t \), it holds \( W_2(\mu_{t+h}, (\id +h v_t)_{\sharp}\mu_t) = o(h) \) as \( h\to 0 \). Fix some \( t \) with this property. Then  \phi(\mu_{t+h}) - \phi(\mu_t) = \left[\phi(\mu_{t+h}) - \phi((\id+h v_t)_{\sharp}\mu_t)\right] + \left[\phi\left((\id+hv_t)_{\sharp}\mu_t\right) - \phi(\mu_t)\right].     The first difference from the right is \( o(h) \), because \[ \left|\phi(\mu_{t+h}) - \phi((\id+hv_t)_{\sharp}\mu_t)\right|\le \Lip(\phi)\, W_2(\mu_{t+h},(\id+hv_t)_{\sharp}\mu_t) = o(h). \] The latter formula holds due to the Lipschitz continuity of \( \phi \) and the choice of \( t \). The second difference in the right-hand side of~\eqref{eq:xixi} equals \[ h(\mathbf{d} \phi)_{\mu_t}(v_t) + o(h), \] due to the differentiability of \( \phi \).",2502.01274
proof,"% Let us show that $\bm p$ is indeed a mild solution.    Fix \( \mu\in \mathcal{P}_2 \).   Proposition~\ref{prop:basic}(3) together with Lemma~\ref{lem:testlip}(1) imply that the map \( t\mapsto \mathbf{p}_t(\mu) \) is Lipschitz continuous.   Therefore, for almost all \( t\in I \), the limit             \partial_t \mathbf{p}_t(\mu) = \lim_{h\to 0}\frac{ \mathbf{p}_{t+h}(\mu) - \mathbf{p}_t(\mu)}{h}=-\lim_{h\to 0}\frac{\mathbf{p}_{t+h}(\Phi_{t,t+h}(\mu)) - \mathbf{p}_{t+h}(\mu)}{h}      is well-defined.     At the same time, as the flow of \( F_t(\cdot, u_t) \), the map \( \Phi \) satisfies            \lim_{h\to 0}\frac{W_2\left(\Phi_{t,t+h}(\mu), (\id +h F_t(\mu,u_t))_{\sharp}\mu\right)}{h} = 0,      for almost all \( t\in I \).     Clearly, the set of all \( t\in I \) for which both~\eqref{eq:tmp1} and~\eqref{eq:tmp2} hold has full Lebesgue measure. Fix some \( t \) from this set.   Due to Proposition~\ref{prop:basic}(3), the map \( \mu \mapsto \mathbf{p}_{t+h}(\mu) \) is Lipschitz with modulus \( L\Lip(\ell) \).    Therefore, using~\eqref{eq:tmp1} and~\eqref{eq:tmp2}, we may write    \[     \partial_t \mathbf{p}_t(\mu) =-\lim_{h\to 0}\frac{\mathbf{p}_{t+h}\left((\id +h F_t(\mu,u_t))_{\sharp}\mu\right) - \mathbf{p}_{t+h}(\mu)}{h}.   \]   By Proposition~\ref{prop:dp_cont}(1), the family \( (\mathbf{p}_{t})_{t \in I} \) is uniformly equidifferentiable.    Thus,   \[     \partial_t \mathbf{p}_t(\mu) =-\lim_{h\to 0}\left< \bm \nabla \mathbf{p}_{t+h}(\mu), F_t(\mu,u_t) \right>_{\mu} = -\left< \bm \nabla \mathbf{p}_{t}(\mu), F_t(\mu,u_t) \right>_{\mu},   \]   where we use Proposition~\ref{prop:dp_cont}(2) to prove the last equality.",2502.01274
proof,"Let $\bm p$ be a solution to \eqref{eq:Wadjoint} such that~\eqref{der-pmu} holds true for any \( g \) satifying \ref{F1}. Let \( \Phi \) be the flow of \( F_t(\cdot,u_t) \) and $\bm q_{s,t} \doteq \bm p_t\circ \Phi_{s,t}$. By the differentiation rule \eqref{der-pmu} written for \( \mu_t\doteq \Phi_{s,t}(\vartheta) \) with any \( \vartheta\in \mathcal{P}_2 \), the mapping $t\mapsto \bm q_{s,t}$ is constant. Then, we can write: \[     \bm p_t \doteq \bm q_{t,t} = \bm q_{t, T} \doteq \ell\circ \Phi_{t, T}, \] showing that $\bm p$ is uniquely defined.",2502.01274
proof,"Let \( \Phi \) be the flow of \( (t,\mu)\mapsto F_t(\mu_t,u_t) \).   Fix some \( t\in I \).   The representation formula yields \[   \mathbf{p}_t = \ell \circ \Phi_{t,T} = \Phi_{t,T}^\star p_T. \] By differentiating with respect to \( \mu \) we obtain, thanks to Lemma~\ref{lem:Wcommut}, that \[   \mathbf{d} \mathbf{p}_t = \mathbf{d} \left(\Phi_{t,T}^\star \mathbf{p}_T\right) = \Phi_{t,T}^\star (\mathbf{d}\mathbf{p}_T). \] Let \( v_s \) with \( s\in [t,T] \) be the vector field from Proposition~\ref{prop:Wflowdiff}. In this case, \( v_T = (\Phi_{t,T})_{\star,\mu}v_t \). Plugging this formula in the previous identity and recalling the definition of the pullback for \( 1 \)-forms, we obtain: \(   (\mathbf{d} \mathbf{p}_t)_{\mu}(v_t) = (\mathbf{d}\mathbf{p}_{T})_{\Phi_{t,T}(\mu)}(v_T). \) Replacing \( \mu \) with \( \mu_t \) gives \(   (\mathbf{d} \mathbf{p}_t)_{\mu_t}(v_t) = (\mathbf{d}\mathbf{p}_{T})_{\mu_{T}}(v_{T}) \), or, in the 'non-geometric' notation, \[   \left\langle\bm \nabla \mathbf{p}_t(\mu_t), v_t\right\rangle_{\mu_t} = \left\langle\bm \nabla \mathbf{p}_T(\mu_T), v_T\right\rangle_{\mu_T}. \] If we let \( \widetilde p_t \doteq \bm\nabla \mathbf{p}_t(\mu_t) \), then the latter identity can be written as \( \left\langle\widetilde p_t,v_t\right\rangle_{\mu_t} = \left< \ell, v_{T} \right>_{\mu_T} \) Recall that the co-trajectory \( p_t \) satisfies the same identity, that is, \( \left\langle\widetilde p_t,v_t\right\rangle_{\mu_t} = \left\langle p_t,v_t\right\rangle_{\mu_t} \).  Since the initial tangent vector \( v_t \) can be arbitrarily selected from \( L^2_{\mu_t} \), we conclude that \( \widetilde p_t= p_t \).",2502.01274
proof,"\textbf{1.} First, note that, for each \( \phi \in \bm{\mathcal D} \),   the composition \( t \mapsto \phi \circ \Phi_{0, t} \) is Lipschitz by the definition of \( \bm{\mathcal D} \) and hypotheses \ref{a4}. Hence, we have for any \( s,t > 0 \): \[     \left|\left\langle \vartheta, (\bm \Psi_{s,0} - \bm \Psi_{t,0})\phi\right\rangle\right| = \left|\int \left(\phi\circ\Phi_{0,s} - \phi\circ\Phi_{0,t}\right)\d \vartheta\right| \leq \|\vartheta\|_{\bm X'} \, \Lip(\phi) \, \Lip(\Phi)\, |t-s|, \] where the integral w.r.t. a finitely additive measure is defined in the usual way \cite[\S 4.7(iv)]{bogachevMeasureTheoryVolume2007a}. Thus, the map \(t \mapsto \langle \bm{x}_t , \phi \rangle\) is Lipschitz on $I$.  Let us ensure that \( \bm x \) is indeed a solution to \eqref{weak}. To this end, we apply the relation \eqref{psiT} with $s=0$, written as \[ \bm \Psi_{t,0} \phi = \phi + \int_0^t \bm \Psi_{s,0} \mathfrak L_s \phi\d s, \]   and employ the fact that the Lebesgue integral commutes with linear functionals \cite[Sec.~8, Propos.~7]{dinculeanu2014vector}, yielding:  \langle \bm x_t-  \vartheta, \phi\rangle \doteq \langle\vartheta,(\bm \Psi_{t,0}-\id)\phi \rangle = \ &  \Big< \vartheta, \int_0^t \bm \Psi_{s,0} \mathfrak L_s \phi \d s \Big>\\  = \  & \int_0^t \left\langle \vartheta, \bm \Psi_{s,0} \mathfrak L_s \phi\right\rangle \d s \doteq \int_0^{t}\left< \bm x_s,  \mathfrak L_s \phi\right> \d s,  as is claimed.  \smallskip  \textbf{2.} To prove Assertion 2a, let us express:              -\big(\bm \Psi_{t, s+h} - \bm \Psi_{t,s} + h\mathfrak L_s \bm \Psi_{t,s}\big)\phi = \big(\bm \Psi_{s+h,s}  {-} \id  - h\mathfrak L_s\big)\bm \Psi_{t,s+h}\phi + h\mathfrak L_s \big(\bm \Psi_{t, s+h} - \bm \Psi_{t, s}\big)\phi.         Denoting  $\alpha \doteq (a,b)$ and $\phi_\alpha \doteq \bm \Psi_{(b,a)}\phi$, we have the estimate:               \frac{1}{h}\left\|(\bm \Psi_{t, s+h} - \bm \Psi_{t,s} + h\mathfrak L_s \bm \Psi_{t,s})\phi\right\|_{\bm X}  \leq & \frac{1}{h}\sup_{\alpha \in \Delta}\left\|\big(\bm \Psi_{s+h,s}  - \id  - h\mathfrak L_s\big)\phi_\alpha\right\|_{\bm X}\\         & +\left\|\mathfrak L_s \big(\bm \Psi_{t, s+h} - \bm \Psi_{t, s}\big)\phi\right\|_{\bm X}.         Passing to the limit as $h \to 0+$, both terms vanish due to assumption \ref{a5}.     \smallskip     \textbf{3.} It remains to prove Assertion 2b. Let \( \bm y \) be any solution \( I \to \bm X' \) to \eqref{weak}. Fix \( t \in (0,T] \) and \( \phi \in \bm{\mathcal D} \), denote \( \eta_s \doteq \langle \bm y_s, \bm \Psi_{t,s} \phi \rangle \), \( 0 \leq s \leq t \), and assume that \( \eta \) is absolutely continuous on \( [s, T] \).       Let us show that \( \d \eta / \d s = 0 \). To this end, we represent:     \[       \frac{\left\langle \bm y_{s+h}, \bm \Psi_{t, s+h} \phi\right\rangle - \left\langle \bm y_s, \bm \Psi_{t,s} \phi\right\rangle}{h} =       \]       \[       \big\langle \bm y_{s+h}, 1/h\left(\bm \Psi_{t,s+h} - \bm \Psi_{t,s} + h \mathfrak L_s \bm \Psi_{t, s}\right) \phi\big\rangle - \left\langle \bm y_{s+h}, \mathfrak L_s \bm \Psi_{t, s} \phi \right\rangle  +  1/h\langle \bm y_{s+h} - \bm y_s, \bm \Psi_{t,s} \phi\rangle,     \] when \( 0 < s < s+h < t \), and estimate the first term using the Cauchy-Schwartz inequality:              \left|\big\langle \bm y_{s+h}, \phi_{s,t,h}\big\rangle\right| \leq \left\|\phi_{s,t,h}\right\|_{\bm X}\|\bm y_{s+h}\|_{\bm X'},          where \( \phi_{s,t,h} \doteq \frac{1}{h}\left(\bm \Psi_{t,s+h} - \bm \Psi_{t,s}   + h \mathfrak L_s \bm \Psi_{t, s}\right) \phi \).       Letting \( h \to 0+ \), and recalling that the set \( \{\bm y_s\colon s \in I\} \) is \( \|\cdot\|_{\bm X'} \)-bounded, this term      vanishes due to the previous assertion. The second term tends to the value \(-\left\langle \bm y_{s},\mathfrak L_s \bm \Psi_{t, s} \phi \right\rangle\) because \( \bm y \) is weakly* continuous, and the third expression tends to \( \left\langle \bm y_{s},\mathfrak L_s \bm \Psi_{t, s} \phi \right\rangle \) by the very definition of \( \bm y \).           Now, since \( s \mapsto \eta_s \) is constant, we have: \(     \langle \bm y_t, \phi \rangle \doteq \eta_t = \eta_0 \doteq \langle \vartheta , \bm \Psi_{t,0} \phi \rangle \), showing that \( \bm y \) coincides with \( \bm x \) as a functional \( \bm{\mathcal D} \to \F \).",2502.01274
proof,"\textbf{1.} Notice that $U$ is compact in $\bm V'$ w.r.t. the induced weak* topology $\sigma(\bm V', \bm V)$ by the Banach-Alaoglu theorem. In addition, since $\bm V$ is separable, the weak* topology on $U$ is metrizable by a (non-translation-invariant) metric given by \[     d_{U}(\mathrm u^1, \mathrm u^2) = \sum_{i \in \mathbb N} 2^{-i} \left|\langle \mathrm u^1 - \mathrm u^2, \mathrm v_i\rangle\right|, \] for a dense sequence \(\{v_i\}_{i \in \mathbb N} \subset \bm V\). %\cite[pp. 225-273]{Narici Beckenstein 2011} [ 'Topics in Banach Space Theory', page 17].  In other words, we can endow $U$ with the structure of a compact (and, consequently, separable)  metric space $(U, d_{U})$. By the same line of arguments, the set ${\mathcal U}$ is compact in the corresponding (weak* subspace) topology $\sigma({L}^\infty_{w^*}, {L}^1)$. Furthermore, since ${L}^1(I; \bm V)$ inherits the separability of $\bm V$, $\mathcal{U}$ can also be viewed as a compact (and separable) metric space. %$(\mathcal{U}, \rho_{\mathcal U})$.    \textbf{2.} With a slight abuse of notation, we name a representative of the class $u \in \mathcal U$ by the same letter. Following \cite[Theorem I.4.20]{warga1972optimal}, the measurability of a function $u \colon I \to (U, d_{U})$ to a separable metric space is equivalent to the measurability of the functions $t \mapsto d_{U}(u_t, {\mathrm{u}})$ for all $\mathrm{u} \in \bm V'$. By leveraging the above definition of $d_{U}$ and the concept of weak* measurability, we observe that each $t \mapsto d_{U}(u_t, {\mathrm{u}})$ is a countable sum of measurable maps, and therefore, it is also measurable.",2502.01274
proof,"First, note that due to assumption $(a)$, the value \( |\partial_t \xi_t(x_t)| \) is well-defined at all \( t \in J \), and     \[         |\partial_t \xi_t(x_t)| \leq \Lip(\xi),     \]     which shows that \( t \mapsto \partial_t \xi_t(x_t) \) belongs to \( L^1(I) \). Similarly, the subset \( \hat{J} \subset J \) of differentiability points of \( x \) has full Lebesgue measure, and by assumption $(b)$, for all \( t \in \hat{J} \),     \[         \lim_{h \to 0+} \frac{\left| (\Phi^\star_{t, t+h} \xi_t)(x_t) - \xi_t(x_t) \right|}{h} \leq \Lip(\xi) \, \lim_{h \to 0+} \frac{d(x_{t+h}, x_t)}{h} \doteq \Lip(\xi) \, |\dot{x}|_t,     \]     implying that \( t \mapsto (\mathfrak{L}_t \xi_t)(x_t) \) is also in \( L^1(I) \).      Abbreviate \( \mathfrak{L}_t \doteq \mathfrak{L}_t^u \). Recall that \( \xi \circ x \) is differentiable at any \( t \in \hat{J} \), and represent:              \frac{\mathrm{d}}{\mathrm{d}t} (\xi \circ x)_t  = \lim_{h \to 0+} \frac{\xi_{t+h}(x_{t+h}) - \xi_{t+h}(x_{t})}{h} + \lim_{h \to 0+} \frac{\xi_{t+h}(x_t) - \xi_t(x_t)}{h}.       To compute the first limit, we use assumption $(c)$ and the obvious inequality:       \frac{\left|\xi_{t+h}(x_{t+h}) - \xi_{t+h}(x_{t}) - h\mathfrak L_{t} \xi_{t+h}(x_{t})\right|}{h} & \doteq \frac{1}{h}\Big|\big(\left[\Phi^\star_{t, t+h}-\id - h\mathfrak L_t\right]\xi_{t+h}\big){(x_t)}\Big|\\ &\leq \sup_{(s, {\mathrm x})\in I \times \mathcal X}\frac{1}{h}\Big|\big(\left[\Phi^\star_{t, t+h}-\id - h\mathfrak L_t\right]\xi_{s}\big){{(\mathrm x)}}\Big|,  and the uniform equi-differentiability of $(\xi_s)_{s \in \hat J \subset J}$ then implies that \[     \lim_{h \to 0+}\frac{\xi_{t+h}(x_{t+h}) - \xi_{t+h}(x_{t})}{h} =  \mathfrak L_{t} \xi_{t}(x_{t}). \]  Finally, note that the second term of \eqref{proof} coincides with $\partial_t \xi_t(x_t)$, provided by the inclusion $t \in \hat J \subseteq J$.",2502.01274
proof,"Recall that $(\mathcal U =\mathcal U(U), d_U)$ is a compact metric space inheriting the convexity of $U$.   \textbf{1.} Define the functional $\mathfrak N\colon {\mathcal U}\times {\mathcal U}\to \R$ and the set-valued mapping $\mathfrak M \colon {\mathcal U} \rightsquigarrow {\mathcal U}$ by %the expressions \[    \mathfrak N[u,v] \doteq \displaystyle\int_{I}\bm H_t(\bm x_t^{u},  \bar{\bm p}_t, v_t)\,dt \ \text{ and } \ \mathfrak M[u] \doteq  \left\{v\in {\mathcal U}\colon \mathfrak N[u, v]=\inf_{w\in \mathcal U} \mathfrak N[u, w]\right\}. \] Under the made assumptions, the mapping $\mathfrak N$ is continuous in the product topology and linear in the second argument. It follows that $\mathfrak M$ is upper semicontinuous \cite[Theorem~6, p.~53]{aubin1984differential}, and its values are convex subsets of $\mathcal U$. By applying Kakutani's theorem \cite[Corollary~1, p.~85]{aubin1984differential}, we conclude that there exists $\check u \in \mathcal U$ with the property: $\check u\in \mathfrak M[\check u]$.   \textbf{2.} Denote \[\eta_t(\mathrm{u}) \doteq \bm H_t(x_t[\check u], \bar{\bm p}_t, \mathrm{u}),\qquad \alpha_t \doteq \displaystyle\min_{{\rm u} \in U}\eta_t(\mathrm u), \] and provide the obvious estimate      \int_{I} \bm H_t(x_t[\check u], \bar{\bm p}_t, \check {u})\,dt      \doteq      %W[u, u] = \inf_{w\in \mathcal U}W[\check u, w]      \inf_{w\in \mathcal U}\int_I \eta_t(w_t) \d t      \geq \int_{I}\min_{\mathrm{u} \in U} \bm H_t(x_t[\check u], \bar{\bm p}_t, \mathrm{u}) \doteq \int_{I} \alpha_t \d t.   Noticing that the function \( \eta \colon I \times U \to \R\) is Carath\'{e}odory due to the definition of $\bm H$ and assumptions \ref{a8}, and \( \alpha_t\in  \eta_t(U) \) for a.e. \( t \in I \), it follows from Filippov's lemma~\cite[Theorem 8.2.10]{Aubin2009} that there exists a function $\check w \in \mathcal U$ such that \(\alpha = \eta \circ \check w\). Therefore, the above estimate holds with equality, and $\check u$ is a desired solution of \eqref{ucomp}.",2502.01274
proof,"Consider the sequence $(x^N, u^N)$ defined by the sample-and-hold method, using the feedback $\mathfrak u$. Represent:     \[       \int_I h_t(x^N_t, u^N_t) \d t = \sum_k \int_{{I_k^N}}\left[h_t(x^N_t, u^{N,k}_t) - h_{t}({\mathrm x}^N_{k}, u^{N,k}_t)\right]\d t,      \]     and recall that      \(h_{t}({\mathrm x}^N_{k}, u^{N,k}_t) = 0\) for a.e. $t \in {I_k^N} \doteq [t_k^N, t_{k+1}^N]$, all $k = 0, \ldots, N$, and any $N \geq 1$, by assumption of the assertion.     Each term in the latter sum is estimated as                      \int_{{I_k^N}}\left[h_t(x^N_t, u^{N,k}_t) - h_{t}(\mathrm x^N_{k}, u^{N,k}_t)\right]\d t \leq & \ \Lip_{\mathcal K}(h) \int_{{I_k^N}}d(x^N_t,\mathrm x^N_{k})\notag\\                  \leq & \  \Lip_{\mathcal K}(h) \Lip(\Phi) |\pi^N|^2\notag\\                  \doteq & \,  O\left(\frac{1}{N^2}\right)>0.          Therefore, \[         0\leq \int_I h_t(x^N_t, u^N_t) \d t \leq O\left(\frac{1}{N^2}\right) N \doteq  O\left(\frac{1}{N}\right)>0.     \]     Let $x=x^{u}$. As a consequence,          0 & \leq          \int_I h_t(x_t, u_t)\d t\\          & \leq  \left|\int_I \left[h_t(x_t, u_t) - h_t(x^N_t, u^N_t)\right] \d t\right|+ O\left(\frac{1}{N}\right)\\                & \leq \left|\int_I \left[h_t(x_t, u_t) - h_t(x_t, u^N_t)\right] \d t\right| + \int_I \left|h_t(x_t, u_t^N) - h_t(x^N_t, u^N_t)\right| \d t+ O\left(\frac{1}{N}\right)\\               & \leq \left|\int_I \left[h_t(x_t, u_t) - h_t(x_t, u^N_t)\right] \d t\right| + \Lip(h)\int_I d\big(x_t, x^N_t\big)\d t+ O\left(\frac{1}{N}\right).          Passing to a partial limit as $u^{N_j} \to u$,     we conclude that     \[       \int_I h_t(x_t, u_t)\d t =  0.     \]   To complete the proof, it only remains to leverage the non-negativity of the integrand.",2502.01274
proof,"The result follows from the previous assertion, provided by the choice     \(         \displaystyle h_t(\mathrm x, \mathrm{u}) \doteq  \bar H_t ({\rm x, u}) - \min_{{\mathrm u} \in U} \bar H_t(\mathrm{ x}, {\mathrm u}).     \)",2502.01274
proof,"We split the proof into several steps.    \textbf{1.} Consider the identity:        F_{t} &\left(X_t(\mathrm{x}) + \varepsilon v(\mathrm{x}), (X_t + \varepsilon v)_{\sharp}\mu  \right) - F_{t}\left(X_t(\mathrm{x}),X_{t\sharp}\mu\right)\notag\\     &= F_{t} \left( X_t(\mathrm{x}) + \varepsilon v(\mathrm{x}), (X_t + \varepsilon v)_{\sharp}\mu  \right) - F_{t} \left( X_t(\mathrm{x}), (X_t + \varepsilon v)_{\sharp}\mu  \right)\notag\\     &+ F_{t} \left( X_t(\mathrm{x}), (X_t + \varepsilon v)_{\sharp}\mu  \right) - F_{t}(X_t(\mathrm{x}),X_{t\sharp}\mu).           By the mean value theorem, the first difference in the right-hand side takes the form:        \varepsilon\int_{0}^{1} DF_{t} \left( X_t(\mathrm{x}) + s\varepsilon v(\mathrm{x}), (X_t + \varepsilon v)_{\sharp}\mu \right)v(\mathrm{x}) \d s,     and, due to the definition of \( \frac{\delta F_t}{\delta \mu} \), the second difference writes:        \int_{0}^{1}     &\int \frac{\delta F_{t}}{\delta \mu} \left(X_t(\mathrm{x}), \mu_{\varepsilon,\tau}, \mathrm{y} \right) \d \left( (X_t + \varepsilon v)_{\sharp}\mu - X_{t\sharp}\mu \right)(\mathrm{y}) \d \tau\\     &= \int_{0}^{1}\int \left[\frac{\delta F_{t}}{\delta \mu} \left(X_t(\mathrm{x}), \mu_{\varepsilon,\tau}, X_t(\mathrm{y}) + \varepsilon v(\mathrm{y}) \right) - \frac{\delta F_{t}}{\delta \mu} \left(X_t(\mathrm{x}), \mu_{\varepsilon,\tau}, X_t(\mathrm{y}) \right)\right] \d \mu(\mathrm{y}) \d \tau\\     &= \varepsilon\int_{0}^{1}\int_{0}^{1}\int \mathbf{D}F_{t} \left(X_t(\mathrm{x}), \mu_{\varepsilon,\tau}, X_t(\mathrm{y}) + s\varepsilon v(\mathrm{y})\right)v(\mathrm{y}) \d \mu(\mathrm{y}) \d s \d \tau,      where \( \mu_{\varepsilon,\tau} = (1-\tau) X_{t\sharp} \mu + \tau (X_t + \varepsilon v)_{\sharp}\mu \).    \textbf{2.} Since \( DF_t \) and \( \mathbf{D}F_t \) are Lipschitz, it holds:        \left| DF_{t} \left( X_t(\mathrm{x}) + s\varepsilon v(\mathrm{x}), (X_t + \varepsilon v)_{\sharp}\mu \right) v(\mathrm{x}) - DF_{t}(X_t(\mathrm{x}), X_{t\sharp}\mu) v(\mathrm{x}) \right|\notag \\     \leq \Lip(DF_{t}) \left( s\varepsilon |v(\mathrm{x})| + W_2\left( (X_t + \varepsilon v)_{\sharp}\mu, X_{t\sharp}\mu \right) \right) |v(\mathrm{x})| \notag \\     \leq \varepsilon \, \Lip(DF_{t}) \left( |v(\mathrm{x})|^2 + \|v\|_{\mu} |v(\mathrm{x})| \right),     \\     \hspace{-12pt}\Big| \int \mathbf{D}F_{t} \left(X_t(\mathrm{x}), \mu_{\varepsilon,\tau}, X_t(\mathrm{y}) + s\varepsilon v(\mathrm{y})\right) v(\mathrm{y}) \d \mu(\mathrm{y}) \notag \\     - \int \mathbf{D}F_{t}\left(X_t(\mathrm{x}), X_{t\sharp}\mu, X_t(\mathrm{y})\right) v(\mathrm{y}) \d \mu(\mathrm{y}) \Big| \notag \\     \leq \Lip(\mathbf{D}F_{t}) \left( W_2\left( X_{t\sharp}\mu, \mu_{\varepsilon,\tau} \right) \int |v(\mathrm{y})| \d \mu(\mathrm{y}) + \varepsilon \|v\|_{\mu}^2 \right).        \textbf{3.} Let us estimate the value \( W_2 \left( \mu, \mu_{h,\tau} \right) \).   To this end, recall that             W_{2}^{2} \left( (1 - \tau) \mu_0 + \tau \mu_1, \nu \right) \leq (1 - \tau) W_{2}^{2} (\mu_0, \nu) + \tau W_{2}^{2} (\mu_1, \nu),      for all \( \mu_0, \mu_1, \nu \in \mathcal{P}_{2}(\mathbb{R}^n) \) and all \( \tau \in [0,1] \).   This inequality becomes evident if we note that, for any \( \Pi_0 \in \Gamma_o(\mu_0, \nu) \) and \( \Pi_1 \in \Gamma_o(\mu_1, \nu) \), the convex combination \( (1 - \tau)\Pi_0 + \tau \Pi_1 \) is a transport plan between \( (1 - \tau) \mu_0 + \tau \mu_1 \) and \( \nu \).   In our case,~\eqref{eq:convex} implies that             W_2 \left( X_{t\sharp}\mu, \mu_{\varepsilon,\tau} \right) \leq \sqrt{\tau} W_2 \left( X_{t\sharp}\mu, (X_t + \varepsilon v)_{\sharp}\mu \right) \leq \sqrt{\tau} \varepsilon \|v\|_{\mu}.         \textbf{4.} By combining the inequalities~\eqref{eq:aux0}--\eqref{eq:aux2}, \eqref{eq:aux3} and integrating with respect to \( \mu \), we obtain the desired estimate.",2502.01274
proof,"\textbf{1.} Consider the following operator: \[ \mathcal{F}(w)_t(\mathrm{x}) \doteq v(\mathrm{x}) + \int_{0}^t \left\{A_s(\mathrm{x}) w_s(\mathrm{x}) + \int B_s(\mathrm{x},\mathrm{y}) w_s(\mathrm{y}) \d \mu(\mathrm{y}) \right\} \, ds, \quad \mathrm{x} \in \mathbb{R}^n, \] which acts from the Banach space \( C\left(I;L^1_{\mu}\right) \) to itself.  Indeed, if \( w \in C\left(I;L^1_{\mu}\right) \), then \[ |\mathcal{F}(w)_t(\mathrm{x})| \le |v(\mathrm{x})| + \int_{0}^t \left( \|A_s\|_{\infty} |w_s(\mathrm{x})| + \|B_s\|_{\infty} \int |w_s(\mathrm{y})| \d \mu(\mathrm{y}) \right) \, ds. \] After integrating, we obtain: \[ \int |\mathcal{F}(w)_t(\mathrm{x})| \, \mu(\mathrm{x}) \le \int |v(\mathrm{x})| \d \mu(\mathrm{x}) + \int_{0}^t \left( \|A_s\|_{\infty} + \|B_s\|_{\infty} \right) \int |w_s(\mathrm{y})| \d \mu(\mathrm{y}) \, ds. \] Therefore, \( \mathcal{F}(w)_t \in L^1_{\mu} \) whenever \( w \in C\left(I;L^1_{\mu}\right) \).  Next, let us check that \( t \mapsto \mathcal{F}(w)_t \) is continuous as a map from \( I \) to \( L^1_{\mu} \).  Indeed, if \( t_1 < t_2 \), then \[ \int |\mathcal{F}(w)_{t_2}(\mathrm{x}) - \mathcal{F}(w)_{t_1}(\mathrm{x})| \d \mu(\mathrm{x}) \le \int_{t_1}^{t_2} \left( \|A_s\|_{\infty} + \|B_s\|_{\infty} \right) \|w_s\|_{L^1_{\mu}} \, ds. \] The integral on the right-hand side clearly vanishes as \( t_1 \to t_2 \).  \textbf{2.} We claim that \( w \to \mathcal{F}(w) \) is a contraction when \( C(I;L^1_{\mu}) \) is equipped with the norm     \|w\|_{\lambda} = \max_{t \in I} \left\{ e^{-\lambda t} \|w_t\|_{L^1_{\mu}} \right\},  and \( \lambda > 0 \) is sufficiently large.  Indeed, for any pair \( w^1, w^2 \in C(I;L^1_{\mu}) \), we have:  &\int \left| \mathcal{F}(w^1)_t(\mathrm{x}) - \mathcal{F}(w^2)_t(\mathrm{x}) \right| \d \mu(\mathrm{x})\\  &\quad \le \int_{0}^t \left( \|A_s\|_{\infty} + \|B_s\|_{\infty} \right) \int |w^1_s(\mathrm{x}) - w^2_s(\mathrm{x})| \d \mu(\mathrm{x}) \d s.  Equivalently, \[ \left\| \mathcal{F}(w^1)_t - \mathcal{F}(w^2)_t \right\|_{L^1_{\mu}} \le \int_{0}^t \left( \|A_s\|_{\infty} + \|B_s\|_{\infty} \right) e^{\lambda s} e^{-\lambda s} \|w^1_s - w^2_s\|_{L^1_{\mu}} \, ds, \] which implies \[ \left\| \mathcal{F}(w^1)_t - \mathcal{F}(w^2)_t \right\|_{L^1_{\mu}} \le \int_{0}^t \left( \|A_s\|_{\infty} + \|B_s\|_{\infty} \right) e^{\lambda s} \, ds \cdot \|w^1 - w^2\|_{\lambda}. \] Using the Cauchy-Schwarz inequality, we then get  \int_{0}^t \left( \|A_s\|_{\infty} + \|B_s\|_{\infty} \right) e^{\lambda s} \, ds &\le \sqrt{\int_{0}^t \left( \|A_s\|_{\infty} + \|B_s\|_{\infty} \right)^2 \, ds} \cdot \sqrt{\int_{0}^t e^{2\lambda s} \, ds} \\ &\le \sqrt{\int_{0}^t \left( \|A_s\|_{\infty} + \|B_s\|_{\infty} \right)^2 \, ds} \cdot \frac{e^{\lambda t}}{\sqrt{2\lambda}}.  Therefore, \[   \left\| \mathcal{F}(w^1) - \mathcal{F}(w^2) \right\|_{\lambda} \le \frac{1}{\sqrt{2\lambda}} \sqrt{\int_{0}^T \left( \|A_s\|_{\infty} + \|B_s\|_{\infty} \right) \, ds} \cdot \|w^1 - w^2\|_{\lambda}, \] which shows that \( \mathcal{F} \) is a contraction if \( \lambda \) is sufficiently large.  Now, by the Banach fixed-point theorem, \( \mathcal{F} \) has a unique fixed point, which, by construction, is the only solution of~\eqref{eq:Alin} that satisfies the initial condition \( w_0 = u \).    \textbf{3.} The linearity of the map \( v \mapsto w_t \) is obvious.  Let us verify that \( v\in {L}^2_{\mu} \) implies that \( w_t\in {L}^2_{\mu} \), for all \( t\in I \).   Fix an arbitrary \( \mathrm{x}\in \mathbb{R}^n \). Then, for all \( t\in I \), it holds         |w_t(\mathrm{x})| \le |v(\mathrm{x})| + \int_{0}^t \left(\|A_s\|_{\infty} |w_s(\mathrm{x})| + \|B_{s}\|_{\infty}\int |w_s(\mathrm{y})|\d \mu(\mathrm{y})\right)\d s.    Next we integrate with respect to \( \mathrm{x} \):   \[    \int |w_t(\mathrm{x})|\d \mu(\mathrm{x}) \le \int|v(\mathrm{x})|\d \mu(\mathrm{x}) + \int_{0}^t \left(\|A_s\|_{\infty}+ \|B_{s}\|_{\infty}\right)\int |w_s(\mathrm{y})|\d \mu(\mathrm{y})\d s,  \]  so that Gr\""onwall's inequality yields:  \[    \int |w_t(\mathrm{x})|\d \mu(\mathrm{x})\le \exp \left\{\int_{0}^t \left(\|A_s\|_{\infty}+ \|B_{s}\|_{\infty}\right)\d s  \right\}\int|v(\mathrm{x})|\d \mu(\mathrm{x}).  \]  We use the previous inequality to estimate the last term form the right in~\eqref{eq:Awle}:  \[     |w_t(\mathrm{x})| \le |v(\mathrm{x})| + \int_{0}^t \|A_s\|_{\infty}|w_s(\mathrm{x})|\d s + g(t)\int|v(\mathrm{x})|\d \mu(\mathrm{x}),   \]   where   \[     g(t) \doteq \int_{0}^t\|B_s\|_{\infty}\,\exp \left\{\int_{0}^s \left(\|A_\tau\|_{\infty}+ \|B_{\tau}\|_{\infty}\right)\d \tau  \right\}\d s.   \]   Once again Gr\""onwall's inequality gives        |w_t(\mathrm{x})| \le \left( |v(\mathrm{x})| + g(t) \int|v(\mathrm{x})|\d \mu(\mathrm{x}) \right) e^{\int_{0}^t\|A_s\|_{\infty}\d s}.      Squaring yields that   \[     |w_t(\mathrm{x})|^2 \le C\left( |v(\mathrm{x})|^{2} + |v(\mathrm{x})| \int|v(\mathrm{x})|\d \mu(\mathrm{x}) + \left(\int|v(\mathrm{x})|\d \mu(\mathrm{x})\right)^2\right)   \]   for some \( C>0 \) depending only on \( \|A\|_{\infty} \) and \( \|B\| _{\infty}\).   By integrating, we obtain:        \int|w_t(\mathrm{x})|^2 \d \mu(\mathrm{x})     &\le C\left( \int|v(\mathrm{x})|^{2}\d\mu(\mathrm{x}) + 2\left(\int|v(\mathrm{x})|\d \mu(\mathrm{x})\right)^2\right)\notag\\     &\le 3C \int|v(\mathrm{x})|^{2}\d\mu(\mathrm{x}),    completing the proof.",2502.01274
proof,"\textbf{1.} Let \( v\in {L}^2_{\mu} \) and \( \mu_{\varepsilon}\doteq(\id+\varepsilon v)_{\sharp}\mu\).   We will write, for brevity, \( X^{\varepsilon}_t \doteq X^{\mu_{\varepsilon}}_{0,t} \). Recall that \( X^\varepsilon \) satisfies \[   \dot X^{\varepsilon}_{t}(\mathrm{x}) = F(X^{\varepsilon}_{t}(\mathrm{x}),X^{\varepsilon}_{t\sharp}\mu_{\varepsilon}),\quad X^{\varepsilon}_{0}(\mathrm{x})=\mathrm{x}. \] By replacing \( \mathrm{x} \) with \( \mathrm{x}+\varepsilon v(\mathrm{x}) \), we obtain \[   \dot X^{\varepsilon}_t\left(\mathrm{x}+\varepsilon v(\mathrm{x})\right) = F_t\left(X^{\varepsilon}_t\left(\mathrm{x}+\varepsilon v(\mathrm{x})\right),X^{\varepsilon}_{t\sharp}\mu_{\varepsilon}\right),\quad X^{\varepsilon}_0\left(\mathrm{x}+\varepsilon v(\mathrm{x})\right)=\mathrm{x}+\varepsilon v(\mathrm{x}). \] Now let \( \varphi^{\varepsilon}_t \doteq X_t^{\varepsilon}\circ (\id + \varepsilon v) \). Then it holds \[   \dot \varphi_t^{\varepsilon}(\mathrm{x}) = F_t\left(\phi_t^{\varepsilon}(\mathrm{x}), \phi_{t\sharp}^{\varepsilon}\mu\right), \quad \phi^{\varepsilon}_0(\mathrm{x}) = \mathrm{x} + \varepsilon v(\mathrm{x}). \]  \textbf{2.} Consider the following map \[   \mathcal{T}(\varepsilon,\varphi)_t(\mathrm{x}) \doteq \mathrm{x} + \varepsilon v(\mathrm{x}) + \int_0^t F_s\left(\phi_s(\mathrm{x}),\phi_{s\sharp}\mu\right)\d s, \] where \( \epsilon\in [0,1] \) and \( \varphi \in C(I;{L}^1_{\mu}) \). The inclusion \( v\in L^2_\mu \) and the boundedness of \( F \) imply that the image of \( \mathcal{T} \) lies in \( C(I;{L}^1_{\mu}) \).  We state that \( \varphi\mapsto \mathcal{T}(\varepsilon,\phi) \) is a contraction if \( C(I;{L}^1_{\mu}) \) is equipped with the norm~\eqref{eq:lambdanorm} and \( \lambda>0 \) is sufficiently large.  Indeed, for any pair of functions \( \phi^{1},\phi^{2} \in C(I;{L}^1_{\mu})\) it holds    \left| \mathcal{T}(\varepsilon,\phi^1)_t(\mathrm{x}) - \mathcal{T}(\varepsilon,\phi^2)_t(\mathrm{x})\right|   &\le M\int_0^t\left\{|\phi^1_s(\mathrm{x}) - \phi^2_s(\mathrm{x})| + W_2\left(\phi^1_{s\sharp}\mu,\phi^2_{s\sharp}\mu\right)\right\}\d s\\   &\le M\int_0^t\left\{|\phi^1_s(\mathrm{x}) - \phi^2_s(\mathrm{x})| + \left\|\phi^1_{s}-\phi^2_{s}\right\|_{\mu}\right\}\d s,  thanks to Assumption \ref{F1}. After integrating, we obtain    \left\| \mathcal{T}(\varepsilon,\phi^1)_t - \mathcal{T}(\varepsilon,\phi^2)_t\right\|_{L^1_\mu}   &\le M\int_0^t\left\{\int\left|\phi^1_s - \phi^2_s\right|\d \mu + \left\|\phi^1_{s}-\phi^2_{s}\right\|_{\mu}\right\}\d s.  Now it follows from \[ \int \left|\phi^1_s-\phi^2_s\right|\d \mu \le \left\|\phi^1_s-\phi^2_s\right\|_{\mu} \] that    \left\| \mathcal{T}(\varepsilon,\phi^1)_t - \mathcal{T}(\varepsilon,\phi^2)_t\right\|_{L^1_\mu}   &\le 2M\int_0^t \left\|\phi^1_{s}-\phi^2_{s}\right\|_{\mu}\d s\\   &\le 2M\int_0^t e^{\lambda s} e^{-\lambda s}\left\|\phi^1_{s}-\phi^2_{s}\right\|_{\mu}\d s\\   &\le 2M\int_0^t e^{\lambda s} \d s \left\|\phi^1-\phi^2\right\|_{C(I;{L}^1_{\mu})}\\   &\le \frac{2M}{\lambda}e^{\lambda t} \left\|\phi^1-\phi^2\right\|_{C(I;{L}^1_{\mu})}  Therefore, \[   \left\| \mathcal{T}(\varepsilon,\phi^1) - \mathcal{T}(\varepsilon,\phi^2)\right\|_{C(I;{L}^1_{\mu})}\le \frac{2M}{\lambda}\left\|\phi^1-\phi^2\right\|_{C(I;{L}^1_{\mu})}, \] meaning that \( \varphi\mapsto \mathcal{T}(\varepsilon,\phi) \) is a contraction if \( \lambda > 2M\).  \textbf{3.} Now we will use Banach's contraction principle as it is stated in~\cite[Theorem A.2.1]{ABressan_BPiccoli_2007a}.  By definition, \( \phi^{\varepsilon} \) defined in the first step is a fixed point of \( \mathcal{T}(\varepsilon,\cdot) \). In terms of~\cite[Theorem A.2.1]{ABressan_BPiccoli_2007a}, we choose \( y = \phi^0 + \varepsilon w \) and \( x(\varepsilon) = \phi^{\varepsilon} \) thus getting     \left\|\phi^0+\varepsilon w - \phi^{\varepsilon}\right\|_{\lambda} \le \kappa \left\|\phi^0+ \varepsilon w - \mathcal{T}\left(\varepsilon,\phi^0+\varepsilon w\right)\right\|_{\lambda}  for \( \kappa = \frac{\lambda}{\lambda-2M} \). Since \( \phi^0_t = X_t\doteq X^{\mu}_{0,t} \), the quantity inside the norm in the right-hand side reads: \[  \int_0^t F_s\left(X_s, X_{s\sharp}\mu\right)\d s + \varepsilon w_t - \varepsilon v - \int_0^t F_s\left(X_s+\varepsilon w_{s}, (X_s+\varepsilon w_s)_{\sharp}\mu\right)\d s. \] By~Lemma~\ref{lem:O2vf}, it holds    \Big\| F_s&\left(X_s+\varepsilon w_{s}, (X_s+\varepsilon w_s)_{\sharp}\mu\right)-   F_s\left(X_s, X_{s\sharp}\mu\right) \\   &-   \varepsilon DF\left(X_s,X_{s\sharp}\mu\right)w_s + \varepsilon\int \mathbf{D}F\left(X_s,X_{s\sharp}\mu,X_s(\mathrm{y})\right)w_s(\mathrm{y})\d \mu\Big\|_{L^1_{\mu}} \le 4M\|w_s\|^2_{\mu}\varepsilon^{2}.  Recalling the definition of \( w \) and the estimate~\eqref{eq:wu}, we conclude that the right-hand side of~\eqref{eq:Aphi} is less that \( C\|v\|^2_{\mu}\varepsilon^{2} \) for some \( C>0 \) depending only on \( F \).  \textbf{4.} Recall the relation with the original notation: \(\phi^0_t = X^{\mu}_{0,t} \) and \( \phi^{\varepsilon}_t = X_{0,t}^{\mu_\varepsilon}\circ(\id +\varepsilon v) \). Hence \( \|\phi^0+\varepsilon w - \phi^{\varepsilon}\|_{\lambda}\le 4C\|v\|^2_{\lambda}\varepsilon^{2} \) implies that \[ \left\|X_{0,t}^{\mu}+\varepsilon w_t - X_{0,t}^{\mu_{\varepsilon}}\circ (\id + \varepsilon u)\right\|_{L^1_\mu}\le C\|v\|^2_{\mu}\varepsilon^{2}, \] for all \( t\in I \). Therefore,    W_1&\left(\Phi_{0,t}\circ (\id + \varepsilon v)_{\sharp}\mu, (\id + \varepsilon w_t)_{\sharp} \Phi_{0,t}(\mu)\right)\\   &=     W_1\left(\left(X^{\mu_{\varepsilon}}_{0,t}\circ (\id + \varepsilon v)\right)_{\sharp}\mu, \left((\id + \varepsilon w_t) \circ X^{\mu}_{0,t}\right)_{\sharp}\mu\right)\\      &\le      \left\|X_{0,t}^{\mu}+\varepsilon w_t - X_{0,t}^{\mu_{\varepsilon}}\circ (\id + \varepsilon v)\right\|_{L^1_{\mu}}\\   &\le C\|v\|^2_{\mu}\varepsilon^{2},  completing the proof.",2502.01274
proof,"\textbf{1.}   Let \( \vartheta_k\to \vartheta \).   Thanks to~\cite[Theorem 6.9]{zbMATH05306371}, it suffices to show that \( \int \varphi \d \mathcal{T}(\vartheta_k)\to \int \phi \d \mathcal{T}(\vartheta) \), for any continuous quadratically bounded function \( \phi \).   Recall that \( \varphi \) is quadratically bounded if \[   |\varphi(\mathrm{x},\mathrm{y})| \le C\left(1+|\mathrm{x}|^2 + |\mathrm{y}|^{2}\right) \quad \forall \mathrm{x},\mathrm{y} \in \mathbb{R}^{n}, \] for a certain \( C>0 \).  Now, due to the definition of \( \mathcal{T} \), we must demonstrate that    \int \varphi \left( \mathrm{x}, \bm\nabla \ell\left(\vartheta_k,\mathrm{x}\right) \right)\vartheta_k(\mathrm{x}) \to   \int \varphi \left( \mathrm{x}, \bm\nabla \ell\left(\vartheta,\mathrm{x}\right) \right)\d \vartheta(\mathrm{x}).      We will prove this in two steps, by showing that        \int \left[\varphi \left( \mathrm{x}, \bm\nabla \ell\left(\vartheta_k,\mathrm{x}\right) \right) -     \varphi \left( \mathrm{x}, \bm\nabla \ell\left(\vartheta,\mathrm{x}\right) \right)\right]\d \vartheta_k(\mathrm{x})\to 0,\\     \int \varphi \left( \mathrm{x}, \bm\nabla \ell\left(\vartheta,\mathrm{x}\right) \right)\d\left[ \vartheta_k - \vartheta\right](\mathrm{x})\to 0.       \textbf{2.} Let us prove~\eqref{eq:gamma1}.   Since \( \varphi \) is continuous, for any \( \varepsilon>0 \) there exists \( \delta>0 \) such that   \[     \left|\varphi \left( \mathrm{x}, \bm\nabla \ell\left(\vartheta_k,\mathrm{x}\right)\right) -     \varphi \left( \mathrm{x}, \bm\nabla \ell\left(\vartheta_k,\mathrm{x}\right) \right)\right|< \varepsilon   \]   as soon as        \left|\bm\nabla \ell\left(\vartheta_k,\mathrm{x}\right)     -\bm\nabla \ell\left(\vartheta,\mathrm{x}\right)     \right|\le \Lip(\bm\nabla \ell)W_2\left(\vartheta_k,\vartheta\right)<\delta.      Therefore, for any \( \varepsilon>0 \) there exists \( N\in \mathbb{N} \) such that \[   \int \left[\varphi \left( \mathrm{x}, \bm\nabla \ell\left(\vartheta_k,\mathrm{x}\right) \right) -   \varphi \left( \mathrm{x}, \bm\nabla \ell\left(\vartheta, \mathrm{x}\right) \right)\right]\d \vartheta_k(\mathrm{x})< \varepsilon, \] for all \( k\ge N \). Thus~\eqref{eq:gamma1} indeed holds.  \textbf{3.} Since both functions \( \varphi \) and \( x\mapsto \bm \nabla \ell(\vartheta,x) \) are continuous, their composition \( \mathrm{x}\mapsto \phi \left( \mathrm{x}, \bm\nabla \ell\left(\vartheta,\mathrm{x}\right)\right) \)  is continuous as well.   Let us check that the composition is quadratically bounded.   In fact, it follows from   \[     \left|\varphi \left( \mathrm{x}, \bm\nabla \ell\left(\vartheta,\mathrm{x}\right)\right)   \right|\le C \left( 1+ |\mathrm{x}|^2 + \left|\bm\nabla \ell\left(\vartheta,\mathrm{x}\right)\right|^2 \right) \quad \forall \mathrm{x}\in \mathbb{R}^n    \]    and the boundedness of \( \bm \nabla \ell \).    Now,~\eqref{eq:gamma2} follows from~\cite[Theorem 6.9]{zbMATH05306371}.",2502.01274
proof,"Let \( t^k\to t \) and \( \gamma^k\to \gamma \).   Consider the following difference        \iint \mathrm{y}\cdot g_s(\pi^1_{\sharp}\gamma^k_{t^k},\mathrm{x})\d \gamma^k_{t^k}(\mathrm{x},\mathrm{y}) &-     \iint \mathrm{y}\cdot g_s(\pi^1_{\sharp}\gamma_t,\mathrm{x})\d \gamma_{t}(\mathrm{x},\mathrm{y})\notag\\     &\le     \iint \mathrm{y}\cdot \left[g_s\left(\pi^1_{\sharp}\gamma^k_{t^k},\mathrm{x}\right)-g_s\left(\pi^1_{\sharp}\gamma_{t},\mathrm{x}\right)\right]\d \gamma^{k}_{t^k}(\mathrm{x},\mathrm{y})\notag\\     &+     \iint y\cdot g_s\left(\pi^1_{\sharp}\gamma_t,\mathrm{x}\right)\d \left[\gamma^k_{t^k}(\mathrm{x},\mathrm{y})-\gamma_t(\mathrm{x},\mathrm{y})\right]      and show that every term in the right-hand side vanishes as \( k\to \infty \).    Due to Lipschitz continuity of \( g_s \) and \( \pi^1 \), it holds  \left|g_s\left(\pi^1_{\sharp}\gamma^k_{t^k},\mathrm{x}\right)-g_s\left(\pi^1_{\sharp}\gamma_{t},\mathrm{x}\right)\right| & \leq MW_2(\gamma^k_{t^k},\gamma_t)\\ & \leq M \left( W_2(\gamma^k_{t^k},\gamma_{t^k}) + W_2(\gamma_{t^k},\gamma_t) \right)\to 0,  for all \( \mathrm{x}\in \mathbb{R}^n \). Moreover, by~\cite[Theorem 6.9]{zbMATH05306371}, \( \iint \mathrm{y}\d\gamma^k_{t^k}\to \iint \mathrm{y}\d \gamma_{t} \).   Therefore,        \iint \mathrm{y}\cdot \left[g_s\left(\pi^1_{\sharp}\gamma^k_{t^k},\mathrm{x}\right)-g_s\left(\pi^1_{\sharp}\gamma_{t},\mathrm{x}\right)\right]\d \gamma^{k}_{t^k}(\mathrm{x},\mathrm{y})\to 0.       Consider now the second term in the right-hand side of~\eqref{eq:key1}.   By our assumptions, the map \( (\mathrm{x},\mathrm{y})\mapsto \mathrm{y}\cdot g_s(\pi^1_{\sharp}\gamma_t,\mathrm{x}) \) is continuous.   Moreover, it is linearly (and thus quadratically) bounded since \( |\mathrm{y}\cdot g_s(\mu,\mathrm{x})|\le |\mathrm{y}|M \), where \( M \) is an upper bound of \( |g| \).   Thus             \iint \mathrm{y}\cdot g_s\left(\pi^1_{\sharp}\gamma_t,\mathrm{x}\right)\d \left[\gamma^k_{t_k}(\mathrm{x},\mathrm{y})-\gamma_t(\mathrm{x},\mathrm{y})\right]\to 0,    by~\cite[Theorem 6.9]{zbMATH05306371}.",2502.01274
proof,"Note that    \frac{1}{h}\int_t^{t+h}\left|f(s,t)-f(t,t)\right|\d s & \le \frac{1}{h}\int_t^{t+h}\left|f(s,t)-f(s,s)\right|\d s\\ & + \frac{1}{h}\int_t^{t+h}\left|f(s,s)-f(t,t)\right|\d s.            Since \( f \) is a Carath\'eodory function, the map \( t \mapsto f(t,t) \) is Lebesgue measurable.   Therefore, \[ \frac{1}{h}\int_t^{t+h}\left|f(s,s)-f(t,t)\right|\d s \to 0, \] for a.e. \( t\in [0,1] \).  By our assumptions, for any \( \varepsilon>0 \) there exists \( \delta>0 \) such that \[ |s-t|<\delta \quad \implies \quad |f(s,t)-f(s,s)|<\varepsilon. \] Thus for all \( h<\delta \) we have \[   \frac{1}{h}\int_t^{t+h}\left|f(s,t)-f(s,s)\right|\d s<   \frac{1}{h}\int_t^{t+h}\varepsilon\d s = \varepsilon. \] Hence \( \frac{1}{h}\int_t^{t+h}\left|f(s,t)-f(s,s)\right|\d s \to 0\) for all \( t\in [0,1] \). This observation completes the proof.",2502.01274
proposition,"Let \( u \in \mathcal{U} \) be fixed, \( (x, p) \) be the corresponding state and adjoint trajectories, and $\bm p$ be defined by \eqref{LCadj}. Then, the equality \( \nabla \bm{p}_t(x(t)) = p(t) \) holds for all \( t \in I \).",2502.01274
proposition,"In addition to~\ref{a0}, suppose that \( f \) and \( \ell \) are \( C^\infty \) maps in \( \mathrm x \). %, and their second partial derivatives are Lipschitz in \( (\rm x,u) \) uniformly w.r.t. \( t \).   Then, for \( u^{\varepsilon} \) defined as in~\eqref{eq:perturb}, it holds        \widetilde{\mathcal I}[u^{\varepsilon}] - \widetilde{\mathcal I}[\bar{u}]     &= \varepsilon\int_I \bar{p}(t)\cdot f_t \left(\bar{x}(t), u_t - \bar{u}_t \right)\, dt \notag\\     &+\varepsilon^2\int_I \left( \bar{P}(t)^{\T} f_t\left(\bar{x}(t),u_t - \bar{u}_t \right) + Df_t\left(\bar{x}(t),u_t - \bar{u}_t \right)^{\T}\bar{p}(t)  \right)\cdot \bar{y}(t)\, dt\notag \\     &+ o(\varepsilon^2),         where \( \bar{p} \) is the co-trajectory corresponding to \( \bar{u} \), \( \bar{P} \) satisfies the matrix Riccati equation     \dot P = - Df[t]^{\T} P - P Df[t] - D^2H[t], \quad P(T)=-D^2\ell(\bar{x}(T)),  and \( \bar{y} \) is a solution of the linearized equation     \dot y = Df[t] \, y + f_t(\bar{x},u_{t}-\bar{u}_{t}),\quad y(0) = 0,  with \[   Df[t] \doteq Df_t(\bar{x}(t), \bar{u}_t), \quad D^2H[t] \doteq D^2H_t(\bar{x}(t),\bar{p}(t),\bar{u}_t). \]  Moreover, it holds \[   \bar{p}(t) = \nabla \bar{\bm p}_t(\bar{x}(t)),\quad   \bar{P}(t) = D^2 \bar{\bm p}_t(\bar{x}(t)), \quad t \in I, \] where $D^2$ stands for the Hessian matrix.",2502.01274
proposition,"Let Assumptions \ref{F1} hold. [\rm (1)]   \item For each \( \mu\in \mathcal{P}_{2} \), there exists a unique map \(X^{\mu}\colon  I \times I\times \mathbb{R}^d \to \mathbb{R}^d \) satisfying the differential equation \[   \frac{d}{dt} X^{\mu}_{s,t} = F_t\left(X^{\mu}_{s,t},X^{\mu}_{s,t\sharp}\mu\right),\quad X^{\mu}_{s,t}=\id. 				\]   \item The map \( \Phi\colon  I \times  I \times \mathcal{P}_2\to \mathcal{P}_2 \), defined by the rule \( \Phi_{s,t}(\mu) \doteq (X^{\mu}_{s,t})_\sharp \mu \), is the flow of the dynamical system                     \partial_t \varrho_t + \div(F_t(\varrho_t)\,\varrho_t) = 0.                     In other words, \(t \mapsto \mu_t = \Phi_{s,t}(\vartheta) \) is a unique distributional solution to the equation~\eqref{eq:nlcont} with the initial condition \( \mu_{s} = \vartheta \).  \item The map \( (s,t,\mu)\mapsto \Phi_{s,t}(\mu) \) is \( M \)-Lipschitz as a function of \( t \) or \( s \), and \( L \)-Lipschitz as a function of \( \mu \), with some \( L>0 \) depending only on \( M \) and \( T \).",2502.01274
proposition,"[Pushforward of vectors]      Let the nonlocal vector field \( F \) satisfy \ref{F1} and \ref{F2}, and let \( \Phi \) denote its flow.   Then, for each \( a,b\in I \), the function \( \Phi_{a,b} \colon \mathcal{P}_2 \to \mathcal{P}_2 \) is uniformly differentiable with a constant \( C>0 \) depending only on \( F \).   Its derivative \( (\Phi_{a,b})_{\star,\mu}\colon {L}^2_{\mu}\to L^{2}_{\Phi_{a,b}(\mu)} \) acts as \( v_a \mapsto v_b \). Here, the time-dependent vector field \( v_t\in L^{2}_{\mu_t} \) is defined along the curve \(t \mapsto \mu_{t}= \Phi_{a,t}(\mu)\) as  \( v_t \doteq w_t\circ (X^{\mu}_{a,t})^{-1} \), where \( w \) is a unique solution to the linear equation        \partial_t w_t(\mathrm{x}) = & \ DF_t\left(X^{\mu}_{a,t}(\mathrm{x}),X^{\mu}_{a,t\sharp}\mu\right)w_t(\mathrm{x}) \nonumber\\     + &  \,\int\mathbf{D}F_t\left(X^{\mu}_{a,t}(\mathrm{x}),X^{\mu}_{a,t\sharp}\mu, X^{\mu}_{a,t}(\mathrm{y})\right)w_t(\mathrm{y})\d\mu(\mathrm{y}),      with the initial condition \( w_{a}(\mathrm{x}) = v_a(\mathrm{x}) \).",2502.01274
proposition,"[Pullback of covectors]    Let the nonlocal vector field \( F \) satisfy assumptions~\ref{F1} and \ref{F2}, and let \( \Phi \) denote its flow.   The map \( (\Phi_{a,b})^{\star}_{\mu}\colon L^2_{\Phi_{a,b}(\mu)}\to L^{2}_{\mu} \) acts as \(   p_b \mapsto p_a \).   Here, the time-dependent vector field \( p_t\in L^2_{\mu_t} \) is defined along the curve \( \mu_t = \Phi_{a,t}(\mu) \) by the formula   \[   p_t({\rm x}) \doteq \int {\rm y}\d \gamma^{\rm x}_t({\rm y}), % \doteq \mathcal{B}(\gamma_t)(x).   \] with \( \gamma \) being a unique solution to the Hamiltonian equation         \partial_t \gamma_t + \mathrm{div}_{({\rm x,y})}\left( {\mathbb J}_{2n}\bm \nabla\mathcal{H}_t(\gamma_{t})\right) = 0,\quad \gamma_b = (\id, p_b)_{\sharp}\mu_b,    where \[ \mathcal{H}_t(\gamma) = \iint{\rm  y}\cdot F_t(\pi^1_{\sharp}\gamma,{\rm x})\d \gamma({\rm x,y}), \] the family \( \gamma^{\rm x}_t \) is obtained by disintegration of \( \gamma_t \) w.r.t. \(\mu_t\), and \( \mathbb J_{2n} \) is the symplectic matrix $\left({cc}     0 & \id  \\    -\id  & 0 \right)$ of dimension \( {2n} \).",2502.01274
proposition,"Let \( u \in {\mathcal U}\), and \( \Phi \doteq \Phi^u \) be the flow of \( F_t(\cdot,u_t) \).  Let \( g \) be a time-dependent vector field on \( \mathcal{P}_2 \) satisfying Assumption \ref{F1}. Then,  [{\rm (1)}]   \item The family $\{\mathbf{p}_t\}_{t \in I}$, defined by~\eqref{p-repr}, is uniformly equidifferentiable.     \item For any \( s\in I \), the map \( I \times \mathcal{P}_2 \to \mathbb{R} \) given by      \[       (t,\mu) \mapsto \left< \bm \nabla \mathbf{p}_{t}(\mu), g_s(\mu) \right>_{\mu}     \]     is continuous.    \item For any compact set  \( \mathcal{K} \subset \mathcal{P}_2 \), the family of functions \( \mathcal{K} \to \mathbb{R} \) given by     \[     \mu \mapsto \left< \bm \nabla \mathbf{p}_{t}(\mu), g_t(\mu) \right>_{\mu}, \quad t\in I,     \]     is equicontinuous.",2502.01274
proposition,The map \eqref{p-repr} is a mild solution to~\eqref{eq:Wadjoint}.,2502.01274
proposition,"Let \( g \) be a time-dependent vector field on \( \mathcal{P}_2 \) satisfying Assumption~\ref{F1}, \( t\mapsto \mu_t \) be any of its trajectories, and \( \bm p \) be defined as in \eqref{p-repr}.   Then, for a.a. \( t\in I \), the function \( t\mapsto \bm p_t(\mu_t) \) is absolutely continuous, and        \frac{\d}{\d{t}} \bm p_t(\mu_t)     &=\partial_t \bm p_t(\mu_t) + (\mathbf{d} \bm p_t)_{\mu_t}(g_t)\nonumber\\     &=\left< \bm \nabla \bm p_t(\mu_t),g_t(\mu_t) - F_t(\mu_t,u_t)\right>_{\mu_t}.",2502.01274
proposition,"Let \( u \in \mathcal U \), \( \mu_t \) and \( p_t \) be the corresponding primal and co-trajectories, and \( \bm p_t \) the associated solution to the super-adjoint system~\eqref{eq:Wadjoint}.   Then \( \bm \nabla \bm p_t(\mu_t) = p_t \) for all \( t\in I \).",2502.01274
proposition,"Let $\bm{\mathcal D} \subset C^{1\text{-}\Phi}(\mathcal{X})$ consist of bounded Lipschitz functions.   \item Assume \ref{a4}. Then, for any $\vartheta \in \bm{X}'$, the function $\bm{x}\colon I \to \bm{X}'$, defined by the actions  \[ \langle \bm{x}_t, \phi\rangle \doteq \langle \bm \Phi_{0, t}\vartheta,\phi \rangle \doteq \langle\vartheta,\bm{\Psi}_{t,0}\phi\rangle,\quad t \in I, \quad \phi \in \bm{X}, \] is a distributional solution to the initial value problem \eqref{X} with the class $\bm{\mathcal D}$ of tests functions, namely, the following Newton-Leibniz formula holds:   \langle \bm{x}_t - \vartheta, \phi \rangle  = \int_0^t \langle \bm{x}_s, \mathfrak{L}_s \phi \rangle \d s, \quad t \in I, \quad \phi \in \bm{\mathcal D}.    \item In addition to \ref{a4}, suppose the following regularity (see Remark~\ref{rem:a}(b) below):   ~           \item For any $\phi\in \bm{\mathcal D}$,  the family \((\phi_{\alpha} \doteq \bm{\Psi}_{b,a} \phi )_{\alpha = (a,b) \in \Delta}\) is uniformly equidifferentiable w.r.t. $\Phi$.           \item Moreover, the equality         \[         \lim_{h\to 0+}\left\|\mathfrak{L}_s \left(\bm{\Psi}_{t, s+h} - \bm{\Psi}_{t,s}\right)\phi\right\|_{\bm{X}} = 0 %\doteq \lim_{h\to 0+}\sup_{\mathcal{X}}\left|\mathfrak{L}_s \left(\phi\circ\Phi_{s+h, t} - \phi \circ\Phi_{s,t}\right)(\mathrm{x})\right|          \]         holds for all $\phi \in \bm{\mathcal D}$, $t \in (0, T]$, and a.a. $0 \leq s < t$.                   Then,     [2a.]         \item  the family $\mathfrak{L} = (\mathfrak{L}_t)_{t \in I}$ of linear operators \eqref{L} generates the linear backward dynamical system $\bm{\Psi}$ on $\bm{\mathcal D}$, i.e., for any $\phi \in \bm{\mathcal D}$, every $t \in (0, T]$, and a.a. $0 \leq s < t$, it holds:                   \lim_{h \to 0+}\frac{1}{h}\left\|\left(\bm{\Psi}_{t, s+h} - \bm{\Psi}_{t,s} + h \mathfrak{L}_s \bm{\Psi}_{t, s}\right)\phi\right\|_{\bm{X}} = 0.                    \item  The function $\bm x$ is a unique solution to \eqref{weak} in the sense that any distributional solution $\bm{y}$  to \eqref{X}, such that all maps $s \mapsto \langle \bm{y}_s, \bm{\Psi}_{t,s} \phi\rangle$, $\phi \in \bm{\mathcal D}$, are absolutely continuous, coincides with $\bm{x}$ on $\bm{\mathcal D}$ (Remark~\ref{rem:a}(b)).",2502.01274
proposition,"Let $\mathcal{X}$, $\Phi$, and $f$ be as in Example~\ref{ex_5}. Additionally, assume that \( Df_t \) is uniformly Lipschitz in \( t \in I \). Then:      [i)]         \item the class \( \bm{\mathcal D} \) of test functions can be specified as \( C^{1,1}_b(\R^n) \), the collection of bounded \( C^1 \)-functions with bounded Lipschitz gradients, and          \item with this choice of \( \bm{\mathcal D} \), assumptions \ref{a5} are fulfilled.",2502.01274
proposition,"Assume that $\bm V$ is separable. Then,          \item $\mathcal U$ is compactly metrizable.     \item Each representative of the class $u \in \mathcal U$ is measurable in the preimage sense.",2502.01274
proposition,"The control systems, introduced in Examples \ref{ex1} and \ref{ex:2}, are well-posed, that is, the corresponding ODEs have unique solutions on $I$, for any $u$ from the corresponding set $\mathcal U$, and, moreover, the operators $u \mapsto x^{u}$ are continuous as $\mathcal U \to C_b(\R^n)$.",2502.01274
proposition,"Under the assumptions of Lemma~\ref{coro:bmp}, \(\bar{\bm{p}}\) is a mild solution to the backward Cauchy problem      \dot{\bm{p}}_t \doteq \partial_t \bar{\bm{p}}_t = - \mathfrak{L}_t^{\bar u} \, \bm{p}_t, \quad \bm{p}_T = \ell.",2502.01274
proposition,"The duality relation \eqref{d-w} holds for any Banach space $\bm V$, provided by the pairing \eqref{wp*}.",2502.01274
proposition,"Let $\bar H$ satisfy all hypotheses of Lemma~\ref{lem:sampl}, except for non-negativity, and $\mathfrak{u}=(u^{\rm x})$ be defined as a measurable family of solutions $u^{\rm x} \in \mathcal U$ to~%6of solutions $u^{\rm x} \in \mathcal U$ to: \[  \bar H_t (\mathrm x, u^{\mathrm x}_t) = \min_{{\mathrm u} \in U} \bar H_t(\mathrm{ x}, {\mathrm u}). \]     Then, any open-loop control \(u = u[\mathfrak{u}]\) generated by $\mathfrak{u}$ validates \eqref{u-comp}, i.e., $u\in {\bar{\mathcal U}}_\text{ext}$.",2502.01274
lemma,"[\!\!{\cite[Theorem 2.3.2]{ABressan_BPiccoli_2007a}}]   Let \( u \in \mathcal U\), and \( \Phi \) be the flow of the vector field \( (t,\mathrm{x}) \mapsto f_t(\mathrm{x}, u_t) \).   Then, for each \( s, t \in I \), the map \( \Phi_{s,t} \colon \mathbb{R}^n \to \mathbb{R}^n \) is differentiable. Its derivative at a point \( \mathrm{x} \in \mathbb{R}^n \) is given by the map \( (\Phi_{s,t})_{\star,\mathrm{x}} \colon T_{\mathrm{x}} \mathbb{R}^n \to T_{\Phi_{s,t}(\mathrm{x})} \mathbb{R}^n \), which acts as \( w(s) \mapsto w(t) \), where \( w \) satisfies the linear equation             \dot{w}(t) = D_\mathrm{x} f_t\left( \Phi_{s,t}(x), u_t \right) w(t).",2502.01274
lemma,"The following statements hold:     [{\rm (i)}]       \item Let \( \Phi\colon \mathcal{P}_2\to \mathcal{P}_2 \) be uniformly differentiable and \( \phi\colon \mathcal{P}_2\to \mathbb{R} \) be uniformly differentiable and Lipschitz w.r.t. the distance \( W_1 \).   Then, the pullback \( \Phi^{\star}\phi\colon \mathcal{P}_2\to \mathbb{R} \) is uniformly differentiable, moreover \[   \Phi^\star(\mathbf{d} \phi) = \mathbf{d}(\Phi^\star \phi). \]  \item Given $\phi$ as above, let a family $(\Phi_t)_{t \in I}$ be uniformly equidif\-fe\-ren\-ti\-able. Then, such is the family \(\left(\Phi^{\star}_t\phi\right)_{t\in I}\).",2502.01274
lemma,"Any function \( \phi \in  \bm{\mathcal D}\) has the following properties:   [{\rm (1)}]     \item \( \phi \) is Lipschitz w.r.t. the distances \( W_1 \) and \( W_2 \).     \item \( \phi \) is differentiable in the sense of Definition~\ref{def:diff_fn} and its gradient \( \bm \nabla \phi \) coincides with \( \nabla\frac{\delta \phi}{\delta \mu}  \).     \item More specifically, \( \phi \) is uniformly differentiable, i.e.,   for all \( \mu\in \mathcal{P}_2 \), \( v \in {L}^2_{\mu} \), and \( \varepsilon\in \mathbb{R} \), we have          \left|\phi \left((\id+\varepsilon v)_{\sharp}\mu  \right) - \phi(\mu) - \varepsilon \mathbf{d}\phi_{\mu}(v)\right| \le 2\Lip(\bm\nabla \phi)\|v\|^2_{\mu} \varepsilon^2.        \item The composition \( t\mapsto \phi(\mu_t) \) with any absolutely continuous curve \( \mu\colon I\to \mathcal{P}_2 \) is absolutely continuous, and      \frac{d}{dt} \phi(\mu_t) = (\mathbf{d}\phi)_{\mu_t}(\dot \mu_t) = \left< \bm \nabla \phi(\mu_t), \dot \mu_t \right>_{\mu_t},  for a.e. \( t\in I \). In fact, this holds even if \( \phi \) is merely Lipschitz continuous and differentiable.",2502.01274
lemma,"Let assumptions \ref{a6} hold, and let $u \in \mathcal{U}$ be arbitrary. Consider a function \( \xi \in C_b(I \times \mathcal{X}) \) satisfying:     [(a)]         \item The maps \( t \mapsto \xi_t(\mathrm{x}) \) are Lipschitz on $I$ with a common Lipschitz constant \( \Lip(\xi) \), independent of $\mathrm{x}$. Furthermore, there exists a set \( J \subset I \) of full Lebesgue measure such that, for each \( t \in J \), the derivative \( \partial_t \xi_t(\mathrm{x}) \) exists for all \( \mathrm{x} \in \mathcal{X} \).         \item The maps \( \mathrm{x} \mapsto \xi_t(\mathrm{x}) \) are Lipschitz on \( \mathcal{X} \) with the same common constant \( \Lip(\xi) \).         \item The family \( (\xi_t)_{t \in J} \) is uniformly equidifferentiable with respect to \( \Phi^u \).          Then, the composition \( t \mapsto (\xi \circ x)_t \), where \( x = x^{u} \), is absolutely continuous. Furthermore, the following Newton-Leibniz formula holds for all \( (s, t) \in \Delta \):              \xi_t(x_t) - \xi_s(x_s) = \int_s^t \left\{ \partial_\tau + \mathfrak{L}^u_\tau \right\} \xi \big|_{x_\tau} \, \mathrm{d} \tau.",2502.01274
lemma,"Provided by Assumption \((a)\) of Lemma~\ref{propos:xi}, let \(\xi\) be a bounded Lipschitz function \(\mathcal{X} \to \mathbb{F}\). Then: [(1)]     \item The map \(s \mapsto (\xi \circ \Phi_{s,t}^{u})(\mathrm{x})\) is Lipschitz on \([0, t]\), uniformly with respect to \(\mathrm{x} \in \mathcal{X}\).     \item The map \(\mathrm{x} \mapsto (\xi \circ \Phi_{s,t}^{u})(\mathrm{x})\) is Lipschitz, uniformly with respect to \((s, t) \in \Delta\).",2502.01274
lemma,"Along with hypotheses \ref{a6}, suppose the following:  %\textbf{Assumption \((A_7)\):}      ~      \item For any \(u \in \mathcal{U}\), the collection \((\bm{\Psi}_{T,s}^{\bar{u}}\ell)_{0 \leq s \leq T}\) is uniformly equidifferentiable with respect to \(\Phi^u\).  \item There exists a subset \(\bar{J} \subset I\) of full Lebesgue measure such that the derivative \(\partial_t \ell(\bar{\Phi}_{t,T}(\mathrm{x}))\) is defined on \(\bar{J}\) for all \(\mathrm{x} \in \mathcal{X}\).    Then, the function \(\bar{\bm{p}}\) defined by \eqref{p-rep} satisfies all assumptions of Lemma~\ref{propos:xi}.",2502.01274
lemma,"If \( F\colon M\to N \) and \( g\colon N\to \mathbb{R} \) are \( C^{1} \) maps, then   \[     F^\star(\mathrm{d}g) = \mathrm{d}(F^\star g).   \]",2502.01274
lemma,"Let a function $h \colon I \times \mathcal X \times U \to \R$, $h = h_t({\rm x}, {\mathrm u})$, be non-negative, measurable in $t$, continuous in $({\rm x, u})$,  and locally Lipschitz in $\rm x$ uniformly w.r.t. $(t, \mathrm u) \in I \times U$. Furthermore, assume that, for any converging sequence $(u^k) \subset \mathcal U$ with a limit $u \in \mathcal U$, it holds: \[     \lim_{k \to \infty}\int_I \left[h_t(x_t^{u}, u_t) - h_t(x_t^{u}, u^k_t)\right] \d t = 0, \] and there exists a family $\mathfrak{u}=(u^{\rm x})$ of controls $u^{\rm x} \in \mathcal U$ such that \[  h_t(\mathrm x, u^{\mathrm x}_t) = 0 \mbox{ for all }\mathrm x\in \mathcal S,\mbox{ and a.e. } t \in I. \]     Then, the equality  \[  h_t(x_t^{u}, u_t) = 0\mbox{ for a.e. }t\in I, \] holds for any open-loop control \(u = u[\mathfrak{u}]\) generated by $\mathfrak{u}$.",2502.01274
lemma,"Let \( F_t(\mathrm{x},\mu) = F_{t}(\mathrm{x},\mu,u_{t}) \) and \( \Phi \) be the corresponding flow.   Fix \( \mu\in \mathcal{P}_2 \) and let \( X_t \doteq X_{0,t}^{\mu} \).   The estimate        \Big\|F_{t} \left( X_{t} + \varepsilon v, (X_t + \varepsilon v)_{\sharp}\mu  \right) - F_{t}(X_t,X_{t\sharp}\mu)  - \varepsilon DF_{t}\left(X_t,X_{t\sharp}\mu\right)v\\     - \varepsilon\int \mathbf{D}F_t\left(X_t,X_{t\sharp}\mu,X_{t}(\mathrm{y})\right)v(\mathrm{y})\d\mu(\mathrm{y})\Big\|_{L^1_\mu} \le 2\left(\Lip(DF_t)+\Lip(\mathbf{D}F_t)\right)\|v\|^2_{\mu}\varepsilon^2      holds for all \( t \in I \), \( v \in {L}^2_{\mu} \), and \( \varepsilon \in \mathbb{R} \).",2502.01274
lemma,"Let \( A \colon I \times \mathbb{R}^n \to \mathcal{L}(\mathbb{R}^n;\mathbb{R}^n) \) and \( B\colon I \times \mathbb{R}^n \times \mathbb{R}^n \to \mathcal{L}(\mathbb{R}^n;\mathbb{R}^n) \) be bounded Carath\'eodory functions, and \( v\in L^1_{\mu} \).   There exists a unique function \( w\colon I \times \mathbb{R}^n\to \mathbb{R}^n \) that satisfies, for all \( \mathrm{x}\in \mathbb{R}^n \), the equation             \partial_t w_t(\mathrm{x}) = A_t(\mathrm{x}) w_t(\mathrm{x}) + \int B_t(\mathrm{x},\mathrm{y}) w_t(\mathrm{y})\d \mu(\mathrm{y})\quad \text{a.e. on } I      and the initial condition \( w_{0}(\mathrm{x}) = v(\mathrm{x}) \).   Moreover, \( v \mapsto w_t \) is a linear bounded map from \( {L}^2_{\mu} \) to itself.",2502.01274
lemma,"Under the assumptions of Proposition~\ref{prop:Wflowdiff} and for any \( v\in {L}^2_{\mu} \) and \( \varepsilon\in \mathbb{R} \), it holds \[ W_1\left(\Phi_{0,t}\circ (\id + \varepsilon v)_{\sharp}\mu, (\id + \varepsilon w_t)_{\sharp} \Phi_{0,t}(\mu)\right) \le C\|v\|^2_{\mu}\varepsilon^2, \] for some \( C>0 \) depending only on \( F \).",2502.01274
lemma,"The map \( \mathcal{T} \colon \mathcal{P}_2(\mathbb{R}^n)\to \mathcal{P}_2(\mathbb{R}^n \times \mathbb{R}^n) \) defined by     \[       \mathcal{T}(\vartheta) = (\id, \bm\nabla \ell(\vartheta))_{\sharp}\vartheta     \]     is continuous.",2502.01274
lemma,"The map \( \mathcal{F}\colon I \times \bm \Gamma \mapsto \mathbb{R} \) defined by    \[      \mathcal{F}(t,\gamma) = \iint y\cdot g_s(\pi^1_{\sharp}\gamma_t,\mathrm{x})\d \gamma_t(\mathrm{x},\mathrm{y})    \]    is continuous.",2502.01274
lemma,"Let \( f \colon [0,1] \times [0,1] \to \mathbb{R} \) be Lebesgue measurable in the first variable and equicontinuous in the second, i.e., for any \( \varepsilon>0 \) there exists \( \delta>0 \) such that \[ |t_1-t_2|<\delta \quad \implies \quad  |f(s,t_{1}) - f(s,t_2)|< \varepsilon, \] for all \( t_{1},t_2\in [0,1] \) and almost all \( s\in [0,1] \). Then \[ \lim_{h\to 0}\frac{1}{h}\int_t^{t+h}\left|f(s,t)-f(t,t)\right|\d s=0, \] for almost all \( t\in [0,1] \).",2502.01274
example,"Remaining within assumptions \ref{a4}, let $\mathcal X = \R^n$, and $\Phi$ be the flow of the control-linear vector field \[f_t(\mathrm x) = \sum_{k=1}^m f^k(\mathrm x) \, u_k(t),\] where $f^k\colon \R^n \to \R^n$ are bounded and Lipschitz, and $u =(u_1, u_2, \ldots, u_m) \in L^\infty(I;U)$ with a compact $U \subset \R^m$.  Then, any function $\phi \in C^1(\R^n) \cap C_b(\R^n)$ with a bounded gradient belongs to $C^{1\text{-}\Phi}(\R^n)$.   This conjecture follows from the fact that operators $\mathfrak{L}_t$ act on elements $\phi \in \bm{\mathcal D}$ as the usual Lie derivatives, $\mathfrak{L}_t \phi = \sum u_k(t)\, \nabla \phi \cdot f^k $, which meet the condition \eqref{Ls} due to the obvious estimate: \[      \int_t^{t+h}\big\|[\mathfrak{L}_s- \mathfrak{L}_t]{\phi}\big\|_{\bm X} \d s \leq \|\nabla \phi\|_{\bm X}\,\max_{k}\|f^k\|_\infty \sum_k \int_t^{t+h}\big|u_k(s)- u_k(t)\big| \d s \] and Lebesgue's differentiation theorem.",2502.01274
example,"Let $\mathcal X = \mathcal P_2$, and $\Phi = \Phi$ be the flow of a nonlocal vector field \( F \colon I \times (\mathbb{R}^n \times \mathcal{P}_2 \times U) \to \mathbb{R}^n \) with the structure  \[F_t(x, \mu) = \sum_{j=1}^m u_j(t) F^j(x, \mu), \] where all $F^j$ satisfy assumptions \ref{F1} and \ref{F2}. Then, any function $\phi \in \bm{\mathcal D}$ satisfies \eqref{Ls}, implying the inclusion $\phi \in C^{1\text{-}\Phi}(\mathcal P_2)$.",2502.01274
example,"Let $\mathcal X$, $\Phi$, $f$ and $\phi$ be as in Example~\ref{ex2}. Assume, in addition, that $\nabla \phi$ and $D f$ are bounded. Then, the functional family $(\phi_\alpha)_\Delta$,  $\alpha \doteq (a, b)$,   $\phi_\alpha \doteq \bm \Psi_{b,a} \phi \doteq \phi\circ \Phi_\alpha$, is uniformly $\Phi$-equidifferentiable. This follows from the estimates:        \big|[\mathfrak{L}_s-\mathfrak L_t] \phi_\alpha\big| & \leq \sum_k\left|\nabla \phi\circ \Phi_{\alpha}\right|\cdot |D \Phi_{\alpha}|\cdot \left|f^k\right|\cdot \big|u_k(t) - u_k(s)\big|,  and the representation \cite[Theorems~2.3.2, 2.2.3]{ABressan_BPiccoli_2007a}: \[     D\Phi_{a,s} = \id + \displaystyle\int_a^s D f_{\tau}(\Phi_{a,\tau})D\Phi_{a,\tau}   \d \tau, \] giving the uniform bound: \[ |D\Phi_\alpha| \leq  \exp\left\{\sum_k\||D f^k|\|_{\bm X}\|u_k\|_{L_1[a,b]}\right\} \] due to Gr\""{o}nwall's lemma.",2502.01274
example,"In addition to the hypotheses of Example~\ref{ex0}, suppose that the maps $DF^j$ and $\bm D F^j$ are bounded. Then, for any $\phi \in \bm{\mathcal D}$, the family $(\phi \circ \Phi_{\alpha})_{\alpha \in \Delta}$ is uniformly equidifferentiable w.r.t. $\Phi$. This fact is established in Appendix~\ref{apex4}",2502.01274
example,"[Lipschitz vector fields as controls] The right-hand side of a Carath\'{e}odory ODE may serve as a control input:          \dot x = f_t(x) \doteq u_t(x), \quad x(0)={\rm x}_0 \in \R^n.  To fit our general construction, let $\bm V$ be the Arens-Eells (Lipschitz free) space $\bm{\mathcal F}(\R^n;\R^m)$ over $\R^n$ (see Remark~\ref{AES} in Appendix~\ref{app:proof-ex12}), and $U$ be a closed ball in the Banach space $\bm V' = \bm{Lip}_0(\R^n, \R^m)$, composed by Lipschitz functions $\mathrm u\colon \R^n \to \R^m$ with the property $\mathrm u(0)=0$, under the Lipschitz norm:     \[     \|\mathrm u\|_{\bm{Lip}_0} = %|u(0)|+     \sup\left\{\displaystyle\frac{|\mathrm u(\mathrm x)-\mathrm u(\mathrm y)|}{|\mathrm{x}-\mathrm{y}|}\colon \mathrm x \neq \mathrm y\right\}.     \]",2502.01274
example,"[$L^{\mathrm{p}}$ vector fields as controls]     Let $\bm V = {L}^{\mathrm{p}}(\R^n; \R^m)$, $1\leq p < \infty$, and $U$ be a closed ball of $\bm V' = {L}^{\rm q}(\R^n; \R^m)$, $\frac{1}{\mathrm p}+\frac{1}{\rm q}=1$. Consider the ODE driven by ``pre-filtered'' feedback controls $u = u_t({\mathrm x})$:              \dot x = \sum_k f^k_t(x)\,  v^k_t(x)% \doteq F_t(x) \, v_t(x),          \quad x(0)={\rm x}_0 \in \R^n;\\ v^k_t \doteq  \eta * u_t^k, \quad u \, {=}\,          (u^1, \ldots, u^m)  \in \mathcal U,\notag          where $f^k$ are sublinear Carath\'{e}odory vector fields, and the convolution kernel $\eta$ belongs to $C_c(\R^n)$ and is Lipschitz on its support.",2502.01274
theorem,"For each pair $\left(m,n\right)\in\left(\mathbb{N}\cup\left\{0\right\}\right)^2$, there is a unique positive solution $q$ to each of the equations $a_n\left(q_{m,n}^{e,\mathrm{BC}}\right)=c_m^{\mathrm{BC}}\left(q_{m,n}^{e,\mathrm{BC}}\right)$ and $ b_n\left(q_{m,n}^{o,\mathrm{BC}}\right)=d_m^\mathrm{BC}\left(q_{m,n}^{o,\mathrm{BC}}\right).$",2502.01291
theorem,"There exists a countable subset $\mathcal{C}\subset\left]0,1\right]$ so that if $b\notin\mathcal{C}$, then each eigenvalue of the Dirichlet or Neumann Laplace operator of the ellipse $\mathcal{E}_{b}$ is simple, i.e., it has multiplicity one.",2502.01291
theorem,"For any $\ep>0$, any ball $B$ of $\mathbb{R}^2$, any $k\in\mathbb{N}$ and any $\vp\in\MW$, there exist a sequence $\lambda_n$ of eigenvalues, a sequence of associated eigenfunctions $u_{n}$ and a sequence of open sets $O_{n,\varphi}\subseteq \mathcal{P}$, depending on $\varphi$ and $\ep$, such that  		|O_{n,\varphi}|=\int_{O_{n,\varphi}}1\ dz\xrightarrow[n\rightarrow\infty]{}\left|\mathcal{P}\right|\text{, along the sequence} 	and  		\left\|\vp-u_{n}\left(z^0+\frac{\cdot}{\sqrt{\lambda_n}}\right)\right\|_{C^k(B)}<\ep, 	for all the $z^0\in O_{n,\varphi}$ and any $n$ large enough.",2502.01291
theorem,"Set any $z^0\in \mathcal{P}$, any $k\in\mathbb{N}$, any $\ep>0$, any ball $B\subset \mathbb{R}^2$ and any $\vp\in\MW$ that satisfies a certain symmetry condition depending on $\mathcal{P}$ and the boundary conditions.  Then we can find a sequence of eigenvalues $\lambda_n$ and an associated sequence of eigenfunctions $u_{n}$ that satisfy   	\left\|\vp-u_{n}\left(z^0+\frac{\cdot}{\sqrt{\lambda_n}}\right)\right\|_{C^k(B)}<\ep, for all $n$ large enough. The conditions over $\vp$ are collected in the Table \ref{TableA} of Appendix \ref{AppendixC}.",2502.01291
theorem,"[Dirichlet's approximation theorem] 		 		Given $\alpha_1,\ldots,\alpha_d$ in $\mathbb{R}$ with at least one of them being irrational, then there are infinitely many $d-$tuples $\left(\frac{r_1}{s},\ldots,\frac{r_d}{s}\right)$ with $\GCD(s,r_1,\ldots,r_d)=1$ and  			\left|\alpha_i-\frac{r_i}{s}\right|<\frac{1}{s^{1+(1/d)}},\ \ \ i=1,\ldots,d.",2502.01291
theorem,"We consider $\mathcal{P}=\mathcal{Q}_1\subset\RR^2$ or $\mathcal{P}=\mathcal{T}_{\mathrm{equi}}\subset\RR^2$ with the Robin condition~\eqref{BCsi}. Let any $k\in\mathbb{N}$ and any ball $B\subset\mathbb{R}^2$. If we ask  $\Sigma=\frac{\sin(\sigma)}{\cos(\sigma)}$ to be well defined, positive and small enough, then in $\Omega$ with the Robin condition associated to $\Sigma$ the inverse localization property fails strongly.",2502.01291
theorem,There exists $\Sigma_0^{Q_1}>0$ so that for all $0<\Sigma<\Sigma_0^{Q_1}$ there are no spectral multiplicities other than the trivial ones $\lambda_{nm}^\Sigma=\lambda_{mn}^\Sigma$.,2502.01291
theorem,"There exists $\Sigma_0^{\mathcal{T}_{\mathrm{equi}}}>0$ so that for all $0<\Sigma<\Sigma_0^{\mathcal{T}_{\mathrm{equi}}}$ there are no spectral multiplicities other than systematic doubling, i.e., other than having symmetric $T_s^{mn}$ and antisymmetric $T_a^{mn}$  eigenfunctions.",2502.01291
theorem,"For any irrational rectangle $\mathcal{Q}_l\subset\RR^d$, i.e., at least one $l_j^2\notin\mathbb{Q}$ for $1\leq j\leq d-1$, with Dirichlet or Neumann boundary conditions and any ball $B\subset\RR^d$, the inverse localization property fails strongly.",2502.01291
theorem,"Let $\mathcal{B}\subset\mathbb{R}^d$ be the centered unit ball, $d\geq2$, and let $B\subset\mathbb{R}^d$ be any ball. If we consider Dirichlet or Neumann boundary conditions, then the inverse localization property fails strongly.",2502.01291
theorem,"Let us fix any ball $B\subset\RR^2$. There exists a countable subset $\mathcal{C}\subset\left]0,1\right]$ so that if $b\notin\mathcal{C}$, then in the ellipse $\mathcal{E}_{b}$ with Dirichlet or Neumann boundary conditions the inverse localization property fails strongly.",2502.01291
theorem,"Let $\Omega\subset\RR^2$ be a rational almost integrable polygon. Let us consider the eigenvalue problem with Dirichlet or Neumann boundary conditions on $\Omega$. Then the following two results of inverse localization are satisfied: 	 \textbf{$\bullet$ inverse localization around a fixed base point}  Pick any $z^0\in \Omega\backslash L_\mathcal{P}$, any $k\in\mathbb{N}$, any $\ep>0$, any ball $B\subset \mathbb{R}^2$ and any $\vp\in\MW$ that satisfies a certain symmetry condition depending on $\mathcal{P}$ and the boundary conditions.  Then we can find a sequence of eigenvalues $\lambda_n$ and an associated sequence of eigenfunctions $u_{n}$ that satisfies   	\left\|\vp-u_{n}\left(z^0+\frac{\cdot}{\sqrt{\lambda_n}}\right)\right\|_{C^k(B)}<\ep, for all $n$ large enough. The conditions over $\vp$ are collected in Table \eqref{TableB} of  Appendix \ref{AppendixC}.  \textbf{$\bullet$ inverse localization without a fixed base point}  For any $\ep>0$, any ball $B$ of $\mathbb{R}^2$, any $k\in\mathbb{N}$ and any $\vp\in\MW$, there exists a sequence $\lambda_n$ of eigenvalues, a finite amount of sequences of associated eigenfunctions $u_{n}^j$ , where $1\leq j\leq J$ and $J$ depends only on $\Omega$, and a sequence of open sets $O_{n,\varphi}\subseteq \Omega$, depending on $\varphi$ and $\ep$, such that  	|O_{n,\varphi}|=\int_{O_{n,\varphi}}1\ dz\xrightarrow[n\rightarrow\infty]{}\left|\Omega\right|\text{, along the sequence} and for any $z^0\in O_{n,\varphi}$ there is one $1\leq j_0\leq J$, such that   	\left\|\vp-u^{j_0}_{n}\left(z^0+\frac{\cdot}{\sqrt{\lambda_n}}\right)\right\|_{C^k(B)}<\ep, for any $n$ large enough.",2502.01291
theorem,"Let $\Omega\subset\mathbb{R}^{2}$ be a rational almost integrable polygon in the lattice $L_\mathcal{P}$ (see Definition \ref{ai})  or $\Omega=\mathcal{Q}_l\subset\mathbb{R}^{d}$ with $ l_i^2\in \mathbb{Q}$ for all $1\leq i\leq d-1$, and consider the eigenvalue problem  with Dirichlet or Neumann conditions. Take any~$M,N\in\NN$, a collection of compact embedded hypersurfaces~$\Si_j$, where $1\leq j\leq N$, of~$\RR^d$ that are not linked, and any positive integer~$k$. Let us consider any $\ep>0$ and any  $z^0\in\Omega$. Then there exist a sequence of eigenvalues $\la_n\to\infty$ and  some~$R>0$ such that for all large enough~$n$ there is an eigenfunction $u_n$ of $\lambda_n$ that has in the ball $B\left(z^0,R\la_n^{-1/2}\right)$ at least~$N$ nodal components of the form 	 	\widetilde\Si_j^n:= \la_n^{-1/2} \,  \Phi_{n}(c_j \Si_j + p_j) 	 	and at least $M$ nondegenerate local extrema. Here $c_j>0$, $p_j\in\RR^d$, and $\Phi_n$ is a diffeomorphism of~$\RR^d$ which is close to the identity: 	$  \|\Phi_n-\id\|_{C^k(\RR^d)}<\ep$.",2502.01291
theorem,"Let $\Omega\subset\mathbb{R}^{2}$ be a rational almost integrable polygon in the lattice $L_\mathcal{P}$ (see Definition \ref{ai})  or $\Omega=\mathcal{Q}_l\subset\mathbb{R}^{d}$ with $ l_i^2\in \mathbb{Q}$ for all $1\leq i\leq d-1$, and consider the associated eigenvalue problem  with Dirichlet or Neumann conditions. Take any $t\in\mathrm{T}$ and any  $z^0\in\Omega$. Then there exists a sequence of eigenvalues $\la_n\to\infty$ and  some~$R>0$ such that for all large enough~$n$ there is an eigenfunction $u_n$ of $\lambda_n$ that has a nodal domain $c\in\mathcal{C}\left(u_n\right)$ with $e(c)=t$ in the ball $B\left(z^0,R\la_n^{-1/2}\right)$.",2502.01291
theorem,"For any solution to Helmholtz $\vp$ in $\MW$, any $\ep>0$, any ball $B\subset\mathbb{R}^d$ and any $k\in\mathbb{N}$ there exists a number $J$ and a positive measure set $M=M(\varphi,k,\ep,J)\subset \mathcal{Q}_1$ such that for any point $z^0\in M$ we have  		\left\|u_{n_J}\left(z^0+\frac{\cdot}{\sqrt{\lambda_{n_J}}}\right)-\vp\right\|_{C^k(B)}<\ep, 	where $\left\{n_j\right\}_{j=1}^\infty$  is a density one subsequence and $u_{n_j}$ are the subsequences that follow. 	 		\item Dirichlet boundary condition: 	u_{n}^\mathrm{D}(z)=\frac{4}{\left|\mathcal{N}_\lambda^{\mathcal{Q}_1,\mathrm{D}}\right|^{1/2}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{Q}_1,\mathrm{D}}}\sin\left(z_1m\pi\right)\sin\left(z_2n\pi\right).  		\item Neumann boundary condition: 		  	u_{n}^\mathrm{N}(z)=\frac{4}{\left|\mathcal{N}_\lambda^{\mathcal{Q}_1,\mathrm{N}}\right|^{1/2}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{Q}_1,\mathrm{N}}}\cos\left(z_1m\pi\right)\cos\left(z_2n\pi\right).",2502.01291
theorem,"[Strong inverse localization where Berry's random wave property is true] 	Let $\Omega$ be a chaotic billiard, with a certain boundary condition, where Berry's random wave property is true in the sense of Statement \ref{BerryLWL}. For any $\vp\in\MW$, any ball $B\subset\RR^d$, any $\ep>0$, any $U\subset\Omega$ open subset and any $k\in\mathbb{N}$, there exist a natural number $J\in\mathbb{N}$ and a positive measure set $M=M(k,\ep,J,\varphi,B, U)\subset U$ such that for any point $z^0\in M\subset U$ we have  		\left\|u_{n_J}\left(z^0+\frac{\cdot}{\sqrt{\lambda_{n_J}}}\right)-\vp\right\|_{C^k(B)}<\ep, 	where $\left\{u_{n_j}\right\}$ is a subsequence of eigenfunctions on $\Om$ with the prescribed boundary condition associated to the sequence $\lambda_{n_j}$ and given by the Berry's random wave property, i.e., satisfying that $	\sigma_\Omega\left(\left\{u_{n_j}\right\}_j\right)=\left\{\muRMW\right\}.$",2502.01291
theorem,"There exists a density one sequence $n_j$ such that we have  		\sigma_{U}\left(\{u_{n_j}\}_j\right)=\left\{\muRMW\right\}, 	 for any Borel set $U\subset\mathbb{T}^2$, where  	 		u_{n_j}(z)=\frac{1}{\left|\mathcal{N}_{\lambda_{n_j}}^{\mathcal{Q}_1,\mathrm{P}}\right|^{1/2}}\sum_{\xi\in\mathcal{N}_{\lambda_{n_j}}^{\mathcal{Q}_1,\mathrm{P}}}e^{2i\pi z\cdot \xi}, 	 is an eigenfunction of the torus $\mathbb{T}^2$ associated to the eigenvalue $\lambda_{n_j}$.",2502.01291
definition,"Modulo isometries and dilations, the {\em integrable polygons}\/ in $\RR^2$ are the following (see Figure~\ref{polygons}): 		 			\item The {\em equilateral triangle}\/ $\mathcal{T}_{\mathrm{equi}}$,  with angles $\frac{\pi}{3},\frac{\pi}{3},\frac{\pi}{3}$. 			\item The {\em isosceles right triangle}\/ $\mathcal{T}_{\mathrm{iso}}$, with angles $\frac{\pi}{2},\frac{\pi}{4},\frac{\pi}{4}$. 			\item The {\em hemiequilateral triangle}\/ $\mathcal{T}_{\mathrm{hemi}}$, with angles $\frac{\pi}{2},\frac{\pi}{3},\frac{\pi}{6}$. 		\item All the {\em rectangles}\/ $\mathcal{Q}_l:=(0,l)\times(0,1)$, with sides $1$ and $l>0$. The rectangle~$\mathcal Q_l$ is said to be {\em rational}\/ if $l^2\in\mathbb{Q}$ and {\em irrational}\/ otherwise.",2502.01291
definition,"We say that $\mathcal{P}\subset\RR^2$ is an {\em almost integrable}\/ polygon if it is drawn on one of the following four lattices: $L_{\mathcal{Q}_{l}}$, $L_{\mathcal{T}_{\mathrm{equi}}}$, $L_{\mathcal{T}_{\mathrm{iso}}}$ or $L_{\mathcal{T}_{\mathrm{hemi}}}$. 	If $\mathcal{P}$ is drawn in the lattice $L_{\mathcal{Q}_{l}}$ for an irrational rectangle  we say that it is an {\em irrational}\/ almost integrable polygon, and otherwise we say it is a {\em rational}\/ one.",2502.01291
definition,"For a fixed ball $B\subset\mathbb{R}^2$ and a bounded domain $\Omega$ with boundary conditions $\mathrm{BC}$ (typically, Dirichlet or Neumann), we say that the \emph{inverse localization property fails strongly}\/ if the set  		\mathcal{N}_{\Omega,\mathrm{BC}}=\left\{\varphi\in \MW^{\mathrm{s}}: \inf_{z^0\in\mathcal{P}}\inf_{\lambda\in \Lambda_\Omega^{\mathrm{BC}}}\inf_{u_\lambda\in\mathcal{V}_{\Omega,\mathrm{BC}}^\lambda}\left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0\left(B\right)}>0\right\}, 	 is dense and open in $\MW^{\mathrm{s}}$ with the topology given by \eqref{norm}. Here $\Lambda_\Omega^{\mathrm{BC}}$ is the set of all eigenvalues in $\Omega$ with $\mathrm{BC}$ boundary conditions, and $\mathcal{V}_{\Omega,\mathrm{BC}}^\lambda$ is the eigenspace associated to $\lambda$ in the same eigenvalue problem.\footnote{By elliptic regularity, we could replace $C^0(B)$ by any other H\""older norm.}",2502.01291
definition,"We shall say that 		 			\mathcal{N}^\mathcal{P}_\lambda=\left\{N\in\mathbb{Z}^d: \mathcal{Q}^\mathcal{P}(N)=\mu=C^\mathcal{P}\cdot\lambda\right\}, 		 		is {\em asymptotically equidistributed}\/ over the ellipsoid 		 			\mathcal{M}^{\mathcal{P}}=\left\{\xi\in\mathbb{R}^d, \mathcal{Q}^{\mathcal{P}}(\xi)=1\right\} 		 		along a certain sequence of $\lambda_n$ if, for every function $f\in C^\infty(\RR^d)$, 		 			\lim_{n\to\infty}\frac1{\#	\mathcal{N}^\mathcal{P}_{\lambda_n}}\sum_{N\in	\mathcal{N}^\mathcal{P}_{\lambda_n}} f\left(\frac{N}{\sqrt{C^\mathcal{P}\lambda}}\right) = \frac1{\left|	\mathcal{M}^{\mathcal{P}}\right|} \int_{	\mathcal{M}^{\mathcal{P}}} f(\eta)\, d\si_{	\mathcal{M}^{\mathcal{P}}}(\eta)\,, 		 		where $d\sigma_{	\mathcal{M}^{\mathcal{P}}}$ and $\left|	\mathcal{M}^{\mathcal{P}}\right|$ are the hypersurface measure form and hypersurface total measure of $	\mathcal{M}^{\mathcal{P}}$.",2502.01291
definition,"We say that $\Omega\subset\RR^2$ is a rational almost integrable polygon if it is drawn on one of the following four lattices:  $L_{\mathcal{T}_{\mathrm{equi}}}$, $L_{\mathcal{T}_{\mathrm{iso}}}$,  $L_{\mathcal{T}_{\mathrm{hemi}}}$ or $L_{\mathcal{Q}_{l}}$ for a rational rectangle  	(i.e., $l^2\in\mathbb{Q}$).",2502.01291
definition,Let $\{\Si_j\}_{j=1}^N\subset\mathbb R^d$ be a collection of smoothly embedded codimension one compact orientable submanifolds without boundary that are pairwise disjoint. We say that the collection $\{\Si_j\}_{j=1}^N\subset\mathbb R^d$ is not linked if there are $N$ pairwise disjoint contractible domains $V_j$ such that each hypersurface is contained in one of them $\Sigma_j\subset V_j$.,2502.01291
definition,"For $z^0\in\Omega$ and $n\in\mathbb{N}$ we define the function $\tilde{u}_{z^0,\mathrm{N}}\in C^\infty_c(\mathbb{R}^d)$, 	 		\tilde{u}_{z^0,\mathrm{N}}(z)=u_n\left(z^0+\frac{z}{\sqrt{\lambda_n}}\right)\chi\left(\frac{|z|}{\sqrt{\lambda_{n}}\dist(z^0,\partial\Omega)}\right), 	where $\chi\in C^\infty_c\left([0,\infty),[0,1]\right)$ is a decreasing function taking value one in a neighborhood of the origin and vanishing outside $[0,1]$.",2502.01291
definition,"For each $n\in\mathbb{N}$ and $z^0\in\Omega$, we have $\tilde{u}_{z^0,\mathrm{N}}\in C^0\left(\RR^d\right)$, so we may define $\delta_{\tilde{u}_{z^0,\mathrm{N}}}\in\mathcal{M}_0$. For any set $U\subset\Omega$ of positive Lebesgue measure, we then define the \emph{local measure} of $u_n$ on $U$ as  		\LM_{U}(u_n):=\frac{1}{\Vol(U)}\int_Udz^0\delta_{\tilde{u}_{z^0,\mathrm{N}}}. 	This defines a probability measure in $\mathcal{M}_0$. Taking $\iota$ as in \eqref{iota} we can also define $\LM_{U}^{\iota}(u_n)\in \left(C_b(\MW)\right)^*$ by 	 		\forall G\in C_b(\MW),\ \left\langle\LM_{U}^{\iota}(u_n),G\right\rangle=\left\langle\LM_{U}(u_n),\iota G\right\rangle.",2502.01291
definition,"We denote by $\sigma_{U}\left(\left\{u_n\right\}_n\right)$ to the set of accumulation points of $\LM_{U}(u_n)$ for the weak$-*$ topology, and by $\sigma_{U}^{\iota}\left(\{u_n\}_n\right)$ the set of accumulation points of $\LM_{U}^{\iota}\left(u_n\right)$ for the weak$-*$ topology.",2502.01291
definition,For any measure $ \nu\in\mathcal{M}$ we say that $\nu$ is the local weak limit of $\{u_n\}_n$ on $U$ if $\sigma_U\left(\left\{u_n\right\}_n\right)=\{\nu\}$.,2502.01291
definition,"[Berry's random monochromatic wave] 		 We call \emph{random isotropic monochromatic wave}, and denote by $\PsiR$, the unique centered stationary Gaussian field on $\mathbb{R}^d$ whose covariance function is 	\mathbb{E}\left[\PsiR(x)\PsiR(y)\right]=\int_{\mathbb{S}^{d-1}}e^{2\pi i(x-y)\theta}d\omega_{d-1}(\theta), where $d\omega_{d-1}$ is the uniform measure on $\mathbb{S}^{d-1}$.  We denote by  $\muRMW$ the Borel measure associated to $\PsiR$, i.e. \begin {equation}\mu_{Berry}:\ &\mathcal{B}(\MW)\rightarrow\mathbb{R}^+_0\\&A\mapsto P(\PsiR\in A).",2502.01291
definition,"[Berrys random wave property]     Let $\Omega\subset\mathbb{R}^d$ be an open set with positive Lebesgue measure. We say that $\Omega$, with boundary conditions $\mathrm{BC}$, satisfies the Berry's Random Wave property if there exist a $\{\lambda_n\}$ a sequence of eigenvalues with full density, and $\{u_n\}_n$ an orthogonal sequence of real-valued eigenfunctions of the Laplacian in $\Omega$ with boundary conditions $\mathrm{BC}$, satisfying $\left\|u_n\right\|_{L^2(\Omega)}^2=\Vol(\Omega)$, and such that its local weak limit in $\Omega$ is $\muRMW$, i.e.,   		\sigma_\Omega\left(\left\{u_n\right\}_n\right)=\left\{\muRMW\right\}.",2502.01291
proof,"Along the whole proof we will be writing $\mathbb{R}^d$ and $d$ should be understood as $d=2$ for all the cases except for $\mathcal{P}=\mathcal{Q}_l$. We split the proof into several parts. Some of them are the same for all $\mathcal{P}$ but for others we will need to differentiate cases. 	 \textbf{	\underline{Step 1:}}	To begin with, we follow \cite[Proposition 2.2]{EPT21} to find a function  		\phi(z):=\sum_{\gamma=1}^{L} \frac{\tilde{c}_\gamma}{\left|z-z^\gamma\right|^{\frac{d}{2}-1}} J_{\frac{d}{2}-1}\left(\left|z-z^\gamma\right|\right) 	 	with large $L>0$, some constants $\tilde{c}_\gamma\in\mathbb{R}$, and points $z^\gamma\in B_R\subset\mathbb{R}^d$ for all $1\leq \gamma\leq L$, where the radius $R\geq 1$ depends on $\vp$ and the approximation error; the function $\phi$	approximates the function $\vp$ in the unit ball as 	 		\|\phi-\varphi\|_{C^k(B)}<\ep/3 . 	 	We invoke \cite[Proposition 2.1]{EPR20} to write  	 		\phi(z)=\sum_{\gamma=1}^{L} c_\gamma\int_{\mathbb{S}^{d-1}}e^{i(z-z^\gamma)\xi}d\sigma_{\mathbb{S}^{d-1}}(\xi)=\sum_{\gamma=1}^{L}c_\gamma\int_{\mathbb{S}^{d-1}}\cos\left((z-z^\gamma)\xi\right)d\sigma_{\mathbb{S}^{d-1}}(\xi),  	with $c_\gamma=\tilde{c}_\gamma\cdot\left(2\pi\right)^{-d/2}$. To pass to the second equality we have used that~$\sin((z-z^\gamma)\xi)=-\sin(-(z-z^\gamma)\xi)$, and the integral of the imaginary part then vanishes. We conclude that 	 		\left\|\vp-\sum_{\gamma=1}^{L}c_\gamma\int_{\mathbb{S}^{d-1}}\cos\left((\cdot-z^\gamma)\xi\right)d\sigma_{\mathbb{S}^{d-1}}(\xi)\right\|_{C^k(B)}<\ep/3 . 	 	 \textbf{	\underline{Step 2:}} For the next step we choose a point $z^0\in \mathcal{P}$ that will be fixed later and we define an eigenfunction $u_\lambda$, with the following general form:  	 		 			&u_\lambda^{\mathcal{P},\mathrm{BC}}\left(z^0+\frac{z}{\sqrt{\lambda}}\right)=\sum_{\gamma=1}^{L}c_\gamma u_{\lambda,\gamma}^{\mathcal{P},\mathrm{BC}}\left(z^0+\frac{z}{\sqrt{\lambda}}\right), 		 	where we set      		 			& u_{\lambda,\gamma}^{\mathcal{P},\mathrm{BC}}\left(z^0+\frac{z}{\sqrt{\lambda}}\right):=\frac{4^{d}}{\#\mathcal{N}_\lambda^{\mathcal{P}}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{P},\mathrm{BC}}}c_{N,\gamma}^{\mathcal{P},\mathrm{BC}}u_N^{\mathcal{P},\mathrm{BC}}\left(z^0+\frac{z}{\sqrt{\lambda}}\right), 		 	whenever $\mathcal{P}\in\left\{\mathcal{Q}_l,\mathcal{T}_\mathrm{iso},\mathcal{T}_\mathrm{hemi}\right\}$. The case of $\mathcal{P}=\mathcal{T}_\mathrm{iso}$ is slightly different, and it will be defined later.      	For any $\gamma$, the precise definitions of all $	c_{N,\gamma}^{\mathcal{P},\mathrm{BC}}$, $u_N^{\mathcal{P},\mathrm{BC}}$, $\mathcal{N}_\lambda^{\mathcal{P}}$, and $\mathcal{N}_\lambda^{\mathcal{P},\mathrm{BC}}$ depend on the polygon $\mathcal{P}$ and the boundary conditions. We refer the reader to Chapter \ref{formulas} for the definitions of the sets $\mathcal{N}_\lambda^{\mathcal{P}}$ and $\mathcal{N}_\lambda^{\mathcal{P},\mathrm{BC}}$. The introduced functions and constants are as follows: 	 		\item For $\mathcal{P}=\mathcal{Q}_l$, we recall that 		 			 				&u_{N}^{\mathcal{Q}_l,\mathrm{D}}\left(z^0+\frac{z}{\sqrt{\lambda}}\right)=\prod_{j=1}^{d}\sin\left(\frac{z^0_jN_j\pi}{l_j}+\frac{z_jN_j\pi}{l_j\sqrt{\lambda}}\right)\text{ and }\\	&u_{N}^{\mathcal{Q}_l,\mathrm{N}}\left(z^0+\frac{z}{\sqrt{\lambda}}\right)=\prod_{j=1}^{d}\cos\left(\frac{z^0_jN_j\pi}{l_j}+\frac{z_jN_j\pi}{l_j\sqrt{\lambda}}\right). 			 		 		And the coefficients are defined as  		 			c_{N,\gamma}^{\mathcal{Q}_l,\mathrm{BC}}=u_N^{\mathcal{Q}_l,\mathrm{BC}}\left(z^0+\frac{z^\gamma}{\sqrt{\lambda}}\right), 		 		\item	In the case of $\mathcal{P}=\mathcal{T}_\mathrm{iso}$, where $N=(m,n)$, we have from the previous chapter that 		 			 				&u_{N}^{\mathcal{T}_\mathrm{iso},\mathrm{D}}\left(z^0+\frac{z}{\sqrt{\lambda}}\right)=\sin\left(\pi m\left(z^0_1+\frac{z_1}{\sqrt{\lambda}}\right)\right)\sin\left(\pi n\left(z^0_2+\frac{z_2}{\sqrt{\lambda}}\right)\right)\text{ and }\\	&u_{N}^{\mathcal{T}_\mathrm{iso},\mathrm{N}}\left(z^0+\frac{z}{\sqrt{\lambda}}\right)=\cos\left(\pi m\left(z^0_1+\frac{z_1}{\sqrt{\lambda}}\right)\right)\cos\left(\pi n\left(z_2^0+\frac{z_2}{\sqrt{\lambda}}\right)\right). 			 		 		We define the coefficients as follows: 		 			 				c_{N,\gamma}^{\mathcal{T}_\mathrm{iso},\mathrm{D}}&=\sin\left(\pi m\left(z_1^0+\frac{z_1^\gamma}{\sqrt{\lambda}}\right)\right)\sin\left(\pi n\left(z_2^0+\frac{z_2^\gamma}{\sqrt{\lambda}}\right)\right)\\&-\sin\left(\pi n\left(z_1^0+\frac{z_1^\gamma}{\sqrt{\lambda}}\right)\right)\sin\left(\pi m\left(z_2^0+\frac{z_2^\gamma}{\sqrt{\lambda}}\right)\right)\text{ and }\\ 				c_{N,\gamma}^{\mathcal{T}_\mathrm{iso},\mathrm{N}}&=\cos\left(\pi m\left(z_1^0+\frac{z_1^\gamma}{\sqrt{\lambda}}\right)\right)\cos\left(\pi n\left(z_2^0+\frac{z_2^\gamma}{\sqrt{\lambda}}\right)\right)\\&+\cos\left(\pi n\left(z_1^0+\frac{z_1^\gamma}{\sqrt{\lambda}}\right)\right)\cos\left(\pi m\left(z_2^0+\frac{z_2^\gamma}{\sqrt{\lambda}}\right)\right). 			 		 		We remark that the coefficients so defined satisfy conditions \eqref{condD} and \eqref{condN}, respectively, and therefore equation \eqref{eigenPNF} defines a proper eigenfunction. 		 		\item  When $\mathcal{P}=	\mathcal{T}_\mathrm{equi}$, as already stated, the structure is a bit different: both $c_{N,\gamma}^{\mathcal{P},\mathrm{BC}}$ and $u_N^{\mathcal{P},\mathrm{BC}}$ are understood as vector valued with two components (one symmetric $S$ and another antisymmetric $A$) and their product as a scalar product. We recall that for any pair $N=(m,n)$, there are now two linearly independent eigenfunctions: 		 			 				&u^{	\mathcal{T}_\mathrm{equi},\mathrm{D}}_{N,S}\left(z^0+\frac{z}{\sqrt{\lambda}}\right)=\sin\left(\frac{2\pi\sqrt{3}n}{3}\left(z^0_2+\frac{z_2}{\sqrt{\lambda}}\right)\right)\cos\left(\frac{2\pi m}{3}\left(z^0_1+\frac{z_1}{\sqrt{\lambda}}\right)\right),\\ 				&u^{	\mathcal{T}_\mathrm{equi},\mathrm{D}}_{N,A}\left(z^0+\frac{z}{\sqrt{\lambda}}\right)=\sin\left(\frac{2\pi\sqrt{3}n}{3}\left(z^0_2+\frac{z_2}{\sqrt{\lambda}}\right)\right)\sin\left(\frac{2\pi m}{3}\left(z^0_1+\frac{z_1}{\sqrt{\lambda}}\right)\right),\\ 				&u^{	\mathcal{T}_\mathrm{equi},\mathrm{N}}_{N,S}\left(z^0+\frac{z}{\sqrt{\lambda}}\right)=\cos\left(\frac{2\pi\sqrt{3}n}{3}\left(z^0_2+\frac{z_2}{\sqrt{\lambda}}\right)\right)\cos\left(\frac{2\pi m}{3}\left(z^0_1+\frac{z_1}{\sqrt{\lambda}}\right)\right),\\ 				&u^{	\mathcal{T}_\mathrm{equi},\mathrm{N}}_{N,A}\left(z^0+\frac{z}{\sqrt{\lambda}}\right)=\cos\left(\frac{2\pi\sqrt{3}n}{3}\left(z^0_2+\frac{z_2}{\sqrt{\lambda}}\right)\right)\sin\left(\frac{2\pi m}{3}\left(z^0_1+\frac{z_1}{\sqrt{\lambda}}\right)\right).\\ 			 		 So we define the following different constants 		 			 				&c_{N,\gamma,S}^{	\mathcal{T}_\mathrm{equi},\mathrm{D}}=u^{	\mathcal{T}_\mathrm{equi},\mathrm{D}}_{N,S}\left(z^0+\frac{z^\gamma}{\sqrt{\lambda}}\right),\ c_{N,\gamma,A}^{	\mathcal{T}_\mathrm{equi},\mathrm{D}}=u^{	\mathcal{T}_\mathrm{equi},\mathrm{D}}_{N,A}\left(z^0+\frac{z^\gamma}{\sqrt{\lambda}}\right),\\ 				&c_{N,\gamma,S}^{	\mathcal{T}_\mathrm{equi},\mathrm{N}}=u^{	\mathcal{T}_\mathrm{equi},\mathrm{N}}_{N,S}\left(z^0+\frac{z^\gamma}{\sqrt{\lambda}}\right),\ c_{N,\gamma,A}^{	\mathcal{T}_\mathrm{equi},\mathrm{N}}=u^{	\mathcal{T}_\mathrm{equi},\mathrm{N}}_{N,A}\left(z^0+\frac{z^\gamma}{\sqrt{\lambda}}\right). 			 		 		And, finally, for any $1\leq\gamma\leq L$ and both boundary conditions, the eigenfunction is defined as  			 				&u_{\lambda,\gamma}^{	\mathcal{T}_\mathrm{equi},\mathrm{BC}}\left(z^0+\frac{z}{\sqrt{\lambda}}\right)=\\&\frac{8}{\#\mathcal{N}_\lambda^{	\mathcal{T}_\mathrm{equi},\mathrm{BC}}}\sum_{N\in\mathcal{N}_\lambda^{	\mathcal{T}_\mathrm{equi},\mathrm{BC}}}\left(c_{N,\gamma,A}^{	\mathcal{T}_\mathrm{equi},\mathrm{BC}}\cdot u_{N,A}^{	\mathcal{T}_\mathrm{equi},\mathrm{BC}}+c_{N,\gamma,S}^{	\mathcal{T}_\mathrm{equi},\mathrm{BC}}\cdot u_{N,S}^{	\mathcal{T}_\mathrm{equi},\mathrm{BC}}\right). 			 		 		Notice also that there is a small change in the constant in front. 		 		\item Finally, for $\mathcal{P}=\mathcal{T}_\mathrm{hemi}$ and $N=(m,n)$, the eigenfunctions are 		 			 				&u^{\mathcal{T}_\mathrm{hemi},\mathrm{D}}_{N}\left(z^0+\frac{z}{\sqrt{\lambda}}\right)=\sin\left(\frac{2\pi\sqrt{3}n}{3}\left(z^0_2+\frac{z_2}{\sqrt{\lambda}}\right)\right)\sin\left(\frac{2\pi m}{3}\left(z^0_1+\frac{z_1}{\sqrt{\lambda}}\right)\right)\text{ and }\\ 				&u^{\mathcal{T}_\mathrm{hemi},\mathrm{N}}_{N}\left(z^0+\frac{z}{\sqrt{\lambda}}\right)=\cos\left(\frac{2\pi\sqrt{3}n}{3}\left(z^0_2+\frac{z_2}{\sqrt{\lambda}}\right)\right)\cos\left(\frac{2\pi m}{3}\left(z^0_1+\frac{z_1}{\sqrt{\lambda}}\right)\right). 			 		 		We again choose coefficients to be 		 			 				&c_{N,\gamma}^{\mathcal{T}_\mathrm{hemi},\mathrm{D}}=u^{\mathcal{T}_\mathrm{hemi},\mathrm{D}}_{N}\left(z^0+\frac{z^\gamma}{\sqrt{\lambda}}\right)\text{ and }\\ 				&c_{N,\gamma}^{\mathcal{T}_\mathrm{hemi},\mathrm{N}}=u^{\mathcal{T}_\mathrm{hemi},\mathrm{N}}_{N}\left(z^0+\frac{z^\gamma}{\sqrt{\lambda}}\right) 		 	 	 \textbf{	\underline{Step 3:}}	In the previous step we have chosen the constants in such a way that we can apply one of the following trigonometric identities   		 			&\sin(a+b)\sin(a+c)=\frac{1}{2}\left(\cos(b-c)-\cos(2a+(b+c))\right),\\& 			\cos(a+b)\cos(a+c)=\frac{1}{2}\left(\cos(2a+(b+c))+\cos(b-c)\right). 		 	 With these trigonometric double-angle relations, we can split, for all $1\leq \gamma\leq L$, the eigenfunctions as 	 		u_{\lambda,\gamma}^{\mathcal{P},\mathrm{BC}}\left(z^0+\frac{z}{\sqrt{\lambda}}\right)=K_{\lambda}^\mathcal{P}(z-z^\gamma)+\mathcal{E}_{\lambda,\mathcal{P},\mathrm{BC}}^{z^0}(z,z^\gamma), 	 where $K_{\lambda}^\mathcal{P}$ is a translation invariant part, which does not depend on the base point $z^0$, and $\mathcal{E}_{\lambda,\mathcal{P},\mathrm{BC}}^{z^0}$ is some translation-dependent function that will be bounded by a small quantity depending on $\lambda$ in the following step. 	 	In this step we pay attention to the translation invariant part. We restrict ourselves to eigenvalues $\lambda$ that are neither a perfect square $\lambda\neq m^2$ nor three times a perfect square $\lambda\neq 3\cdot n^2$. It is easy to see that then the translation invariant part depends only on the domain $\mathcal{P}$ but not on the boundary conditions.  A list of the functions that we get is as follows: 	 		\item $\mathcal{P}=\mathcal{Q}_l$ gives us	 			K_{\lambda}^{\mathcal{Q}_l}(z-z^\gamma)=\frac{2^d}{\#\mathcal{N}_\lambda^{\mathcal{Q}_l}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}\prod_{j=1}^{d}\cos\left(\frac{N_j\pi}{l_j\sqrt{\lambda}}(z_j-z^\gamma_j)\right). 		 		\item For $\mathcal{P}=\mathcal{T}_\mathrm{iso}$ we have 		 			K_{\lambda}^{\mathcal{T}_\mathrm{iso}}(z-z^\gamma)=\frac{4}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso}}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso},\mathrm{D}}}\cos\left(\frac{\pi m}{\sqrt{\lambda}}(z_1-z^\gamma_1)\right)\cos\left(\frac{\pi n}{\sqrt{\lambda}}(z_2-z^\gamma_2)\right). 		Notice that this is just a particular case of the previous one $(d=2,l_1=1)$.  		\item When considering $\mathcal{P}=	\mathcal{T}_\mathrm{equi}$ or $\mathcal{P}=\mathcal{T}_\mathrm{hemi}$, we get the same: 		 				&K_{\lambda}^{\mathcal{T}_\mathrm{hemi}}(z-z^\gamma)=K_{\lambda}^{	\mathcal{T}_\mathrm{equi}}(z-z^\gamma)=\\&\frac{4}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi}}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{hemi},\mathrm{D}}}\cos\left(\frac{2\pi m}{3\sqrt{\lambda}}(z_1-z^\gamma_1)\right)\cos\left(\frac{2\pi n\sqrt{3}}{3\sqrt{\lambda}}(z_2-z^\gamma_2)\right) 			 		 	 	The symmetry of $\mathcal{N}_\lambda^{\mathcal P}$ and the extra hypotheses on $\lambda$ allow us to see these as: 	 		 			&K_{\lambda}^{\mathcal{Q}_l}(z-z^\gamma)=\frac{1}{\#\mathcal{N}_\lambda^{\mathcal{Q}_l}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{Q}_l}}\cos\left(\sum_{j=1}^d\frac{N_j\pi}{l_j\sqrt{\lambda}}(z_j-z^\gamma_j)\right),\\ 			&	K_{\lambda}^{\mathcal{T}_\mathrm{iso}}(z-z^\gamma)=\frac{1}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso}}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso}}}\cos\left(\frac{\pi m}{\sqrt{\lambda}}(z_1-z^\gamma_1)+\frac{\pi n}{\sqrt{\lambda}}(z_2-z^\gamma_2)\right),\\ 			&	K_{\lambda}^{\mathcal{T}_\mathrm{equi}}(z-z^\gamma)=\frac{1}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi}}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{hemi}}}\cos\left(\frac{2\pi m}{3\sqrt{\lambda}}(z_1-z^\gamma_1)+\frac{2\pi n\sqrt{3}}{3\sqrt{\lambda}}(z_2-z^\gamma_2)\right)\text{ and }\\&K_{\lambda}^{\mathcal{T}_\mathrm{hemi}}(z-z^\gamma)=K_{\lambda}^{\mathcal{T}_\mathrm{equi}}(z-z^\gamma). 		 	 	 	To continue, we will follow \cite{ILtori} and use equidistribution properties of integer points on ellipsoids. Before introducing the following key definition, we notice that there exist constants $C^\mathcal{P}$ such that $C^\mathcal{P}\cdot\lambda=\mu\in\mathbb{N}$ for all $\lambda$ eigenvalues of the problems that we are considering here. With this in mind, we can now introduce the following definition: 		We shall say that 		 			\mathcal{N}^\mathcal{P}_\lambda=\left\{N\in\mathbb{Z}^d: \mathcal{Q}^\mathcal{P}(N)=\mu=C^\mathcal{P}\cdot\lambda\right\}, 		 		is {\em asymptotically equidistributed}\/ over the ellipsoid 		 			\mathcal{M}^{\mathcal{P}}=\left\{\xi\in\mathbb{R}^d, \mathcal{Q}^{\mathcal{P}}(\xi)=1\right\} 		 		along a certain sequence of $\lambda_n$ if, for every function $f\in C^\infty(\RR^d)$, 		 			\lim_{n\to\infty}\frac1{\#	\mathcal{N}^\mathcal{P}_{\lambda_n}}\sum_{N\in	\mathcal{N}^\mathcal{P}_{\lambda_n}} f\left(\frac{N}{\sqrt{C^\mathcal{P}\lambda}}\right) = \frac1{\left|	\mathcal{M}^{\mathcal{P}}\right|} \int_{	\mathcal{M}^{\mathcal{P}}} f(\eta)\, d\si_{	\mathcal{M}^{\mathcal{P}}}(\eta)\,, 		 		where $d\sigma_{	\mathcal{M}^{\mathcal{P}}}$ and $\left|	\mathcal{M}^{\mathcal{P}}\right|$ are the hypersurface measure form and hypersurface total measure of $	\mathcal{M}^{\mathcal{P}}$. 	 We find in \cite{Iwaniek,Cill} that there exist sequences of $\lambda_n$ with the asymptotically equidistribution property for all the quadratic forms that we are considering here. Therefore, restricting ourselves to one of those sequences (notice that the sequence to choose will depend on $\mathcal{P}$), we get one of the following: 	 	 		 			&K_{\lambda}^{\mathcal{Q}_l}(z-z^\gamma)=\frac{1}{|\mathcal{M}^{\mathcal{Q}_l}|}\int_{\mathcal{M}^{\mathcal{Q}_l}}\cos\left(\frac{\xi \sqrt{p}}{l}(z-z^\gamma)\right)d\sigma_{\mathcal{M}^{\mathcal{Q}_l}}(\xi)+\mathbb{E}(\lambda_n),\\ 			&K_{\lambda}^{\mathcal{T}_\mathrm{iso}}(z-z^\gamma)=\frac{1}{|\mathcal{M}^{\mathcal{T}_\mathrm{iso}}|}\int_{\mathcal{M}^{\mathcal{T}_\mathrm{iso}}}\cos\left(\xi_1(z_1-z_1^\gamma)+\xi_2(z_2-z_2^\gamma)\right)d\sigma_{\mathcal{M}^{\mathcal{T}_\mathrm{iso}}}(\xi)+\mathbb{E}(\lambda_n),\\ &K_{\lambda}^{\mathcal{T}_\mathrm{equi}/\mathcal{T}_\mathrm{hemi}}(z-z^\gamma)=\mathbb{E}(\lambda_n)+\\&\frac{1}{|\mathcal{M}^{\mathcal{T}_\mathrm{equi}}|}\int_{\mathcal{M}^{\mathcal{T}_\mathrm{equi}}}\cos\left(\xi_1(z_1-z_1^\gamma)+\sqrt{3}\xi_2(z_2-z_2^\gamma)\right)d\sigma_{\mathcal{M}^{\mathcal{T}_\mathrm{equi}}}(\xi), 		 	where $\mathbb{E}(\lambda_n)$ is an error term that satisfies $\mathbb{E}(\lambda_n)\xrightarrow[n\rightarrow \infty ]{}0$. 	 	All of them satisfy that  	 		 			K_{\lambda}^\mathcal{P}(z-z^\gamma)=&\frac{1}{|\mathcal{M}^\mathcal{P}|\cdot C_\mathcal{P}}\int_{\mathbb{S}^{d-1}}\cos\left(\xi\cdot(z-z^\gamma)\right)d\sigma_{\mathbb{S}^{d-1}}(\xi)+\mathbb{E}(\lambda_n), 		 	where $C_\mathcal{P}$ is the determinant of the matrix that defines the change of variables to go from $\mathbb{S}^{d-1}$ to $\mathcal{M}^\mathcal{P}$. Precisely $C_{\mathcal{Q}_l}=\frac{p^{d/2}}{l_1\cdot l_2\cdot \ldots\cdot l_{d-1}}$, $C_{\mathcal{T}_\mathrm{iso}}=1$ and $C_{\mathcal{T}_\mathrm{equi}}=C_{\mathcal{T}_\mathrm{hemi}}=\frac{1}{\sqrt{3}}$. 	 	We then choose $\lambda_n$ large enough in the sequence to ensure that $\mathbb{E}(\lambda_n)<\ep/3$ and notice that 		\left|	\vp(x)-	C_{\mathcal{P}}|\mathcal{M}^\mathcal{P}|	u_\lambda^{\mathcal{P},\mathrm{BC}}\left(z^0+\frac{z}{\sqrt{\lambda}}\right)\right|\leq\frac{2\ep}{3}+	C_\mathcal{P}|\mathcal{M}^\mathcal{P}|\sum_{\gamma=1}^{L}|c_\gamma|4^d\left|\mathcal{E}_{\lambda,\mathcal{P},\mathrm{BC}}^{z^0}(z,z^\gamma)\right|. 	 	 \textbf{	\underline{Step 4:}} 	In this last step we bound the terms $\mathcal{E}_{\lambda,\mathcal{P},\mathrm{BC}}^{z^0}(z,z^\gamma)$ by a small value for most $z\in\mathcal{P}$. We get it by combining the following lemmas: 	 		For $R>0$, set $\mathcal{R}^{2d}=[-R,R]^{2d}$. Then, for all $\delta>0$,  			\int_{\mathcal{P}}\int_{\mathcal{R}^{2d}}\left(\mathcal{E}_{\lambda,\mathcal{P},\mathrm{BC}}^{z^0}(z,z^\gamma)\right)^2dzdz^\gamma dz^0\leq\frac{C_\delta R^{2d}}{\lambda^{1/2-\delta}}, 		when $\lambda\rightarrow \infty$ along a sequence that gives us asymptotic equidistribution. 	 	In the proof of this lemma different tools are needed depending on the domain $\mathcal{P}$ we are considering. Notice, however, that there is no difference in considering Neumann o Dirichlet conditions because error terms differ (at most) in a sign that does not affect the bound. The proof is postponed until Section \ref{lemmas}, where we consider the four different cases. The other essential lemma is the following. 	 	 		Let $\left(f_L\right)_{L=1}^\infty$ be a sequence of continuously differentiable functions $f_L: \mathcal{P}\times \mathcal{R}^{2d} \rightarrow \mathbb{R}$ and write $f_{z^0, L}(u):=f_L(z^0, u)$. Suppose that $\left\|f_L\right\|_{\mathcal{P} \times \mathcal{R}^{2d}}^{\mathrm{Lip}} \leq D$ is bounded uniformly with respect to $R$ and $L$ and that 		 		 			\int_{\mathcal{P}}\int_{\mathcal{R}^{2d}}\left(f_{z^0, L}(u)\right)^2 d u d z^0 \leq C \frac{R^{2d}}{\Gamma(L)}, 		 		 		where $\Gamma(L)$ is some positive real function of $L$. Then 		 		 			\int_{\mathcal{P}}\left\|f_{z^0, L}\right\|_{\mathcal{R}^{2d}}^{\infty} d z^0 \leq C \frac{R^{2}}{(\Gamma(L))^{\frac{1}{d+3}}}. 		 		 	 	This is \cite[lemma 2.18]{Cann}. In the statement we have used the notation  		\|g\|_{\mathcal{D}}^{\mathrm{Lip}}=\sup _{w, v \in \mathcal{D}} \frac{|g(w)-g(v)|}{|w-v|} 	 and  	\|g\|_{\mathcal{D}}^{\infty}:=\sup _{w \in \mathcal{D}}|g(w)|. 	 We notice that the condition $\left\|f_L\right\|_{\mathcal{P} \times \mathcal{R}^{2d}}^{\mathrm{Lip}} \leq D$ follows from the smoothness of eigenfunctions. Lemma \ref{finalbound} together with Lemma \ref{BoundOfNonTrans} gives us that, for all $\delta>0$, 		\int_{\mathcal{P}}\left\|\mathcal{E}_{\lambda, \mathcal{P},\mathrm{BC}}^{z^0}\right\|_{\mathcal{R}^{2d}}^{\infty} d z^0 \leq C_\delta \frac{R^{2}}{\lambda^{\frac{1/2-\delta}{d+3}}}. 	 	Choosing, e.g., $\delta=1/4$, we have  		\int_{\mathcal{P}}\left\|\mathcal{E}_{\lambda,\mathcal{P},\mathrm{BC}}^{z^0}\right\|_{\mathcal{R}^{2d}}^{\infty} d z^0 \leq C \frac{R^{2}}{\lambda^{\frac{1}{4d+12}}}. 	 	 	Let $\mathbb{M}=\max_{1\leq \gamma\leq L}|c_\gamma|$ and define $\tilde{\ep}=\frac{\ep}{3C_l2^d|\mathcal{M}^\mathcal{Q}|L\mathbb{M}}$. We now use Markov's inequality to see that the set  	 		O_\lambda:=\left\{z^0\in \mathcal{P},\left\|\mathcal{E}_{\lambda,\mathcal{P},\mathrm{BC}}^{z^0}\right\|_{\mathcal{R}^{2d}}^{\infty}<\frac{\tilde{\ep}}{3} \right\} 	 	satisfy that  		 			&\left|O_\lambda\right|=1-\left|\left\{z^0\in \mathcal{P},\left\|\mathcal{E}_{\lambda,\mathcal{P},\mathrm{BC}}^{z^0}\right\|_{\mathcal{R}^{2d}}^{\infty}\geq\frac{\tilde{\ep}}{3} \right\}\right|\\&\geq1-\frac{	\int_{\mathcal{P}}\left\|\mathcal{E}_{\lambda,\mathcal{P},\mathrm{BC}}^{z^0}\right\|_{\mathcal{R}^{2d}}^{\infty} d z^0}{\tilde{\ep}/3}\geq 1-3C \frac{R^{2}}{\tilde{\ep}\lambda^{\frac{1}{4d+12}}}. 		 	 Particularly, for any fixed $\tilde{\ep}$, letting $\lambda_n\rightarrow\infty$ along the chosen sequence (the one with the equidistribution property) we have $\left|O_{\lambda_n}\right|\xrightarrow[\lambda\rightarrow\infty]{}1$. Notice also that $O_\lambda$ is an open set for any $\lambda$.           Finally, let's denote $O_{n,\varphi}=O_{\lambda_n}$ and notice that for any $z^0\in O_{n,\varphi} $, we have   		 			&	\left|	\vp(x)-	C_l|\mathcal{M}^\mathcal{Q}|u_{\lambda_n}^{\mathcal{P},\mathrm{BC}}\left(z^0+\frac{z}{\sqrt{\lambda}}\right)\right|\leq\frac{2\ep}{3}+	C_l|\mathcal{M}^\mathcal{Q}|\sum_{\gamma=1}^{L}|c_\gamma|2^d\left|\mathcal{E}_{\lambda,\mathcal{P},\mathrm{BC}}^{z^0}(z,z^\gamma)\right|\\ 			&\leq\frac{2\ep}{3}+	C_l|\mathcal{M}^\mathcal{Q}|L\mathbb{M}2^d\left\|\mathcal{E}_{\lambda,\mathcal{P},\mathrm{BC}}^{z^0}\right\|_{\mathcal{R}^{2d}}^{\infty}<\ep, 		 	for any $x\in B_R$. 	Finally, setting $u_n$ as  		u_n(x)=C_l|\mathcal{M}^\mathcal{Q}|u_{\lambda_n}^{\mathcal{P},\mathrm{BC}}(x), 	we get  		\left\|\vp-u_\lambda\left(z^0+\frac{z}{\sqrt{\lambda}}\right)\right\|_{C^0(B_R)}<\ep. 	 Using standard elliptic arguments we have the desired bound for the $C^k$ norm in any ball $B$ choosing $R>0$ big enough such that $B\subset B_R$ and all the $z^\gamma\in B_R$ for $1\leq\gamma\leq L$.",2502.01291
proof,"\textbf{	\underline{Step I:}} 	To write the error term, we consider two kind of functions, 		 			&C_j^{2,\mathrm{N}}(z,z^\gamma)=\cos\left(\frac{N_j\pi}{l_j\sqrt{\lambda}}(z_j-z^\gamma_j)\right),\\ 			&C_j^{1,\mathrm{N}}(z,z^\gamma)=\cos\left(\frac{2N_j\pi z^0_j}{l_j}+\frac{N_j\pi }{l_j\sqrt{\lambda}}(z_j+z^\gamma_j)\right). 		 	We also consider $i=(i_1,\ldots,i_d)$ with $i_j\in\{1,2\}$ for all $1\leq j\leq d$ and $|i|=i_1+\ldots+i_d$. In eigenfunctions we have all the possible products of $C_j^{i_j,\mathrm{N}}(z,z^\gamma)$, so with this notation, the function to bound is, in the Dirichlet case, 	 		 			\mathcal{E}_{\lambda,\mathcal{Q}_l,\mathrm{D}}^{z^0}(z,z^\gamma)&=\frac{1}{\#\mathcal{N}_\lambda^{\mathcal{Q}_l}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}\left[\prod_{j=1}^d\left(C_j^{2,\mathrm{N}}(z,z^\gamma)-C_j^{1,\mathrm{N}}(z,z^\gamma)\right)-\prod_{j=1}^dC_j^{2,\mathrm{N}}(z,z^\gamma)\right]\\ 			&=\frac{1}{\#\mathcal{N}_\lambda^{\mathcal{Q}_l}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}\sum_{\substack{1\leq i\leq 2\\|i|<2d}}(-1)^{|i|}\prod_{j=1}^dC_j^{i_j,\mathrm{N}}(z,z^\gamma), 		 	and, in the Neumann case,  	 		 			\mathcal{E}_{\lambda,\mathcal{Q}_l,\mathrm{N}}^{z^0}(z,z^\gamma)&=\frac{1}{\#\mathcal{N}_\lambda^{\mathcal{Q}_l}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{N}}}\left[\prod_{j=1}^d\left(C_j^{2,\mathrm{N}}(z,z^\gamma)+C_j^{1,\mathrm{N}}(z,z^\gamma)\right)-\prod_{j=1}^dC_j^{2,\mathrm{N}}(z,z^\gamma)\right]\\ 			&=\frac{1}{\#\mathcal{N}_\lambda^{\mathcal{Q}_l}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{N}}}\sum_{\substack{1\leq i\leq 2\\|i|<2d}}\prod_{j=1}^dC_j^{i_j,\mathrm{N}}(z,z^\gamma). 		 	  	Since we are only interested in bounding this function, we can forget about the sign of each term and the proof works the same for Dirichlet and Neumann conditions. 	 \textbf{	\underline{Step II:}}	We first fix $(z,z^\gamma)\in\mathcal{R}^{2d}$ and integrate over $\mathcal{Q}_l$. So with $z,z^\gamma\in [-R,R]^d$ fixed, recalling \eqref{DE} (and \eqref{NE} for the Neumann case, where only the sign changes), we get the following 	 	 		 			&\int_{\mathcal{Q}_l}\left(\mathcal{E}_{\lambda,\mathcal{Q}_l,\mathrm{D}}^{z^0}(z,z^\gamma)\right)^2dz^0=\int_{\mathcal{Q}_l}\left(\sum_{N\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}\sum_{\substack{1\leq i\leq 2\\|i|<2d}}\frac{(-1)^{|i|}}{\#\mathcal{N}_\lambda^{\mathcal{Q}_l}}\prod_{j=1}^dC_j^{i_j,\mathrm{N}}(z,z^\gamma)\right)^2dz^0\\ 			&=\sum_{\substack{N\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}\\M\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}}\sum_{\substack{1\leq i,k\leq 2\\|i|,|k|<2d}}\frac{(-1)^{|i|+|k|}}{\left(\#\mathcal{N}_\lambda^{\mathcal{Q}_l}\right)^2} \int_{\mathcal{Q}_l}\left(\prod_{j=1}^dC_j^{i_j,\mathrm{N}}(z,z^\gamma)\right)\left(\prod_{j=1}^dC_j^{k_j,M}(z,z^\gamma)\right)dz^0\\ 			&=\sum_{\substack{N\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}\\M\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}}\sum_{\substack{1\leq i,k\leq 2\\|i|,|k|<2d}} \frac{(-1)^{|i|+|k|}}{\left(\#\mathcal{N}_\lambda^{\mathcal{Q}_l}\right)^2}\prod_{j=1}^d\left(\int_{0}^{l_j}C_j^{i_j,\mathrm{N}}(z,z^\gamma)C_j^{k_j,M}(z,z^\gamma)dz^0\right). 		 	We study now each $\int_{0}^{l_j}C_j^{i_j,\mathrm{N}}(z,z^\gamma)C_j^{k_j,M}(z,z^\gamma)dz^0$ separately. There are three different cases: 	 		\item None of the terms depend on $z^0$, $(i_j,k_j)=(2,2)$,  			 				&\int_{0}^{l_j}C_j^{2,\mathrm{N}}(z,z^\gamma)C_j^{2,M}(z,z^\gamma)dz^0=	\\&\int_{0}^{l_j}\cos\left(\frac{N_j\pi}{l_j\sqrt{\lambda}}(z_j-z^\gamma_j)\right)\cos\left(\frac{M_j\pi}{l_j\sqrt{\lambda}}(z_j-z^\gamma_j)\right)dz^0\\ 				&=	l_j\cdot \cos\left(\frac{N_j\pi}{l_j\sqrt{\lambda}}(z_j-z^\gamma_j)\right)\cos\left(\frac{M_j\pi}{l_j\sqrt{\lambda}}(z_j-z^\gamma_j)\right). 			 		 \item Only one of the terms depends on $z^0$, $(i_k,k_j)=(1,2)$ or $(i_k,k_j)=(2,1)$, 			 				&\int_{0}^{l_j}C_j^{1,\mathrm{N}}(z,z^\gamma)C_j^{2,M}(z,z^\gamma)dz^0=	\\&\int_{0}^{l_j}\cos\left(\frac{2N_j\pi z^0_j}{l_j}+\frac{N_j\pi }{l_j\sqrt{\lambda}}(z_j+z^\gamma_j)\right)C_j^{2,M}(z,z^\gamma)dz^0\\ 				&=	\cos\left(\frac{M_j\pi}{l_j\sqrt{\lambda}}(z_j-z^\gamma_j)\right)	\int_{0}^{l_j}\cos\left(\frac{2N_j\pi z^0_j}{l_j}+\frac{N_j\pi }{l_j\sqrt{\lambda}}(z_j+z^\gamma_j)\right)dz^0=0. 			 		 		\item both terms depend on $z^0$, $(i_k,k_j)=(1,1)$, 			 				&\int_{0}^{l_j}C_j^{1,\mathrm{N}}(z,z^\gamma)C_j^{1,M}(z,z^\gamma)dz^0=\\ 				&	\int_{0}^{l_j}\cos\left(\frac{2N_j\pi z^0_j}{l_j}+\frac{N_j\pi }{l_j\sqrt{\lambda}}(z_j+z^\gamma_j)\right)\cos\left(\frac{2M_j\pi z^0_j}{l_j}+\frac{M_j\pi }{l_j\sqrt{\lambda}}(z_j+z^\gamma_j)\right)dz^0\\ 				&=\left\{ 					&\frac{l_j}{2}\text{ if }M_j=N_j,\\ 					&0\text{ if }M_j\neq N_j. 				\right. 			 		 	 	We can then rewrite,  	 		 			&\int_{\mathcal{Q}_l}\left(\mathcal{E}_{\lambda,\mathcal{Q}_l,\mathrm{BC}}^{z^0}(z,z^\gamma)\right)^2dz^0=\\&\frac{1}{\left(\#\mathcal{N}_\lambda^{\mathcal{Q}_l}\right)^2}\sum_{\substack{N,M\\ \in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}}\sum_{\substack{1\leq i\leq 2\\|i|<2d}} \prod_{j=1}^d\left(\int_{0}^{l_j}C_j^{i_j,M}(z,z^\gamma)C_j^{i_j,\mathrm{N}}(z,z^\gamma)dz^0\right)\\ 			&=\frac{1}{\left(\#\mathcal{N}_\lambda^{\mathcal{Q}_l}\right)^2}\sum_{\substack{N,M\\ \in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}}\sum_{\substack{1\leq i\leq 2\\|i|<2d}} \prod_{j=1}^d A_j^{i_j,N,M}(z,z^\gamma), 		 	where we have computed $A_j^{i_j,N,M}(z,z^\gamma)$ as 	 		A_j^{i_j,N,M}(z,z^\gamma)=\left\{ 			&\frac{l_j}{2}\delta_{N_j,M_j},\text{ if }i_j=1\\ 			&l_j\cdot\cos\left(\frac{N_j\pi}{l_j\sqrt{\lambda}}(z_j-z^\gamma_j)\right)\cos\left(\frac{M_j\pi}{l_j\sqrt{\lambda}}(z_j-z^\gamma_j)\right),\text{ if }i_j=2, 		 		\right. 	 	where $\delta_{\cdot,\cdot}$ is the Kronecker delta. We now notice that if $N_j=M_j$ for all $1\leq j\leq d$ except for one, obviously it is true that $N=M$. 	Then we can split the integral in two parts:      	 		 			&\int_{\mathcal{Q}_l}\left(\mathcal{E}_{\lambda,\mathcal{Q}_l,\mathrm{BC}}^{z^0}(z,z^\gamma)\right)^2dz^0=I(z,z^\gamma)+II(z,z^\gamma)=\\ 			&=\frac{1}{\left(\#\mathcal{N}_\lambda^{\mathcal{Q}_l}\right)^2}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}\sum_{\substack{1\leq i\leq 2\\|i|=d, d+1}} \prod_{j=1}^d A_j^{i_j,N,\mathrm{N}}(z,z^\gamma)+\\&\frac{1}{\left(\#\mathcal{N}_\lambda^{\mathcal{Q}_l}\right)^2}\sum_{\substack{N,M\\ \in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}}\sum_{\substack{1\leq i\leq 2\\d+1<|i|<2d}} \prod_{j=1}^d A_j^{i_j,N,M}(z,z^\gamma), 		 	 	 \textbf{	\underline{Step III:}} 	The next step is to integrate over $\mathcal{R}^{2d}$. We proceed to study the first term  $\int_{\mathcal{R}^{2d}}I(z,z^\gamma)dzdz^\gamma$. 	 		 			&\int_{\mathcal{R}^{2d}}I(z,z^\gamma)dzdz^\gamma=\\&\frac{1}{\left(\#\mathcal{N}_\lambda^{\mathcal{Q}_l}\right)^2}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}\sum_{\substack{1\leq i\leq 2\\|i|=d,d+1}} \prod_{j=1}^d \int_{-R}^R\int_{-R}^RA_j^{i_j,N,\mathrm{N}}(z,z^\gamma)dz_jdz^\gamma_j\\&=\frac{1}{\left(\#\mathcal{N}_\lambda^{\mathcal{Q}_l}\right)^2}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}\sum_{\substack{1\leq i\leq 2\\|i|=d,d+1}} \prod_{j=1}^d B_j^{i_j,\mathrm{N}}. 		 	 	Here we are defining  		 			&B_j^{i_j,\mathrm{N}}=\int_{-R}^R\int_{-R}^RA_j^{i_j,N,\mathrm{N}}(z,z^\gamma)d(z_j,z^\gamma_j)=\\&\left\{ 				&\frac{l_j (2R)^2}{2},\text{ if }i_j=1\\ 				&l_j\int_{-R}^R\int_{-R}^R\cos^2\left(\frac{N_j\pi}{l_j\sqrt{\lambda}}(z_j-z^\gamma_j)\right),i_j=2 			\right.\\&=\left\{ 				&\frac{l_j \cdot (2R)^2}{2},\text{ if }i_j=1\\ 				&2l_j R^2+\frac{l_j^3\lambda}{4N_j^2\pi^2}\left(1-\cos\left(\frac{4RN_j\pi}{l_j\sqrt{\lambda}}\right)\right),i_j=2. 			\right. 		 	 	We are only interested in bounding this integral, not in calculating it, so we can use an explicit error for the Taylor expansion of $\cos(x)$ at $x=0$ to have  	 		 			&B_j^{i_j,\mathrm{N}}\leq\left\{ 				&\frac{l_j \cdot (2R)^2}{2},\text{ if }i_j=1\\ 				&2l_j R^2+\frac{l_j^3\lambda}{4N_j^2\pi^2}\frac{1}{2}\left(\frac{4RN_j\pi}{l_j\lambda}\right)^2,\text{ if }i_j=2. 			\right.=\left\{ 				&\frac{l_j \cdot (2R)^2}{2},\text{ if }i_j=1\\ 				&4l_jR^2,\text{ if }i_j=2. 			\right. 		 	 	Let's call $\mathcal{A}=\prod_{j=1}^dl_j$, then  	 		 			&\int_{\mathcal{R}^{2d}}I(z,z^\gamma)dzdz^\gamma=\frac{1}{\left(\#\mathcal{N}_\lambda^{\mathcal{Q}_l}\right)^2}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}\sum_{\substack{1\leq i\leq 2\\|i|=d,d+1}} \prod_{j=1}^d B_j^{i_j,\mathrm{N}}.\\ 			&\leq \frac{1}{\left(\#\mathcal{N}_\lambda^{\mathcal{Q}_l}\right)^2}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}\sum_{\substack{1\leq i\leq 2\\|i|=d,d+1}} \prod_{j=1}^d 4l_j R^2=\\&\frac{1}{\mathcal{N}_\lambda^2}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}\sum_{\substack{1\leq i\leq 2\\|i|=d,d+1}} (2R)^{2d} \mathcal{A}=\frac{C\cdot R^{2d}}{\mathcal{N}_\lambda}. 		 	 	 \textbf{	\underline{Step IV:}}	We now study $\int_{\mathcal{R}^{2d}}II(z,z^\gamma)dzdz^\gamma$. Note that this term does not exist in dimension $d=2$ since there is no natural number $|i|$ such that $3=d+1<|i|<2d=4$. First, we are going to bound the function inside the integral by noting that  	 		A_j^{i_j,N,M}(z,z^\gamma)\leq\left\{ 			&\frac{l_j}{2}\delta_{N_j,M_j},\text{ if }i_j=1\\ 			&l_j,\text{ if }i_j=2. 		 		\right. 	 	Since $d+1<|i|<2d$ we have $i$ with $2,3,4,\ldots,d-1$ entries $i_j=2$, so we write 	 		 			&II(z,z^\gamma)=\frac{1}{\left(\#\mathcal{N}_\lambda^{\mathcal{Q}_l}\right)^2}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}\sum_{M\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}\sum_{\substack{1\leq i\leq 2\\d+1<|i|<2d}} \prod_{j=1}^d A_j^{i_j,N,M}(z,z^\gamma)\\ 			&=\frac{1}{\left(\#\mathcal{N}_\lambda^{\mathcal{Q}_l}\right)^2}\sum_{M\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}\sum_{k=d+2}^{2d-1}\sum_{\substack{1\leq i\leq 2\\|i|=k}}\left[ \sum_{N\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}\prod_{j=1}^d A_j^{i_j,N,M}(z,z^\gamma)\right].	 	 	Paying attention only to $\sum_{M\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}\prod_{j=1}^d A_j^{i_j,N,M}(z,z^\gamma)$ for a fixed $N$ we see that 	 		\sum_{M\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}\prod_{j=1}^d A_j^{i_j,N,M}(z,z^\gamma)\leq\mathcal{A}\sum_{\substack{M\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}\\M_j=N_j\text{ if }i_j=1}}1. 	And applying this into \eqref{secondterm}, it is easy to see that 	 		 			&II(z,z^\gamma)\leq\frac{\mathcal{A}}{\left(\#\mathcal{N}_\lambda^{\mathcal{Q}_l}\right)^2}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}\sum_{k=d+2}^{2d-1}\sum_{\substack{1\leq i\leq 2\\|i|=k}}\left[ \sum_{\substack{M\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}\\N_j=M_j\text{ if }i_j=1}}1\right]. 		 	 	To continue with the bounding, we define the following positive definite integral diagonal quadratic forms:   		 For $|i|=d+2,$ with $i_{j_1}=i_{j_2}=2,$ we define  		 	\mathcal{Q}^i_2(k_1,k_2)=q_{j_1}\frac{p}{p_{j_1}}k_1^2+q_{j_2}\frac{p}{p_{j_2}}k_2^2; 		  for $|i|=d+3,$ with $i_{j_1}=i_{j_2}=i_{j_3}=2,$ we define  		 \mathcal{Q}^i_3(k_1,k_2, k_3)=q_{j_1}\frac{p}{p_{j_1}}k_1^2+q_{j_2}\frac{p}{p_{j_2}}k_2^2+q_{j_3}\frac{p}{p_{j_3}}k_3^2; 		 and we continue like this, until for $|i|=2d-1,$ with $i_{j}=1,$ we have  		 	\mathcal{Q}^i_{d-1}(k_1,\ldots,k_{j-1},k_{j+1},\ldots, k_d)=&q_{1}\frac{p}{p_{1}}k_1^2+\ldots+q_{j-1}\frac{p}{p_{j-1}}k_{j-1}^2+\\&q_{j+1}\frac{p}{p_{j+1}}k_{j+1}^2+\ldots+q_{d}\frac{p}{p_{d}}k_d^2. 		  	 	Note that each of them satisfy  $\mathcal{Q}^i_{|i|-d}$ and call  		r^{\mathcal{Q},i}_{|i|-d}(N)=\left|\left\{(k_1,\ldots,k_{|i|-d})\in\mathbb{N}^{|i|-d}, \mathcal{Q}^i_{|i|-d}(k_1,\ldots,k_{|i|-d})=N\right\}\right|, 	 so we have 		 			&II(z,z^\gamma)\leq\frac{\mathcal{A}}{\left(\#\mathcal{N}_\lambda^{\mathcal{Q}_l}\right)^2}\sum_{N,k,i}r^{\mathcal{Q},i}_{k-d}\left(\lambda-q_{j_1}\frac{p}{p_{j_1}}N_{j_1}^2-\ldots-q_{j_{2d-k}}\frac{p}{p_{j_{2d-k}}}N_{j_{2d-k}}^2\right), 		 	where $\sum_{N,k,i}$ represents the following:\sum_{N,k,i}=\sum_{N\in\mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}\sum_{k=d+2}^{2d-1}\sum_{\substack{1\leq i\leq 2\\|i|=k}}.For the next step we introduce the following lemma: 	 	  		Let $Q\left(k_1, \ldots, k_d\right)$ be a positive definite integral diagonal quadratic form in $d \geq 2$ variables. 		The number of integral representations $Q\left(k_1, \ldots, k_d\right)=n$ satisfies, for all $\delta>0$ small enough, 			 			r_Q(n)\leq C_{d,\delta} n^{d / 2-1+\delta} . 		 		 			The constant depends only on $d$ and $\ep$, so it is independent of the actual coefficients of $Q$ and of $n$. 	 	 		 		We proceed by induction on $d$. The case $d=2$ is well known and based on limiting bounds of the divisors function: for all $\delta>0$, 		 		 			r^2_Q(n)\leq C_{2,\delta} n^{\delta} . 		  		The induction hypothesis is for all $\delta>0$, 		 		 			r_Q^{d-1}(n)\leq C_{d-1,\delta} n^{(d-1) / 2-1+\delta} .  		 		By changing coordinates we can assume that $Q(z_1,\ldots,k_d)=a_1k_1^2+\ldots+a_dk_d^2$ with $0\leq a_1\leq a_2\leq \ldots \leq a_d$. Since $\det(Q)=a_1\cdot\ldots\cdot a_d$ it is true that $a_d\geq \det Q^{1/d}$. 		 		Using the hypothesis of induction, the number of representations with $k_d^2=0$ is $\leq C_{d-1,\delta}n^{(d-3)/2+\delta}$, so we focus on the representations with $k_d^2>0$. Notice that  			k_d^2=\frac{n}{a_d}-\sum_{i=1}^{d-1}\frac{a_i}{a_d}k_i^2\leq \frac{n}{ \det Q^{1/d}}. 		 And then $k_d\leq C_Q\sqrt{n}$. It is then obvious that $k_{d-1}\leq C_Q\sqrt{n}$, $\ldots$, $k_{3}\leq C_Q\sqrt{n}$. Then we have $n^{\frac{d-2}{2}}\det Q^{-\frac{d-2}{2d}}$ options for the $(d-2)$-tuple $(k_3,\ldots,k_d)$. Fixing this, we are left with  			 			    &a_1k_1^2+a_2k_2^2=n-\left(\sum_{i=3}^{d}a_ik_i^2\right) \iff\\& a_1k_1^2+a_2k_2^2+e=0,\text{ with }e=\left(\sum_{i=3}^{d}a_ik_i^2\right)-n\leq c_Q n. 			 		 		Using a \cite[Lemma 8]{Blomer}, we know that the choices for $(k_1,k_2)$ are for any $\delta>0$, at most $\leq C_\delta \det Q^\delta n^\delta$.  		Finally,  			r_Q^d(n)\leq C_\delta n^{\frac{d-3}{2}+\delta}+C_\delta n^{\frac{d-2}{2}+\delta}\det Q^{-\frac{d-2}{2d}+\delta}\leq C_{d,\delta}n^{\frac{d}{2}-1+\delta}. 		The last constant is independent of $Q$ because the quadratic form is positive definite and of integer coefficients and, consequently, $\det Q^{-\frac{d-2}{2d}+\delta}$ is bounded by one for any $\delta<\frac{d-2}{2d}$ (recall that this is needed only for $d>2$ so $\frac{d-2}{2d}>0$).",2502.01291
proof,"\textbf{	\underline{Step I:}}	To make computations easier, we will consider the error term $\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{iso},\mathrm{BC}}^{z^0}(z,z^\gamma)$ split into two terms: $\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{iso},\mathrm{BC}}^{z^0, (1)}(z,z^\gamma)$ and $\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{iso},\mathrm{BC}}^{z^0, (2)}(z,z^\gamma)$. In this subsection, we will prove lemma \ref{BoundOfNonTrans} for both of them.  	 	First, notice that 		 		\int_{\mathcal{T}_\mathrm{iso}}\int_{\mathcal{R}^{4}}F^{(i)}(z,z^\gamma,z^0)d(z,z^\gamma,z^0)\leq	\int_{Q_1}\int_{\mathcal{R}^{4}}F^{(i)}(z,z^\gamma,z^0)d(z,z^\gamma,z^0), 	 for $i=1,2$ and F^{(i)}(z,z^\gamma,z^0)=\left(\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{iso},\mathrm{BC}}^{z^0,(i)}(z,z^\gamma)\right)^2>0.  	 	 Therefore, it is enough to study the right hand side integral, which is easier because of the symmetry of $Q_1$. 	 	We then	define sets   $O_\lambda^{(1)}$ and $O_\lambda^{(2)}$ as in \eqref{set} for both error terms, choosing   		\tilde{\ep}=\frac{\ep}{24C_l|\mathcal{M}^\mathcal{Q}|L\mathbb{M}}. 	 Applying \ref{finalbound} and the later analysis to both sets we get, instead of equation \eqref{error},  	 		 			&	\left|	\vp(x)-	C_l|\mathcal{M}^\mathcal{Q}|u_\lambda^{\mathcal{T}_\mathrm{iso},\mathrm{BC}}\left(z^0+\frac{z}{\sqrt{\lambda}}\right)\right|\leq\frac{2\ep}{3}+	C_l|\mathcal{M}^\mathcal{Q}|\sum_{\gamma=1}^{L}|c_\gamma|4\left|\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{iso},\mathrm{BC}}^{z^0,(1)}(z,z^\gamma)\right|\\ 			&+C_l|\mathcal{M}^\mathcal{Q}|\sum_{\gamma=1}^{L}|c_\gamma|4\left|\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{iso},\mathrm{BC}}^{z^0,(2)}(z,z^\gamma)\right|\leq\frac{2\ep}{3}+	C_l|\mathcal{M}^\mathcal{Q}|L\mathbb{M}\left\|\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{iso},\mathrm{BC}}^{z^0,(1)}\right\|_{\mathcal{R}^{4}}^{\infty}\\&+C_l|\mathcal{M}^\mathcal{Q}|L\mathbb{M}\left\|\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{iso},\mathrm{BC}}^{z^0,(2)}\right\|_{\mathcal{R}^{4}}^{\infty}<\frac{2\ep}{3}+\frac{\ep}{6}+\frac{\ep}{6}=\ep, 		 	 	for any $x\in B_R$ and any $z^0\in O_\lambda^{(1)}\cap O_\lambda^{(2)}$.  	 	It is also easy to notice that 	 		 			&\left|O_\lambda^{(1)}\cap O_\lambda^{(2)}\right|=1-\left|\mathcal{T}_\mathrm{iso}\backslash\left(O_\lambda^{(1)}\cap O_\lambda^{(2)}\right)\right|\geq1-\left(\left|\mathbb{T_{IR}}\backslash O_\lambda^{(1)}\right|+\left|\mathbb{T_{IR}}\backslash O_\lambda^{(2)}\right|\right) \\&\geq1-\left(\left\{z^0\in \mathcal{P},\left\|\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{iso},\mathrm{BC}}^{z^0,(1)}\right\|_{\mathcal{R}^{4}}^{\infty}\geq\frac{\tilde{\ep}}{3} \right\}+\left\{z^0\in \mathcal{P},\left\|\mathcal{E}_{\lambda,\mathbb{T}_ {IR},\mathrm{BC}}^{z^0,(2)}\right\|_{\mathcal{R}^{4}}^{\infty}\geq\frac{\tilde{\ep}}{3} \right\}\right)\\&\geq1-\left(\frac{	\int_{\mathcal{P}}\left\|\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{iso},\mathrm{BC}}^{z^0,(1)}\right\|_{\mathcal{R}^{4}}^{\infty} d z^0}{\tilde{\ep}/3}+\frac{	\int_{\mathcal{P}}\left\|\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{iso},\mathrm{BC}}^{z^0,(2)}\right\|_{\mathcal{R}^{4}}^{\infty} d z^0}{\tilde{\ep}/3}\right)\geq 1-3C \frac{R^{2}}{\tilde{\ep}\lambda^{\frac{1}{4d+12}}}. 		 	 	 	The first term  $\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{iso},\mathrm{BC}}^{z^0, (1)}(z,z^\gamma)$ is defined to be a particular case of the previously introduced $\mathcal{E}_{\lambda,\mathcal{Q}_l,\mathrm{BC}}^{z^0}(z,z^\gamma)$, whenever $d=2$ and $l=1$. Using the same notation as in Subsection \ref{QlNF}, 	we have 	 	 		 			&\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{iso},\mathrm{D}}^{z^0,(1)}(z,z^\gamma) 			=\frac{1}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso}}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso},\mathrm{D}}}\sum_{\substack{1\leq i\leq 2\\|i|=2,3}}(-1)^{|i|}c_1^{i_1,\mathrm{N}}(z,z^\gamma)c_2^{i_2,\mathrm{N}}(z,z^\gamma)\\&=\frac{1}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso}}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso},\mathrm{D}}}\left(c_1^{1,\mathrm{N}}c_2^{1,\mathrm{N}}-c_1^{1,\mathrm{N}}c_2^{2,\mathrm{N}}-c_1^{2,\mathrm{N}}c_2^{1,\mathrm{N}}\right)(z,z^\gamma), 		 	for the Dirichlet case, and, in the Neumann case,  	 		 			&\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{iso},\mathrm{N}}^{z^0,(1)}(z,z^\gamma) 			=\frac{1}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso}}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso},\mathrm{N}}}\sum_{\substack{1\leq i\leq 2\\|i|=2,3}}c_1^{i_1,\mathrm{N}}(z,z^\gamma)c_2^{i_2,\mathrm{N}}(z,z^\gamma)\\&=\frac{1}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso}}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso},\mathrm{N}}}\left(c_1^{1,\mathrm{N}}c_2^{1,\mathrm{N}}+c_1^{1,\mathrm{N}}c_2^{2,\mathrm{N}}+c_1^{2,\mathrm{N}}c_2^{1,\mathrm{N}}\right)(z,z^\gamma). 		 	 	Therefore, Lemma \ref{BoundOfNonTrans} in this case follows form the previous subsection (Steps II and III). 	 \textbf{	\underline{Step II:} }For the second term, we introduce a similar notation: 	 		 			&	P_1^{1,\mathrm{N}}(z,z^\gamma,z^0)=\cos\left(z_1^0\pi(n-m)+\frac{\pi nz_1^\gamma-\pi mz_1}{\sqrt{\lambda}}\right) \\ 			&	P_1^{2,\mathrm{N}}(z,z^\gamma,z^0)=\cos\left(z_1^0\pi(n+m)+\frac{\pi nz_1^\gamma+\pi mz_1}{\sqrt{\lambda}}\right) \\ 			&	P_2^{1,\mathrm{N}}(z,z^\gamma,z^0)= \cos\left(z_2^0\pi(m-n)+\frac{\pi mz_2^\gamma-\pi nz_2}{\sqrt{\lambda}}\right)\\ 			&	P_2^{2,\mathrm{N}}(z,z^\gamma,z^0)=\cos\left(z_2^0\pi(m+n)+\frac{\pi mz_2^\gamma+\pi nz_2}{\sqrt{\lambda}}\right) . 		 	  	So then, in the Dirichlet case, it is true that 	 		 			&\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{iso},\mathrm{D}}^{z^0,(2)}(z,z^\gamma) 			=\frac{1}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso}}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso},\mathrm{D}}}\sum_{1\leq i,j\leq 2}(-1)^{i+j}P_1^{i,\mathrm{N}}(z,z^\gamma,z^0)P_2^{j,\mathrm{N}}(z,z^\gamma,z^0)\\&=\frac{1}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso}}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso},\mathrm{D}}}\left(P_1^{1,\mathrm{N}}P_2^{1,\mathrm{N}}+P_1^{2,\mathrm{N}}P_2^{2,\mathrm{N}}-P_1^{1,\mathrm{N}}P_2^{2,\mathrm{N}}-P_1^{2,\mathrm{N}}P_2^{1,\mathrm{N}}\right)(z,z^\gamma,z^0), 		 	 while for the Neumann case we get,  	 		 			&\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{iso},\mathrm{N}}^{z^0,(2)}(z,z^\gamma) 			=\frac{1}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso}}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso},\mathrm{N}}}\sum_{1\leq i,j\leq 2}P_1^{i,\mathrm{N}}(z,z^\gamma,z^0)P_2^{j,\mathrm{N}}(z,z^\gamma,z^0)\\&=\frac{1}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso}}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso},\mathrm{N}}}\left(P_1^{1,\mathrm{N}}P_2^{1,\mathrm{N}}+P_1^{2,\mathrm{N}}P_2^{2,\mathrm{N}}+P_1^{1,\mathrm{N}}P_2^{2,\mathrm{N}}+P_1^{2,\mathrm{N}}P_2^{1,\mathrm{N}}\right)(z,z^\gamma,z^0), 		 	  	We fix $(z,z^\gamma)\in \mathcal{R}^4$ and integrate over $Q_1$ (we do it in the Dirichlet case, but the Neumann case is analogous), 	 	 		 			&\int_{Q_1}\left(\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{iso},\mathrm{D}}^{z^0,(2)}(z,z^\gamma)\right)^2dz^0=\int_{Q_1}\left(\frac{1}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso}}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso},\mathrm{D}}}\sum_{1\leq i,j\leq 2}(-1)^{i+j}P_1^{i,\mathrm{N}}P_2^{j,\mathrm{N}}\right)^2dz^0\\ 			&=\frac{1}{\left(\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso}}\right)^2}\sum_{N,M\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso},\mathrm{D}}}\sum_{\substack{1\leq i,j\leq 2\\1\leq k,l\leq 2}}(-1)^{i+j+k+l} \int_{Q_1}\left(P_1^{i,\mathrm{N}}P_2^{j,\mathrm{N}}\right)\left(P_1^{k,M}P_2^{l,M}\right)dz^0\\ 			&=\frac{1}{\left(\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso}}\right)^2}\sum_{N,M\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso},\mathrm{D}}}\sum_{\substack{1\leq i,j\leq 2\\1\leq k,l\leq 2}}(-1)^{i+j+k+l} \int_{0}^1\left(P_1^{i,\mathrm{N}}P_1^{k,M}\right)dz_1^0\int_0^1\left(P_2^{j,\mathrm{N}}P_2^{l,M}\right)dz_2^0. 		 	     We study now each possible combination of $\int_{0}^{1}\left(P_j^{i,\mathrm{N}}P_j^{k,M}\right)dz_j^0$, $j,i,k=1,2$. Notice that all of them are of the form  		\int_{0}^{1}\left(P_j^{i,\mathrm{N}}P_j^{k,M}\right)dz_j^0=\int_0^1\cos\left(\pi \alpha x+c_1\right)\cos\left(\pi \beta x+c_2\right)dz, 	 with constants $\alpha,\beta\in\mathbb{Z}$ and $ c_1,c_2\in \mathbb{R}$. This kind of integral is known to be 	 		 			&	\int_0^1\cos\left(\pi \alpha x+c_1\right)\cos\left(\pi \beta x+c_2\right)dz=\\&\frac{\sin\left(c_1-c_2+\pi(\alpha-\beta)\right)-\sin\left(c_1-c_2\right)}{2\pi(\alpha-\beta)}+\frac{\sin\left(c_1+c_2+\pi(\alpha+\beta)\right)-\sin\left(c_1+c_2\right)}{2\pi(\alpha+\beta)}, 		 	if $\left|\alpha\right|\neq\left|\beta\right|$, 	 		 			\int_0^1\cos\left(\pi \alpha x+c_1\right)\cos\left(\pi \beta x+c_2\right)dz=\frac{\sin\left(\pi \alpha \right)\cos\left(c_1+c_2+\pi \alpha\right)}{2\pi \alpha}+\frac{\cos\left(c_1-c_2\right)}{2}, 		 	if $\alpha=\beta$ and, finally,  	 		 			\int_0^1\cos\left(\pi \alpha x+c_1\right)\cos\left(\pi \beta x+c_2\right)dz=\frac{\sin\left(\pi \alpha\right)\cos\left(c_1-c_2+\pi \alpha\right)}{2\pi \alpha}+\frac{\cos\left(c_1+c_2\right)}{2}, 		 	if $\alpha=-\beta$. 	 	By definition, $\alpha,\beta\equiv 0\mod(2)$ if $m,n$ (resp. $a,b$) have the same parity. As seen in \cite{CillDisk}, the sequence of $\lambda$ along which we have asymptotic equidistribution runs along even values of $\lambda$, being $m\equiv n \mod(2)$ (resp. $a\equiv b\mod(2)$). This simplifies the integral: 	 		\int_0^1\cos\left(\pi \alpha x+c_1\right)\cos\left(\pi \beta x+c_2\right)dz=\left\{ 			&0\text{ if }|\alpha|\neq|\beta|,\\ 			&\frac{1}{2}\cos\left(c_1-c_2\right)\text{ if }\alpha=\beta\text{ and }\\ 			&\frac{1}{2}\cos\left(c_1+c_2\right)\text{ if }\alpha=-\beta. 		\right. 	 	In particular, paying attention to the definition of $\alpha$ and $\beta$, for $i,j=1,2$  		\int_{0}^{1}\left(P_j^{1,\mathrm{N}}P_j^{2,M}\right)dz_j^0=0, 	and also  		\int_{0}^{1}\left(P_j^{i,\mathrm{N}}P_j^{i,M}\right)dz_j^0\leq \frac{1}{2}\left(\delta(n-b)+\delta(n-a)\right). 	In the end, we get the existence of a constant $C$ such that	 		 			&\int_{Q_1}\left(\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{iso},\mathrm{BC}}^{z^0,(2)}(z,z^\gamma)\right)^2dz^0\leq \frac{1}{\left(\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso}}\right)^2}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso},\mathrm{BC}}}C\leq\frac{C}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso}}}. 		 	 	Lemma \ref{Iwaniec} gives us, for any $\gamma>0$ and $\lambda$ in the sequence that gives asymptotic equidistribution, the bound	 		 			&\int_{Q_1}\left(\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{iso},\mathrm{BC}}^{z^0,(2)}(z,z^\gamma)\right)^2dz^0\leq\frac{C}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso}}}\leq c_\gamma\lambda^{-\gamma}. 		 	We now compute the other integral as follows: 	 		\int_{\mathcal{R}^{4}}\int_{Q_1}\left(\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{iso},\mathrm{BC}}^{z^0,(2)}(z,z^\gamma)\right)^2dz^0d(z^\gamma,x)\leq c_\gamma\lambda^{-\gamma} R^4, 	for any $\gamma>0$, concluding Lemma \ref{BoundOfNonTrans} in this case.",2502.01291
proof,"In this easier case the error function is, for the Neumann case,	 		 			&\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{equi},\mathrm{N}}^{z^0}(z,z^\gamma) 			=\\&\frac{1}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi}}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi},\mathrm{N}}}\cos\left(\frac{2\pi m\left(z_1-z_1^\gamma\right)}{3\sqrt{\lambda}}\right)\cos\left(\frac{2\pi\sqrt{3}n}{3}\left(2z_2^0+\frac{z_2+z_2^\gamma}{\sqrt{\lambda}}\right)\right), 		 	 while for Dirichlet is 	 		 			&\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{equi},\mathrm{D}}^{z^0}(z,z^\gamma) 			=\\&\frac{-1}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi}}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi},\mathrm{D}}}\cos\left(\frac{2\pi m\left(z_1-z_1^\gamma\right)}{3\sqrt{\lambda}}\right)\cos\left(\frac{2\pi\sqrt{3}n}{3}\left(2z_2^0+\frac{z_2+z_2^\gamma}{\sqrt{\lambda}}\right)\right). 		 	  	As in the previous case, we note that  		\int_{	\mathcal{T}_\mathrm{equi}}\left(\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{equi},\mathrm{BC}}^{z^0}(z,z^\gamma)\right)^2dz^0\leq \int_{Q_E}\left(\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{equi},\mathrm{BC}}^{z^0}(z,z^\gamma)\right)^2dz^0, 	where $Q_E=\left\{(z_1,z_2),\ -1/2\leq z_1\leq 1/2,\ 0\leq z_2\leq \sqrt{3}/2\right\}$. We then have, for fixed $(z,z^\gamma)\in\mathcal{R}^4$,  	 		 			&\int_{Q_E}\left(\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{equi},\mathrm{BC}}^{z^0}(z,z^\gamma)\right)^2dz^0=\\&\frac{1}{\left(\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi}}\right)^2}\sum_{N,M\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi},\mathrm{BC}}}\cos\left(\frac{2\pi m\left(z_1-z_1^\gamma\right)}{3\sqrt{\lambda}}\right)\cos\left(\frac{2\pi a\left(z_1-z_1^\gamma\right)}{3\sqrt{\lambda}}\right)\cdot\\&\int_0^{\sqrt{3}/2}\int_{-1/2}^{1/2}\cos\left(\frac{2\pi\sqrt{3}n}{3}\left(2z_2^0+\frac{z_2+z_2^\gamma}{\sqrt{\lambda}}\right)\right)\cos\left(\frac{2\pi\sqrt{3}b}{3}\left(2z_2^0+\frac{z_2+z_2^\gamma}{\sqrt{\lambda}}\right)\right)dz_1^0dz_2^0.The last integral is $0$ if $n\neq b$ and $\frac{3}{4\sqrt{3}}$ otherwise. Since $3n^2+m^2=3b^2=a^2$, $n=b$ implies that also $a=m$, so we can simplify it as:  	 		 			&\int_{Q_E}\left(\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{equi},\mathrm{BC}}^{z^0}(z,z^\gamma)\right)^2dz^0=\frac{3}{4\sqrt{3}\left(\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi}}\right)^2}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi},\mathrm{BC}}}\cos\left(\frac{2\pi m\left(z_1-z_1^\gamma\right)}{3\sqrt{\lambda}}\right)^2\\&\leq\frac{3}{4\sqrt{3}\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi}}}.  	We conclude like in the last case: applying Lemma \ref{BoundOfNonTrans} and integrating over $\mathcal{R}^4$ we get that, for any $\gamma>0$ and $\lambda$ large enough along the sequence with asymptotic equidistribution,  	 		\int_{\mathcal{R}^{4}}\int_{	\mathcal{T}_\mathrm{equi}}\left(\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{equi},\mathrm{BC}}^{z^0}(z,z^\gamma)\right)^2dz^0d(z^\gamma,x)\leq c_\gamma\lambda^{-\gamma} R^4.",2502.01291
proof,"\textbf{	\underline{Step I:}}	In this final case, the error function is, for Dirichlet conditions,  		 			&\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{hemi},\mathrm{D}}^{z^0}(z,z^\gamma) 			=\frac{1}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi}}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi},\mathrm{D}}}\left(P^{1,\mathrm{N}}_1P^{1,\mathrm{N}}_2-P^{2,\mathrm{N}}_1P^{1,\mathrm{N}}_2-P^{1,\mathrm{N}}_1P^{2,\mathrm{N}}_2\right)(z,z^\gamma,z^0), 		 	 and for Neumann,  	 		 			&\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{hemi},\mathrm{N}}^{z^0}(z,z^\gamma) 			=\frac{1}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi}}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi},\mathrm{N}}}\left(P^{1,\mathrm{N}}_1P^{1,\mathrm{N}}_2+P^{2,\mathrm{N}}_1P^{1,\mathrm{N}}_2+P^{1,\mathrm{N}}_1P^{2,\mathrm{N}}_2\right)(z,z^\gamma,z^0), 		 	where now we define 	 		 			&P_1^{1,\mathrm{N}}(z,z^\gamma,z^0)= \cos\left(\frac{2\pi m}{3}\left(2z_1^0+\frac{z_1+z_1^\gamma}{\sqrt{\lambda}}\right)\right) ,\\ 			&P_1^{2,\mathrm{N}}(z,z^\gamma,z^0)= \cos\left(\frac{2\pi m\left(z_1-z_1^\gamma\right)}{3\sqrt{\lambda}}\right) ,\\ 			&P_2^{1,\mathrm{N}}(z,z^\gamma,z^0)= \cos\left(\frac{2\pi\sqrt{3}n}{3}\left(2z_2^0+\frac{z_2+z_2^\gamma}{\sqrt{\lambda}}\right)\right) ,\\ 			&P_2^{2,\mathrm{N}}(z,z^\gamma,z^0)=\cos\left(\frac{2\pi\sqrt{3}n\left(z_2-z_2^\gamma\right)}{3\sqrt{\lambda}}\right)  . 		 	  	One more time, we notice that   		\int_{\mathcal{T}_\mathrm{hemi}}\left(\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{hemi},\mathrm{BC}}^{z^0}(z,z^\gamma)\right)^2dz^0\leq \int_{Q_{HE}}\left(\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{hemi},\mathrm{BC}}^{z^0}(z,z^\gamma)\right)^2dz^0, 	where $Q_E=\left\{(z_1,z_2),\ 0\leq z_1\leq 3/2,\ 0\leq z_2\leq \sqrt{3}/2\right\}$. We then have, for fixed $(z,z^\gamma)\in\mathcal{R}^4$ and for Dirichlet (the Neumann case is similar without negative signs),  	 	 		 			&\int_{Q_{HE}}\left(\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{hemi},\mathrm{D}}^{z^0}(z,z^\gamma)\right)^2dz^0=\\&\frac{1}{\left|\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{hemi}}\right|^2}\sum_{N,M\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{hemi},\mathrm{D}}}\sum_{\substack{1\leq i,j\leq 2\\1\leq k,l\leq 2\\i+j, k+l<4}}(-1)^{i+j+k+l}\int_{Q_{HE}}\left(P^{i,\mathrm{N}}_1P^{j,\mathrm{N}}_2\right)\left(P^{k,M}_1P^{l,M}_2\right)dz^0=\\&\frac{(-1)^{i+j+k+l}}{\left|\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{hemi}}\right|^2}\sum_{N,M\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{hemi},\mathrm{D}}}\sum_{\substack{1\leq i,j\leq 2\\1\leq k,l\leq 2\\i+j, k+l<4}}\int_0^{\sqrt{3}/2}\left(P^{j,\mathrm{N}}_2P^{l,M}_2\right)dz_2^0\int_{0}^{3/2}\left(P^{i,\mathrm{N}}_1P^{k,M}_1\right)dz_1^0. 	An analysis of the integrals as the one in previous subsections gives us that: 	 		\int_0^{\sqrt{3}/2}\left(P^{2,\mathrm{N}}_2P^{1,M}_2\right)dz_2^0=\int_{0}^{3/2}\left(P^{2,\mathrm{N}}_1P^{1,M}_1\right)dz_1^0=0, 	 	 		 		   & B_1^{2,N,M}=\int_0^{3/2}\left(P^{2,\mathrm{N}}_1P^{2,M}_1\right)dz_1^0\\&=\frac{3}{2}\cos\left(\frac{2\pi m\left(z_1-z_1^\gamma\right)}{3\sqrt{\lambda}}\right)\cos\left(\frac{2\pi a\left(z_1-z_1^\gamma\right)}{3\sqrt{\lambda}}\right), 		 	 		 		    &B_2^{2,N,M}=\int_0^{\sqrt{3}/2}\left(P^{2,\mathrm{N}}_2P^{2,M}_2\right)dz_2^0\\&=\frac{\sqrt{3}}{2}\cos\left(\frac{2\pi\sqrt{3} n\left(z_2-z_2^\gamma\right)}{3\sqrt{\lambda}}\right)\cos\left(\frac{2\pi\sqrt{3} b\left(z_2-z_2^\gamma\right)}{3}\right), 		 	 	 		B_2^{1,N,M}=	\int_0^{\sqrt{3}/2}\left(P^{1,\mathrm{N}}_2P^{1,M}_2\right)dz_2=\left\{ 			& 0\text{ if }n\neq b,\\ 			&\frac{3}{4\sqrt{3}}\text{ if }n=b; 		\right. 	and, finally,  	 		B_1^{1,N,M}=	\int_0^{3/2}\left(P^{1,\mathrm{N}}_1P^{1,M}_1\right)dz_1=\left\{ 			& 0\text{ if }a\neq m,\\ 			&\frac{3}{4}\text{ if }n=b. 		\right. 	When considering the product of two terms, it is always true that it is zero except for the case $N=M$. Therefore, the error satisfies, for any boundary condition, 	 		 			&\int_{Q_{HE}}\left(\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{hemi},\mathrm{BC}}^{z^0}(z,z^\gamma)\right)^2dz^0=\\&\frac{1}{\left|\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{hemi}}\right|^2}\sum_{N,M\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{hemi},\mathrm{BC}}}\left(B_1^{1,N,M}B_2^{1,N,M}+B_1^{2,N,M}B_2^{1,N,M}+B_1^{1,N,M}B_2^{2,N,M}\right)(z,z^\gamma)=\\&\frac{1}{\left|\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{hemi}}\right|^2}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{hemi},\mathrm{BC}}}\left(B_1^{1,N,\mathrm{N}}B_2^{1,N,\mathrm{N}}+B_1^{2,N,\mathrm{N}}B_2^{1,N,\mathrm{N}}+B_1^{1,N,\mathrm{N}}B_2^{2,N,\mathrm{N}}\right)(z,z^\gamma). 	Moreover, notice that $\left|B_j^{i,N,\mathrm{N}}(z,z^\gamma)\right|\leq \frac{3}{2}$ for all $1\leq i,j \leq 2$ and all $(z,z^\gamma)\in\mathcal{R}^4$. 	 \textbf{	\underline{Step II:}} The next step is to integrate over $\mathcal{R}^4$ and bound that integral:  	 		 			&\int_{\mathcal{R}^{4}}\int_{Q_{HE}}\left(\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{hemi},\mathrm{BC}}^{z^0}(z,z^\gamma)\right)^2dz^0d(z,z^\gamma)\leq\\&\frac{1}{\left|\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{hemi}}\right|^2}\sum_{N\in\mathcal{N}_\lambda}\int_{\mathcal{R}^{4}}\left|B_1^{1,N,\mathrm{N}}B_2^{1,N,\mathrm{N}}+B_1^{2,N,\mathrm{N}}B_2^{1,N,\mathrm{N}}+B_1^{1,N,\mathrm{N}}B_2^{2,N,\mathrm{N}}\right|d(z,z^\gamma)\leq\\&\frac{1}{\left|\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{hemi}}\right|^2}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{hemi},\mathrm{BC}}}\frac{27}{4}\int_{\mathcal{R}^{4}}d(z,z^\gamma)\leq\frac{27R^4}{4\left|\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{hemi}}\right|}. 	To conclude, we apply Lemma \ref{BoundOfNonTrans}, to get that, for any $\gamma>0$,  		\int_{\mathcal{R}^{4}}\int_{\mathcal{T}_\mathrm{hemi}}\left(\mathcal{E}_{\lambda,\mathcal{T}_\mathrm{hemi},\mathrm{BC}}^{z^0}(z,z^\gamma)\right)^2dz^0d(z,z^\gamma)\leq c_\gamma\lambda^{-\gamma}R^{4}. 	 	The study of these four cases concludes the proof of the lemma and, therefore, of Theorem \ref{pnft}.",2502.01291
proof,"\textbf{	\underline{Step I:}} 	We just follow Step I in the proof of Theorem \ref{pnft} to get a function $\phi$ that	approximates the function $\vp$ in the ball as 	 		\|\phi-\varphi\|_{C^k(B)}<\ep/2, 	 	and that can be written as  	 		\phi(z)=\sum_{\gamma=1}^{L} c_\gamma\int_{\mathbb{S}^{d-1}}e^{i(z-z^\gamma)\xi}d\sigma_{\mathbb{S}^{d-1}}(\xi), 	 	with large $L>0$, $R\geq 1$, ${c}_\gamma\in\mathbb{R}$ and $z^\gamma\in B_R\subset\mathbb{R}^d$ for all $1\leq \gamma\leq L$. 	Choosing  		p(\xi)=\sum_{\gamma=1}^{L} c_\gamma e^{-i\xi z^\gamma}, 	we get also the expression 	 		\phi(z)=\int_{\mathbb{S}^{d-1}} e^{i z\cdot\xi} p(\xi) \, d\si_{\mathbb{S}^{d-1}}(\xi), 	 	where $p$ is a complex-valued Hermitian polynomial (i.e., $p(-\xi)=\overline{p(\xi)}$). 	 	As already studied in Appendix \ref{AppendixC}, all the different conditions that we ask on $\vp$ can be seen as follows: 		\vp\left(S^{\mathcal{P}}_j\left(z\right)\right)=\left(-1\right)^{\sigma_\mathrm{BC}}\vp(z),\ 1\leq j\leq J_\mathcal{P}, 	 	where $\sigma_D=1$ and $\sigma_N=2$ and $S^\mathcal{P}_j$ is an orthogonal symmetry for any $1\leq j\leq J_\mathcal{P}$ and all $\mathcal{P}$ (see Remark \ref{conditions} for a precise description of these transforms). Notice that it was seen in Appendix \ref{AppendixC} there there exist such monochromatic waves. 	 	Thanks to these extra conditions, it is not difficult to see (use e.g. Herglotz's theorem \cite[Theorem 7.1.27]{Hor}) that, for any $1\leq j\leq J_\mathcal{P}$, $p$ can be chosen so that it satisfies the same conditions: 		p\left(S^{\mathcal{P}}_j\left(z\right)\right)=\left(-1\right)^{c_\mathrm{BC}}p(z),\ 1\leq j\leq J_\mathcal{P}. 	To do this, we notice that if the polynomial $p$ does not satisfy these conditions we can consider a new monochromatic wave $\tilde{\phi}$ given by \tilde{	\phi}(z)=\int_{\mathbb{S}^{d-1}} e^{i z\cdot\xi} \tilde{p}(\xi) \, d\si_{\mathbb{S}^{d-1}}(\xi)=\int_{\mathbb{S}^{d-1}} e^{i z\cdot\xi} \frac{\left(-1\right)^{\sigma_{\mathrm{BC}}}}{J_\mathcal{P}}\sum_{j=1}^{J_\mathcal{P}}p\left(S^\mathcal{P}_j\left(\xi\right)\right) \, d\si_{\mathbb{S}^{d-1}}(\xi). 	It is clear that $\tilde{p}$ satisfies the desired conditions and notice that 	 	 	&\|\tilde{\phi}-\varphi\|_{C^k(B)}\leq\left\|\tilde{\phi}-\frac{\left(-1\right)^{\sigma_{\mathrm{BC}}}}{J_\mathcal{P}}\sum_{j=1}^{J_\mathcal{P}}\left(\varphi\circ S^\mathcal{P}_j\right)\right\|_{C^k(B)}\leq\\&\left\|\frac{\left(-1\right)^{\sigma_{\mathrm{BC}}}}{J_\mathcal{P}}\sum_{j=1}^{J_\mathcal{P}}\left(\int_{\mathbb{S}^{d-1}} e^{i z\cdot\xi} p\left(S^\mathcal{P}_j\left(\xi\right)\right) \, d\si_{\mathbb{S}^{d-1}}(\xi)-\left(\varphi\circ S^\mathcal{P}_j(z)\right)\right)\right\|_{C^k(B)}\\&\leq \frac{1}{J_\mathcal{P}}\sum_{j=1}^{J_\mathcal{P}}\left\|\phi\circ S^\mathcal{P}_j-\varphi\circ S^\mathcal{P}_j\right\|_{C^k(B)}\leq\|\phi-\varphi\|_{C^k(B)}<\ep/2. 	 	 	Notice now that these conditions allow us to rewrite \eqref{HermitianpolyII} as 	 		\phi(z)=\int_{\mathbb{S}^{d-1}}p(\xi)\mathbb{T}_\mathcal{P}(z,\xi)d\si_{\mathbb{S}^{d-1}}(\xi), 	where $\mathbb{T}_\mathcal{P}$ is a trigonometric function that depends on the polygon and boundary conditions under consideration. Note also that in the particular case of $\mathcal{P}=	\mathcal{T}_\mathrm{equi}$, we get something slightly different: 		\phi(z)=\int_{\mathbb{S}^{1}}\left(p_s(\xi)\mathbb{T}_{	\mathcal{T}_\mathrm{equi}}^s(z,\xi)+p_a(\xi)\mathbb{T}_{	\mathcal{T}_\mathrm{equi}}^a(z,\xi)\right)d\si_{\mathbb{S}^{d-1}}(\xi), 	where both $\mathbb{T}_{	\mathcal{T}_\mathrm{equi}}^s(z,\xi)$ and $\mathbb{T}_{	\mathcal{T}_\mathrm{equi}}^a(z,\xi)$ are trigonometric functions and $p_s$ and $p_a $ are the symmetric and antisymmetric part of $p(\cdot,\xi_2)$, i.e., $p(\xi)=p_a(\xi)+p_s(\xi),$ with  		 p_a(-\xi_1,\xi_2)=-p_a(\xi),\text{ and } p_s(-\xi_1,\xi_2)=p_s(\xi). 	 	The precise functions are as in the following tables: for Dirichlet boundary condition, we have   	 		{cc}  			\hline 			\rule{0pt}{3ex}Polygon & $\mathbb{T}_\mathcal{P}$ \\ 			\hline 			 \rule{0pt}{3ex}$\mathcal{Q}_l$& $\prod_{j=1}^d\sin\left(z_j\xi_j\right)$\\ 			 \rule{0pt}{3ex}$\mathcal{T}_\mathrm{iso}$ & $\sin\left(z_1\xi_1\right)\sin\left(z_2\xi_2\right)-\sin\left(z_1\xi_2\right)\sin\left(z_2\xi_1\right)$ \\ 			 			 \rule{0pt}{3ex}$	\mathcal{T}_\mathrm{equi}$ & $\mathbb{T}_{	\mathcal{T}_\mathrm{equi}}^s(z,\xi)= \cos\left(z_1\xi_1\right)\sin\left(z_2\xi_2\right)$ and $\mathbb{T}_{	\mathcal{T}_\mathrm{equi}}^a(z,\xi)= \sin\left(z_1\xi_1\right)\sin\left(z_2\xi_2\right)$\\ 			 \rule{0pt}{3ex}$\mathcal{T}_\mathrm{hemi}$ & $\sin\left(z_1\xi_1\right)\sin\left(z_2\xi_2\right)$ \\\hline 		  	While, on the other hand, for Neumann boundary conditions, we have  	 		{cc}  			\hline 			\rule{0pt}{3ex}Polygon & $\mathbb{T}_\mathcal{P}$ \\ 		 			\hline 		\rule{0pt}{3ex}$\mathcal{Q}_l$ & $\prod_{j=1}^d\cos\left(z_j\xi_j\right)$ \\ 			\rule{0pt}{3ex} $\mathcal{T}_\mathrm{iso}$ & $\cos\left(z_1\xi_1\right)\cos\left(z_2\xi_2\right)-\cos\left(z_1\xi_2\right)\cos\left(z_2\xi_1\right)$  \\ 			 \rule{0pt}{3ex}$	\mathcal{T}_\mathrm{equi}$ & $\mathbb{T}_{	\mathcal{T}_\mathrm{equi}}^s(z,\xi)= \cos\left(z_1\xi_1\right)\cos\left(z_2\xi_2\right)$ and $\mathbb{T}_{	\mathcal{T}_\mathrm{equi}}^a(z,\xi)= \sin\left(z_1\xi_1\right)\cos\left(z_2\xi_2\right)$ \\ 			\rule{0pt}{3ex} $\mathcal{T}_\mathrm{hemi}$ & $\cos\left(z_1\xi_1\right)\cos\left(z_2\xi_2\right)$ \\ 			\hline 		  	 \textbf{	\underline{Step II:}} We now make some computations (that will depend of the polygon under consideration) to approximate this function by eigenfunctions. 	 	For the case $\mathcal{P}=\mathcal{Q}_l$ we notice that, for Dirichlet conditions, 	 		\int_{\mathbb{S}^{d-1}} p(\xi) \prod_{j=1}^d\sin\left(z_j\xi_j\right) d\sigma_{\mathbb{S}^{d-1}}(\xi)=C_{\mathcal{Q}_l}\int_{\mathcal{M}^{\mathcal{Q}_l}}p(\xi) \prod_{j=1}^d\sin\left(\frac{z_j\pi}{l_j}\xi_j\right)d\sigma_{\mathcal{M}^{\mathcal{Q}_l}}(\xi), 	and, in the Neumann case,  	 		\int_{\mathbb{S}^{d-1}} p(\xi) \prod_{j=1}^d\cos\left(z_j\xi_j\right) d\sigma_{\mathbb{S}^{d-1}}(\xi)=C_{\mathcal{Q}_l}\int_{\mathcal{M}^{\mathcal{Q}_l}}p(\xi) \prod_{j=1}^d\cos\left(\frac{z_j\pi}{l_j}\xi_j\right)d\sigma_{\mathcal{M}^{\mathcal{Q}_l}}(\xi). 	 	 	We now choose $\lambda$ along a sequence in which we have asymptotic equidistribution as introduced in Definition \ref{aequid} and satisfies the same extra conditions as in Step 3 of the proof of Theorem \ref{pnft}. Thus we have, for Dirichlet, 	 		 			&\frac{C_{\mathcal{Q}_l}|\mathcal{M}^{\mathcal{Q}_l}|}{\#\mathcal{N}_\lambda^{\mathcal{Q}_l}}\sum_{N\in \mathcal{N}_\lambda^{\mathcal{Q}_l}}p\left(\frac{N}{\sqrt{\lambda}}\right) \prod_{j=1}^d\sin\left(\frac{z_jN_j\pi}{l_j\sqrt{\lambda}}\right)+\mathbb{E}(\lambda)\\ 			&	=\frac{2^dC_{\mathcal{Q}_l}|\mathcal{M}^{\mathcal{Q}_l}|}{\#\mathcal{N}_\lambda^{\mathcal{Q}_l}}\sum_{N\in \mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}c_N \prod_{j=1}^d\sin\left(\frac{z_jN_j\pi}{l_j\sqrt{\lambda}}\right)+\mathbb{E}(\lambda); 		 	and in the Neumann case 	 		 			&\frac{C_{\mathcal{Q}_l}|\mathcal{M}^{\mathcal{Q}_l}|}{\#\mathcal{N}_\lambda^{\mathcal{Q}_l}}\sum_{N\in \mathcal{N}_\lambda^{\mathcal{Q}_l}}p\left(\frac{N}{\sqrt{\lambda}}\right) \prod_{j=1}^d\cos\left(\frac{z_jN_j\pi}{l_j\sqrt{\lambda}}\right)+\mathbb{E}(\lambda)\\ 			&	=\frac{2^dC_{\mathcal{Q}_l}|\mathcal{M}^{\mathcal{Q}_l}|}{\#\mathcal{N}_\lambda^{\mathcal{Q}_l}}\sum_{N\in \mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{N}}}c_N \prod_{j=1}^d\cos\left(\frac{z_jN_j\pi}{l_j\sqrt{\lambda}}\right)+\mathbb{E}(\lambda); 		 	where	$\mathbb{E}(\lambda)$ is an error function that satisfies $\lim_{\lambda_n\rightarrow\infty}\mathbb{E}(\lambda_n)=0$, when $\lambda_n$ is a subsequence with the asymptotic equidistribution property (see again Definition \ref{aequid}), and $c_m$ is given by all the possible changes of sign in $p\left(\frac{N}{\sqrt{\lambda}}\right)$. 	 	We then have  		\vp(z)=\frac{2^dC_{\mathcal{Q}_l}|\mathcal{M}^{\mathcal{Q}_l}|}{\#\mathcal{N}_\lambda^{\mathcal{Q}_l}}\sum_{N\in \mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{D}}}c_N \prod_{j=1}^d\sin\left(\frac{z_jN_j\pi}{l_j\sqrt{\lambda}}\right)+\mathbb{E}(\lambda)+\frac{\ep}{2}, 	for $\mathrm{BC}=D$ and, for $\mathrm{BC}=N$,  	 		\vp(z)=\frac{2^dC_{\mathcal{Q}_l}|\mathcal{M}^{\mathcal{Q}_l}|}{\#\mathcal{N}_\lambda^{\mathcal{Q}_l}}\sum_{N\in \mathcal{N}_\lambda^{\mathcal{Q}_l,\mathrm{N}}}c_N \prod_{j=1}^d\cos\left(\frac{z_jN_j\pi}{l_j\sqrt{\lambda}}\right)+\mathbb{E}(\lambda)+\frac{\ep}{2}. 	 	 	When $\mathcal{P}=\mathcal{T}_\mathrm{iso}$, we first note that 	 		 			&\int_{\mathbb{S}^{1}}p(\xi)\left(\sin(z_1\xi_1)\sin(z_2\xi_2)-\sin(z_1\xi_2)\sin(z_2\xi_1)\right)d\si_{\mathbb{S}^{1}}(\xi)\\&=\int_{\mathbb{S}^{1}}\left(p(\xi)-p(\xi_2,\xi_1)\right)\sin(z_1\xi_1)\sin(z_2\xi_2)d\si_{\mathbb{S}^{1}}(\xi),  		 	and also  		 			&\int_{\mathbb{S}^{1}}p(\xi)\left(\cos(z_1\xi_1)\cos(z_2\xi_2)+\cos(z_1\xi_2)\cos(z_2\xi_1)\right)d\si_{\mathbb{S}^{1}}(\xi)\\&=\int_{\mathbb{S}^{1}}\left(p(\xi)+p(\xi_2,\xi_1)\right)\cos(z_1\xi_1)\cos(z_2\xi_2)d\si_{\mathbb{S}^{1}}(\xi). 		 	Therefore, a similar approach allows us to get  	 		\vp(z)=\frac{4|\mathbb{S}^1|}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso}}}\sum_{N\in \mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso},\mathrm{D}}}c_N \sin\left(\frac{z_1N_1\pi}{\sqrt{\lambda}}\right)\sin\left(\frac{z_2N_2\pi}{\sqrt{\lambda}}\right)+\mathbb{E}(\lambda)+\frac{\ep}{2}, 	 for the Dirichlet case, where $c_N$ is defined with all the possible signs in      $$     p\left(\frac{\pi N_1}{\sqrt{\lambda}},\frac{\pi N_2}{\sqrt{\lambda}}\right)-p\left(\frac{\pi N_2}{\sqrt{\lambda}},\frac{\pi N_1}{\sqrt{\lambda}}\right)     $$ and satisfy $c_{N_2,N_1}=-c_{N_1,N_2}$, and for Neumann, 	 		\vp(z)=\frac{4|\mathbb{S}^1|}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso}}}\sum_{N\in \mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso},\mathrm{N}}}c_N \cos\left(\frac{z_1N_1\pi}{\sqrt{\lambda}}\right)\cos\left(\frac{z_2N_2\pi}{\sqrt{\lambda}}\right)+\mathbb{E}(\lambda)+\frac{\ep}{2}, 	where $c_N$ is now defined with $p\left(\frac{\pi N_1}{\sqrt{\lambda}},\frac{\pi N_2}{\sqrt{\lambda}}\right)+p\left(\frac{\pi N_2}{\sqrt{\lambda}},\frac{\pi N_1}{\sqrt{\lambda}}\right)$ and satisfy $c_{N_2,N_1}=c_{N_1,N_2}$. 	 	When $\mathcal{P}=	\mathcal{T}_\mathrm{equi}$, choosing correctly $c_N^a$ and $c_N^s$, we get to similar expressions: 	 		 			&\vp(z)=\mathbb{E}(\lambda)+\frac{\ep}{2}+\\&\frac{4|\mathcal{M}^{	\mathcal{T}_\mathrm{equi}}|}{\sqrt{3}\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi}}}\sum_{N\in \mathcal{N}_\lambda^{	\mathcal{T}_\mathrm{equi}},\mathrm{D}} \sin\left(\frac{2n\pi\sqrt{3}z_2}{3\sqrt{\lambda}}\right)\left[c_N^s\cos\left(\frac{2\pi mz_1}{3\sqrt{\lambda}}\right)+c_N^a\sin\left(\frac{2\pi mz_1}{3\sqrt{\lambda}}\right)\right], 		 	when considering Dirichlet and 		 			&\vp(z)=\mathbb{E}(\lambda)+\frac{\ep}{2}+\\&\frac{4|\mathcal{M}^{	\mathcal{T}_\mathrm{equi}}|}{\sqrt{3}\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi}}}\sum_{N\in \mathcal{N}_\lambda^{	\mathcal{T}_\mathrm{equi}},\mathrm{N}} \cos\left(\frac{2n\pi\sqrt{3}z_2}{3\sqrt{\lambda}}\right)\left[c_N^s\cos\left(\frac{2\pi mz_1}{3\sqrt{\lambda}}\right)+c_N^a\sin\left(\frac{2\pi mz_1}{3\sqrt{\lambda}}\right)\right], 		 	for Neumann. 	Finally, the same works for $\mathcal{P}=\mathcal{T}_\mathrm{hemi}$, with Dirichlet,  	 		 			&\vp(z)=\mathbb{E}(\lambda)+\frac{\ep}{2}+\frac{4|\mathcal{M}^{	\mathcal{T}_\mathrm{equi}}|}{\sqrt{3}\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi}}}\sum_{N\in \mathcal{N}_\lambda^{	\mathcal{T}_\mathrm{equi}},\mathrm{D}}c_N \sin\left(\frac{2n\pi\sqrt{3}z_2}{3\sqrt{\lambda}}\right)\sin\left(\frac{2\pi mz_1}{3\sqrt{\lambda}}\right), 		 	and for Neumann, 	 		 			&\vp(z)=\mathbb{E}(\lambda)+\frac{\ep}{2}+\frac{4|\mathcal{M}^{	\mathcal{T}_\mathrm{equi}}|}{\sqrt{3}\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi}}}\sum_{N\in \mathcal{N}_\lambda^{	\mathcal{T}_\mathrm{equi}},\mathrm{N}}c_N \cos\left(\frac{2n\pi\sqrt{3}z_2}{3\sqrt{\lambda}}\right)\cos\left(\frac{2\pi mz_1}{3\sqrt{\lambda}}\right). 		 	 	For the next part of the proof, we differentiate into two different cases depending on the point $z^0\in\mathcal{P}$ around which we want to approximate. 	 \textbf{	\underline{Step III:}} In this step we consider those points with all components being rational with respect to the sides of $\mathcal{P}$. This means, when $\mathcal{P}=\mathcal{Q}_l$, that 	 		z^0=(z^0_1,\ldots,z_d^0)=\left(\frac{r_1}{s_1}l_1,\ldots,\frac{r_{d-1}}{s_{d-1}}l_{d-1},\frac{r_d}{s_d}\right); 	for $r_j,s_j\in\mathbb{N}$ for any $1\leq j\leq d$; when $\mathcal{P}=\mathcal{T}_\mathrm{iso}$ that 		z^0=(z^0_1,z_2^0)=\left(\frac{r_1}{s_1},\frac{r_2}{s_2}\right); 	 and, finally, when $\mathcal{P}=	\mathcal{T}_\mathrm{equi}$ or $\mathcal{P}=\mathcal{T}_\mathrm{hemi}$ that  	 		z^0=(z^0_1,z_2^0)=\left(\frac{3r_1}{2s_1},\frac{\sqrt{3}r_2}{2s_2}\right), 	 	both with $r_1,r_2,s_1,s_2\in\mathbb{N}$. In any case, let $s=\LCM(s_1,\ldots,s_d)$ (with $d=2$ whenever $\mathcal{P}\neq \mathcal{Q}_l$). We choose $\lambda$ in the asymptotically equidistributed subsequence and large enough so that $\mathbb{E}(\lambda)<\frac{\ep}{2}$ and consider the eigenvalue $\lambda s^2$ and an associated eigenfunction  that depends on the polygon 		u_{s^2\lambda}^{\mathcal{P},\mathrm{BC}}\left(z^0+\frac{z}{s\sqrt{\lambda}}\right).  	The eigenfunctions are as in the following tables: for Dirichlet boundary conditions, 	 		\vspace{0.1cm} 		 	{cc}  		\hline 		\rule{0pt}{3ex}Polygon & $u_{s^2\lambda}^{\mathcal{P},\mathrm{BC}}(z)$\vspace{0.1cm} \\ 		\hline 		\rule{0pt}{5ex}$\mathcal{Q}_l$& $\frac{2^dC_{\mathcal{Q}_l}|\mathcal{M}^{\mathcal{Q}_l}|}{\left|\mathcal{N}_{\lambda}^{\mathcal{Q}_l}\right|}\sum_{M\in \mathcal{N}_{s^2\lambda}^{\mathcal{Q}_l,\mathrm{D}}}C_M \prod_{j=1}^d\sin\left(\frac{z_jM_j\pi}{l_j}\right)$\\ 		\rule{0pt}{5ex} $\mathcal{T}_\mathrm{iso}$ & $\frac{4|\mathbb{S}^1|}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso}}}\sum_{M\in \mathcal{N}_{s^2\lambda}^{\mathcal{T}_\mathrm{iso},\mathrm{D}}}C_M \sin\left(z_1M_1\pi\right)\sin\left(z_2M_2\pi\right)$ \\ 		 		\rule{0pt}{5ex} $	\mathcal{T}_\mathrm{equi}$ & $\frac{4|\mathcal{M}^{	\mathcal{T}_\mathrm{equi}}|}{\sqrt{3}\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi}}}\sum_{M\in \mathcal{N}_{s^2\lambda}^{	\mathcal{T}_\mathrm{equi}},\mathrm{D}} \sin\left(\frac{2M_2\pi\sqrt{3}z_2}{3}\right)\left[C_M^s\cos\left(\frac{2\pi M_1z_1}{3}\right)+C_M^a\sin\left(\frac{2\pi M_1z_1}{3}\right)\right]$\\ 		\rule{0pt}{5ex} $\mathcal{T}_\mathrm{hemi}$ & $\frac{4|\mathcal{M}^{	\mathcal{T}_\mathrm{equi}}|}{\sqrt{3}\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi}}}\sum_{M\in \mathcal{N}_{s^2\lambda}^{	\mathcal{T}_\mathrm{equi}},\mathrm{D}}C_M \sin\left(\frac{2M_2\pi\sqrt{3}z_2}{3}\right)\sin\left(\frac{2\pi M_1z_1}{3}\right)$ \\  \vspace{0.1cm} 	  	  			while for Neumann boundary condition, 	 	\vspace{0.1cm} 	 		{cc}  		\hline 		\rule{0pt}{3ex} Polygon & $u_{s^2\lambda}^{\mathcal{P},\mathrm{BC}}(z)$ \vspace{0.1cm}\\ 		\hline 			\rule{0pt}{5ex}   $\mathcal{Q}_l$ & $\frac{2^dC_{\mathcal{Q}_l}|\mathcal{M}^{\mathcal{Q}_l}|}{\left|\mathcal{N}_{\lambda}^{\mathcal{Q}_l}\right|}\sum_{M\in \mathcal{N}_{s^2\lambda}^{\mathcal{Q}_l,\mathrm{N}}}C_M \prod_{j=1}^d\cos\left(\frac{z_jM_j\pi}{l_j}\right)$ \\ 			\rule{0pt}{5ex}  $\mathcal{T}_\mathrm{iso}$ & $\frac{4|\mathbb{S}^1|}{\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{iso}}}\sum_{M\in \mathcal{N}_{s^2\lambda}^{\mathcal{T}_\mathrm{iso},\mathrm{N}}}C_M \cos\left(z_1M_1\pi\right)\cos\left(z_2M_2\pi\right)$  \\ 			\rule{0pt}{5ex}  $	\mathcal{T}_\mathrm{equi}$ & $\frac{4|\mathcal{M}^{	\mathcal{T}_\mathrm{equi}}|}{\sqrt{3}\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi}}}\sum_{M\in \mathcal{N}_{s^2\lambda}^{	\mathcal{T}_\mathrm{equi}},\mathrm{N}} \cos\left(\frac{2M_2\pi\sqrt{3}z_2}{3}\right)\left[C_M^s\cos\left(\frac{2\pi M_1z_1}{3}\right)+C_M^a\sin\left(\frac{2\pi M_1z_1}{3}\right)\right]$ \\ 			\rule{0pt}{5ex}  $\mathcal{T}_\mathrm{hemi}$ & $\frac{4|\mathcal{M}^{	\mathcal{T}_\mathrm{equi}}|}{\sqrt{3}\#\mathcal{N}_\lambda^{\mathcal{T}_\mathrm{equi}}}\sum_{M\in \mathcal{N}_{s^2\lambda}^{	\mathcal{T}_\mathrm{equi}},\mathrm{N}}C_M \cos\left(\frac{2M_2\pi\sqrt{3}z_2}{3}\right)\cos\left(\frac{2\pi M_1z_1}{3}\right)$ \\\vspace{0.1cm}	 	  	 	To conclude, we have defined  		C_{M}^*=\left\{ 			&c_{N}^*(-1)^{\sum_{j=1}^d r_j N_j\frac{s}{s_j}}\text{ if }M=sN 			\\ 			&0, \text{ otherwise.} 		\right. 	Here $*$ represents $s$ and $a$ in the equilateral triangle case and nothing in all the other cases. We have also used the trigonometric identities  		 			&\cos\left(x+n\pi\right)=(-1)^n\cos\left(x\right),\\ 			&\sin\left(x+n\pi\right)=(-1)^n\sin\left(x\right), 		 	 	so that we get  		\left\|u_{s^2\lambda}^{\mathcal{P},\mathrm{BC}}\left(z^0+\frac{\cdot}{s\sqrt{\lambda}}\right)-\vp\right\|_{C^0(B)}=\mathbb{E}(\lambda)+\frac{\ep}{2}<\ep. 	 \textbf{	\underline{Step IV:}}  In this final step, we consider points with at least one component being irrational with respect to the sides of $\mathcal{P}$. This means, when $\mathcal{P}=\mathcal{Q}_l$,  	 		z^0=\left(z^0_1,\ldots,z^0_d\right)=\left(\alpha_1l_1,\ldots,\alpha_{d-1}l_{d-1},\alpha_d\right) 	 with some $\alpha_j\notin\mathbb{Q}$; when $\mathcal{P}=\mathcal{T}_\mathrm{iso}$ that 		z^0=(z^0_1,z_2^0)=\left(\alpha_1,\alpha_2\right); 	 and, finally, when $\mathcal{P}=	\mathcal{T}_\mathrm{equi}$ or $\mathcal{P}=\mathcal{T}_\mathrm{hemi}$ that  	 		z^0=(z^0_1,z_2^0)=\left(\frac{3\alpha_1}{2},\frac{\sqrt{3}\alpha_2}{2}\right), 	with the same condition: either $\alpha_1$ or $\alpha_2$ is not in $\mathbb{Q}$. 	 	 	 	We choose $\lambda$ large enough so that $\mathbb{E}(\lambda)<\ep/4$. Let us also consider the quantity  		F(\lambda)=\frac{2^d\pi C_{\mathcal{P}}|\mathcal{M}^{\mathcal{P}}|}{\left|\mathcal{N}_{\lambda}^{\mathcal{P}}\right|}\sum_{N\in \mathcal{N}_{\lambda}^{\mathcal{P},\mathrm{BC}}}|c_N|\left(N_1+\ldots+N_d\right).  	It might be large but it is finite for a fixed $\lambda$. We recall that $d=2$ except when $\mathcal{P}=\mathcal{Q}_l$. We use now Dirichlet's approximation theorem \cite[Theorem 1B]{Sch}. 	[Dirichlet's approximation theorem] 		 		Given $\alpha_1,\ldots,\alpha_d$ in $\mathbb{R}$ with at least one of them being irrational, then there are infinitely many $d-$tuples $\left(\frac{r_1}{s},\ldots,\frac{r_d}{s}\right)$ with $\GCD(s,r_1,\ldots,r_d)=1$ and  			\left|\alpha_i-\frac{r_i}{s}\right|<\frac{1}{s^{1+(1/d)}},\ \ \ i=1,\ldots,d. 		 	 	Since there are infinitely many $d-$tuples, we can choose a sequence of integer numbers $\left\{(s^n,r_1^n,\ldots,r_d^n)\right\} _{n=1}^\infty$ satisfying that $\lim_{n\rightarrow\infty}s^n=\infty$. Therefore, choosing $N$ large enough, we can assure that for $s:=s^N$  		\frac{F(\lambda)}{s^{1/d}}<\ep/2. 	 	Let us also define $r_j:=r_j^N$ for all $1\leq j\leq d$. We then consider the point $y^0$ rational with respect to the sides of $\mathcal{P}$ as in the previous step: when $\mathcal{P}=\mathcal{Q}_l$,  	 		y^0=(y^0_1,\ldots,y_d^0)=\left(\frac{r_1}{s}l_1,\ldots,\frac{r_{d-1}}{s}l_{d-1},\frac{r_d}{s}\right); 	for $\mathcal{P}=\mathcal{T}_\mathrm{iso}$, 		y^0=(y^0_1,y_2^0)=\left(\frac{r_1}{s},\frac{r_2}{s}\right); 	 and, finally, when $\mathcal{P}=	\mathcal{T}_\mathrm{equi}$ or $\mathcal{P}=\mathcal{T}_\mathrm{hemi}$ that  	 		y^0=(y^0_1,y_2^0)=\left(\frac{3r_1}{2s},\frac{\sqrt{3}r_2}{2s}\right). 	 	 	Doing just like in the previous step, we get to   		\left\|u_{s^2\lambda}^{\mathcal{P},\mathrm{BC}}\left(y^0+\frac{\cdot}{s\sqrt{\lambda}}\right)-\vp\right\|_{C^0(B)}<\ep/2. 	For any $z\in B$, using the Mean Value Theorem, we have the following  			&\left|u_{s^2\lambda}^{\mathcal{P},\mathrm{BC}}\left(y^0+\frac{z}{s\sqrt{\lambda}}\right)-u_{s^2\lambda}^{\mathcal{P},\mathrm{BC}}\left(z^0+\frac{z}{s\sqrt{\lambda}}\right)\right| \\&\leq 			\frac{2^d\pi C_{\mathcal{P}}|\mathcal{M}^{\mathcal{P}}|}{\left|\mathcal{N}_{\lambda}^{\mathcal{P}}\right|}\sum_{N\in \mathcal{N}_{\lambda}^{\mathcal{P},\mathrm{BC}}}|c_N| \sum_{j=1}^d\left(sN_j\left|\frac{r_j}{s_j}-\alpha_j\right|\right)\\ 			&<s^{-1/d}\frac{2^d\pi C_{\mathcal{P}}|\mathcal{M}^{\mathcal{P}}|}{\left|\mathcal{N}_{\lambda}^{\mathcal{P}}\right|}\sum_{N\in \mathcal{N}_{\lambda}^{\mathcal{P},\mathrm{BC}}}|c_N| \sum_{j=1}^d\left(N_j\right)=\frac{F(\lambda)}{s^{1/d}}<\frac{\ep}{2}. 		 	Finally,  	 			&\left\|u_{s^2\lambda}^{\mathcal{P},\mathrm{BC}}\left(z^0+\frac{\cdot}{s\sqrt{\lambda}}\right)-\vp\right\|_{C^0(B)}\leq\left\|u_{s^2\lambda}^{\mathcal{P},\mathrm{BC}}\left(y^0+\frac{\cdot}{s\sqrt{\lambda}}\right)-\vp\right\|+ \\&\left\|u_{s^2\lambda}^{\mathcal{P},\mathrm{BC}}\left(y^0+\frac{\cdot}{s\sqrt{\lambda}}\right)-u_{s^2\lambda}^{\mathcal{P},\mathrm{BC}}\left(z^0+\frac{\cdot}{s\sqrt{\lambda}}\right)\right\|_{C^0(B)}<\ep/2+\ep/2=\ep. 	 	In any of the two cases, using standard elliptic estimates we get the same for the $C^k\left(B\right)$ norm, which completes the proof.",2502.01291
proof,"We first see the case of $\mathcal{P}=Q_1$ and recall the formulas for the eigenfunctions that we saw in Section \ref{rect}. We will use also the following result proved in~\cite[Theorem 1.1.]{RudWig}: 	 		There exists $\Sigma_0^{Q_1}>0$ so that for all $0<\Sigma<\Sigma_0^{Q_1}$ there are no spectral multiplicities other than the trivial ones $\lambda_{nm}^\Sigma=\lambda_{mn}^\Sigma$. 	 	Using this, we know that for any eigenvalue $\lambda_{nm}^\Sigma$ all the eigenfunctions associated to the Robin condition given by $\Sigma$ have the following form:  	 		 			u_{nm}(z_1,z_2)=&c_1\left(k_n\cos\left(k_nz_1\right)+\Sigma\sin(k_nz_1)\right)\cdot \left(k_m\cos\left(k_mz_2\right)+\Sigma\sin(k_mz_2)\right)+\\&c_2\left(k_m\cos\left(k_mz_1\right)+\Sigma\sin(k_mz_1)\right)\cdot \left(k_n\cos\left(k_nz_2\right)+\Sigma\sin(k_nz_2)\right), 		 	 	with $c_1,c_2$ arbitrary real constants. Localizing on any $(z_1^0,z_2^0)\in Q_1$ we have the following formula. 	 	 		 			u_{nm}\left(z_1^0+\frac{z_1}{\sqrt{\lambda}},z_2^0+\frac{z_2}{\sqrt{\lambda}}\right)=&c_1\left[k_n\cos\left(k_n\left(z_1^0+\frac{z}{\sqrt{\lambda}}\right)\right)+\Sigma\sin\left(k_n\left(z_1^0+\frac{z}{\sqrt{\lambda}}\right)\right)\right]\cdot\\&\cdot \left[k_m\cos\left(k_m\left(z_2^0+\frac{z_2}{\sqrt{\lambda}}\right)\right)+\Sigma\sin\left(k_m\left(z_2^0+\frac{z_2}{\sqrt{\lambda}}\right)\right)\right]+\\&c_2\left[k_m\cos\left(k_m\left(z_1^0+\frac{z}{\sqrt{\lambda}}\right)\right)+\Sigma\sin\left(k_m\left(z_1^0+\frac{z}{\sqrt{\lambda}}\right)\right)\right]\cdot\\&\cdot \left[k_n\cos\left(k_n\left(z_2^0+\frac{z_2}{\sqrt{\lambda}}\right)\right)+\Sigma\sin\left(k_n\left(z_2^0+\frac{z_2}{\sqrt{\lambda}}\right)\right)\right]. 		 	 Using trigonometric simplifications this is equal to  	 		 			&	u_{nm}\left(z_1^0+\frac{z_1}{\sqrt{\lambda}},z_2^0+\frac{z_2}{\sqrt{\lambda}}\right)=\sqrt{\left(k_n^2+\Sigma^2\right)\left(k_m^2+\Sigma^2\right)}\cdot\\&\left[c_1\sin\left(\frac{k_nz_1}{\sqrt{\lambda}}+z_1^{0,n}\right)\sin\left(\frac{k_mz_2}{\sqrt{\lambda}}+z_2^{0,m}\right)\right.+\left.c_2\sin\left(\frac{k_mz_1}{\sqrt{\lambda}}+z_1^{0,m}\right)\sin\left(\frac{k_nz_2}{\sqrt{\lambda}}+z_2^{0,n}\right)\right], 		 	 	taking $z_1^{0,n}=\arctan\left(\frac{k_n}{\Sigma}\right)+k_nz_1^0$ and similarly for $z_1^{0,m}$, $z_2^{0,n}$ and $z_2^{0,m}$. Applying the Euler formula, we see that  		u_{nm}\left(z_1^0+\frac{z_1}{\sqrt{\lambda}},z_2^0+\frac{z_2}{\sqrt{\lambda}}\right)\in \mathcal{A}_T=\left\{\sum_{j=1}^T\alpha_je^{\theta_j\cdot(z_1,z_2)}:\ \alpha_j\in\mathbb{C}, \theta_j\in\mathbb{R}^2,|\theta_j|=1\right\}, 	 for $T\in\mathbb{N}$ with $T\geq 8$.	 	 	On the other hand, for the case of $\mathcal{P}=\mathcal{T}_{\mathrm{equi}}$ we recall a similar result in \cite[Theorem 1.5]{RudWig2} 	 		There exists $\Sigma_0^{\mathcal{T}_{\mathrm{equi}}}>0$ so that for all $0<\Sigma<\Sigma_0^{\mathcal{T}_{\mathrm{equi}}}$ there are no spectral multiplicities other than systematic doubling, i.e., other than having symmetric $T_s^{mn}$ and antisymmetric $T_a^{mn}$  eigenfunctions. 	 	This result together with the study done in Section \ref{equi} about eigenfunctions for the Robin problem allow us, in an analogous way, to know that for any eigenvalue $\lambda_{mn}^\Sigma$, all the eigenfunctions are of the form 	 		 			u_{mn}(z_1,z_2)=c_sT_s^{mn}(z_1,z_2)+c_aT_a^{mn}(z_1,z_2), 		 	where $c_s$ and $c_a$ are real constants and $T_s^{mn}$ and $T_a^{mn}$ are trigonometric functions of the form: 	 	 			T_s^{mn}(z_1,z_2)=\left[ 				& \cos \left(\frac{2\sqrt{3}\pi \zeta}{3}z_2-\delta_1\right) \cos \left(\frac{2\pi(\mu-\nu)}{3}z_1\right) \\ 				& +\cos \left(\frac{2\pi\sqrt{3} \mu}{3 }z_2-\delta_2\right) \cos \left(\frac{2\pi(\nu-\zeta)}{3}z_1\right) \\ 				& +\cos \left(\frac{2\pi\sqrt{3} \nu}{3}z_2-\delta_3\right) \cos \left(\frac{2\pi(\zeta-\mu)}{3}z_1\right) 			\right],and 		T_a^{mn}(z_1,z_2)=\left[ 				& \cos \left(\frac{2\sqrt{3}\pi \zeta}{3}z_2-\delta_1\right)  \sin \left(\frac{2\pi(\mu-\nu)}{3}z_1\right) \\ 				& +\cos \left(\frac{2\pi\sqrt{3} \mu}{3 }z_2-\delta_2\right) \sin \left(\frac{2\pi(\nu-\zeta)}{3}z_1\right) \\ 				& +\cos \left(\frac{2\pi\sqrt{3} \nu}{3}z_2-\delta_3\right) \sin \left(\frac{2\pi(\zeta-\mu)}{3}z_1\right) 			\right], 	where $\zeta,\mu,\nu,\delta_1,\delta_2$ and $\delta_3$ depend on $m$ and $n$ (see Section \ref{equi}). 	For any $z^0\in\mathcal{T}_{\mathrm{equi}}$, localized eigenfunctions can, again by Euler formula, be seen as elements of $\mathcal{A}_T$,  	 		u_{mn}\left(z_1^0+\frac{z_1}{\sqrt{\lambda}},z_2^0+\frac{z_2}{\sqrt{\lambda}}\right)\in	\mathcal{A}_T=\left\{\sum_{j=1}^{T}\alpha_je^{\theta_j\cdot(z_1,z_2)}:\ \alpha_j\in\mathbb{C}, \theta_j\in\mathbb{R}^2,|\theta_j|=1\right\}, 	with now $T\geq 24$. 	 	 	To finish the proof for both cases, we notice that the set $\mathcal{A}_T|_B$ is a linear subspace of real dimension $3T$ of the space $L^2(B)$, and that $\MW^s|_B\subset L^2(B)$ is an infinite dimensional linear space. Notice also that, for any $\varphi\in\MW^s$,  and for $\mathcal{P}\in\left\{\mathcal{Q}_1,\mathcal{T}_\mathrm{equi}\right\}$,  	 		\inf_{z^0\in\mathcal{P}}\inf_{\lambda\in\Lambda_{\mathcal{P}}^{\mathrm{R}_\Sigma}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{P},\mathrm{R}_\Sigma}^\lambda}\left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0\left(B\right)}\geq C_B\dist_{L^2(B)}\left(\varphi,\mathcal{A}_T\right), 	     for some constant $C_B$  that only depends on $B$. Therefore, (\MW^s\backslash\mathcal{N}_{\mathcal{P},\mathrm{R}_\Sigma})|_B\subset\mathcal{A}_T|_B for $\mathcal{P}\in\left\{\mathcal{Q}_1,\mathcal{T}_\mathrm{equi}\right\}$ and $\Sigma$ small enough.  Consequently, being $\mathcal A_T$ finite dimensional,  $\mathcal{N}_{\mathcal{P},\mathrm{R}_\Sigma}$ is dense in $\MW^s$. To conclude, we see that $\mathcal{N}_{\mathcal{P},\mathrm{R}_\Sigma}$ is open. 	 	To do that, we just consider a $\varphi\in\mathcal{N}_{\mathcal{P},\mathrm{R}_\Sigma}$. This means that there exists $\delta>0$ such that 		\inf_{z^0\in\mathcal{P}}\inf_{\lambda\in\Lambda_{\mathcal{P}}^{\mathrm{R}_\Sigma}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{P},\mathrm{R}_\Sigma}^\lambda}\left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0\left(B\right)}>\delta>0.If we consider those $\psi\in\MW^s$ such that $\left\|\varphi-\psi\right\|<\delta/2$, we can easily check that it is true the following 	 		\left\|\varphi-\psi\right\|\geq \left\|\varphi-\psi\right\|	_{C^0\left(B\right)}, 	and so 	&	\inf_{z^0\in\mathcal{P}}\inf_{\lambda\in\Lambda_{\mathcal{P}}^{\mathrm{R}_\Sigma}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{P},\mathrm{R}_\Sigma}^\lambda}\left\|\psi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0\left(B\right)}\geq\\&\inf_{z^0\in\mathcal{P}}\inf_{\lambda\in\Lambda_{\mathcal{P}}^{\mathrm{R}_\Sigma}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{P},\mathrm{R}_\Sigma}^\lambda}\left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0\left(B\right)}-\delta/2>\delta/2.Therefore, $B_{\left\|\cdot\right\|}\left(\varphi,\delta/2\right)\subset\mathcal{N}_{\mathcal{P},\mathrm{R}_\Sigma}$, proving that it is open thus finishing the proof.",2502.01291
proof,"%The first remark is to notice that, for any $\varphi\in \MW^s$, thanks to \eqref{torus}, \inf_{\lambda\in\Lambda_{\mathcal{Q}_l}^{\mathrm{D}}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{Q}_l,\mathrm{D}}^\lambda}\left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0(B)}\leq \inf_{\lambda\in\Lambda_{\mathcal{Q}_l}^{\mathrm{P}}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{Q}_l,\mathrm{P}}^\lambda}\left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0(B)},and also\inf_{\lambda\in\Lambda_{\mathcal{Q}_l}^{\mathrm{N}}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{Q}_l,\mathrm{N}}^\lambda}\left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0(B)}\leq \inf_{\lambda\in\Lambda_{\mathcal{Q}_l}^{\mathrm{P}}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{Q}_l,\mathrm{P}}^\lambda}\left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0(B)},so it is enough to prove the result for periodic boundary conditions.  	 	We start by considering the jet space of order $3$ at the point $0$ of solutions to the Helmholtz equation  		\widetilde{\mathcal{H}}:=\left\{\left(\varphi(0), \left(\partial_i\varphi(0)\right)_{1\leq i\leq d},\left(\partial_{i}\partial_{j}\varphi(0)\right)_{1\leq i,j\leq d},\left(\partial_{i}\partial_{j}\partial_{l}\varphi(0)\right)_{1\leq i, j, l\leq d}\right): \varphi\in \MW^s\right\}. 	This set is well defined since $\MW^s\subset C^\infty\left(\mathbb{R}^d\right)$. It is easy to check that $\widetilde{\mathcal{H}}\subset\mathbb{R}^{1+d+d^2+d^3}$ is a linear space and its dimension satisfies that $\dim\left(\widetilde{\mathcal{H}}\right)\leq d_H:=\binom{d+2}{3} +\binom{d+1}{2}$. This can be seen by the fact that, thanks to the equation, we have  		\varphi(0)=\sum_{j=1}^d\partial_{j}^2\varphi(0), 	 and also, for any $1\leq i\leq d$, 		\partial_{i}\varphi(0)=\sum_{j=1}^d\partial_{j}^2\partial_{i}\varphi(0). 	Therefore, the four first entries of each vector are determined by the others. Moreover, since $\varphi$ is smooth, crossed derivatives are symmetric, and so many other entries are already determined. Consequently, we can find an isomorphism between $\widetilde{\mathcal{H}}$ and a new space $\mathcal{H}$ given by 		\mathcal{H}:=\left\{\left(\left(\partial_{i}\partial_{j}\varphi(0)\right)_{1\leq i\leq j\leq d},\left(\partial_{i}\partial_{j}\partial_{l}\varphi(0)\right)_{1\leq i\leq j\leq l\leq d}\right): \varphi\in \MW^s\right\}\subset\mathbb{R}^{d_H}. 	 	 	Therefore, if we define the function  		 			\mathcal{J}:&\MW^s\longrightarrow \mathbb{R}^{d_H}\\&\varphi\mapsto\left(\left(\partial_{z_i}\partial_{z_j}\varphi(0)\right)_{1\leq i\leq j\leq d},\left(\partial_{z_i}\partial_{z_j}\partial_{z_l}\varphi(0)\right)_{1\leq i\leq j\leq l\leq d}\right), 		 	then $\mathcal{H}=\mathcal{J}\left(\MW^s\right)$. Notice that this is a map  that is continuous and linear.  	 	To continue with the proof, we recall the next lemma that follows from \cite[Theorem 3.2]{Damon}: 		For any $p\in \mathbb{R}^{d_H}$, there exist $\delta_p>0$, a ball $B_{\delta_p}\subset\mathbb{R}^d$ and a function $\phi\in C^\infty\left(B_{\delta_p}\right)$ such that $\Delta \phi+\phi=0$ in $B_{\delta_p}$ and  			p=\left(\left(\partial_{z_i}\partial_{z_j}\phi(0)\right)_{1\leq i\leq j\leq d},\left(\partial_{z_i}\partial_{z_j}\partial_{z_l}\phi(0)\right)_{1\leq i\leq j\leq l\leq d}\right). 		 	In other words, for any $p\in\RR^{d_H}$, there exists a locally defined monochromatic wave $\phi$ such that $\mathcal{J}(\phi)=p$. Moreover, the global approximation theory with decay for solutions to Helmholtz equation (see \cite[Chapter 1]{Mangeles}) allows us to find another monochromatic wave $\varphi\in\MW^s$, globally defined, as close as we want in norm $\left\|\cdot\right\|_{C^3\left(B\right)}$ to $\phi$. Therefore, since by classical elliptic regularity bound, the norms $\left\|\cdot\right\|_{C^3\left(B\right)}$ and $\left\|\cdot\right\|$ as defined in \eqref{norm} are equivalent, we have $\overline{\mathcal{H}}=\mathbb{R}^{d_H}$. 	 	 However, since $\mathcal{H}=\mathcal{J}\left(\MW^s\right)$ is a linear subspace of a finite dimensional linear space, it is closed and we infer that $\mathcal{J}$ is surjective, i.e., $\mathcal H=\mathbb R^{d_H}$. 	 	Now we are ready to show that $\mathcal{N}_{\mathcal{Q}_l,\mathrm{BC}}$, for $\mathrm{BC}=\mathrm{D}$ or $\mathrm{BC}=\mathrm{N}$, is open. To do that, we just consider $\varphi\in\mathcal{N}_{\mathcal{Q}_l,\mathrm{BC}}$. This means that there exists $\delta>0$ such that 	\inf_{z^0\in\mathcal{Q}_l}\inf_{\lambda\in\Lambda_{\mathcal{Q}_l}^{\mathrm{BC}}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{Q}_l,\mathrm{BC}}^\lambda}\left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0\left(B\right)}>\delta>0.If we consider those $\psi\in\MW^s$ such that $\left\|\varphi-\psi\right\|<\delta/2$, we can easily check that it is true the following 	 		\left\|\varphi-\psi\right\|\geq \left\|\varphi-\psi\right\|	_{C^0\left(B\right)}, 	and so 	&\inf_{z^0\in\mathcal{Q}_l}\inf_{\lambda\in\Lambda_{\mathcal{Q}_l}^{\mathrm{BC}}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{Q}_l,\mathrm{BC}}^\lambda}\left\|\psi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0\left(B\right)}\geq\\&	\inf_{z^0\in\mathcal{Q}_l}\inf_{\lambda\in\Lambda_{\mathcal{Q}_l}^{\mathrm{BC}}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{Q}_l,\mathrm{BC}}^\lambda}\left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0\left(B\right)}-\delta/2>\delta/2.Therefore, $B_{\left\|\cdot\right\|}\left(\varphi,\delta/2\right)\subset\mathcal{N}_{\mathcal{Q}_l,\mathrm{BC}}$, and we conclude that it is open. 	 	To see the density of $\mathcal{N}_{\mathcal{Q}_l,\mathrm{BC}}$, we first prove the following lemma: 		The set 			\mathcal{V}:=\left\{&\left(\left(\partial_{i}\partial_{j}f(0)\right)_{1\leq i\leq j\leq d},\left(\partial_{i}\partial_{j}\partial_{l}f(0)\right)_{1\leq i\leq j\leq l\leq d}\right), 				\\& f=u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right),\ z^0\in\mathcal{Q}_l,\ \lambda \in \Lambda_{\mathcal{Q}_l}^{\mathrm{BC}},\ u_\lambda\in\mathcal{V}_{\mathcal{Q}_l,\mathrm{BC}}^\lambda 			\right\}\subset\mathbb{R}^{d_H} 		 satisfies that its closure has empty interior.  	 	 		Let us start by fixing an eigenvalue $\lambda>0$. For now, we will assume that $\lambda=\sum_{r=1}^m\beta_r\lambda_r$ with $\lambda_1\neq 0$. We have already seen in Section \ref{rect} that any eigenfunction associated to $\lambda$ with Dirichlet, Neumann or periodic boundary condition has the form  		 			u_\lambda(z)=\sum_{\substack{N\in\mathbb{Z}^d\\ \mathcal{Q}_l(N)=\lambda}}c_N\exp\left(i\pi\sum_{j=1}^d\frac{N_jz_j}{l_j}\right), \ c_N\in\mathbb{C},\text{ with } \overline{c_N}=c_N. 		For Dirichlet or Neumann conditions we have some extra hypothesis on $c_N$.                   We define the set  			\mathcal{V}_\lambda:=\left\{\left(\left(\partial_{i}\partial_{j}f(0)\right)_{1\leq i\leq j\leq d},\left(\partial_{i}\partial_{j}\partial_{l}f(0)\right)_{1\leq i\leq j\leq l\leq d}\right), 				& f=u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\\& u_\lambda\in\mathcal{V}_{\mathcal{Q}_l,\mathrm{BC}}^\lambda,\ z^0\in\mathcal{Q}_l 			\right\}. 		Since we saw thanks to Lemma \ref{Damon} that $\mathcal{H}=\mathbb{R}^{d_H}$, we immediately have that   $\mathcal{V}_\lambda\subset\mathcal{H}$. By Lemma \ref{independence}, we also have that for any $u_\lambda\in\mathcal{V}_{\mathcal{Q}_l,\mathrm{BC}}^\lambda$,  			\sum_{i\in I_1}\partial_{i}^2u_\lambda(z)+\lambda_1u_\lambda(z)=0. 		  		Together with the Helmholtz equation and the hypothesis of $\lambda_1\neq 0$, we get  			\left(1-\frac{\lambda}{\lambda_1}\right)\sum_{i\in I_1}\partial_{i}^2u_\lambda\left(z^0+\frac{z}{\sqrt{\lambda}}\right)+\sum_{i\notin I_1}\partial_{i}^2u_\lambda\left(z^0+\frac{z}{\sqrt{\lambda}}\right)=0; 		and, taking derivatives, for any $1\leq j\leq d$,  			\left(1-\frac{\lambda}{\lambda_1}\right)\sum_{i\in I_1}\partial_{i}^2\partial_{j}u_\lambda\left(z^0+\frac{z}{\sqrt{\lambda}}\right)+\sum_{i\notin I_1}\partial_{i}^2\partial_{j}u_\lambda\left(z^0+\frac{z}{\sqrt{\lambda}}\right)=0. 		So, the set $\mathcal{V}_\lambda$ satisfies  			\mathcal{V}_\lambda=\left\{&\left(\left(\partial_{i}\partial_{j}f(0)\right)_{1\leq i\leq j\leq d},\left(\partial_{i}\partial_{j}\partial_{l}f(0)\right)_{1\leq i\leq j\leq l\leq d}\right), 					& f=u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\\& u_\lambda\in \mathcal{V}_{\mathcal{Q}_l,\mathrm{BC}}^\lambda,\ z^0\in\mathcal{Q}_l 				,\\& 				\left(1-\frac{\lambda}{\lambda_1}\right)\sum_{i\in I_1}\partial_{i}^2f(0)+\sum_{i\notin I_1}\partial_{i}^2f(0)=0,\\& 				\left(1-\frac{\lambda}{\lambda_1}\right)\sum_{i\in I_1}\partial_{i}^2\partial_{j}f(0)+\sum_{i\notin I_1}\partial_{i}^2\partial_{j}f(0)=0,\text{ for any $1\leq j\leq d$.} 			\right\}. 		 		Doing some computations in the equations that define $\mathcal{V}_\lambda$, we can define a new set  			\mathcal{A}_1=\left\{&\left(\left(\partial_{i}\partial_{j}f(0)\right)_{1\leq i\leq j\leq d},\left(\partial_{i}\partial_{j}\partial_{k}f(0)\right)_{1\leq i\leq j\leq k\leq d}\right),\text{ such that $\forall\ 1\leq j\leq d$}\\& \left(\sum_{i\in I_1}\partial_{i}^2\partial_{j}f(0)\right)\left(\sum_{i\notin I_1}\partial_{i}^2f(0)\right)=\left(\sum_{i\notin I_1}\partial_{i}^2\partial_{j}f(0)\right)\left(\sum_{i\in I_1}\partial_{i}^2f(0)\right) 			\right\}. 		 		Since $\mathcal{A}_1$ does not depend on $\lambda$, we have the following inclusion.  		 			\bigcup_{\lambda>0, \lambda_1\neq 0}\mathcal{V}_\lambda\subset\mathcal{A}_1. 		 		Since any $\lambda>0$ needs to have some $\lambda_r\neq 0$ and we can do the same reasoning for that one, we have 			\mathcal{V}=	\bigcup_{\lambda>0}\mathcal{V}_\lambda=\bigcup_{r=1}^m	\bigcup_{\lambda>0,\lambda_r\neq 0}\mathcal{V}_\lambda\subset\bigcup_{r=1}^m\mathcal{A}_r. 		It is immediate to prove that $\bigcup_{r=1}^m\mathcal{A}_r$ is a subset of a closed submanifold $\mathcal{A}\subset\mathbb{R}^{d_H}$ of codimension bigger or equal than one, and consequently, it is closed and has empty interior. One can now just notice that  $\overline{\mathcal{V}}$ is a subset of $\mathcal{A}$ and, consequently, it also has empty interior in $\mathbb R^{d_H}$, as we wanted to see.",2502.01291
proof,"To begin, we recall the definition of the set  		\mathcal{N}_{\mathcal B,\mathrm{BC}}=\left\{\varphi\in \MW^s,\ \inf_{ z^0\in\mathcal B}\inf_{\lambda\in \Lambda_\mathcal{B}^{\mathrm{BC}}}\inf_{u_\lambda\in\mathcal{V}_{\mathcal{B},\mathrm{BC}}^\lambda}        \left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0\left(B\right)}>0\right\}, 	     We also recall from Section 2 that eigenfunctions for the Dirichlet and Neumann problem have the same formal expression and they differ only in the eigenvalues, therefore as far as we consider eigenvalues $\lambda_{ln}$ and we do not use particular properties of them, we can again address both problems simultaneously.     %and we introduce the new sets: 	%\mathcal{N}_{\mathcal B,\mathrm{BC}}^{z^0}=\left\{\varphi\in \MW^s,\ \inf_{\lambda\in \Lambda_\mathcal {B}^{\mathrm{BC}}}\inf_{u_\lambda\in\mathcal{V}_{\mathcal{B},\mathrm{BC}}^\lambda}\left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0\left(B\right)}>0\right\}.       %Notice that   \mathcal{N}_{\mathcal B,\mathrm{BC}}=\bigcup_{z^0\in\mathcal{B}}\mathcal{N}_{\mathcal B,\mathrm{BC}}^{z^0}.           We now split the proof in four steps:        	\textbf{	\underline{Step I:}} In this first step, we will see that $\mathcal{N}_{\mathcal{B},\mathrm{BC}}$ is open. To do that, we do just like in the previous section and consider a $\varphi\in\mathcal{N}_{\mathcal{B},\mathrm{BC}}$. This means that there exists $\delta>0$ such that 	\inf_{ z^0\in\mathcal B}\inf_{\lambda\in\Lambda_{\mathcal{B}}^{\mathrm{BC}}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{B},\mathrm{BC}}^\lambda}\left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0\left(B\right)}>\delta>0.If we consider those $\psi\in\MW^s$ such that $\left\|\varphi-\psi\right\|_{C^0\left(B\right)}<\delta/2$, we can easily check that it is true the following 	&\inf_{ z^0\in\mathcal B}\inf_{\lambda\in\Lambda_{\mathcal{B}}^{\mathrm{BC}}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{B},\mathrm{BC}}^\lambda}\left\|\psi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0\left(B\right)}\geq\\&	\inf_{ z^0\in\mathcal B}\inf_{\lambda\in\Lambda_{\mathcal{B}}^{\mathrm{BC}}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{B},\mathrm{BC}}^\lambda}\left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0\left(B\right)}-\delta/2>\delta/2.So, $B_{C^0\left(B\right)}\left(\varphi,\delta/2\right)\subset\mathcal{N}_{\mathcal{B},\mathrm{BC}}$, and we conclude that it is open. In the rest of the proof, we will see that this set is dense in $\MW^s$.           %To do that, we will instead consider\mathcal{N}_{\mathcal B,\mathrm{BC}}^c=\left\{\varphi\in \MW^s,\ \inf_{ z^0\in\mathcal B}\inf_{\lambda\in \Lambda_\mathcal{B}^{\mathrm{BC}}}\inf_{u_\lambda\in\mathcal{V}_{\mathcal{B},\mathrm{BC}}^\lambda}\left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0\left(B\right)}=0\right\}, and see that it has empty interior.          \textbf{	\underline{Step II:}} In this step, we will introduce some notations and maps that we will need in the rest of the proof, and we will comment some of their properties.  We start by  considering a point $z^0=\left(r_0,\theta_0\right)\in[0,1]\times\mathbb{S}^{d-1}$. For any $0<R<1$ that we will fix later, we associate to any $r_0\in[0,1]$ a smooth map as follows                   I: &[0,1]\rightarrow C^\infty\left([0,R],\mathbb{R}\right)\\            &r_0\mapsto                I_{r_0}: [0,R]&\rightarrow\mathbb{R}\\               r&\mapsto r_0\left(1-R\right)+r.                        Notice that $I_{r_0}\left([0,R]\right)=\left[r_0\left(1-R\right),r_0\left(1-R\right)+R\right]\subset [0,1]$ is always an interval of length $R$ and notice that $I$ and $I_{r_0}$ are continuous maps.      We can then define, for any pair $\left(r_0,\theta_0\right)\in[0,1]\times\mathbb{S}^{d-1}$, the following  map:                     R_{\theta_0}^{r_0}:&\MW^s\rightarrow C^2\left([0,R]\right)\\&\varphi\mapsto\varphi\left(I_{r_0}\left(\cdot\right),\theta_0\right).            This map is the restriction (of a monochromatic wave) to a segment of length $R$ around $\left(r_0,\theta_0\right)$ in the direction of $\theta_0$. It is easy to notice that any $  R_{\theta_0}^{r_0}$ is continuous and so it is the map                     R:&[0,1]\times\mathbb{S}^{d-1}\rightarrow C\left(\MW^s,C^2\left([0,R]\right)\right)\\&\left(r_0,\theta_0\right)\mapsto R_{\theta_0}^{r_0}:=R(r_0,\theta_0).             We also define the map  $\tilde{R}_{\theta_0}^{r_0}$ as the extension of $R_{\theta_0}^{r_0}$ to the set of two times differentiable functions in a neighborhood of the segment L_{\theta_0}^{r_0}:=\left\{(r,\theta_0)\in\mathcal{B},\ r\in I_{r_0}([0,R])\right\}. We then use the explicit expression of the eigenfunctions to notice that any localized eigenfunction associated to an eigenvalue $\lambda_{ln}$, defined as $\tilde{u}_{ln}^{z^0}:=u_{ln}\left(z^0+\frac{\cdot}{\sqrt{\lambda_{ln}}}\right)$ when $z^0=\left(r_0,\theta_0\right)$, has the following form:  		 			& \tilde{R}_{\theta_0}^{r_0}\left(\tilde{u}_{ln}^{z^0}\right)(r)=u_{ln}\left(r_0+\frac{I_{r_0}(r) }{\sqrt{\lambda_{ln}}},\theta_0\right)=\\&\sum_{m=1}^{M(d,l)}c_m\left(r_0+\frac{r_0\left(1-R\right)+r}{\sqrt{\lambda_{ln}}}\right)^{1-d/2}J_{\frac{d}{2}+l-1}\left(\sqrt{\lambda_{ln}}r_0+r_0\left(1-R\right)+r\right)Y_{lm}\left(\theta_0\right)=\\&c_{l,n,z^0}\left(\sqrt{\lambda_{ln}}r_0+r_0\left(1-R\right)+r\right)^{1-d/2}J_{d/2+l-1}\left(\sqrt{\lambda_{ln}}r_0+r_0\left(1-R\right)+r\right)=\\&c_{l,n,z^0}f_{\sqrt{\lambda_{ln}}r_0+r_0\left(1-R\right),l}(r)             \,, 		 	 	with $r\in [0,R]$ and $f_{t,l}(r):=\left(t+r\right)^{1-d/2}J_{d/2+l-1}\left(t+r\right)$. A straightforward computation allows us to check that, for any $t\in\mathbb{R}^+_0$ and for any $l\in\mathbb{N}\cup\left\{0\right\}$, the function $f_{t,l}$ satisfies the following Bessel type differential equation on the whole $\mathbb{R}$: 	 		\left(t+r\right)^2 f_{t,l}''(r)+(d-1)(t+r)f_{t,l}'(r)+\left(\left(t+r\right)^2-l(l+d-2)\right)f_{t,l}(r)=0. 	 	We define now the evaluation map as follows: 	 		 			& \mathcal{EM}^M: C^2\left(\left[0,R\right]\right)\rightarrow\mathbb{R}^{12M}\\&f\mapsto [\mathcal{EM}^M(f)]_i=\left({c c c} 				f\left(0+\frac{iR}{M}\right) & f'\left(0+\frac{iR}{M}\right) & f''\left(0+\frac{iR}{M}\right) \\ f\left(\frac{R}{4M}+\frac{iR}{M}\right) & 				f'\left(\frac{R}{4M}+\frac{iR}{M}\right) & f''\left(\frac{R}{4M}+\frac{iR}{M}\right) \\ f\left(\frac{R}{2M}+\frac{iR}{M}\right) & f'\left(\frac{R}{2M}+\frac{iR}{M}\right) & 				f''\left(\frac{R}{2M}+\frac{iR}{M}\right)	\\ f\left(\frac{3R}{4M}+\frac{iR}{M}\right) & f'\left(\frac{3R}{4M}+\frac{iR}{M}\right) & f''\left(\frac{3R}{4M}+\frac{iR}{M}\right) \\ 			\right) 		 	     for $i=0,1,\cdots, M-1$. 	Here $M$ is an integer that will be fixed later. This map is easily checked to be continuous and linear.	On the other hand, by interpolation, we know that for any $P\in \mathbb{R}^{12M}$ there exists a polynomial $\mathbb{P}(P)\in C^2\left([0,R]\right) $ such that $\mathcal{EM}^M\left(\mathbb{P}(P)\right)=P$. Therefore, $\mathcal{EM}^M$ is also surjective and open. For a point $P=\left(P_1,\ldots,P_{12M}\right)$ let us denote the coordinates as:  	     	        &P_{j}=:P^0_j,\text{ whenever }1\leq j\leq 12,\\             &P_{j}=:P^1_{j-12},\text{ whenever }13\leq j\leq 24=12\cdot 2,\\             &\ldots\\             &P_{j}=:P^{M-1}_{j-12(M-1)},\text{ whenever }12(M-1)+1\leq j\leq 12M.\\               	For any $0\leq i\leq M-1$, we denote $P^i:=\left(P^i_1,\ldots,P^i_{12}\right)\in\mathbb{R}^{12}.$ We also define the following six functions from $\mathbb{R}^{12}$ (let us say $P\in\mathbb{R}^{12}$) to $\mathbb{R}$. Notice that some of them depend on $M$ and $0\leq j\leq M-1$ through the parameter $\al_j^M:=\frac{jR}{M}$.      	              &a(P)=P_{3}P_{4}-P_{6}P_{1},\ d(P)=P_{9}P_{10}-P_{12}P_{7},\\          &b^M_j(P)=2\al_j^M(P_{3}P_{4}+P_{1}P_{4})+(d-1)(P_{2}P_{4}-P_{5}P_{1})\\&-\left(2\al_j^M+\frac{R}{2}\right)(P_{6}P_{1}+P_{4}P_{1}),\\         &c^M_j(P)=(\al_j^M)^2(P_{3}P_{4}+P_{1}P_{4})+\al_j^M(d-1)P_{2}P_{4}\\         &-\left(\al_j^M+\frac{R}{2}\right)(d-1)P_{5}P_{1}-\left(\al_j^M+\frac{R}{4}\right)^2(P_{6}P_{1}+P_{4}P_{1}),\\         &e^M_j(P)=\left(2\al_j^M+R\right)(P_{9}P_{10}+P_{7}P_{10})+(d-1)(P_{8}P_{10}-P_{11}P_{7})\\         &-\left(2\al_j^M+\frac{3R}{2}\right)(P_{12}P_{7}+P_{10}P_{7}),\\         &f^M_j(P)=\left(\al_j^M+\frac{R}{2}\right)^2(P_{9}P_{10}+P_{7}P_{10})+\left(\al_j^M+\frac{R}{2}\right)(d-1)P_{8}P_{10}\\         &-\left(\al_j^M+\frac{3R}{4}\right)(d-1)P_{11}P_{7}-\left(\al_j^M+\frac{3R}{4}\right)^2(P_{12}P_{7}+P_{10}P_{7}).      All of them are homogeneous polynomials of degree two. 	We define now the polynomials:              &\tilde{Q}^M_j(P):=\left(b^M_j(P)^2d(P)-2a(P)c^M_j(P)d(P)-a(P)b^M_j(P)e(P)+2a(P)^2f^M_j(P)\right)^2\\         &-\left(a(P)e^M_j(P)-b^M_j(P)d(P)\right)^2\left(b^M_j(P)^2-4a(P)c^M_j(P)\right).           With all this, we can finally define the function                      &Q_M:\mathbb{R}^{12M}\rightarrow\mathbb{R}^{M}\\             &P=(P^0,P^1,\ldots,P^{M-1})\mapsto Q_M(P)=\left(\tilde{Q}^M_0\left(P^0\right), \tilde{Q}^M_1\left(P^1\right),\ldots,\tilde{Q}^M_{M-1}\left(P^{M-1}\right)\right).               	        Notice that $Q_M^{-1}\left(\left\{0\right\}\right)$ is an (affine) algebraic variety (in particular, a closed set with empty interior because $Q_M$ is surjective) and, consequently, $\mathbb{R}^{12M}\backslash Q_M^{-1}\left(\left\{0\right\}\right)$ is open and dense.  Moreover, since any entry of $Q_M$ is evaluated in different coordinates, we notice that all of them are independent and so $Q_M^{-1}\left(\left\{0\right\}\right)$ is of codimension at least $M$ on $\mathbb{R}^{12M}$.          On the other hand, it is straightforward to check that, for any $t\in\mathbb{R}^+$ and for any $l\in\mathbb{N}\cup\left\{0\right\}$, $Q_M\left(\mathcal{EM}^M\left(f_{t,l}\right)\right)=0$ and, consequently, for any eigenfunction $u_{ln}$ and any $z^0\in\mathcal{B}$, 	 		\mathcal{EM}^M\left(\tilde{R}_{\theta_0}^{r_0}\left(\tilde{u}_{ln}^{z^0}\right)\right)\in Q_M^{-1}\left(\left\{0\right\}\right). 	     %By introducing a change of coordinates in $\mathbb{R}^{12(d+1)}$ if necessary we can see $Q^{-1}\left(\left\{0\right\}\right)$  as $\bigcap_{0\leq j\leq d}Q_j^{-1}\left(\left\{0\right\}\right)$ where each $Q_j$ is defined as a function $Q_j:\mathbb{R}^{12(d+1)}\rightarrow\mathbb{R}$. 	   \textbf{	\underline{Step III:}} To continue the proof, we will see that, for any pair $\left(r_0,\theta_0\right)\in[0,1]\times\mathbb{S}^{d-1}$, the set $\left(\mathcal{EM}^M\circ	R_{\theta_0}^{r_0}\right)^{-1}\left( Q_M^{-1}\left(\left\{0\right\}\right)\right)$ has at least codimension $M$ in $\MW^s$, and in particular it has empty interior and it is closed.      For any $P\in \RR^{12M}$, we consider the polynomial $\mathbb{P}(P)$ introduced before. An easy application of the CauchyKovalevskaya theorem ensures the existence of a neighborhood $N_P$ of $L_{\theta_0}^{r_0}$ in $\mathbb{R}^{d}$ and a function $H_P:N_P\rightarrow\mathbb{R}$ satisfying the Helmholtz equation $\Delta H_P+H_P=0$ in $N_P$ such that $ \tilde{R}_{\theta_0}^{r_0}\left(H_P\right)=\mathbb{P}(P)$. Moreover, thanks to the global approximation theory with decay \cite{APDE}, for any $\ep>0$ there exists another function $\varphi_P\in\MW^s$ such that  		\left\|\varphi_P-H_P\right\|_{C^2\left(N_P\right)}<\ep. 	If we notice that 	 		\left\|\varphi_P-H_P\right\|_{C^2\left(N_P\right)}\geq\frac{1}{4M} \left|\mathcal{EM}^M\left( R_{\theta_0}^{r_0}\left(\varphi_P\right)\right)-\mathcal{EM}^M\left(\tilde{ R}_{\theta_0}^{r_0}\left(H_P\right)\right)\right|, 	it follows that for any $P\in\RR^{12M}$ and any $\de>0$ there exists $\varphi_P\in \MW^s$ such that $\left|\mathcal{EM}^M\left( R_{\theta_0}^{r_0}\left(\varphi_P\right)\right)-P\right|<\de.$ Equivalently, $\left(\mathcal{EM}^M\circ R_{\theta_0}^{r_0}\right)\left(\MW^s\right)$ is dense in $\RR^{12M}$.  Notice that the map $\mathcal{EM}^M\circ R_{\theta_0}^{r_0}$ is linear and continuous (between two Banach spaces).           Therefore, we just proved that the map $\mathcal{EM}^M\circ R_{\theta_0}^{r_0}:\MW^s\rightarrow\mathbb{R}^{12M}$ is a linear and continuous map between two Banach spaces with image dense in $\mathbb{R}^{12M}$ and, therefore, surjective (because all linear subspace of a finite dimensional linear space are closed).  By the open mapping theorem, we can conclude that it is also open and so $\left(\mathcal{EM}^M\circ R_{\theta_0}^{r_0}\right)^{-1}\left(\mathbb{R}^{12M}\backslash Q_M^{-1}\left(\left\{0\right\}\right)\right)=\MW^s\backslash\left(\mathcal{EM}^M\circ R_{\theta_0}^{r_0}\right)^{-1}\left( Q_M^{-1}\left(\left\{0\right\}\right)\right)$ is open and dense in $\MW^s$.           Taking into account the codimension of $Q_M^{-1}\left(\{0\}\right)$, we can also infer that the set $\left(Q_M\circ\mathcal{EM}^M\circ R_{\theta_0}^{r_0}\right)^{-1}\left(\{0\}\right)$ has codimension at least $M$ in $\MW^s$. Indeed, since the codimension of $Q_M^{-1}\left(\{0\}\right)$ in $\mathbb{R}^{12M}$ is at least $M$ and $\mathcal{EM}^M\circ R^{r_0}_{\theta_0}$ is surjective, we easily conclude that a generic $(M-1)$-parameter family of functions in $\MW^s$ does not intersect $\left(Q_M\circ\mathcal{EM}^M\circ R^{r_0}_{\theta_0}\right)^{-1}\left(\{0\}\right)$, and hence its codimension is at least $M$. Here, generic family means belonging to an open and dense subset of the set of families determined by at most $M-1$ parameters. 	 	 \textbf{	\underline{Step IV:}} The last step in the proof is to consider what happens whenever we change the point $(r_0,\theta_0)\in\mathcal{B}$ around which we are doing the localization.  We first notice that, for any $\varphi\in \MW^s$, and whenever the previously introduced $R>0$ is small enough, it is true that	 		 			&\inf_{z^0\in\mathcal{B}}\inf_{\lambda\in\Lambda_{\mathcal{B}}^{\mathrm{BC}}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{B},\mathrm{BC}}^\lambda}\left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0\left(B\right)}\geq\\&C\inf_{z^0\in\mathcal{B}}\inf_{\lambda\in\Lambda_{\mathcal{B}}^{\mathrm{BC}}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{B},\mathrm{BC}}^\lambda}\left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^2\left(B_R\right)}\geq\\&\frac{C}{4M}\inf_{z^0\in\mathcal{B}}\inf_{\lambda\in\Lambda_{\mathcal{B}}^{\mathrm{BC}}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{B},\mathrm{BC}}^\lambda}\left|\mathcal{EM}^M\circ R_{\theta_0}^{r_0}\left(\varphi\right)-\mathcal{EM}^M\circ\tilde{R}_{\theta_0}^{r_0}\left(\tilde{u}_\lambda^{z^0}\right)\right|\geq\\ &\frac{C}{4M}\inf_{z^0\in\mathcal{B}} \dist\left(\mathcal{EM}^M\circ R_{\theta_0}^{r_0}(\varphi),Q_M^{-1}\left(\{0\}\right)\right). 		 	   Therefore, the set        \mathcal{N}_{\mathcal B,\mathrm{BC}}^c:=\left\{\varphi\in \MW^s,\ 0=\inf_{z^0\in\mathcal{B}}\inf_{\lambda\in\Lambda_{\mathcal{B}}^{\mathrm{BC}}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{B},\mathrm{BC}}^\lambda}\left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0\left(B\right)}\right\},   is contained in the set \mathcal{A}:=\bigcup_{\substack{r_0\in[0,1]\\\theta_0\in\mathbb{S}^{d-1}}}\left(Q_M\circ\mathcal{EM}^M\circ R_{\theta_0}^{r_0}\right)^{-1}\left(\{0\}\right). The set $\mathcal{A}$ is the union of a family of codimension $M$ sets that is parametrized by the pair $(r_0,\theta_0)\in\mathcal{B}$. Since these parameters live in a space of dimension $d$ and the dependence of them is continuos, we can ensure that $\mathcal{A}$ is a subset of $\MW^s$ of codimension at least $M-d$. Taking $M>d$, we can ensure that the set of monochromatics waves $\vp\in\MW^s$ that do not belong to $ \mathcal{N}_{\mathcal B,\mathrm{BC}}^c$ is dense in $\MW^s$.  Finally, we just recall from Step I that it is also open, which completes the proof.",2502.01291
proof,"We first recall from Section \ref{elli} that eigenfunctions for the Dirichlet and Neumann problem have the same formal expression and that they differ only in the eigenvalues. Therefore as far as we consider eigenvalues $\lambda_{mn}$ and we do not use particular properties of them, we can address both problems simultaneously. We will then write $\mathrm{BC}$ for the dependence on the boundary conditions and it can be $\mathrm{BC}=\mathrm{D}$ or $\mathrm{BC}=\mathrm{N}$. We split the proof in four steps:        	\textbf{	\underline{Step I:}} In this first step, we show that $\mathcal{N}_{\mathcal{E}_b,\mathrm{BC}}$ is open. We proceed exactly as in the  previous section: let us consider $\varphi\in\mathcal{N}_{\mathcal{E}_b,\mathrm{BC}}$. This means that there exists $\delta>0$ such that 	\inf_{ z^0\in\mathcal{E}_b}\inf_{\lambda\in\Lambda_{\mathcal{E}_b}^{\mathrm{BC}}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{E}_b,\mathrm{BC}}^\lambda}\left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0\left(B\right)}>\delta.If we consider those $\psi\in\MW^s$ such that $\left\|\varphi-\psi\right\|_{C^0\left(B\right)}<\delta/2$, we can easily check that the following holds 	&\inf_{ z^0\in\mathcal{E}_b}\inf_{\lambda\in\Lambda_{\mathcal{E}_b}^{\mathrm{BC}}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{E}_b,\mathrm{BC}}^\lambda}\left\|\psi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0\left(B\right)}\geq\\&	\inf_{ z^0\in\mathcal{E}_b}\inf_{\lambda\in\Lambda_{\mathcal{E}_b}^{\mathrm{BC}}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{E}_b,\mathrm{BC}}^\lambda}\left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0\left(B\right)}-\delta/2>\delta/2.So, $B_{C^0\left(B\right)}\left(\varphi,\delta/2\right)\subset\mathcal{N}_{\mathcal{E}_b,\mathrm{BC}}$, and we conclude that it is open. In the rest of the proof, we will see that this set is dense in $\MW^s$.         \textbf{	\underline{Step II:}} In this step, we introduce some notations and maps that we will need in the proof, and we will comment on some of their properties.        	We first fix a point $z^0\in\mathcal{E}_{b}$ given by the elliptical coordinates $\left(\xi_0,\eta_0\right)\in[0,\xi_b]\times [0,2\pi]$. For any small $0<R<1$ that we will fix later, we associate to any $\xi_0\in[0,\xi_b]$ a smooth map:                         I: &[0,\xi_b]\rightarrow C^\infty\left([-R,R],\mathbb{R}\right)\\            &\xi_0\mapsto                I_{\xi_0}: [-R,R]&\rightarrow\mathbb{R}\\               \xi&\mapsto \xi_0\left(1-R\right)+\xi_b\xi.                        Notice that $I_{\xi_0}\left([-R,R]\right)=\left[\xi_0-R\left(\xi_0+\xi_b\right),\xi_0+R\left(\xi_b-\xi_0\right)\right]$ is always an interval of length $2R\xi_b$ contained in $[0,\xi_b]$ for any $\xi_0$ and $R$ small enough, and notice that the maps $I$ and $I_{\xi_0}$ are continuous maps. We can also define, for any pair $\left(\xi_0,\eta_0\right)\in[0,\xi_b]\times[0,2\pi]$, the following  map:                     R_{\eta_0}^{\xi_0}:&\MW^s\rightarrow C^2\left([-R,R]\right)\\&\varphi\mapsto\varphi\left(c\cdot\cosh\left(I_{\xi_0}\left(\cdot\right)\right)\cos(\eta_0),c\cdot\sinh\left(I_{\xi_0}\left(\cdot\right)\right)\sin(\eta_0)\right).            Recall that $c=\sqrt{1-b^2}$ is the eccentricity of the ellipse. This map is the restriction of $\varphi$ to the set:  		L_{z^0}=\left\{\left(c\cdot\cosh\left( 		\xi\right)\cos\left(\eta_0\right),c\cdot\sinh\left(\xi\right)\sin\left(\eta_0\right)\right),\ \xi\in I_{\xi_0}([-R,R])\right\}, 	 which is contained in $\mathcal{E}_b$. $L_{z^0}$ is easily checked to be a segment of a straight line (if $\eta_0=\pi/2$ or $\eta_0=3\pi/2$ ) or an arc of a hyperbola (if $\xi_0\neq\pi/2,\ 3\pi/2 $). It is easy to notice that  $  R_{\eta_0}^{\xi_0}$ is continuous and so it is the map                     R:&[0,\xi_b]\times[0,2\pi]\rightarrow C\left(\MW^s,C^2\left([-R,R]\right)\right)\\&\left(\xi_0,\eta_0\right)\mapsto R_{\eta_0}^{\xi_0}:=R(\xi_0,\eta_0).                  We also define the map  $\tilde{R}_{\eta_0}^{\xi_0}$ as the extension of $R_{\eta_0}^{\xi_0}$ to the set of twice differentiable functions in a neighborhood of $L_{z^0}$.  Following the discussion in Section \ref{elli} and taking $b\notin\mathcal{C}$, we notice that any localized eigenfunction associated to an eigenvalue $\lambda_{mn}$, defined as $\tilde{u}_{mn}^{z^0}:=u_{mn}\left(z^0+\frac{\cdot}{\sqrt{\lambda_{ln}}}\right)$ when $z^0=\left(\xi_0,\eta_0\right)$, has the following form:  		 			& \tilde{R}_{\eta_0}^{\xi_0}\left(\tilde{u}_{mn}^{z^0}\right)(\xi)=u_{mn}\left(\xi_0+\frac{I_{\xi_0}(\xi) }{\sqrt{\lambda_{mn}}},\eta_0\right)=\\&d\cdot S^p_m\left(\xi_0+\frac{\xi_0(1-R)+\xi_b\xi}{\sqrt{\lambda_{mn}}},q_{m,n}\right)E^p_n\left(\eta_0,q_{m,n}\right). 		 	     Here  $d\in\mathbb{R}$ is a constant, $p\in\left\{e,o\right\}$, $m,n\geq 0$, and we are not including the dependence on the boundary conditions. Some computations (including formulas for the $\cosh$) allow us to check that, for any $s,t\in\mathbb{R}^+_0$ and any $m,n\in\mathbb{N}\cup\{0\}$, the function $f_{s,t,m,n}(\xi):=S_m^p\left(t+\frac{\xi}{s},q_{m,n}\right)$ satisfies the following ordinary differential equation for any $\xi\in\mathbb{R}$: 	 		s^2f''_{s,t,m,n}(\xi)-\left(\al_{m,n}-2q_{m,n}\cosh\left(2t+\frac{2\xi}{s}\right)\right)f_{s,t,m,n}(\xi)=0, 	for certain $q_{m,n}>0$ and $\al_{m,n}=a_{m,n}$ or $\alpha_{m,n}=b_{m,n}$.      	 We define now the evaluation map as follows:  	 		 			&\mathcal{EM}^M:C^2\left(\left[-R,R\right]\right)\rightarrow\mathbb{R}^{14M}\\&f\mapsto \left({c c | c } 				f\left(\frac{jR}{M}\right) & f''\left(\frac{jR}{M}\right) &\multirow{4}{*}{$ f\left(-\frac{R}{8M}-\frac{jR}{M}\right)&   f''\left(-\frac{R}{8M}-\frac{jR}{M}\right)\\         f\left(-\frac{R}{4M}-\frac{jR}{M}\right)&  f''\left(-\frac{R}{4M}-\frac{jR}{M}\right)\rule{0pt}{18pt}\\  f\left(-\frac{R}{2M}-\frac{jR}{M}\right)&  f''\left(-\frac{R}{2M}-\frac{jR}{M}\right)\rule{0pt}{18pt}$}\rule{0pt}{15pt} \\ f\left(\frac{R}{8M}+\frac{jR}{M}\right)&  f''\left(\frac{R}{8M}+\frac{jR}{M}\right) \rule{0pt}{15pt}\\f\left(\frac{R}{4M}+\frac{jR}{M}\right)&  f''\left(\frac{R}{4M}+\frac{jR}{M}\right)\rule{0pt}{15pt}\\f\left(\frac{R}{2M}+\frac{jR}{M}\right)&  f''\left(\frac{R}{2M}+\frac{jR}{M}\right)\rule{0pt}{15pt} 			\right)_{j=0}^{M-1} 		         Here $M$ is an integer that will be fixed later. This map is easily checked to be continuous and linear.	If we proceed as in the previous section, we can see by interpolation, that for any $P\in \mathbb{R}^{14M}$ there exists a polynomial $\mathbb{P}(P)$ such that $\mathcal{EM}^M\left(\mathbb{P}(P)\right)=P$. Therefore, it is surjective and open, because of the open mapping theorem. 	 	For a point $P=\left(P_1,\ldots,P_{14M}\right)$ let us denote the coordinates as:  	     	        &P_{j}=:P^0_j,\text{ whenever }1\leq j\leq 14,\\             &P_{j}=:P^1_{j-14},\text{ whenever }15\leq j\leq 28=14\cdot 2,\\             &\ldots\\             &P_{j}=:P^{M-1}_{j-14(M-1)},\text{ whenever }14(M-1)+1\leq j\leq 14M.\\               	For any $0\leq i\leq M-1$, we set $P^i:=\left(P^i_1,\ldots,P^i_{14}\right)\in\mathbb{R}^{14}.$ We also define the following six polynomial functions from $\mathbb{R}^{14}$ (let us say $P\in\mathbb{R}^{14}$) to $\mathbb{R}$. Notice that all of them depend on certain parameters: $\alpha$, $q$, $\beta^j$, $a$, that correspond to $\alpha_{m,n}$, $q_{m,n}$, $\cosh\left(2t+\frac{2j}{Ms}\right)$, $\cosh\left(\frac{R}{4sM}\right)$, respectively:                           &a(P)=\alpha\left(P_{13}P_{2}-P_{1}P_{14}\right)-2q\beta\left(aP_{13}P_{2}-P_{1}P_{14}\right)+2q\sqrt{\beta^2-1}\sqrt{a^2-1}P_{13}P_2,\\  &b(P)=\alpha\left(P_{11}P_{2}-P_{1}P_{12}\right)-2q\beta\left(aP_{11}P_{2}-P_{1}P_{12}\right)-2q\sqrt{\beta^2-1}\sqrt{a^2-1}P_{11}P_2,\\  &c(P)=\alpha\left(P_{9}P_{2}-P_{1}P_{10}\right)-2q\beta\left(\left(2a^2-1\right)P_{9}P_{2}-P_{1}P_{10}\right)\\&+2q\sqrt{\beta^2-1}2a\sqrt{a^2-1}P_{9}P_2,\\  &d(P)=\alpha\left(P_{7}P_{2}-P_{1}P_{8}\right)-2q\beta\left(\left(2a^2-1\right)P_{7}P_{2}-P_{1}P_{8}\right)\\&-2q\sqrt{\beta^2-1}2a\sqrt{a^2-1}P_{7}P_2,\\  &e(P)=\alpha\left(P_{5}P_{2}-P_{1}P_{6}\right)-2q\beta\left(\left(8a^2\left(a^2-1\right)+1\right)P_{5}P_{2}-P_{1}P_{6}\right)\\&+2q\sqrt{\beta^2-1}2\left(2a^2-1\right)\sqrt{\left(a^2-1\right)^2+1}P_{5}P_2,\\  &f(P)=\alpha\left(P_{3}P_{2}-P_{1}P_{4}\right)-2q\beta\left(\left(8a^2\left(a^2-1\right)+1\right)P_{3}P_{2}-P_{1}P_{4}\right)\\&-2q\sqrt{\beta^2-1}2\left(2a^2-1\right)\sqrt{\left(a^2-1\right)^2+1}P_{3}P_2.                    	All of them are homogeneous polynomials of degree two. We define the system of equations given by $a(P^j)=b(P^j)=c(P^j)=d(P^j)=e(P^j)=f(P^j)=0$ for each $0\leq j\leq M-1$ (where the dependence on $j$ appears also in the functions through $\beta^j$ even if it is not explicitly indicated). Some computations allow us to see that if this system is satisfied, so it is the equation $\tilde{Q}_j^M(P)=0$ for each $0\leq j\leq M-1$, where $\tilde{Q}_j^M$ is an homogeneous polynomial independent now of the parameters $\alpha,\beta,q,a$, analogous to the one we found in the previous section. Essentially, we are using the different equations to remove the parameters from them. This can always be done since the dependence on this parameters is polygonal or through square roots.             With all this, we can finally define the function                      &Q_M:\mathbb{R}^{14M}\rightarrow\mathbb{R}^{M}\\             &P=(P^0,P^1,\ldots,P^{M-1})\mapsto Q_M(P)=\left(\tilde{Q}^M_0\left(P^0\right), \tilde{Q}^M_1\left(P^1\right),\ldots,\tilde{Q}^M_{M-1}\left(P^{M-1}\right)\right).               	        Notice that $Q_M^{-1}\left(\left\{0\right\}\right)$ is an (affine) algebraic variety (in particular, a closed set with empty interior because $Q_M$ is surjective) and, consequently, $\mathbb{R}^{14M}\backslash Q_M^{-1}\left(\left\{0\right\}\right)$ is open and dense.  Moreover, since any entry of $Q_M$ is evaluated at different coordinates, we notice that all of them are independent and so $Q_M^{-1}\left(\left\{0\right\}\right)$ is of codimension at least $M$ in $\mathbb{R}^{14M}$.          On the other hand, it comes from an easy computation that , for any $s,t\in\mathbb{R}^+_0$ and any $m,n\in\mathbb{N}\cup\{0\}$, $Q_M\left(\mathcal{EM}^M\left(f_{s,t,m,n}\right)\right)=0$ and, consequently, for any eigenfunction $u_{mn}$ and any $z^0\in\mathcal{E}_b$, 	 		\mathcal{EM}^M\left(\tilde{R}_{\eta_0}^{\xi_0}\left(\tilde{u}_{mn}^{z^0}\right)\right)\in Q_M^{-1}\left(\left\{0\right\}\right). 	      	  \textbf{	\underline{Step III:}}  We continue the proof in a similar way as the one in the previous section:  for any $P\in \RR^{14M}$, we consider the polynomial $\mathbb{P}(P)$ given by interpolation. 	An easy application of the CauchyKovalevskaya theorem ensures the existence of a neighborhood $N_P$ of $L_{z_0}$ in $\mathbb{R}^{2}$ and a function $H_P:N_P\rightarrow\mathbb{R}$ satisfying the Helmholtz equation $\Delta H_P+H_P=0$ in $N_P$ such that $\restr{H_P}{L_{z_0}}=\mathbb{P}(P)$. Moreover, by the global approximation theory with decay \cite{APDE}, this means that for any $\ep>0$, there exists another function $\varphi_P\in\MW^s$ such that  		\left\|\varphi_P-H_P\right\|_{C^2\left(N_P\right)}<\ep. 	If we notice that 	 		\left\|\varphi_P-H_P\right\|_{C^2\left(N_P\right)}\geq\frac{1}{7M} \left|\mathcal{EM}^M\left(R_{\eta_0}^{\xi_0}\left(\varphi_P\right)\right)-\mathcal{EM}^M\left(\tilde{R}_{\eta_0}^{\xi_0}\left(H_P\right)\right)\right|, 	we are saying that for any $P\in\mathbb{R}^{14M}$ and any $\de>0$ there exists $\varphi_P\in \MW^s$ such that $\left|\mathcal{EM}^M\left(R_{\eta_0}^{\xi_0}\left(\varphi_P\right)\right)-P\right|<\de.$ Accordingly $\left(\mathcal{EM}^M\circ R_{\eta_0}^{\xi_0}\right)\left(\MW^s\right)$ is dense in $\mathbb{R}^{14M}$. Since the composition map $\mathcal{EM}^M\circ	R_{\eta_0}^{\xi_0}:\MW^s\rightarrow\mathbb{R}^{14M}$ is linear and continuous and has a dense image in $\mathbb{R}^{14M}$ and, it is surjective. By the open mapping theorem, we can conclude that it is also open and, consequently, $\left(\mathcal{EM}^M\circ	R_{\eta_0}^{\xi_0}\right)^{-1}\left(\mathbb{R}^{14M}\backslash Q^{-1}\left(\left\{0\right\}\right)\right)=\MW^s\backslash\left(\mathcal{EM}^M\circ	R_{\eta_0}^{\xi_0}\right)^{-1}\left( Q^{-1}\left(\left\{0\right\}\right)\right)$ is open and dense in $\MW^s$. Reasoning as in the previous section,  we can then conclude that the set $\left(Q_M\circ\mathcal{EM}^M\circ R_{\eta_0}^{\xi_0}\right)^{-1}\left(\{0\}\right)$ has codimension at least $M$ in $\MW^s$. 	 	 \textbf{	\underline{Step IV:}} The last step in the proof is to consider what occurs whenever we change the point $(\xi_0,\eta_0)\in\mathcal{E}_b$ around which we are doing the localization.  We first notice that, for any $\varphi\in \MW^s$, taking $R>0$ small enough, it is true that	 		 			&\inf_{z^0\in\mathcal{E}_b}\inf_{\lambda\in\Lambda_{\mathcal{E}_b}^{\mathrm{BC}}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{E}_b,\mathrm{BC}}^\lambda}\left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0\left(B\right)}\geq\\&C\inf_{z^0\in\mathcal{E}_b}\inf_{\lambda\in\Lambda_{\mathcal{E}_b}^{\mathrm{BC}}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{E}_b,\mathrm{BC}}^\lambda}\left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^2\left(B_R\right)}\geq\\&\frac{C}{7M}\inf_{z^0\in\mathcal{E}_b}\inf_{\lambda\in\Lambda_{\mathcal{E}_b}^{\mathrm{BC}}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{E}_b,\mathrm{BC}}^\lambda}\left|\mathcal{EM}^M\circ R_{\eta_0}^{\xi_0}\left(\varphi\right)-\mathcal{EM}^M\circ\tilde{R_{\eta_0}^{\xi_0}}\left(\tilde{u}_\lambda^{z^0}\right)\right|\geq\\ &\frac{C}{7M}\inf_{z^0\in\mathcal{E}_b} \dist\left(\mathcal{EM}^M\circ R_{\eta_0}^{\xi_0}(\varphi),Q_M^{-1}\left(\{0\}\right)\right). 		 	   Therefore, the set        \mathcal{N}_{\mathcal{E}_b,\mathrm{BC}}^c:=\left\{\varphi\in \MW^s,\ 0=\inf_{z^0\in\mathcal{E}_b}\inf_{\lambda\in\Lambda_{\mathcal{E}_b}^{\mathrm{BC}}}\inf_{u_\lambda \in\mathcal{V}_{\mathcal{E}_b,\mathrm{BC}}^\lambda}\left\|\varphi-u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right)\right\|_{C^0\left(B\right)}\right\},   is contained in the set \mathcal{A}:=\bigcup_{\substack{\xi_0\in[0,\xi_b]\\\eta_0\in[0,2\pi]}}\left(Q_M\circ\mathcal{EM}^M\circ R_{\eta_0}^{\xi_0}\right)^{-1}\left(\{0\}\right). The set $\mathcal{A}$ is the union of a family of codimension $M$ sets that is parametrized by the pair $(\xi_0,\eta_0)\in\mathcal{E}_d$. Since these parameters live in a space of dimension $2$ and the dependence of them is continuous, we can ensure that $\mathcal{A}$ is a subset of $\MW^s$ of codimension at least $M-2$. Taking $M>2$ we can then ensure that the set of monochromatic waves $\vp\in\MW^s$ that do not belong to $ \mathcal{N}_{\mathcal{E}_b,\mathrm{BC}}^c$ is dense in $\MW^s$.  Finally, we just recall from Step I that it is also open and we conclude the proof.",2502.01291
proof,"\textbf{	\underline{Step I:}} We start by proving the first part of this result. We notice that, for any point $z^0\in\Omega\backslash L_\mathcal{P}$, there exists $1\leq j_0\leq J$ such that $z^0\in \mathbb{A}_{j_0}(\mathcal{P})$ and there exists some $\delta>0$ small enough such that $B\left(\mathbb{A}_{j_0}^{-1}\left(z^0\right),\delta\right)\subset\mathcal{P}$. Recall that, for any $1\leq j\leq J$, $\mathbb{A}_j$ is a composition of affine reflections with respect some of the lines of the lattice $L_{\mathcal{P}}$ and, therefore, we have  	 		\left(\mathbb{A}_j\right)^{-1}\left(z^0+\frac{z}{\sqrt{\lambda_n}}\right)=\left(\mathbb{A}_j\right)^{-1}\left(z^0\right)+\frac{\mathbb{S}^j\left(z\right)}{\sqrt{\lambda_n}}, 	where $\mathbb{S}^j$ is a composition of linear reflections with respect to different lines that goes through the origin, as the ones presented in \eqref{reflex} in Appendix \ref{AppendixC}. More precisely, every $\mathbb{S}^j$ is a composition of reflections, possibly repeated, of the following table: 		 		{cc}  			\hline 			\rule{0pt}{3ex}\text{Polygon} & \text{Reflections} \\ 			\hline 			\rule{0pt}{3ex}\mathcal{Q}_l& \mathbb{S}_0,\ \mathbb{S}_\infty\\ 			\rule{0pt}{3ex}\mathcal{T}_\mathrm{iso} & \mathbb{S}_0,\ \mathbb{S}_\infty,\ \mathbb{S}_1\\ 			 			\rule{0pt}{3ex}	\mathcal{T}_\mathrm{equi} & \mathbb{S}_0,\ \mathbb{S}_{\sqrt{3}},\ \mathbb{S}_{\sqrt{-3}} \\ 			\rule{0pt}{3ex}\mathcal{T}_\mathrm{hemi} & \mathbb{S}_0,\ \mathbb{S}_\infty,\ \mathbb{S}_{\sqrt{3}},\ \mathbb{S}_{\sqrt{-3}}\\ 		  	  We now choose a monochromatic wave $\varphi\in\MW$ satisfying the extra conditions on the Table \ref{TableB} associated with $\mathcal{P}$ (it was seen in Appendix \ref{AppendixC} there there exist such monochromatic waves), and notice that $-\varphi\in\MW$ also satisfies them. Since we have seen that $\mathbb{S}^j$ is a composition of symmetries of Table \ref{TableS} (which are the same appearing in the conditions of Table \ref{TableB}) we know that, for any $1\leq j\leq J$,  $\varphi\circ \left(\mathbb{S}^j\right)^{-1}=\left(-1\right)^{\sigma_\mathrm{BC}^j}\varphi$, where $\sigma_\mathrm{BC}^j$ is either $1$ or $2$ and depends on the boundary conditions and on the amount of reflections that form $\mathbb{S}^j$.     The next step consists in applying the positive part of Theorem \ref{BT.polygons}. We first observe that, since the conditions in Table \ref{TableB} are more restrictive than the ones in Table \ref{TableA} (see Appendix \ref{AppendixC} for more details), we will be able to apply it to any $\varphi$ satisfying the conditions in Table \ref{TableB}. We fix now $k\in\mathbb{N}$, $\ep>0$ and $B\subset\RR^2$ and we recall that  $\mathbb{A}_{j_0}^{-1}\left(z^0\right)\in\mathcal{P}$. The positive part of Theorem \ref{BT.polygons} then gives us the existence of a sequence of eigenvalues $\lambda_n$ and eigenfunctions $\tilde{u}_{n}$ of $\mathcal{P}$ with Dirichlet or Neumann boundary conditions, respectively, such that  		\left\|\left(-1\right)^{\sigma^{j_0}_\mathrm{BC}}\vp-\tilde{u}_{n}\left(\mathbb{A}_{j_0}^{-1}\left(z^0\right)+\frac{\cdot}{\sqrt{\lambda_n}}\right)\right\|_{C^k(B)}<\ep, 	for all $n$ large enough. 	If the ball $B$ has radius $R$, we choose $n$ large enough so that $\frac{R}{\sqrt{\lambda_n}}\leq \delta$ and therefore we are only considering $\tilde{u}_{n}$ inside the ball $B\left(\mathbb{A}_{j_0}^{-1}\left(z^0\right),\delta\right)$.  	 	We can now define the following function $	u_{n}:\ \Omega\rightarrow\mathbb{R}$. For any $z\in\Omega$ there exist some $1\leq j_z\leq J$ such that $z\in\overline{\mathbb{A}_{j_z}\left(\mathcal{P}\right)}$, then we define $u_n(z):=\tilde{u}_{n}\left(\left(\mathbb{A}_{j_z}\right)^{-1}\left(z\right)\right).$ Notice that, by Lam's Fundamental Theorem (see \cite[Theorem 1]{trigIV}), the boundary conditions satisfied by $\tilde{u}_n$ ensure that this function is well defined in $L_\mathcal{P}$ and smooth in $\Omega$. Moreover, $u_n$ satisfies the equation $\Delta u_n+\lambda_n u_n=0$ in the whole $\Omega$ and the same boundary condition in $\partial\Omega$ that $\tilde{u}_n$ satisfies in $\partial\mathcal{P}$. 		 		  With this definition we can then estimate  		 			&\left\|\vp-u_{n}\left(z^0+\frac{\cdot}{\sqrt{\lambda_n}}\right)\right\|_{C^k(B)}=	\left\|\vp-\tilde{u}_{n}\left(\left(\mathbb{A}_{j_0}\right)^{-1}\left(z^0+\frac{\cdot}{\sqrt{\lambda_n}}\right)\right)\right\|_{C^k(B)}=\\&\left\|\vp-\tilde{u}_{n}\left(\left(\mathbb{A}_{j_0}\right)^{-1}\left(z^0\right)+\frac{\mathbb{S}^{j_0}\left(\cdot\right)}{\sqrt{\lambda_n}}\right)\right\|_{C^k(B)}=\\&\left\|\left(-1\right)^{\sigma^{j_0}_\mathrm{BC}}\vp-\tilde{u}_{n}\left(\left(\mathbb{A}_{j_0}\right)^{-1}\left(z^0\right)+\frac{\cdot}{\sqrt{\lambda_n}}\right)\right\|_{C^k(B)}<\ep. 		 	 	 	We conclude the proof taking the sequence of eigenvalues $\lambda_n$ given by the positive part of Theorem~\ref{BT.polygons}, the sequence of eigenfunctions given by $u_{n}$ and imposing the extra condition of  $n$ being big enough such that  $\frac{R}{\sqrt{\lambda_n}}\leq \delta$. 	 \textbf{	\underline{Step II:}} 	We now prove the second part of the theorem. We will apply Theorem \ref{pnft} to the base polygon $\mathcal{P}$ but first, we recall from Remark \ref{lambda} the fact that the sequence of eigenvalues $\lambda_n$ that we use to make the approximation does not depend on the monochromatic wave $\vp\in\MW$ that we choose.  On the other hand, we allude to the fact that, since the Laplace operator commutes with any isometry of $\RR^2$, it is obvious that for any $\vp\in\MW$ and any isometry $\mathbb{S}:\mathbb{R}^2\rightarrow\mathbb{R}^2$, we have $\vp\circ\mathbb{S}\in\MW$. As in the previous step we know that for any $1\leq j\leq J$, we can find an isometry $\mathbb{S}^j$ given as a composition of reflections of the Table \ref{TableS} such that 	 	\left(\mathbb{A}_j\right)^{-1}\left(z^0+\frac{z}{\sqrt{\lambda_n}}\right)=\left(\mathbb{A}_j\right)^{-1}\left(z^0\right)+\frac{\mathbb{S}^j\left(z\right)}{\sqrt{\lambda_n}}.   We can then apply Theorem \ref{pnft} to the basic polygon $\mathcal{P}$ of the lattice considering some $\ep>0$, some $B\subset\RR^2$ and some $k\in\mathbb{N}$. As monochromatic wave we consider different cases: $\vp_1=\vp=\vp\circ \I=\vp\circ\mathbb{S}^1$, $\vp_2=\vp\circ\mathbb{S}^2$, $\ldots$,  $\vp_J=\vp\circ\mathbb{S}^J$. Therefore we get a sequence of eigenvalues $\lambda_n$, different sequences of eigenfunctions $\tilde{u}_{n}^j$ and different sequences of sets $\tilde{O}_n^j\subset\mathcal{P}$, with $1\leq j\leq J$, that satisfy Theorem \ref{pnft}.  	 	Let us now consider the set $\tilde{O}_n:=\bigcap_{j=1}^J \tilde{O}_n^j\subset\mathcal{P}$. Since any $\tilde{O}_n^j$ is open, this set is open and, for $n$ big enough, it is non empty. Since, for any $1\leq j\leq J$, we have $\left|\tilde{O}_n^j\right|\xrightarrow[n\rightarrow\infty]{}\left|\mathcal{P}\right|$, then it is also true that $\left|\tilde{O}_n\right|\xrightarrow[n\rightarrow\infty]{}\left|\mathcal{P}\right|$, by just considering the complementary sets. 	 	We then define the finite set of eigenfunction $	u_{n}^j:\ \Omega\rightarrow\mathbb{R}$ as in the previous step:  for any $z\in\Omega$ there exist some $1\leq i\leq J$ such that $z\in\overline{\mathbb{A}_i\left(\mathcal{P}\right)}$, then we define $u_n^j(z):=\tilde{u}_{n}^j\left(\left(\mathbb{A}_i\right)^{-1}\left(z\right)\right).$ Recall that, this function is well defined in $L_\mathcal{P}$, smooth in $\Omega$ and satisfies the equation $\Delta u_n^j+\lambda_n u_n^j=0$ in the whole $\Omega$ with the same boundary condition in $\partial\Omega$ that $\tilde{u}_n^j$ satisfies in $\partial\mathcal{P}$. 	 	Since $\tilde{O}_n^j\subset\mathcal{P}$, we can define a new set given by  	     \overline{O}_n:=\left\{z\in\tilde{O}_n \text{ such that }B\left(z,\frac{R}{\sqrt{\lambda_n}}\right)\subset\mathcal{P}\right\}, 	where $R$ is the radius of $B$. We can conclude the proof taking the sequences $\lambda_n$, $O_n=\bigcup_{i=1}^J\mathbb{A}_i \left(\overline{O}_n\right)$, which obviously satisfies, $\left|O_n\right|\xrightarrow[n\rightarrow\infty]{}\left|\Omega\right|$, and $u_{n}^j:\Omega\rightarrow\mathbb{R}$ where  $1\leq j\leq N$. 	 	To see that this concludes the proof, we notice that for any $z^0\in O_{n}$, in particular, there exists a $j_0\in\left\{1,2,\ldots,J\right\}$ such that $z^0\in  \mathbb{A}_{j_0}\left(\tilde{O}_{n}\right)$. Therefore we have that, for any $n$ large enough so that Theorem \ref{pnft} holds and that  $B\left(\mathbb{A}_{j_0}^{-1}\left(z^0\right),\frac{R}{\sqrt{\lambda_n}}\right)\subset\mathcal{P}$, it is true that  		\left\|\vp_{j_0}-\tilde{u}^{j_0}_{n}\left(\mathbb{A}_{j_0}^{-1}\left(z^0\right)+\frac{\cdot}{\sqrt{\lambda_n}}\right)\right\|_{C^k(B)}<\ep. 	 	Finally, we see that  	 		 		&	\left\|\vp-u^{j_0}_{n}\left(z^0+\frac{\cdot}{\sqrt{\lambda_n}}\right)\right\|_{C^k(B)}=\left\|\vp_{j_0}\circ\left(\mathbb{S}^{j_0}\right)^{-1}-\tilde{u}^{j_0}_{n}\circ\mathbb{A}_{j_0}^{-1}\left(z^0+\frac{\cdot}{\sqrt{\lambda_n}}\right)\right\|_{C^k(B)}=\\&\left\|\vp_{j_0}-\tilde{u}^{j_0}_{n}\circ\mathbb{A}_{j_0}^{-1}\left(z^0+\frac{\mathbb{S}^{j_0}\left(\cdot\right)}{\sqrt{\lambda_n}}\right)\right\|_{C^k(B)}=\left\|\vp_{j_0}-\tilde{u}^{j_0}_{n}\left(\mathbb{A}_{j_0}^{-1}\left(z^0\right)+\frac{\cdot}{\sqrt{\lambda_n}}\right)\right\|_{C^k(B)}<\ep.",2502.01291
proof,"For the benefit of the reader, we will split the proof in two parts.   \textbf{	\underline{Step I:}} 	We first construct a set of analytic hypersurfaces diffeomorphic to the ones we want to construct and some additional ones that will yield the critical points. Moreover, we make this set invariant with respect to the symmetry conditions of Appendix \ref{AppendixC}.          Indeed, an easy application of Whitney's approximation theorem ensures that, by perturbing the hypersurfaces a little if necessary, we can assume that $\Sigma_j$ is a real analytic hypersurface of $\mathbb{R}^d$.  Let us choose the constants $c_j$ so that the first Dirichlet eigenvalue of the domain~$\Om_j$ bounded by the rescaled hypersurface $c_j\Si_j$ is~1. 	To ensure that we also have at least $M$ nondegenerate local extrema, we consider $M$ new hypersurfaces $\Si_j$ with $N+1\leq j\leq N+M$ that we take to be hyperspheres of radius $r$ so that the first Dirichlet eigenvalue of the corresponding balls that they bound is $1$. This eigenvalue is simple and the corresponding eigenfunction is spherically symmetric around the center of the ball and has a nondegenerate local extremum at the center, as desired.     %Since any monochromatic wave is smooth and the domains $\Omega_j$ bounded by the hypersurfaces are precompact, we can ensure that it will have at least a local extremum inside each one of these new $\Omega_j$. The reason why we can assume that the local extrema are nondegenerate is that for generic domains, the first Dirichlet eigenfunctions are Morse~\cite{Uhlen}, so perturbing the domain a little we have the desired property. 	 	Let us now pick any vectors $p_j\in\RR^d$ so that the translated domains $\Om_j':=\Om_j+p_j$ have disjoint closures (which is possible because $\Sigma_j$ are not linked), and take some large ball~$B_R$ so that $\Om_j'\subset B_R$ for all $j$. Moreover, if $\Omega$ is an almost integrable polygon, we take the vectors $p_j$ so that the ball $B_R$ is contained in the fundamental sector $\mathbb{F}_\mathcal{P}\subset\mathbb{R}^2$ associated to $\mathcal{P}$, as defined in Remark \ref{nod}. On the other hand, whenever $\Omega=\mathcal{Q}_l$, we take $B_R$ contained in the first orthant $\mathbb{O}^+$, i.e., those $z\in\mathbb{R}^d$ such that $z_i>0$ for any $1\leq i\leq d$. This implies that all the $\Om_j'$ are contained in $\mathbb{F}_\mathcal{P}$ or $\mathbb{O}^+$.  In the case that $\Om$ is an almost integrable polygon, we can now apply all the reflections of the group of isometries presented in Remark \ref{nod} to any $\Om_j'$. Let us define the sets $\tilde{\Om}_j^0=\Om_j'$, $\tilde{\Om}_j^i=\tilde{\Om}_j^{i-1}\cup\mathbb{S}_i^{\pi/I}\left(\tilde{\Om}_j^{i-1}\right)$, where $I\in\{2,3,4,6\}$ depends on $\mathcal{P}$ and $1\leq i\leq I$. The maps $\mathbb{S}_i^{\pi/I}$ are defined in Remark \ref{nod}. Taking $\tilde{\Om}_j:=\tilde{\Om}_j^I$, we have a set formed by $2I$ copies of $\Om_j'$  and that is invariant with respect to the finite group of isometries that we are considering.   On the other hand, when $\Om=\mathcal{Q}_l$, we define $\tilde{\Om}_j^0=\Om_j'$ and  $\tilde{\Om}_j^i=\tilde{\Om}_j^{i-1}\cup\mathbb{S}_i^{\mathcal{Q}_l}\left(\tilde{\Om}_j^{i-1}\right)$, with $\mathbb{S}_i^{\mathcal{Q}_l}$ defined as in \eqref{sim} and $1\leq i\leq d$. Again $\tilde{\Om}_j:=\tilde{\Om}_j^d$ is formed by $2^d$ copies of $\Om_j'$  and is invariant with respect to the finite group of reflections that we are considering.   Following the same construction, in both cases, we define the symetrized hypersurfaces $\tilde{\Sigma}_j\subset\tilde{\Om}_j$ that are the symmetrized of $\Si'_j=c_j \Si_j+p_j$. In any case, this is also invariant with respect to the finite group of reflections that we are considering.   \textbf{	\underline{Step II:}} Finally, we construct the eigenfunction that will have the desired properties. To do so, we first construct a monochromatic wave with the desired nodal set and then we approximate it by localized eigenfunctions, without losing the construction.   It was proved in~\cite[Theorem 2.2.]{APDE} (see also \cite[Proposition 3.2.]{EP15}) that there exists a  solution~$\phi'$ to the Helmholtz equation in a neighborhood of a symmetric compact set $\mathcal N$ (by symmetric we mean with respect to the reflections introduced in the previous step), which has a union of structurally stable nodal components diffeomorphic to $\bigcup_{j=1}^{M+N}\tilde{\Si}_j$ inside $\mathcal N$. Moreover, $\phi'$ can be taken to be symmetric as well under the corresponding group. By the way of choosing $\Si_j$ with $N+1\leq j\leq N+M$, we notice that $\phi'$ has at least $M$ non-degenerate local extrema in $\mathcal N$. The global approximation theorem for monochromatic waves then implies that there is $\phi\in MW^s$ that approximates $\phi'$ in $\mathcal N$ as much as desired, i.e.,  \|\phi-\phi'\|_{C^k(\mathcal N)}\leq \delta\,.   %The proof concludes by noticing that $\bigcup_{j=1}^{M+N}\Sigma_j$ is a structurally stable components of the the nodal set of $\tilde{\phi}$. More precisely, there exists some~$\de>0$ such that any function~$v$ on~$\RR^d$ with$\|v-\varphi\|_{C^{k}(B_R)}<\de$ has at least $M$ nondegenerate local extrema in~$B_R$ and the zero level set $v^{-1}(0)$ has at least $N$ components of the form $\Phi(\Si_j')$, where $\Phi$ is a diffeomorphism of~$\RR^d$ with $\|\Phi-\id\|_{C^l(\RR^d)}<\ep$. For details on this, we refer the reader to \cite{APDE}.      The next step of the proof is to define a symmetric function in $MW^s$ that still has a union of structurally stable nodal components diffeomorphic to $\bigcup_{j=1}^{N+M}\tilde{\Si}_j$. To do that, we distinguish the two cases:     \item In the case of $\Omega$ being an almost integrable domain, we denote by $g_i$ the elements of the group of isometries of Remark \ref{nod}, where $1\leq i\leq \left|\mathbb{G}_\mathcal{P}\right|$ and $g_1=\I$ is the identity, and we define the function $\varphi\in MW^s$ as follows:          \varphi(z):=\frac{1}{\left|\mathbb{G}_\mathcal{P}\right|}\sum_{i=1}^{\left|\mathbb{G}_\mathcal{P}\right|}\left(-1\right)^{s_i^{\mathrm{BC}}}\phi\circ g_i,     where $s_i^{\mathrm{N}}=0$ always and $s_i^{\mathrm{D}}$ is $0$ when $g_i$ is a composition of an even number of generators and $1$ when it is composed by an odd number. It is immediate to check then that $\vp$ satisfies the conditions on Table \ref{TableB}.          \item In the case of $\Omega=\mathcal{Q}_l$, we denote by $h_i$ with $1\leq i\leq 2^d$ all the possible nontrivial composition of the reflections $\mathbb{S}_j^{\mathcal{Q}_l}$ with $1\leq j\leq d$. We can the define the function $\varphi\in MW^s$ as follows:               \varphi(z):=\frac{1}{2^d}\sum_{i=1}^{2^d}\left(-1\right)^{s_i^{\mathrm{BC}}}\phi\circ h_i,     where $s_i^{\mathrm{BC}}$ depends on the boundary conditions under consideration:  $s_i^{\mathrm{N}}=0$ always and $s_i^{\mathrm{D}}$ is $0$ when $h_i$ is composition of an even number of reflections and $1$ when it is defined by an odd number. Again, we can check that $\vp$ satisfies the conditions on the first line of Table \ref{TableA}.           We now notice that, in the case of $\Omega=\mathcal{Q}_l$ (the other one is analogous), the following bound holds:                     & \left\|{\phi}-\varphi\right\|_{C^{k}(\mathcal{N})}\leq\left\|\frac{1}{2^d}\sum_{i=1}^{2^d}\left(-1\right)^{s_i^{\mathrm{BC}}}{\phi'}\circ h_i-\frac{1}{2^d}\sum_{i=1}^{2^d}\left(-1\right)^{s_i^{\mathrm{BC}}}\phi\circ h_i\right\|_{C^{k}(\mathcal{N})} \\&+\|\phi-\phi'\|_{C^k(\mathcal N)}\leq C_d\left\|{\phi}-\phi'\right\|_{C^{k}(\mathcal{N})}\leq C_d{\delta},              where we have used both the symmetry of ${\phi'}$ and the invariance of $\mathcal{N}$. Therefore, $\varphi$ also has a union of structurally stable nodal components diffeomorphic to $\bigcup_{j=1}^{M+N}\tilde{\Si}_j$ inside  $\mathcal N$.      Since we have the needed symmetry conditions, both the positive part of Theorem~\ref{BT.polygons}, when $\Omega=\mathcal{Q}_l$, and Theorem \ref{T.LATICE}, when considering almost integrable polygons, apply, and we infer that for any point $z^0\in\Omega$ there exists a sequence of localized eigenfunctions $u_n\left(z^0+\frac{\cdot}{\sqrt{\la_n}}\right)$ with eigenvalues $\la_n\to\infty$ such that 	 	\lim_{n\to\infty}\left\|u_n\left(z^0+\frac{\cdot}{\sqrt{\la_n}}\right)-\varphi\right\|_{C^{k}(B_R)}=0\,, 	 	where $B_R$ is any sufficiently large ball that contains $\mathcal N$.      	To conclude the result, we just apply the structural stability of the constructed components of the nodal set.",2502.01291
proof,"To the given tree $t\in\mathrm{T}$ we associate a new one, say $t'$, in which we just add a new vertex connected only with the root. This new vertex is now the root of the tree and represents the existence of a new nodal component surrounding all the nodal domains composing $t$. We can safely assume that $c'$ is contained in $\mathbb{F}_{\mathcal{P}}$, in the case of an almost integrable polygon, or in $\mathbb{O}^+$, in the case in which $\Omega=\mathcal{Q}_l$. Applying \cite[Theorem 2]{Yaiza} and proceeding as in the previous section, we easily obtain a function $\phi'$ that solves the Helmholtz equation in a neighborhood of a compact set $\mathcal N$ that contains $c'$, so that $c'\in\mathcal{C}\left(\phi'\right)$ and $e(c')=t'$. As before, the set $\mathcal N$ is symmetric (with respect to the corresponding reflections) as well as the function $\phi'$, and the components of the nodal set that exhibit the $t'$ structure are structurally stable. It follows from the global approximation theorem that there exists $\phi\in MW^s$ that approximates $\phi'$ in $\mathcal N$ as much as desired, i.e.,  \|\phi-\phi'\|_{C^k(\mathcal N)}\leq \delta\,.  	  	     The next step consists in constructing a new monochromatic wave that is symmetric under the corresponding group of reflections, and still has a set of nodal components with the desired tree structure. To do that, we define $\varphi$ following the same symmetrization process as in the Section before:  	 	\item In the case of $\Omega$ being an almost integrable domain, we recall that $g_i$ are the elements of the group of isometries of Remark \ref{nod}, where $1\leq i\leq \left|\mathbb{G}_\mathcal{P}\right|$, and we define the function $\varphi:\mathbb{R}^2\rightarrow\mathbb{R}$ as follows:  	 		\varphi(z):=\frac{1}{\left|\mathbb{G}_\mathcal{P}\right|}\sum_{i=1}^{\left|\mathbb{G}_\mathcal{P}\right|}\left(-1\right)^{s_i^{\mathrm{BC}}}\phi\circ g_i, 	 	where $s_i^{\mathrm{N}}=0$ always and $s_i^{\mathrm{D}}$ is $0$ when $g_i$ is the composition of an even number of generators and $1$ when it is composed by an odd number.  	 	 	 	\item In the case of $\Omega=\mathcal{Q}_l$, we recall that $h_i$ with $1\leq i\leq 2^d$ are all the possible nontrivial composition of the reflections $\mathbb{S}_j^{\mathcal{Q}_l}$ with $1\leq j\leq d$. We can the define the function $\varphi:\mathbb{R}^2\rightarrow\mathbb{R}$ as follows:  	 	 	 		\varphi(z):=\frac{1}{2^d}\sum_{i=1}^{2^d}\left(-1\right)^{s_i^{\mathrm{BC}}}\phi\circ h_i, 	 	where $s_i^{\mathrm{N}}=0$ always and $s_i^{\mathrm{D}}$ is $0$ when $h_i$ is composition of an even number of reflections and $1$ when it is defined by an odd number.  	  	   In any case, ${\varphi}$ is still a solution to Helmholtz equation that now satisfies the symmetry conditions of Table \ref{TableA} or Table \ref{TableB}, respectively. Moreover, by structural stability, we notice that the nodal set of $\varphi$ contains a finite number of copies of $c'$ (one in each reflection of the fundamental sector), and $e(c')=t'$. These nodal sets are contains in a ball $B_R$ for large enough $R$. The extra vertex (resp. nodal domain) that we added when defining $t'$ ensures that there is a bounded convex domain in $B_R$ inside which we only have those nodal sets that allow us to construct~$t$.  	    	   We conclude the proof as in the previous section:  since we have the needed symmetry conditions,  	   those of Theorem~\ref{BT.polygons}, when $\Omega=\mathcal{Q}_l$, or Theorem \ref{T.LATICE}, when considering almost integrable polygons, for any point $z^0\in\Omega$ there exists a sequence of localized eigenfunctions $u_n\left(z^0+\frac{\cdot}{\sqrt{\la_n}}\right)$ with eigenvalues $\la_n\to\infty$ such that 	    	   	\lim_{n\to\infty}\left\|u_n\left(z^0+\frac{\cdot}{\sqrt{\la_n}}\right)-\varphi\right\|_{C^{k}(B_R)}=0\,, 	    	   Finally, we just apply again the structural stability of the constructed components of the nodal set, and the theorem follows.",2502.01291
proof,"Fix any open set $U\subseteq \Omega$.	Since we assume that Berry's conjecture holds, we have	 		\sigma_U\left(\left\{u_{n_j}\right\}_j\right)=\left\{\muRMW\right\}, 	which means  		\forall F\in \mathcal{C}_b\left(C^0\left(\RR^d\right)\right), \ \lim_{j\rightarrow\infty}\left\langle \LM_{U}\left(\tilde{u}_{z^0,n_j}\right), F\right\rangle=\left\langle \muRMW, F\right\rangle. 	This can be understood as  		\lim_{j\rightarrow\infty}\frac{1}{\Vol(U)}\int_{U}F\left(\tilde{u}_{z^0,n_j}\right)dz^0=\int_{C^0\left(\RR^d\right)}Fd\muRMW.  	Now let $\chi\in C^\infty(\mathbb{R}^d)$ be an even decreasing function that is equal to $1$ on $(0,\ep/2)$ and is supported on $(0,\ep)$. For the chosen $\varphi,\ep,$ and $k$ we define the functional $F_0\in \mathcal{C}_b(C^\infty\left(\RR^d\right))$ given by  		F_0(f):=\chi\left(\left\|f-\varphi\right\|_{C^k(B)}\right) 	for any $f\in C^\infty(\mathbb{R}^d)$. Explicitly, we have   		F_0(f)=\chi\left(\left\|f-\varphi\right\|_{C^k(B)}\right)=\left\{ 			&1 \text{ if } \|f-\varphi\|_{C^k(B)}<\ep/2 \\ 			&\text{Smooth in the middle}\\ 			&	0 \text{ if } \|f-\varphi\|_{C^k(B)}>\ep. 		\right. 	In particular,   		F_0\left(\tilde{u}_{z^0,n_j}\right)=\chi\left(\left\|\tilde{u}_{z^0,n_j}-\varphi\right\|_{C^k(B)}\right), 	for any $j\in\NN$. This non-linear functional is continuous and bounded. 	 	The next step is to see that  $\left\langle \muRMW, F_0\right\rangle>0$. This is easy and a proof can be found e.g. in \cite{Yo}.  Let us briefly recall the argument here. 	  	First, notice that any solution to the Helmholtz equation in the ball $B\subset \mathbb R^d$ can be expanded as a Bessel-Fourier series  		\varphi(z)= \sum_{l=0}^\infty \sum_{m=1}^{d_l} c_{lm}\,\frac{J_{l+\frac d2-1}(|z|)}{|z|^{\frac d2-1}}\, Y_{lm}\left(\frac z{|z|}\right). 	 	On the other hand, it is known that the random field $\PsiR$ associated to the measure $\muRMW$ can be written as  		\PsiR(x)= \sum_{l=0}^\infty \sum_{m=1}^{d_l} a_{lm}\,\frac{J_{l+\frac d2-1}(|x|)}{|x|^{\frac d2-1}}\, Y_{lm}\left(\frac x{|x|}\right), 	where $a_{lm}$ are independent random Gaussian variables. 	Since the topology we are considering in $C^0\left(\mathbb{R}^d\right)$ is precisely the topology given by convergence of each coefficient in the expansion, the claim follows because for any $l\in\mathbb{N}$ and any $1\leq m\leq d_l$, $\mathbb P(\{|a_{lm}-c_{lm}|<\varepsilon\})>0$. 	 	 	 We conclude that $\frac{1}{\Vol(U)}\int_{U}F\left(\tilde{u}_{z^0,n_j}\right)dz^0$ converges to a positive number when $j\rightarrow\infty$, and hence for big enough $J$ there must be a positive measure set of points $M$ on $U\subseteq \Om$ for which $F\left(\tilde{u}_{z^0,n_J}\right)>0$. This clearly implies, by the definition of $F$, that for those points, we have   	 	\|\tilde{u}_{z^0,n_J}-\varphi\|_{C^k(B)}=	\left\|u_{n_J}\left(z^0+\frac{\cdot}{\sqrt{\lambda_{n_J}}}\right)-\vp\right\|_{C^k(B)}\leq\ep. 	 This concludes the proof.",2502.01291
proof,"The eigenfunction can be rewritten as  	 		u_{n}(z)=\frac{1}{\sqrt{\left|\mathcal{N}_\lambda^{\mathcal{Q}_1,\mathrm{D}}\right|}}\sum_{\substack{N\in\mathcal{N}_\lambda^{\mathcal{Q}_1},\mathrm{P},\\ \lambda\text{ not a square}}}\sign\left(m\cdot n\right)e^{\pi i z\cdot N}, 	 where we have used that $\left|\mathcal{N}_\lambda^{\mathcal{Q}_1,\mathrm{P}}\right|=4\mathcal{N}_\lambda^{\mathcal{Q}_1,\mathrm{D}}$ (when $\lambda$ is not a perfect square) and some trigonometric formulas. In this case, the coefficients are given by the formula $a_\xi=\frac{1}{\sqrt{\left|\mathcal{N}_\lambda^{\mathcal{Q}_1,\mathrm{D}}\right|}}\sign\left(m\cdot n\right)$, for any $N=(m,n)\in\mathcal{N}_\lambda^{\mathcal{Q}_1,\mathrm{D}}$, and we get the same associated measure on $\mathbb{S}^1$. Therefore, it satisfies the  conditions of \cite[Hypothesis 1]{Ingremeau} and we can apply again Bourgain, Buckley and Wigman techniques. 	 To conclude the proof, one needs to take into account two things. The first one is that local weak measures in $\mathcal{Q}_1$ and in $\mathbb{T}^2$ differ in the presence of the cut-off function $\chi$. However, it is just introduced to ensure that $\tilde{u}_{z^0,\mathrm{N}}$ is defined in the whole $\RR^d$ and, by its definition, it is easy to check that it does not make any difference in the limit. The second one, is that any Borel set $U$ of $\mathcal{Q}_1$ is also a Borel set of $\mathbb{T}^2$. With all this, we can finally argue as in the proof of \cite[Theorem 2]{Ingremeau} and conclude that, taking as a full density sequence the one of \ref{BerryIngremeau} without the perfect squares (this is still of full density), for any Borel set $U\subset\mathcal{Q}_1$,  		\sigma_{Q}\left((u_{n_j}^\mathrm{D})_j\right)=	\sigma_{\mathbb{T}^2}\left((u_{n_j})_j\right)=\left\{\muRMW\right\}.",2502.01291
proof,"The eigenfunction can be rewritten as 		 		u_{n}^\mathrm{N}(z)=\frac{1}{\sqrt{\left|\mathcal{N}_\lambda^{\mathcal{Q}_1,\mathrm{N}}\right|}}\sum_{N\in\mathcal{N}_\lambda^{\mathcal{Q}_1,\mathrm{P}}}e^{\pi i x\cdot N}, 		 		whenever $\lambda_n$ is not a perfect square, and the associated measure is again essentially the same. Consequently, the proof is analogous to the proof of the previous lemma, and the result follows.",2502.01291
lemma,"For $\mathbb{Q}_l$ as stated, any $N,M\in\mathbb{Z}^d$ satisfy $\mathbb{Q}_l(N)=\mathbb{Q}_l(M)$ if and only if $\mathbb{Q}_r(N)=\mathbb{Q}_r(M)$ for all $1\leq r\leq m$.",2502.01291
lemma,"Let us take $J_\alpha(\rho)$ and $J_{\alpha+m}(\rho)$ for $\alpha$ rational and $m$ natural numbers. If there exists a $\rho_0$ such that $J_\alpha(\rho_0)=0$ and $J_{\alpha+m}(\rho_0)=0$, then $\rho_0=0$.",2502.01291
lemma,"For any values of $l\in\mathbb{N}\cup\{0\}$ and $m\in\mathbb{N}$, then the functions $\frac{d}{d\rho}\left(\rho^{1-d/2}J_{d/2+l-1}\left(\rho\right)\right)$ and $\frac{d}{d\rho}\left(\rho^{1-d/2}J_{d/2+l+m-1}\left(\rho\right)\right)$ have no common positive zeros.",2502.01291
lemma,"For $R>0$, set $\mathcal{R}^{2d}=[-R,R]^{2d}$. Then, for all $\delta>0$,  			\int_{\mathcal{P}}\int_{\mathcal{R}^{2d}}\left(\mathcal{E}_{\lambda,\mathcal{P},\mathrm{BC}}^{z^0}(z,z^\gamma)\right)^2dzdz^\gamma dz^0\leq\frac{C_\delta R^{2d}}{\lambda^{1/2-\delta}}, 		when $\lambda\rightarrow \infty$ along a sequence that gives us asymptotic equidistribution.",2502.01291
lemma,"Let $\left(f_L\right)_{L=1}^\infty$ be a sequence of continuously differentiable functions $f_L: \mathcal{P}\times \mathcal{R}^{2d} \rightarrow \mathbb{R}$ and write $f_{z^0, L}(u):=f_L(z^0, u)$. Suppose that $\left\|f_L\right\|_{\mathcal{P} \times \mathcal{R}^{2d}}^{\mathrm{Lip}} \leq D$ is bounded uniformly with respect to $R$ and $L$ and that 		 		 			\int_{\mathcal{P}}\int_{\mathcal{R}^{2d}}\left(f_{z^0, L}(u)\right)^2 d u d z^0 \leq C \frac{R^{2d}}{\Gamma(L)}, 		 		 		where $\Gamma(L)$ is some positive real function of $L$. Then 		 		 			\int_{\mathcal{P}}\left\|f_{z^0, L}\right\|_{\mathcal{R}^{2d}}^{\infty} d z^0 \leq C \frac{R^{2}}{(\Gamma(L))^{\frac{1}{d+3}}}.",2502.01291
lemma,"Let $Q\left(k_1, \ldots, k_d\right)$ be a positive definite integral diagonal quadratic form in $d \geq 2$ variables. 		The number of integral representations $Q\left(k_1, \ldots, k_d\right)=n$ satisfies, for all $\delta>0$ small enough, 			 			r_Q(n)\leq C_{d,\delta} n^{d / 2-1+\delta} . 		 		 			The constant depends only on $d$ and $\ep$, so it is independent of the actual coefficients of $Q$ and of $n$.",2502.01291
lemma,"If we choose $\lambda$ large enough along a sequence that satisfies the  asymptotic equidistribution as in Definition \ref{aequid}, then we have 		 			 				&\#\mathcal{N}_\lambda^{\mathcal{Q}_l}\geq c\cdot \lambda^{d/2-1},\text{ if }d\geq 5,\\ 				&\#\mathcal{N}_\lambda^{\mathcal{Q}_l}\geq c\cdot \lambda\log\left(\log(3\lambda)\right)^{-1},\text{ if }d=4,\\ 				&\#\mathcal{N}_\lambda^{\mathcal{Q}_l}\geq c_\gamma\cdot \lambda^{1/2-\gamma},\text{ for all }\gamma>0\text{ and }\text{ if }d=3,\\ 				&\#\mathcal{N}_\lambda^{\mathcal{Q}_l}\geq c_\gamma\cdot \lambda^{\gamma},\text{ for all }\gamma>0\text{ and }\text{ if }d=2, 			 		when $\lambda\rightarrow\infty$. In particular, for $d\geq 3$,  			\#\mathcal{N}_\lambda^{\mathcal{Q}_l}\geq c_{\gamma,\mathrm{D}}\cdot \lambda^{\frac{d-2}{2}-\gamma},\text{ for all }\gamma>0.",2502.01291
lemma,"For any $p\in \mathbb{R}^{d_H}$, there exist $\delta_p>0$, a ball $B_{\delta_p}\subset\mathbb{R}^d$ and a function $\phi\in C^\infty\left(B_{\delta_p}\right)$ such that $\Delta \phi+\phi=0$ in $B_{\delta_p}$ and  			p=\left(\left(\partial_{z_i}\partial_{z_j}\phi(0)\right)_{1\leq i\leq j\leq d},\left(\partial_{z_i}\partial_{z_j}\partial_{z_l}\phi(0)\right)_{1\leq i\leq j\leq l\leq d}\right).",2502.01291
lemma,"The set 			\mathcal{V}:=\left\{&\left(\left(\partial_{i}\partial_{j}f(0)\right)_{1\leq i\leq j\leq d},\left(\partial_{i}\partial_{j}\partial_{l}f(0)\right)_{1\leq i\leq j\leq l\leq d}\right), 				\\& f=u_\lambda\left(z^0+\frac{\cdot}{\sqrt{\lambda}}\right),\ z^0\in\mathcal{Q}_l,\ \lambda \in \Lambda_{\mathcal{Q}_l}^{\mathrm{BC}},\ u_\lambda\in\mathcal{V}_{\mathcal{Q}_l,\mathrm{BC}}^\lambda 			\right\}\subset\mathbb{R}^{d_H} 		 satisfies that its closure has empty interior.",2502.01291
lemma,"Let  $u_n\in C^\infty(\Omega,\mathbb{R})$ be as in \eqref{eigeneq}. Let $U\subset\Omega$ be a Borel set of positive Lebesgue measure. There exists a subsequence $n_j$ and a probability measure $\mu\in\mathcal{M}_0$ such that $\LM_{U}(u_n)\stackrel{*}{\rightharpoonup} \mu$, i.e., for all $G\in C_b\left(\MW\right)$, we have  		\lim_{n\to\infty}\left\langle\LM_{U}(u_n),G\right\rangle=\left\langle\mu,G\right\rangle. 	 	Moreover, $\mu$ is supported in $\MW$.",2502.01291
lemma,"There exists a density one sequence $n_j$ such that   		\sigma_{U}\left((u_{n_j}^\mathrm{D})_j\right)=\left\{\mu_{\text{Berry}}\right\}, 	for any Borel set $U\subset\mathcal{Q}_1$.",2502.01291
lemma,"There exists a density one sequence $n_j$ such that  		\sigma_{U}\left((u^\mathrm{N}_{n_j})_j\right)=\left\{\muRMW\right\}, 	for any Borel set $U$ of $\mathcal{Q}_1$.",2502.01291
theorem,"\cite{Oseledets.2011}  %   If for each unfolding matrix $A_k$ of a $d$-dimensional tensor $\cc{A}$   %      %     {\rm rank}(A_k) = r_k,    %     % then there exists a decompositions with TT-ranks not higher than $r_k$. %",2502.01293
theorem,"{\rm (\cite{OSELEDETS201070})}.     Suppose that the unfoldings $A_k$ of the tensor $\cc{A}$ satisfy (\ref{lowrank}). The TT-SVD computes a tensor $\cc{B}$ in the TT-format with TT-ranks $r_k$ and              \|\cc{A}-\cc{B}\|_F^2\le \sum_{k=1}^{d-1}\epsilon_k^2 ,          where $\epsilon_k$ is the distance (in the Frobenius norm) from $A_k$ to its best rank-$r_k$ approximation      \[     \epsilon_k = \min_{{\rm rank}(B)\le r_k}\|A_k - B\|_F.     \]",2502.01293
theorem,"{\rm (\cite{jiang2017tensor})} For a given tensor $\cX\in\RR^{n_1 \times \dots\times n_d}$ with independent Tucker decomposition $\cX= \cc{C}\times_1 A^{(1)}\times_2 A^{(2)},\ldots\times_d A^{(d)}$, we have that      \alpha\|\cc{C}\|_F\le\|\cX\|_F\le\beta\|\cc{C}\|_F,  where $\beta=\|A^{(1)}\|_2\|A^{(2)}\|_2\dots\|A^{(d)}\|_2$ and $\alpha=\beta/(\Pi_{i=1}^{d}\kappa(A^{(i)})$ with $\kappa(A^{(i)})$ being the condition number of the matrix $A^{(i)}$.",2502.01293
definition,"Given a tensor $\cX\in\RR^{n_1\times \dots\times n_d}$, the Tucker decomposition of $\cX$ is defined as \[ \cX\approx \cc{C}\times_1 A^{(1)}\times_2 A^{(2)}\dots \times_N A^{(d)}, \] where $\cc{C}\in\RR^{m_1\times \dots\times m_d}$ is the core tensor and $A^{(j)}\in\RR^{n_j\times m_j}$.",2502.01293
theorem,"[\cite{seneta1973non}, The Perron-Frobenius Theorem for irreducible matrices.]  Suppose \(A\) is an \(n \times n\) non-negative irreducible matrix. Then there exists an eigenvalue \(r\) such that:      \item \(r\) is real and \(r>0\);     \item with \(r\) there can be associated strictly positive left and right eigenvectors;     \item \(r \geqslant |\lambda| \) for any eigenvalue \(\lambda\) of \(A\).",2502.01314
theorem,"[\cite{minc1988nonnegative}]     If \(A\) is an \( n \times n\) non-negative matrix with positive maximal eigenvalue \(r\) and a corresponding positive eigenvector \(x = (x_1, x_2, \ldots, x_n)\), then \( (1/r) \cdot D^{-1}AD \) is a stochastic matrix, with the diagonal matrix \(D = \text{diag}(x_1, x_2, \ldots , x_n)\).",2502.01314
theorem,\( \Xi_1 = \{ 1 \} \).,2502.01314
theorem,[Reduction Theorem]      For every \(n \geqslant 3\): \(\Xi_{n} \subseteq \Theta_{n-1} \).,2502.01314
theorem,"[Complete description of \(\Xi_3\)]     \(\Xi_3 = [-1/2, 1]\).",2502.01314
definition,"[\cite{seneta1973non}]     An \(n \times n\) matrix \(A=(a_{ij})\) is called non-negative if all matrix elements are non-negative, i.e. \(a_{ij} \geqslant 0 \) for all \(1 \leqslant i \leqslant n\) and \(1 \leqslant j \leqslant n\). In this case we write \(A \geqslant 0 \).",2502.01314
definition,"[\cite{minc1988nonnegative}]     An \(n \times n\) non-negative matrix \(A\), \( n \geqslant 2 \), is called reducible if there exists a permutation matrix \(P\) such that     \[P^{T}AP =          B & C \\         O & D     , \]     where \(B\) and \(D\) are square submatrices, and the notation \(P^{T}\) refers to the transpose of \(P\). Otherwise \(A\) is called irreducible. A \(1 \times 1\) matrix is irreducible by definition.",2502.01314
definition,"A non-negative \(n \times n\) matrix \(S\) is stochastic if the sum of all matrix elements in each row is equal to \(1\). So a stochastic matrix \(S = (s_{ij}) \) satisfies the following conditions:              \item \(s_{ij} \geqslant 0, \forall i,j \in \{1, \ldots , n \}  \);         \item \(\sum_{j=1}^{n} s_{ij} = 1, \forall i \in \{ 1, \ldots , n\}.\)",2502.01314
definition,"For each \(n\), the eigenvalue regions (also known as the Karpelevich regions) are defined as follows:     \[ \Theta_n = \{ \lambda \in \mathds{C} : \lambda \text{ is an eigenvalue of an \(n \times n\) \hfill \\ stochastic  matrix}  \}.\]",2502.01314
definition,"[\cite{daley1968stochastically}]     A monotone matrix \(M =(m_{ij})\) is a stochastic matrix satisfying the following conditions:     \[\sum_{j=r}^n m_{lj} \geqslant \sum_{j=r}^n m_{kj} \hspace{4mm} \forall l > k, \hspace{2mm} \forall r \in \{1, \ldots, n \} .\]",2502.01314
definition,"[\cite{conlisk1990monotone}] For an \(n \times n\) monotone matrix \(M\) the \((n-1) \times (n-1)\) \text{dominance matrix \(D(M)\)} is given by:         \[(D(M))_{kl} = \sum_{j=1}^l m_{kj} - \sum_{j=1}^l m_{k+1,j} \hspace{4mm} \forall k,l \in \{1, \ldots, n-1 \} . \]",2502.01314
definition,"For each \(n\), the monotone eigenvalue regions are defined as follows:     \[ \Xi_n = \{ \lambda \in \mathds{C} : \lambda \text{ is an eigenvalue of an \(n \times n\) \hfill \\ monotone  matrix}  \}.\]",2502.01314
proof,"Let \(\lambda \in \Xi_n\) and let \(M\) be an \(n \times n\) monotone matrix of which \(\lambda\) is an eigenvalue. Then, one can easily verify that \(\lambda\) is an eigenvalue of the matrix     \(M' =          M & 0 \\         0^{T} & 1     \)     as well, where \(0\) is a \( n \times 1\) vector filled with all zeros. The matrix \(M'\) is a \((n+1) \times (n+1) \) monotone matrix. So it immediately follows that \(\lambda \in \Xi_{n+1} \).",2502.01314
proof,This statement is trivial since a \(1 \times 1\) monotone matrix can only be the matrix \((1)\).,2502.01314
proof,"Let \(M\) be a \(2 \times 2\) monotone matrix with \(\sigma(M)= \{\lambda_1 = 1, \lambda_2 \}\), then \(\lambda_2 \geqslant 0\) (because of Theorem \ref{PerronFrobenius}). Hence, \(\Xi_2 \subseteq [0,1]\). Furthermore, for \(\lambda_2 \in [0,1] \) the monotone matrix \(                 \lambda_2 & 1 - \lambda_2 \\                 0 & 1              \), has \(\lambda_2\) as eigenvalue. This concludes the proof.",2502.01314
proof,"The reducible matrix \(A\) can be transformed, using a certain permutation matrix \(P\), into the following form: \[ P^T \cdot A \cdot P =              A_1 & * & * & \cdots & * \\             0 & A_2 & * & \cdots & * \\             0 & 0 & A_3 & \cdots & * \\             \vdots & \vdots & \vdots & \ddots & \vdots \\             0 & 0 & 0 & \cdots & A_l  , \] where all \(A_i\)'s are irreducible square matrices. It can easily be seen that \(A\) and \(P^T \cdot A \cdot P\) have the same eigenvalues, so we can focus ourselves to the new obtained blockmatrix above. Since \[\det (A - \lambda I) = \det (A_1 - \lambda I) \cdot \ldots \cdot \det (A_l - \lambda I),\] we can rewrite the spectrum of \(A\) as \[ \sigma(A) = \sigma (A_1) \cup \cdots \cup \sigma (A_l).\] In this way the eigenvalues of \(A\) can be determined as the eigenvalues of the smaller irreducible matrices \(A_1, \ldots , A_l\). Because the matrix \(A\) is non-negative, it follows that \(A_1, \ldots , A_l\) have the same property, which concludes the proof.",2502.01314
proof,"By Lemma \ref{ReducibeleGeval}, it suffices to prove this theorem in case where the dominance matrix \(D(M)\) is a non-negative irreducible matrix. It follows from Theorem \ref{PerronFrobenius} that \(D(M)\) has a strictly positive maximal eigenvalue \(r\) and a strictly positive maximal eigenvector.  It follows from Theorem \ref{Minc} that \(S = (1/r) \cdot D^{-1} \cdot D(M) \cdot D \) is an \((n-1) \times (n-1)\) stochastic matrix. If \( \sigma(S) = \{\mu_1, \ldots, \mu_{n-1} \}\), then we have the following link between the eigenvalues of \(S\) en \(D(M)\):         \[\mu_i = \lambda_{i+1}/r \text{ for } i \in \{1, \ldots, n-1\}.\]  Since \(r\) is a eigenvalue of the stochastic matrix \(M\), necessarily holds \(r \leq 1\).  Hence, \(|\mu_i| = |\lambda_{i+1}|/r \geqslant |\lambda_{i+1}| \). Because each \(\mu_i\) lies in the region \(\Theta_{n-1}\) and, moreover, this region is star-convex, it follows that also \(\lambda_{i+1}\) lies in \(\Theta_{n-1}\). Thus \( \sigma(D(M)) = \{\lambda_2, \ldots, \lambda_{n} \} \subseteq \Theta_{n-1} \), which completes the proof.",2502.01314
proof,"Let \(M\) be the following \(3 \times 3\) monotone matrix:     \[M =          m_{11} & m_{12} & m_{13} \\         m_{21} & m_{22} & m_{23} \\         m_{31} & m_{32} & m_{33}      .\]    Then we have the following dominance matrix: \[ D(M) =      a & b \\     c & d , \] with       a &= m_{11} - m_{21}; \nonumber \\     b &= (m_{11} + m_{12}) - (m_{21} + m_{22}); \\     c &= m_{21} - m_{31}; \\     d &= (m_{21} + m_{22}) - (m_{31} + m_{32}). \nonumber  Since \(D(M)\) is a non-negative matrix, it follows that \(a, b, c, d \geq 0\).      The eigenvalues of \(D(M)\) are:     \[ \lambda_2 = \frac{a + d + \sqrt{(a-d)^2 + 4bc}}{2} \text{ and } \lambda_3 = \frac{a + d - \sqrt{(a-d)^2 + 4bc}}{2} .\]     In order to prove the intended inclusion, we want to know how small an eigenvalue can be. Therefore, we are going to minimize the smallest eigenvalue:              \lambda_3 &= \frac{a + d - \sqrt{(a-d)^2 + 4bc}}{2} \nonumber \\          &\geqslant \frac{a + d - \sqrt{(a+d)^2 + 4bc}}{2} \\          &\geqslant \frac{a + d - \sqrt{(a+d)^2 + 2(a+d)2\sqrt{bc} + (2\sqrt{bc})^2}}{2} \\          &= \frac{a + d - \sqrt{(a+d + 2 \sqrt{bc})^2}}{2} \nonumber \\          &= \frac{a + d - (a+d + 2 \sqrt{bc})}{2} \nonumber\\          &= - \sqrt{bc}          Above, inequalities (3) and (4) follow from the fact that \(a\) and \(d\) are positive.      It follows from equation (5) that, in order to investigate a lower bound for the eigenvalues, we need to maximize the expression \(b \cdot c\).          According to (1) an upper bound for \(b\) can be obtained by choosing \(m_{22} = 0\) en \(m_{11} + m_{12} = 1\). In turn, according to (2), \(c\) can be bounded upwards by setting \(m_{31} = 0\). In this way, we get \( b \cdot c \leq (1-m_{21}) \cdot m_{21}.\)      One can easily check that the maximum of this last expression is reached for \(m_{21}=1/2\) and is equal to \(1/4\). So we obtain that \( \lambda_3 \geqslant - 1/2 \), and as we know that an eigenvalue of a stochastic matrix is at most 1, this concludes the proof.",2502.01314
proof,"For each \( x \in [0,1]\), we construct the following monotone matrix  \[     0 & 1-x & x \\     0 & 1-x & x \\     0 & 0 & 1  .\]  Via a simple calculation, we obtain the following characteristic equation  \[(\lambda - 1)(-\lambda^2 - \lambda x + \lambda) = 0,\] from which the eigenvalues below follow: \[ \lambda_1 = 1, \lambda_2 = 1-x \text{ and } \lambda_3 = 0  .\]  For \( x \in [0,1] \), the eigenvalue \( \lambda_2 = 1 - x \) traverses the line segment \([0,1]\).",2502.01314
proof,"For each \( x \in [0, 1/2]\), we construct the following monotone matrix  \[      1/2 - x & 1/2 + x & 0 \\     1/2 - x & 0 & 1/2 + x \\     0 & 1/2 - x & 1/2 +x \]  with characteristic equation  \[-\lambda^3 + \lambda^2 + (1/4 - x^2) \lambda + (x^2 - 1/4) = 0,\]  from which the eigenvalues below follow:  \[ \lambda_1 = 1,  \lambda_2 = \sqrt{1/4 - x^2} \text{ and } \lambda_3 = - \sqrt{1/4 - x^2}  .\]  For \( x \in [0,\frac{1}{2}] \), the eigenvalues \(\lambda_2 = \sqrt{1/4 - x^2}\) and \(\lambda_3 = - \sqrt{1/4 - x^2} \) traverse respectively line segments \([-1/2,0]\) and \([0, 1/2]\).",2502.01314
lemma,"If \(A\) is an \(n \times n\) non-negative reducible matrix, then \(\sigma(A) = \sigma (A_1) \cup \sigma (A_2) \cup \cdots \cup \sigma (A_l)\), with \(l \in \mathbb{N}\) and \(A_1, A_2, \ldots, A_l\) non-negative irreducible matrices of order at most \(n-1\).",2502.01314
lemma,"\(\Xi_3 \subseteq [-1/2, 1]\).",2502.01314
lemma,"[Realising matrices type 1]     Each \(\lambda \in [0,1]\) is an eigenvalue of a \(3 \times 3\) monotone matrix.",2502.01314
lemma,"[Realising matrices type 2]     Each \(\lambda \in [-1/2,1/2]\) is an eigenvalue of a \(3 \times 3\) monotone matrix.",2502.01314
theorem,"Suppose conditions (A1)-(A4) are satisfied and the inequalities \eqref{eq38}-\eqref{eq41} are feasible. Let $\hat{X}$ be the matrix defined in \eqref{eq42}. If the linear matrix inequalities 	 		& \Sigma_{\hat{X}}+\Lambda_{\hat{X}}^{\dagger} Q \Pi+\Pi^{\dagger} Q^{\dagger} \Lambda_{\hat{X}}<0,   \\ 		& {\left[{cc} 				\tilde{\gamma}^{2} I_{n_{y}} & D_{Q} \\ 				D_{Q}^{\dagger} & I_{n} 			\right]>0} , 	 	in which the variable $Q$ is restricted to have the form 	 		Q=\left[{cc} 		A_{Q} & 0  \\ 		C_{Q} & D_{Q} 	\right], 	 	have a feasible solution, then the controller	 	 		& \mathscr{C} \sim\left[{c|c}A_{\mathscr{C}} & B_{\mathscr{C}} \\ \hline C_{\mathscr{C}} & D_{\mathscr{C}}\right],\\ 		& A_{\mathscr{C}}=A_{K_{c}}+B_{K_{c}, 2} D_{Q} C_{K_{c}, 2},  \nonumber\\ 		& B_{\mathscr{C}}=B_{K_{c}, 1}+B_{K_{c}, 2} D_{Q},  \nonumber\\ 		& C_{\mathscr{C}}=C_{K_{c}, 1}+D_{Q} C_{K_{c}, 2},  \nonumber\\ 		& D_{\mathscr{C}}=D_{Q},  	 	solves the two-disk problem \eqref{eq32}, \eqref{eq33}.",2502.01332
theorem,"Given a $\gamma>0$, suppose Assumptions \ref{ass1} and \ref{eq2} are satisfied and the matrix pair  	\Big(A_{\lambda}+\frac{1}{\bar{\gamma}^{2}} B_{\lambda}(I_{p}-\bar{D}_{1, \lambda}^{\dagger} \bar{E}_{1}^{-1} \bar{D}_{1, \lambda}) D_{2, \lambda}^{\dagger} R_{1}^{-1} C_{2, \lambda}, C_{1, \lambda}\Big)   with $\bar{\gamma}=\left(\gamma^{2}+\lambda^{2}\right)^{1 / 2}$, is detectable. Also, suppose the Riccati equation \eqref{eq59} has the stabilizing solution $\tilde{X} \geq 0$. Furthermore, suppose that the central controller $K_{c}$ defined in \eqref{eq60} satisfies the conditions of Theorem \ref{th1} with $\tilde{\gamma}=1$. Obtain $\bar{H}_{11}$ using equation \eqref{eq58}, in which $\mathscr{C}$ is defined in \eqref{eq47}. Then the transfer function $H(s)$ comprised of  	H_{11}(s)=\bar{H}_{11}\left(s^{*}\right)^{\dagger},  and $H_{12}(s), H_{21}(s), H_{22}(s)$ defined in \eqref{eq15}, \eqref{eq16} represents a completely passive physically realizable equalizer which guarantees that  	\bar{\boldsymbol{\sigma}}\left(P_{e}(i \omega)\right)<\gamma^{2} \quad \forall \omega \in \bar{\mathbf{R}}.",2502.01332
theorem,"For any $\gamma>0$ such that $\mathscr{H}_{11, \gamma}^{-} \neq \emptyset$,  	\sup _{\bar{\omega}} \nu_{\bar{\omega}}^{2} \leq \inf \sup _{\omega} \bar{\boldsymbol{\sigma}}\left(P_{e}(i \omega)\right)<\gamma^{2}.",2502.01332
definition,"[\cite{Ugrinovskii2024a}, Definition 1] 	 An element $H(s)$ of the Hardy space $H_{\infty}$ is said to represent a completely passive physically realizable equalizer if $H(s)$ is a stable rational $n_{f} \times n_{f}$ transfer function, $n_{f}=n_{y}+n_{z} \geq n$, which is analytic in the right half-plane $\operatorname{Re}s>-\tau\;(\exists \tau>0)$ and is paraunitary, 	  	 	H(s)^{H} H(s)=H(s) H(s)^{H}=I_{n_{f}}.",2502.01332
definition,"Given $\gamma>0$, the auxiliary problem is to obtain a proper rational $n\times n_y$ transfer function $H_{11}(s)$ with the following properties: 	 		\item[(a)] All poles of $H_{11}(s)$ are in the open left half-plane of	 		the complex plane, and $H_{11}(s)$ is analytic in a half-plane $\operatorname{Re}s>-\tau\;(\exists\tau>0)$; 		\item[(b)] 		 			H_{11}(i\omega)H_{11}(i\omega)^\dagger<I_n\quad\forall\omega\in\bar{\mathbf{R}}, 		 		here $\bar{\mathbf{R}}$ is the closed real axis, $\bar{\mathbf{R}}=\mathbf{R}\cup\{\pm\infty\};$ 		\item[(c)] 		 			P_e(i\omega)<\gamma^2I_n\quad\forall\omega\in\bar{\mathbf{R}}. 		 	 The set of all transfer functions meeting the above requirements is denoted $\mathscr{H}_{11, \gamma}^{-}$.",2502.01332
proposition,"Under Assumption \ref{ass1}, (A4) is satisfied.",2502.01332
proposition,"If the matrix pair \eqref{eq61} is detectable, then $(\tilde{A}, \tilde{B}_{2})$ is stabilizable.",2502.01332
proposition,"Under Assumption \ref{ass2}(iii), (A3) holds true.",2502.01332
lemma,"[Lemma 2, \cite{Ugrinovskii2024a}]  A stable proper transfer function $H_{11}(s)$ which is analytic in a half-plane $\operatorname{Re}s >-\tau\;(\exists \tau>0)$ satisfies \eqref{eq12} if and only if 	 		T_{\lambda}(i \omega)^{\dagger} T_{\lambda}(i \omega)<\bar{\gamma}^{2} I_{n} \quad \forall \omega \in \bar{\mathbf{R}},  	 	where  	T_{\lambda}(s) \triangleq \bar{\Upsilon}_{\lambda}(s)\left[{c} 	\bar{H}_{11}(s)  \\ 	I_{n} \right].",2502.01332
lemma,"Under Assumptions \ref{ass2}(i) and (ii), a controller $\bar{H}_{11}$ which solves the two-disk problem \eqref{eq31} exists if and only if there exists a solution to the two-disk problem \eqref{eq32}, \eqref{eq33} involving the plant  \tilde{\mathscr{P}} \sim\left[{c|cc} 	\tilde{A} & \tilde{B}_{1} & \tilde{B}_{2}  \\ 	\hline \tilde{C}_{1} & \tilde{D}_{11} & \tilde{D}_{12} \\ 	\tilde{C}_{2} & \tilde{D}_{21} & \tilde{D}_{22} \right]=\left[{c|cc} 	\tilde{A} & \tilde{B}_{1} & \tilde{B}_{2} \\ 	\hline \tilde{C}_{1} & 0 & \tilde{D}_{12} \\ 	\tilde{C}_{2} & I_{n} & 0 \right],  whose coefficients are given in \eqref{eq55}, the constant $\tilde{\gamma}=1$ and the matrices $V$, $W$ and $J$ defined as  	V & =\bar{\gamma} \bar{V}_{12} \bar{\boldsymbol{\Sigma}}_{12}^{-1}, \nonumber \\ 	W & =\bar{W}_{21} \bar{\boldsymbol{\Sigma}}_{21}^{-1}, \nonumber \\ 	J & =\bar{E}_{1}^{-1} D_{1, \lambda} D_{2, \lambda}^{\dagger}.   If a controller $\mathscr{C}$ solves the latter problem, then the corresponding solution of the problem \eqref{eq31} is given by  	\bar{H}_{11}(s)=\bar{\gamma} \bar{V}_{12} \bar{\boldsymbol{\Sigma}}_{12}^{-1} \mathscr{C}(s) \bar{\boldsymbol{\Sigma}}_{21}^{-1} \bar{W}_{21}^{\dagger}-\bar{E}_{1}^{-1} D_{1, \lambda} D_{2, \lambda}^{\dagger}.",2502.01332
proof,"First, note that for any ${\bf f}\in \mathbb{C}^n$, \[ \|\mathcal{A}({\bf \tilde{f}}) - {\bf y}\|_2 \leq \|\mathcal{A}({\bf f}) - {\bf y}\|_2 \leq \|\mathcal{A}({\bf f})-\mathcal{A}({\bf f_0})\|_2 + \|\boldsymbol{\varepsilon}\|_2. \] By letting ${\bf f} = \bf{f_0}$, we get \[ \|\mathcal{A}({\bf \tilde{f}}) - {\bf y}\|_2 \leq \|\boldsymbol{\varepsilon}\|_2. \] Now, using the reverse triangle inequality and the bi-Lipschitz property of $\mathcal{A}$, we obtain   \|\mathcal{A}({\bf \tilde{f}}) - {\bf y}\|_2 & = \|\mathcal{A}({\bf \tilde{f}}) - \mathcal{A}({\bf f_0}) - \boldsymbol{\varepsilon}\|_2 \\& \geq \|\mathcal{A}({\bf \tilde{f}})-\mathcal{A}({\bf f_0})\|_2-\|\boldsymbol{\varepsilon}\|_2 \\& \geq \alpha^{-1}\|{\bf \tilde{f}}-{\bf f_0}\|_2 - \|\boldsymbol{\varepsilon}\|_2.   Combining the two inequalities yields \[ \alpha^{-1}\|{\bf \tilde{f}}-{\bf f_0}\|_2 \leq 2\|\boldsymbol{\varepsilon}\|_2, \] which gives the desired result.",2502.01338
proof,"The first step is to upper bound the residual in terms of the bias and variance. By definition of ${\bf y}$ and using the triangular inequality, we have that for any ${\bf z}\in \mathbb{C}^k$,  $$\|\mathcal{A}\circ \mathcal{G}({\bf\tilde{z}}) - {\bf y}\|_2 \leq \|\mathcal{A}\circ \mathcal{G}({\bf z})-\mathcal{A}({\bf f_0})\|_2 + \| \boldsymbol{\varepsilon}\|_2.$$ Picking ${\bf z} = {\bf z_0}$ and utilizing the bi-Lipschitz property of $\mathcal{A}$ then yields $$\|\mathcal{A}\circ \mathcal{G}({\bf\tilde{z}}) - {\bf y}\|_2 \leq \alpha \|\mathcal{G}({\bf z_0})-{\bf f_0}\|_2+\| \boldsymbol{\varepsilon}\|_2.$$  The second step is to lower-bound the residual in terms of the error $\|{\bf \tilde{z}} - {\bf z}\|_2$. We split the residual $\|\mathcal{A}\circ \mathcal{G}({\bf\tilde{z}})-{\bf y}\|_2$ as $$\|\mathcal{A}\circ \mathcal{G}({\bf \tilde{z}}) - \mathcal{A}\circ \mathcal{G}({\bf z_0}) + \mathcal{A}\circ \mathcal{G}({\bf z_0}) - \mathcal{A}({\bf f_0}) - \boldsymbol{\varepsilon}\|_2,$$ and apply the reverse triangle inequality to obtain               \|\mathcal{A}\circ \mathcal{G}({\bf \tilde{z}}) - {\bf y}\|_2 & \geq \|\mathcal{A}\circ \mathcal{G}({\bf\tilde{z}}) - \mathcal{A}\circ \mathcal{G}({\bf z_0})\|_2  \\& - \|\mathcal{A}\circ \mathcal{G}({\bf z_0}) - \mathcal{A}({\bf f_0})\|_2-\|\boldsymbol{\varepsilon}\|_2.       Using bi-Lipschitz property of $\mathcal{A}\circ \mathcal{G}$ and $\mathcal{A}$ and moving terms around we find $$\gamma^{-1}\|{\bf \tilde{z}} -{\bf z_0}\|_2 \leq  \|\mathcal{A}\circ \mathcal{G}({\bf \tilde{z}}) - {\bf y}\|_2 +  \alpha\|\mathcal{G}({\bf z_0}) -{\bf f_0}\|_2 + \|\boldsymbol{\varepsilon}\|_2.$$  The third step is to split the error $\|{\bf\tilde{f}} - {\bf f_0}\|_2$ and apply the triangle inequality               \|{\bf\tilde{f}} - {\bf f_0}\|_2 = & \|\mathcal{G}({\bf \tilde{z}})-\mathcal{G}({\bf z_0}) + \mathcal{G}({\bf z_0}) - {\bf f_0}\|_2 \\& \leq \|\mathcal{G}({\bf\tilde{z}}) - \mathcal{G}({\bf z_0})\|_2+ \|\mathcal{G}({\bf z_0}) - {\bf f_0}\|_2.       The bi-Lipschitz property of $\mathcal{G}$ then yields $$\|{\bf\tilde{f}} - {\bf f_0}\|_2\leq \beta \|{\bf \tilde{z}} - {\bf z_0}\|_2 + \|\mathcal{G}({\bf z_0}) - {\bf f_0}\|_2.$$ The desired result follows by combing the three steps.",2502.01338
proof,"As in the previous results, the bi-Lipschitz property of the map $\mathcal{A}$ yields \[ \alpha^{-1}\|{\bf \tilde f}-{\bf f_0}\|_2 \leq \|\mathcal{A}({\bf \tilde f})-{\bf y}\|_2 + \|\boldsymbol{\varepsilon}\|_2. \] Using the optimality of ${\bf \tilde{f}}$, for any ${\bf f}\in \mathbb{C}^n$, ${\bf z}\in \mathbb{C}^k$, we trivially have \[ \|\mathcal{A}({\bf\tilde f})-{\bf y}\|_2 \leq \sqrt{\|\mathcal{A}({\bf f})-\mathcal{A}({\bf f_0})\|_2^2 + \lambda^2 \|\mathcal{G}({\bf z})-{\bf f}\|_2^2 + \|\boldsymbol{\varepsilon}\|_2^2}. \] Now by picking ${\bf f} = {\bf f_0}$ and ${\bf z}={\bf z_0}\equiv\min_{\bf z} \|\mathcal{G}({\bf z})-{\bf f_0}\|$ and bounding the expression above using $\sqrt{a^2+b^2} \leq |a|+|b|$, we get the desired result.",2502.01338
lemma,[] Let ${\bf \tilde{f}} = \argmin_{{\bf f}} \|\mathcal{A}({\bf f})-{\bf y}\|_2$ with ${\bf y} = \mathcal{A}({\bf f_0}) + \boldsymbol{\varepsilon}$. Then the reconstruction error is given by  \[ \|{\bf \tilde{f}} - {\bf f_0}\|_2 \leq 2\alpha \|\boldsymbol{\varepsilon}\|_2. \],2502.01338
lemma,"Define ${\bf \tilde{z}} = \argmin_{\bf z} \|\mathcal{A}\circ\mathcal{G}({\bf z}) - {\bf y}\|_2$ with ${{\bf y} = \mathcal{A}({\bf f_0})+\boldsymbol{\varepsilon}}$, and ${\bf\tilde{f}}=\mathcal{G}({\bf\tilde{z}})$. Then the reconstruction error is bounded by  \[ \|{\bf \tilde{f}} - {\bf f_0}\|_2 \leq (1 + 2\alpha\beta\gamma) \|\mathcal{G}({\bf z_0}) - {\bf f_0}\|_2 + 2\beta\gamma\|\boldsymbol{\varepsilon}\|_2, \] where ${\bf z_0} = \argmin_{\bf z} \|\mathcal{G}({\bf z})- {\bf f_0}\|_2$.",2502.01338
lemma,The estimate ${\bf \tilde f}$ resulting from \eqref{eq:combined} has a reconstruction error bounded as \[ \|{\bf \tilde f}-{\bf f_0}\|_2 \leq \lambda\alpha \|G({\bf z_0})-{\bf f_0}\|_2 +  2\alpha\|\boldsymbol{\varepsilon}\|_2 \],2502.01338
theorem,"We have $M_1(a)M_1(b)=M_1(a+b)$ for all $a,b\in\ZZ$.",2502.01343
theorem,We have $\det(H_1^{(n)})=\pm 1$ as well as $\det(H_2^{(n)})=\pm 1$ for all $n\in\NN$.,2502.01343
proof,"We may assume that both $a$ and $b$ are nonzero. Note that the case where $a=0$ or $b=0$ is obvious.  	We heavily use Lucas' Theorem modulo $2$, which states  	 	\binom{j}{i}\pmod{2}=\prod_{k=0}^\infty\binom{j_k}{i_k}, 	 	where $i=i_0+i_12+i_22^2+\cdots$ and $j=j_0+j_12+j_22^2+\cdots$ are the binary representations of $i$ and $j$.  	Obviously, $\binom{j}{i}\mod{2}=1$, if $j_k\geq i_k$ for all $k\geq 0$ and $\binom{j}{i}\mod{2}=0$, else.  	Here and in the following $[C]_{i,j}$ denotes the coefficient of $C\in\ZZ^{\NN_0\times \NN_0}$ in the $i$th row and $j$th column.  	 	We compute $[M_1(a)\cdot M_1(b)]_{i,j}$ by using the binary representation of $l=l_0+l_12+l_22^2+\cdots$: 	 	[M_1(a)\cdot M_1(b)]_{i,j}&=\sum_{l=0}^\infty [M_1(a)]_{i,l}\cdot [M_1(b)]_{l,j}\\ 	&=\sum_{l=0}^\infty\Big(\binom{l}{i}\pmod{2}\Big) a^{s_2(l)-s_2(i)}\Big(\binom{j}{l}\pmod{2}\Big) b^{s_2(j)-s_2(l)}\\ 	&=a^{-s_2(i)}b^{s_2(j)}\prod_{k=0}^\infty\sum_{l_k=0}^1\binom{j_k}{l_k}\binom{l_k}{i_k}a^{l_k}b^{-l_k}\\ 	&=\prod_{k=0}^\infty a^{-i_k}b^{j_k}\sum_{l_k=i_k}^{j_k}{\binom{j_k}{l_k}\binom{l_k}{i_k}a^{l_k}b^{-l_k}}. 	 We observe  	$$a^{-i_k}b^{j_k}\sum_{l_k=i_k}^{j_k}{\binom{j_k}{l_k}\binom{l_k}{i_k}a^{l_k}b^{-l_k}}=\left\{{ll}0=\binom{j_k}{i_k}(a+b)^{j_k-i_k}& \mbox{if }1=i_k>j_k=0\\  	a^{-i_k}b^{j_k}=\binom{j_k}{i_k}(a+b)^{j_k-i_k}& \mbox{if }i_k=j_k=0\\ 	a^{-i_k}b^{j_k}\frac{a+b}{b}=\binom{j_k}{i_k}(a+b)^{j_k-i_k}& \mbox{if }0=i_k<j_k=1\\ 		a^{-i_k}b^{j_k}\frac{a}{b}=\binom{j_k}{i_k}(a+b)^{j_k-i_k}& \mbox{if }i_k=j_k=1. 	\right.$$ 	Finally, we arrive at the desired equality, 	 	[M_1(a)\cdot M_1(b)]_{i,j}&=\prod_{k=0}^\infty a^{-i_k}b^{j_k}\sum_{l_k=i_k}^{j_k}{\binom{j_k}{l_k}\binom{l_k}{i_k}a^{l_k}b^{-l_k}}\\ 	&=\prod_{k=0}^\infty\binom{j_k}{i_k}(a+b)^{j_k-i_k}=(\binom{j}{i}\pmod{2})(a+b)^{s_2(j)-s_2(i)}=[M_1(a+b)]_{i,j}.",2502.01343
proof,"We compute by applying Lucas' Theorem modulo $2$ (see equation \eqref{eq:LT}) and by using the binary representation of $l=l_0+l_12+l_22^2+\cdots$:  [M_1^T\diag\big((-1)^{t_i})_{i\geq 0}\big) M_1]_{i,j}&=\sum_{l\geq 0}\Big(\binom{i}{l}\pmod{2}\Big)(-1)^{s_2(l)}\Big(\binom{j}{l}\pmod{2}\Big)\\ &=\prod_{k\geq 0}\sum_{l_k=0}^1\binom{i_k}{l_k}(-1)^{l_k} \binom{j_k}{l_k}\\ &=\prod_{k\geq 0}\Big(1+(-1)\binom{i_k}{1}\binom{j_k}{1}\Big)\\ &=\prod_{k\geq 0}\big(\binom{i_k+j_k}{i_k}\pmod{2}\big)\\ &=\binom{i+j}{i}\pmod 2,  where in the last step we used that $\binom{i+j}{i}\pmod 2=0$ if there occurs at least one carry when adding the binary expansions $i=i_0+i_12+i_22^2+\cdots$ and $j=j_0+j_12+j_22^2+\cdots$, and $\binom{i+j}{i}\pmod 2=1$ else.",2502.01343
proof,"%We denote the upper $n\times n$ submatrix of $C\in\RR^{\NN_0\times \NN_0}$ starting at column $j$ as $C^{(n,j)}$.  From Lemma \ref{cor:1} we know $(M_1^{(n)})^T\diag((-1)^{t_i})_{0\leq i<n} M_1^{(n)}=M_2^{(n)}$. Since $M_1$ is a non-singular upper triangular matrix with diagonal entries all $1$ we immediately obtain $\det(M_2^{(n)})=\det(\diag((-1)^{t_i})_{0\leq i<n})=\prod_{i=0}^{n-1}(-1)^{s_2(i)}$.",2502.01343
proof,"We observe first $M_1(a)=\diag((a^{-s_2(i)})_{i\geq 0})M_1(1) \diag((a^{s_2(i)})_{i\geq 0})$. Thus  $$M_1(a)^{(n,k)}=\diag((a^{-s_2(i)})_{0\leq i<n}) M_1(1)^{(n,k)}\diag((a^{s_2(i)})_{k\leq i<n+k}) .$$ Using \cite[Theorem~1]{mereb} we know $\det(M_1(1)^{(n,k)})=\pm 1$ and the result follows.",2502.01343
proof,"Let $c:=b-a\not\equiv 0\pmod{p}$, $m\in\NN$, and $d_1,d_2\geq 0$ such that $d_1+d_2=m$.  Corollary~\ref{cor:3} ensures that every upper $d_2\times d_2$ submatrix of $M_1(c)$ has determinant $\not\equiv 0 \pmod{p}$. This together with the fact that $M_1(0)=(\delta_{i,j})_{i,j\geq 0}$ immediately yields the linear independence of the system of vectors $([M_1(0)]_{i,0},\ldots,([M_1(0)]_{i,m-1})$, $0\leq i<d_1$ and $([M_1(c)]_{i,0},\ldots,([M_1(c)]_{i,m-1})$, $0\leq i<d_2$. Hence $M_1(0),M_1(c)$ are qualified to construct a $(0,2)$ sequence in base $p$ in the sense of Niederreiter.  From the fact that $M_1(a)$ is a non-singular upper triangular matrix with determinant $1$ we know then that the system of vectors $([M_1(0)M_1(a)]_{i,0},\ldots,([M_1(0)M_1(a)]_{i,m-1})$, $0\leq i<d_1$ and $([M_1(c)M_1(a)]_{i,0},\ldots,([M_1(c)M_1(a)]_{i,m-1})$, $0\leq i<d_2$ are linear independent modulo $p$. From Theorem~\ref{thm:1} we obtain that $M_1(0)M_1(a)=M_1(a)$, that $M_1(c)M_1(a)=M_1(b)$. Thus $M_1(a),M_1(b)$ are qualified to construct a $(0,2)$-sequence in base $p$ in the sense of Niederreiter.",2502.01343
proof,"The first is a consequence of \cite[Lemma~1]{hofJNT} together with \cite[Proposition~1]{hofJNT}, which ensures $\det(H_1^{(n)})\pmod{p}\not\equiv 0$ for every $n\in\NN$ and every $p\in\PP$.   The second is an immediate consequence of the ArXiv paper \cite[Theorem~10.1 (i)]{bacher}, which gives the $LDU$ decomposition of $H_2$. (Details on the $LDU$ decomposition can be found in the subsequent Remark~\ref{rem:3}). As \cite{bacher} is an ArXiv paper we give a proof of the second statement of this Theorem~\ref{thm:PM_Hankel}. We observe that $H_2^{(2^k-1)}$ is an anti-diagonal upper triangular matrix with anti-diagonal-entries all equal to $1$ for all $k\in\NN$. Hence, obviously $\det(H_2^{(2^k-1)})=\pm 1$ for all $k$. For $\det(H_2^{(n)})=\pm 1$ for all $2^k-1<n<2^{k+1}-1$ we proceed by induction on $k$. Let $k$ in $\NN$ and assume that $n=2^k-1+l$ with $1\leq l<2^k$. The induction hypothesis ensures $\det(H_2^{(m)})=\pm 1$ for all $m\leq 2^k-1$. We do row as well as column manipulation in $H_2^{(2^k-1+l)}$ without changing the determinant. In more details we exploit the anti-diagonal part denoted by $J_{2l+1}$ in the right bottom of this matrix. We obtain then a matrix $Q$ of the form $Q=H_2^{(2^k-1-l+1)}&\boldsymbol{0}\\\boldsymbol{0}&J_{2l-1}$ where $\boldsymbol{0}$ stands for a submatrix with all entries equal to $0$. Now obviously, $\det(Q)=\det(H_2^{(2^k-1-l+1)})\cdot \det(J_{2l-1})=\pm 1$, where for the last equality we used the induction hypothesis for $n=2^k-l$. A sketch of the matrices $H_2^{(2^k-1+l)}$ and $Q$, which contains $H_2^{(2^k-1-l+1)}$ and $J_{2l-1}$, can be found in Figure \ref{fig:1}.   [h] 	\centering 		\includegraphics[width=0.25\textwidth]{Fig_Mat1.jpg}\hspace{1cm}\includegraphics[width=0.50\textwidth]{Fig_Mat2.jpg} \caption{Sketch of $H_2^{(2^k-1+l)}$ and $Q$.}       %Or we use the subsequent proposition  in extension of \cite[Theorem~10.1 (i)]{bacher}.",2502.01343
proof,"The continued fraction $\mathcal{L}_1=[0;\overline{X}]$ is the starting point in \cite{hofJNT} to obtain the formal Laurent series $\mathcal{L}_1=\sum_{k\geq 0}c_kX^{-k-1}$ determined via the Catalan numbers. Hence the first equality $\mathcal{L}_1=[0;\overline{X}]$ can be found in \cite{hofJNT}.   The equality $[0,{s_1 X},s_2X,s_3X,\ldots]=\sum_{k\geq 0}(c_k\pmod 2)X^{-k-1}$ can be found in e.g. \cite[Equation~(9)]{Alletal}, previously in e.g. \cite[Theorem~1]{PoSh}.",2502.01343
proposition,"%Let $n\in\NN$. We have $H_1^{(n,0)}=(U^{(n,0)})^TD^{(n,0)}U^{(n,0)}$ where $D=\diag(((-1)^k)_{k\geq 0})$ and $U=(u_{i,j})_{i,j\geq 0}$ with  %$$u_{i,j}=1_{2\NN_0(j-i)}(-1)^{(j-i)/2} \frac{(i+1)^{(j-i)}}{({i+2})^{(\frac{j-i}{2})}(\frac{j-i}{2})!}=1_{2\NN_0(j-i)}(-1)^{(j-i)/2} \frac{i+1}{j+1}\binom{j+1}{(j-i)/2}$$  %where $l^{(k)}$ with $l,k\in\NN$ denotes the rising factorial $l(l+1)\cdots(l+k-1)$.   %",2502.01343
proposition,"Let $\mathcal{L}_1=\sum_{k\geq 0}c_kX^{-k-1}$ and $\mathcal{L}_2=\sum_{k\geq 0}(c_k\pmod 2)X^{-k-1}$ be formal Laurent series over $\QQ$, with $$c_{2k}=(-1)^kC_k \mbox{ and } c_{2k+1}=0.$$ The continued fraction expansions of $\mathcal{L}_1$ and $\mathcal{L}_2$ satisfy $$\mathcal{L}_1=[0;\overline{X}]\quad \mbox{ and } \quad \mathcal{L}_1=[0;{s_1 X},s_2X,s_3X,\ldots]$$ with $(s_i)_{i\geq 1}$ in $\{1,-1\}$ is a paperfolding sequence often denoted by $\mathcal{F}(1,-1,-1,-1,\ldots)$ (cf. e.g. \cite{Alletal} for this notation), that defines $(s_i)_{i\geq 1}=\lim_{i\to\infty}w_i$ via the recursion $w_1=s_1=(1)$, $w_{i+1}=w_i\cdot(-1)\cdot(-{w_i}^R)$ for $i\geq 1$. Here $\cdot$ denotes the concatenation of the finite sequences, $w^R$ denotes the finite sequence $w$ in reflected order, and the $-$ in front of a finite sequence changes the signs of the elements of the sequence.",2502.01343
lemma,We have $M_1^T\diag\big(((-1)^{t_i})_{i\geq 0}\big) M_1=M_2$ where $t_i:=s_2(i)\pmod{2}$ is the $i$-th element of the Thue--Morse sequence $(t_i)_{i\geq 0}$.,2502.01343
theorem,%move to appendix with proof      (informal) The homology groups $H_i(\Phi(\mathcal{M}))$ can be fully determined by knowing the rank and the overlap decompositions.,2502.01360
theorem,"Given a neural network $\Phi$ with a polyhedral decomposition $\mathcal{G}^l_J$ such that $\mathcal{M} \cap G^l_J$ is convex for any $G^l_J \in \mathcal{G}^l_J$, the homology groups $H_k(\Phi(\mathcal{M})) \simeq H_k(\mathcal{M}, \mathcal{O}_\Phi)$.",2502.01360
theorem,"A ReLU neural network $\Phi: \mathcal{M} \to \text{Im}(\Phi)$, with $\mathcal{M}$ being a compact manifold, is not a homeomorphism iff $\Phi$ is not injective.",2502.01360
theorem,"Denote the set of equivalence classes generated by $\Phi$ as $\sim_\Phi = \{[x] | \Phi(x)=\Phi(y)\}$. This set is equal to the union of $\mathcal{R}_\Phi = \{[x] | \text{rank}(\Phi|_x) < \dim(\mathcal{M}), y \in G_J, \Phi(x)=\Phi(y)\}$ and $\mathcal{O}_\Phi$ (defined in \ref{Overlap definition}).",2502.01360
theorem,$\Phi(\mathcal{M})$ is homeomorphic to $q(\mathcal{M})$. Where $q:\mathcal{M} \to \mathcal{M}/\sim_\Phi$ is the canonical quotient map.,2502.01360
theorem,"If $\mathcal{M}\cap G_J$ is convex (or more generally - contractible) $\forall G_J$, then $H_k(\Phi(\mathcal{M})) \simeq H_k(\mathcal{M},\mathcal{O}_\Phi)$.",2502.01360
definition,"For a codeword $J  \in \{0,1\}^{n_l}$ and a supporting set $R$ of input space under consideration (for example the dataset $\mathcal{D}$), there is an associated codeword set supported on $R$,              L^l_J|_R = \{x | c_l(x)=J, x \in R \subset \mathbb{R}^{n_0}\}.          Then the \textit{local layer decomposition} supported on $R$ is defined by the set going over all possible $J$'s and $\mathcal{L}^l|_R = \{L^l_J|_R\}$.",2502.01360
definition,"For a codeword $J \in \{0,1\}^{\sum\limits_{k=1}\limits^{l} n_k}$  and a supporting set $R$ of input space under consideration, there is an associated codeword set supported on $R$,              G^l_J|_R = \{x | C_l(x)=J, x \in R \subset \mathbb{R}^{n_0}\}.          Then the \textit{polyhedral decomposition} supported on $R$ is defined by the set going over all possible $J$'s and $\mathcal{G}^l|_R = \{G^l_J|_R\}$.",2502.01360
definition,"A neural network $\Phi^l$ has an the equivalence class which describes all  non-injective regions of a network,              \sim_{\Phi^l} = \{[x] | \Phi^l(x)=\Phi^l(y)\}.          The \textit{overlap decomposition} describes the part of the equivalence class coming from the intersection source and is given by,                   & \mathcal{O}_{\Phi^l} = \{[x] | \Phi(y) \in \bigcap\limits_{i \in I} \Phi(G^l_{J_i}) \text{ for }\\         &   I \subset \{1,2,...,\text{\# polyhedra}\} \text{ and } \Phi(y) \not\in \bigcap\limits_{i \in K} \Phi(G^l_{J_i})  \\          & \text{ for any }  I \subsetneq K, \Phi(x)=\Phi(y), |I|>1 \}.",2502.01360
definition,"A half-space is the set given by a linear equation,              H_- = \{x | a^Tx \leq b\}.          In the H-representation, a polyhedron is described as the intersection of finitely many half-spaces. Then, a system of linear equations specified by a matrix $A$ and a vector $b$ form the H-representation of a polyhedron,              P = \{x | Ax \leq b\}.",2502.01360
definition,A relation $\sim$ is an equivalence relation if and only if obeys the following properties.              \item $x \sim x$ (reflexivity).         \item $x \sim y \Leftrightarrow y\sim x$ (symmetry).         \item If $x \sim y$ and $y \sim z$ then $x \sim z$ (reflexivity).,2502.01360
proof,"It is useful to remind the reader of the properties necessary for a map to be a homeomorphism.               \item $\Phi$ is bijective,         \item $\Phi$ is continuous,         \item There is an inverse continuous function $\Phi^{-1}$.           From this we can see that since if $\Phi$ is not injective it is therefore not bijective, this is enough to prove one direction of the statement. Now we have to show that if $\Phi$ is not a homeomorphism then it is not injective. We will do that by showing that all other properties for a homeomorphism are guaranteed by the nature of the maps that neural networks can implement. For this we use \textbf{Theorem 2.1} in Arora et al. 2016., which states that every ReLU deep neural network represents a continuous piecewise linear function.      Since such neural networks are continuous piecewise linear functions, the continuity of $\Phi$ follows. We have seen that surjectivity trivially follows from the way we define the codomain, so the only thing left to show is that $\Phi^{-1}$ is also continuous.      It turns out that such a function need not be continuous, but that occurs solely when $\Phi$ is not injective. Let us assume that $\Phi$ is injective, then it is a continuous bijection (surjectivity applies everywhere). Since $\mathcal{M}$ is compact we can use \textbf{Theorem 26.6} from \cite{munkres200} to see that this implies that $\Phi^{-1}$ is continuous (the theorem in Munkres also requires that $\text{Im}(\Phi)$ is Hausdorff but this property follows from the fact that $\mathcal{M}$ is a compact manifold and $\Phi$ is continuous). This proves that injectivity implies that we have a homeomorphism and thus all topological changes occur as a result of the network failing to be injective.",2502.01360
proof,"Any equivalence class $[x]$ in $\sim_\Phi$ contains a set of points in $\mathcal{M}$. The input manifold has a polyhedral decomposition and can be written as $\mathcal{M} = \bigcup\limits_J G_J$, what this means is that the set of points contained in $[x]$ live in either one or several regions $G_J$. Thus, depending on how many polyhedra are occupied by the points in $[x]$, we can consider two cases.               \item \textbf{Case 1:} The points in $[x]$ all fall in the same region $G_J$. We know that within the same region the network applies an affine transformation and whenever such a transformation is full rank, the map is locally a homeomorphism. Therefore, for a map to be non-injective within a single region, it has to fail to be full rank. This is the exact set described by the rank decomposition $\mathcal{R}_\Phi$.         \item \textbf{Case 2:} The points in $[x]$ fall in several different regions $G_J$. In this case we know that since for any two points in $[x]$, coming from different regions $G_J$, we have $\Phi(x)=\Phi(y)$ then $\Phi(y) \in \bigcap\limits_{i \in I} \Phi(G_{J_i})$ for any $y \in [x]$. This set exactly coincides with the overlap decomposition $\mathcal{O}_\Phi$.          Since these are the only two possibilities for where the points in any $[x]$ can come from, we have shown that $\sim_\Phi = \mathcal{R}_\Phi \cup \mathcal{O}_\Phi$. It is also worthwhile to note that the intersection $\mathcal{R}_\Phi \cap \mathcal{O}_\Phi$ is not necessarily trivial.",2502.01360
proof,"We essentially have the following diagram:                        \mathcal{M} \arrow[r, ""\Phi""] \arrow[d, ""q""']         & \text{Im}\Phi  \\         \mathcal{M}/\sim_\Phi \arrow[ru, ""\pi""]\\               If we can find some $\pi$ that is a homeomorphism, then we can write $\Phi = \pi \circ q$ and the proof would be complete. We can construct such a map in the following way,               \pi([x]) =                       \Phi(x) \text{ if } |[x]|=1, \\             \Phi(y) \text{ for some } y \in [x].                   This function is injective, since $\pi([x])=\pi([z])$ implies $\Phi(x)=\Phi(z)$ and therefore $[x]=[z]$. It is also surjective as for any $z \in \text{Im}\Phi$, there is an $x \in \mathcal{M}$ such that $\Phi(x) = z$ and $\pi([x]) = z$. The continuity of $\pi$ simply follows from the fact that $\Phi$ is continuous. Finally, the continuity of the inverse $\pi^{-1}$ again follows from \textbf{Theorem 26.6} in Munkres \cite{munkres200} as the quotient space of a compact space is compact,     and the precise choice of $y$ is irrelevant.",2502.01360
proof,This follows simply from the fact that homeomorphic spaces have identical homology groups.,2502.01360
proof,"In the corrolary of the previous theorem we have already shown that $H_k(\Phi(\mathcal{M})) \simeq H_k(\mathcal{M},\sim_\Phi)$. We also know that $\sim_\Phi = \mathcal{R}_\Phi \cup \mathcal{O}_\Phi$, therefore our proof will be complete if we can show that quotiening out the part of the rank decomposition that does not intersect the overlap decomposition leaves the homology groups invariant.      Since we know that homology groups are invariant under homotopy equivalence, we require that $\mathcal{M}/(\mathcal{R}_\Phi \cup \mathcal{O}_\Phi)$ is homotopy equivalent to $\mathcal{M}/(\mathcal{O}_\Phi)$. This is represented by the diagram:                       \mathcal{M} \arrow[r, ""p""] \arrow[d, ""q""']         & \mathcal{M}/\mathcal{O}_\Phi \arrow[ld,shift left = 1, ""\sigma""] \\         \mathcal{M}/\sim_\Phi \arrow[ru, shift left = 1, ""\pi""] \\               The two arrows $p$ and $q$ coming out from $\mathcal{M}$ are canonical quotient maps. To show homotopy equivalence we now prove that $\pi \circ \sigma$ and $\sigma \circ \pi$ are homotopic to $\text{id}_{\mathcal{M}/\mathcal{O}_\Phi}$ and $\text{id}_{\mathcal{M}/\sim_\Phi}$ respectively. The two quotient maps split $\mathcal{M}$ into equivalence classes that we denote as $[x]_p$ and $[x]_q$. Since both $p$ and $q$ take a quotient with respect to $\mathcal{O}_\Phi$ the equivalence classes $[x]_q$ and $[x]_p$ will match on $x \in \mathcal{M} - (\mathcal{R}_\Phi-\mathcal{R}_\Phi\cap\mathcal{O}_\Phi)$. Therefore on this set $\pi$ and $\sigma$ map identical equivalence classes to each other. The interesting part of the proof is dealing with the remaining set that is generated purely by the rank decomposition.      We can define the map $\sigma: \mathcal{M}/\mathcal{O}_\Phi \to \mathcal{M}/\sim_\Phi$ as another quotient canonical map such that $q = \sigma \circ p$, that collapses the points that were missed by $p$ or,                   \sigma([x]_p) =                       q(x) \text{ if } x \in \mathcal{M} - (\mathcal{R}_\Phi - \mathcal{R}_\Phi \cap \mathcal{O}_\Phi), \\             q \circ p^{-1}([x]_p) \text{ if } x \in \mathcal{R}_\Phi - \mathcal{R}_\Phi \cap \mathcal{O}_\Phi.                        Where we note that since $p$ is injective on points that are purely in $\mathcal{R}_\Phi$, it is invertible on this subdomain. The map $\pi: \mathcal{M}/\sim_\Phi \to \mathcal{M}/\mathcal{O}_\Phi$ is tricker, but we define it piecewise as,           \pi([x]_q) =                       p(x) \text{ if } x \in \mathcal{M} - (\mathcal{R}_\Phi-\mathcal{R}_\Phi\cap\mathcal{O}_\Phi), \\             [z]_p \text{ such that } \sigma([z]_p) = [x]_q \text{ for some } z \in \mathcal{R}_\Phi - \mathcal{R}_\Phi\cap\mathcal{O}_\Phi).                    For the second condition we need to choose some representative $[z]_p$, since there are many $\sigma([z]_p) = [x]_q$, this particular choice does not really matter as in the end $\sigma \circ \pi ([x]_q) = \sigma([z]_p) = [x]_q$ and $\pi \circ \sigma([x]_p) = \pi([x]_q) =  [z]_p$. The first composition of maps is clearly homotopic to the identity, for the second we construct the homotopy.      For the points in $\mathcal{M}$ representative of an equivalence class $[x]_q \in \mathcal{R}_\Phi- \mathcal{R}_\Phi\cap\mathcal{O}_\Phi$ we can define a strong deformation retraction as $F:\mathcal{M}/\mathcal{O}_\Phi\times [0,1] \to \mathcal{M}/\mathcal{O}_\Phi$, where we have $F(x,0) = \text{id}_{\mathcal{M}/\mathcal{O}_\Phi}([x]_p)$ and $F(x,1) = \pi \circ \sigma ([x]_p)$.               F([x]_p,t) =                       [x]_p \text{ if } x\notin \mathcal{R}_\Phi- \mathcal{R}_\Phi\cap\mathcal{O}_\Phi),\\             \gamma_z(t) \text{ if } x \in \mathcal{R}_\Phi- \mathcal{R}_\Phi\cap\mathcal{O}_\Phi).                    Where $\gamma_z(t)$ is a continuous path (which exists due to the equivalence classes being convex and therefore contractible) from any point $[x]_p \in p\circ q^{-1}([x]_q)$ to the representative $[z]_p$ point. This map starts at $\gamma_z(0)([x]_p) = [x]_p$ and ends at $\gamma_z(1)([x]_p) = [z]_p$ while following a continuous path. This proves that there is a homotopy equivalence between $\mathcal{M}/\sim_\Phi$ and $\mathcal{M}/\mathcal{O}$. Since homology groups are invariant under homotopy equivalence we get our final result,              H_k(\mathcal{M},\sim_\Phi) \simeq H_k(\mathcal{M},\mathcal{O}_\Phi).",2502.01360
proof,"We can prove this by a simple counterexample. Consider the interval $[-1,1]$, let's say that there is a piecewise-function,              f(x) =                       x+1 \text{ if } x<0\\             -x+1 \text{ if } x > 0.                   Since this is a piecewise-linear function we know that there is an associated neural network $\Phi: \mathbb{R} \to \mathbb{R}$ with a single output neuron that implements it. We also know that the local decomposition is $\mathcal{L} = L_{\{1\}} = [-1,1]$. Clearly the two affine functions are not equal to each other.",2502.01360
proposition,"Given a region $L^l_J$ of the local decomposition $\mathcal{L}^l$, there can be two points $x,y \in L^i_J$ for which the maps $\Phi^l|x \neq \Phi^l|y$.",2502.01360
proof,"Since $f_s$ is acting on each $E_i$ by multiplication by a complex scalar, any $g\in C(f)$ is of the form $g=\sum_{i=1}^m g_i\pi_i,$ where $g_i$ is some endomorphism of $E_i$. Therefore, the centre of the centralizer consists of endomorphisms of the form $g=\sum_{i=1}^n a_i\pi_i,$ where $a_i\in \C.$",2502.01395
proof,"For the first inclusion, since $f_s$ commutes with $f$, if $[s,g] = 0$ for all $g \in C(f_s)$, then in particular $[s,f] = 0$. The second inclusion holds because $f_n$ can be expressed as a polynomial in $f$ (see, e.g., \cite[section 4.2]{Hu}).",2502.01395
proof,"To prove (1), take the Schur decomposition $\pi = \pi_a + \pi_u$ with respect to the ordering that puts the 1-eigenspace first and the 0-eigenspace second. Then $\pi_a$ is exactly $\pi'$, so $\pi - \pi' = \pi_u$.           To prove (2), we first calculate     \[     |\pi - \pi^*|_h^2 = \tr((\pi - \pi^*)(\pi - \pi^*)^*) = 2\tr(\pi\pi^*) - \tr(\pi^2) - \tr((\pi^*)^2) = 2 |\pi|^2_h - 2\tr(\pi).     \]    On the other hand, since diagonal matrices are $h$-orthogonal to upper triangular matrices, we have     \[     |\pi|^2_h = |\pi_a|_h^2 + |\pi_u|_h^2.     \]     Together with $|\pi_a|^2_h = \tr(\pi_a) = \tr(\pi)$, this implies (2).",2502.01395
proof,"For any $v_i\in V_i$ and $v_j\in V_j,$ since $\pi_iv_i=v_i$ and $\pi_i v_j =0,$ $$h(v_i,v_j)  = h(\pi_i v_i,v_j) - h(v_i, \pi_i v_j)=h((\pi_i-\pi_i^*)v_i,v_j)\leq \sqrt{2}\epsilon |v_i|_h |v_j|_j.$$      For the converse, we give a more informal justification. For each $V_i,$ we choose an $h$-orthonormal basis. Assembling these bases into a basis of $V,$ the matrix $H$ representing $h$ has identity block matrices corresponding to each $V_i,$ and (5) implies that the norms of the entries outside the blocks are bounded above by $\epsilon.$ The matrix $\Pi_i$ of $\pi_i$ is the identity on a block corresponding to $V_i,$ and zero elsewhere, and it is easily computed that $\Pi_i^*=H^{-1}\Pi_i H$ is $\epsilon$-close to $\Pi_i.$",2502.01395
proof,"Using the Cauchy-Schwarz inequality and Lemma \ref{lem:almostorthogonal1} (2), we have \[     |s^* - s^\dagger|_h^2 = |\sum_i \overline{s}_i(\pi_i^* - \pi_i)|^2_h \leq n\sum_i |s_i|^2|\pi_i^* - \pi_i|^2_h \leq 2n\epsilon^2 \sum_i |s_i|^2 \tr(\pi_i) = 2n\epsilon^2 |s_a|^2. \] For the second inequality, we observe that since the $\pi_i$ commute, there is a simultaneous Schur basis for all of them, such that if $s = \sum_i s_i \pi_1$ then  \[ s_u = \sum s_i (\pi_i)_u. \] Then one uses the Cauchy-Schwarz and Lemma \ref{lem:almostorthogonal1} (1) as above.",2502.01395
proof,"For any meromorphic vector field $V$, apply the Jordan-Chevalley decomposition over the field $F$ of meromorphic functions on $S$ to the endomorphism $\phi(V)$ to give a decomposition of endomorphisms $\phi(V) = \phi^V_{s} + \phi^V_n$. Since the decomposition is linear over $F$, $\phi^V_{s} = \phi_s(V)$ for a possibly meromorphic 1-form $\phi_s^V$, and similarly for $\phi^V_n$.  If $U$ is a contractible open subset of $S$ disjoint from the critical set, then by than canonicity of the Jordan-Chevalley decomposition, $\phi_s$ restricted to $U$ is the semisimple part of $\phi$ restricted to $U$. On the other hand we can decompose $E = \oplus_{i=1}^m E_i$ into generalized eigenspaces of $\phi$ over $U$, with corresponding eigen-$1$-forms $\alpha_i$ and set $\phi_s^U = \sum \alpha_i \mathrm{Id}_{E_i}$. Since $\phi_s^U$ is clearly part of a Jordan-Chevalley decomposition of $\phi$ over $U$, we must have $\phi_s^U = \phi_s$ restricted to $U$. This proves the last statement of the proposition.",2502.01395
proof,"Fix an ordering of the generalized eigenspaces, and let $f = f_a + ({f_s})_u + f_n$ be the Jordan-Chevalley-Schur decomposition relative to this ordering. By Lemma \ref{lem: star and dagger} and Theorem \ref{GRSdecoupling}, we have $|f_s^* - f_s^\dagger|_h \leq \sqrt{2n}Ce^{-cd}|f_a|_h$. Since $\phi \in S_n(d,A)$, we have $|f_a|_h \leq \sqrt{n}dA$; hence there is a new constant $C = C(n, r, A)$ such that $|f_s^* - f_s^\dagger|_h \leq C e^{-cd}$.  On the other hand, by the definition of $f_s^\dagger$ (section \ref{DCthm}) we have $[f_s, f_s^\dagger] = 0$, and from the commutativity condition of the Jordan-Chevalley decomposition we also have $[f_n, f_s^\dagger] = 0$. Together with the previous bound this gives \[ |[f_s,f_s^*]|_h = |[f_s,f_s^* - f_s^\dagger]|_h \leq Ce^{-cd}|f_s|_h \] and similarly   |[f_n,f_s^*]|_h \leq Ce^{-cd}|f_n|_h.  Next, we show that we have bounds $|f_s|_h \leq C d$ and $|f_n|_h \leq C (d+1)$ for some constant $C$, so that we can absorb them into the exponential decay at the cost of redefining $C$ as before. For the first one, by Lemma \ref{lem: star and dagger}, we have \[ |f_s|_h^2 = |f_a|_h^2 + |(f_s)_u|_h^2 \leq (1 + C^2e^{-2cd})|f_a|_h^2 \leq (1+C^2)(nA^2d^2). \]  The linear-in-$d$ bound on $|f_n|_h$ follows from this together with the linear-in-$d$ bound on $|f|_h$ in Proposition \ref{firstbound} by the triangle inequality (see the remark below).  The third inequality on the first line is immediate as $[f_s, f_n^*]$ is just the adjoint of $[f_n, f_s^*]$. Finally the inequality $|F(h)+[f_n,f_n^{*_h}]|_{h}\leq Ce^{-cd}$ follows by plugging in the Jordan-Chevalley decomposition of $f$ into Hitchin's equation $F(h) + [f, f^*] = 0$ and applying the first three inequalities.",2502.01395
proof,"We begin by applying Lemma \ref{lem: origsim} to the nilpotent part $f_n$ of the Higgs field, with the aim of showing that it is a subsolution of an elliptic equation.           \partial_z \partial_{\overline{z}} \log |f_n|^2 &\geq \frac {|[f_n,f^*]|^2}{|f_n|^2} \\         &= \frac{|[f_n, f_n^*] + [f_n, f_s^*]|^2}{|f_n|^2} \\         &\geq \frac{|[f_n, f_n^*]|^2}{2|f_n|^2} - \frac{|[f_n, f_s^*]|^2}{|f_n|^2}.  By Proposition \ref{SMprop}, the first term is bounded below by $C_0^{-2} |f_n|^2$ for some constant $C_0$ depending only on $n$. For the second term, we apply equation \eqref{fn and fss} in the proof of Proposition \ref{asymdecoupling}. The result is that on $D(r_1)$,  \[ \partial_z \partial_{\overline{z}} \log |f_n|^2 \geq C_0^{-2}|f_n|^2 - C_1^2e^{-2cd}.  \]  Finally we conclude by Proposition \ref{maxprinc} below that $|f_n| \leq \frac{C(1 + C_2e^{-2cd})}{(1-(r/r_1)^2)},$ which is clearly bounded above independently of $d$.",2502.01395
proof,"Let $v(z) = \frac{C_2 + 1}{C_1} \frac{r^2}{r^2 - |z|^2}$. A simple calculation shows that $v$ is a supersolution to \eqref{assumeddifineq}:      r^2\partial_z\partial_{\overline{z}}\log v &= \frac{r^4}{(r^2 - |z|^2)^2} \\     &\leq C_1^2 v^2 - C_2^2.  Since $v$ tends to infinity on the boundary of $D(0,r)$, it is greater than or equal to any subsolution that is bounded on the closed disk, which is exactly what we wanted to show. We remark that although the equation degenerates when $u=0$, the inequality $u \leq v$ holds trivially at these points so the maximum principle argument still works.",2502.01395
proof,"By Proposition \ref{asymdecoupling}, there exists $C=C(n,r,A),c=c(n,r,A)>0$ such that in $D(r)$, $$|F(h)+[\phi_n,\phi_n^{*_h}]|_{h}\leq Ce^{-cR}.$$ Using Theorem B, we have $|\phi_n|_{h}\leq C(n,r,A)$. We thus find that $$|F(h)|_{h,\sigma}\leq C|\phi_n|_{ h}^2 + Ce^{-cR}\leq C.$$",2502.01395
proof,"We first construct a ``radial frame,"" by which we mean a frame obtained by fixing a disk around a point with polar coordinates $(r,\theta)$, and parallel transporting that frame at the center along the rays $\{\theta =\textrm{constant}\}.$ If $\Omega$ is the connection form, then by construction, $\Omega(\partial_r)=0,$ and $\Omega(\partial_\theta)$ is controlled by the curvature (see \cite[section 2.2.1]{DK}).   Following the procedure from the proof of the Koszul-Malgrange theorem, as explained in \cite[section 2.2.1]{DK}, after passing to $D(r)$ one can find a gauge transformation that transforms our radial frame to a holomorphic frame, and in which the norm of $\Omega$ is uniformly controlled in terms of the norm in the previous frame.     Set $H_0$ to be the matrix representing $h_0$. Since $\Omega=H_0^{-1}\partial H_0,$ $H_0$ is determined by its entries at the center and parallel transport using $\Omega$, and hence $H_0$ is uniformly bounded.  The same reasoning applies to $H_0^{-1}.$",2502.01395
proof,"The quantities of the estimate above do not depend on the frame, so we are welcome to work in a holomorphic radial frame. Let $H$ be the matrix of $h$ in this frame, so that $H^{-1}\partial_z H dz$ is the connection form. From the formula $\partial_h u = \partial_z u dz + [H^{-1}\partial_z H dz,u],$      \overline{\partial}\partial_h u = (\partial_{\overline{z}}\partial_z u + [H^{-1}\partial_z H ,\partial_{\overline{z}}u]+[\partial_{\overline{z}}(H^{-1}\partial_z H ),u])d\overline{z}\wedge dz.  Note that $F(h) = \partial_{\overline{z}}(H^{-1}\partial_z H)d\overline{z}\wedge dz,$ and hence by Corollary \ref{localbound} and Proposition \ref{prop:boundinframes}, the coefficients of $\overline{\partial}\partial_h$ are uniformly bounded, depending on $n,r,$ and $A$, but not on $d$.  Thus, in the Euclidean norm we have the interior elliptic estimate  $$|\partial_h u|_{W^{2,p}(D(r))}\leq C(n,r,p,A)(|\overline{\partial}\partial_h u|_{L^p(D(1))}+| u|_{L^p(D(1))})$$ (see \cite[Theorem 9.11]{GT} for the estimate in the case of functions and \cite[Theorem 10.33]{Ni} for treating sections of bundles). Since $H$ and $H^{-1}$ are uniformly bounded, we obtain a comparable estimate when we change Euclidean norms to $h$-norms.",2502.01395
proof,"[Proof of Proposition \ref{dels}] First observe that for any holomorphic section $s$ of $\textrm{End}(E)$, $$\overline{\partial}\partial_h s =[s,[\phi,\phi^{*_h}]].$$ Indeed, $$\overline{\partial}\partial_h s=\overline{\partial}\partial_hs - \partial_h\overline{\partial}s=[F(h),s]= [s,[\phi,\phi^{*_h}]],$$ where in the last equality we used the Hitchin equation.      Now, for notational convenience, set $s=\pi_i$. We first show that there exists $C=C(n,r_1,A)$ and $c=c(n,r_1,A)$ such that on $D(r),$               |\overline{\partial}\partial_h s|_h\leq Ce^{-cd}.       Since $[s,\phi]=0,$ the Jacobi identity yields that $$\overline{\partial}\partial_h s= [s,[\phi,\phi^{*_h}]]=[\phi,[s,\phi^{*_h}]].$$ Taking norms and applying Proposition \ref{firstbound}, we have $$|\overline{\partial}\partial_h s|_{h}\leq \sqrt{2}|\phi|_{h}|[s,\phi^{*_h}]|_{h}\leq Cd|[s,\phi^{*_h}]|_h.$$      Note that $s=s^\dagger$ and $$|[s^\dagger,\phi^{*_h}]|_h= |[s^\dagger-s^{*_h},\phi^{*_h}]|_h\leq 2|\phi|_h|s^\dagger-s^{*_h}|_h.$$ By Proposition \ref{firstbound} and Theorem \ref{GRSdecoupling} combined with Lemma \ref{lem: almost orthogonal}, we deduce $$|[s,\phi^{*_h}]|_h=|[s^\dagger,\phi^{*_h}]|_h\leq AdCe^{-cd}|s|_h.$$  From part (1) of Lemma \ref{lem:almostorthogonal1}, $|s|_h$ is uniformly bounded, and the claim follows after enlarging the constants $C$ and $c$ in order to absorb $Ad$.  To deduce the proposition, by holomorphicity of $s$, $\partial_h s^{*_h}=0$, and hence (\ref{eq: deldelbars}) yields $$|\overline{\partial}\partial_h (s-s^{*_h})|\leq Ce^{-cd}.$$ By Lemma \ref{lem: schauder estimate}, and because $L^p$ norms on a disk are controlled by $L^\infty$ norms, for all $1<p<\infty$ we have $C=C(n,r,p,A)>0$ such that $$|s-s^{*_h}|_{h,W^{2,p}(D(r))}\leq C(|\overline{\partial}\partial_h (s-s^{*_h})|_{h}+|s-s^{*_h}|_{h})=C(|\overline{\partial}\partial_h (s-s^{*_h})|_{h}+|s-s^{*_h}|_{h}),$$ where the $C^0$-norms above are taken over $D(r_1).$ Hence, by Theorem \ref{GRSdecoupling} again and the estimate above, $$|s-s^{*_h}|_{h,W^{2,p}(D(r))}\leq Ce^{-cd}.$$ Via Morrey's theorem, for all $\alpha\in (0,1)$ we can find $C=C(n,r,\alpha,A)>0$ such that $$|s-s^{*_h}|_{h,C^{1,\alpha}(D(r))}\leq C|s-s^{*_h}|_{h,W^{2,p}(D(r))}\leq Ce^{-cd},$$ from which we obtain $$|\partial_h s|_{h,C^{0,\alpha}(D(r))}=|\partial_h (s-s^{*_h})|_{h,C^{0,\alpha}(D(r))}\leq Ce^{-cd},$$ as desired.",2502.01395
proof,"As in the proof of Proposition 2.11 in \cite{Mo}, this is an algebraic consequence of the $C^1$ bound in Proposition \ref{dels}. Since $\overline{\partial} \pi_i = 0$, Proposition \ref{dels} shows that $|\nabla_h \pi_i| \leq C e^{-cd}$. Now let $\pi_i'$ be the $h$-orthogonal projection to $E_i$. With respect to the splitting $E = E_i \oplus E_i^\perp$ we have \[ \nabla_h \pi'_i =      0 & B_i \\     B_i^{*_h} & 0 \\ , \] where $B_i$ is the second fundamental form of $E_i$. On the other hand, if $s_i \in E_i$, then $(\nabla_h \pi_i)s_i$ and $(\nabla_h \pi_i')s_i$ are congruent modulo $E_i$, so the upper right part of $\nabla_h \pi_i$ is also equal to $B_i$. Therefore  \[ \frac{1}{2}|\nabla_h \pi'_i|^2_h =  |B_i|^2_h \leq  |\nabla_h \pi_i|^2_h \leq Ce^{-cd}. \] This shows that $E_i$ is almost parallel.",2502.01395
proof,"[Proof of Corollary C]     Decomposing $D_h$ as $$D_h = \nabla_h + \phi_s+\phi_s^{*_h}+\phi_n+\phi_n^{*_h},$$ we see that proving (\ref{asymptotic2}) amounts to showing that on $D(r),$ $$ |\phi_s+\phi_s^{*_h}-\sum_{i=1}^m (\phi_i\pi_i+\overline{\phi}_i\pi_i) |_{h}, |\phi_n^{*_h}-\phi_n^{*_{h^{\oplus}}}|_h, \textrm{ and } |\partial_h - \sum_{i=1}^m \partial_i|_h$$ are all bounded above by $Ce^{-cd}.$ For the first item, note that $\phi_s^\dagger=\Big (\sum_{i=1}^m \phi_i\pi_i\Big )^\dagger= \sum_{i=1}^m \overline{\phi_i}\pi_i,$ so by Lemma \ref{lem: star and dagger} and Theorem \ref{GRSdecoupling}, on $D(r)$ and for constants $C,c$, $$\Big |\phi_s+\phi_s^{*_h}-\sum_{i=1}^m (\phi_i\pi_i+\overline{\phi}_i\pi_i)\Big |_{h}\leq Ce^{-cd}.$$   For the $\phi_n$ term, recall that if $H$ is the matrix-valued function determined by $h,$ then $\phi_n^{*_h}=H^{-1}\overline{\phi}_n^\vee H, $ where the $\vee$ is the transpose operator, and likewise for $h^{\oplus}$. Since the splitting $E=\oplus_{i=1}^m E_i$ is $h^\oplus$-orthogonal, using this expression, the inequality $|\phi_n^{*_h}-\phi_n^{*_{h^{\oplus}}}|_h\leq Ce^{-cd}$ follows from Theorem \ref{GRSdecoupling} and Theorem B.  Proving $|\partial_h - \sum_{i=1}^m \partial_i|_h\leq Ce^{-cd}$ amounts to finding the right estimate on the action of $\partial_h-\partial_i$ on sections of $E_i$. For any section $s$ of $E_i$, by the Leibniz rule, $$(\partial_h-\partial_i) s  = \pi_i'\circ \pi_i \circ \partial_h s - \pi_i'\partial_h(\pi_i s)=\pi_i'\circ \partial_h\pi_i(s).$$ Therefore, by Proposition \ref{dels}, $$|\partial_h s - \partial_i s|_{h}= |\pi_i'\circ \partial_h\pi_i(s)|_{h}\leq |\partial_h\pi_i(s)|_{h}\leq Ce^{-cd}|s|_h.$$ The result follows.",2502.01395
proof,"By Corollary \ref{localbound}, $F(h)$ is uniformly bounded depending only on $n,r,$ and $A$. By Corollary \ref{cor: curvature of sub-bundles}, the same bound holds for $F(h|_{E_i}),$ with a slight change in the constant. We then apply Proposition \ref{prop:boundinframes}.",2502.01395
proof,"Since we have uniform bounds for the connection form $H^{-1}\partial H$, the curvature $\overline{\partial}(H^{-1}\partial H)$, and $H$ itself, and $H$ is real, all entries of $\partial_z H$, $\partial_{\overline{z}}H$, and $\partial_{\overline{z}}\partial_z H$ are uniformly bounded.  We now assume $i\neq j$. Since $H$ is real, the norms of $\partial_z H$ and $\partial_{\overline{z}} H$ agree, so we only need to find a bound on $\partial_z H$. Let $u_i$ be any element of the holomorphic radial frame for $E_i$, and $u_j$ in the frame for $E_j$. Our assumption on the frame implies that $u_i$ and $\partial_h u_i$ are uniformly bounded in $h$-norm, and likewise for $u_j$.   By holomorphicity, $$\partial_z h(u_i,u_j)=h((\partial_h \pi_i)u_i,u_j) + h(\pi_i (\partial_h u_i), u_j),$$ and hence by Theorem \ref{GRSdecoupling} and Proposition \ref{dels},     $$|h((\partial_h \pi_i)u_i,u_j)|\leq |\partial_h \pi_i|_h |u_i|_h|u_j|_h\leq Ce^{-cd}.$$ The proof of Corollary C shows that $|\partial_h u_i - \partial_i u_i|\leq Ce^{-cd}|u_i|_h.$ Hence, for the second term, by Theorem \ref{GRSdecoupling} again, $$|h(\pi_i (\partial_h u_i), u_j)|\leq |h(\partial_i u_i, u_j)|+Ce^{-cd}\leq Ce^{-cd}|\partial_i u_i|_h |u_j|_h +Ce^{-cd} \leq Ce^{-cd}.$$ This establishes the first result. For the second order term, Proposition \ref{asymdecoupling} implies $$F(h)=[\phi_n,\phi_n^{*_h}] +a,$$ where $a$ is an endomorphism whose $h$-norm is exponentially small. Observe that $[\phi_n,\phi_n^{*_{h_\infty}}]$ is a sum of endomorphisms of the $E_i$'s. We previously showed that the norm of $\phi_n^{*_h}$ differs from that of $\phi_n^{*_{h_\infty}}$ by an exponential error, and it follows that the $\textrm{Hom}(E_i,E_j)$ components of the matrix representing $[\phi_n,\phi_n^{*_h}]$ have the same exponential decay.",2502.01395
proof,"We'll repeatedly use the basic fact that the product of two nearly block matrices is nearly block. As well, we use throughout that the Cauchy estimates give linear bounds on the derivatives of $\Phi$ in terms of $d$.     The known estimate on $\partial_{\overline{z}}\partial_z H_{ij}^{\alpha\beta}$, applied in the disk $D(r_1)$, where we remind that $r_1=\frac{1+r}{2}$, together with elliptic regularity, give the desired bounds for the cases $(\ell_1,\ell_2)=(2,0)$ or $(0,2)$ on $D(r)$. We'll now bootstrap on the Hitchin equation, which is written in our frame as      H^{-1}\partial_{\overline{z}}\partial_z H - H^{-1}\partial_{\overline{z}}H\cdot H^{-1}\partial_z H-[\Phi,H^{-1}\overline{\Phi}^\vee H]=0.   We first consider $\ell_1,\ell_2>0,$ and go by induction on $k=\ell_1+\ell_2,$ with the result of Lemma \ref{localhobounds} on $\partial_z\partial_{\overline{z}}H$ being the base case. Assume the result holds for $k-1$ (including $\ell_1=0$ or $\ell_2=0$). Since $r<1$ is arbitrary, we can assume that we have the bounds for the case $k-1$ in $D(r_1)$ rather than $D(r)$. Applying $\partial_z^{\ell_1-1}\partial_{\overline{z}}^{\ell_2-1}$ to the equation (\ref{equation for H}), we get $$H^{-1}\partial_z^{\ell_1}\partial_{\overline{z}}^{\ell_2}H -[\partial_z^{\ell_1-1}\Phi,H^{-1}\overline{\partial_{z}^{\ell_2-1}\Phi^\vee}H]+G=0,$$ where $G$ is a linear combination of matrices that are products of derivatives of $H$, $\Phi$, $\overline{\Phi^\vee}$, and derivatives of $\Phi$ and $\overline{\Phi^\vee}$. By the induction hypothesis and using the $(2,0)$ and $(0,2)$ cases, $G$ is uniformly bounded by $C$ and the $\textrm{Hom}(E_i,E_j)$ components of $G$ are bounded above by $Ce^{-cd}$, with $C$ and $c$ depending on $n,r,\ell_1,$ $\ell_2$, and $A$. The same is true for the commutator term, by the previous reasoning from the proof of Lemma \ref{localhobounds} and the Cauchy bound.  Thus, $\partial_z^{\ell_1}\partial_{\overline{z}}^{\ell_2}H$ is $H$ times a matrix that's bounded and has the correct decay in the $\textrm{Hom}(E_i,E_j)$ components. By our choice of frames, multiplying by $H$ preserves this structure, and so we've completed the induction step.            For the cases $\ell_1=0$ or $\ell_2=0,$ i.e., $\partial_{\overline{z}}^{\ell_2}$ or $\partial_z^{\ell_1},$ again we differentiate the equation (\ref{equation for H}) and go by induction on $\ell_2$ and $\ell_1$ separately. For $(0,\ell_2)$, we apply $\partial_{\overline{z}}^{\ell_2-1}$ and get      $$H^{-1}\partial_{\overline{z}}^{\ell_2}H\cdot H^{-1}\partial_z H = G,$$ where, by our previous results, $G$ is bounded and the $\textrm{Hom}(E_i,E_j)$ components are small, in the same way as above. Rearranging gives the result for $\partial_{\overline{z}}^{\ell_2}H$. The same argument applies for $(\ell_1,0).$",2502.01395
proof,"For each point $p \in S - B$, choose a local coordinate at $p$ such that $D(1)$ is compactly contained in $S-B$, and let $d$ and $A$ be such that $\phi \in S_n(d,A)$ on $D(1)$. Let $U = \sqcup_\alpha U_\alpha$ be a locally finite covering of $S-B$ by open sets $U_\alpha \cong D(1/2)$ in these coordinates. From Corollary \ref{localbound}, we see that the curvature $F(h_R)$ of the Chern connection $\nabla_R$ is locally bounded on $S$ independently of $R$. Let $\hat{h}_R$ be the metric on $\hat{E}$ induced from $h_R$ by restriction to each generalized eigenspace. From Corollary \ref{cor: curvature of sub-bundles} it follows that the curvature of the Chern connection of $\hat{h}_R$ is also locally bounded on $S$. Let $p\mapsto C(p)$ be a continuous function on $S$ dominating this curvature.   Since $U_\alpha$ is contractible, each $\hat{U}_\alpha$ is a union of copies of $U_\alpha$. By Proposition \ref{prop:E_iframe}, we can choose a frame $\hat{\tau}_R$ of $\hat{E}$ over each $\hat{U}_\alpha$ such that if $\hat{H}_R := \hat{\tau}_R^*\hat{h}_R$ is the hermitian metric in this frame, then $\hat{H}_R$ is the identity matrix at each $\hat{p}_\alpha$ and the connection matrix $\hat{H}_R^{-1} \partial \hat{H}_R$ is bounded in terms of $C(p)$. By integration, we get control on $\hat{H}_R$ on all of $\hat{U}_\alpha$. Let $H_R = \tau^* h_R$ be the entire metric in this frame (so that $\hat{H}_R$ is just the block-diagonal entries of $H_R$). Then by asymptotic orthogonality, Theorem \ref{GRSdecoupling}, and the bound on $\hat{H}_R$, we see that $H_R$ is also controlled at $p_\alpha$ by $C(p)$. It furthermore follows from Proposition \ref{holocalbounds} that each derivative of the matrix $H_R$ is also bounded in terms of $C(p)$. Hence by the Arzel{\`a}-Ascoli theorem, there is a smoothly convergent subsequence of the $H_R$, converging to a metric $H_\infty$. Using again the asymptotic orthogonality theorem as $R$ tends to infinity, it follows that $H_\infty$ is block-diagonal, i.e., that it is the pushforward of a metric $\hat{H}_\infty$ on each $\hat{U}_\alpha$.  We next show that upon passing to a further subsequence we can arrange that $R\Phi_n := \tau_R^*R\phi_n$, the pullback of the nilpotent part of the rescaled Higgs field, also locally converges. By the corollary to Theorem B, the norm $|R\phi_n|_{h_R}$ is bounded in terms of $C(p)$. Since $|R\phi_n|_{h_R} = |R\Phi_n|_{H_R}$ and $H_R$ are controlled, the Euclidean norm $|R\Phi_n|$ is also controlled by $C(p)$. Since both $\tau_R$ and $R\Phi_n$ are moreover holomorphic, $R\Phi_n$ form a normal family, so there is a locally convergent subsequence, with limit $\Psi_\infty$.  Now let $\pi_1$ and $\pi_2$ be the two projections from $\hat{U} \times_{\hat{S}} \hat{U}$ to $\hat{U}$, and let $(\hat{\tau}_R)_j = \pi_j^* \hat{\tau}_R$, $j=1,2$. Set $\hat{g}_R = (\hat{\tau}_R)_1^{-1} \circ (\hat{\tau}_R)_2$. We may view $\hat{g}_R$ as a matrix-valued function on $\hat{U} \times_{\hat{S}} \hat{U}$. Since the trivializations $\hat{\tau}_R$ are holomorphic, so are the $\hat{g}_R$. Since the matrices $H_R$ are locally bounded, the $\hat{g}_R$ land in a compact subset of $GL({n_i}, \C)$ and therefore form a normal family. Hence, we can extract a sub-sequential $C^{\infty}_{\mathrm{loc}}$ limit $\hat{g}_\infty$.",2502.01395
proof,"[Proof of Theorem A] Following the strategy outlined at the beginning of this section, our aim is to construct a sequence of smooth bundle isomorphisms $\hat{\sigma}_R: \hat{E}_{\infty} \to \hat{E}$ such that the triple $(\hat{\sigma}_R^* \dbar_E, \hat{\sigma}_R^*(R\phi_n), \hat{\sigma}_R^*h_R)$ converges smoothly locally on $E_\infty$ to $(\dbar_\infty, \psi_\infty, h_\infty)$. Since $E$ and $E_\infty$ are both presented in terms of their trivializations on $U$, a bundle isomorphism between them is equivalently a refinement $U'$ of the covering $U$, and smooth matrix-valued functions $\hat{\sigma}_R$ on $U'$ such that $\hat{g}_\infty = (\hat{\sigma}_R)_1^{-1}\hat{g}_R (\hat{\sigma}_R)_2$ on $\hat{U}' \times_{\hat{S}} \hat{U}'$. As long as $\hat{\sigma}_R$ converges locally smoothly to the identity as $R$ tends to infinity, the smooth convergence of $H_R$ and $R\Phi_n$ to $H_\infty$ and $\Psi_\infty$ will imply smooth convergence on $E_\infty$.  Uhlenbeck's patching argument \cite[Proposition 3.2]{Uh1} establishes the existence of such smooth $\hat{\sigma}_R$ when the base manifold and the gauge group are both compact. The proof mirrors the vanishing of $H^1$ for fine sheaves of abelian groups, but in the nonabelian setting.  To apply this argument, we first address the non-compactness of the gauge group. For each $R$, let $\hat{\rho}_R = \sqrt{{\hat{H}_R}^{-1}\hat{H}_\infty}$ as a matrix-valued function on $\hat{U}$. Then $\hat{\rho}_R$ converges smoothly to the identity, and pulls back the metric $\hat{H}_R$ to $\hat{H}_\infty$. The remaining gauge freedom is in the unitary group of $\hat{H}_\infty$, a compact group.  Second, we address the (usual) case where $\hat{S}$ is noncompact. Fix an exhaustion by compact subsurfaces $K_i$ with boundary. On each compact subsurface, Uhlenbeck's argument produces a sequence of gauge transformations $\hat{\sigma}_{i,R}$ satisfying the requirements. Since the complement of $\overline{K}_i$ is an open surface and the gauge group is connected, the bundles $\hat{E}$ and $\hat{E}_\infty$ are both trivializable on the complement of $K_i$. Similarly, $\hat{\sigma}_{R,i}$ can be extended in some way to a smooth bundle isomorphism on all of $\hat{S}$. Of course, since our aim is $C^\infty_{loc}$ convergence, the choice of extension is not important. Then the desired sequence of gauge transformations is of the form $\hat{\sigma}_{R, i(R)}$, for any function $i(R)$ tending to infinity.",2502.01395
proof,"[Proof of Proposition \ref{normcomparison}] We split up   |\phi|_{h_R}^2 =|\phi_{a}|_{h_R,\sigma}^2+|\phi_u|_{h_R,\sigma}^2 = |\eta|_{\sigma}^2+|(\phi_s)_u + \phi_n|_{h_R,\sigma}^2\leq |\eta|_\sigma^2+|(\phi_s)_u|_{h_R,\sigma}^2 + |\phi_n|_{h_R,\sigma}^2.  By Lemma \ref{lem:almostorthogonal1} combined with Theorem \ref{GRSdecoupling}, for $z\in S-B$ we can find $C_1=C_1(G,U,\sigma,\eta),c=c(G,U,\sigma,\eta)>0$ such that $|(\phi_s)_u|_{h_R,\sigma}^2\leq C_1e^{-cR}$ (we did the same bound in the proof of Proposition \ref{asymdecoupling}). By Theorem B, for $z\in S-B$, there exists $C_2=C_2(G,U,\sigma)$ such that $|\phi_n|_{h_R,\sigma}\leq C_2.$ In all of these bounds, the only dependence on $G$ comes from the dimension of the underlying holomorphic vector bundle, which is $\dim \g^{\C}$. Inserting the bounds on $|(\phi_s)_u|_{h_R,\sigma}^2$ and $|\phi_n|_{h_R,\sigma}$ into (\ref{expanded norm}), we obtain Proposition \ref{normcomparison}.",2502.01395
proof,"To prevent the notation from becoming confusing, in this proof we differentiate our notation and use $\nu$ for the metric on the symmetric space, and $\nu_0$ for the associated bilinear form on $\g$ and the bilinear form on $\textrm{End}(E)$ induced from $\nu_0$ and the adjoint representation.  We work in $\textrm{Hom}(\R F_\phi,\textrm{End}_{h_R}(E))$, which inherits a norm $|\cdot|_{\nu_0^*\otimes h_R}$ from $\nu_0$ and $h_R$. Using the identifications above, $\nabla^{f_R^*}$ becomes $\nabla_{h_R}$ and $d^{f_\eta^*}$ becomes the flat connection $d$ on $\R F_\phi$ as defined in section 3. Since $h_R$ restricts to the $\nu_0$ on $\textrm{End}_{h_R}(E)$, $f_R^*\nu$ becomes $h_R$. As well, we highlight that $m$ is defined to be a restriction of $\nu_0$. We deduce that on $S-B$, $$ |\textrm{Re}_R \circ d^{f_\eta^*}-\nabla^{f_R^*}  \circ \textrm{Re}_R|_{m^*\otimes f_R^*\nu,\sigma}=|\textrm{Re}_{h_R}\circ d-\nabla_{h_R}\circ \textrm{Re}_{h_R}|_{\nu^*\otimes h_R,\sigma}.$$     Working with the right hand side of the equation above, since the $\pi_i$'s form an orthonormal basis for $\R F_\phi,$ Proposition \ref{dels} directly implies the claimed estimate.",2502.01395
proof,"[Proof of Theorem E] For the first claim, $f_R^*\nu-R^2f_\eta^*m= |R\phi|_{h_R}^2 - R^2|\eta|^2.$ Applying Proposition \ref{normcomparison} yields the stated comparison of $f_R^*\nu$ and $f_\eta^*m$. For the comparison between pullback connections, we apply Proposition \ref{prop:thmE2ndpart}.",2502.01395
proof,"Let $\{z_k:k\in \mathbb{N}\}\subset U$ be a countable and dense subset. For each $k,$ choose a point $z_k^*$ on $\partial U$ that minimizes the distance from $z_k$ to $\partial U$. Define, for $j\geq 2$, $$\delta_j = \min \{d(z_k,z_m), d(z_k^*,z_m^*):1\leq k < m \leq j\}.$$ For each $k\in \mathbb{N}$, choose a bounded sequence of points $x_{k,n}\in X_n$ such that $u(z_k)=[x_{k,n}]$. Inductively build a sequence of subsets $\mathbb{N}=N_1\supset N_2\supset\dots $ such that for each $j\geq 2$ we have $\omega(N_j)=1$ and for all $1\leq k,m\leq j,$ $$|d_\omega(u(z_k),u(z_m))-d_n(x_{k,n},x_{m,n})|\leq \epsilon B\delta_j$$ and $$|d_\omega(u(z_k^*),u(z_m))-d_n(f_n(z_k^*),x_{m,n})|\leq \epsilon B\delta_j.$$ For every $j\in\mathbb{N}$, define $M_j=N_j\backslash N_{j+1},$ and $M_\infty=\cap_{i\in\mathbb{N}}N_i.$ We define a function $j:\mathbb{N}\to \mathbb{N}$ on $M_\infty$ by $j(n)=n$, and off $M_\infty$ by setting $j(n)$ to be the unique number such that $n\in M_{j(n)}.$ We define $u_n:\{z_1,\dots, z_{j(n)}\}\cup\partial U\to X_n$ by $u_n(z_k)=x_{k,n}$ and $u_n|_{\partial U}=f_n|_{\partial U}$.      We prove that every $u_n$ is $3\max\{A,(1+\epsilon)B\}$-Lipschitz. Firstly, note that for all $1\leq k <m\leq j(n),$ $$d_n(u_n(z_k),u_n(z_m))\leq d_\omega(u(z_k),u(z_m))+\epsilon B \delta_{j(n)}\leq (1+\epsilon)Bd(z_k,z_m),$$ and the analogous inequality holds if we replace $z_m$ with $z_m^*.$ We thus see that $u_n$ is $(1+\epsilon)B$-Lipschitz on $\{z_1,\dots, z_{j(n)}\},$ and $A$-Lipschitz on $\partial U$. We're left to examine the Lipschitz constant we get when one point is a $z_i$ and the other is in $\partial U$. Given $z_i$ and $x\in \partial U$,           d(u_n(z_i),u_n(x))&\leq d(u_n(z_i),u_n(z_i^*))+d(u_n(z_i^*),u_n(x))\leq (1+\epsilon)Bd(z_i,z_i^*) + Ad(z_i^*,x) \\       &\leq \max\{A,(1+\epsilon)B\} (d(z_i,z_i^*) + d(z_i^*,x)).    Observing that $$d(z_i,z_i^*)+d(z_i^*,x)\leq 2d(z_i,z_i^*) + d(z_i,x) \leq 3d(z_i,x),$$ we get the claim.         By the Lipschitz extension property, each $u_n$ extends to a $3\max\{A,(1+\epsilon)B\}$-Lipschitz map from $\overline{U}\to X_n.$ Each $u_n$ takes $z_1$ to $x_{1,n},$ which together with Lipschitzness implies the distance to $p_n$ is controlled, and hence we can form the limit $u_\omega =[u_n].$ We obtain the lemma by setting $\epsilon=1.$",2502.01395
proof,"[Proof of Proposition \ref{prop: hmapsconvergence}]    First note that, by Korevaar-Schoen's construction of the locally $L^1$ metrics associated with Lipschitz maps, we have that for any relatively compact sub-surface $U\subset \tilde{S}$, $$\mathcal{E}_\omega (U, f_\omega)=\lim_\omega \mathcal{E}_n(U,f_n).$$ Above, we use $\mathcal{E}_n$ and $\mathcal{E}_\omega$ for energies taken with respect to the targets $(X_n,d_n)$ and $(X_\omega, d_\omega)$ respectively. Now, for $U\subset \tilde{S}$ relatively compact, let $u:\overline{U}\to (X_\omega,d_\omega)$ be a Lipschitz map that agrees with $f_\omega$ on $\partial U,$ i.e., a competitor for the energy. By Lemma \ref{lem: sequence}, one can represent $u$ by a sequence of Lipschitz maps $u=[u_n],$ where $u_n|_{\partial U}=f_n|_{\partial U}$. To compare the energy of $f_\omega$ to that of $u$, we have that, since each $f_n$ is harmonic, $$\mathcal{E}_n(U,f_n)\leq \mathcal{E}_n(U,u_n).$$ Taking the limit with respect to $\omega$ yields that $$\mathcal{E}_\omega (U, f_\omega)=\lim_\omega \mathcal{E}_n(U,f_n)\leq \lim_\omega \mathcal{E}_n(U,u_n)=\mathcal{E}_\omega(U,u),$$ which establishes that $f_\omega$ is harmonic.",2502.01395
proof,"Let $U$ be any relatively compact conformal disk intersecting $\Omega$. By Proposition \ref{firstbound}, there exists $C_j=C_j(G,U,\sigma)>0,$ $j=1,2,$ such that, on $U$,  $$|R_i\phi|_{h_{R_i},\sigma}^2\leq C_1R_i^2\max_{z\in U}|\eta(z)|_{\sigma}^2 +C_2.$$ Hence, on $U$, $$\textrm{Lip}(f_i)^2\leq \max_{z\in U} e(f_i)(z)=\max_{z\in U} R_i^2|\phi(z)|_{h_{R_i},\sigma}^2\leq C_1R_i^2\max_{z\in U}|\eta(z)|_{\sigma}^2 +C_2.$$ By covering the closure of $\Omega$ with finitely many disks, we obtain a uniform bound on $\textrm{Lip}(f_i)$ over all of $\Omega$.",2502.01395
proof,"[Proof of Corollary E] By the construction of $L^1$ measurable pullback metrics in Korevaar-Schoen's work \cite{KS}, for any point $p\in S$ and any tangent vector $v\in T_pS,$ $$g_{f_\omega}(v,v)=\lim_{\omega}R_i^{-2} f_i^*\nu(v,v).$$     The first part of Theorem E thus implies that $g_{f_{\omega}}=f^*m$. For the $\ft^{\C}//W$-valued $1$-forms, for every $i$ let $h_{R_i}$ be the harmonic metric obtained by taking our harmonic $G$-bundle to an ordinary harmonic bundle via the adjoint representation. Each harmonic metric determines a harmonic map to the symmetric space of $\textrm{SL}(\g).$ Using the same principal ultrafilter $\omega$ and going through Proposition \ref{roughlipbound} again, we obtain a new harmonic map to a building $f_\omega':\tilde{S}\to (\mathcal{B}',d'),$ where $(\mathcal{B}',d')$ is the asymptotic cone of the symmetric space of $\textrm{SL}(\g)$.      Under the adjoint representation, $\ft$ is injectively mapped into a maximal split toral subalgebra $\mathfrak{a}$ of $\mathfrak{sl}(\g)$. The $\ft^{\C}//W$-valued $1$-form of $f_\omega$ is recovered from that of $f_\omega'$, which is a $\mathfrak{a}^{\C}//S_n$-valued $1$-form, by undoing (the complexification of) this mapping.          By Proposition \ref{prop: singular set}, the regular set $S_{reg}$ of $f_\omega'$ is non-empty. Fixing a small contractible disk $U$ in $S_{reg}-B$ and a lift $V$ in $\tilde{S}$, let $x$ and $y$ be points in $U$ with lifts $\tilde{x}$ and $\tilde{y}$ in $\tilde{U}$, and let $\Pi_{R_i}$ be the parallel transport from $x$ to $y$ coming from the flat connection of our harmonic bundle. The vector distance between the harmonic metrics $h_{R_i}(x)$ and $\Pi_{R_i}^*h_R(y)$, rescaled by $R_i^{-1},$ limits precisely as $R_i\to \infty$ to the Weyl-chamber valued distance between points $f_\omega'(\tilde{x})$ and $f_\omega'(\tilde{y})$ in the limiting building.  Thus, from Theorem D, the solution to the WKB problem, if $\phi_1,\dots, \phi_{\textrm{dim}\g}$ are the eigen-$1$-forms (with multiplicity) of the adjoint representation of $\phi,$ then $f_\omega'$ is locally described as, up to translation and reflections, $$f_\omega'(z) = (\int_{z_0}^z\textrm{Re}\phi_1,\dots, \int_{z_0}^z \textrm{Re}\phi_{\textrm{dim}\g} ).$$  Taking $\partial$ in the affine chart then yields the $\mathfrak{a}^{\C}//S_n$-valued $1$-form associated with $f_\omega'|_U.$ Undoing the mapping the $\ft^{\C}\to \mathfrak{a}^{\C},$ we see that the $\ft^{\C}//W$-valued $1$-form of $f_\omega|_U$ is $\eta$. By holomorphicity, the $\ft^{\C}//W$-valued $1$-form agrees with $\eta$ everywhere.",2502.01395
proof,"[Proof of Theorem D] Choose a precompact and contractible open neighbourhood $U\subset S$ that does not intersect the critical set and that contains the image of our non-critical path $\gamma([0,1])$. We equip $U$ with a flat metric, which we use to measure norms. Extract open balls $B_1(r),\dots, B_m(r)$ of small radius $r>0$ such that       \item $\cup_i B_i(r)$ does not intersect the critical set, and      \item $U\subset \cup_i B_i(r/2)$.  Since $\cup_i B_i(r/2)$ has a definite distance from the critical set, we can find positive numbers $A$ and $b$ such that in restriction to each $B_j(r/2)$, $R\phi$ lies in $S(bR,A)$. As we chose $U$ to be contractible, over $U$ we can split $E$ into generalized eigenspaces as $E = \oplus_{i=1}^m E_i$, with eigen-$1$-forms $\phi_i$ and projections $\pi_i$. For each $i$, let $h_R^i$ be the restriction of $h_R$ to $E_i$ and $h_R^{\oplus}=\oplus_{i=1}^m h_R^i$ and let $\nabla_{h_R}^{\oplus}$ be the  Chern connection. Write $*_R^{\oplus}$ for the adjoint operator of $h_R^{\oplus}.$ Corollary C implies that on $U,$ $D_{h_R}$ differs from      \nabla_{h_R}^{\oplus} +\sum_{i=1}^m R(\phi_i+\overline{\phi}_i)\pi_i + R\phi_n+R\phi_n^{*_R^{\oplus}}  by an $\textrm{End}(E|_U)$ valued $1$-form whose $h_R$-norm is on the order of $Ce^{-cR},$ where $C$ and $c$ depend on $n,r$, and the eigen-$1$-forms of $\phi$. Note that Theorem B implies that $|R\phi_n|_{h_R}$ is uniformly controlled, and the proof of Corollary C demonstrates $|R\phi_n^{*_R}|_{h_R}$ differs from $|R\phi_n^{*_{h_R}}|_{h_R}=|R\phi_n|_{h_R}$ by a term that decays like $Ce^{-cR}.$  To compute the operator norms of parallel transport operators, we will work on the pullback vector bundle $\gamma^*E=\oplus_{i=1}^m\gamma^*E_i$ over $[0,1]$ with connections $\gamma^*D_{h_R}$ and $\gamma^*\nabla_{h_R},$ and choose good frames. Specifically, we take $h_i$-orthonormal frames $u_i=(u_{i1},\dots, u_{im_i})$ for $E_i$ that are $\gamma^*\nabla_i$ parallel, which means that $\gamma^*\nabla_i u_{ij}=0$ for all $i,j$. We then pull these back to frames for $\gamma^*E_i$, and combine all of the frames for the $\gamma^*E_i$'s to get a frame for $\gamma^*E$. We then normalize the frame dividing every $u_{ij}$ by $R$. With respect to this frame, $\gamma^*\nabla_R$ has diagonal connection form $$A(s)ds = \textrm{diag}(2\textrm{Re}\phi_1(s),\dots, 2\textrm{Re}\phi_n(s)),$$ and $\gamma^*\nabla_{h_R}$ has connection form $$(A(s)+B_0(s)+B_1(s))ds,$$ where   \item $B_0$ is a $C^0$ map from $[0,1]\to M(n,\C)_0$ that is $C^\infty$ on $(0,1)$, and \item $B_1$ is a $C^0$ map from $[0,1]\to M(n,\C)_1$ that is $C^\infty$ on $(0,1)$.   Using our comparison to (\ref{connectionestimate}), as well as our uniform controls, there exists $C>0$ with the same dependencies as above such that both $B_0$ and $B_1$ satisfy $$|B_m(s)|\leq CR^{-1}.$$ Taking $R$ sufficiently large, we may assume that both $||B_m||_0$  are small enough to satisfy the hypothesis of Lemma \ref{cor2.19}. Invoking Lemma \ref{cor2.19}, we know that there exists a $C^1$ function $G:[0,1]\to M(r,\C)$, a $C^0$ function $H:[0,1]\to M_0(n,\C)$, and a constant $C_1$ such that   \item in $C^1$-norm, $||G||_{C^1}<C_1R^{-1}$, \item in $C^0$ norm, $||H||_{C^0}<C_1R^{-1}$, and \item with respect to the frame $v=(I+G)u$, the connection form of $\gamma^*D_{h_R}$ is $$(A(s)+B_0(s)+H(s))ds.$$  Next, note that the frame $$v'=\textrm{exp}\Big (-\int_0^s(A(p)+B_0(p)+H(p))dp\Big )v$$ is flat for $\gamma^*D_{h_R}$. Therefore, the matrix of the parallel transport operator for $\gamma^*D_{h_R}$ from $\gamma(0)$ to $\gamma(1)$ is $$(I+G(1))\textrm{exp}\Big (-\int_0^s(A+B_0+H)dp\Big )(I+G(0))^{-1}.$$ Using the Gram-Schmidt process, we transform the frame $v'$ into an orthogonal frame such that all vectors have norm $R^{-1}.$ Denoting the new frame by $q$, it can be described by $$q(s)=(1+K(s))v'(s),$$ where $||K(s)||_{C^0}$ decays like $R^{-1}.$ If we set $$L(s)=(1+K(s))(I+G(s))-I,$$ then $\Pi_{R,\gamma}$ is represented in the frame $q$ by $$Z_{\gamma}:=(1+L(1))\textrm{exp}\Big (-\int_0^s(A(p)+B_0(p)+H(p))dp\Big )(I+L(0))^{-1}.$$ With this representation, we directly compute operator norms. For some constant $C>0,$ by the formula (\ref{beta1formula}), $$\log ||Z_\gamma||_{op}\leq \log ||\textrm{exp}\Big (-\int_0^s(A(p)+B_0(p)+H(p))dp\Big )||_{op}+CR^{-1}\leq 2\alpha_1+CR^{-1}.$$ Similarly, $|\Pi_{R,\gamma}(p(0))|_{(h_R)_{\gamma}(1)}\geq 2\alpha_1+CR^{-1},$ which implies $\log ||Z_\gamma||_{op}\geq 2\alpha_1+CR^{-1},$ so that $$|\log ||\Pi_{R,\gamma}||_{op}- 2\alpha_1|=|\log ||Z_\gamma||_{op}- 2\alpha_1|\leq CR^{-1}.$$ Estimating $||\wedge^k Z_\gamma||_{op}$ in the same fashion, but with (\ref{betakformula}), we find that for all $k$, $$|\log ||\wedge^k \Pi_{R,\gamma}||_{op} -2\sum_{j=1}^k\alpha_j|\leq CR^{-1}.$$ Theorem D then follows from inserting the inequalities above into the formula (\ref{differenceeq}). To understand the dependencies, note that our choices for $r>0$ depend on $S$ and $\gamma$.",2502.01395
theorem,"Let $A$ be a tridiagonal symmetric positive definite $n \times n$ matrix. Then it can be factorized as              A = LL^{\top},          where $L$ is a bidiagonal lower triangular matrix, and then mapping $A \rightarrow L$ is not local, which means      that there exist matrix $A$ and $A'$ such that $A-A'$ has only one non-zero element, where as $L - L'$ have all elements greater than zero.",2502.01397
theorem,"%  % If $f:X\to Y$ is bijective, the cardinality of $X$ and $Y$ are the same. %",2502.01397
definition,"%  % A function $f:X \to Y$ is injective if for any $x,y\in X$ different, $f(x)\ne f(y)$. %",2502.01397
proof,"Consider the matrix $A$ given by $A=LL^{\top}$ where $L$ is a bidiagonal matrix with $L_{ii} = \frac{1}{i}, i = 1, \ldots, n$ and     $L_{i, i-1} = 1, i = 2$. Then $A$ is a symmetric positive definite tridiagonal matrix with elements $A_{11} = 1, A_{i, i} = 1 + \frac{1}{i^2},      A_{i+1, i} = A_{i, i+1} = \frac{1}{i}, i = 1, \ldots, n-1$.     Now, consider the matrix $A' = A + e_1 e_1^{\top}$, where $e_1$ is the first column of the identity matrix. Let     $A' = L' L'^{\top}$ be its Cholesky factorization. The matrix $L'$ is bidiagonal. The element $L'_{11}$ is equal to $\sqrt{2}$,     and for each $i=2, \ldots, n$ we have the well-known formulas             L'_{i, i-1} = \frac{L_{i, i-1}}{L'_{i-1, i-1}} = \frac{\frac{1}{i-1}}{L'_{i-1, i-1}},           and $L'_{i, i} = \sqrt{A_{i, i} - \left( L_{i, i-1}\right)^2 }.$  Let $d_i = (L'_{i, i})^2$, then     $d_1 = 2, d_i = 1 + \frac{1}{i^2} - \frac{1}{d_{i-1} (i-1)^2}$. From this recurrence relation it is easy to see that $d_i$     converges to $1$ as $i \to \infty$.",2502.01397
proof,% Left as an exercise to the reader.  %,2502.01397
proposition,"% If $f$ is injective mapping a set $X$ to another set $Y$,  % the cardinality of $Y$ is at least as large as that of $X$ %",2502.01397
lemma,"%  % For any $f:X \to Y$ and $g:Y\to Z$ injective functions, $f \circ g$ is injective. %",2502.01397
proof,"The functor $\Sigma^{(-)}:\sK(X)\to \Aut(\SH(X))$ of \eqref{eq:SigmaFunctorOfGroupoids} gives rise to a functor of groupoids                    \Sigma^{(-)-\sO_X^{\rnk(-)}}1_X:\sK(X)\to \SH(X)_\simeq.      Composing \eqref{eq:FunctorOfGroupoids} with the canonical functor of groupoids $i:\Locfree(X) \to \sK(X)$, we get a functor of groupoids $\Locfree(X) \to \SH(X)_\simeq$. Let $\alpha:\sW\to \sV$ be an isomorphism in  $\Locfree(X)$, giving the induced isomorphism $\th(\alpha):\Sigma^{\sW-\sO_X^{\rnk(\sW)}}1_X\to \Sigma^{\sV-\sO_X^{\rnk(\sV)}}1_X$. By \eqref{enum:ThomClassAxioms}(2), we see that $\th_\sE(\sV)\circ \th(\alpha)= \th_\sE(\sW)$, and we can then see the assignment $\Locfree(X) \ni \sV \mapsto \th_\sE(\sV)$ as a natural transformation of functors of groupoids            [\th_\sE(-):(\Sigma^{(-)-\sO_X^{\rnk(-)}}1_X)\circ i\to c_{p^*\sE}]: \Locfree(X)\to \SH(X)_\simeq,  from the functor $(\Sigma^{(-)-\sO_X^{\rnk(-)}}1_X)\circ i$ to the constant functor $c_{p^*\sE}$ with value $p^*\sE$.  If $q:\tilde{X}\to X$ is a morphism in $\Sm/k$, the two functors commute with $q^*$. Thus, taking $q$ as a Jouanolou cover of $X$, we can assume that $X$ is affine.   If $\sV \in \Locfree(X)$, with $X$ affine, we have a canonical isomorphism $$\sV\oplus \sO_X^r-\sO_X^{\rnk(\sV\oplus \sO_X^r)} \xrightarrow{\sim} \sV-\sO_X^{\rnk(\sV)}$$ in $\sK(X)$, which gives the corresponding isomorphism in $\SH(X)$ after applying $\Sigma^{(-)}1_X$. We then have a diagram     $$          \Sigma^{\sV\oplus \sO_X^r-\sO_X^{\rnk(\sV\oplus \sO_X^r)}}1_X \arrow[rr, ""\sim""] \arrow[dr, swap, ""\th_\sE(\sV\oplus \sO_X^r)""] & & \Sigma^{\sV-\sO_X^{\rnk(\sV)}}1_X \arrow[dl, ""\th_\sE(\sV)""] \\         & p^*\sE, &  $$ It follows by \eqref{enum:ThomClassAxioms}(1,3) that this diagram commutes. Thus, we can extend $\th_\sE(-)$ to differences $\sV-\mathcal{O}_X^r$ by letting $\th_\sE(\sV-\mathcal{O}_X^r)\coloneqq \th_\sE(\sV)$.  We recall from \cite{Gra:Quillen} that the groupoid $\sK(X)$ is obtained from the groupoid $\Locfree(X)$ by inverting the autoequivalence $\oplus \mathcal{O}_X$. Therefore, we can extend the natural transformation \eqref{eq:NaturalTransformation} to a natural transformation $$[\th_\sE(-):(\Sigma^{(-)-\sO_X^{\rnk(-)}}1_X)\to c_{p^*\sE}]:\sK(X)\to \SH(X)_\simeq.$$",2502.01404
proof,"Since the forgetful functor $\Mod_{p^*\sE}\to\SH(X)$ reflects isomorphisms, it suffices to see that $\th_{\sE}^f(v)$ is an isomorphism in $\SH(X)$. It follows from the normalization axiom (2) that for $v=[\sO_X^r]$, $\th_\sE(v):1_X\to p^*\sE$ is the unit $u_{\sE,X}\in \sE^{0,0}(X)$, which easily implies the lemma for $v=[\sO_X^r]$. In general, we take a Zariski open cover $\sU=\{U_i\}_i$ for $X$ for which the restriction of $v$ to each $U_i$ is $r_i[\sO_{U_i}]$ for some integer $r_i$. The result then follows from the gluing axiom for the sheaf $\SH(-)$ on $X_\Zar$.",2502.01404
proof,"(2) follows directly from (1).  For (1), let $\phi:v\to v'$ be an isomorphism in $\sK(X)$,  let $r=\rnk(v)=\rnk(v')$ and let $\Sigma^\phi(p_X^*\sE):\Sigma^{v}p_X^*\sE\simeq \Sigma^{v'}p_X^*\sE$ be the isomorphism induced from $\Sigma^\phi:\Sigma^v \simeq \Sigma^{v'}$. This gives us the commutative diagram of isomorphisms in $\SH(X)$ \[ \xymatrixcolsep{40pt} \xymatrix{ \Sigma^{v-\sO_X^r}p_X^*\sE\ar[d]_{\Sigma^{-\sO_X^r}\Sigma^\phi(p_X^*\sE)}\ar[r]^-{\th_{\sE}^f(v)}&p_X^*\sE\\ \Sigma^{v'-\sO_X^r}p_X^*\sE\ar[ru]_{\th_{\sE}^f(v')} } \] In other words $\Sigma^{\phi}(p_X^*\sE)=\Sigma^{\sO_X^r}(\th_{\sE}^f(v)^{-1}\circ \th_{\sE}^f(v))$. This shows that $\Sigma^{\phi}(p_X^*\sE)$ is independent of the choice of $\phi:v\to v'$, proving (1).",2502.01404
proof,"For (1), we first note that $s^*:\sE^{*,*}(V)\to \sE^{*,*}(X)$ is an isomorphism, and is equal to the isomorphism $s_0^*:\sE^{*,*}(V)\to \sE^{*,*}(X)$. In fact, $s_0$ and $s$ are both inverse of the structure map $V \to X$ in $\sH(k)$, which is a weak equivalence by homotopy invariance. Thus, they induce the same isomorphism in $\sE$ cohomology by pullback. Now, by construction of the proper pushforward for $s_0$, we have that $s_{0*}(1^\sE_X)\in \sE^{2r,r}(V)$ is the image of $\th^\sE(V)\in \sE^{2r,r}(\Th(V))$ under the map  $\pi^*:\sE^{2r,r}(\Th(V))\to \sE^{2r,r}(V)$ induced by the quotient map $\pi:V_+\to \Th(V)$ in $\sH_\bullet(k)$. Finally, by considering the commutative diagram \[ \xymatrix{ \sE^{*,*}(\Th(V))\ar[r]^{\pi^*}\ar[dr]_{z_0^*}&\sE^{*,*}(V)\ar[d]^{s_0^*}\\ &\sE^{*,*}(X), } \] we get  $$c_r(V) =z_0^*(\th(V)) =s_0^*(\pi^*\th(V)) =s_0^*(s_{0*}(1^\sE_X)) =s^*(s_{0*}(1^\sE_X)).$$ This proves (1).  We prove (2). Using (1) and applying Proposition \ref{prop:PushPull}(2) to the transverse cartesian diagram \[ \xymatrix{ Y\ar[r]^i\ar[d]^i&X\ar[d]^s\\ X\ar[r]^{s_0}&V, } \] gives $$c_r(V)=s^*(s_{0*}(1^\sE_X))=i_*(i^*(1^\sE_X))=i_*(1^\sE_Y).$$",2502.01404
proof,"By using a Jouanolou cover of $X$, we may assume that $X$ is affine. In that case, there exists a vector bundle $E$ over $X$ such that $-e=[E]-s[\sO_X]$, and let $r \coloneqq s-d$. In this way, we are reduced to prove the commutativity of the diagram                             \Sigma^{2r,r}\Sigma^{-[E +\oplus_i^nL_i]}1_X \wedge p^*H\Z \arrow[rrrr, ""\Sigma^{2r,r}\Anan_{E;L_1,\ldots,L_n} \wedge \id_{p^*H\Z}"", ""\sim""'] \arrow[drr, swap, ""\th^f_{H\Z \Mod} (-E-\oplus_i^nL_i)"", ""\sim""'] &&&&  \Sigma^{2r,r}\Sigma^{-[E +\oplus_i^nL_i^{\vee}]}1_X \wedge p^*H\Z \arrow[dll, ""(-1)^n\th^f_{H\Z \Mod} (-E-\oplus_i^nL_i^\vee)"", ""\sim""'] \\         &&p^*H\Z&&               in $\Mod_{p^*H\Z}$. Let $\rho:\Th(E +\oplus_{i=1}^nL_i)\xrightarrow{\sim}\Th(E + \oplus_{i=1}^nL_i^\vee)$ the isomorphism in $\sH_{\bullet}(k)$ defined by Ananyevskiy.          The commutativity of \eqref{eq:anatriangle} is equivalent to     $$(\Sigma^{2r,r}\Anan_{E;L_1,\ldots,L_n} \wedge \id_{p^*H\Z})^*\th_{H\Z}^f (E\oplus_i^nL_i^\vee) =(-1)^n \th_{H\Z}^f (E+\oplus_i^nL_i),$$     and this is in turn equivalent to     $$\rho^*\th^{H\Z} (E+\oplus_i^nL_i^\vee) = (-1)^n \th^{H\Z} (E+\oplus_i^nL_i).$$     Lemma \ref{lemma:anatwists} below shows in detail the computation for $n=1$. The result immediately follows by induction on $n$.",2502.01404
proof,"Since we are working in the stable setting, we simplify the notation by writing $\rho$ for $\Sigma^{\infty}_{\P^1}\rho:p_\#\Sigma^{E +L}1_X \xrightarrow{\sim} p_\#\Sigma^{E+L^\vee}1_X$, with $p\coloneqq p_X:X \to \Spec k$ the structure map. Let us briefly review the construction of $\rho$ from \cite{Ana:Slor}.      Let $\pi_L:L\to X$ and $\pi_{L^\vee}:L^\vee \to X$ the structure morphisms of the two vector bundles. Let us denote by $L^0$ and $(L^\vee)^0$ the complements of the zero sections, and by $\pi_{L^0}$, $\pi_{(L^\vee)^0}$ the restrictions of the relative morphisms. Let us note that $\A^1$-invariance (Proposition \ref{prop:hom-invariance}) implies $\pi_{L\#}1_L \simeq 1_X \simeq \pi_{L^\vee \#}1_{L^\vee}$. The localization sequence associated to the inclusion $L^0 \hookrightarrow L$ as in \eqref{eq:thom-loc2} gives a distinguished triangle                    \pi_{L^0\#}1_{L^0} \to 1_X \to \Sigma^L1_X \to \pi_{L^0\#}1_{L^0}[1],           and analogously, we have the distinguished triangle                   \pi_{(L^\vee)^0\#}1_{(L^\vee)^0} \to 1_X \to \Sigma^{L^\vee}1_X \to \pi_{(L^\vee)^0\#}1_{(L^\vee)^0}[1].          There is a unique isomorphism of $X$-schemes $f:L^0\xrightarrow{\sim}(L^{\vee})^0$ given by taking, fiberwise, the vector $v$ to the functional $f_v$ such that $f_v(v)=1$. By taking $\Sigma_{\P^1}^\infty f$ over $X$, this gives an isomorphism between the right and terms of \eqref{eq:locseq1} and \eqref{eq:locseq2}, that, together with $\id_X$, induces the isomorphism $\Anan_L:\Sigma^L1_X \xrightarrow{\sim} \Sigma^{L^\vee}1_X$ on the cofibers. Applying $p_\# \circ \Sigma^E$ to $\Anan_L$ gives the isomorphism $\rho: p_\#\Sigma^{E+L}1_X \xrightarrow{\sim} p_\#\Sigma^{E +L^\vee}1_X$.      From this construction, we see that $\rho=\id_{p_\# \Sigma^E1_X}\wedge \rho_L$, with $\rho_L \coloneqq p_\# \Anan_L$, and since Thom classes are additive, we have $\rho^*\th^{H\mathbb{Z}}(E + L^{\vee})=\th^{H\Z}(E) \cup \rho_L^*(L)$. This reduces to the case $E=0$ and $\rho=\rho_L$.      Next, we reduce to the case $X=\Spec k(X)$. The Thom isomorphism in $H\mathbb{Z}$-cohomology makes $H\mathbb{Z}^{**}(p_{\#}\Sigma^L1_X)$ and $H\mathbb{Z}^{**}(p_{\#}\Sigma^{L^{\vee}}1_X)$ two free $H\mathbb{Z}^{**}(X)$-modules of rank $1$, generated respectively by $\th^{H\mathbb{Z}}(L)$ and $\th^{H\mathbb{Z}}(L^{\vee})$, both in bidegree $(2,1)$. $\rho_L^*$, as an isomorphism of $H\mathbb{Z}^{**}(X)$-modules, sends generators to generators, then $\rho_L^*\th^{H\mathbb{Z}}(L^{\vee})=\alpha \cdot \th^{H\mathbb{Z}}(L)$, with $\alpha \in H\mathbb{Z}^{0,0}(X)=\mathbb{Z}.$ Since $X$ is irreducible, there is a unique generic point $i:\Spec k(X) \to X$. Let then     $$\rho_{i^*L}: p_{k(X)\#}\Sigma^{i^*L}1_{k(X)} \xrightarrow{\sim} p_{k(X)\#}\Sigma^{i^*L^{\vee}}1_{k(X)}$$     be the isomorphism obtained in the same way as $\rho$, with $p_{k(X)}\coloneqq p \circ i =\Spec(k \hookrightarrow k(X))$. We have the commutative diagram \[  \xymatrix{  H\Z^{0,0}(X)\ar@{=}[d]\ar[r]^{i^*}_\sim&H\Z^{0,0}(k(X))\ar@{=}[d]\\   [1_X, p^*H\Z]_{\SH(X)}\ar[r]^{i^*}\ar[d]_\wr^{\cup \; \th^{H\mathbb{Z}}(L)}&[1_{k(X)}, p_{k(X)}^*H\Z]_{\SH(k(X))}\ar[d]_\wr^{\cup \; \th^{p_{k(X)}^*H\mathbb{Z}}(i^*L)}\\  [\Sigma^L1_X, \Sigma^{2,1}p^*H\Z]_{\SH(X)}\ar@{=}[d]\ar[r]^{i^*}&[\Sigma^{i^*L}1_{k(X)}, \Sigma^{2,1}p_{k(X)}^*H\Z]_{\SH(k(X))}\ar@{=}[d]\\  H\Z^{2,1}(\Th(L))\ar[r]^{i^*}&H\Z^{2,1}(\Th(i^*L))   }  \]  and a similar diagram for $L^\vee$. Let $\alpha_{k(X)}\in \Z=H\Z^{0,0}(k(X))$ be the element such that $\rho_{i^*L}(\th^{p_{k(X)}^*H\mathbb{Z}}(i^*L^{\vee}))=\alpha_{k(X)} \cdot \th^{p_{k(X)}^*H\mathbb{Z}}(i^*L)$. The maps $\rho_L$ and $\rho_{i^*L}$ define a map of the above diagram to the corresponding one for $L^\vee$, so we have $i^*\alpha=\alpha_{k(X)}$. But since $i^*:\Z=H\Z^{0,0}(X)\to H\Z^{0,0}(k(X))=\Z$ is the identity map on $\Z$, we have $\alpha_{k(X)}=\alpha$. This reduces to the case $X =\Spec k(X)$.     Changing notation, we may simply assume that $X=\Spec k$. $L$ is then a one dimensional $k$-vector space with zero section being the origin. The total space of $L$ is (non canonically) isomorphic to $\mathbb{A}^1$. Let us choose any isomorphism $L\xrightarrow{\sim} \mathbb{A}^1$. This also induces an isomorphism $L^{\vee}\xrightarrow{\sim}\mathbb{A}^1$ through $f\mapsto f(1)$. Through these isomorphisms, we identify $L^0$ and $(L^{\vee})^0$ with $\mathbb{G}_m$. The isomorphism of schemes $L^0 \xrightarrow{\sim}(L^{\vee})^0$ given by $v \mapsto f_v$, induces the automorphism $t \mapsto t^{-1}$ of $\mathbb{G}_m$, because $1=f_t(t)=t\cdot f_t(1)$. The isomorphisms $L\xrightarrow{\sim}\mathbb{A}^1\xleftarrow{\sim}L^{\vee}$ induce     $$\Sigma^L1_X \xrightarrow{\sim}S^1\wedge \mathbb{G}_m \xleftarrow{\sim} \Sigma^{L^{\vee}}1_X,$$     and trough these, the isomorphism $\rho_L$ can be read as the automorphism $\id_{S^1}\wedge(t\mapsto t^{-1})$ of $S^1\wedge\G_m$, where $t$ is the canonical coordinate on $\G_m$. We have     $$H\Z^{2,1}(\P^1) \simeq H\mathbb{Z}^{2,1}(S^1\wedge\G_m)\simeq  H\mathbb{Z}^{1,1} (\G_m) \xleftarrow{\sim} \mathbb{Z},$$     with the last isomorphism sending $n\in\Z$ to $t^n\in H\mathbb{Z}^{1,1}(\G_m))$. Thus, $\rho_L$ induces the isomorphism $n\mapsto -n$ on $\Z\cong H\mathbb{Z}^{2,1}(\P^1)$.      $\th^{H\mathbb{Z}(L)}$ and $\th^{H\mathbb{Z}}(L^{\vee})$ belong to $H\mathbb{Z}^{2,1}(\mathbb{P}^1)\simeq \mathbb{Z}$, and they are generators. Since $L\simeq L^\vee\simeq \A^1_F$ as line bundles over $\Spec F$, we have $\th^{H\mathbb{Z}}(L)=\th^{H\mathbb{Z}}(L^{\vee})$, and since $\rho_L^*(n)=-n$, we conclude $\rho_L^*(\th^{H\mathbb{Z}}(L^{\vee}))= -\th^{H\mathbb{Z}}(L)$.",2502.01404
proof,"By rewriting the construction of the proper pushforward map (Construction~\ref{constr:properpushforward}), and recalling the definition of the degree map (Definition~\ref{defn:Degree}), we have that the degree map $\deg_k:H\Z^{2d_X, d_X}(X)\to \Z$ is given by the composition  H\Z^{2d_X, d_X}(X)&=[1_X, \Sigma^{2d_X, d_X}p^*H\Z]_{\SH(X)}\\ &\xrightarrow{\sim} [p^*H\Z, \Sigma^{2d_X, d_X}p^*H\Z]_{\Mod_{p^*H\Z}}\\ &\xrightarrow{\th_{H\Z\Mod}^f(-T_X)^*}[\Sigma^{-T_X+d_X[\sO_X]}1_X\wedge p^*H\Z, \Sigma^{2d_X, d_X}p^*H\Z]_{\Mod_{p^*H\Z}}\\ &=[\Sigma^{-T_X}1_X\wedge  p^*H\Z, p^*H\Z]_{\Mod_{p^*H\Z}}\\ &=[\Sigma^{-T_X}1_X, p^*H\Z]_{\SH(X)}\\ &=[p_\#(\Sigma^{-T_X}1_X), H\Z]_{\SH(k)}\\ &\xrightarrow{(p^\vee)^*}[1_k,H\Z]_{\SH(k)}=H\Z^{0,0}(\Spec k)=\Z.  By comparing this composition with \eqref{eq:anandeg} and applying Lemma~\ref{lem:Anan}, we complete the proof.",2502.01404
proof,"Let $p:=p_Y:Y \to \Spec k$ be the structure map. We write $\Anan$ for $\Anan_{e, -L_1,\ldots, -L_n}(v)$.          By looking at the definition of $[Y,v,\vartheta]_\sE$ (Definition \ref{defn:twistclass}), and recalling that $\vartheta$ is the isomorphism $\Sigma^{-2d,-d}\Anan$, we see that $c\circ [Y,v,\vartheta]$ is the composition     $$1_k\xrightarrow{p^\vee}p_{\#}\Sigma^{-T_Y}1_Y\xrightarrow[\sim]{p_\#\Sigma^{-2d,-d}\Anan} p_{\#}\Sigma^{v}1_Y\xrightarrow{\Sigma^{-2d,-d}\th_\sE(v)'} \Sigma^{-2d,-d}\sE\xrightarrow{\Sigma^{-2d-d}c}H\Z,$$ where $\th_\sE(v)'$ is the map corresponding to $\th_\sE(v)$ by adjunction $p_\# \dashv p^*$.  On the other hand, by looking at the definition of $c^\sE(v)$ (Definition \ref{defn:HZclasses}), we note that the composition $$p_{\#}\Sigma^{v}1_Y\xrightarrow{\Sigma^{-2d,-d}\th_\sE(v)'} \Sigma^{-2d,-d}\sE\xrightarrow{\Sigma^{-2d-d}c}H\Z$$ is the class $\Sigma^{-2d,-d}\tilde{c}^\sE(v)$, where $\tilde{c}^\sE(v)$ is the class that induces $c^\sE(v)$ through the isomorphism $H\Z^{2d,2}(p_\#\Sigma^{v+d[\sO_Y]}1_Y)\simeq H\Z^{2d,d}(Y)$. Then $$c\circ [Y,v,\vartheta]=(p^\vee)^*(\Sigma^{-2d,-d}(p_\#\Anan)^*(\Sigma^{-2d,-d}\tilde{c}^\sE(v))).$$  We also see from Definition \ref{defn:HZclasses} that the isomorphism $H\Z^{2d,2}(p_\#\Sigma^{v+d[\sO_Y]}1_Y)\simeq H\Z^{2d,d}(Y)$ giving $c^\sE(v)$ is induced by the isomorphism $\th_{H\Z}^f(v)$, or equivalently, by $\th_{H\Z}^f(v)^*$.  Lastly, the isomorphism $p_\#\Anan$ in $\SH(k)$ corresponds to the isomorphism  $$\Anan \wedge \id_{p^*H\Z}:\Sigma^{-T_Y+d[\sO_Y]}1_Y \wedge p_*H\Z \xrightarrow{\sim} \Sigma^{v +d[\sO_Y]}1_Y \wedge p^*H\Z$$ in $\Mod_{p^*H\Z}$ through the free-forgetful adjunction.   Thus, by looking at the composition \eqref{eq:anandeg} defining the twisted degree $\deg_k^\Anan$, we see that $c\circ [Y,v,\vartheta]$ is the class $\deg_k^\Anan(c^\sE(v))$ in $H\Z^{0,0}(\Spec k)$. Applying Proposition \ref{prop:comparisondegrees} concludes the proof.",2502.01404
proof,"As is well known, see for example \cite[Theorem 2.2]{Panin:algcob}, one has $$H\Z^{*,*}(\BGL_r)=H\Z^{*,*}(k)[c_1,\ldots, c_r],$$ with $c_r$ in bidegree $(2r,r)$ being the usual $r$-th Chern class $c_r(E_m)$ for $m\ge r$, defined by the Grothendieck formula.  For $i_r:\BGL_r\to\BGL_{r+1}$ and for all $a,b$, the map $$i_r^*:H\Z^{a,b}(\BGL_{r+1})=H\Z^{a,b}(k)[c_1, \ldots, c_{r+1}] \to H\Z^{a,b}(k)[c_1, \ldots, c_r]=H\Z^{a,b}(\BGL_r)$$ is surjective, because $i_r^*(c_i)=c_i$ for $i\le r$ and $i_r^*(c_{r+1})=0$, by the functoriality of Chern classes. Thus, the inverse system $\{H\Z^{a,b}(\BGL_r), i_r^*\}_r$ satisfies the Mittag-Leffler condition, and its $\lim^1$-term vanishes. We get the identity:        H\Z^{a,b}(\BGL):=[\colim_r\Sigma^\infty_{\P^1}\BGL_{r,+}, \Sigma^{a,b}H\Z]_{\SH(k)}\simeq \lim_rH\Z^{a,b}(\BGL_r).  Thus, because $H\Z^{a,b}(k)=0$ for $b<0$, it follows that $$H\Z^{*,*}(\BGL)=H\Z^{*,*}(k)[c_1,\ldots, c_r, \ldots].$$  Since $\MGL_r=\Th(E_r)$, the fact that $H\Z$ is oriented gives us the Thom isomorphism       H\Z^{a+2r, b+r}(\MGL_r)\simeq H\Z^{a,b}(\BGL_r).  Through this, we have a similar description of $H\Z^{a,b}(\MGL)$, namely,  H\Z^{a,b}(\MGL)&:=[\MGL, \Sigma^{a,b}H\Z]_{\SH(k)}\\ &=[\colim_r\Sigma^{-2r, -r}\MGL_r, \Sigma^{a,b}H\Z]_{\SH(k)}\\ &\simeq \lim_r H\Z^{2r+a, r+b}(\MGL_r)\\ &\overset{\eqref{eq:thomisoBGL}}{\simeq}\lim_r H\Z^{a,b}(\BGL_r)\\ &\overset{\eqref{eq:cohomologyBGL}}{\simeq} H\Z^{a,b}(\BGL).",2502.01404
proof,"The statement for $\th^{\Sp, f}_{\sE\Mod}(V,\omega)$ follows immediately from that for $\th^{\Sp,f}_{\sE}(V,\omega)$, by applying the forgetful functor. We prove the statement for $\th^{\Sp,f}_{\sE}(V,\omega)$.      Let us suppose that $(V,\omega)$ is a trivial symplectic vector bundle, namely, a trivial rank $2r$ vector bundle $V$, equipped with the standard symplectic form $\omega = \phi_{2r}$. In this case $\th^{\Sp,f}_{\sE}(V,\omega)$ is an isomorphism. Indeed, we have $\Sigma^V=\Sigma^{4r,2r}$, and the map $\th_{\sE}^\Sp(V,\omega): \Sigma^V1_X \to \Sigma^{4r,2r}p_X^*\sE$ in $\SH(X)$ is obtained by applying $\Sigma^{4r,2r}$ to the unit map $\epsilon_{p_X^*\sE}$ of $p_X^*\sE$ in $\SH(X)$. In particular, the map      $$\th^{\Sp,f}_{\sE}(V,\omega)=\Sigma^{4r,2r}\mu_{p_X^*\sE} \circ \Sigma^{4r,2r}(\epsilon_{p_X^*\sE} \wedge 1) = \Sigma^{4r,2r}\id_{p_X^*\sE}$$     is an isomorphism.  We now claim that every symplectic vector bundle is Zariski-locally isomorphic to the trivial symplectic vector bundle. We can prove this by applying a skew-symmetric version of the Gram-Schmidt process to find (not uniquely) a Zariski-local trivialization of the bundle, as follows.  Let $(V,\omega)$ be a symplectic vector bundle over $X$ of rank $2r$, and let us consider $x \in X$ a point. Let $v_1$ be a local section such that $v_1(x)\neq 0$. $v_1$ will be a nowhere zero section on a Zariski open neighbourhood $U_1$ of $x$. Since $\omega$ is non-degenerate, there exists a section $v_{2r}$ such that $\omega(v_1,v_{2r})(x)\neq 0$. The closed subset of $U_1$ where $\omega(v_1,v_{2r})=0$ is a Zariski closed subset. Then, after removing this closed subset from $U_1$, we can suppose $\omega(v_1,v_{2r}) \neq 0$ on $U_1$. Moreover, by rescaling $v_{2r}$ by the function $1/\omega(v_1,v_{2r})$, we can suppose $\omega(v_1,v_{2r})=1$ on $U_1$. Let us consider the restriction of $V$ to $U_1$, and let $V_1 \coloneqq \langle v_1, v_{2r} \rangle$ be the rank $2$ subbundle of $V\mid _{U_1}$ spanned by the two sections $v_1,v_{2r}$. The restriction of $\omega$ to the subbundle $V_1$ is then represented by the standard $2 \times 2$ symplectic matrix $\phi_2$ with respect to the two generating sections $v_1,v_{2r}$. So, $(V_1,\omega\mid_{V_1})$ is a rank $2$ symplectic subbundle of $V$ on $U_1$. Let us consider its perpendicular symplectic bundle $$V_1 ^{\perp} \coloneqq \{v' \in V \mid_{U_1} \; : \; \omega(v',v)=0 \; \; \forall \; v \in V_1\}.$$ This gives us the orthogonal decomposition of the restriction of $(V,\omega)$ to $U_1$ as $(V_1,\omega_1)\perp(V_1^\perp,\omega_1^\perp)$, where $\omega_1$ is the restriction of $\omega$ to $V_1$ and $\omega_1^\perp$ is defined similarly. By proceeding inductively on the rank $2r$ of $V$, we find a neighbourhood $U_2 \subset U_1$ of $x$ over which $V_1^\perp$ admits a trivialization as a symplectic vector bundle. As a result, we have found a Zariski open neighbourhood $U_x$ of $x$ and a decomposition  $$V \mid_U=V_1 \oplus \ldots \oplus V_r = \langle v_1, \ldots, v_{2r} \rangle$$ such that $\omega$ is represented by the standard $2r \times 2r$ symplectic matrix $\phi_{2r}$ with respect to the generating sections $v_1, \ldots v_{2r}$. This proves that $(V,\omega)$ is Zariski-locally isomorphic to the trivial symplectic bundle, whence the claim.  Thus, there will exist a Zariski open cover $\{U_{\alpha}\}_{\alpha}$ of $X$ such that, for all $j_{\alpha}:U_{\alpha}\to X$, the restriction of $(V,\omega)$ on $U_{\alpha}$ is a trivial symplectic vector bundle. If we write $(V_{\alpha},\omega_{\alpha}) \coloneqq j_{\alpha}^*(V,\alpha)$, we have that $\th_{\sE}^{\Sp,f}(V_\alpha,\omega_\alpha)$ is an isomorphism in $\SH(U_{\alpha})$ for all $\alpha$. Clearly, the restriction of $(V,\omega)$ to the intersection of finitely many such opens is trivial as well.  We will conclude by using a Mayer-Vietoris argument to show that $\th^{\Sp,f}_{\sE}(V,\omega)$ is an isomorphism as follows. To simplify the notation, we write $\Psi$ for $\th^{\Sp,f}_{\sE}(V,\omega)$.   Since $X$ is quasi-compact, there are  $\alpha_1,\ldots, \alpha_n$ such that $X=\cup_{i=1}^nU_{\alpha_i}$, and thus this gives a finite open cover of $X$ trivializing the symplectic bundle $(V,\omega)$.   Let $X_i=\cup_{j=1}^iU_{\alpha_i}$ with open immersion $j_i:X_i\to X$. We show by induction on $i$ that $j_i^*\Psi:j_i^*\Sigma^Vp_X^*\sE\to j_i^*\Sigma^{4r,2r}p_X^*\sE$ is an isomorphism, the case $i=1$ following by our construction of $U_{\alpha_1}$.  Let us take $i>1$ and write $X_i=X_{i-1}\cup U_{\alpha_i}$.  Let $j:X_{i-1}\cap U_{\alpha_i}\hookrightarrow X_i$, $j_1:X_{i-1}\hookrightarrow X_i$ and $j_2:U_{\alpha_i}\hookrightarrow X_i$ be the evident open immersions. Lemma \ref{lemma:Mayer-Vietoris} below shows that there exists a Mayer-Vietoris  distinguished triangle        j_\#j^* \to j_{1\#}j_1^* \oplus j_{2\#}j_2^* \to \id_{\SH(X_i)}\to  j_\#j^*[1]  of endofunctors of $\SH(X_i)$, inducing the corresponding distinguished triangle of endofunctors of $\Mod_{p_{X_i}^*\sE}$. We apply this to the map of spectra $j_i^*\Psi$, giving the commutative diagram \[ \xymatrixcolsep{60pt} \xymatrix{ j_\#j^*j_i^*\Sigma^Vp_X^*\sE\ar[d]\ar[r]^-{j_\#j^*j_i^*\Psi}&j_\#j^*j_i^*\Sigma^{(4r,2r)}p_X^*\sE\ar[d]\\ \hbox{$j_{1\#}j_{i-1}^*\Psi\\\oplus\\ j_{2\#}j_2^*j_i^*\Psi$}\ar[d]\ar[r]^-{\tinyj_{1\#} j_{i-1}^*\Psi\\ \oplus\\  j_{2\#}j_2^*j_i^*\Psi}&\hbox{$j_{1\#}j_{i-1}^*\Sigma^{(4r,2r)}p_X^*\sE\\\oplus \\j_{2\#}j_2^*j_i^*\Sigma^{(4r,2r)}p_X^*\sE$}\ar[d]\\ j_i^*\Sigma^Vp_X^*\sE\ar[d]\ar[r]^-{j_i^*\Psi}&j_i^*\Sigma^{(4r,2r)}p_X^*\sE\ar[d]\\ j_\#j^*j_i^*\Sigma^Vp_X^*\sE[1]\ar[r]^-{j_\#j^*j_i^*\Psi[1]}&j_\#j^*j_i^*\Sigma^{(4r,2r)}p_X^*\sE[1],  } \] with columns distinguished triangles in $\Mod_{p_{X_i}^*\sE}$.  Noting that the trivialization of restriction of $(V,\omega)$ to $U_{\alpha_i}$ induces a trivialization of the restriction to $X_{i-1}\cap U_{\alpha_i}$ and using the induction hypothesis, we see that the horizontal maps in the first, second, and fourth rows are isomorphisms, hence $j_i^*\Psi$ is an isomorphism and the induction goes through.",2502.01404
proof,"Let us consider the diagram $$      U_1 \cap U_2 \arrow[r, ""t_2""] \arrow[d, swap, ""t_1""] \arrow[dr, ""j""] & U_2\arrow[d, ""j_2""] \\     U_1 \arrow[r, ""j_1""] & U_1 \cup U_2 =X.  $$ Let $i_1: X-U_1 \to X$ be the closed complement of $j_1$, and similarly, let $i_2$ be the closed complement of $t_2$. From Proposition \ref{prop:localization}, the localization sequence for the pair $(j_1,i_1)$ is the distinguished triangle        j_{1!}j_1^*\to \id_{\SH(X)} \to i_{1*}i_1^* \to j_{1!}j_1^*[1]  of endofunctors of $\SH(X)$. Analogously, the localization sequence for the pair $(t_2,i_2)$ is the distinguished triangle $$t_{2!}t_2^* \to \id_{\SH(X)} \to i_{2*}i_2^* \to t_{2!}t_2^*[1].$$ By applying $j_{2!}(-)j_2^*$ to the last triangle, we get the distinguished triangle $$j_{2!}t_{2!}t_2^*j_2^* \to j_{2!}j_2^* \to j_{2!}i_{2*}i_2^*j_2^* \to j_{2!}t_{2!}t_2^*j_2^*[1],$$ that can be rewritten as         j_!j^* \to j_{2!}j_2^* \to j_{2!}i_{2*}i_2^*j_2^* \to j_!j^*[1].  Moreover, we have a canonical distinguished triangle       j_{1!}j_1^* \to j_{1!}j_1^* \oplus j_{2!}j_2^* \to j_{2!}j_2^* \to j_{1!}j_1^*[1].   Since $i_1 \simeq j_2 \circ i_2$ on $U_2-(U_1\cap U_2)$, we have that $j_{2!}i_{2*}i_2^*j_2^* \simeq i_{1*}i_1^*$, that is, the right-hand terms of \eqref{eq:MV1} and \eqref{eq:MV2} are isomorphic. Thus, we have the conditions for applying the octahedral axiom to the triangles \eqref{eq:MV1}, \eqref{eq:MV2} and \eqref{eq:MV3}, and we get the distinguished triangle $$j_!j^* \to j_{1!}j_1^* \oplus j_{2!}j_2^* \to \id_{\SH(X)} \to j_!j^* \to j_{1!}j_1^*[1].$$ Finally, for any $f$ open immersion, we have $f_!\simeq f_\#$ by Remark \ref{rmk:etalemaps}. This concludes the proof.",2502.01404
proof,"We start by proving the following extra statement: \\[5pt] (3${}'$) The maps $\th^{\Sp,f}_{\sE}(v, \omega)$ define a natural isomorphism of functors \[ \th^{\Sp,f}_{\sE}(-):\Sigma^{(-)-\sO_X^{\rnk(-)}}p^*_X\sE\to c_{p_X^*\sE}:\sK^\Sp(X)\to (\SH(X))_\simeq.  \] We have already shown that the individual morphisms $\th^{\Sp,f}_{\sE}(v,\omega)$ are isomorphisms in $\SH(X)$, so we only need to show the naturality with respect to the morphisms in $\sK^\Sp(X)$.   We first prove the naturality with respect to morphisms in $\sS{p}(X)^2=\sS{p}(X) \times \sS{p}(X)$. Let $f:(V_1,\omega_1)\to (V_2,\omega_2)$, and $f':(V'_1,\omega_1')\to (V'_2,\omega_2')$ be isomorphisms of symplectic vector bundles (of respective ranks $2r,2r'$) on $X$. We need to show that the diagram \[ \xymatrixcolsep{100pt} \xymatrix{ \Sigma^{V_1-\sO_X^{2r}-V_1'+\sO_X^{2r'}}p_X^*\sE\ar[d]^-\sim\ar[r]^{\Sigma^{f-f'}}& \Sigma^{V_2-\sO_X^{2r}-V_2'+\sO_X^{2r'}}p_X^*\sE\ar[d]^-\sim\\ \Sigma^{V_1-\sO_X^{2r}}(\Sigma^{-V_1'+\sO_X^{2r'}}p_X^*\sE)\ar[d]^{\Sigma^{V_1-V_1'-\sO_X^{2r}-\sO_X^{2r'}}(\th^{\Sp,f}_{\sE}(V_1',\omega')^{-1})}\ar[r]^{\Sigma^f(\Sigma^{-f'})}& \Sigma^{V_2-\sO_X^{2r}}(\Sigma^{-V_2'+\sO_X^{2r'}}p_X^*\sE)\ar[d]^{\Sigma^{V_2-V_2'-\sO_X^{2r}-\sO_X^{2r'}}(\th^{\Sp,f}_{\sE}(V_2',\omega')^{-1})}\\ \Sigma^{V_1-\sO_X^{2r}}p_X^*\sE\ar[d]^{\th^{\Sp,f}_{\sE}(V_1,\omega)}\ar[r]^{\Sigma^f}& \Sigma^{V_2-\sO_X^{2r}}p_X^*\sE\ar[d]^{\th^{\Sp,f}_{\sE}(V_2,\omega)}\\ \sE\ar@{=}[r]&\sE } \] commutes. The commutativity of the top square is clear. The commutativity of the bottom one follows from the naturality of the isomorphisms $\th^{\Sp,f}_{\sE}((V,\omega_V))$ with respect to isomorphisms of symplectic bundles $(V,\omega_V)\simeq (W,\omega_W)$.  Next, we check the naturality with respect to morphisms in $\sS{p}(X)_{st}$. Since we have already checked  the naturality with respect to morphisms in $\sS{p}(X)^2$, we only need to check  naturality with respect to morphisms of the form $$((V'',\omega''),\id_{V\oplus V''},\id_{V'\oplus V''}):((V,\omega), (V',\omega'))\to((V\oplus V'',\omega\oplus \omega''), (V'\oplus V'',\omega'\oplus \omega'')).$$ This is equivalent to the commutativity of the diagram \[ \xymatrix{ \Sigma^{(V+V'')-(V'+V'')-\sO_X^{2r}+\sO_X^{2r'}}p_X^*\sE\ar[d]^\wr\ar[r]^-{can}_-\sim&\Sigma^{V-V'-\sO_X^{2r}+\sO_X^{2r'}}p_X^*\sE\ar[d]^\wr\\ p_X^*\sE\ar@{=}[r]&p_X^*\sE, } \] where the vertical maps are the respective Thom isomorphisms. This is the identity  \th^{\Sp,f}_{\sE}(V,\omega)\circ \Sigma^{V-V'-\sO_X^{2r}-\sO_X^{2r'}}(\th^{\Sp,f}_{\sE}(V',\omega')^{-1})\circ {can}\\= \th^{\Sp,f}_{\sE}(V\oplus V'',\omega\oplus \omega'')\circ \Sigma^{V-V'-\sO_X^{2r}-\sO_X^{2r'}}(\th^{\Sp,f}_{\sE}(V'\oplus V'',\omega'\oplus \omega'')^{-1}).  To check this identity, we note that Lemma~\ref{lem:SympThomMult} gives us the commutativity of the diagrams \[ \xymatrix{  \Sigma^{(V\oplus V'')-(V'\oplus V'')-\sO_X^{2(r+r'')}+\sO_X^{2(r'+r'')}}p_X^*\sE\ar[rrr]^-{can}_-\sim \ar[d]^-{can}_-\wr&&& \Sigma^{-V'+\sO_X^{2r'}}\Sigma^{V-\sO_X^{2r}}p_X^*\sE \ar[dd]_-{\Sigma^{-V'+\sO_X^{2r'}}\th^{\Sp,f}_{\sE}(V,\omega)} \\  \Sigma^{-V'+\sO_X^{2r'}}\Sigma^{-V''+\sO_X^{2r''}}\Sigma^{V\oplus V''-\sO_X^{2(r+r'')}}p_X^*\sE  \ar[d]^-{\Sigma^{-V'+\sO_X^{2r'}}\Sigma^{-V''+\sO_X^{2r''}}\th^{\Sp,f}_{\sE}(V\oplus V'',\omega\oplus\omega'')}\\ \Sigma^{-V'+\sO_X^{2r'}}\Sigma^{-V''+\sO_X^{2r''}}p_X^*\sE&&& \Sigma^{-V'+\sO_X^{2r'}}p_X^*\sE\ar[lll]^-{\Sigma^{-V'+\sO_X^{2r'}}\Sigma^{-V''+\sO_X^{2r''}}\th^{\Sp,f}_{\sE}(V'',\omega'')} } \] and \[ \xymatrixcolsep{30pt} \xymatrix{ \Sigma^{-V'+\sO_X^{2r'}}\Sigma^{-V''+\sO_X^{2r''}}p_X^*\sE\ar[d]^-{can}_-\wr&&&& \Sigma^{-V'+\sO_X^{2r'}}p_X^*\sE\ar[llll]_-{\Sigma^{-V'+\sO_X^{2r'}}\Sigma^{-V''+\sO_X^{2r''}}\th^{\Sp,f}_{\sE}(V'',\omega'')}\\ \Sigma^{-(V'\oplus V'')+\sO_X^{2r'+2r''}}p_X^*\sE&&&& \ar[llll]^-{\Sigma^{-(V'\oplus V'')+\sO_X^{2r'+2r''}}\th^{\Sp,f}_{\sE}(V'\oplus V'',\omega'\oplus \omega'')}p_X^*\sE,\ar[u]^-{\Sigma^{-V'+\sO_X^{2r'}}\th^{\Sp,f}_{\sE}(V',\omega')} } \] which together yield the identity \eqref{mult:Identity}.  Since $\sK^\Sp(X)$ is formed from $\sS{p}(X)_{st}$ by localization, the naturality on  $\sK^\Sp(X)$ follows from the naturality on $\sS{p}(X)_{st}$. We have then proved the extra statement ($3'$).  Having proved (3${}'$), (1) follows by composing $\th^{\Sp,f}_{\sE}(-)$ with the unit map  \[ \Sigma^{(-)-\sO_X^{\rnk(-)}}\epsilon_{p_X^*\sE}:\Sigma^{(-)-\sO_X^{\rnk(-)}}1_X\to \Sigma^{(-)-\sO_X^{\rnk(-)}}p^*_X\sE.  \]  For (2), let us suppose we are given two isomorphisms of symplectic vector bundles $f_1, f_2:(V,\omega)\to (V', \omega')$ of rank $2r$. It follows from (3${}'$) that $$\Sigma^{f_i}:\Sigma^{V-\sO_X^{2r}}p_X^*\sE\to \Sigma^{V'-\sO_X^{2r}}p_X^*\sE,$$ for $i=1,2$, are both equal to $(\th^{\Sp,f}_{\sE}(V',\omega'))^{-1}\circ \th^{\Sp,f}_{\sE}(V,\omega)$. This shows that the functor  $\Sigma^{(-)-\sO_X^{\rnk(-)}}p^*_X\sE$ descends to $K_0^\Sp(X)$.   Finally, (3) follows directly from (3${}'$) and (2).",2502.01404
proof,"First, let us note that $\E''$ is the homotopy cofiber of $\E' \to \E$. Thus, if $\E'$ and $\E$ are cellular, so is $\E''$ since $\langle E \rangle$ is closed with respect to homotopy colimits, and in particular homotopy cofibers.      For the other two cases, we can simply observe that $\E'$ is the homotopy cofiber of $\Sigma^{-1,0}\E \to \Sigma^{-1,0}\E''$, and $\E$ is the homotopy cofiber of $\Sigma^{-1,0}\E'' \to \E'$, and the $\Sigma^{-1,0}$-suspension of a cellular spectrum is cellular by definition. In both cases, the result follows because $\langle E \rangle$ is closed by homotopy cofibers.",2502.01404
proof,"Let $i_0(X)$ be the maximum index $i$ such that $F^iX$ is not empty; we proceed by induction on $i_0(X)$. We may also assume that $X$ is irreducible and is not the empty scheme. Let $d \coloneqq \dim_kX\ge0$.  If $i_0(X)=0$, then $X=F^0X=F^0X \setminus F^1X$ is a disjoint union of a finite number $n$ of copies of $\A^d_k$. Thus, $$\Sigma_{\P^1}^\infty X_+ = \Sigma_{\P^1}^\infty (\A^d _{k+})^{\vee n} \simeq\Sigma_{\P^1}^\infty (\Spec k _+)^{\vee n} \simeq \oplus_{i=1}^n \mathbb{S}_k$$ is $\mathbb{S}_k$-cellular.  Suppose now that $i_0:=i_0(X)>0$. Then $F^{i_0}X=F^{i_0}X\setminus F^{i_0+1}X$ is the disjoint union of a finite number $n$ of copies of $\A^{d-i_0}_k$, and as above, we find that $\Sigma_{\P^1}^\infty F^{i_0}X_+\simeq \oplus_{i=1}^n \mathbb{S}_k$ is $\mathbb{S}_k$-cellular. Let $j:U\to X$ be the open subscheme $X\setminus F^{i_0}X$, with closed complement $i:Z:=F^{i_0}X\to X$. Let $F^iU:= F^iX\setminus Z$. This defines a filtration $$U=F^0U\supset F^1U\supset\ldots\supset F^{d+1}U=\0$$ which exhibits $U$ as a cellular scheme in $\Sm/k$, with $i_0(U)<i_0(X)$. By induction, $\Sigma_{\P^1}^\infty U_+ \in \SH(k)$ is $\mathbb{S}_k$-cellular.  On the other hand, by Proposition \ref{prop:localization}, we have a distinguished triangle     $$j_!j^!1_X \to 1_X \to i_*i^* 1_X \to j_!j^!1_X[1]$$     in $\SH(X)$. Let $p:X \to \Spec k$ be the structure map. By applying $p_\#$ to the distinguished triangle above, we get the distinguished triangle                   p_\# j_! j^! 1_X \to \Sigma_{\P^1}^\infty X_+ \to p_\#i_*i^*1_X \to  p_\# j_! j^! 1_X[1],            Since a distinguished triangle is in particular a cofiber sequence, by Proposition \ref{prop:s.e.s.-cellularity}, it is enough to prove that the left hand term and the right hand term of \eqref{eq:cellularschemes} are $\mathbb{S}_k$-cellular.      Let us look at the left hand term $p_\# j_! j^! 1_X$. Since $j$ is an open immersion, we have $j^! \simeq j^*$ and $j_! \simeq j_\#$ by Remark \ref{rmk:etalemaps}. Then $p_\# j_! j^! 1_X \simeq p_{U\#}1_U \simeq \Sigma_{\P^1}^\infty U_+$, where $p_U:U \to \Spec k$ is the structure map, and we have already shown that $\Sigma^\infty_{\P^1}U_+$ is $\mathbb{S}_k$-cellular.      Let us now look at the right-hand term $p_\#i_*i^*1_X \simeq p_\#i_*1_Z$. We note that $Z$ is a disjoint union of affine spaces $\A^{d-i_0}_k$, is in $\Sm/k$. By Theorem \ref{thm:MorVoePurity}, $p_\#i_*1_Z \simeq p_{Z\#}\Sigma^{N_i}1_Z$, where $p_Z:Z \to \Spec k$ is the structure map, and $N_i$ is the normal bundle of $i$. Now, by $\A^1$-homotopy invariance of $K_0$ \cite[Corollary to Theorem 8, p. 122]{Quillen:K}, we have $K_0(\A_k^n)\simeq K_0(\Spec k)$ for all $n\ge 0$, and $K_0(\Spec k)$ is isomorphic to $\Z$ through the rank homomorphism. Then on each component $\A_k^{d-i_0}$ of $Z$, we have $[N_i\mid_{\A_k^{d-i_0}}]=i_0[\sO_{\A_k^{d-i_0}}]$ in $K_0(\A_k^{d-i_0})\simeq \Z$. Thus, $[N_i]=i_0[\sO_Z]$ in $K_0(Z)$. Thus, since the isomorphism class of      $p_{Z\#}\Sigma^{N_i}1_Z$ in $\SH(k)$ only depends on the $K_0$-class of $N_i$, we get     $$p_{Z\#}\Sigma^{N_i}1_Z \simeq p_{Z\#}\Sigma^{2i_0, i_0}1_Z \simeq \Sigma^{2i_0, i_0}\Sigma^\infty_{\P^1}Z_+\simeq  \oplus_{i=1}^n\Sigma^{2i_0,i_0} \mathbb{S}_k.$$     Therefore, $p_{Z\#}\Sigma^{N_i}1_Z$ is $\mathbb{S}_k$-cellular.",2502.01404
proof,"For $\Sigma^\infty_{\P^1}V_+$, we have $\Sigma^\infty_{\P^1}V_+\simeq \Sigma^\infty_{\P^1}X_+$ by homotopy invariance, and $\Sigma^\infty_{\P^1}X_+$ is $\mathbb{S}_k$-cellular by Lemma~\ref{lemma:cellularSchemes}.  For $\Sigma^\infty_{\P^1}V^0_+$, we retain the notation of the proof of Lemma \ref{lemma:cellularSchemes} and use a similar induction on $i_0(X)$.  If $i_0(X)=0$, $X=F^0X=F^0X \setminus F^1X$ is a disjoint union of a finite number $n$ of copies of $\A^d_k$, with $d=\dim_kX$. By reasoning as in the last part of the proof of Lemma \ref{lemma:cellularSchemes}, with $V$ instead of $N_i$, we find that $[V]=r[\sO_{\A_k^d}]$ in $K_0(X)$, and  $$\Sigma_{\P^1}^\infty\Th(V)\simeq p_{X\#}\Sigma^V1_X \simeq \oplus_{i=1}^n\Sigma^{2r,r}\mathbb{S}_k$$ is $\mathbb{S}_k$-cellular. Also, $\Sigma_{\P^1}^\infty V_+^0$ fits in the distinguished triangle $$\Sigma_{\P^1}^\infty V_+^0 \to \Sigma_{\P^1}^\infty V_+ \to \Sigma^\infty_{\P^1}\Th(V) \to \Sigma_{\P^1}^\infty V_+^0[1]$$ in $\SH(k)$ (see triangle \eqref{eq:thom-loc3}). Thus, $\Sigma_{\P^1}^\infty V_+^0$ is $\mathbb{S}_k$-cellular by Proposition \eqref{prop:s.e.s.-cellularity}.  Let now $i_0:=i_0(X)>0$, and let us assume that the statement is true for any $X'$ with $i_0(X')<i_0$. Following the proof of Lemma~\ref{lemma:cellularSchemes}, we have the closed immersion $i:Z:=F^{i_0(X)}\hookrightarrow X$ with open complement $j:U:=X\setminus Z\hookrightarrow X$, with $i_0(U)<i_0(X)$. $V^0$ maps to $X$ through $\pi^0\coloneqq \pi\mid_{V^0}$. This gives us the open subscheme $\tilde{j}:j^*V^0\to V^0$ of $V^0$ with closed complement $\tilde{i}:i^*V^0\to V^0$. We have the cartesian square $$      i^*V \arrow[r, hook, ""\tilde{i}""] \arrow[d, swap, ""\pi^0_Z""] & V^0 \arrow[d, ""\pi^0""] \\     Z \arrow[r, hook, ""i""] & X  $$ As in the proof of Lemma~\ref{lemma:cellularSchemes}, the $K_0$-class of the normal bundle $N_i$ of $i$ in $K_0(Z)$ is the $K_0$-class of the trivial rank $i_0$ vector bundle on $Z$, which implies that the $K_0$-class of the normal bundle $N_{\tilde{i}}$ of $\tilde{i}$ in $K_0(i^*V^0)$ is the $K_0$-class of the trivial rank $i_0$ vector bundle on $i^*V^0$, since $N_{\tilde{i}}$ is the pullback $(\pi^0_Z)^*N_i$. This gives us the distinguished triangle \[ \Sigma^\infty_{\P^1}(j^*V^0)_+\to \Sigma^\infty_{\P^1}V^0_+\to \Sigma^{2i_0, i_0}\Sigma^\infty_{\P^1}(i^*V^0)_+\to  \Sigma^\infty_{\P^1}(j^*V^0)_+[1] \]  in $\SH(k)$ by Proposition \ref{prop:localization}. Because of Proposition \ref{prop:s.e.s.-cellularity}, it is enough to prove that $\Sigma^\infty_{\P^1}(j^*V^0)_+$ and $\Sigma^{2i_0, i_0}\Sigma^\infty_{\P^1}(i^*V^0)_+$ are $\mathbb{S}_k$-cellular.   $\Sigma^\infty_{\P^1}(j^*V^0)_+$ is $\mathbb{S}_k$-cellular by the induction hypothesis.  Using once again the $\A^1$-homotopy invariance of $K_0$ and the fact that $Z$ is a disjoint union of a finite number $m$ of copies of $\A^{d-i_0}$, we find that the $K_0$-class of $i^*V$ in $K_0(Z)$ is the $K_0$-class of the trivial rank $r$ vector bundle on $Z$. Thus, $\Sigma^\infty_{\P^1}(i^*V)_+\cong \Sigma^\infty_{\P^1}Z_+$ and $\Sigma^{i^*V}1_Z\cong \Sigma^{2r, r}1_Z$, so $\Th(i^*V)\cong \Sigma^{2r,r}\Sigma^\infty_{\P^1}Z_+$. Using again the distinguished triangle \eqref{eq:thom-loc3} we see that $\Sigma^{2i_0, i_0}\Sigma^\infty_{\P^1}(i^*V^0)_+$ is  $\mathbb{S}_k$-cellular. This concludes the proof.",2502.01404
proof,"[Proof of Theorem \ref{thm:mglcellular}]     By Remark \ref{rmk:MGLcolim}, $\MGL$ is isomorphic to the homotopy colimit of the system     $$\Sigma^\infty_{\P^1}\MGL_0 \to \Sigma^{-2,-1}\Sigma^\infty_{\P^1}\MGL_1 \to \Sigma^{-4,-2}\Sigma^\infty_{\P^1}\MGL_2 \to \ldots \; .$$      Thus, we need to prove that $\Sigma_{\P^1}^\infty \MGL_r$ is cellular for all $r$. $\MGL_r=\Th(E_r)$ is in turn the colimit $\colim_n\Th(E_{r,n})$, with $E_{r,n}$ the tautological rank $r$ vector bundle over $\Gr(r,n)$. Thus, we have $\Sigma_{\P^1}^\infty \MGL_r \simeq \colim_n \Sigma_{\P^1}^\infty \Th(E_{r,n})$, and such colimit, as a filtered colimit, is a homotopy colimit. We then need to prove that $\Sigma_{\P^1}^\infty \Th(E_{r,n})$ is cellular.           $\Th(E_{r,n})$ fits in the cofiber sequence     $$\Sigma_{\P^1}^\infty E_{r,n \; +}^0 \to \Sigma_{\P^1}^\infty E_{r,n \; +} \to \Sigma_{\P^1}^\infty \Th(E_{r,n}),$$     where $E_{r,n}^0$ is the open complement of the zero section. Thus, by Proposition \ref{prop:s.e.s.-cellularity}, it is enough to prove that the spectra $\Sigma_{\P^1}^\infty E_{r,n \; +}^0$ and $\Sigma_{\P^1}^\infty E_{r,n \; +}$ are cellular.       The classical Schubert cell decomposition for Grassmannians through Schubert varieties gives the Grassmannian $\Gr(r,n)$ the structure of a cellular scheme. The decomposition is described in \cite[Chapter 1, Section 5]{Griffith:AlgGeom} over $k=\C$, but the description works over any field $k$, and it is straightforward to see that it satisfies the condition of Definition \ref{defn:CellularSchemes}. Therefore, $\Sigma_{\P^1}^\infty E_{r,n \; +}^0$ and $\Sigma_{\P^1}^\infty E_{r,n \; +}$ are cellular spectra by Lemma \ref{lemma:cellularSchemes2}.",2502.01404
proof,"Let us fix $n$ and $i$. Since $X_{2n}=\mathbb{A}^{2n}$, we can suppose $i<n$. By construction, $X_{2i}$ is the subspace of $\HP^n$ classifying the $2$-dimensional subspaces $\Pi$ of $V=\langle x_1, \ldots x_{n+1},y_{n+1}, \ldots y_1 \rangle$ symplectic with respect to $\phi$ that are also subspaces of $\langle x_1, \ldots x_{n+1},y_{n+1}, \ldots y_{i+1} \rangle$ but are not subspaces of $\langle x_1, \ldots x_{n+1}, y_{n+1}, \ldots, y_{i+2}\rangle$. Therefore, a point in $X_{2i}$ is defined (not uniquely) by two linearly independent vectors $e=(e_1, \ldots, e_{2n+2-i})$ and $f=(f_1, \ldots, f_{2n+2-i})$ in $V$ such that $e_{2n+2-i}$ and $f_{2n+2-i}$ are not both zero and $\phi(e,f)\neq 0$.      Consider now the restriction of the rank $2$ universal bundle $\pi_{\mathcal{U}}: \mathcal{U} \to X_{2i}$, with $\mathcal{U}\coloneqq E_{2,2n}^\Sp \mid_{X_{2i}}$. A point in the total space of $\mathcal{U}$ over $X_{2i}$ is then a pair $u=(\Pi,v)$, with $\Pi \in X_{2i}$ identifying a certain two-dimensional vector space, and $v=(v_1,\ldots, v_{2n+2-i})$ a vector of $\Pi$. Let       \lambda : \mathcal{U} & \to \mathcal{O}_S \\     u & \mapsto v_{2n+2-i}  be the map taking the coefficient of $y_{i+1}$ of the vector $v$. Let $Y \coloneqq \lambda^{-1}(1)$, and consider the induced map $\pi :=\pi_Y: Y \to X_{2i}$. We want to use this map to define a homotopy equivalence between $X_{2i}$ and a contractible space.  First, we need to show that $\pi: Y \to X_{2i}$ is an affine space bundle, with fibre $\A^1$.  We note that the map $\lambda$ is surjective. In fact, for any $0\neq t \in \A^1$, we can take $e \in V$ as the vector with $e_{2n+2-i}=T$ and $e_j=0$ for $j \neq 2n+2-i$, and $f \in V$ as any vector with $f_{i+1} \neq 0$ and $f_j=0$ for all $j \neq i+1$. In this way, we have that $\lambda(\langle e,f \rangle,e)=t$, and $\lambda (\langle e,f \rangle,f)=0$. Thus, $\lambda$ is surjective. Therefore, $\Ker(\lambda)$ is a vector subbundle of $\mathcal{U}$ of rank 1, and thus $\lambda^{-1}(1)=Y \to X_{2i}$ is a torsor for the line bundle $\Ker(\lambda)$. In particular, $\pi:Y \to X_{2i}$ is a Zariski-locally trivial affine space bundle with fibre $\A^1$.  We now want to find an isomorphism between $Y$ and an $\A^1$-contractible scheme.  Let us define $Y' \coloneqq \{(e,f) \in \mathbb{A}^{2n+2-i} \times \mathbb{A}^{2n+2-i} \mid \lambda(e)=0, \; \lambda(f)=1, \; \phi(e,f)=1\}$, where $\lambda$ is the projection on the $(2n+2-i)$-th component, and let us consider the map $\beta: Y' \to Y$ given by $\beta((e,f)):=(\langle e,f \rangle,f).$ We now show that $\beta$ is an isomorphism.   For any $\Pi \in X_{2i}$ and $f$ a vector of $\Pi$ with $f_{2n+2-i}=1$, there is a unique vector $e(\Pi,f)$ in $\Pi$ such that $(e(\Pi,f))_{2n+2-i}=0$ and $\phi(e(\Pi,f),f)=1$. Indeed, $e(\Pi, f)$ can be obtained from any generator $e$ of the one-dimensional vector subspace $\Pi \cap \{y_{i+1}=0\}$ of $\Pi$, noting that $\phi(e,f) \neq 0$ because $\langle e,f \rangle =\Pi$, and then replacing $e$ by $(1/\phi(e,f))\cdot e$. Arguing as for $Y$, we see that sending $(e,f)\in Y'$ to $\langle e,f \rangle\in X_{2i}$ also makes $Y'\to X_{2i}$ a Zariski-locally trivial affine space bundle with fibre $\A^1$. We can show that the map $\beta^{-1}:Y \to Y'$ defined by $\beta^{-1}(\Pi, f):=(e(\Pi,f),f)$ is the inverse of $\beta$. We have $$\beta(\beta^{-1}(\Pi,f))=\beta(e(\Pi,f),f)=(\langle e(\Pi,f),f \rangle, f),$$ but $\langle e(\Pi,f),f \rangle=\Pi$ because $e(\Pi,f)$ and $f$ belong to $\Pi$ and are linearly independent. On the other hand $$\beta^{-1}(\beta(e,f))=\beta^{-1}(\langle e,f \rangle, f)=(e(\langle e,f \rangle,f),f),$$ but $e(\langle e,f \rangle,f)=e$ because $e$ is the only vector of $\langle e,f \rangle$ such that $e_{2n+2-1}=0$ and $\phi(e,f)=1$. Since $\beta$ and $\beta^{-1}$ are affine linear maps on the fibers of $Y$ and $Y'$ over $X_{2i}$, we conclude that $\beta$ is an isomorphism.  Finally, we observe that $Y'$ is isomorphic to $\A^{4n+1-2i}$ through  $$\varphi:(e,f) \mapsto (e_1,\ldots, e_i, e_{i+1}, \ldots, e_{2n+1-i}, f_1, \ldots , f_{2n+1-i}).$$ In fact, once fixed these $4n+1-2i$ components for the vectors $(e,f)$, the remaining $3$ components are determined by definition of $Y'$. In particular, $e_{2n+2-1}=0$, $f_{2n+2-i}=1$, and $e_i$ is determined by the condition $\phi(e,f)=1$.  We have then proved that there exists a map $\A^{4n+1-2i} \to X_{2i}$ which is a Zariski-locally trivial $\A^1$-bundle. Thus, $X_{2i}$ is smooth of dimension $4n-2i$ over $k$, and is $\A^1$-contractible in $\sH(k)$.",2502.01404
proof,"We can prove the statement for all the closed strata $\overline{X}_{2n-2i}$ by induction on $i$. Since $\HP^n=\overline{X}_0$, the case $i=n$ will give us the result.  For $i=0$, we have $X \coloneqq \overline{X}_{2n}\simeq \mathbb{A}^{2n}$. Let $p :=p_X$. By the already mentioned $\A^1$-invariance of $K_0$ \cite[Corollary to Theorem 8]{Quillen:K}, the map $\rnk:K_0(\A^{2n})\to \Z$ is a ring isomorphism. Thus, for $v \in K_0(\A^{2n})$ of virtual rank $r$, we have $p_\#\Sigma^v1_X \simeq \Sigma^{2r,r}p_\#1_X \simeq \Sigma^{2r,r}\Sigma_{\P^1}^\infty \A^{2n}_+$, and since $\A^{2n}$ is a $\A^1$-contractible, this belongs to $\langle \mathbb{S}_k \rangle$.  For $i>0$, we have $X \coloneqq \overline{X}_{2n-2i}=X_{2n-2i}\sqcup X_{2n-2i+2} \sqcup \ldots \sqcup X_{2n}$. In particular, $X$ is the union of the closed stratum $Z \coloneqq \overline{X}_{2n-2i+2}$ and the open cell $U \coloneqq X_{2n-2i}$, which is $\A^1$-contractible by Proposition \ref{prop:contractibleopencellofHPn}.  Let $i:Z \hookrightarrow X$ and $j:U \hookrightarrow X$ the two immersions, with $p_Z:Z \to \Spec k$ and $p_U:U \to \Spec k$ the structure maps. Let us take again $v \in K_0(X)$ of virtual rank $r$. By Proposition \ref{prop:localization}, we have the distinguished triangle $$p_{\#}j_!j^!\Sigma^v1_X \to p_{\#}\Sigma^v1_X \to p_{\#}i_*i^*\Sigma^v1_X \to p_{\#}j_!j^!\Sigma^v1_X[1]$$ in $\SH(k)$. By proposition \ref{prop:s.e.s.-cellularity}, in order to get $p_{\#}\Sigma^v1_X \in \langle \mathbb{S}_k \rangle$ it is sufficient to show that the left-hand term and the right-hand term of the above sequence belong to $\langle \mathbb{S}_k \rangle$.   Let us see the left-hand term $p_{\#}j_!j^!\Sigma^v 1_X$. Since $j$ is an open immersion, we have $j_!=j_{\#}$ and $j^! \simeq j^*$ by Remark \ref{rmk:smoothsharp}, and since $U$ is smooth over the base, we have  $p_{\#}j_!j^!\Sigma^v1_X\simeq p_{U\#}j^*\Sigma^v1_X.$ Now, since $U$ is contractible and algebraic $K$-theory is representable in $\SH(k)$ (see Example \ref{exmp:KGL}), we have again that the map  $\rnk:K_0(U) \to \Z$ is an isomorphism of abelian groups, and $j^*\Sigma^v1_X=\Sigma^{j^*v}1_U \simeq \Sigma^{2r,r}1_U$. Thus,  $$p_{U\#}j^*\Sigma^v1_X \simeq p_{U\#}\Sigma^{2r,r}1_U \simeq \Sigma^{2r,r}\Sigma^\infty_{\P^1}\Spec k_+$$  belongs to $\langle \mathbb{S}_k \rangle$.   For the right-hand term, we recall that $\overline{X}_{2n-2i+2}=\Gr(2, E_{n-i+1}^\perp)\cap \HP^n$, and as $\HP^n$ is an open subscheme of $\Gr(2,2n+2)$, $Z=\overline{X}_{2n-2i+2}$ is an open subscheme of the smooth $k$-scheme $\Gr(2, E_{n-i+1}^\perp)$, and hence is smooth. Thus, by Theorem \ref{thm:MorVoePurity} we have:  $$p_{\#}i_*i^*\Sigma^v1_X \simeq p_{Z\#}\Sigma^{N_i}i^*\Sigma^v1_X \simeq p_{Z\#}\Sigma^{N_i+i^*v}1_Z.$$ We can now use our induction hypothesis and we get that $p_{Z\#}\Sigma^{N_i + i^*v}1_Z$ belongs to $\langle \mathbb{S}_k \rangle$.   Therefore, we conclude that $p_{\#}\Sigma^v1_{\HP^n}$ belongs to $\langle \mathbb{S}_k \rangle$.",2502.01404
proof,"Since $Y_1=\lambda^{-1}(1)$, the map $g_1$ is the restriction of the projection $\mathcal{U}\to Y$ to a Zariski closed subscheme of $\mathcal{U}. $ $Ker\lambda$ is a subbundle of rank $2r-1$ of $\mathcal{U}$, and fiberwise, it acts freely on $\mathcal{U}$ by translations. Since this action preserves the image of $\lambda$, it induces an action on $Y_1$. Since the action is fiberwise it preserves $Y$, and $Y$ is obtained as the quotient of $Y_1$ by this action. By construction, $\lambda$ is surjective. For example, for $0 \neq t \in \A^1$, on can take $[y]:= \langle x_1, \ldots, x_r,y_r,\ldots, t \cdot y_1 \rangle$, and we have $\lambda(y, t \cdot y_1)=t$, and $\lambda(y,x_1)=0$. Thus, $Y_1 \to Y$ is a torsor for the vector subbundle $\Ker\lambda$, and since $\Ker\lambda \to Y$ is a rank $(2r-1)$ vector bundle, $g_1$  is a Zariski-locally trivial affine space bundle with fibre $\mathbb{A}^{2r-1}$.  In order to obtain the statement for $g_2$, let us consider the rank $2r-1$ vector bundle $g_1^*\Ker\lambda$ over $Y_1$. A point in this bundle will then be identified by a point $(y,f)$ in $Y_1$ and a point $e$ in its fiber, or in other words, will be a triple $(y,e,f)$ with $y$ in $Y$, and $e,f$ two vectors in $[y]$, with $\lambda(f)=1$ and $\lambda(e)=0$. We then get a surjective map of vector bundles       \lambda':g_1^*\Ker\lambda & \to \mathcal{O}_S\\     (y,e,f) &\mapsto \psi(e,f),  and $Y_2=\lambda'^{-1}(1)$. $Y_2$ is then a Zariski closed subscheme of the vector bundle $g_1^{-1}Ker\lambda$ over $Y_1$, and $Ker\lambda'$ is a subbundle of rank $2r-2$ that acts fiberwise on $g_1^{-1}Ker\lambda$ by translations. The induced map $Y_2 \to Y_1$ is the map $(y,e,f) \mapsto (y,f)$, that is, the map $g_2$. By applying the previous argument to this situation, we obtain that $g_2$ is a Zariski locally trivial affine space bundle with fiber $\mathbb{A}^{2r-2}$.",2502.01404
proof,"Firstly, let us note that the vector space $V$ can be written as $\langle x_1 \rangle \oplus V' \oplus \langle y_1 \rangle$, with $V' = \langle x_2, \ldots, x_n, y_n, \ldots, y_2 \rangle$. $V'$ equipped with the symplectic structure induced by $\phi$ is a symplectic vector subspace of $V$, and we can identify $\HGr(r-1,n-1)$ with $\HGr(r-1,V')$. A point of $\Tilde{Y}\times \HGr(r-1,n-1)$ is then a triple $(e,f,x)$ with $e,f$ vectors of $V$ satisfying the three conditions requested for $\Tilde{Y}$, and $x$ classifying a symplectic subspace $[x]$ of $V'$ of rank $2r-2$. One can associate to the pair of vectors $(e,f)$ two invertible matrices $$\rho_e=      1 & 0 & 0 & & \ldots  &  & & & 0 \\     e_2 & 1 & 0 & & & & & & 0 \\     e_3 & 0 & 1 & 0 & & 0 & & & \ldots \\     \ldots  & & & 1 & & & & & \ldots \\     \ldots & & & & 1 & & & & \ldots \\     \ldots & & 0 & & & 1 & & & \ldots \\     e_{2n-2} & & & & & & 1 & & 0 \\     e_{2n-1} & & & & & \ldots & 0 & 1 & 0 \\     0 & -e_{2n-1} & -e_{2n-2} & \ldots & -e_{n+1} & e_{n} & \ldots & e_{2} & 1 ,$$  $$\rho_f=      1 & -f_{2n-1} & -f_{2n-2} & \ldots & -f_{n+1} & f_n & \ldots & f_2 & f_1 \\     0 & 1 & 0 & & & & & & f_2 \\     0 & 0 & 1 & 0 & & & 0 & & f_3 \\     \ldots  & & & 1 & & & & & \\     \ldots & & & & 1 & & & & \ldots \\     \ldots & & 0 & & & 1 & & & \ldots \\     \ldots & & & & & & 1 & & \\     0 & & & & & & 0 & 1 & f_{2n-1} \\     0 & & & \ldots & & & & 0 & 1 . $$ Let now $\rho_{e,f}\coloneqq \rho_f \cdot \rho_e$. We get $\rho_{e,f}(x_1)=\rho_f(1, e_2, \ldots, e_{2n-1},0)=e$, and $\rho_{e,f}(y_1)=\rho_f(y_1)=f$. It is immediate to see that $\rho_{e,f}$ preserves the form $\phi$:  $$\rho_{e,f}^T \cdot \phi \cdot \rho_{e,f}=\rho_e^T\cdot \rho_f^T \cdot \phi \cdot \rho_f \cdot \rho_e = \rho_e^T \cdot \phi \cdot \rho_e = \phi.$$ Thus, for each symplectic subspace $W$ of $V$, $\rho_{e,f}$ maps $W^{\perp}$ isometrically to $(\rho_{e,f}(W))^{\perp}$. In particular, $\rho_{e,f}(V')=\rho_{e,f}(\langle x_1,y_1\rangle^{\perp}) \simeq \langle e,f \rangle^{\perp}$. We can then define a map:      \gamma:\Tilde{Y}\times \HGr(r-1,n-1) & \to Y_2 \\     ((e,f),x) & \mapsto (\rho_{e,f}([x])\oplus \langle e \rangle \oplus \langle f \rangle, e, f),  and note that this is an isomorphism with inverse      \gamma^{-1}: \; \;  Y_2 & \to \Tilde{Y}\times \HGr(r-1,n-1)\\     (y,e,f) & \mapsto ((e,f), \rho_{e,f}^{-1}([y])\cap V').",2502.01404
proof,"We can prove this statement for all $n \ge r \ge 0$ by induction on $r$.  For $r=0$ the statement is trivial, and for $r=1$, $\HGr(r,n)=\HP^{n-1}$, so the statement follows from Proposition \ref{prop:vectorbundlesonHPn}. We can then assume $r>1$ and proceed by induction on $n \ge r$.  For $n=r$ and $n=r+1$, $\HGr(r,n)$ is isomorphic to $\Spec k$ and $\HP^r$ respectively. So we can assume $n>r+1$.  Let us denote by $Z$ and $Y$ respectively the closed subscheme $N^+$ of $\HGr(r,n)$ and its open complement. Since $N^+\to \HGr(r,n-1)$ is a rank $2r$ vector bundle, $Z$ is smooth over $k$ of codimension $2r$ in $\HGr(r,n)$.  From the diagram            Z \arrow[r, hookrightarrow, ""i""] \arrow[dr, ""p_Z"", swap] & \HGr(r,n) \arrow[d, ""p""] & Y \arrow[l, hook', ""j"", swap] \arrow[dl, ""p_Y""] \\     & \Spec k &   we get the localization distinguished triangle $$j_!j^! \to \id_{\SH(\HGr(r,n))} \to i_*i^* \to j_!j^![1]$$ of endofunctors of $\SH(\HGr(r,n))$, by Proposition \ref{prop:localization}. By composing this sequence with $p_{\#}$ and applying it to $\Sigma^v1_{\HGr(r,n)}$, we get the cofiber sequence in $\SH(k)$           p_{\#}j_!j^!\Sigma^v1_{\HGr(r,n)} \to p_{\#}\Sigma^v1_{\HGr(r,n)} \to p_{\#}i_*i^*\Sigma^v1_{\HGr(r,n)}.    By Proposition \ref{prop:s.e.s.-cellularity}, we just need to show that the left-hand term and the right-hand term of \eqref{eq:s.e.s.ofThomSpaces} belong to $\langle \mathbb{S}_k \rangle$.  Let us see the left-hand term first. Because $j$ is an open immersion, we have $j_!\simeq j_\#$ and $j^!\simeq j^*$, then $$p_{\#}j_!j^!\Sigma^v1_{\HGr(r,n)}\simeq p_{Y\#}j^*\Sigma^v1_{\HGr(r,n)} \simeq p_{Y\#}\Sigma^{j^*v}1_Y.$$  By Proposition~\ref{prop:summary}, we have the diagram $$     &&Y_2 \arrow[dl, swap, ""g_2""] \arrow[dr, ""q""]& \\     &Y_1 \arrow[dl, swap, ""g_1""]&&\HGr(r-1,n-1)\\     Y &&&     $$ where the maps $g_1,g_2$ and $q$ are $\mathbb{A}^1$-weak equivalences, in fact, affine space bundles. Moreover, $q$ is a trivial $\mathbb{A}^{4n-3}$-bundle, hence, it has a zero section $s_0:\HGr(r-1,n-1) \to Y_2$, which is an inverse of $q$ in $\sH(k)$. The composition $h \coloneqq g_1 \circ g_2 \circ s_0: \HGr(r-1,n-1) \to Y$ is thus an $\mathbb{A}^1$-weak equivalence.  Now, $g_1,g_2$ and $q$ are affine space bundles, and $Y_1$, $Y_2$ and  $\HGr(r-1,n-1)$ are smooth, hence, by $\A^1$-homotopy invariance of $K$-theory on regular schemes \cite[\S7 paragraph 1, and Proposition 4.1]{Quillen:K}, the maps $q^*:K_0(\HGr(r-1,n-1))\to K_0(Y_2)$ and $(g_1g_2)^*:K_0(Y)\to K_0(Y_2)$ are isomorphisms. Thus, there is an element $v'\in K_0(\HGr(r-1,n-1))$ such that $q^*v'=(g_1g_2)^*j^*v$ in $K_0(Y_2)$, and, since $g_1,g_2$ and $q$ are $\A^1$ weak equivalences, we have $$ p_{Y\#}\Sigma^{j^*v}1_Y \simeq p_{(\HGr(r-1,n-1)\#}\Sigma^{v'}1_{\HGr(r-1,n-1)} $$ in $\SH(k)$.  By the induction hypothesis on $r$, we conclude that $p_{Y\#} \Sigma^{j^*v}1_Y$ belongs to $\langle \mathbb{S}_k \rangle$.  Let us now prove the claim for the right-hand term of \eqref{eq:s.e.s.ofThomSpaces}. Let us recall that $Z$ is isomorphic to the tautological rank $2r$ symplectic bundle over $\HGr(r,n-1)$, and as such, it is a smooth scheme with projection $q:Z\to \HGr(r,n-1)$ realizing $Z$ as a vector bundle over $\HGr(r,n-1)$. For simplicity, let us call $X \coloneqq \HGr(r,n)$. By Theorem \ref{thm:MorVoePurity}, we have $$p_{\#}i_*i^*\Sigma^v1_X \simeq p_{Z\#}\Sigma^{N_i}i^*\Sigma^v1_X \simeq p_{Z\#}\Sigma^{N_i+i^*v}1_Z.$$  Since the morphism $q:Z\to \HGr(r,n-1)$ realizes $Z$ as a vector bundle over $\HGr(r,n-1)$, there is an element $v''\in K_0(\HGr(r,n-1))$ such that $q^*v''=i^*v+N_i$ in $K_0(Z)$. Since $q$ is an $\A^1$-weak equivalence, $$p_{Z\#}\Sigma^{N_i + i^*v}1_Z\simeq p_{\HGr(r,n-1)\#}\Sigma^{v''}1_{\HGr(r,n-1)}.$$ By our induction hypothesis, we have that $p_{Z\#}\Sigma^{N_i + i^*v}1_Z$ belongs to $\langle \mathbb{S}_k \rangle$.  Therefore, we conclude that $p_{\#}\Sigma^V1_{\HGr(r,n)}$ belongs to $\langle \mathbb{S}_k \rangle $.",2502.01404
proof,"By definition, $\MSp$ is isomorphic to the filtered colimit of the system     $$\Sigma^\infty_{\P^1}\MSp_0 \to \Sigma^{-4,-2}\Sigma^\infty_{\P^1}\MSp_2 \to \Sigma^{-8,-4} \Sigma_{\P^1}^\infty \MSp_4 \to \ldots,$$     which is in particular a homotopy colimit. Thus, it is enough to show that $\Sigma^\infty_{\P^1}\MSp_{2r}$ is cellular for all $r$. $\MSp_{2r}$ is in turn the homotopy colimit $\colim_n\Th(E_{r,n}^{\Sp})$, where $E_{r,n}^{\Sp}$ is the tautological rank $2r$ symplectic bundle over the quaternionic Grassmannian $\HGr(r,n)$. It is then enough to prove that $\Sigma^\infty_{\P^1}\Th(E_{r,n}^\Sp)$ is cellular for all $r,n$. Since $\Sigma^\infty_{\P^1}\Th(E_{r,n}^\Sp)=p_{\HGr(r,n)\#}\Sigma^{E_{r,n}^\Sp}1_{\HGr(r,n)}$, this follows from Proposition \ref{prop:bundlesonHGr}.",2502.01404
proof,"First, by adapting the proof of Proposition \ref{prop:bundlesonHGr}, we prove that for all $n \ge r \ge 0$, the $H\Z$-module $\Sigma^\infty_{\P^1} \HGr(r,n)_+ \wedge H\Z$ is of the form $\oplus_s \Sigma^{4m_s,2m_s}H\Z$, for a finite number of non-negative integers $m_s$.       For $r=0$ or $r=n$, we have $\Sigma^\infty_{\P^1} \HGr(r,n)_+\simeq \Sigma^\infty_{\P^1}\Spec k_+=\mathbb{S}_k$, and the statement trivially holds. We can then take $n>r>0$ and suppose the claim true for all quaternionic Grassmannians $\HGr(r',n')$ with $r'\le r$ and $n'<n$, or $r'<r$ and $n'\le n$.       As in the diagram \eqref{diag:loc.sequence.HGr}, we consider $i:Z \hookrightarrow \HGr(r,n)$ the inclusion of the closed subscheme $Z \coloneqq N^+$, and $j:Y \hookrightarrow \HGr(r,n)$ its open complement, and we get the localization distinguished triangle              j_!j^! \to \id_{\SH(\HGr(r,n))} \to i_*i^* \to j_!j^![1].           Let $X\coloneqq \HGr(r,n)$ and let $p:X \to \Spec k$ be the structure map. By applying the sequence above to $1_X$, and applying $p_\#(-)\wedge H\Z$ to the resulting distinguished triangle in $\SH(X)$, we get the distinguished triangle                       p_\#j_!j^!1_X \wedge H\Z \to \Sigma^\infty_{\P^1}X_+ \wedge H\Z \to p_\# i_*i^*1_X \wedge H\Z \xrightarrow{\alpha} j_!j^!1_X[1] \wedge H\Z          in $\DM(k)$. By the same arguments as in the proof of Proposition \ref{prop:bundlesonHGr}, we have $p_\#j_!j^!1_X \simeq p_{Y\#}1_Y$ and $p_\#i_*i^*1_X \simeq p_{Z\#}\Sigma^{N_i}1_Z$, with $N_i$ the normal bundle of $i$.          For the remainder of the proof, except where indicated to the contrary, we will work in $\DM(k)$.    Let us look at the right-hand term $p_{Z\#}\Sigma^{N_i}1_Z \wedge H\Z$ of \eqref{eq:loc.seq.HGr}. Since $p_{Z\#}$ satisfies projection formula against $p_Z^*$ by Remark \ref{rmk:smoothsharp-properties}, we have that $$p_{Z\#}\Sigma^{N_i}1_Z \wedge H\Z \simeq p_{Z\#}(\Sigma^{N_i}1_Z \wedge p_Z^*H\Z) \simeq p_{Z\#}\Sigma^{N_i}p_Z^*H\Z,$$     and through the isomorphism $\th^f_{H\Z \Mod}(N_i)$, we have $p_{Z\#}\Sigma^{N_i}p_Z^*H\Z \xrightarrow{\sim} \Sigma^{4c,2c}p_{Z\#}p_Z^*H\Z$, with $2c$ the codimension of $Z$ in $X$. By the projection formula again, we have $p_{Z\#}p_Z^*H\Z \simeq p_{Z\#}1_Z \wedge H\Z \simeq \Sigma_{\P^1}^\infty Z_+\wedge H\Z$, but $Z$ is a vector bundle over $\HGr(r,n-1)$, so $\Sigma_{\P^1}^\infty Z_+ \simeq \Sigma_{\P^1}^\infty \HGr(r,n-1)_+$. We can then apply the induction hypothesis to get     $$p_{Z\#}\Sigma^{N_i}1_Z \wedge H\Z\simeq \Sigma^{4c,2c}\oplus_i \Sigma^{4m_i^Z,2m_i^Z}H\Z$$     for a finite number of non-negative integers $m_i^Z$.      Let us look at the left-hand term $p_{Y\#}1_Y \wedge H\Z$ of \eqref{eq:loc.seq.HGr}. As seen in the proof of Proposition \ref{prop:bundlesonHGr}, there is an $\A^1$-weak equivalence $h:\HGr(r-1,n-1) \to Y$, then $p_{Y\#}1_Y \wedge H\Z \simeq \Sigma^\infty_{\P^1}Y_+\wedge H\Z \simeq \Sigma_{\P^1}^\infty \HGr(r-1,n-1)_+ \wedge H\Z$. We can then use again our induction hypothesis to get     $$p_{Y\#}1_Y \wedge H\Z\simeq \oplus_{i'} \Sigma^{4m_{i'}^Y,2m_{i'}^Y}H\Z$$     for a finite number of non-negative integers $m_{i'}^Y$.      Now, the boundary map $\alpha$ in \eqref{eq:loc.seq.HGr} is an element in               [p_\# i_*i^*1_X \wedge H\Z,j_!j^!1_X[1] \wedge H\Z]_{\DM(k)}\simeq \\          [\Sigma^{4c,2c}\oplus_i \Sigma^{4m_i^Z,2m_i^Z}H\Z,\Sigma^{1,0}\oplus_{i'} \Sigma^{4m_{i'}^Y,2m_{i'}^Y}H\Z]_{\DM(k)} \simeq \\          \oplus_{i,i'}[\Sigma^{4(c+m_i^Z),2(c+m_i^Z)}H\Z, \Sigma^{4m_{i'}^Y+1,2m_{i'}^Y}H\Z]_{\DM(k)} \simeq \\          \oplus_{i,i'}[H\Z, \Sigma^{4(m_{i'}^Y-m_i^Z-c)+1,2(m_{i'}^Y-m_i^Z-c)}H\Z]_{\DM(k)}.          By the free-forgetful adjunction, this corresponds to an element in     $$\oplus_{i,i'}[1_k, \Sigma^{4(m_{i'}^Y-m_i^Z-c)+1,2(m_{i'}^Y-m_i^Z-c)}H\Z]_{\SH(k)} = \oplus_{i,i'}H\Z^{4(m_{i'}^Y-m_i^Z-c)+1,2(m_{i'}^Y-m_i^Z-c)}(\Spec k),$$     but each abelian group $H\Z^{4(m_{i'}^Y-m_i^Z-c)+1,2(m_{i'}^Y-m_i^Z-c)}(\Spec k)$ is trivial by Theorem \ref{thm:MazWeiHZ}. We conclude that $\alpha=0$, and the sequence \eqref{eq:loc.seq.HGr} splits. Hence      $$\Sigma^\infty_{\P^1}\HGr(r,n)_+ \wedge H\Z \simeq \oplus_s\Sigma^{4m_s,2m_s}H\Z$$     for a finite number of non-negative integers $m_s$, proving the claim.      Now, let us recall from Construction \ref{constr:MSp} that there are canonical inclusions $\HGr(r,rN) \hookrightarrow \HGr(r,r(N+1))$, and $\BSp_{2r}=\colim_N \HGr(r,rN)$. Since the $\text{free}_{H\Z}$ functor $(-)\wedge H\Z$ is a left adjoint, it commutes with small colimits, hence                    \Sigma_{\P^1}^\infty \BSp_{2r \, +}\wedge H\Z \simeq \colim_N(\Sigma_{\P^1}^\infty \HGr(r,rN)_+\wedge H\Z).           By the inductive proof of the identity $\Sigma^\infty_{\P^1} \HGr(r,n)_+ \wedge H\Z \simeq \oplus_s \Sigma^{4m_s,2m_s}H\Z$, we can see that, once we fix $r$, for each non-negative integer $m$ the number of summands in the right-hand side for which $m_s=m$ is eventually constant for $n>>0$. Indeed, we can assume that this is the case for $\Sigma^\infty_{\P^1} \HGr(r-1,n)_+ \wedge H\Z$ by induction. Noting that $Z$ has codimension $c=2r$, independent of $n$, the above argument shows that the pairs $(4m,2m)$ that occur for $\HGr(r,n+1)$ are the pairs that occur for $\HGr(r-1,n)$ together with pairs of the form $(4(r+m'), 2(r+m'))$ where $(4m',2m')$ is a pair occurring for $\HGr(r,n)$. This proves the claim on the coefficients $m_s$.          We can then rewrite \eqref{eq:MotiveOfBsp} as                   \Sigma_{\P^1}^\infty \BSp_{2r \, +}\wedge H\Z \simeq \oplus_s \Sigma^{4m_s,2m_s}H\Z,          where now the sum will be infinite, but for all $m$ there is only a finite number of summands for which $m_s=m$.      As before, by using projection formula of $p_{\BSp_{2r}\#}$ against $p_{\BSp_{2r}}^*$ and the isomorphism $\th^f_{H\Z \Mod}(E_{2r}^\Sp):\Sigma^{E_{2r}^\Sp}p_{\BSp_{2r}}^*H\Z \xrightarrow{\sim}\Sigma^{4r,2r}p_{\BSp_{2r}}^*H\Z$, we get     $$p_{\BSp_{2r}\#}\Sigma^{E_{2r}^\Sp}1_{\BSp_{2r}}\wedge H\Z \simeq \Sigma^{4r,2r}p_{\BSp_{2r}\#}1_{\BSp_{2r}}\wedge H\Z.$$     Thus, since $\Sigma_{\P^1}^\infty \MSp_{2r}\simeq p_{\BSp_{2r}\#}\Sigma^{E_{2r}^\Sp}1_{\BSp_{2r}}$, we can write     $$\Sigma_{\P^1}^\infty \MSp_{2r} \wedge H\Z \simeq \Sigma^{4r,2r}\oplus_s \Sigma^{4m_s,2m_s}H\Z,$$     with $m_s$ as in \eqref{eq:MotiveBsp2}. Since $\MSp =\colim_r(\Sigma^{-4r,-2r}\Sigma^\infty_{\P^1}\MSp_{2r})$, we can use again that $(-)\wedge H\Z$ commutes with small colimits and that, for each integer $m$, the number of summands in the right hand side of \eqref{eq:MotiveBsp2} such that $m_s=m$ becomes constant for $r>>0$, to get        \MSp \wedge H\Z \simeq \oplus_\alpha \Sigma^{4n_\alpha,2n_\alpha}H\Z,        where, for all integers n, there are only finitely many indices $\alpha$ with $n_\alpha=n$, and each $n_\alpha$ is non-negative.      We have then the following chain of isomorphisms:   H\Z^{*,*}(\MSp)&= [\MSp, \Sigma^{*,*}H\Z]_{\SH(k)}\\         &\simeq [\MSp \wedge H\Z, \Sigma^{*,*}H\Z]_{\DM(k)}\\         &\overset{\eqref{eqn:MSpDecom}}{\simeq} [\oplus_\alpha \Sigma^{4n_\alpha,2n_\alpha}H\Z,\Sigma^{*,*}H\Z]_{\DM(k)} \\        & \simeq \prod_\alpha[H\Z,\Sigma^{*-4n_\alpha,*-2n_\alpha}H\Z]_{\DM(k)}\\        & \simeq \prod_\alpha[1_k,\Sigma^{*-4n_\alpha,*-2n_\alpha}H\Z]_{\SH(k)}\\        &=\oplus_\alpha H\Z^{*,*}(\Spec k)\cdot b_\alpha,     with $b_\alpha$ in bidegree $(4n_\alpha,2n_\alpha)$. But from Theorem \ref{thm:cohomologyofmsp}, with Remark \ref{rmk:homogeneous}, we know that      $$H\Z^{*,*}(\MSp) \simeq H\Z^{*,*}(\Spec k)[b_1,b_2,\ldots]$$     with $b_i$ in bidegree $(4i,2i)$, in other words, $H\Z^{*,*}(\MSp)$ is a free bigraded $H\Z^{*,*}$-module with basis the monomials in $b_1, b_2,\ldots$. Thus, the bidegrees $(4n_\alpha,2n_\alpha)$ that occur in our decomposition \eqref{eqn:MSpDecom} are exactly the bidegrees of the monomials in $b_1, b_2,\ldots$.          From this we see that      $$\MSp \wedge H\Z \simeq \Z[b_1',b_2',\ldots] \otimes H\Z,$$ with $b_i'$ a polynomial generator of degree $-2i$.",2502.01404
proof,"In the proof of Proposition \ref{prop:MotiveOfMSp} we have seen that we can write the motive of $\MSp$ as                   \MSp \wedge H\Z \simeq \oplus_\alpha \Sigma^{4n_\alpha,2n_\alpha}H\Z,          for some non-negative integer $n_\alpha$, and for each non-negative integers $n$, there are only finitely many indices $\alpha$ such that $n_\alpha=n$.      By induction on $m$, we will also have                   (\MSp^{\wedge m}) \wedge H\Z \simeq (\MSp \wedge H\Z)^{\wedge_{H\Z} m} \simeq \oplus_\beta \Sigma^{4m_\beta,2m_\beta}H\Z,           with analogous conditions on the non-negative integers $m_\beta$. Thus, computing the motivic cohomology of $\MSp^{\wedge m}$ we have                   H\Z^{p,q}(\MSp^{\wedge m})=[\MSp^{\wedge m},\Sigma^{p,q}H\Z]_{\SH(K)} \simeq [\MSp^{\wedge m} \wedge H\Z, \Sigma^{p,q}H\Z]_{\DM(k)} \\         \simeq [\oplus_\beta \Sigma^{4m_\beta,2m_\beta}H\Z,\Sigma^{p,q}H\Z]_{\DM(k)}\simeq [1_k,\Sigma^{p-4m_\beta,q-2m_\beta}H\Z]_{\SH(k)} \\ \simeq \prod_\beta H\Z^{p-4m_\beta,q-2m_\beta}(\Spec k).          Since $H\Z^{a,b}(\Spec k)$ vanishes for $b<0$ by Theorem \ref{thm:MazWeiHZ}, we also have                    \prod_\beta H\Z^{p-4m_\beta,q-2m_\beta}(\Spec k) \simeq \oplus_\beta H\Z^{p-4m_\beta,q-2m_\beta}(\Spec k).           The expressions \eqref{eq:MotiveMSp} and \eqref{eq:MotiveMSp^n} give the isomorphism of $H\Z$-modules     $$(\oplus_\alpha \Sigma^{4n_\alpha,2n_\alpha}H\Z)^{\wedge_{H\Z} m} \simeq \oplus_\beta \Sigma^{4m_\beta,2m_\beta} H\Z.$$     With the product in motivic cohomology, this induces the isomorphism     $$(\oplus_\alpha H\Z^{*-4n_\alpha,*-2n_\alpha}(\Spec k))^{\otimes_{H\Z^{*,*}(\Spec k)} m} \xrightarrow{\sim} \oplus_\beta H\Z^{*-4m_\beta,*-2m_\beta}(\Spec k),$$     which can be rewritten, through \eqref{eq:chain2} and \eqref{eq:chain1}, as     $$H\Z^{*,*}(\MSp)^{\otimes_{H\Z^{*,*}(\Spec k)} m} \xrightarrow{\sim} H\Z^{*,*}(\MSp^{\wedge m}).$$",2502.01404
proof,$(1)$ is \cite[Theorems 9.4-9.5]{Voev-power}. $(2)$ is \cite[Lemma 9.8]{Voev-power}. $(3)$ is \cite[9.9]{Voev-power}. The formulas for the bidegrees of $Q_i$ and $P^{k \cdot e_i}$ come directly from their definition in \cite[Section 13]{Voev-power}.,2502.01404
proof,"We start by briefly reviewing the topological analogue for $\MSp^{\top}$, studied in \cite[Chapter 1]{Thomcompl}.      Let $H^*(-)$ denote the mod $\ell$ singular cohomology $H^*(-,\mathbb{Z}/\ell)$. We take $\Sp_{2r}^\top:=\Sp_{2r}(\C)$, with the classical topology. This gives the classifying space $\BSp_{2r}^\top$, as well as the tautological rank $2r$ symplectic bundle $E^{\Sp,\top}_{2r}\to \BSp_{2r}^\top$ and the Thom space $\MSp_{2r}^\top \coloneqq \Th(E^{\Sp,\top}_{2r})$. The $S^4$-spectrum $\MSp^{\top}$ is the sequence      $$\MSp^\top=(\MSp_0^\top, \MSp_2^\top, ,\ldots,\MSp_{2r}^\top,\ldots).$$ Equivalently, $\MSp^{\top}$ is the colimit of the shifted suspension spectra $\Sigma^{-4r}_{S^1}\Sigma^\infty_{S_1}\MSp_{2r}^\top$. Thus, the cohomology $H^*(\MSp^\top)$ is the limit of the cohomologies $H^{*+4r}(\MSp_{2r}^\top)$, for each fixed degree $*$. This limit is eventually constant.     The cohomology algebra $H^{*}(\BSp_{2r}^\top)$ is described for instance in \cite{BorelSerre:Steenrod}: it is the polynomial algebra over $\Z/\ell$ with generators the mod $\ell$ quaternionic Borel classes $$k_{4j}:=b_j^\top(E^{\Sp,\top}_{2r})\in H^{4j}(\BSp_{2r}^\top), \; j=1,\ldots, r.$$    Novikov \cite[Lemma 3]{Thomcompl} showed that the pullback by the zero section $z_{2r}^{\top*}:H^{*+4r}(\MSp_{2r}^\top)\to  H^{*+4r}(\BSp_{2r}^\top)$ is injective, with image the ideal generated by the top Borel class $k_{4r}$.    Writing $\BSp^\top$ as $\colim_r\BSp_{2r}^\top$ gives the isomorphism $H^*(\BSp^\top)\simeq \lim_rH^*(\BSp_{2r}^\top)$, and similarly, we have the isomorphism   $H^*(\MSp^\top)\simeq \lim_rH^{*+4r}(\MSp_{2r}^\top)$. Together with the Thom isomorphisms $H^*(\BSp_{2r}^\top)\simeq H^{*+4r}(\MSp_{2r}^\top)$, this  gives the commutative diagram of isomorphisms  $$        H^*(\BSp^\top) \arrow[d, ""\wr""] \arrow[r, dashed, ""\sim""] & H^*(\MSp^\top) \arrow[d, ""\wr""] \\      \lim_rH^*(\BSp_{2r}^\top) \arrow[r, ""\sim""] & \lim_r H^{*+4r}(\MSp_{2r}^\top)    $$  Under the isomorphism $H^*(\BSp^\top)\xrightarrow{\sim}H^*(\MSp^\top)$, we can write  $$H^*(\MSp^\top)\simeq H^*(\BSp^\top)= \Z/\ell[k_4, k_8,\ldots].$$    Now, since the operations in the topological mod $\ell$ Steenrod algebra $A^\top$ are stable with respect to $S^1$-suspension, the action on $H^*(\MSp^\top)$ is induced by the action on $H^{*+4r}(\MSp_{2r}^\top)$ for $r\gg0$, and thus by the action on $H^{*+4r}(\BSp_{2r}^\top)$ via $z_{2r}^{\top*}$. Let us note that this does not identify with the action of $A^\top$ on $H^*(\BSp^\top)$ via the above isomorphism $H^*(\MSp^\top)\simeq H^*(\BSp^\top)$.    Let $\HGr(r,n)^\top \coloneqq \HGr(r,n)(\C)$, again with the classical topology. We can approximate $H^{*+4r}(\BSp_{2r}^\top)$ by $H^{*+4r}(\HGr(r,n)^\top)$, and similarly, we can approximate $H^*(\MSp^\top)$ as $A^\top$-module by the $A^\top$-module $H^{*+4r}(\HGr(r,n)^\top)$.   Explicitly, $k_{4j}\in H^{4j}(\BSp^\top_{2r})$ corresponds to the elementary symmetric polynomial $\sum_{i_1,\ldots, i_j}t_{i_i}^2 \cdot \ldots \cdot t_{i_j}^2$ in $t_1^2,\ldots, t_r^2$, and to each even partition $\omega=(2q_1,\ldots,2q_s)$, we can assign the element     $$v^{(r)}_{\omega}\coloneqq \sum_{i_1,\ldots, i_s}t_{i_1}^{2q_1}\cdot \ldots \cdot t_{i_s}^{2q_s}\in  H^{2|\omega|}(\BSp_{2r}^\top).$$ The $v^{(r)}_{\omega}$ are compatible in $r$, giving the elements $v_\omega\in H^{2|\omega|}(\BSp^\top)$, and we let $u_\omega\in H^{2|\omega|}(\MSp^\top)$ be the element corresponding to $v_\omega$ via the isomorphism $H^*(\MSp^\top)\simeq H^*(\BSp^\top)$. Via the Thom isomorphism, $v^{(r)}_\omega$ maps to an element $v_\omega^{(r)'}\in H^{*+4r}(\MSp_{2r}^\top)$, and then $z_{2r}^*v_\omega^{(r)'}=v^{(r)}_{\omega}\cdot k_{4r}\in  H^{2|\omega|+4r}(\BSp_{2r}^\top)$. We can drop the ${}^{(r)}$ from the notation, and we see that the action of the Steenrod algebra on  $u_\omega\in H^{2|\omega|}(\MSp^\top)$ is given by the action on $v_{\omega}\cdot k_{4r}\in  H^{2|\omega|+4r}(\BSp_{2r}^\top)$ for $r\gg0$.       The natural product $\mu_{\MSp^\top}: \MSp^\top\wedge \MSp^\top\to \MSp^\top$ on the spectrum $\MSp^\top$ is induced by the embeddings $\Sp(m)\times \Sp(n) \subset \Sp(m+n)$. Together with the K\""unneth formula, $\mu_{\MSp^\top}$ gives rise to the ``diagonal map''  \[  \delta^\top:=\mu_{\MSp^\top}^*:H^*(\MSp^\top)\to H^*(\MSp^\top)\otimes_{\Z/\ell}H^*(\MSp^\top).  \]       By \cite[Lemma 7]{Thomcompl} the diagonal morphism on the generators $u_{\omega}^{\top}$ has the following form:                   \delta^\top(u_{\omega}^{\top})= \sum_{{(\omega_1,\omega_2)=\omega} \atop{\omega_1 \neq \omega_2}}(u_{\omega_1}^{\top} \otimes u_{\omega_2}^{\top}+u_{\omega_2}^{\top}\otimes u_{\omega_1}^{\top}) + \sum_{(\omega_1,\omega_1)=\omega}(u_{\omega_1}^{\top}\otimes u_{\omega_1}^{\top}).               The fact that $H^*(\MSp^{\top})$, as a module over $A^{\top}$, is the direct sum of modules $M_B^{\top}u_{\omega}^{\top}$ over even non-$\ell$-adic partitions $\omega$ follows by \cite[Lemma 4]{Thomcompl}. In Novikov's paper, the $Q_i^{\top}$ are the Adams elements $e_r'$ of Cartan type $1$ defined in \cite[Section 2.2]{Thomcompl}, and the $P_{\top}^i$ are a subfamily of the Adams elements $e_{r,k}$ of Cartan type $0$ defined in the same section. In other words, the map     $$\Phi^{\top} \coloneqq \bigoplus_{\omega \in P} \Phi_{\omega}^{\top}:\bigoplus_{\omega \in P}M_B^{\top}u_{\omega}^{\top}\to H^*(\MSp^{\top})$$     where $\Phi_{\omega}^{\top}$ is defined in the same way as we defined $\Phi_{\omega}$, is an isomorphism of graded left  $A^{\top}$-modules.      Now let us recall that, by \cite[Chapter 6, Section 1]{steenrod:cohomology}, the $P_{\top}^i$ and $\beta_{\top}$ satisfy the Adem relations and $\beta_{\top}^2=0$, and these relations determine $A^{\top}$ as $\mathbb{Z}/\ell$-algebra. By \cite[Theorem 5.1]{Hoy:Steenrod}, the operations $P^i$ also satisfy the Adem relations, and $\beta^2=0$, hence, there is a unique ring homomorphism $\theta:A^{\top}\to A^{**}$ defined by sending $P_{\top}^i$ to $P^i$ and $\beta_{\top}$ to $\beta$. In particular, if we let $A^{*,*}_0$ be the $\mathbb{Z}/\ell$-subalgebra of $A^{*,*}$ generated by $\beta$ and the $P^i$, $\theta$ induces an isomorphism of rings $A^{\top} \to A^{*,*}_0$ by \cite[Lemma 4.1 (1)]{lev:ellcoh}. Moreover, the $H^{*,*}$-linear extension of $\theta$     $$\id_{H^{*,*}}\otimes_{\mathbb{Z}/\ell}\theta: H^{*,*}\otimes_{\mathbb{Z}/\ell}A^{\top}\to A^{*,*}$$     is an isomorphism of left $H^{*,*}$-modules, still by \cite[Lemma 4.1]{lev:ellcoh}. We similarly define $M_{B0}$ as the $\mathbb{Z}/\ell$-subalgebra of $M_B$ generated by the $P^i$.          The action of $A^{*,*}$ on $H^{*,*}(\MSp)$ restricts to an action of $A^{*,*}_0$ on $H^{0,0}[b_1,b_2,\ldots]=\mathbb{Z}/\ell[b_1,b_2,\ldots] \subset H^{*,*}[b_1,b_2,\ldots]$, where $\beta$ acts trivially, because $\deg\beta=(1,0)$. Let us denote by $H_0^{*,*}(\MSp)$ the bigraded ring $\mathbb{Z}/\ell[b_1,b_2,\ldots]$. The map $\Phi_{\omega}$ of $A^{*,*}$-modules induces then a map $\Phi_{\omega}^0$ of $A_0^{*,*}$-modules, so, finally, we get a map     $$\Phi^0 \coloneqq \bigoplus_{\omega \in P} \Phi_{\omega}^0:\bigoplus_{\omega \in P}M_{B0}u_{\omega}\to H^{*,*}_0(\MSp).$$          Let us now note that, as left $H^{*,*}$-modules, $M_B$ is isomorphic to $H^{*,*}\otimes_{\mathbb{Z}/\ell} M_{B0}$, and $H^{*,*}(\MSp)$ is isomorphic to $H^{*,*}\otimes_{\mathbb{Z}/\ell}H^{*,*}_0(\MSp)$. In particular, as homomorphisms of $\mathbb{Z}/\ell$-vector spaces, $\Phi_{\omega}$ and $\Phi$ can be written as $$\Phi_{\omega}=\id_{H^{*,*}}\otimes \Phi_{\omega}^0, \; \; \text{and} \; \; \Phi=\id_{H^{*,*}}\otimes(\bigoplus_{\omega \in P} \Phi_{\omega}^0)=\id_{H^{*,*}}\otimes \Phi^0.$$     Thus, if $\Phi^0$ is an isomorphism of $A^{*,*}_0$-modules, $\Phi$ will be an isomorphism of $\mathbb{Z}/\ell$-vector spaces, and then also an isomorphism of left $A^{*,*}$-modules. It is then enough to prove that $\Phi^0$ is an isomorphism of $A^{*,*}_0$-modules.      Let us consider again the cohomology of $\MSp^{\top}$, $H^*(\MSp^{\top})=H^*(\BSp^{\top})=\mathbb{Z}/\ell[b_1^{\top},b_2^{\top},\ldots]$. Since every homogeneous element in $H_0^{*,*}(\MSp)$ has bidegree $(4i,2i)$ for some $i$, it is immediate by the presentations detailed above that the map $\rho:H^*(\MSp^{\top})\to H^{*,*}_0(\MSp)$ defined by taking $b_n^{\top}$ to $b_n$ is an isomorphism of graded rings. We want to show that it is also an isomorphism of left $A^{*,*}_0$-modules, using $A^{*,*}_0\simeq A^{\top}$ to define the module structure on $H^*(\MSp^{\top})$.      Since the action of $\beta$ is trivial, it is enough to show that $\rho$ preserves the action of the power operations, that is, $\rho(P^i_{\top}(b_n^{\top}))=P^i(b_n)$ for all $i$.      For each positive integer $r$, the action of $P^i$ on $\mathbb{Z}/\ell[b_1,\ldots,b_r]\subset H^{*,*}_0(\MSp)$ is induced by the action on the cohomology of the quaternionic Grassmannian $H^{*,*}(\HGr(r,n))$ as follows. As in the topological case, the canonical map $\Sigma_{\P^1}^{-2r}\Sigma^\infty_{\P^1}\MSp_{2r}\to \MSp$ induces an isomorphism $H^{a,b}(\MSp)\cong H^{a+4r, b+2r}(\MSp_r)$ for $r\gg0$, namely for $r$ bigger than a certain positive integer $r_0$ depending on $(a,b)$. By Proposition~\ref{prop:CohBSpMSp}(2), the restriction by the zero section $z_{2r}^*:H^{*+4r, *+2r}     (\MSp_{2r})\to H^{*+4r, *+2r}     (\BSp_r)$ is injective, with image isomorphic to the ideal generated by the mod $\ell$ Borel class $b_r(E^\Sp_{2r})$. Similarly, we have an isomorphism $\BSp_{2r}\simeq \colim_n\HGr(r, n)$, in $\sH(k)$, giving the approximation of $H^{*+4r, *+2r}     (\BSp_r)$ by $H^{*+4r, *+2r}(\HGr(r, n))$ for $n\gg0$, and we can identify $H^{a,b}(\MSp)$ with the bidegree $(a+4r, a+2r)$ component of the ideal in $H^{*, *}(\HGr(r, n))$ generated by the mod $\ell$ Borel class $b_r(E^\Sp_{r,n})$, for $r,n\gg0$ (depending on $(a,b)$). As the motivic Steenrod operations are $\Sigma^{a,b}$-stable, it follows that this identification of $H^{a,b}(\MSp)$ with $H^{a+4r, b+2r}(\HGr(r, n))$ for $r,n\gg0$ is compatible with the respective $A^{*,*}$-module structures.       Thus, $P^i(b_j)\in H^{4(i+j), 2(i+j)}(\MSp)$ corresponds to $$P^i(b_j(E^\Sp_{r,n})\cdot b_r(E^\Sp_{r,n}))\in H^{4(i+j+r), 2(i+j+r)}(\HGr(r, n)), \; \; r,n\gg0.$$      Let us denote by $\text{HFlag}(1^r;n)$ the complete quaternionic flag variety associated to $\HGr(r,n)$ as in \cite[\S 3, p. 147]{panwal:grass}. By the symplectic splitting principle for quaternionic Grassmannians \cite[Theorem 10.1]{panwal:grass}, the pullback of $E^\Sp_{2r,2n}$ by the map $\text{HFlag}(1^r;n)\to \HGr(r,n)$ splits as the orthogonal direct sum of the $r$ universal rank $2$ symplectic subbundles $(\mathcal{U}_2^{(1)},\phi_2^{(1)}) \perp \ldots \perp (\mathcal{U}_2^{(r)},\phi_2^{(r)})$, and the cohomology pullback maps injectively the Borel classes $b_j(E^\Sp_{2r,2n})$ to the elementary symmetric polynomials $e_j(\xi_1,\ldots,\xi_r)$ in the Borel roots $\xi_m\coloneqq b_1(\mathcal{U}_2^{(m)},\phi_2^{(m)}) \in H^{4,2}(\text{HFlag}(1^r;n))$. Then $P^i(b_j(E^\Sp_{r,n})\cdot b_r(E^\Sp_{r,n}))$ is determined by $P^i((e_j \cdot e_r)(\xi_1,\ldots,\xi_r))$. Moreover, by the Cartan formula \cite[Proposition 9.7]{Voev-power}, $P^i((e_j \cdot e_r)(\xi_1,\ldots,\xi_r))$ is completely determined by the values $P^s(\xi_m)$ for $s=0,1,\ldots,i$, but those values are in turn completely determined by the properties of reduced power operations, as follows.          \item Since $P^0=\id$ by \ref{lemma:someproperties} (1), $P^0(\xi_m)=\xi_m$.      \item $P^1(\xi_m)=0$ by looking at the degree and at the presentation of $H^{**}(\text{HFlag}(1^r;n))$ given by \cite[Theorem 11.1]{panwal:grass}.     \item Since $\xi_m$ has bidegree $(2\cdot 2,2)$, $P^2(\xi_m)=\xi_m^{\ell}$ by \ref{lemma:someproperties} (2).      \item $P^s(\xi_m)=0$ for all $s \ge 3$ by \ref{lemma:someproperties} (3).           The analogous result works for the topological case. Namely, the same argument shows that $P^i_{\top}(b_j^{\top})$ is determined by the values $P^s_{\top}(\xi_m^{\top})$ for $s=0,1,\ldots,i$, with $\xi_m^{\top}$ the topological Borel roots of the complex symplectic flag manifold. For those values, the same expressions as before are valid, by the axioms of the power operations $P^i_{\top}$ (see for instance \cite[Chapter VI]{steenrod:cohomology}).       Thus, if we express $P^i_{\top}(b_n^{\top})$ as a polynomial $p$ in the variables $e^\top_j=e_j(\xi_1^{\top}, \ldots, \xi_r^{\top})$, the same polynomial $p$ in the variables $e_j=e_j(\xi_1,\ldots, \xi_r)$ will give an expression for $P^i(b_n)$, and thus:     $$\rho(P^i_{\top}(b_n^{\top}))=\rho(p(b_1^{\top},b_2^{\top},\ldots))=p(b_1,b_2,\ldots)=P^i(b_n).$$     We have then proved that in the following commutative diagram     $$              \bigoplus_{\omega \in P}M_B^{\top}u_{\omega}^{\top} \arrow[r, ""\Phi^{\top}""] \arrow[d, swap, ""\theta'""] & H^*(\MSp^{\top}) \arrow[d, ""\rho""]\\         \bigoplus_{\omega \in P}M_{B0}u_{\omega} \arrow[r, ""\Phi^0""] & H^{**}_0(\MSp),          $$     where $\theta'$ is the map induced by $\theta$, all maps except $\Phi^0$ are isomorphisms of left $A^{*,*}_0$-modules. Thus, so is $\Phi^0$.",2502.01404
proof,"[Proof of Proposition \ref{prop:mspconnective}]     Let us consider the quaternionic Grassmannian $\HGr(n,np)$, and let us take an open cover $\{U_i\}_i$ of $\HGr(n,np)$ that trivializes, as ordinary vector bundle, the tautological symplectic bundle $E_{n,np}^\Sp$. The symplectic structure on $E_{n,np}^\Sp$ will not play any role here. Since $\HGr(n,np)$ is quasi-compact, we may assume that this open cover is finite. For every $i$, we have $\Th(E_{n,np}^\Sp \mid_{U_i})\simeq \Th(\mathcal{O}_{U_i}^{2n})$. By Remark \ref{rmk:Thomspaces}(2), we have     $$\Th(\mathcal{O}_{U_i}^{2n}) \simeq S^{4n,2n}\wedge U_{i\; +} \simeq S^{2n} \wedge \G_m^{\wedge 2n} \wedge U_{i \; +},$$     from which we see that $\Th(\mathcal{O}_{U_i^{2n}}) \in \Spc_{\bullet}(k)$ is $(2n-1)$-connected. By Theorem \ref{thm:MorelConnectivity}, $\Sigma_{\P^1}^\infty \Th(\mathcal{O}_{U_i}^{2n}) \in \SH(k)$ is $(2n-1)$-connected. By a Mayer-Vietoris argument for the sheaves $\pi_p(-)$, for $p\le 2n-1$, we see that $\Sigma_{\P^1}^\infty \Th(E_{n,np}^\Sp \mid_{U_i \cup U_j})$ is $(2n-1)$-connected for all $i,j$. By induction on the cardinality of $\{U_i\}_i$, we conclude that $\Sigma_{\P^1}^\infty \Th(E_{n,np}^\Sp)$ is $(2n-1)$-connected.       In general, a filtered colimit of $r$-connected spectra is $r$-connected, and let us note that, if $\E \in \SH(k)$ is $r$-connected, $\Sigma^{2,1}\E=S^1 \wedge \G_m \wedge \E$ is $(r+1)$-connected and $\Sigma^{-2,-1}\E$ is $(r-1)$-connected.      Going back to our situation, since $\Sigma_{\P^1}^\infty \MSp_{2n}$ is the filtered colimit of $\Sigma_{\P^1}^\infty \Th(E^\Sp_{n,np})$, it is still $(2n-1)$-connected. Thus, $\Sigma^{-4n,-2n}\Sigma_{\P^1}^\infty \MSp_{2n}$ is $(-1)$-connected. This holds for all $n$. Therefore, $\MSp$ is a filtered colimit of $(-1)$-connected spectra, and as such, is $(-1)$-connected itself.",2502.01404
proof,"The result follows from Proposition \ref{prop:a.s.s}, provided that the two conditions of the propositions are satisfied for $\MSp$.      The fact that $\MSp$ is cellular is Corollary \ref{cor:cellularityofMSp}. Therefore, we just need to show that $W_s(\MSp)$ is a motivically finite type wedge of copies of $H\Z/\ell$ for all $s$, where we remind the reader that we are considering $\sE=H\Z/\ell$ in the definition of $W_s(\MSp)$.      $W_s(\MSp)=W_s \wedge \MSp = W_s \wedge_{H\Z/\ell} H\Z/\ell \wedge \MSp$. By Proposition \ref{prop:MotiveOfMSp} and Remark \ref{rmk:HZ/ell}, we can write $$H\Z/\ell \wedge \MSp \simeq \oplus_{\alpha \ge 0} \Sigma^{4n_\alpha,2n_\alpha}H\Z/\ell,$$     for some non-negative integers $n_\alpha$ such that, for all $n$, there are only finitely many indices $\alpha$ with $n_\alpha=n$. Moreover, by \cite[Lemma 6.8]{lev:ellcoh}, we can write     $$W_s = \oplus_{(p,q) \in S_s}\Sigma^{p,q}(H\Z/\ell)^{r_{p,q}},$$     where $S_s = \{(p,q) \mid p+s \ge 2q \ge0 \}$, and for each $q$, $r_{p,q}=0$ for almost all $p$. We note that $(4n_\alpha,2n_\alpha)\in S_s$, and we conclude that we can write     $$W_s(\MSp) \simeq \oplus_{(p,q) \in S_s}\Sigma^{p,q}(H\Z/\ell)^{n_{p,q}},$$     where, again, $S_s = \{(p,q) \mid p+s \ge 2q \ge0 \}$, and for each $q$, $n_{p,q}=0$ for almost all $p$. In particular, $W_s(\MSp)$ is a motivically finite type wedge of copies of $H\Z/\ell$ for all $s$. This concludes the proof.",2502.01404
proof,"For all $s,t,u$, we have $E_2^{s,t,u}= \Ext_{A^{*,*}}^{s,(t-s,u)}(H^{*,*}(\MSp),H^{*,*})$ by Proposition \ref{prop: a.s.s.MSp}. In particular, from Proposition \ref{prop:pres.ExtAlgebra}(1), we can see that $E_2^{2u+1,u}=0$. Hence, $d_r^{2u,u}$ vanishes for all $r \ge 2$. By Proposition \ref{prop:pres.ExtAlgebra}(2), $E_2^{r,2,1}=0$ for all $r \ge 2$. Therefore, $d_r^{0,1,1}$ will vanish for all $r \ge 2$. Finally, by Proposition \ref{prop:pres.ExtAlgebra}(3), $E_2^{0,1,1}=H^{1,1}$.      By Proposition \ref{prop:a.s.s.multiplication}, the product on $E_2$ given by the multiplicative structure on the spectral sequence is the product of the $\Z/\ell$-algebra $\Ext_{A^{*,*}}(H^{*,*}(\MSp),H^{*,*})$ of Proposition \ref{prop:pres.ExtAlgebra}. In particular, the product     $$E_2^{0,1,1}\otimes_{\Z/\ell} \bigoplus_s E_2^{s,2u-2,u-1} \to \bigoplus_s E_2^{s,2u-1,u}$$     is surjective. Thus, from the vanishing of differentials $d_r^{0,1,1}$ and $d_r^{2u,u}$, we obtain the vanishing of differentials $d_r^{2u-1,u}$.      Now, since the differentials $d_r^{2u,u}$ and $d_r^{2u-1,u}$ are zero for $r\ge2$, we have that $E_{r+1}^{2u,u}=E_r^{2u,u}$ for $r \ge 2$, from which it follows that $E_2^{2u,u}=E_\infty^{2u,u}$ and $\lim_r^1E_r^{s,2u,u}=0$. Hence, by Proposition \ref{prop:a.s.s}, the spectral sequence converges completely to $(\MSp_{H\Z/\ell}^\wedge)^{2u,u}$. Finally, by Corollary \ref{cor:EtaEllComplMSp}, we get $(\MSp_{H\Z/\ell}^\wedge)^{2u,u} \simeq (\MSp_{\eta,\ell}^\wedge)^{2u,u}$, which concludes the proof.",2502.01404
proof,"The multiplicativity follows directly from the multiplicativity of the symplectic Thom classes, as expressed in Lemma~\ref{lem:SympThomMult}.  The class $[0]_\MSp$ is the image of $1_{\MSp^{0,0}(X)}\in \MSp^{0,0}(X)$ under the symplectic Thom isomorphism for the 0 symplectic vector bundle, which is by construction the map $\th^\Sp_{\MSp\Mod}(0):p_X^*\MSp\to p_X^*\MSp$, namely the identity map.",2502.01404
proof,"Since $X$ is projective, the $k$-vector space $H^0(X,L)$ of global sections is finite-dimensional, and we have $\P(H^0(X,L))\simeq \P^N$, with $N=h^0(X,L)-1$. Since $L$ is very ample, there exists a closed immersion $i:X \hookrightarrow \P(H^0(X,L))\simeq \P^N$ such that $L$ is the pullback $i^*\mathcal{O}(1)$ of the line bundle $\mathcal{O}(1)\to \P^N$, and the hyperplane sections of $X$ are exactly the closed subschemes $Z(s)\hookrightarrow X$ given by zero loci of global sections $s:X \to L$.       Let $d\coloneqq \dim_k X$. For each point $x \in X$, we consider the projective tangent space $\overline{T}_{(X,x)}$ of $X$ at the point $x$ as a $d$-dimensional projective subspace $\P^d \subset \P^N$. Let us consider the dual space $(\P^N)^*$ of $\P^N$, defined as the space parametrizing the hyperplane divisors in $\P^N$, which is isomorphic to $\P^N$, and take the subset $W \subseteq X \times (\P^N)^*$ defined by     $$W \coloneqq \{(x,H) \in X \times (\P^N)^* \mid \overline{T}_{(x,X)}\subseteq H \}.$$      Now, we note that for any $d$-dimensional linear subspace $L\simeq \P^d \subseteq \P^N$, the set of hyperplanes of $\P^N$ containing $L$ can be parametrized by the set of hyperplanes in a complementary linear subspace $L'$. Indeed, let $L'\simeq \P^{N-d-1}$ be a linear subspace of $\P^N$ of dimension $(N-d-1)$ such that $L \cap L'=\{0\}$. We have a bijection of sets     $$\{H \; \text{hyperplane in} \; \P^N \mid H \supset L \} \xrightarrow{\varphi} \{h \; \text{hyperplane in} \; L'\}$$     given as follows. For a hyperplane $H \subset \P^N$ containing $L$ one takes $\varphi(H) \coloneqq H \cap L'$, and for a hyperplane $h \subset L'$ one takes $\varphi^{-1}(h) \coloneqq \langle L,h \rangle$, the hyperplane in $\P^N$ generated by $L$ and $h$. Clearly, the set of hyperplanes of $L'$ is parametrized by $\P^{N-d-1}$.      Therefore, for each point $x \in X$, the fibre $f^{-1}(x) \subset W$ over $x$ through $f:W \hookrightarrow X \times \P^N \xrightarrow{p_1} X$ is isomorphic to $\P^{N-d-1}$, and $W \subset X \times (\P^N)^*$ is closed. From $\dim_kX=d$, we deduce that $W$ has dimension $N-1<N$. In particular, the closed subset $p_2(W)\subset (\P^N)^*\simeq \P^N$ is a proper closed subset. We can then consider the open complement $U \coloneqq \P^N \setminus p_2(W)$ of $\P^N$.           Let us now take a hyperplane $H \in U$. For every point $x \in X$, the intersection $H \cap \overline{T}_{X,x}$ will be a codimension $1$ linear space in $\overline{T}_{X,x}$. This is true in particular for all $x \in X \cap H$, which means that $X \cap H$ is smooth as a scheme over the field of definition $k(H)$ of $H$. Since $(\P^N)^*\simeq \P^N$, we can identify $(\P^N)^*$ with $\P(H^0(X,L)$, $U$ with an open subspace of $\P(H^0(X,L)$, and hyperplanes $H\in U$ with sections $s$ in $U$, and we will have that, for each $s$, $Z(s)$ is a codimension $1$ subscheme of $X \times_k k(s)$, smooth over $k(s)$.",2502.01404
proof,"(1) follows from the fact that for $X\in \Sm/k$,  $H\mathbb{Z}^{2n,n}(X)=\CH^n(X)=0$ for $n>\dim_kX$. (2) follows immediately from the definition of Newton classes and the fact that if $V_1$ has Chern roots $\xi_1, \ldots, \xi_r$ and $V_2$ has Chern roots $\xi_{r+1}, \ldots, \xi_{r+s}$, then $V_1\oplus V_2$ has Chern roots $\xi_1, \ldots, \xi_{r+s}$. (3) follows from the naturality of the Chern roots with respect to pullback.      (4) follows from the other three, since $T_X\simeq p_1^*T_{X_1}\oplus p_2^*T_{X_2}$, with $p_i:X \to X_i$ the projections.",2502.01404
proof,"By the definitions of the Segre number and the degree map, we have:     $$s_{(2d)}(Y) =\text{deg}_k(c_{(2d)}(T_Y))=p_{Y*}(c_{(2d)}(T_Y)),$$     after making the canonical identification $H\Z^{0,0}(\Spec k)=\Z$.          The short exact sequence     $$0 \to T_Y \to i^*T_X \to N_i \to 0$$     gives $c_{(2d)}(T_Y) + c_{(2d)}(N_i)=c_{(2d)}(i^*T_X)$, but since $X$ is decomposable, Lemma \ref{lemma:newtonclasses}(3)-(4) gives $c_{(2d)}(i^*T_X)=i^*c_{(2d)}(T_X)=0$. Then $$c_{(2d)}(T_Y)=-c_{(2d)}(N_i)=-c_{(2d)}(i^*(\xi \oplus \xi))=-i^*c_{(2d)}(\xi \oplus \xi).$$     Moreover, $c_{(2d)}(\xi \oplus \xi)=(c_1(\xi))^{2d}+(c_1(\xi))^{2d}=2\alpha^{2d}$. We have then     $$\text{deg}_k(c_{(2d)}(T_Y))= \text{deg}_k(-2i^*\alpha^{2d}).$$          We now claim that $i_*i^*x = \alpha^2 x$ for all $x \in H\mathbb{Z}^{4d,2d}(X)$. To see this, let $1^Y\in H\mathbb{Z}^{0,0}(Y)$, $1^X\in H\mathbb{Z}^{0,0}(X)$   be the respective units. By the projection formula (Proposition~\ref{prop:PushPull}(2)) we have    \[   i_*i^*x=i_*(1^Y\cdot i^*x)= i_*(1^Y)\cdot x.   \]   Next, we recall that $Y$ is the zero-locus of a global section $s$ of $\xi \oplus \xi$ that is transverse to the zero section $s_0$. This gives us the transverse cartesian diagram \[ \xymatrix{ Y\ar[r]^i\ar[d]^-i&X\ar[d]^{s_0}\\ X\ar[r]^-s&\xi \oplus \xi. } \] Thus, by the push-pull formula (Proposition~\ref{prop:PushPull}(1)) and Lemma~\ref{lem:FirstChernClassFacts}(1), we have \[ i_*(1^Y)=i_*i^*(1_X)=s^*s_{0*}(1_X)=c_2(\xi \oplus \xi). \] By the Whitney sum formula \eqref{enum:ChernClassAxioms}(2), we have $c_2(\xi \oplus \xi)=c_1(\xi)^2=\alpha^2$,  so $ i_*i^*x=\alpha^2\cdot x$, as claimed.      Thus    \text{deg}_k(c_{(2d)}(T_Y))&=  p_{Y*}(c_{(2d)}(T_Y))\\  &=p_{Y*}(-i^*c_{(2d)}(\xi \oplus \xi))\\  &=p_{X*}i_*(-i^*c_{(2d)}(\xi \oplus \xi))\\ &=p_{X*}(-\alpha^2\cdot 2\cdot\alpha^{2d})\\ &=(-2)\cdot\deg_k(\alpha^{2d+2})",2502.01404
proof,"Let $d$ be any positive integer such that $2d \neq \ell^i-1$ for all $i$. Let $$2d+2= a_0 +a_1\ell + \ldots +a_r \ell^r$$ be the $\ell$-adic expansion of $2d+2$. Let us define $$X_{2d+2} \coloneqq (\mathbb{P}^1)^{\times a_0} \times (\mathbb{P}^{\ell})^{\times a_1} \times \ldots \times (\mathbb{P}^{\ell^r})^{\times a_r},$$ where all products are products over $\Spec k$. Then $\dim(X_{2d+2})=2d+2$. Let $Y_{2d} \subset X_{2d+2}$ be the zero locus of a general section of the vector bundle $\xi \oplus \xi \to X_{2d+2}$ as in Construction \ref{constr:Stongvars}. Then $s_{(2d)}(Y_{2d})=\deg_k (-2\alpha^{2d+2})$ by Lemma \ref{lemma:segrenumbers}.  Let $\alpha_{i,j}\coloneqq c_1(p_{i,j}^*\mathcal{O}(1))$, where $p_{i,j}$ is the projection of $X_{2d+2}$ onto the $j$-th component of $(\mathbb{P}^{\ell^i})^{\times a_i}$, so that  $$\alpha=(\alpha_{0,1}+\alpha_{0,2}+\ldots +\alpha_{0,a_0}+\alpha_{1,1}+\ldots + \alpha_{1,a_1}+\ldots +\alpha_{r,a_r}).$$ In particular: $$\alpha^{2d+2}=(\alpha_{0,1}+\alpha_{0,2}+\ldots +\alpha_{0,a_0}+\alpha_{1,1}+\ldots + \alpha_{1,a_1}+\ldots +\alpha_{r,a_r})^{a_0 +a_1\ell +\ldots +a_r \ell^r}.$$  Since $X_{2d+2}$ is a product of projective spaces, we have K\""unneth formula $$H\Z^{2*, *}(X)\simeq H^{2*,*}(\P^1)^{\otimes a_0}\otimes\ldots\otimes H^{2*,*}(\P^{\ell^r})^{\otimes a_r},$$ with all tensor products over $\Z$, and the isomorphism given by taking the respective pullbacks and cup products. This follows by repeated application of the projective bundle formula (Theorem \ref{thm:PBF}). For all projective spaces $\P^n$, the top degree term in $H^{2*,*}(\P^n)$ is $H^{2n,n}(\P^n)\simeq \Z$, with generator $c_1(\mathcal{O}_{\P^n}(1))^n$, and $p_{\P^n*}(c_1(\mathcal{O}_{\P^n}(1))^n)=1\in H\Z^{0,0}(\Spec k)\simeq \Z$, where $1$ is the unit. Thus, through a series of uses of the push-pull formula and the projection formula (Proposition \ref{prop:PushPull}(1)-(2)), we see that the top degree term in $H\Z^{2*, *}(X_{2d+2})$ is $H\Z^{4d+4, 2d+2}(X_{2d+2})\simeq \Z$, with generator  \[ \alpha_*^*:=\alpha_{0,1} \cdot\alpha_{0,2}\cdots\alpha_{0,a_0} \cdot \alpha_{1,1}^{\ell} \cdots \alpha_{1,a_1}^{\ell} \cdots \alpha_{r,1}^{\ell^r} \cdots \alpha_{r,a_r}^{\ell^r}, \] and $\deg_k(\alpha_*^*)=1$. Therefore, $\deg_k(2\alpha^{2d+2})$ is the coefficient of  $$\alpha_{0,1} \cdot \alpha_{0,2}\cdots\alpha_{0,a_0} \cdot \alpha_{1,1}^{\ell} \cdots \alpha_{1,a_1}^{\ell} \cdots \alpha_{r,1}^{\ell^r} \cdots \alpha_{r,a_r}^{\ell^r}$$ in the expansion of $2\alpha^{2d+2}$.  The multinomial theorem gives the combinatorial formula $$(x_1 +x_2 + \ldots x_m)^n=\sum_{i_1 + \ldots +i_m=n}\frac{n!}{i_1!i_2!\ldots i_m!} x_1^{i_1}x_2^{i_2}\ldots x_m^{i_m}.$$ Moreover, multinomial coefficients satisfy the identity $$\frac{n!}{i_1!i_2!\ldots i_m!} =\binom{i_1}{i_1} \binom{i_1+i_2}{i_2}\cdots \binom{i_1+i_2+\ldots +i_m}{i_m}.$$ Thus, $\deg_k(2\alpha^{2d+2})$ is the coefficient       2 \cdot \frac{(2d+2)!}{1!1!\cdots 1!\ell! \cdots \ell! \ell^{2}! \cdots \ell^r!}= \\ = 2 \binom{1}{1}\binom{2}{1} \cdots \binom{a_0}{1} \binom{a_0+\ell}{\ell}\binom{a_0+2\ell}{\ell} \cdots \binom{a_0+a_1\ell}{\ell} \binom{a_0+a_1+\ell^2}{\ell^2} \cdots\binom{2d+2}{\ell^r}.  The product of the first $a_0$ binomial coefficients is $a_0!$. The product of the following $a_1$ binomial coefficients, reduced modulo $\ell$, is $a_1!$. And so on. Iterating this, we get $$\deg_k(2\alpha^{2d+2}) \equiv\ 2a_0!a_1! \cdots a_r! \; \; \; \text{mod}\;\ell.$$ In particular, $\ell$ does not divide $\deg_k(2\alpha^{2d+2})$, so $\nu_{\ell}(s_{2d}(Y_d))=0$.  Let now $d$ be a positive integer such that $2d=\ell^r-1$ for some $r$. In this case, let us define $$X_{2d+2} \coloneqq \mathbb{P}^1 \times (\mathbb{P}^{\ell^{r-1}})^{\ell},$$ so that $\dim(X_{2d+2})=\ell^r+1=2d+2$, and take $Y_{2d} \subset X_{2d+2}$ obtained again as in Construction \ref{constr:Stongvars}. Now we let $p_0$ be the projection of $X_{d+2}$ on the first factor $\mathbb{P}^1$, and $p_{1,j}:X_{2d+2} \to \mathbb{P}^{\ell^{r-1}}$ be the projection on the $j$-th component of $(\mathbb{P}^{\ell^{r-1}})^{\ell}$. As before, we write  $$\alpha=\alpha_0 +\alpha_{1,1} +\ldots + \alpha_{1,\ell},$$ and then $$\alpha^{2d+2}=(\alpha_0 +\alpha_{1,1} +\ldots + \alpha_{1,\ell})^{\ell^r+1}.$$ So, $\deg_k(2\alpha^{2d+2})$ is now the coefficient of $$\alpha_0 \cdot \alpha_{1,1}^{\ell^{r-1}} \cdot \alpha_{1,2}^{\ell^{r-1}} \cdots \alpha_{1,\ell}^{\ell^{r-1}}$$ in the expansion of $2\alpha^{\ell^r+1}$. By using the multinomial theorem as before, we get $$\deg_k(2\alpha^{2d+2})=2\binom{1}{1}\binom{1+\ell^{r-1}}{\ell^{r-1}}\binom{1+2\ell^{r-1}}{\ell^{r-1}} \cdots \binom{1+\ell^r}{\ell^{r-1}}.$$ Let us note that: $$\binom{1+j\ell^{r-1}}{\ell^{r-1}}=\binom{j\ell^{r-1}}{\ell^{r-1}}\frac{1+j\ell^{r-1}}{1+j\ell^{r-1}-\ell^{r-1}}.$$ In the right hand term, the fraction does not contain the factor $\ell$ in either the nominator or denominator, while the binomial coefficient contains the factor $\ell$ only when $j=\ell$ and never contains the factor $\ell^2$. We conclude that $\ell$ divides $\deg_k(2\alpha^{2d+2})$ and $\ell^2$ does not, that is, $\nu_{\ell}(s_{2d}(Y_{2d}))=1$.",2502.01404
proof,"The map $\Phi: \MSp \to \MGL$ induces a map between the two respective Adams spectral sequences. By looking at the decompositions of $H^{*,*}(\MSp)$ and $H^{*,*}(\MGL)$ given by Lemmas \ref{lemma:decompmsp} and \ref{lemma:decompMGL}, we see that the induced map between the two respective $E_2$-pages is an isomorphism on the summands of the $\Ext$-algebras corresponding to the duals of the summands $M_B u_\omega$, with $w\in P$, namely with $\omega$ being an even (necessarily non-$\ell$ adic) partition. In particular, the $E_2$ page for $\MSp$ is a split summand of the $E_2$ page for $\MGL$. Since both spectral sequences degenerate at $E_2$, this implies, using the complete convergence, that the map  $\Phi_*:(\MSp_{\eta, \ell}^\wedge)^* \to (\MGL^*)_\ell^\wedge$ induced by $\Phi$ is injective.  We can consider the filtration $F^*(\MSp_{\eta,\ell}^\wedge)^*$ associated to the spectral sequence $E(\MSp)$ for $\MSp$. Analogously to the case of $F^*(\MGL^*)_\ell^\wedge$ in Remark \ref{rmk:liftingGenerators}, the generators $z_{(2k)}$ and $h_r$ of $E_2(\MSp)$ lift to generators $\tilde{z}_{(2k)}$ and $\tilde{h}_r$ of the graded $\Z_\ell$ algebra $(\MSp_{\eta,\ell}^\wedge)^*$, with $r\ge 0$, $k\ge 1$, $2k \neq \ell^i-i$ for any $i \ge 0$,  uniquely up to sums with decomposable elements and elements in $\ell \cdot (\MSp_{\eta,\ell}^\wedge)^*$. We see that, through the inclusion $\Phi_*:(\MSp_{\eta, \ell}^\wedge)^* \hookrightarrow (\MGL^*)_\ell^\wedge$, $\tilde{z}_{(2k)}$ and $\tilde{h}_r$ map to the polynomial generators $\tilde{z}'_{(2k)}$ and $\tilde{h}'_r$ respectively, up to decomposable elements and elements in $\ell \cdot (\MGL^*)^\wedge_\ell$. Indeed, $z_{(2k)}$ is the dual of $u_{(2k)}$,  hence it belongs to the summand of $E_2(\MSp)$ corresponding to the summand $M_B u_{(2k)}$, while the elements $h_r$ are generators of the $\Z/\ell$ algebra $\Ext_B(\Z/\ell,H^{*,*})\simeq \Ext_{A^{*,*}}(M_B,H^{*,*})$, so they belong to the summand of $E_2(\MSp)$ corresponding to the summand $M_B u_{(0)}$.   Thus, the $\Z_\ell$-algebra generators $\tilde{z}_{(2k)}$ and $\tilde{h}_r$ of $(\MSp_{\eta, \ell}^\wedge)^*$ map to polynomial generators of the $\Z_\ell$-algebra $(\MGL^*)_\ell^\wedge=\Z_\ell[\{\tilde{z}'_{(k)}, \tilde{h}'_r\}_{k,r}]$, mapping to (possibly new) polynomial generators in all even degrees. Thus $\Phi_*$ identifies $(\MSp_{\eta, \ell}^\wedge)^*$ with this polynomial subalgebra of $(\MGL^*)_\ell^\wedge$.",2502.01404
proof,"We retain the notation used in the proof of Proposition~\ref{prop:PolynomialMSp}.   From Remark \ref{rmk:liftingGenerators}, we see that the elements $\tilde{h}_r'$, for $r \ge 1$, give generators of $(\MGL^*)^\wedge_\ell$ of degrees $1-\ell^r$ respectively, and the elements $\tilde{z}_{(k)}'$ give generators in the remaining non-zero degrees. Thus, by Proposition \ref{prop:CriterionMGL}, we have $$\nu_\ell(c_{(k)}(\tilde{z}_k'))=0 \; \; \; \text{and} \; \; \; \nu_\ell(c_{(\ell^r-1)}(\tilde{h}'_r))=1.$$ Therefore, we also have        \nu_\ell(c_{(2k)}(\Phi_* \tilde{z}_{2k}))=0 \; \; \; \text{and} \; \; \; \nu_\ell(c_{(\ell^r-1)}(\Phi_* \tilde{h}_r))=1.  If now $y\in (\MGL^n)^\wedge_\ell$ is a polynomial generator, then modulo $\ell\cdot (\MGL^n)^\wedge_\ell$ and decomposable elements we must have that $y$ is a $\Z_\ell$-unit times a generator $\tilde{h}_r'$ (if $n=1-\ell^r$) or $\tilde{z}_k'$ (if $n$ is not of the form $1-\ell^r$). Since Newton classes vanish on decomposable elements, we see that, for arbitrary $y\in (\MGL^n)^\wedge_\ell$, $y$ is a polynomial generator if and only if $\nu_\ell(c_{(n)}(y))=1$ if $n$ is of the form  $1-\ell^r$, and $\nu_\ell(c_{(n)}(y))=0$ if $n$ is not of this form.   From Proposition~\ref{prop:PolynomialMSp}, we see that the sub-$\Z_\ell$-algebra $(\MSp^\wedge_{\eta,\ell})^*$ is the polynomial sub-$\Z_\ell$-algebra of $(\MGL^*)^\wedge_\ell$ with polynomial generators the $\tilde{h}'_r$, $r\ge1$ and the $\tilde{z}_k'$ for $k$ even (and non-$\ell$-adic). Applying the above criterion, we see that an element $y_{2d}' \in (\MSp^\wedge_{\eta,\ell})^{-2d}$, $d \ge 1$, is a polynomial generator of $(\MSp^\wedge_{\eta,\ell})^*$ if and only if    $$  \nu_\ell(c_{(2d)}(\Phi_* y_{2d}'))=                      1 \; \; \; \; \text{for} \; \; 2d= \ell^r-1, \; r\ge 1 \\             0 \; \; \; \text{for} \; \; 2d \neq \ell^r-1 \; \forall r \ge 1.          $$ This gives the result.",2502.01404
proof,"We first note that, for $x \in \MGL^{-n}=\MGL^{-2n,-n}(\Spec k)=\MGL_{2n,n}(\Spec k)$, and $c_{(n)} \in H\Z^{2n,n}(\MGL)$, we have \[ c_{(n)}(x) := \langle c_{(n)},h(x) \rangle =c_{(n)}\circ x\in H\Z^{0,0}(\Spec k)=\Z \] by Remark \ref{rmk:HurewiczMap}.  Next, expanding the full definition of $[Y,(v_Y,\omega_Y)]_\MSp$ as $[Y,(v_Y,\omega_Y),\vartheta_Y, 2r]_\MSp$, since the map $\Phi:\MSp\to \MGL$ is induced by the maps $\BSp_{2r}\to \BGL_{2r}$, we have \[ \Phi_* [Y,(v_Y,\omega_Y),\vartheta_Y, 2r]_\MSp =[Y, v_Y+\sO_Y^{2r},\vartheta_Y]_\MGL\in  \MGL^{-2d,-d}(\Spec k), \] where $v_Y\in K_0(Y)$ is the image of $(v_Y,\omega_Y)\in K_0^\Sp(Y)$ under the evident map  $K_0^\Sp(Y)\to K_0(Y)$ forgetting the symplectic structure. Thus \[ c_{(2d)}\circ \Phi_* [Y,(v_Y,\omega_Y),\vartheta_Y, 2r]_\MSp=c_{(2d)}\circ [Y, -T_Y',\vartheta_Y]_\MGL. \] Furthermore, $-T_Y'$ has virtual rank $-2d$ and $\vartheta_Y$ is a composition of $2r+1$ isomorphisms of the form $\Anan_{e,-L_1,\ldots, -L_s}$, $2r$ for the factors $\P^{2n_1+1}$ and one coming from the rank $2$ bundle $\xi'\oplus \xi'$. In particular, for each factor $\P^{2n_i+1}$ of $X$ we have $s=n_i+1$, and for $\xi'\oplus \xi'$ we have $s=1$. Thus, the sum of all the indices $s$ relative to the isomorphisms $\Anan_{e,-L_1,\ldots, -L_s}$ is $n_Y$, and it follows from Corollary~\ref{cor:TwistClassComp} that  \[ c_{(2d)}\circ [Y, -T_Y',\vartheta_Y]_\MGL=(-1)^{n_Y}\cdot\deg_k (c_{(2d)}(-T_Y')) =(-1)^{n_Y}\cdot\deg_k (c_{(2d)}(-T_Y')). \]  Finally, up to isomorphisms, $-T_Y$ and $-T_Y'$ are both (virtual) sums in $K_0(Y)$ of classes of line bundles, where the only difference is that some of the line bundles $L_i$ appearing in $-T_Y$ get replaced with $L_i^\vee$. But if $-T_Y=\sum_i\epsilon_i[L_i]$, with $\epsilon_i\in\{\pm1\}$, then we have by additivity of the Newton classes that  $c_{(2d)}(-T_Y)=\sum_i\epsilon_i\cdot c_1^{H\Z}(L_i)^{2d}$ and $c_{(2d)}(-T_Y')=\sum_i\epsilon_i\cdot c_1^{H\Z}(L_i^{\otimes \tau_i})^{2d}$ for suitable $\tau_i\in\{\pm1\}$. Since $H\Z$ has additive formal group law (Example \ref{exmp:orientedHZ}), we have  \[ c_1(L_i^{\otimes -1})^{2d} =(-c_1(L_i))^{2d}=c_1(L_i)^{2d}, \] so $c_{(2d)}(-T_Y')=c_{(2d)}(-T_Y)$, completing the proof.",2502.01404
proof,"Let us use the notation $(-)_{r-\tors}$ for the $r$-torsion elements of a ring. To show that there is an injective map $((\MSp^\wedge_\eta)^*)^\wedge_\ell\hookrightarrow (\MSp_{\eta,\ell}^\wedge)$, we can follow the proof of \cite[Lemma 6.13 (3)]{lev:ellcoh} for $\MSL$. In particular, for all $s,t \in Z$, $n \ge 0$, there is a diagram     $$              0 \arrow[r] & \MSp^{s,t}/\ell^n \arrow[r] \arrow[d] & (\MSp/\ell^n)^{s,t} \arrow[r] \arrow[d] & (\MSp^{s+1,t})_{\ell^n-\tors} \arrow[r] \arrow[d] & 0 \\         0 \arrow[r] & \MSp^{s,t}/\ell^{n-1} \arrow[r] & (\MSp/\ell^{n-1})^{s,t} \arrow[r] & (\MSp^{s+1,t})_{\ell^{n-1}-\tors} \arrow[r] & 0,          $$     from which, by considering $\eta$-completions and taking the limit over $n$, we get the exact sequence              0 \to \lim_n((\MSp_\eta^\wedge)^{s,t}/\ell^n) \to \lim_n((\MSp_\eta^\wedge /\ell^n)^{s,t}) \to \lim_n((\MSp_\eta^\wedge)^{s+1,t}) \\ \to \lim_n^1((\MSp_\eta^\wedge)^{s+1,t}/\ell^n.          This gives us an injection $((\MSp^\wedge_\eta)^*)^\wedge_\ell \simeq \lim_n((\MSp_\eta^\wedge)^{2s,s}/\ell^n) \hookrightarrow \lim_n((\MSp_\eta^\wedge /\ell^n)^{2s,s}) \simeq (\MSp_{\eta,\ell}^\wedge)^*$. To show the surjectivity, it is sufficient to show that $(\MSp_{\eta,\ell}^\wedge)^*$, seen as a subalgebra of $(\MGL_{\eta,\ell}^\wedge)^*$ through $\Phi_*$, is generated, as $\Z_\ell$-module, by the images $\Phi_*[Y_{2d}, (v_Y,\omega_Y)]_\MSp$. But we already know this, from Theorem \ref{thm:ClassOfGenerators}. This concludes the proof.",2502.01404
proof,"$(\overline{\MSp}_\eta^\wedge)^*[1/2p]$ is a $\Z[1/2p]$-module. Then for all odd prime $\ell$ different from $p$, we have      $$(\overline{\MSp}_\eta^\wedge)^*[1/2p] \otimes_{\Z[1/2p]}\Z_\ell \simeq  (\overline{\MSp}_\eta^\wedge)^* \otimes_\Z \Z_\ell \simeq ((\MSp_\eta^\wedge)^*)^\wedge_\ell \simeq (\MSp_{\eta,\ell}^\wedge)^*,$$     where the last isomorphism is Proposition \ref{prop:eta-ellCompl}.      By using Proposition \ref{prop:CriterionMSp} as a generating criterion for $(\overline{\MSp}_\eta^\wedge)^*[1/2p] \otimes_{\Z[1/2p]}\Z_\ell$, for each $\ell$, we obtain that an element $y'_{2d} \in {(\overline{\MSp}^\wedge_\eta})^{-2d}[1/2p]$ is a generator if and only if          c_{(2d)}(\Phi_* y_{2d}')=                      \lambda \in \Z[1/2p]^\times & \text{if} \; \; 2d \neq \ell^r-1, \; \; \text{for all prime} \;  \ell \neq 2,p; \; \forall r \ge 1 \\             \lambda' \cdot \ell, \; \lambda' \in \Z_\ell^\times & \text{if} \; \; 2d= \ell^r-1, \; \; \ell \; \text{prime}, \; \ell \neq 2,p; \; r\ge 1.",2502.01404
lemma,"[\cite{voe:homotopy_theory}, Theorem 5.2]      For $X \in \sH_{\bullet}(S)$ and $\E \in \SH(S)$, one has     $$\Map_{\SH(S)}(\Sigma^{\infty}_{\P^1}X, \E) = \colim_i \Map_{\sH_{\bullet}(S)}((\P^1)^{\wedge i}\wedge X, E_n),$$     where the maps in the direct system are given by the bonding maps of $\E$.",2502.01404
lemma,"The assignment $\Locfree(X) \ni \sV\mapsto \th_\sE(\sV) \in \Map_{\SH(X)}(\Sigma^{\sV-\sO_X^r}1_X, p^*\sE),$ with $r=\rnk \sV$, extends to a natural transformation of functors of groupoids from $\sK(X)$ to $\SH(X)_\simeq$ $$ [\th_\sE(-):(\Sigma^{(-)-\sO_X^{\rnk(-)}}1_X)\to c_{p^*\sE}]:\sK(X)\to \SH(X)_\simeq, $$ where $\SH(X)_\simeq$ is the underlying groupoid of $\SH(X)$, and $c_{p^*\sE}$ is the constant functor with value $p^*\sE$.",2502.01404
lemma,"For $v,v'\in \sK(X)$, $\th_\sE(v+v')$ is the composition  \Sigma^{v+v'-\sO_X^{\rnk(v+v')}}1_X\simeq \Sigma^{v-\sO_X^{\rnk(v)}}1_X\wedge_X\Sigma^{v'-\sO_X^{\rnk(v')}} 1_X\\\xrightarrow{\th_\sE(v)\wedge\th_\sE(v')}p^*\sE\wedge_Xp^*\sE\xrightarrow{\mu_{p^*\sE}} p^*\sE\notag  where $\mu_{p^*\sE}$ is the multiplication on $p^*\sE$.   Consequently, letting $r:=\rnk(v)$ and $r'=\rnk(v')$, we have the following commutative diagram \[ \xymatrix{ \Sigma^{v+v'-\sO_X^{r+r'}}1_X\ar[ddrrr]^{\th_\sE(v+v')}\ar[d]_-\wr\ar[r]^-\sim&\Sigma^{v-\sO_X^r}(\Sigma^{v'-\sO_X^{r'}}1_X)\ar[rr]^-{\Sigma^{v-\sO_X^r}(\th_\sE(v'))}&&\Sigma^{v-\sO_X^r}p_X^*\sE\ar[d]^-{\id\wedge\th_\sE(v)}\\ \Sigma^{v'-\sO_X^{r'}}(\Sigma^{v-\sO_X^r}1_X) \ar[d]_-{\Sigma^{v'-\sO_X^{r'}}(\th_\sE(v))}&&&p_X^*\sE\wedge_Xp^*\sE\ar[d]^-{\mu_{p^*\sE}}\\ \Sigma^{v'-\sO_X^{r'}}p^*\sE\ar[r]^-{\th_\sE(v')\wedge\id}&p_X^*\sE\wedge_Xp^*\sE\ar[rr]^-{\mu_{p^*\sE}}&&p^*\sE. } \]",2502.01404
lemma,"For $X\in \Sm/k$, $v\in \sK(X)$, $\sE\in \SH(k)$ oriented, the map $\th_{\sE}^f(v):\Sigma^{v-\sO_X^{rnk(v)}}p^*\sE\to p^*\sE$ in $\SH(X)$ is an isomorphism in $\SH(k)$, and for $\sE$ highly structured, $\th^f_{\sE\Mod}(v)$ is an isomorphism in $\Mod_{p^*\sE}$.",2502.01404
lemma,"Let $V_1\to X$, $V_2\to X$ vector bundles on $X\in \Sm/k$ of rank $r_1, r_2$, and let $\sV_1, \sV_2$ be the respective locally free sheaves of sections of $V_1^\vee, V_2^\vee$. Then $\th_{\sE}^f(V_1-V_2)\in [\Sigma^{[\sV_1]-[\sV_2]-(r_1-r_2)[\sO_X]}p^*\sE, p^*\sE]_{\SH(X)}$ is the composition      \Sigma^{[\sV_1]-[\sV_2]-(r_1-r_2)[\sO_X]}p^*\sE\xrightarrow{\Sigma^{r_2[\sO_X]-[\sV_2]}\th_{\sE}^f(V_1)}\Sigma^{-[\sV_2]+r_2[\sO_X]}p^*\sE \\ \xrightarrow{(\Sigma^{-[\sV_2]+r_2[\sO_X]}\th_{\sE}^f(V_2))^{-1}}p^*\sE  In particular, for $V\to X$ a vector bundle of rank $r$, we have $$\th_{\sE}^f(-V)=(\Sigma^{-[\sV]+r[\sO_X]}\th_{\sE}^f(V))^{-1}.$$",2502.01404
lemma,"Let $V\to X$ be a rank $r$ vector bundle on $X\in \Sm/k$, and let $\sE\in \SH(k)$ be an oriented ring spectrum. \\[5pt] 1. Let $s_0:X\to V$ be the zero section and let $s:X\to V$ be an arbitrary section. Then    c_r(V)=s^*(s_{0*}(1^\sE_X)),  where $1^\sE_X\in \sE^{0,0}(X)$ is the unit.\\[2pt] 2. In the same setting as in (1), let us suppose that the cartesian square \[ \xymatrix{ Y:=s_0^*V\ar[r]^i\ar[d]^i&X\ar[d]^s\\ X\ar[r]^{s_0}&V } \] is transverse, that is, $i:Y\to X$ is a codimension $r$ closed subscheme of $X$, smooth over $k$. Then   c_r(V)=i_*(1^\sE_Y)),   where $1^\sE_Y\in \sE^{0,0}(Y)$ is the unit.",2502.01404
lemma,"Let us suppose $X \in \Sm/k$ irreducible, and use the shorthand $\Anan \coloneqq \Anan_{e;-L_1,\ldots,-L_n}$ for the isomorphism \eqref{eq:Anaconstruction}. Let also $d\coloneqq \rnk(e)-n$. For $p:X\to \Spec k$ in $\Sm/k$, the diagram in $\Mod_{p^*H\Z}$ $$  \Sigma^{e- \sum_{i=1}^n[L_i] - r[\mathcal{O}_X]}1_X\wedge p^*H\Z \arrow[rr, ""\Sigma^{-2d,-d} \Anan\wedge\id_{p^*H\Z}"", ""\sim""'] \arrow[dr, swap, ""\th_{H\Z\Mod}^f (e- \sum_{i=1}^nL_i)"", ""\sim""'] && \Sigma^{e-\sum_{i=1}^n[L_i^\vee]-r[\mathcal{O}_X]}1_X\wedge p^*H\Z \arrow[dl, ""(-1)^n\th^f_{H\Z\Mod} (e-\sum_{i=1}^nL_i^\vee)"", ""\sim""'] \\ & p^*H\Z &  $$ commutes.",2502.01404
lemma,"Let $X \in \Sm/k$ irreducible. Let $E \to X$ a vector bundle of finite rank over $X$ and $L \to X$ a line bundle over $X$, with dual bundle $L^{\vee}\to X$. Let $\rho: \Th(E\oplus L) \xrightarrow{\sim} \Th(E \oplus L^\vee)$ the isomorphism in $\SH(k)$ defined as in \cite[Lemma 4.1]{Ana:Slor}. Then $$\rho^*\th^{H\mathbb{Z}}(E + L^{\vee})=-\th^{H\mathbb{Z}}(E+L).$$",2502.01404
lemma,"The map $\th^{\Sp,f}_{\sE}(V,\omega)$ is an isomorphism in $\SH(X)$, and if $\sE$ is highly structured, the map $\th^{\Sp, f}_{\sE\Mod}(V,\omega)$ is an isomorphism in $\Mod_{p^*\sE}$.",2502.01404
lemma,"Let $X=U_1 \cup U_2$ be the union of two Zariski open subsets $U_1, U_2$, and let $j_1:U_1 \to X$, $j_2: U_2 \to X$ and $j:U_1 \cap U_2 \to X$ the respective open inclusions. Then we have a Mayer-Vietoris distinguished triangle     $$j_\#j^* \to j_{1\#}j_1^* \oplus j_{2\#}j_2^* \to \id_{\SH(X)} \to j_\#j^* \to j_{1\#}j_1^*[1]$$     of endofunctors of $\SH(X)$.",2502.01404
lemma,"Let $\sE\in \SH(k)$ be symplectically oriented, and take $X\in \Sm/k$.  For $v,v'\in \sK^\Sp(X)$, $\th_\sE^\Sp(v+v')$ is the composition  \Sigma^{v+v'-\sO_X^{\rnk(v+v')}}1_X\simeq \Sigma^{v-\sO_X^{\rnk(v)}}1_X\wedge_X\Sigma^{v'-\sO_X^{\rnk(v')}} 1_X\\\xrightarrow{\th_\sE^\Sp(v)\wedge\th^\Sp_\sE(v')}p^*\sE\wedge_Xp^*\sE\xrightarrow{\mu_{p^*\sE}} p^*\sE\notag  where $\mu_{p^*\sE}$ is the multiplication on $p^*\sE$.   In consequence, the following diagram commutes (with $2r=\rnk(v)$, $2r'=\rnk(v'))$: \[ \xymatrix{ \Sigma^{v+v'-\sO_X^{2r+2r'}}1_X\ar[ddrrr]^{\th^\Sp_\sE(v+v')}\ar[d]_-\wr\ar[r]^-\sim&\Sigma^{v-\sO_X^{2r}}(\Sigma^{v'-\sO_X^{2r'}}1_X)\ar[rr]^-{\Sigma^{v-\sO_X^{2r}}(\th^\Sp_\sE(v'))}&&\Sigma^{v-\sO_X^{2r}}p_X^*\sE\ar[d]^-{\id\wedge\th^\Sp_\sE(v)}\\ \Sigma^{v'-\sO_X^{2r'}}(\Sigma^{v-\sO_X^{2r}}1_X) \ar[d]_-{\Sigma^{v'-\sO_X^{2r'}}(\th^\Sp_\sE(v))}&&&p_X^*\sE\wedge_Xp^*\sE\ar[d]^-{\mu_{p^*\sE}}\\ \Sigma^{v'-\sO_X^{2r'}}p^*\sE\ar[r]^-{\th^\Sp_\sE(v')\wedge\id}&p_X^*\sE\wedge_Xp^*\sE\ar[rr]^-{\mu_{p^*\sE}}&&p^*\sE } \]",2502.01404
lemma,"If $X \in \Sm/k$ is a cellular scheme, $\Sigma_{\P^1}^\infty X_+ \in \SH(k)$ is $\mathbb{S}_k$-cellular.",2502.01404
lemma,"Let $X\in \Sm/k$ be a cellular scheme, let $V\xrightarrow{\pi} X$ be a rank $r$ vector bundle over $X$, and let $V^0\hookrightarrow V$ be the open complement of the zero-section, namely $V^0:=V\setminus\{s_0(X)\}$. Then $\Sigma^\infty_{\P^1}V_+$ and $\Sigma^\infty_{\P^1}V^0_+$ are $\mathbb{S}_k$-cellular.",2502.01404
lemma,The maps $g_1$ and $g_2$ just defined are Zariski-locally trivial affine space bundles.,2502.01404
lemma,"Let $\Tilde{Y}$ be the space     $$\Tilde{Y} \coloneqq\{(e,f)\in V \times V \mid e_{2n}=0, \; f_{2n}=1, \; \phi (e,f)=1\}.$$     There is an isomorphism of $k$-schemes $Y_2 \simeq \Tilde{Y}\times \HGr(r-1,n-1)$.",2502.01404
lemma,"\item[(1)] $P^0= \id$, and, for any $i<0$, $P^i=0$.     \item[(2)] For $x \in H^{2n,n}(\Spec k)$, $P^n(x)=x^\ell$.     \item[(3)] For $x \in H^{p,q}(\Spec k)$, $n > p-q$ and $n\ge q$, we have $P^n(x)=0$.     \item[(4)] $Q_i$ has bidegree $(2 \ell^i -1, \ell^i-1)$, and for each $k \ge 1$, $P^{k \cdot e_i}$ has bidegree $(2k(\ell^i-1),k(\ell^i-1))$.",2502.01404
lemma,"Let $P$ be the set of all even partitions $\omega$ that are not $\ell$-adic. Then the map     $$\Phi \coloneqq \bigoplus_{\omega \in P} \Phi_{\omega}:\bigoplus_{\omega \in P}M_Bu_{\omega}\to H^{*,*}(\MSp)$$     is an isomorphism of left $A^{**}$-modules.",2502.01404
lemma,"1. \cite[Lemma 5.1 and Lemma 5.4]{lev:ellcoh} There is an isomorphism of trigraded $\mathbb{Z}/\ell$-algebras     $$\Ext_{A^{*,*}}(M_B,H^{*,*}) \simeq \Ext_B(\mathbb{Z}/\ell,H^{*,*}),$$  2. \cite[Lemma 5.2]{lev:ellcoh} We have                \item $\underline{t>2u}$: $\Ext_B^{s,(t-s,u)}(\mathbb{Z}/\ell,H^{*,*})=0$.         \item $\underline{t=2u}$: $\Ext_B^{s,(2u-s,u)}(\mathbb{Z}/\ell,H^{*,*})$ is a polynomial $\mathbb{Z}/\ell$-algebra in generators $\{h_r'\}_{r\ge0}$, with $\deg(h_r')=(1,(1-2\ell^r,1-\ell^r))$.          \item $\underline{t<2u}$: $\Ext_B^{0,(2u-1,u)}(\mathbb{Z}/\ell,H^{*,*})$ is $H^{1,1}$ if $u=1$, and $0$ otherwise, and the product map         $$H^{1,1} \otimes \bigoplus_{s,u}\Ext_B^{s,(2u-s,u)}(\mathbb{Z}/\ell,H^{*,*}) \to \Ext_B^{s,(2u-s+1,u+1)}(\mathbb{Z}/\ell,H^{*,*})$$         is surjective.",2502.01404
lemma,"\item[(1)] If $V\to X$ is a vector bundle on $X\in \Sm/k$, and $n>\dim_kX$, then          $c_{(n)}(V)=0$.         \item[(2)] Newton classes are additive: if $V_1, V_2 \to X$ are two vector bundles, we have         $$c_{(n)}(V_1 \oplus V_2) = c_{(n)}(V_1)+c_{(n)}(V_2).$$         \item[(3)] Newton classes are natural: given $V\to X$ a vector bundle and $f:Y\to X$ a morphism in $\Sm/k$, we have $c_{(n)}(f^*(V))=f^*(c_{(n)}(V))$ in $H\Z^{2n,n}(Y)$.         \item[(4)] If $X = X_1 \times X_2$ is the product of two smooth and proper varieties, both of dimension at least $1$, and $n=\dim_kX$, then $c_{(n)}(T_X)=0$. In other words, Segre numbers vanish on decomposable varieties.",2502.01404
lemma,"Let $Y, X$ be as in Construction \ref{constr:Stongvars}, with $i:Y \hookrightarrow X$ the closed immersion. Let $p_X:X \to \Spec k$ be the structure map of $X$, and let $2d \coloneqq 2n-2=\dim_kY$. Also, let $\alpha \coloneqq c_1(\xi) \in H\mathbb{Z}^{2,1}(X)$. Then     $$s_{(2d)}(Y)= (-2)\cdot\deg_k(\alpha^{2d+2}).$$",2502.01404
lemma,"[\cite{lev:ellcoh}, Lemma 5.9]  Let $P'$ denote the set of all partitions that are not $\ell$-adic (see Definition \ref{defn:l-adicpartition}). Then     $$H^{*,*}(\MGL) \simeq \bigoplus_{P'}M_B u_\omega.$$",2502.01404
theorem,"The $\mathcal{O}_D$ Fibonacci zeta functions admit meromorphic continuation to $s \in \mathbb{C}$. We have        \Zodd(s) & =     \frac{q^{s/2}}{8 \Gamma(s) \log \varepsilon}     \sum_{m \in \mathbb{Z}} (-1)^m     \Gamma\Big(\frac{s}{2} + \frac{\pi i m}{2\log \varepsilon}\Big)     \Gamma\Big(\frac{s}{2} - \frac{\pi i m}{2\log \varepsilon}\Big), \\     \Zeven(s)              & =     \frac{q^{\frac{s}{2}} \Gamma(1-s)}{4 \log \varepsilon} \sum_{m \in \mathbb{Z}}     \frac{\Gamma(\frac{s}{2} - \frac{\pi i m}{2 \log \varepsilon})}     {\Gamma(1-\frac{s}{2} - \frac{\pi i m}{2 \log \varepsilon})},      for all $s \in \mathbb{C}$ and for $\Re s < 0$, respectively.",2502.01415
theorem,"For $s \in \mathbb{C}$ away from the poles of the summands,   \[     \Zodd(s) = \frac{q^{s/2}}{8 \Gamma(s) \log \varepsilon}     \sum_{m \in \mathbb{Z}} (-1)^m     \Gamma\Big(\frac{s}{2} + \frac{\pi i m}{2\log \varepsilon}\Big)     \Gamma\Big(\frac{s}{2} - \frac{\pi i m}{2\log \varepsilon}\Big),   \]   Thus $\Zodd(s)$ has meromorphic continuation to $s \in \mathbb{C}$, with simple poles at $s = - 2k + \frac{\pi i m}{\log \varepsilon}$   for $m \in \mathbb{Z}$ and integral $k \geq 0$.",2502.01415
proof,"Let $X$ be a set of representatives for the singular cusps of $\chi_{4D}$ under the action of $W_{4D}$. Then the constant term map $\CT : \calE( \cdot, \tfrac{1}{2}) \to \C^{X}$ is surjective, where $\calE$ is the space spanned by the Eisenstein series and $\CT(f)_x$ is the constant term of $f \vert_{\sigma_x}$. We further consider the decomposition to real vector spaces $\calE = \calE_+ \oplus \calE_-$, where $\calE_+$ consists of $E$ such that $W_{4D} E = \overline{E}$ and $\calE_-$ of those with $W_{4D} E = - \overline{E}$. These induce a decomposition $\C^X = V_+ \oplus V_-$.   It follows that $\CT(f) \in V_+$, so there exists an Eisenstein series $E \in \calE_+$ such that $\CT(E(\cdot, \tfrac{1}{2})) = \CT(f)$.   Finally, if $x \in X$, then the constant term of $f$ at $W_{4D}(x)$ is        \CT(W_{4D} f)_{x} & = \CT(\overline{f})_{x} = \overline{\CT(f)_{x}} = \overline{\CT(E(\cdot, \tfrac{1}{2}))_{x}} \\                       & = \CT(\overline{E(\cdot, \tfrac{1}{2})})_{x} = \CT((W_{4D} E)(\cdot, \tfrac{1}{2}))_{x},      which is the constant term of $E(\cdot, \tfrac{1}{2})$ at $W_{4D}(x)$, showing the result.",2502.01415
proof,"We apply the Rankin--Selberg method to  % chktex 8   unfold the inner product into the integral   \[     \langle     V,     \mathcal{E}_\mathfrak{a}(z,\overline{w}; \chid)     \rangle     =     \int_0^\infty \int_0^1     V(\sigma_\mathfrak{a}z) y^w dx \frac{dy}{y^2}.   \]   The integral in $x$ isolates the constant term of $V(\sigma_{\mathfrak{a}}z)$.   We claim that this constant term is actually $0$, which implies the inner   product is zero.    A short computation shows that the expansion of   $V_1(z) = y^{\frac{1}{2}} \theta(Dz) \overline{\theta(z)}$ at the cusp   $\mathfrak{a}$ is always a constant multiple of $y^{\frac{1}{2}} \theta(uz)     \overline{\theta(vz)}$ for some integers $u,v$ with $uv = D$.   By Proposition~\ref{prop:Fricke-regularizable}, the   non-exponential decay portion of $V_1(z)$ perfectly cancels with the   Eisenstein series $E(z, s)$ at every singular cusp $\mathfrak{a}$.   As such, it suffices to examine the exponential decay part of the constant   term of $y^{\frac{1}{2}}     \theta(uz) \overline{\theta(vz)}$, which is   \[     \sum_{\substack{m,n \geq 1 \\ um = vn}} r_1(m) r_1(n) e^{-2\pi (um + vn)y}.   \]   Since $r_1$ restricts to squares, the condition $um=vn$ forces $u/v$ to be a   rational square, which contradicts that $uv=D$ is square-free.   Hence the constant term of $V(\sigma_\mathfrak{a} z)$ is identically $0$,   implying that the inner product is zero as well.",2502.01415
proof,"[(Proof sketch when $\mu$ is a newform)]   The theta function $\theta(z)$ appears in the residue of a weight $1/2$, level   $4D$ Eisenstein series   \[     E(z,w; \Gamma_0(4D))     \colonequals     \sum_{\gamma \in \Gamma_{\infty} \backslash \Gamma_0(4D)} \Im(\gamma z)^w J(\gamma, z)^{-1},   \]   where $j(\gamma, z) = \theta(\gamma z) / \theta(z)$ and $J(\gamma, z) =     j(\gamma, z) / | j(\gamma, z) |$ is a normalized theta multiplier.   This Eisenstein series has meromorphic continuation to $w \in \mathbb{C}$ with a simple pole at $w=\frac{3}{4}$ with residue of the form $c^{-1} y^{1/4} \theta(z)$.   By computing the constant term in the Fourier expansion of   $E(z,w;\Gamma_0(4D))$ (similar to the computations   from~\cite[\S3.1]{goldfeld2006automorphic}), we conclude that   \[     c = \frac{4 \pi D}{3} \prod_{p \mid 4D} (1 + p^{-1}).   \]   We compute $\langle V, \mu \rangle$ by identifying $\theta(z)$ as the   residue of $E(z,w;\Gamma_0(4D))$ and using this Eisenstein series to unfold   the integral:        \langle V, \mu \rangle      & = \langle y^{\frac{1}{2}} \theta(Dz) \overline{\theta(z)}, \mu \rangle     = c \Res_{w = \frac{3}{4}}     \langle y^{1/4} \theta(Dz) \overline{E(z,\overline{w};\Gamma_0(4D))}, \mu \rangle    \\      & = c \Res_{w = \frac{3}{4}} \int_{0}^{\infty} \int_{0}^{1}     y^{1/4} \theta(Dz) y^{w} \overline{\mu(z)} \frac{dxdy}{y^2}                          \\      & = c \Res_{w = \frac{3}{4}} \sum_{n \ge 1} r_1(n) \overline{\rho(Dn)}     \int_0^{\infty} y^{w-\frac{1}{4}} K_{i t} (2D \pi n y) e^{-2 D \pi n y} \frac{dy}{y} \\      & = c \cdot  2\sqrt{\pi} \Res_{w = \frac{3}{4}}     \frac{\Gamma(w-\frac{1}{4}+it) \Gamma(w-\frac{1}{4} - i t)}     {(4 \pi D)^{w-\frac{1}{4}} \Gamma(w + \frac{1}{4})}     \sum_{n \ge 1} \frac{\overline{\rho(Dn^2)}}{n^{2w-\frac{1}{2}}},      in which we've used~\cite[6.621(3)]{GradshteynRyzhik07} to evaluate the integral.   As the gamma functions are analytic at $w = \frac{3}{4}$, the residue is zero   unless the Dirichlet series has a pole at $w=\frac{3}{4}$.    If $\mu$ is a Hecke newform, this Dirichlet series is essentially the symmetric   square $L$-function associated to $\mu$; it has a pole if and only if $\mu$   is dihedral.",2502.01415
proof,"Let   \[     E(z,w; \Gamma_0(4D)) \colonequals \sum_{\gamma \in \Gamma_{\infty}       \backslash \Gamma_0(4D)} \im(\gamma z)^w J(\gamma, z)^{-1},   \]   where $j(\gamma, z) = \theta(\gamma z) / \theta(z)$ and   $J(\gamma, z) = j(\gamma, z)/ \lvert j(\gamma, z)\rvert$.   As noted above, we recognize $\theta$ as coming from a residue of a   half-integral weight Eisenstein series,   \[     \Res_{w = \frac{3}{4}} E(z,w; \Gamma_0(4D)) = c^{-1} y^{1/4} \theta(z),   \]   with   \[     c = \frac{4 \pi D}{3} \prod_{p \mid 4D} (1 + p^{-1}).   \]   Unfolding and recalling that the Fourier coefficients of $B_a \mu$ satisfy   $\rho_{B_a \mu}(n) = \rho_{\mu}(n / a)$ shows that   \[     \langle V, B_a \mu \rangle_{4D} = c \cdot 2 \sqrt{\pi} \Res_{w = \frac{3}{4}}     \frac{\Gamma(w - \tfrac{1}{4} + it) \Gamma(w - \tfrac{1}{4} - it)}     {(4 \pi D)^{w - \tfrac{1}{4}}\Gamma(w + \tfrac{1}{4})}     \sum_{n \ge 1}     \frac{\overline{\rho(Dn^2/a)}}{n^{2w-\tfrac{1}{2}}}.   \]    Let $\{T_n \}$ be the Hecke operators on $S_0(D, \chi_{D})$, as defined   in~\cite[\S6]{dfi}.   Then for all $D$ and $n$ we have   \[     T_{D} T_{n} = \sum_{d \mid (D, n)} \chi_{D}(d) T_{Dn/d^2} = T_{Dn},   \]   since $\chi_{D}(d) = 0$ for all $1 \ne d \mid D$.   It follows that $\lambda(Dn) = \lambda(D) \lambda(n)$, and as a consequence   $\rho(Dn) = \rho(1) \lambda(D) \lambda(n)$. When $2 \mid D$, we must have   $b = 1$ and $a = 1$;   hence in all cases we have $\rho(Dn^2/a) = \rho(D) \lambda(n^2/a)$.   Therefore we get   \[     \sum_{n=1}^{\infty} \frac{\overline{\rho(Dn^2/a)}}{n^s}     = \overline{\lambda(D)} \sum_{n=1}^{\infty}     \frac{\overline{\rho(n^2/a)}}{n^s}     = \overline{\lambda(D)} \sum_{r=0}^{\infty} \sum_{2 \nmid n}     \frac{\overline{\rho(n^2 \cdot  2^{2r}/a)}}{n^s \cdot 2^{rs}}.   \]   Since $a \mid 4$, we can use multiplicativity to write   \[     \sum_{n=1}^{\infty} \frac{\overline{\rho(Dn^2/a)}}{n^s}     =  \overline{\lambda(D)} \sum_{j=0}^{\infty} \frac{\overline{\rho(2^{2j}/a)}}{2^{js}}     \sum_{2 \nmid n} \frac{\overline{\lambda(n^2)}}{n^s}     =  \overline{\rho(D)}     \frac{P_2(s, B_a \overline{\mu})}{P_2(s, \overline{\mu})}     \sum_{n=1}^{\infty} \frac{\overline{\lambda(n^2)}}{n^s},   \]   where $P_2(s, \mu) = \sum_{j=0}^{\infty} \frac{\rho(2^{2j})}{2^{js}}$ as   in the statement of the lemma.    Recalling that   \[     L(s, \overline{\mu} \otimes \overline{\mu})     = \zeta^{(bq)}(2s) \sum_{n=1}^{\infty} \frac{\overline{\lambda(n)}^2}{n^s}     = \zeta^{(bq)}(2s) L(s, \chi_{bq}) \sum_{n=1}^{\infty}  \frac{\overline{\lambda(n^2)}}{n^s},   \]   we may write   \[     \sum_{n=1}^{\infty} \frac{\overline{\rho(Dn^2/a)}}{n^s}     = \overline{\rho(D)}     \frac{P_2(s, B_a \overline{\mu})}{P_2(s, \overline{\mu})}     \frac{L(s, \overline{\mu} \otimes \overline{\mu})}{\zeta^{bq}(2s) L(s,       \chi_{bq})}.   \]   This has a pole at $s = 1$ if and only if $\mu$ is dihedral.\footnote{The     authors appreciate insight on this from     MathOverflow~\cite{moquestion_dihedral}, which led to us reconsidering     foundational work of Labesse and Langlands~\cite{ll1979}.}   It also follows that        \langle V, B_a \mu \rangle_{4D}     = \frac{P_2(1, B_a \overline{\mu})}{P_2(1, \overline{\mu})} \langle V, \mu     \rangle_{4D}.       We now assume that $\mu$ is dihedral and compute the inner product.   Then   \[     \Res_{s=1} \sum_{n=1}^{\infty} \frac{|\rho(n)|^2}{n^s}     = \frac{4 \cosh(\pi t)}{\pi}     \langle |\mu|^2, \Res_{s=1} \mathcal{E}(z,s)     \rangle_{4D}     = \frac{3 \cosh(\pi t) \langle \mu, \mu \rangle_{4D}}{\pi^2 D \prod_{p         \mid 4D} (1 + \tfrac{1}{p})},   \]   where   \[     \mathcal{E}(z,s)     = \sum_{\gamma \in \Gamma_{\infty} \backslash \Gamma_0(4D)} \im(\gamma z)^s.   \]   By Dirichlet's class number formula, we have        L(1, \chi_{q}) = \frac{2 h(D) \log \varepsilon}{\sqrt{q}}     = \frac{h(D) \sqrt{\ell} \log \varepsilon }{\sqrt{D}}.      As $b \in \{1, 2, 4\}$, we have   \[     \left( 1 - \frac{\chi_{bq}(2)}{2} \right)     L(1, \chi_{bq}) = \left( 1 - \frac{\chi_{q}(2)}{2} \right)     \frac{ h(D) \log \varepsilon \sqrt{\ell}}{\sqrt{D}}.   \]   Consequently,   \[     \left( 1 - \frac{\chi_{q}(2)}{2} \right) \Res_{s=1} \rho(1) \sum_{n=1}^{\infty} \frac{\overline{\rho(Dn^2)}}{n^s}     = %\left( 1 - \frac{\chi_{bq}(2)}{2} \right)     \frac{(1-\frac{\chi_{bq}(2)}{2}) \cdot 3 \overline{\lambda(D)} \cosh(\pi t) \langle \mu, \mu \rangle_{4D}}     {\pi^2 \sqrt{D\ell} h(D) \log \varepsilon \prod_{p \mid 4D} (1 + \tfrac{1}{p})}.   \]   After substituting, we obtain        \left( 1 - \frac{\chi_{q}(2)}{2} \right) \rho(1) \langle V, \mu \rangle_{4D}      & = \left( 1 - \frac{\chi_{bq}(2)}{2} \right) \frac{3c \overline{\lambda(D)} \langle \mu, \mu \rangle_{4D}}     {2 \sqrt{\ell} \pi D h(D) \log \varepsilon \prod_{p \mid 4D} (1 + \tfrac{1}{p})}                              \\      & = \left( 1 - \frac{\chi_{bq}(2)}{2} \right) \frac{  2 \overline{\lambda(D)} \langle \mu, \mu \rangle_{4D}}     { \sqrt{\ell} h(D) \log \varepsilon}.      Using~\eqref{eq:inner_product_with_Ba} we get   \[     \left( 1 - \frac{\chi_{q}(2)}{2} \right) \rho(1) \frac{\langle V, B_a \mu       \rangle_{4D}}{\langle \mu, \mu \rangle_{4D}}     =  \left( 1 - \frac{\chi_{bq}(2)}{2} \right) \cdot \frac{P_2(1, B_a \overline{\mu})}{P_2(1, \overline{\mu})} \cdot \frac{ 2 \overline{\lambda(D)}}     {\sqrt{\ell} h(D) \log \varepsilon},   \]   which is the desired equality.",2502.01415
proof,"Let $\eta$ be a Hecke character of $\Q(\sqrt{D})$, and assume by contradiction that $\mu_{\eta}$ has (minimal) level $2D$ or $4D$.   Since $\mu_{\eta}$ has nebentypus $\chi_{D}$, it follows that $\eta \vert_{\Q^{\times}} = 1_{2}$. In particular, recalling also that $L_2(s, \mu_{\eta}) = L_2(s, \eta)$, the conductor of $\eta$ divides $\frakp_2$, a prime ideal over $2$.   If $2$ is split or ramified in $\Q(\sqrt{D})$, then $\calO_D / \frakp_2 \simeq \F_2$, hence there is no character of conductor $\frakp_2$, showing that $\eta$ has trivial conductor, hence $\mu_{\eta}$ has minimal level $D$.    When $2$ is inert in $\Q(\sqrt{D})$, we have $\calO_D / \frakp_2 \simeq \F_4$, and since $D \equiv 1 \bmod 4$, the image of $\varepsilon$ in $\F_4^{\times}$ is a generator, showing that the map $\calO_D^{\times} \to \{ \pm 1\}^2 \times \F_4^{\times}$ is surjective, and the narrow class group of level $2$ is isomorphic to the class group. Therefore, there are no Hecke characters of conductor $2$, hence in this case as well $\eta$ has trivial conductor, and $\mu_{\eta}$ has minimal level $D$.",2502.01415
proposition,"[Proposition~6 of~\cite{akldwFibonacciGeneral}]   The positive integer $n$ is an $\calO_D$ Fibonacci number if and only if   there is an integer solution in $X$ to the equation        X^2 = qn^2 \pm 4,      where $q = D$ if $D \equiv 1 \bmod 4$ and otherwise $q = 4D$.   If in addition $N(\varepsilon) = -1$, then $n$ is an odd-indexed $\calO_D$   Fibonacci number if and only if there is an integer solution in $X$ to the equation        X^2 = qn^2 - 4.",2502.01415
proposition,"Let $D$ be square-free. Let $f$ be an automorphic form of weight $0$ for $\Gamma_0(4D)$ of nebentypus $\chid$, such that $W_{4D} f = \overline{f}$, where $W_{4D}$ is the Fricke involution.   There exists an Eisenstein series $E(z,s)$, modular for $\Gamma_0(4D)$ of nebentypus $\chid$, such that        f(z) - E(z, \tfrac{1}{2})     \in L^2(\Gamma_0(4D) \backslash \calH; \chid).",2502.01415
lemma,"For each singular cusp $\mathfrak{a}$,   $\langle V(z), \mathcal{E}_\mathfrak{a}(z,\overline{w}; \chid) \rangle = 0$.",2502.01415
lemma,"Let $a,b$ be positive integers such that $ab \mid \ell$.   Let $\mu$ denote a Hecke-Maass form in $\Szero{bq}{\chi_{bq}}^{\new}$ which is an   eigenform of spectral type $\tfrac{1}{2}+it$ for the Hecke algebra with associated Hecke eigenvalues $\lambda(n)$   and Fourier coefficients $\rho(n)$. Then $\langle V, B_a \mu \rangle = 0$ unless $\mu$ is dihedral, in which case        \left(1 - \frac{\chi_q(2)}{2} \right) \rho(1) \frac{\langle V, B_a \mu       \rangle_{4D}}{\langle \mu, \mu \rangle_{4D}}     = \left(1 - \frac{\chi_{bq}(2)}{2} \right) \cdot \frac{P_2(1,B_a \mu)}{P_2(1, \mu)} \cdot     \frac{ 2 \lambda(D)}{ \sqrt{\ell} h(D) \log \varepsilon},      where   \[     P_2(s, \mu) = \sum_{j=0}^{\infty} \frac{\rho(2^{2j})}{2^{js}}   \]   is the $2$-factor of the symmetric square $L$-function associated to $\mu$.",2502.01415
lemma,"If $D \equiv 1 \bmod 4$, then neither of the spaces $\Szero{4D}{\chi_{4D}}^{\new}$ nor   $\Szero{2D}{\chi_{2D}}^{\new}$ contain any dihedral Maass forms.",2502.01415
theorem,"As $n \rightarrow \infty$, for the topology of uniform convergence on compacts, $$\left(\bigg(\frac{G_{p,n}(\lfloor nt\rfloor)}{n}, \frac{D_{p,n}(\lfloor nt\rfloor)}{n} \bigg), t \geq 0 \right) ~\overset{\mathbb P}\longrightarrow~\left(\big(g_p(t),d_p(t)\big), ~t\geq 0 \right).$$",2502.01424
theorem,"As $n \rightarrow \infty$, for the topology of uniform convergence on compacts, $$\left(\bigg(\frac{V_{p,n}(\lfloor nt\rfloor)}{n}, \frac{E_{p,n}(\lfloor nt\rfloor)}{n}, R_{p,n}(\lfloor nt\rfloor)\bigg), ~ t\geq 0\right) ~\overset{\mathbb P}\longrightarrow ~\Big((v_p(t),e_p(t),r_p(t)),~ t\geq 0 \Big)$$ where $$ v_p(t)=1-g_p(t); \qquad e_p(t)=t(1-g_p(t))^2; \qquad r_p(t)=t(1-g_p(t)).  $$ Moreover, $$\left(\bigg(\frac{k \cdot N_{p,n}^{(k)}(\lfloor nt\rfloor)}{n}\bigg)_{k\geq 1}\bigg),~ t\geq 0\right)~\overset{\mathbb P}\longrightarrow~\left(\big(k\cdot t_{p,k}(t) \big)_{k\geq 1}\big), ~t\geq 0 \right)$$ for the usual norm $\|x\|_1:=\sum_{k\geq 1}|x_k|$ on $\ell^1$, the space of summable sequences.",2502.01424
theorem,"For all $k \in \mathbb N$,  as $n \rightarrow \infty$,  $$ \mathbb P\Big(A^{(k+)}_{p,n} =A^{(k)}_{p,n}  \Big)  \; \underset{n \rightarrow \infty}{\longrightarrow} \; 1 $$ and $$ \frac{A^{(k+)}_{p,n} }{n} - \frac{\mathsf t^{(k)}_{p,n}}{2}  \; \underset{n \rightarrow \infty}{\overset{(\mathrm d)}\longrightarrow} \; \frac{\mathrm{Gu}}{2kp}-\frac{\psi(1/p)+\gamma_{\mathrm E}}{2p}+\frac{\ln (k^{k-2}/k!)}{2kp}. $$",2502.01424
theorem,"For all $k \in \mathbb N$ $$ \mathcal A_{p,n}^{(k)} - \mathsf t^{(k)}_{p,n}  \; \underset{n \rightarrow \infty}{\overset{(\mathrm d)}\longrightarrow} \; \frac{\mathrm{Gu}}{kp}-\frac{\Psi(1/p)+\gamma_{\mathrm E}}{p}+\frac{\ln (k^{k-2}/k!)}{kp}. $$",2502.01424
theorem,"For all $k \in \mathbb N$,  $$ \mathbb P\left(\mathcal A^{(k+)}_{p,n} =\mathcal A_{p,n}^{(k)} \right)  \; \underset{n \rightarrow \infty}{\longrightarrow} \; 1. $$ Consequently, $$ \mathcal A_{p,n}^{(k+)} - \mathsf t^{(k)}_{p,n}  \; \underset{n \rightarrow \infty}{\overset{(\mathrm d)}\longrightarrow} \; \frac{G}{kp}-\frac{\Psi(1/p)+\gamma_{\mathrm E}}{p}+\frac{\ln (k^{k-2}/k!)}{kp}. $$ In particular, this gives the asymptotic behavior of the total gelation time, $\mathcal A_{p,n}^{(1+)}=\inf\{t\geq 0:\mathcal G_{p,n}(t)=n\}$.",2502.01424
theorem,"[Theorem 5.1 in \cite{wormald97}, Theorem 2 in \cite{Warnke19}]  	Assume that $D$ contains the closure of  	$$\left\{(0,z_1,\ldots,z_k)\in \mathbb{R}^{k+1}:\mathbb{P}\big(Y_n^{(l)}(0)=z_l n, 1\leq l\leq k \big)\neq 0 \text{ for some } n\right\}$$ 	and that the two following hypotheses hold for all $n \in \mathbb N$: 	 		\item[$\bullet$] \emph{Boundedness hypothesis.} For some functions $\beta:\mathbb N \rightarrow [1,\infty)$ and $\gamma:\mathbb N \rightarrow [0,1]$ the probability that 		$$\max_{1\leq l\leq k}\left\vert \Delta Y^{(l)}_n(m+1)\right\vert \leq \beta(n),$$ conditional on $\mathbf F_{n}(m)$, is at least $1-\gamma(n)$ when $m<H_D(Y^{(1)}_n,...,Y^{(k)}_n)$. 		\item[$\bullet$] \emph{Trend hypothesis.} For some function $\lambda:\mathbb N \rightarrow \mathbb R_+$ such that $\lambda=o(1)$ as $n \rightarrow \infty$, for all $1 \leq l\leq k$, 		$$\left\vert \mathbb{E}\left[\Delta Y^{(l)}_n(m)\vert \mathbf{F}_{n}(m) \right]-F_l\left(\frac{m}{n},\frac{Y^{(1)}_n(m)}{n},...,\frac{Y^{(k)}_k(m)}{n}\right)\right\vert\leq \lambda(n)$$ when $m<H_D(Y^{(1)}_n,...,Y^{(k)}_n)$. 	 	Then: 	[topsep=0cm] 		\item[\emph{(a)}] For $(0,{z}_1,\ldots,{z}_a)\in D$, the system of differential equations 		$$y'_l(t)=F_l(t,y_1,\ldots,y_k),\quad y_l(0)=\hat{z}_l, \quad l=1,\ldots,k $$ 		has a unique maximal solution. 		\item[\emph{(b)}] Let $\eta(n) \geq \lambda(n)+C_0 n\gamma(n) $ with $\eta(n)=o(1)$. For a sufficiently large constant $C$, with probability $1-O\left(n\gamma(n)+\frac{\beta(n)}{\eta(n)}\exp\left(-\frac{n\eta^3(n)}{\beta^3(n)}\right)   \right),$ 		$$Y^{(l)}_n(m)=n y_l\left(\frac{m}{n}\right)+O\left(\eta(n) n\right) $$ 		uniformly in $0\leq m\leq \sigma(n) n $ and $1\leq l \leq k$, where $y_l$ is the solution in \emph{(a)} with $z_l=Y^{(l)}_n(0)/n$, and $\sigma(n)$ is the supremum of the times $t$ to which the solution can be extended before reaching within $\ell^{\infty}$-distance $C\eta(n)$ of the boundary of $D$.",2502.01424
definition,"We call \emph{gel mass function} the function $g_p:[0,\infty)\rightarrow [0,1)$ which is null on $[0,1/2]$ and defined on $[1/2,\infty)$ as the \emph{inverse} of the function $f_p:[0,1) \rightarrow [1/2,\infty)$ given for $t \in [0,1)$ by  f_p(t)~=~\frac{1}{2}+\frac{t}{2p}\int_{0}^1 \frac{u^{\frac{1}{p}}}{1-tu} \mathrm du~=~\frac{1}{2}\sum_{n=0}^{\infty}\frac{t^n}{1+pn}.",2502.01424
definition,"For $\varepsilon>0$ small enough and all $n\geq 1$, we define the (random) couple of  functions $\big(g_{p,n}^{(\varepsilon)}(t),d_{p,n}^{(\varepsilon)}(t)\big)_{t\geq 1/2}$ as: 	\vspace{-0.3cm} 	$${ll} 		\bullet \text{ the solution to \eqref{eq:syst_EDO} starting from } \displaystyle\left(\frac{G_{p,n}\left(\left\lfloor\frac{n}{2}+\varepsilon n\right\rfloor\right)}{n}, \frac{D_{p,n}\left(\left\lfloor\frac{n}{2}+\varepsilon n\right\rfloor\right)}{n}\right) & \text{on }I_n(\varepsilon)\\ 		\bullet ~\left(g_p\left(t+\varepsilon\right),d_p(t+\varepsilon)\right)_{t\geq 1/2} &\text{on } I_n(\varepsilon)^c. 	$$",2502.01424
definition,"For $\varepsilon>0$ small enough and $A>0$,  	$$	D_{\varepsilon,A}=\left\{(t,g,d)\in \left(-\varepsilon, A+1\right)\times(0,K_{\varepsilon,A})\times (0,A+1)~:~\frac{1-K_{\varepsilon,A}}{2}<\frac{t+1/2+\varepsilon-d-g}{1-g}<\frac{1}{2}-\kappa_{\varepsilon} \right\}.$$  Additionally, define  for $(t,g,d)\in D_{\varepsilon,A}$, $$F_{\varepsilon}\left(t,g,d\right)=\frac{2pg(1-g)^2}{1-2(t+1/2+\varepsilon)+g+2d}.$$",2502.01424
definition,"A random variable $B$  follows a \emph{Borel distribution} with parameter $\theta \in (0,1]$ if it is $\mathbb N-$valued and $$ \mathbb P(B=k)=\frac{k^{k-2}}{(k-1)!}\cdot \theta^{k-1} e^{-\theta k}, \qquad \forall k \in \mathbb N. $$ For $r \in \mathbb N$, a random variable $T_r$  follows a \emph{Borel-Tanner distribution} with parameter $\theta \in (0,1]$ if it takes its values in $\{r,r+1,r+2, \ldots\}$ and $$ \mathbb P(T_r=k)=\frac{r}{(k-r)!}\cdot k^{k-r-1}\theta^{k-r} e^{-\theta k}, \qquad \forall k\geq r. $$",2502.01424
proof,"Given that a tree of size $k$ is a connected component of $\mathrm{F}_{p,n}(m)$, it will freeze at time $m+1$  [topsep=0pt] 	\item[-] either if the edge selected at time $m+1$ involves two vertices of that tree, which happens with probability $\frac{k(k-1)}{n(n-1)}$ 	\item[-] or if the edge selected at time $m+1$ involves a vertex of the tree and a vertex of the freezer and is retained, which happens with probability $p \cdot \frac{2k G_{p,n}(m)}{n(n-1)}$.  Next, with a set of $V_{p,n}(m) \geq 1$ vertices, one can build for $k\leq V_{p,n}(m)$  $$ \binom{V_{p,n}(m)}{k} \cdot k^{k-2} \quad \text{different trees of size $k$} $$ (recall Cayley's formula: there are $k^{k-2}$ different trees on a fixed set of $k$ vertices). And since the forest part of $\mathrm{F}_{p,n}(m)$, conditionally on $\mathbf{F}_{p,n}(m)$, is a uniform random forest with $V_{p,n}(m)$ vertices and $E_{p,n}(m)$ edges, the probability that a given tree of size $k \leq E_{p,n}(m)+1$, $k\geq 1$, belongs to this forest is  $$ \frac{\#\mathcal{W}(V_{p,n}(m)-k,E_{p,n}(m)-k+1)}{\#\mathcal{W}(V_{p,n}(m),E_{p,n}(m))}, $$ with the conventions of the statement when $E_{p,n}(m)=V_{p,n}(m)-1$ or $E_{p,n}(m)=V_{p,n}(m)=0$. Gathering these remarks gives the stated expression of $\mathbb{P}\left( \Delta G_{p,n}(m)=k ~| ~ \mathbf{F}_{p,n}(m)\right)$.  Regarding $D_{p,n}$, simply note that the edge selected at time $m+1$ is discarded [topsep=0pt] 	\item[-] either if it involves two vertices of the freezer of $\mathrm{F}_{p,n}(m)$, which, conditionally on $\mathbf{F}_{p,n}(m)$, happens with probability $\frac{G_{p,n}(m)\left(G_{p,n}(m)-1\right)}{n(n-1)}$ 	\item[-] or if it involves a vertex of the forest and a vertex of the freezer and it is not retained, which,  conditionally on $\mathbf{F}_{p,n}(m)$, happens with probability $(1-p) \cdot 2 \cdot  \frac{G_{p,n}(m)\left(n-G_{p,n}(m)\right)}{n(n-1)}$.",2502.01424
proof,"We shall repeatedly use the following consequence of Stirling's formula: as $l \in \mathbb N \rightarrow \infty$, uniformly for all integers $k \in \big[ 1,\epsilon(l) \sqrt l \big]$  $$ \frac{l!}{(l-k)!}=(1+o_l(1)) \cdot l^k. $$	 1) When $\Omega_{p,n}(m)\to -\infty$, one has $~V_{p,n}(m)\to \infty~$ and so $~\Omega_{p,n}^{(k)}(m)= \Omega_{p,n}(m)\big(1+o_{V_{p,n}(m)}(1)\big)$, uniformly in $1\leq k\leq \left(V_{p,n}(m)\right)^{1/2}$. Applying the subcritical regime estimate of Proposition \ref{lm:Britikov} together with Stirling's formula, we thus get {5pt}  	\frac{\#\mathcal{W}(V_{p,n}(m)-k,E_{p,n}(m)-k+1)}{\#\mathcal{W}(V_{p,n}(m),E_{p,n}(m))}&=\big(1+o_{\Omega_{p,n}(m)}(1)\big)\cdot 2^{k-1} \cdot \frac{\left(V_{p,n}(m)-k\right)^{2(E_{p,n}(m)-k+1)}}{V_{p,n}(m)^{2E_{p,n}(m)}}\\          & \hspace{-0.5cm} \times  \frac{E_{p,n}(m)!}{\left(E_{p,n}(m)-k+1\right)!} \cdot \left(\frac{\left(2E_{p,n}(m)-V_{p,n}(m)-k+2\right)V_{p,n}(m)}{(2E_{p,n}(m)-V_{p,n}(m))(V_{p,n}(m)-k)}\right)^{1/2} \\ 	&=\big(1+o_{(\Omega_{p,n}(m),E_{p,n}(m))}(1)\big) \cdot 2^{k-1} \cdot V_{p,n}(m)^{-2k+2} E_{p,n}(m)^{k-1} \\ 	& \hspace{-0.5cm} \times \mathrm{e}^{-2kE_{p,n}(m)/V_{p,n}(m)}      when $(\Omega_{p,n}(m),E_{p,n}(m))\to (-\infty,\infty)$, uniformly for all $1\leq k\leq \epsilon(E_{p,n}(m))\left(E_{p,n}(m)\right)^{1/2}$. Together with Proposition \ref{lm_transitions} this leads to    \mathbb{P}\left( \Delta G_{p,n}(m)=k | \mathbf{F}_{p,n}(m)\right)&=\big(1+o_{(\Omega_{p,n}(m),E_{p,n}(m))}(1)\big) \cdot \frac{k^{k-1}}{k!} \cdot \left(2E_{p,n}(m)\right)^{k-1}V_{p,n}(m)^{-2k+2}\\  & \qquad \times \mathrm{e}^{-2kE_{p,n}(m)/V_{p,n}(m)}\frac{V_{p,n}(m)!}{\left(V_{p,n}(m)-k\right)!} \cdot \left(\frac{k-1+2pG_{p,n}(m)}{n(n-1)}\right)\\  &= \big(1+o_{(\Omega_{p,n}(m),E_{p,n}(m))}(1)\big) \cdot \frac{k^{k-1}}{k!}  \cdot  \left(\frac{2E_{p,n}(m)}{V_{p,n}(m)}\right)^{k-1} \cdot \mathrm{e}^{-2kE_{p,n}(m)/V_{p,n}(m)} \\ & \qquad \times \frac{\left(k-1+2pG_{p,n}(m)\right)\left(n-G_{p,n}(m)\right)}{n^2}  uniformly for all $1\leq k\leq \epsilon(E_{p,n}(m))(E_{p,n}(m))^{1/2}$, where we used again Stirling's formula and that $V_{p,n}(m)=n-G_{p,n}(m)$.  2) The proof is similar. Observe that under the hypotheses we make here we have $\big\lvert\Omega_{p,n}^{(k)}(m)\big\rvert\leq c+o_{V_{p,n}(m)}(1)$, uniformly in $1\leq k\leq (V_{p,n}(m))^{1/2}$.   We can thus apply the asymptotics in the critical regime of Proposition \ref{lm:Britikov} to estimate both $\#\mathcal{W}\left(V_{p,n}(m)-k,E_{p,n}(m)-k+1\right)$ and \linebreak $\#\mathcal{W}\left(V_{p,n}(m),E_{p,n}(m)\right)$, and then plug them in the first identity of Proposition \ref{lm_transitions} to get the result.   3) When $\Omega_{p,n}(m)\to \infty$, again $~V_{p,n}(m)\to \infty~$ and $~\Omega_{p,n}^{(k)}(m)= \Omega_{p,n}(m)\big(1+o_{V_{p,n}(m)}(1)\big)$, uniformly in $1\leq k\leq \left(V_{p,n}(m)\right)^{1/2}$. So we now apply the asymptotics of the supercritical regime of Proposition \ref{lm:Britikov}, together with Proposition \ref{lm_transitions}, to get the expected result. Note that here one may have $E_{p,n}(m)=V_{p,n}(m)-1$, in which case the cardinal $\#\mathcal{W}(V_{p,n}(m)-k,E_{p,n}(m)-k+1)$ is null for each $k$, as well as the probability $\mathbb{P}\left( \Delta G_{p,n}(m)=k  | \mathbf{F}_{p,n}(m)\right)$.",2502.01424
proof,"We use here Proposition \ref{prop_forest_rw} with the measure $\mu_{\mathrm{e}^{-1}}$ and let $X_i,i\geq 1$, be i.i.d. random variables with law $\mu_{\mathrm{e}^{-1}}$. The proof is inspired by \cite{BernikovichPavlov11} for similar results in the case of unlabelled forests.  We recall that the expectation of $\mu_{\mathrm{e}^{-1}}$ is equal to 2 and introduce the centered random variables $Y_i=X_i-2$, $i\geq 1$, as well as $\tilde{S}_N=\sum_{i=1}^{N}Y_i  $ and $ \tilde{S}_N^{(r-2)}=\sum_{i=1}^N Y_i^{(r-2)} $, with $Y_i^{(r-2)}=Y_i\mathbbm{1}_{\{Y_i\leq r-2\}}$, for $N,r \geq 1$. From Proposition \ref{prop_forest_rw}, for any $r\in \mathbb N$:  \mathbb{P}\left(L_1(N,M)\leq r\right)&=\frac{\mathbb{P}\left(\max_{i\leq N-M}Y_i\leq r-2,\tilde{S}_{N-M}=\omega(N)N^{2/3}\right)}{\mathbb{P}\left(\tilde{S}_{N-M}=\omega(N)N^{2/3}\right) }\\ &\leq~\frac{\mathbb{P}\left(\tilde{S}_{N-M}^{(r-2)}=\omega(N)N^{2/3}\right)}{\mathbb{P}\left(\tilde{S}_{N-M}=\omega(N)N^{2/3}\right)}.  The measure $\mu_{\mathrm{e}^{-1}}$ being in the domain of attraction of a $3/2$-stable law, the local limit theorem (see e.g. \cite{GnedenkoKolmogorov54}) yields, under the assumption $2M-N=\omega(N)N^{2/3}$ with $\omega(N)\to \infty $ and $\omega(N)=o\big(N^{1/3}\big)$,   \mathbb{P}\left(\tilde{S}_{N-M}=\omega(N)N^{2/3}\right)=\frac{\left(1+o(1)\right)}{\sqrt{2\pi}} \cdot \omega(N)^{-5/2}N^{-2/3}.  We now want to get an upper bound for $\mathbb{P}\big(\tilde{S}_{N-M}^{(r-2)}=\omega(N)N^{2/3}\big)$ when $r=g(N)N^{2/3}$ with $g(N) \rightarrow \infty$ and $g(N)=o(\omega(N))$. Since $\big\vert r^{-1} Y_1^{(r-2)}\big \vert \leq 1$ and $\mathrm{e}^x\leq 1+x+x^2$ for all $x \in [-1,1]$, we have that  \mathbb{P}\left(\tilde{S}_{N-M}^{(r-2)}=\omega(N)N^{2/3}\right)&\leq \mathrm{e}^{-r^{-1} \omega(N)N^{2/3}}\mathbb{E}\left[\mathrm{e}^{r^{-1} Y_1^{(r-2)}} \right]^{N-M}\\ &\leq  \mathrm{e}^{-r^{-1} \omega(N)N^{2/3}}\left(\mathbb{E}\left[1+r^{-1} Y_1^{(r-2)}+\left(r^{-1} Y_1^{(r-2)}\right)^2\right]\right)^{N-M}.  The distribution of $Y_1$ yields the existence of $a,b \in (0,\infty)$ such that for every $r$ large enough $$\mathbb{E}\left[Y_1^{(r-2)}\right]\leq \frac{-a}{\sqrt{r}} \quad \text{ and }\quad \mathbb{E}\Big[\left(Y_1^{(r-2)}\right)^2\Big]\leq b\sqrt{r}$$  which then leads to  	\mathbb{P}\left(\tilde{S}_{N-M}^{(r-2)}=\omega(N)N^{2/3}\right)&\leq \mathrm{e}^{-r^{-1} \omega(N)N^{2/3}}\left(1+br^{-3/2}\right)^{N-M}\\ 	&\leq \mathrm{e}^{-\omega(N)/g(N)}\mathrm{e}^{bNr^{-3/2}/2}.  Together with (\ref{eq:forest}) and since $N r^{-3/2}=g(N)^{-3/2}\to 0$ as $N\to \infty$, we get the expected upper bound for $\mathbb{P}\big(L_1(N,M)\leq g(N)N^{2/3}\big)$.",2502.01424
proof,"Most assertions of this corollary are easy to check by using the differential equations defining $g_p$ and $d_p$ and the relations between the different functions. We leave their proof to the reader. We wish however to point out that the identity $r_p(t)=t(1-g_p(t))$, $t\geq 0$ stated in 4) is shown in the proof of the forthcoming Lemma \ref{lm:syst_edo}, and we detail here the two following points:   5) The function $r_p$ is decreasing on $[1/2,\infty)$ (note that this implies that $e_p=r_pv_p$ is also decreasing on $[1/2,\infty)$). Indeed, to see this use that $r_p(t)=t(1-g_p(t))$ and note that this function is decreasing on $[1/2,\infty)$ if and only if $t\mapsto f_p(t)(1-t)$ is decreasing on $[0,1)$. Using the series representation (\ref{def:f_p}) of $f_p$, we get that $$ f_p(t)(1-t)=\frac{1}{2}-\frac{p}{2}  \sum_{n=0}^{\infty} \frac{t^{n+1}}{(1+pn)(1+p(n+1))} $$ which is clearly decreasing.   6) The concavity of $g_p$ is a consequence of the convexity of $f_p$ on $[0,1)$, which is an immediate consequence of the series representation of $f_p$. To see the convexity of $d_p$, note that \linebreak $d''_p=2g_p'(1-p+2pg_p)$ on $[1/2,\infty)$ (and 0 otherwise), which is positive.",2502.01424
proof,"Using that $g_p(t)=0$ for $t\in [0,1/2]$ and that $(g_p(t))_{t\geq 1/2}$ is solution to (\ref{eq:f}), we have  \int_0^{\infty} (1-g_p(t)) \mathrm dt&=&\frac{1}{2}+\int_{1/2}^{\infty} \frac{1-2t(1-g_p(t))}{2pg_p(t)} g_p'(t) \mathrm dt \\ &\underset{s=g_p(t)}=& \frac{1}{2}+ \int_0^1  \frac{1-2f_p(s)(1-s)}{2ps} \mathrm ds \\ &=& \frac{1}{2}+\frac{1}{2p} \int_0^1 \left(1-  \sum_{n=1}^{\infty} \frac{s^{n-1}(1-s)}{1+pn} \right)\mathrm ds \\ &=&  \frac{1}{2}+\frac{1}{2p}- \frac{1}{2p} \left(\sum_{n=1}^{\infty} \frac{1}{(1+pn)n}-\sum_{n=1}^{\infty} \frac{1}{(1+pn)(n+1)} \right).   We then use that  $$ \psi(x+1)=-\gamma_E+\sum_{n=1}^{\infty} \frac{x}{n(n+x)} \quad \text{ for }x\geq 0, $$ (see e.g. \cite{spouge94}) and that $~\psi(x+1)=\psi(x)+1/x~$ for $x>0$ (a trivial consequence of the relation $\Gamma(x+1)=x\Gamma(x)$) to get  \int_0^1 (1-g_p(t)) \mathrm dt&=& \frac{1}{2}+\frac{1}{2p}\left(\frac{1}{1-p}\left(\psi(1/p) +\gamma_E\right)-\left(\psi(1/p)+\gamma_E+p \right) \right) \\ &=&\frac{\psi(1/p)+\gamma_E}{2(1-p)}.  Last, the above series representation of $\psi$ shows that it is increasing, with $\psi(1)+\gamma_E=0$ and $\psi(2)+\gamma_E=1$. Moreover $\psi(x) \sim \ln(x)$ when $x \rightarrow \infty$, which gives the asymptotic behavior of the integral when $p\rightarrow 0$.",2502.01424
proof,"1) We could use the Cauchy-Lipschitz theorem but prefer to give here a direct proof ""by hands"", that gives explicitly the inverse of $g_p^{(\varepsilon,a)}$ and adapts immediately to prove the point 4) - for which Cauchy-Lipschitz does not apply. Assume that $g_p^{(\varepsilon,a)}$ exists and let $f_p^{(\varepsilon,a)}:[a,1)\to \left[1/2,\infty\right)$ denotes its inverse. Then $f_p^{(\varepsilon,a)}$ is solution to the linear differential equation 	$$f'(t)=\frac{1-2(f(t)+\varepsilon)(1-t)}{2pt(1-t)}, \quad t\in [a,1)$$  and one easily checks that it writes $$f_p^{(\varepsilon,a)}(t)=\frac{1}{2}-\varepsilon + \frac{\varepsilon a^{1/p}}{t^{1/p}}+\frac{1}{2pt^{1/p}}\int_{a}^t  \frac{u^{1/p}}{1-u}\mathrm{d}u.$$ This shows that $g_p^{(\varepsilon,a)}$ is uniquely determined, if it exists. Its existence will be proved if we show that $f_p^{(\varepsilon,a)}$ is strictly monotone, that is $\big(f_p^{(\varepsilon,a)}(t)+\varepsilon \big)(1-t)<1/2$ for all $t\in [a,1)$. In that aim, note that  	f_p^{(\varepsilon,a)}(t)+\varepsilon&=\frac{1}{2}+ \frac{\varepsilon a^{1/p}}{t^{1/p}}+\frac{t}{2p}\int_{a/t}^1 \frac{u^{1/p}}{1-tu}\mathrm{d}u\\ 	&\leq \frac{1}{2}+ \frac{\varepsilon a^{1/p}}{t^{1/p}}+\frac{t}{2p(1-t)}\int_{a/t}^1 u^{1/p}\mathrm{d}u\\ 	&\leq \frac{1}{2}+ \frac{\varepsilon a^{1/p}}{t^{1/p}}+\frac{t}{2p(1-t)} \cdot \frac{1-\left(a/t\right)^{1+\frac{1}{p}}}{1+1/p}   and then  	\big(f_p^{(\varepsilon,a)}(t)+\varepsilon \big)(1-t)&\leq \frac{1-t}{2}+\varepsilon a^{1/p}t^{-1/p}(1-t)+\frac{t}{2(p+1)}\big(1-\left(a/t\right)^{1+\frac{1}{p}}\big)\\ 	&=\frac{1}{2}+\frac{h(t)}{t^{1/p}}        with  $$h(t)=\varepsilon a^{1/p}(1-t)-\frac{pt^{1+\frac{1}{p}}}{2(p+1)}-\frac{a^{1+\frac{1}{p}}}{2(p+1)}$$ a decreasing function on $[a,1)$. Consequently, for every $t\in [a,1)$ we have $h(t)\leq h(a)$ \linebreak $=a^{1/p}\left(\varepsilon-a\left(\varepsilon +1/2\right)\right) $ and thus $\big(f^{(\varepsilon,a)}_p(t)+\varepsilon\big)(1-t)<1/2 $ as soon as $a>\frac{2\varepsilon}{1+2\varepsilon}$.     2) The function $f^{(\varepsilon,a)}_p$ defined above is in fact well-defined for all $t \in (0,1)$, and for a fixed $t$, $a \in \left(\frac{2\varepsilon}{1+2\varepsilon},1 \right) \mapsto f^{(\varepsilon,a)}_p(t)$ is decreasing. This implies that $g_p^{(\varepsilon,a)}(t)<g_p^{(\varepsilon,b)}(t)$ for $t \geq 1/2$.  Then note that for $s>1/2$, the function $$ x \in  \left(1-\frac{1}{2s},1\right)\mapsto G(s,x):=\frac{2px(1-x)}{1-2s(1-x)} $$             is positive, decreasing. Finally write for $t>1/2$  0 \leq g_p^{(\varepsilon,b)}(t) -g_p^{(\varepsilon,a)}(t) &=& b-a+\int_{1/2}^{t}  G(s,g_p^{(\varepsilon,b)}(s))-G(s,g_p^{(\varepsilon,a)}(s)) ~ \mathrm ds \\ &\leq & b-a.  	 3) Here we just use that for any $t \geq a$, the function, $$ \varepsilon \in (0,\infty) \mapsto \frac{1}{2}-\varepsilon + \frac{\varepsilon a^{1/p}}{t^{1/p}}+\frac{1}{2pt^{1/p}}\int_{a}^t  \frac{u^{1/p}}{1-u}\mathrm{d}u $$ is decreasing.  4) We proceed as in point 1) and show similarly that $f_p(t)(1-t)<1/2$ for every $t\in (0,1)$ which leads to the result.",2502.01424
proof,"1) Consider $(g,d)$ a solution to $(\tilde{E}_{(\varepsilon)})$ starting from $(a,b)$ and set $$  r(t)=\frac{t+\varepsilon-g(t)-d(t)}{1-g(t)}, \quad t \geq 1/2. $$ The first part of  \eqref{eq:syst_EDO} rewrites for $t>1/2$ 	$$g'(t)=\frac{2pg(t)(1-g(t))}{1-2r(t)}.$$  Our goal is to prove that $r(t)=(t+\delta_{(a,b)}(\varepsilon))(1-g(t))$ for every $t \geq 1/2$ which will yield the claim. In that aim set for $t\geq 1/2$, $$h(t)=r(t)-(t+\delta_{(a,b)}(\varepsilon))(1-g(t)).$$ By definition of $\delta_{(a,b)}(\varepsilon)$, $h\left(1/2\right)=0$. Then, for $t > \frac{1}{2}$ 	 		h'(t)&=\frac{1-g'(t)-d'(t)}{1-g(t)}+\frac{g'(t)}{1-g(t)}r(t)-\left(1-g(t)\right)+\big(t+\delta_{(a,b)}(\varepsilon)\big)g'(t)\\ 		&=-h(t)\frac{g'(t)}{1-g(t)} 	  	which implies that $h$ is identically zero.  	 2) When $a>2\delta_{(a,b)}(\varepsilon)/(1+2\delta_{(a,b)}(\varepsilon))$ or $a=\delta_{(a,b)}(\varepsilon)=0$, Lemma \ref{lm:equadiff} gives the existence of a solution $g$ to $(E_{(\delta_{(a,b)}(\varepsilon))})$ starting from $a$. Defining then $d$ from $g$ by $$d(t)=b+\int_{1/2}^{t}\left(2(1-p)g(s)\left(1-g(s)\right)+g^2(s)\right)\,\mathrm{d}s, \quad t\geq \frac{1}{2},$$ one sees that $(g,d)$ is a solution $(\tilde{E}_{(\varepsilon)})$ starting from $(a,b)$ (using the same strategy as above with the ratio function $r$).  To prove the uniqueness, we use 1) together with Lemma \ref{lm:equadiff} which gives the uniqueness of a solution $g$ to $(E_{(\delta_{(a,b)}(\varepsilon))})$ starting from $a$ (this function being $g_p$ when $a=\delta_{(a,b)}(\varepsilon)=0$). The function $d$ is then uniquely determined from $g$.",2502.01424
proof,"For the uniqueness of solutions to this system, note that if $(t_k,k\geq 1)$ is a solution to this equation, then $t_1$ is the solution to a linear differential equation of the first order, and so it is uniquely determined by its initial condition $t_1(0)=1$. Then we proceed by induction on $k$, noticing that, given the functions $t_i, i \leq k-1$, the function $t_k$ is also solution to a linear differential equation of the first order and so is uniquely determined by its value at $t=0$.  To prove the existence, we just have to check that the functions $t_{p,k}, k\geq 1$ are solutions. Regarding the initial conditions, we clearly have that $t_{p,1}(0)=1$ since $g_p(0)=0$, and $t_{p,k}(0)=0$ for $k\geq 2$. Then, setting $u_k(t)=t_k(t)/(t_1(t))^k$ for $k \geq 1$, we note that the system of equations rewrites $$\left\{ 	{ll} 	        t_1'(t)=-2t_1(t)(1-(1-p)g_p(t)), \quad t_1(0)=1 \\ 		u_k'(t)=\sum_{i+j=k}iju_i(t)u_j(t), \quad u_k(0)=0 \text{ for }k\geq 2 	 	\right. \qquad t\geq 0.$$ We immediately see from the definition of $t_{p,1}$ and (\ref{eq:f}) that $t_{p,1}'(t)=-2t_{p,1}(t)(1-(1-p)g_p(t))$, $\forall t \geq 0$. Next, consider the functions $$ u_{p,k}(t):=\frac{t_{p,k}(t)}{(t_{p,1}(t))^k}=\frac{k^{k-2}}{k!}\left(2t\right)^{k-1}, \quad t \geq 0 $$ and write for $k\geq 2$  \sum_{i+j=k}iju_{p,i}(t)u_{p,j}(t)&=& (2t)^{k-2} \cdot \sum_{i=1}^{k-1}\frac{i^{i-1}}{i!} \cdot \frac{(k-i)^{k-i-1}}{(k-i)!}  \\ &\underset{(\text{by }(\ref{eq:ijk}))}=& \frac{2 k^{k-3}}{(k-2)!} \cdot (2t)^{k-2}.  The left-hand side is equal to $u'_{p,k}(t)$, which shows that the functions $t_{p,k},k\geq 1$ are indeed solutions to the system of differential equations of the statement of the proposition.",2502.01424
proof,"For each $n\in \mathbb N$, introduce the process $M_n$ defined by $M_n(0)=0$ and 	$$M_n(m)=\sum_{k=0}^{m-1}\left(\Delta Y_n(k)-\mathbb{E}\left[\Delta Y_n(k)|\mathbf{G}_n(k)\right]\right), \quad m\geq 1.$$ This defines a martingale (with respect to the filtration $\mathbf G_n$) with bounded jumps: $\left\vert \Delta M_n(m)\right\vert \leq 2u_n$, $\forall m \in \mathbb Z_+$. The stopped process defined by $M_n^{T_n}(m)=M_n\left(T_n\wedge m\right)$ is also a martingale, and so is $M_n-M_n^{T_n}$. The jumps of this last martingale are uniformly bounded by $2u_n$ and we conclude by applying Azuma-Hoeffding inequality to $M_n-M_n^{T_n}$ at time $\lfloor An\rfloor$.",2502.01424
proof,"Fix $A\in \left(1/2,1\right)$. Consider the stopping time 		$$T_n:=\inf\left\{m\geq n/2:\, 2E_{p,n}(m)-V_{p,n}(m)\geq \ln(n)^3 n^{2/3} \right\}$$ and the random time $$S_n:=\inf\left\{s\in \left[n/2, T_n\right]\cap \mathbb Z_+ : \frac{\ln(n)^3 n^{2/3}}{2}\leq 2E_{p,n}(m)-V_{p,n}(m)<\ln(n)^3n^{2/3}\quad\forall m \in [s,T_n) \right\}$$ (with the convention $\inf\{\emptyset\}=\infty$). Using that the positive jumps of the process $m \mapsto 2E_{p,n}(m)-V_{p,n}(m)$ are smaller or equal to 2,  we see that for $n$ not too small $\left\{T_n<\infty \right\}\subset \left\{S_n<\infty \right\}$ and that when $T_n<\infty$, $2E_{p,n}(S_n)-V_{p,n}(S_n)\leq \ln(n)^3n^{2/3}/2+2$. This in turn implies that for all $m\in [S_n,S_n+n^{2/3}]$,  $$\frac{\ln(n)^3 n^{2/3}}{2}~\leq~2E_{p,n}(m)-V_{p,n}(m)~\leq 2E_{p,n}(S_n)-V_{p,n}(S_n)+2n^{2/3}~\leq~\frac{\ln(n)^3 n^{2/3}}{2}+2n^{2/3}+2.$$ Consequently, 		 			\{ T_n\leq An\}\subset\bigcup_{s=\left\lceil\frac{n}{2}\right\rceil}^{\left\lfloor An\right\rfloor}A_n(s) 		  with, for $s \in \mathbb Z_+$, $$A_n(s)=\left\{\forall m\in \left[s,s+n^{2/3}\right],\, \frac{\ln(n)^3 n^{2/3}}{2}\leq 2E_{p,n}(m)-V_{p,n}(m)\leq\frac{\ln(n)^3 n^{2/3}}{2}+2n^{2/3}+2  \right\}.$$ Heuristically, on $A_n(s)$ the forest part of the graph is supercritical over the time interval $[s,s+n^{2/3}]$ and this supercriticality hardly varies. In particular, the vertices of a tree of size larger than $2n^{2/3}+5$ at time $s$, if there are any, will not be frozen at time $\lfloor s+n^{2/3} \rfloor$.   Let $T^{(1)}_{p,n}(s)$ be the largest tree in the forest at time $s$ (if several trees have the largest size, we choose such a tree at random) and $\# T^{(1)}_{p,n}(s)$ its size. We use the splitting 		 			A_n(s)\subset &\bigg\{\# T^{(1)}_{p,n}(s)>\ln(n)n^{2/3}, \text{the vertices of }T^{(1)}_{p,n}(s)  \text{ are not frozen at time } \lfloor s+n^{2/3} \rfloor \bigg\}\\ & \cup  \bigg\{\# T^{(1)}_{p,n}(s)\leq \ln(n)n^{2/3},\,  \frac{\ln(n)^3n^{2/3}}{2} \leq 2E_{p,n}(s)-V_{p,n}(s)\leq \ln(n)^3n^{2/3} \bigg\} 		 to obtain a relevant upper bound for $\mathbb P(A_n(s))$. Note that at each step in the process $\mathrm{F}_{p,n}$, the probability that the new arriving edge creates a cycle in a given tree of size $k$ (sending therefore this tree in the gel) is $\frac{k(k-1)}{n(n-1)}$. Consequently,		 		 			& \mathbb P\left(\# T^{(1)}_{p,n}(s)>\ln(n)n^{2/3}, \text{the vertices of }T^{(1)}_{p,n}(s)  \text{ are not frozen at time } \lfloor s+n^{2/3} \rfloor \right)\notag\\ 			& \hspace{2cm}\leq \left(1-\frac{\ln(n)^2n^{4/3}}{n(n-1)}+\frac{\ln(n)n^{2/3}}{n(n-1)}\right)^{n^{2/3}}~\underset{n\to \infty}{\sim} \mathrm{e}^{-\ln(n)^2}.ot_freeze} 		 	Next, recalling that $L_1(N,M)$ denotes the size of the largest tree in a uniform random forest with $N$ vertices and $M$ edges, Proposition \ref{prop:freeforest} yields 		 			&&\mathbb{P}\left(\# T^{(1)}_{p,n}(s)\leq \ln(n)n^{2/3},\, \frac{\ln(n)^3n^{2/3}}{2} \leq 2E_{p,n}(s)-V_{p,n}(s)\leq \ln(n)^3n^{2/3}  \right)\\ 			&\leq & \mathbb{E}\left[\mathbb{P}\left(L_1\left(V_{p,n}(s),E_{p,n}(s)\right)\leq  \frac{\ln(n)}{(1-A)^{2/3}} \cdot V_{p,n}(s)^{2/3}, \right.\right.\\ 			&& \hspace{1cm}\left. \left. \frac{\ln(n)^3}{2}\cdot V_{p,n}(s)^{2/3} \leq 2E_{p,n}(s)-V_{p,n}(s)\leq \frac{\ln(n)^3}{(1-A)^{2/3}} \cdot V_{p,n}(s)^{2/3}~\Big\vert~\mathbf{F}_{p,n}(s)\right)\right] 		 where we used that $(1-A)n \leq V_{p,n}(s) \leq n$ for $s\leq \lfloor An \rfloor$ and recall that $\mathbf{F}_{p,n}$ is the filtration generated by $(V_{p,n},E_{p,n})$. Recall also that $A<1$. 	 Lemma \ref{lm:forest:super}, whose assumptions  are clearly satisfied here, implies that the conditional probability above is smaller than $c_1 (\ln(n))^{15/2} n^{2/3} e^{-c_2\ln(n)^2}$ for deterministic constants $c_1,c_2\in (0,\infty)$ (that depend on $A$) and all $n$ large enough, whatever $s \leq \lfloor An\rfloor$. All in all, we have shown that $$\mathbb P(A_n(s)) \leq e^{-c_3 \ln(n)^2}$$ for some $c_3\in (0,\infty)$ and all $n$ large enough, whatever $s \leq \lfloor An\rfloor$.  Finally, applying the union bound to (\ref{eq:subs:surcrit}) gives the result.",2502.01424
proof,"Fix $\varepsilon \in (0,1/2)$ small enough such that the conclusion of (\ref{eq:borne_inf_edges}) holds on $\tilde{A}_n(\varepsilon)$. 	Corollary \ref{corol:est_transitions} and its consequence \eqref{eq:crit_surcrit} provide $A>0$ (depending on $\varepsilon$) such that for $n$ large enough (the threshold also depends on $\varepsilon$) and all $m\in \left[\frac{n}{2}+\tilde{c}(p)\varepsilon n, \frac{n}{2}+\varepsilon n  \right]$, on the event $\tilde{A}_n(\varepsilon)$: 	 	$\quad \bullet$	for $m\geq 1$  such that $2E_{p,n}(m)-V_{p,n}(m)\leq -AV_{p,n}(m)^{2/3}$ and every $k \in \{1,...,V_{p,n}(m)^{1/4}\} $  		 			\mathbb{P}\left(\Delta G_{p,n}(m)=k\vert \mathbf{F}_{p,n}(m)\right)~\geq~(1-\varepsilon) \frac{k^{k-1}}{k!}\left(\frac{2E_{p,n}(m)}{V_{p,n}(m)}\right)^{k-1}\mathrm{e}^{-2k\frac{E_{p,n}(m)}{V_{p,n}(m)}}\frac{2pG_{p,n}(m)(n-G_{p,n}(m))}{n^2}  		 		 	$\quad \bullet$ for $m\geq 1$ such that $2E_{p,n}(m)-V_{p,n}(m)>-AV_{p,n}(m)^{2/3}$ and every $k \in \{1,...,V_{p,n}(m)^{1/4} \}$ 		 			\mathbb{P}\left(\Delta G_{p,n}(m)=k\vert \mathbf{F}_{p,n}(m)\right)~\geq~\frac{c_A} {k^{3/2}} \cdot \frac{G_{p,n}(m)\left(V_{p,n}(m)-E_{p,n}(m)\right)}{n^2} 		 		where $c_A \in (0,\infty)$ only depends on $A$.  	Here we used that, on $\tilde{A}_n(\varepsilon)$, $E_{p,n}(m)$ and $V_{p,n}(m)$ are deterministically large as soon as $n$ is large, thanks to \eqref{eq:borne_inf_edges} and (\ref{eq:def_H_n}), and also that $V_{p,n}(m)-E_{p,n}(m)-1\geq (V_{p,n}(m)-E_{p,n}(m))/2$ for $n$ large enough, since $V_{p,n}(m)-E_{p,n}(m)=n-m+D_{p,n}(m)\geq (1/2-\varepsilon) n$ when $m \leq n/2+\varepsilon n$.  	 We will need the existence, ensured by Lemma \ref{lm:partial_sum}, of $\delta>0$ and $N_0 \in \mathbb N$ (depending both on $\varepsilon$) such that:   	&& S_{N_0}(2z)=\sum_{k= 1}^{N_0}\frac{k^k}{k!}\left(2z\right)^{k-1}\mathrm{e}^{-2kz}~\geq~\frac{1-\varepsilon}{1-2z}, \quad \forall z\in \left[0,\frac{1}{2}-\delta\right] _{p,n}_1}\\ 	&&	2p\cdot (1-\varepsilon)\cdot \tilde{c}(p)\varepsilon \cdot (1-(2+c(p))\varepsilon)\cdot S_{N_0}(2z)~\geq~2(1+p), \quad \forall z\in \left[\frac{1}{2}-\delta,\frac{1}{2}\right] _{p,n}_2}\\ 	&&	\sum_{k=1}^{N_0}\frac{c_A}{\sqrt{k}} \left(\frac{1}{2}-\varepsilon\right)\tilde{c}(p)\varepsilon~\geq~2(1+p).   	 We then distinguish three cases to show the expected inequality of the statement for \linebreak $m\in\left[\frac{n}{2}+\tilde{c}(p)\varepsilon n,\frac{n}{2}+\varepsilon n\right]$:	  {\underline{Case 1}, when}  $2E_{p,n}(m)-V_{p,n}(m)\leq -2\delta V_{p,n}(m)$: using \eqref{eq:min_probcdtion} and \eqref{eq:min_{F}_{p,n}_1} we get that for $n$ large enough, on $\tilde{A}_n(\varepsilon)$, 		 			\mathbb{E}\left[\Delta G_{p,n}(m)\mathbbm{1}_{\{\Delta G_{p,n}(m)\leq n^{1/4}\}}| \mathbf{F}_{p,n}(m)\right] 			&\geq \left(1-\varepsilon\right)^22p\frac{G_{p,n}(m)\left(n-G_{p,n}(m)\right)}{\left(1-2E_{p,n}(m)/V_{p,n}(m)\right)n^2}\\ 			&=\left(1-\varepsilon\right)^22p\frac{G_{p,n}(m)\left(n-G_{p,n}(m)\right)^2}{\left(n-2m+G_{p,n}(m)+2D_{p,n}(m)\right)n^2}. 		 Observe that on $\tilde{A}_n(\varepsilon)$, by definition of $A_n(\varepsilon)$, 		$\left(1-G_{p,n}(m)/n\right)^2\geq \left(1-(2+c(p))\varepsilon\right)^2,$  		and then use  \eqref{eq:inclusion_An} and \eqref{eq:maj_D_{p,n}} to see that the inequality above implies 		 			& \mathbb{E}\left[\Delta G_{p,n}(m)\mathbbm{1}_{\{\Delta G_{p,n}(m)\leq n^{1/4}\}}| \mathbf{F}_{p,n}(m)\right] \\ 			& \quad \geq \left(1-\varepsilon\right)^2\left(1-(2+c(p))\varepsilon\right)^2 2p\left(1+\frac{2m-n-2D_{p,n}(m)}{n-2m+G_{p,n}(m)+2D_{p,n}(m)}\right) \\ 		 	& \quad \geq \left(1-\varepsilon\right)^2\left(1-(2+c(p))\varepsilon\right)^2 2p\left(1+\frac{2m-n-2\mathrm{c_D}\varepsilon^2 n}{p(2m-n)+2\mathrm{c_D}\varepsilon^2n}\right). 		 		Since $m\geq n/2+\tilde{c}(p)\varepsilon n$, the desired inequality follows in this case for some well chosen constant ${c} \in (0,\infty)$, independent of $\varepsilon$ and $n$.  {\underline{Case 2}, when} $-2\delta V_{p,n}(m)\leq 2E_{p,n}(m)-V_{p,n}(m)\leq -AV_{p,n}(m)^{2/3}$: \eqref{eq:min_probcdtion} yields that for $n$ large enough, on $\tilde{A}_n(\varepsilon)$,   		 			\mathbb{E}\left[\Delta G_{p,n}(m)\mathbbm{1}_{\{\Delta G_{p,n}(m)\leq n^{1/4}\}}| \mathbf{F}_{p,n}(m)\right] &\geq (1-\varepsilon) 2p\frac{G_{p,n}(m)\left(n-G_{p,n}(m)\right)}{n^2}S_{N_0}\left(\frac{2E_{p,n}(m)}{V_{p,n}(m)}\right). 		 Assume now that $\varepsilon$ is small enough such that $(1+\mathrm c_D)\varepsilon \leq 1$. On $ \tilde{A}_n(\varepsilon)$, one then has $G_{p,n}(m)\geq \tilde{c}(p)\varepsilon n$	and $n-G_{p,n}(m)\geq \left(1-(2+c(p))\varepsilon\right)n$ by (\ref{eq:min_G_{p,n}}) and the definition of $A_n(\varepsilon)$ respectively (taking $n$ larger if necessary). The above inequality therefore leads, together with \eqref{eq:min_{F}_{p,n}_2}, to the lower bound 	 	\mathbb{E}\left[\Delta G_{p,n}(m)\mathbbm{1}_{\{\Delta G_{p,n}(m)\leq n^{1/4}\}}| \mathbf{F}_{p,n}(m)\right] 	&\geq 2(1+p). 	 	  {\underline{Case 3}, when} $ 2E_{p,n}(m)-V_{p,n}(m) > -AV_{p,n}(m)^{2/3}$: \eqref{eq:min_prob_cdti_crit+} implies that for sufficiently large $n$, on $\tilde{A}_n(\varepsilon)$, 		 			\mathbb{E}\left[\Delta G_{p,n}(m)\mathbbm{1}_{\{\Delta G_{p,n}(m)\leq n^{1/4}\}}| \mathbf{F}_{p,n}(m)\right] &\geq \sum_{k=1}^{N_0}\frac{c_A}{\sqrt{k}}\frac{G_{p,n}(m)(V_{p,n}(m)-E_{p,n}(m))}{n^2}	\\ 			&\geq \sum_{k=1}^{N_0}\frac{c_A}{\sqrt{k}}\left(\frac{1}{2}-\varepsilon\right)\tilde{c}(p)\varepsilon 		 	where we used that for $m\in \left[\frac{n}{2}+\tilde{c}(p)\varepsilon n,\frac{n}{2}+\varepsilon n\right]$, on $\tilde{A}_n(\varepsilon)$, $G_{p,n}(m)\geq \tilde{c}(p)\varepsilon n$ by (\ref{eq:min_G_{p,n}}) and $V_{p,n}(m)-E_{p,n}(m)=n-m+D_{p,n}(m)\geq \left(1/2-\varepsilon\right)n$. We conclude using \eqref{eq:min_E_crit_sucrit}.",2502.01424
proof,"We use Lemma \ref{lm:syst_edo}. In that aim, introduce 	$$a_n(\varepsilon)=\frac{G_{p,n}\left(\left\lfloor\frac{n}{2}+\varepsilon n\right\rfloor\right)}{n}, \,\,\, b_n(\varepsilon)=\frac{D_{p,n}\left(\left\lfloor\frac{n}{2}+\varepsilon n\right\rfloor\right)}{n} \,\,\, \text{ and }\,  \delta_{n}(\varepsilon)=\frac{\varepsilon-b_n(\varepsilon)-a_n(\varepsilon)^2/2}{\left(1-a_n(\varepsilon)\right)^2}.$$  	 1) By definition of $I_n(\varepsilon)$, it is clear that for $\varepsilon>0$ small enough, $0<\delta_{n}(\varepsilon)<a_n(\varepsilon)/2$ on $I_n(\varepsilon).$ The existence and uniqueness of a solution to \eqref{eq:syst_EDO} follows from Lemma \ref{lm:syst_edo} 2). Moreover Lemma \ref{lm:syst_edo} 1) says that $g_{p,n}^{(\varepsilon)}$ is the unique solution to $(E_{(\delta_n(\varepsilon))})$ (this equation is defined, as  (\ref{eq:syst_EDO}), in Section \ref{section:approximation}) starting from $a_n(\varepsilon)$, which will be useful below.  2) First observe that for any $\varepsilon>0$, the couple $(g_p(\cdot+1/2+\varepsilon),d_p(\cdot+1/2+\varepsilon))$ verifies the desired inequalities $(a)$ and $(b)$ for well-chosen constants $\bar \kappa^{0}_{\varepsilon}>0$, $\bar K^{0}_{\varepsilon,A} \in (0,1)$, see Proposition \ref{prop:propfunctions} for details.   Then observe that for $\varepsilon>0$ small enough, $\delta_n(\varepsilon)< 2\varepsilon$ on $I_n(\varepsilon)$. Consequently, if $\hat{g}_{p,(\varepsilon)}$ denotes the (well-defined) unique solution to $(E_{(2\varepsilon)})$ starting from $C(p)\varepsilon$, since moreover, still on $I_n(\varepsilon)$, ${g}_{p,n}^{(\varepsilon)}$ is the solution to $(E_{(\delta_n(\varepsilon))})$ starting from $a_n(\varepsilon)\leq C(p)\varepsilon$, we have by Lemma \ref{lm:equadiff} that $\tilde{g}_{p,n}^{(\varepsilon)}(t)=g_{p,n}^{(\varepsilon)}(t+1/2)\leq g_{p,n}^{(\varepsilon)}(A+3/2) \leq \hat{g}_{p,(\varepsilon)}(A+3/2)$ for all $t\in \left[0,A+1\right]$. This yields the upper bound (a) with $\bar K_{\varepsilon,A}=\max(\bar K^{0}_{\varepsilon,A},\hat{g}_{p,(\varepsilon)}(A+1)) \in (0,1)$.  Next, working again on $I_n(\varepsilon)$, we have seen in the proof of Lemma \ref{lm:syst_edo} (up to a time shift of $1/2$) that for every $t\geq 0$  	\frac{t+1/2+\varepsilon-\tilde{g}_{p,n}^{(\varepsilon)}(t)-\tilde{d}_{p,n}^{(\varepsilon)}(t)}{1-\tilde{g}_{p,n}^{(\varepsilon)}(t)}= \left(t+1/2+\delta_n(\varepsilon)\right)\big(1-\tilde{g}_{p,n}^{(\varepsilon)}(t)\big)=:\tilde{r}_{p,n}^{(\varepsilon)}(t),  leading to the lower bound of $(b)$. Moreover, observe that $\tilde{r}_{p,n}^{(\varepsilon)}$ verifies  $$\tilde{r}_{p,n}^{(\varepsilon)}(0)\leq \frac{1}{2}-\frac{c(p)\varepsilon}{2}\quad\, \text{and } \quad \left(\tilde{r}_{p,n}^{(\varepsilon)}\right)'(t)=\left(1-\tilde{g}_{p,n}^{(\varepsilon)}(t)\right)\left(1-(t+1/2+\delta_n(\varepsilon))\frac{2p\tilde{g}_{p,n}^{(\varepsilon)}(t)}{1-2\tilde{r}_{p,n}^{(\varepsilon)}(t)}\right), \, t> 0.$$ For $\varepsilon>0$ small enough, by continuity of $\tilde{r}_{p,n}^{(\varepsilon)}$, the time $T:=\inf\big\{t\geq 0:\tilde{r}_{p,n}^{(\varepsilon)}(t)\geq 1/2-\varepsilon^2 \big\}$ (with the usual convention $\inf\{\emptyset\}=\infty$) is strictly positive. It $T$ were finite, there would exist $\eta \in (0,T)$ such that for every $t\in [T-\eta,T]$, $\tilde{r}_{p,n}^{(\varepsilon)}(t)\geq 1/2-2\varepsilon^2$. As $\tilde{g}_{p,n}^{(\varepsilon)}$ is increasing and verifies $\tilde{g}_{p,n}^{(\varepsilon)}(0)\geq (2+c(p))\varepsilon$, it is easy to see that for $\varepsilon>0$ small enough, this would lead to $\big(\tilde{r}_{p,n}^{(\varepsilon)}\big)'(t)\leq 0$ for any $t\in [T-\eta,T]$, which would contradict the definition of $T$. Thus, $T=\infty$ on $I_n(\varepsilon)$ and the claim follows with $\bar \kappa_{\varepsilon}=\min(\bar \kappa^{0}_{\varepsilon},\varepsilon^2)$.",2502.01424
proof,"For $n\geq 1$ and $m\in \big[0,H_{D_{\varepsilon,A}}\big)$, using the definition of $F_{\varepsilon}$, we have that  		&\bigg\vert\mathbb{E}\Big[\Delta \tilde{G}^{(\varepsilon)}_{p,n}(m) | {\mathbf{F}}^{(\varepsilon)}_{p,n}(m)  \Big] -	F_{\varepsilon}\left(\frac{m}{n},\frac{\tilde{G}^{(\varepsilon)}_{p,n}(m)}{n},\frac{\tilde D_{p,n}(m)}{n}\right) \bigg\vert \\ 			\leq & \left\vert\mathbb{E}\left[\Delta G_{p,n}^{(\varepsilon)}(m) | {\mathbf{F}}^{(\varepsilon)}_{p,n}(m)  \right] -\frac{2pG_{p,n}^{(\varepsilon)}(m)(n-G_{p,n}^{(\varepsilon)}(m))}{n^2\left(1-2E_{p,n}^{(\varepsilon)}(m)/V_{p,n}^{(\varepsilon)}(m)\right)}\right\vert\mathbbm{1}_{\{I_n(\varepsilon)\}} \notag \\	 	+& \left \vert \frac{2pG_{p,n}^{(\varepsilon)}(m)(n-G_{p,n}^{(\varepsilon)}(m))^2}{n^3\left(V_{p,n}^{(\varepsilon)}(m)-2\big(m/n+1/2+\varepsilon-G_{p,n}^{(\varepsilon)}(m)-D_{p,n}^{(\varepsilon)}(m)\big)\right)} -\frac{2pG_{p,n}^{(\varepsilon)}(m)(n-G_{p,n}^{(\varepsilon)}(m))^2}{n^3\big(V_{p,n}^{(\varepsilon)}(m)-2E_{p,n}^{(\varepsilon)}(m)\big)} \right\vert \mathbbm{1}_{\{I_n(\varepsilon)\}} \notag\\		 	+&\left\lvert n\left(g_p\left(\frac{m+1}{n}+\frac{1}{2}+\varepsilon\right)-g_p\left(\frac{m}{n}+\frac{1}{2}+\varepsilon\right)\right) -F_{\varepsilon}\left(\frac{m}{n},g_p\left(\frac{m}{n}+\frac{1}{2}+\varepsilon\right),d_p\left(\frac{m}{n}+\frac{1}{2}+\varepsilon\right)\right) \right\rvert \mathbbm{1}_{\{I_n(\varepsilon)^c\}}. \notag   We will show that each of the three terms in the right-hand side of (\ref{3terms}) is deterministically bounded by a function independent of $m$ that converges to 0 as $n \rightarrow \infty$. 		 1) We start by bounding from above the last term: since $\left(g_p(\cdot+\varepsilon),d_p(\cdot+\varepsilon)\right)$ is a solution to \eqref{eq:syst_EDO}, one has for every $m \in \big[0,H_{D_{\varepsilon,A}}\big)$,  n\left(g_p\left(\frac{m+1}{n}+\frac{1}{2}+\varepsilon\right)-g_p\left(\frac{m}{n}+\frac{1}{2}+\varepsilon\right)\right)&=\int_{m}^{m+1}F_{\varepsilon}\left(\frac{s}{n},g_p\left(\frac{s}{n}+\frac{1}{2}+\varepsilon\right),d_p\left(\frac{s}{n}+\frac{1}{2}+\varepsilon\right)\right)\mathrm{d}s\\ &=F_{\varepsilon}\left(\frac{m}{n},g_p\left(\frac{m}{n}+\frac{1}{2}+\varepsilon\right),d_p\left(\frac{m}{n}+\frac{1}{2}+\varepsilon\right)\right)+O\left(\frac{1}{n}\right)  where the $O\left(1/n\right)$ is uniform over $m \in \big[0,H_{D_{\varepsilon,A}}\big)$, as a consequence of the Lipschitz continuity of $F_{\varepsilon}$ over $D_{\varepsilon,A}$ and the fact that the derivatives of $g_p$ and $d_p$ are bounded.   2) Regarding the middle term  in the right-hand side of (\ref{3terms}), we note, using e.g. (\ref{eq:A4}), that it is bounded from above by a constant times  $$ \frac{m/n+1/2+\varepsilon-\lfloor m/n+1/2+\varepsilon \rfloor}{n^2} \leq \frac{1}{n^2} $$ for all $m\in \big[0,H_{D_{\varepsilon,A}}\big)$.  3) Last, on the event $I_n(\varepsilon)$, for every $m\in \big[0,H_{D_{\varepsilon,A}}\big)$, 		 		  &\left\vert\mathbb{E}\left[\Delta G_{p,n}^{(\varepsilon)}(m) | {\mathbf{F}}^{(\varepsilon)}_{p,n}(m)  \right] -\frac{2pG_{p,n}^{(\varepsilon)}(m)(n-G_{p,n}^{(\varepsilon)}(m))}{n^2\big(1-2E_{p,n}^{(\varepsilon)}(m)/V_{p,n}^{(\varepsilon)}(m)\big)}\right\vert\\ 			\leq &\left\vert \mathbb{E}\left[\Delta G_{p,n}^{(\varepsilon)}(m)\mathbbm{1}_{\{\Delta G_{p,n}^{(\varepsilon)}(m)\leq V_{p,n}^{(\varepsilon)}(m)^{1/4}\}} | {\mathbf{F}}^{(\varepsilon)}_{p,n}(m)  \right]-\frac{2p G_{p,n}^{(\varepsilon)}(m)(n-G_{p,n}^{(\varepsilon)}(m))}{n^2}S_{V_{p,n}^{(\varepsilon)}(m)^{1/4}}\left(\frac{2E_{p,n}^{(\varepsilon)}(m)}{V_{p,n}^{(\varepsilon)}(m)}\right) \right\vert \\ 			&+  \mathbb{E}\left[\Delta G_{p,n}^{(\varepsilon)}(m)\mathbbm{1}_{\{\Delta G_{p,n}^{(\varepsilon)}(m)> V_{p,n}^{(\varepsilon)}(m)^{1/4}\}} | {\mathbf{F}}^{(\varepsilon)}_{p,n}(m)  \right] \\ 			&+ 2p \left\vert \frac{1}{1-2E_{p,n}^{(\varepsilon)}(m)/V_{p,n}^{(\varepsilon)}(m)}-S_{V_{p,n}^{(\varepsilon)}(m)^{1/4}}\left(\frac{2E_{p,n}^{(\varepsilon)}(m)}{V_{p,n}^{(\varepsilon)}(m)}\right)  \right\vert  		 		where $S_{N}$ is defined in \eqref{def:S_N} for $N \in \mathbb N$. It remains to show that on the event $I_n(\varepsilon)$ and uniformly over $m<H_{D_{\varepsilon,A}}$, each of the three terms in the right-hand side of this inequality is smaller than a deterministic function of $n$ that converges to 0 as $n \rightarrow \infty$. In the lines below we implicitly work on   $I_n(\varepsilon)$ and with  $m\in \big[0,H_{D_{\varepsilon,A}}\big)$. 		 	\hspace{0.5cm} $\bullet$ By \eqref{eq:A3}, $E_{p,n}^{(\varepsilon)}(m)$ is greater than a constant times $n$, and by \eqref{eq:A4}, $\Omega_{p,n}^{(\varepsilon)}(m)$ is smaller than a negative constant times $n^{1/3}$. Since moreover $V_{p,n}^{(\varepsilon)}(m)\leq n$, Corollary \ref{corol:est_transitions} 1) applies and implies that uniformly in $1 \leq k \leq V_{p,n}^{(\varepsilon)}(m)^{1/4}$, 	 		& \left\vert \mathbb{P}\big(\Delta G_{p,n}^{(\varepsilon)}(m)=k | {\mathbf{F}}^{(\varepsilon)}_{p,n}(m)\big)-\frac{k^{k-1}}{k!}\left(\frac{2E_{p,n}^{(\varepsilon)}(m)}{V_{p,n}^{(\varepsilon)}(m)}\right)^{k-1}\mathrm{e}^{-2k\frac{E_{p,n}^{(\varepsilon)}(m)}{V_{p,n}^{(\varepsilon)}(m)}}\left(\frac{2pG_{p,n}^{(\varepsilon)}(m)\left(n-G_{p,n}^{(\varepsilon)}(m)\right)}{n^2}\right)\right\vert  \\ 		&\leq \left(o_{\big(E_{p,n}^{(\varepsilon)}(m),\Omega_{p,n}^{(\varepsilon)}(m)\big)}(1)+O_{\big(E_{p,n}^{(\varepsilon)}(m),\Omega_{p,n}^{(\varepsilon)}(m)\big)}(1) \cdot \frac{n^{1/4}}{n}\right) \cdot \frac{k^{k-1}}{k!}\left(\frac{2E_{p,n}^{(\varepsilon)}(m)}{V_{p,n}^{(\varepsilon)}(m)}\right)^{k-1}\mathrm{e}^{-2k\frac{E_{p,n}^{(\varepsilon)}(m)}{V_{p,n}^{(\varepsilon)}(m)}}. 	 	There thus exists a deterministic $\lambda_1(n)$ (independent on $m \in \big[0,H_{D_{\varepsilon,A}}\big)$) that converges to 0 as $n \rightarrow \infty$ such that	 	 		\Bigg\vert \mathbb{E}&\Big[\Delta G_{p,n}^{(\varepsilon)}(m)\mathbbm{1}_{\{\Delta G_{p,n}^{(\varepsilon)}(m)\leq V_{p,n}^{(\varepsilon)}(m)^{1/4}\}} | {\mathbf{F}}^{(\varepsilon)}_{p,n}(m)  \Big]-\frac{2p G_{p,n}^{(\varepsilon)}(m)\big(n-G_{p,n}^{(\varepsilon)}(m)\big)}{n^2}S_{V_{p,n}^{(\varepsilon)}(m)^{1/4}}\left(2\frac{E_{p,n}^{(\varepsilon)}(m)}{V_{p,n}^{(\varepsilon)}(m)}\right) \Bigg\vert\\ 		&\leq \lambda_1(n) \cdot \sum_{k\geq 1}\frac{k^{k}}{k!}\left(\frac{2E_{p,n}^{(\varepsilon)}(m)}{V_{p,n}^{(\varepsilon)}(m)}\right)^{k-1}\mathrm{e}^{-2k\frac{E_{p,n}^{(\varepsilon)}(m)}{V_{p,n}^{(\varepsilon)}(m)}} \leq \lambda_1\left(n\right) \cdot (2\kappa_{\varepsilon})^{-1} 	 	where we used (\ref{lm:Borel:law}) and the upper bound of the inequality \eqref{eq:A2} to get the last line.  		 	\hspace{0.5cm} $\bullet$ As we just implicitly said, \eqref{eq:A2} implies $2E_{p,n}^{(\varepsilon)}(m)-V_{p,n}^{(\varepsilon)}(m) \leq -2\kappa_{\varepsilon}V_{p,n}^{(\varepsilon)}(m)$. Recall also that, by (\ref{eq:A1}),$V_{p,n}^{(\varepsilon)}(m)$ is deterministically bounded from below by a constant times $n$. Lemma \ref{lm:forest:sub} and the free forest property of Proposition \ref{prop:freeforest} thus imply that for $n$ large enough   	\mathbb{E}\bigg[\Delta G_{p,n}^{(\varepsilon)}(m)\mathbbm{1}_{\{\Delta G_{p,n}^{(\varepsilon)}(m)>V_{p,n}^{(\varepsilon)}(m)^{1/4}\}}\vert {\mathbf{F}}^{(\varepsilon)}_{p,n}(m)\Big] 	&\leq n\,\mathbb{P}\Big(\Delta G_{p,n}^{(\varepsilon)}(m)>V_{p,n}^{(\varepsilon)}(m)^{1/4} \vert {\mathbf{F}}^{(\varepsilon)}_{p,n}(m) \Big)\notag\\ 	&\leq c_1 nV_{p,n}^{(\varepsilon)}(m)^{3/2}\exp\big(-c_2V_{p,n}^{(\varepsilon)}(m)^{1/4}\big) \notag\\ 	&\leq c_1n^{5/2}\exp\big(-c'_2 n^{1/4}\big), 	 where $c_1,c_2,c'_2$ belong to $(0,\infty)$ and only depend on $\varepsilon$ and $A$.  	\hspace{0.5cm}  $\bullet$ Using again that the ratio $E_{p,n}^{(\varepsilon)}(m)/V_{p,n}^{(\varepsilon)}(m)$ belongs to the compact $\left[0,1/2-\kappa_{\varepsilon}\right]$, we can bound from above the last term by a deterministic function that converges to 0 as $n\rightarrow \infty$, thanks to Lemma \ref{lm:partial_sum} 1) and the fact, by \eqref{eq:A1}, that $V_{p,n}^{\varepsilon}(m) \geq (1-K_{\varepsilon,A})n$.",2502.01424
proof,"We write for $t\geq0$, $\mathcal G_{p,n}(t)=G_{p,n}(\mathcal N((n-1)t/2))$, where $G_{p,n}$ is a discrete version of the $p$-frozen model and $\mathcal N$ is the Poisson process involved in (\ref{lien:dc}), independent of $G_{p,n}$, $\forall n$.   Using that the derivative of $g_p$ is bounded on $\mathbb R_+$ and the convergence in probability of the rescaled process $\mathcal N(n \cdot)/n$ towards the identity function (for the topology of uniform convergence on compacts), we have that for all $A>0$, as $n \rightarrow \infty$, $$ \sup_{t \in [0,A]} \left| g_p\left(\frac{\mathcal N((n-1)t/2)}{n}\right)-g_p(t/2)\right|~\overset{\mathbb P} \longrightarrow~0. $$ Together with Theorem \ref{thm:fluid limit} and a standard use of the triangular inequality this leads to the announced convergence.",2502.01424
proof,"The dynamic of the continuous model implies that conditional on $\mathcal G_{p,n}(t+\sigma_n(1/2))=\ell$ (for $\ell$ integer, $n/2 \leq \ell \leq n$),  we have that $ \mathcal G_{p,n}(t+\varepsilon+\sigma_n(1/2)) \geq \mathcal G_{p,n}(t+\sigma_n(1/2))+1$  with probability greater than   $$p  \left(1-\exp(-\varepsilon  \ell (n-\ell)/n)\right)~\geq~p \left(1-\exp(-\varepsilon (n-\ell)/2)\right), \quad \forall \varepsilon>0. $$ Since the function $~x \mapsto (1-\exp(-x))/x ~$ is decreasing on $(0,\infty)$ and since $n-\ell \leq n/2$ when $\ell \geq n/2$, the above inequality implies that $$ k_n(t+\varepsilon)-k_n(t)=\frac{\mathbb E\left[\mathcal G_{p,n}(t+\sigma_n(1/2))-\mathcal G_{p,n}(t+\varepsilon+\sigma_n(1/2)) \right]}{n}~\leq~ -2p  k_n(t)\frac{1-\exp(-\varepsilon n/4)}{n}. $$ Consequently, for all $t\geq 0$ and all $\varepsilon>0$,  k_n(t)~\leq ~k_n\left(\varepsilon \left \lfloor \frac{t}{\varepsilon} \right\rfloor \right) &\leq& k_n(0) \left(1-2p \frac{1-\exp(-\varepsilon n/4)}{n} \right)^{\lfloor \frac{t}{\varepsilon}\rfloor}~ \underset{\varepsilon \rightarrow 0}\longrightarrow ~ k_n(0) \exp(-pt/2),  which gives the upper bound $k_n(t) \leq k_n(0) \exp(-pt/2) \leq \exp(-pt/2)$ for all $t\geq 0$ and all $n\in \mathbb N$.",2502.01424
proof,"$\bullet$ From the expression of Lemma \ref{lem:cvPnk}, we immediately see that when $t_n \rightarrow \infty$ and $t_n=o(n)$, $$ P^{(k)}_n(\ell,t_n)=\left( \frac{t_n}{n}\right)^{\ell(k-1)}e^{-\ell kpt_n+O\left(\frac{t_n}{n}\right)} \cdot \mathbb E \left[e^{-\ell k (1-p) \int_0^{t_n} \left(1-\frac{\mathcal G_{p,n-\ell k}(u)}{n- \ell k} \right) \mathrm du+O\left(\frac{t_n}{n}\right) }\right], $$ where the $O\left(\frac{t_n}{n}\right)$ in the expectation is deterministic.  So by Corollary \ref{cor:cvintegrale} and then Lemma \ref{lem:identintegral}, $$ \mathbb E \left[e^{-\ell k (1-p) \int_0^{t_n} \left(1-\frac{\mathcal G_{p,n-\ell k}(u)}{n- \ell k} \right) \mathrm du+O\left(\frac{t_n}{n}\right) }\right] \underset{n \rightarrow \infty} \longrightarrow e^{-\ell k\left(\psi(1/p)+\gamma_{\mathrm E}\right)}. $$  $\bullet$ Applying this to $t_n=\mathsf t^{(k)}_{p,n}+c$ immediately gives $n^k \cdot P^{(k)}_n\big(1,\mathsf t^{(k)}_{p,n}+c\big)  \rightarrow e^{-kpc} \cdot e^{-k\left(\psi(1/p)+\gamma_{\mathrm E}\right)}$.",2502.01424
proof,"The ""constants"" $c_1,c_2,c_3$ appearing in this proof may depend on $k$ and $c$, but not on $n$ or $\ell \leq n/k$. On the one hand, by Stirling's formula, there exists some constant $c_1$ such that     \frac{n!}{\ell ! (n-k\ell)!} \; \leq \; \frac{n^{k\ell}}{\ell !} \; \leq \; c_1n^{k\ell} e^{\ell-\ell \ln(\ell)}, \quad \forall n,\ell \geq 1, \ell \leq n/k.  On the other hand, since the expectation involved in the expression of $P_n^{(k)}(\ell,\mathsf t^{(k)}_{p,n}+c)$ is bounded from above by 1, and since $1-e^{-x}\leq x$ for all $x\geq 0$,  $$ P_n^{(k)}(\ell,\mathsf t^{(k)}_{p,n}+c) \leq \left( \frac{\mathsf t^{(k)}_{p,n}+c}{n}\right)^{\ell (k-1)} \cdot e^{-\frac{\mathsf t^{(k)}_{p,n}+c}{n} \left( \frac{\ell k(\ell k-1)}{2}-\ell(k-1)+p\ell k(n-\ell k)\right)}. $$ It is easy to see, using the definition of $\mathsf t^{(k)}_{p,n}$, that for $n$ large enough, simultaneously for all $\ell \geq 1$, $$ e^{\ell(k-1) \ln(\mathsf t^{(k)}_{p,n}+c)-p\ell k \mathsf t^{(k)}_{p,n}} \leq \frac{e^{\ell}}{n^\ell}. $$ And also, for $\ell \leq n/k$, that  $$ e^{\frac{-c}{n} \left( \frac{\ell k(\ell k-1)}{2}-\ell(k-1)+p\ell k(n-\ell k)\right)} \leq e^{c_2 \ell} $$ for some constant $c_2 \in (0,\infty)$.  This implies that   P_n^{(k)}(\ell,\mathsf t^{(k)}_{p,n}+c) \leq \frac{e^{(1+c_2) \ell}}{n^{k\ell}} \cdot e^{-\frac{\mathsf t^{(k)}_{p,n}}{n} \left( \frac{\ell k(\ell k-1)}{2}-\ell(k-1)-p(\ell k)^2\right)}.  $\bullet$ If $p\leq 1/2$, $ \frac{\ell k(\ell k-1)}{2}-\ell(k-1)-p(\ell k)^2 \geq -\frac{3\ell k}{2}$ for all $\ell \geq 1$, so we have that, since moreover $\mathsf t^{(k)}_{p,n} \geq 0$ and $\frac{\mathsf t^{(k)}_{p,n}}{n} \rightarrow 0$ as $n \rightarrow \infty$, $$ P_n^{(k)}(\ell,\mathsf t^{(k)}_{p,n}+c) \leq \frac{e^{c_3 \ell}}{n^{k\ell}}  $$ for all $n$ large enough and all $\ell \geq 1$. Together with (\ref{majo:facto}) this clearly leads to the statement of the corollary.  $\bullet$ If $p\in (1/2,1]$, consider $\eta>0$ such that $a:=(1+\eta)^2(1-\frac{1}{2p}) \in (0,1)$. We then use that $\frac{\mathsf t^{(k)}_{p,n}}{n} \leq (1+\eta) \frac{\ln(n)}{kpn}$ for $n$ large enough, and that $-\frac{\ell k(\ell k-1)}{2}+\ell(k-1)+p(\ell k)^2\leq (1+\eta) (p-\frac{1}{2}) (\ell k)^2$ for $\ell$ large enough, to get for those $n,\ell$, using (\ref{majo:P_n}), $$ P_n^{(k)}(\ell,\mathsf t^{(k)}_{p,n}+c) \leq \frac{e^{(1+c_2) \ell}}{n^{k\ell}} \cdot e^{ (1+\eta)^2 \frac{\ln(n)}{n} \cdot (1-\frac{1}{2p}) \ell^2 k}=\frac{e^{\ell \left((1+c_2)+a\frac{\ln(n)}{n} \ell k\right)}}{n^{k\ell}}. $$ Together with (\ref{majo:facto}), we obtain for those $n,\ell$, assuming moreover that $c_1 \leq e^{\ell}$,   \frac{n!}{\ell ! (n-k\ell !)} \cdot P_n^{(k)}(\ell,\mathsf t^{(k)}_{p,n}+c) \leq e^{\ell \left((3+c_2)+a\frac{\ln(n)}{n}\ell k-\ln(\ell) \right)}=e^{\ell h(\ell)}  where $h(x):=(3+c_2)+a\frac{\ln(n)}{n}x k-\ln(x)$. One easily sees that this function is convex on $(0,\infty)$, with $$ h(x) \leq 3+c_2+\max \left(a \frac{\ln(n)}{n}\ x_0k-\ln(x_0); a \ln(n)-\ln(n/k) \right) \text{ when } x \in [x_0 ; n/k] $$ (whatever $x_0>0$ is). For every $\varepsilon>0$, there exists $\tilde \ell_{\varepsilon} \in \mathbb N$ such that $3+c_2+1-\ln(\tilde \ell_{\varepsilon}) \leq \ln(\varepsilon)$. Then, take $x_0 =\tilde \ell_{\varepsilon}$.  Next, there exists $\tilde n_{\varepsilon} \in \mathbb N$ such that for all $n \geq \tilde n_{\varepsilon}$, we have both $3+c_2+a \ln(n)-\ln(n/k) \leq \ln(\varepsilon)$ (since $a<1$) and $a \frac{\ln(n)}{n} \tilde \ell_{\varepsilon} k\leq 1$. All this implies that for $n \geq \tilde n_{\varepsilon}$ and then $\ell \in [\tilde \ell_{\varepsilon},n/k]$, $$ h(\ell) \leq \ln(\varepsilon). $$ Together with (\ref{ineq:intermediaire1}), this gives the expected upper bound.",2502.01424
proof,"From Lemma \ref{lem:cvPnk},   e^{i} \cdot n^i \cdot P_n^{(i)}(1,\mathsf t^{(k)}_{p,n}+c) &\leq& e^{i+i\ln(n)+(i-1)\ln\Big(\frac{\mathsf t^{(k)}_{p,n}+c}{n}\Big)-\left(\frac{i(i-1)}{2}-(i-1)\right)\frac{\mathsf t^{(k)}_{p,n}+c}{n}-\frac{i(n-i)}{n}p(\mathsf t^{(k)}_{p,n}+c)} \\  &=& e^{\ln(n)\cdot h_n(i)}  where $h_n$ is the polynomial of degree 2 defined for $x \in \mathbb R$ by $$ h_n(x)=\frac{x}{\ln(n)}+x+(x-1)\frac{\ln\Big(\frac{\mathsf t^{(k)}_{p,n}+c}{n}\Big)}{\ln(n)}-\left(\frac{x(x-1)}{2}-(x-1)\right)\frac{\mathsf t^{(k)}_{p,n}+c}{n \ln(n)}-\frac{x(n-x)}{n \ln(n)}p(\mathsf t^{(k)}_{p,n}+c). $$ We let the reader check that as $n \rightarrow \infty$,  $$h_n(k+1)\rightarrow -1/k, \quad  h'_n(k+1)\rightarrow -1/k, \quad h'_n(n) \rightarrow -(1-p)/kp.$$ Hence when $p \in (0,1)$, for $n$ large enough, $h_n'$ is strictly negative, and therefore $h_n$ strictly decreasing, on $[k+1,n]$, uniformly smaller than $-1/2k$ (for $n$ large enough). When $p=1$, $h''_n(x)=\frac{\mathsf t^{(k)}_{p,n}+c}{n\ln(n)}$ for all $x$, hence for $n$ large enough $g_n$ is convex, and $h_n(n) \sim-n/2k$ which, together with $h_n(k+1)\rightarrow -1/k$, implies that $h_n$ is also uniformly smaller than $-1/2k$ on $[k+1,n]$ for $n$ large enough.   In conclusion, whatever $p \in (0,1]$, we have that for $n$ large enough and then all $i \in \llbracket k+1 ,n\rrbracket$, $$ e^{i} \cdot n^i \cdot P_n^{(i)}(1,\mathsf t^{(k)}_{p,n}+c) \leq e^{-\ln(n) \frac{1}{2k}}. $$",2502.01424
proof,"We let $V(\mathrm t_i)$ denote the set of vertices of $\mathrm t_i$, for $i=1,2$. We also let $T<s_1<s_2<\ldots$ be the times larger than $T$ at which the PPP governing $\mathcal {F}_{p,n}$ rings, set $s_0=T$, and introduce for $i\geq 1$ the events:  \item[$\bullet$] $E_{n}(s_i)$=\{at time $s_i$ an edge is added between a vertex of $V(\mathrm t_1)$ and a vertex of $V(\mathrm t_2)$\}  \item[$\bullet$] $\tilde E_{n}(s_i)$=\{at time $s_i$ an edge stemming from either a vertex of $V(\mathrm t_1)$ or a vertex of $V(\mathrm t_2)$ is added in the process\}.  Note that   &&\mathbb P\left(\mathrm t_1,\mathrm t_2 \text{ connect during the process to give a tree of size }\ell_1+\ell_2 \; | \; \mathrm t_1,\mathrm t_2 \text{ are c.c. of } \mathcal {F}_{p,n}(T)\right) \\  &=& \mathbb P\left(\cup_{i=1}^{\infty} E_{n}(s_i) \cap_{j=1}^{i-1} \big(\tilde E_{n}(s_j)\big)^c \; | \; \mathrm t_1,\mathrm t_2 \text{ are c.c. of } \mathcal {F}_{p,n}(T)\right) \\  &=& \sum_{i=1}^{\infty}  \mathbb P\left(E_{n}(s_i) \cap_{j=1}^{i-1} \big(\tilde E_{n}(s_j)\big)^c \; | \; \mathrm t_1,\mathrm t_2 \text{ are c.c. of } \mathcal {F}_{p,n}(T)\right).  The dynamic of the process $\mathcal {F}_{p,n}$ implies that when  $\mathrm t_1,\mathrm t_2 \text{ are c.c. of } \mathcal {F}_{p,n}(s_{i-1})$, for all $i\geq 1$: $$  \mathbb P\left(E_{n}(s_i) \; | \; \mathrm t_1,\mathrm t_2 \text{ are c.c. of } \mathcal {F}_{p,n}(s_{i-1}) \right)= \frac{2\ell_1\ell_2}{n(n-1)} $$  and  && \mathbb P\left(\tilde E_{n}(s_i) \; | \; \mathrm t_1,\mathrm t_2 \text{ are c.c. of } \mathcal {F}_{p,n}(s_{i-1}), \mathcal G_{p,n}(s_{i-1}) \right) \\  &=& \frac{2}{n(n-1)} \cdot \big(\ell_1\left(n-\mathcal G_{p,n}(s_{i-1})-1\right)+\ell_2\left(n-\mathcal G_{p,n}(s_{i-1})-1-\ell_1\right)+(\ell_1+\ell_2)p \mathcal G_{p,n}(s_{i-1}) \big)  \\  &=& \frac{2}{n(n-1)} \cdot \big((\ell_1+\ell_2)(n-(1-p)\mathcal G_{p,n}(s_{i-1})-1 )-\ell_1\ell_2 \big) \\  &\geq& \frac{2}{n(n-1)} \cdot \big( (\ell_1+\ell_2)(pn+(1-p)(\ell_1+\ell_2)-1)-\ell_1\ell_2\big),  where we have used in the last line that $\mathcal G_{p,n}(s_{i-1})\leq n-(\ell_1+\ell_2)$ when $\mathrm t_1,\mathrm t_2 \text{ are c.c. of } \mathcal {F}_{p,n}(s_{i-1})$. This leads to $$  \mathbb P\left(\tilde E_{n}(s_i) \; | \;  \mathrm t_1,\mathrm t_2 \text{ are c.c. of } \mathcal {F}_{p,n}(s_{i-1})\right) \geq  \frac{2p}{n} $$ (to see this note that for $n\geq \ell_1+\ell_2+1$, the function $p \mapsto (\ell_1+\ell_2)(pn+(1-p)(\ell_1+\ell_2)-1)-\ell_1\ell_2 -(n-1)p$ is increasing in $p$ and positive for $p=0$ ; whereas for $n=\ell_1+\ell_2$ it is decreasing in $p$ and positive for $p=1$). We then use these bounds to get    &&\sum_{i=1}^{\infty}  \mathbb P\left(E_{n}(s_i) \cap_{j=1}^{i-1} \big(\tilde E_{n}(s_j)\big)^c \; | \; \mathrm t_1,\mathrm t_2 \text{ are c.c. of } \mathcal {F}_{p,n}(T)\right) \\  &\leq & \sum_{i=1}^{\infty}  \frac{2\ell_1\ell_2}{n(n-1)} \cdot \left(1- \frac{2p}{n}\right)^{i-1} \\  &=& \frac{\ell_1\ell_2}{p(n-1)}.",2502.01424
proof,"Since only two trees can connect at a time, this is easily proved by induction on $m$, using the previous lemma.",2502.01424
proof,"$\bullet$ We start by proving that for any $i \geq k$,   \mathbb P \left(\text{a tree of size $i$ is formed after }\mathsf t^{(k)}_{p,n} +c \right)  \; \underset{n \rightarrow \infty}{\longrightarrow} \; 0.  Indeed, for $i \geq k$,   && \mathbb P \left(\text{a tree of size $i$ is formed after }\mathsf t^{(k)}_{p,n} +c \right) \\ &\leq & \sum_{m=2}^i \; \sum_{\substack{\ell_1 \geq \ldots \geq \ell_m \\\sum_{j=1}^m \ell_j=i}} \mathbb P \left(\text{a tree of size $i$ is formed after time }\mathsf t^{(k)}_{p,n} +c \text{ from $m$ trees present at time } \right.\\ &&  \left.  \hspace{3cm}  \mathsf t^{(k)}_{p,n} +c \text{ with respective sizes }\ell_1,\ldots,\ell_m\right) \\ &=& \sum_{m=2}^i \; \sum_{\substack{\ell_1 \geq \ldots \geq \ell_m \\\sum_{j=1}^m \ell_j=i}} \mathbb P \left(\text{a tree of size $i$ is formed after time }\mathsf t^{(k)}_{p,n} +c \text{ from $m$ trees present at time } \right.\\ &&  \Big.   \mathsf t^{(k)}_{p,n} +c \text{ with respective sizes }\ell_1,\ldots,\ell_m; \mathcal N_{p,n}^{(\ell_j)}(\mathsf t^{(k)}_{p,n} +c) \leq (\ln(n))^{\frac{1}{2}}\left(\frac{n}{\ln(n)}\right)^{1-\frac{\ell_j}{k}}, \forall 1\leq j \leq m\Big) \\ &+& o(1)   where the $o(1)$ (relative to $n\rightarrow \infty$) is a consequence of Proposition \ref{cor:boundsexp}. We then conclude with Lemma \ref{lem:treei} and again Proposition \ref{cor:boundsexp} which imply that when $\sum_{j=1}^m \ell_j=i$,  && \mathbb P \left(\text{a tree of size $i$ is formed after time }\mathsf t^{(k)}_{p,n} +c \text{ from $m$ trees present at time } \mathsf t^{(k)}_{p,n} +c \right. \\  && \Big. \hspace{0.2cm}\text{ with respective sizes }\ell_1,\ldots,\ell_m;  \mathcal N_{p,n}^{(\ell_j)}(\mathsf t^{(k)}_{p,n} +c) \leq (\ln(n))^{\frac{1}{2}}\left(\frac{n}{\ln(n)}\right)^{1-\frac{\ell_j}{k}}, \forall 1\leq j \leq m\Big) \\ &\leq& O\left(\frac{1}{n^{m-1}} \right) \cdot \left(\prod_{j=1}^m  (\ln(n))^{\frac{1}{2}}\left(\frac{n}{\ln(n)}\right)^{1-\frac{\ell_j}{k}} \right) \\ &=& O \left((\ln(n))^{\frac{i}{k}-\frac{m}{2}} \cdot n^{1-\frac{i}{k}} \right)   which converges to 0 as soon as $i\geq k$.   $\bullet$ Next, to improve this in $ \mathbb P \big(\text{a tree of size $\geq k$ is formed after }\mathsf t^{(k)}_{p,n} +c \big)  \; {\rightarrow} \; 0 $ as $n \rightarrow \infty$, we bound from above this probability by $$  \mathbb P\left(\text{a tree of size $\geq 2k+1$ is formed after }\mathsf t^{(k)}_{p,n} +c \right)+\sum_{i=k}^{2k}\mathbb P\left(\text{a tree of size $i$ is formed after }\mathsf t^{(k)}_{p,n} +c \right) $$ and note that (since only two trees can connect at a time)  &&  \hspace{1cm}  \mathbb P\left(\text{a tree of size $\geq 2k+1$ is formed after }\mathsf t^{(k)}_{p,n} +c \right) ~\leq \\  && \hspace{-0.5cm} \mathbb P\left(\text{there is a tree of size}\geq k+1 \text{  at time } \mathsf t^{(k)}_{p,n} +c \right) + \sum_{i=k}^{2k} \mathbb P\left(\text{a tree of size $i$ is formed after }\mathsf t^{(k)}_{p,n} +c \right).  So, we have  &&  \hspace{1cm} \mathbb P \left(\text{a tree of size $\geq k$ is formed after }\mathsf t^{(k)}_{p,n} +c \right) ~\leq \\  && \hspace{-0.5cm} 2\sum_{i=k}^{2k} \mathbb P \left(\text{a tree of size $i$ is formed after } \mathsf t^{(k)}_{p,n} +c \right) + \mathbb P\left(\text{there is a tree of size}\geq k+1 \text{  at time } \mathsf t^{(k)}_{p,n} +c \right),  and this last sum converges to 0 according to (\ref{cv:uni}) and Corollary \ref{cor:treesafterk}.",2502.01424
proof,"Point 1) is obvious. For 2), note that there exists $N_0\geq 1$ such that $S_{N_0}(1)\geq A.$ Then use that $S_N$ is non-increasing on $\left[1-1/N,1\right]$.",2502.01424
proof,"By definition of the Borel distribution and its expectation, $$\sum_{k\geq 1}\frac{k^{k-1}}{k!}\cdot \theta^{k}\mathrm{e}^{-k\theta}=\theta,  \qquad \sum_{k\geq 1}\frac{k^{k}}{k!}\cdot \theta^{k}\mathrm{e}^{-k\theta}=\frac{\theta}{1-\theta}, \quad  \forall \theta \in [0,1].$$ Setting $x(\theta)=\theta\mathrm{e}^{-\theta}$, $~T(0)=0$ and differentiating the function $ \theta \in [0,1] \mapsto T(x(\theta)), $ we see that   \partial_{\theta} T(x(\theta))=\sum_{k\geq 1}\frac{k^{k-1}}{k!}\theta^{k-1}\mathrm{e}^{-k\theta}-\sum_{k\geq 1}\frac{k^{k-1}}{k!}\theta^{k}\mathrm{e}^{-k\theta} = 1-\theta.  Since $T(x(0))=0$, this indeed gives $T(x(\theta))=\theta-\theta^2/2$ for all $\theta \in (0,1]$ and then  $$ \sum_{k=1}^{\infty} k\mu_{x(\theta)}(k)=\frac{1}{T(x(\theta))} \cdot \sum_{k\geq 1}\frac{k^{k-1}}{k!}\theta^{k}\mathrm{e}^{-k\theta}=\frac{2}{2-\theta} $$ $$ \sum_{k=1}^{\infty} k^2\mu_{x(\theta)}(k)=\frac{1}{T(x(\theta))} \cdot \sum_{k\geq 1}\frac{k^{k}}{k!}\theta^{k}\mathrm{e}^{-k\theta}=\frac{2}{(1-\theta)(2-\theta)}, $$ leading to the result.",2502.01424
proposition,"[Free forest property, \cite{ContatCurien23},\cite{viau25}]  	For any $n\in \mathbb N,m\in \mathbb Z_+$, conditionally on $G_{p,n}(m)$ and $D_{p,n}(m)$, the forest part of $\mathrm{F}_{p,n}(m)$ is uniformly distributed over  	$\mathcal{W}\left(V_{p,n}(m),E_{p,n}(m) \right)$ when $V_{p,n}(m) \geq 1$.",2502.01424
proposition,"For all $t<1/2$, $G_{p,n}(\lfloor nt\rfloor)=O_{\mathbb P}(1)$.",2502.01424
proposition,"For all $k \in \mathbb N$ and all $c \in \mathbb R$ $$ N_{p,n}^{(k)}\left(\left \lfloor \frac{n}{2} \cdot \big(\mathsf t^{(k)}_{p,n}+c\big) \right \rfloor \right) \; \underset{n \rightarrow \infty}{\overset{(\mathrm d)}\longrightarrow} \; \mathcal P\left(\frac{k^{k-2}e^{-kpc} e^{-k\left(\psi(1/p)+\gamma_{\mathrm E}\right)}}{k!} \right), $$ where  the notation $\mathcal P(\lambda)$ refers to a Poisson distribution with expectation $\lambda>0$.  Additionally, each positive moment of $N_{p,n}^{(k)}\big(\big \lfloor n \cdot \big(\mathsf t^{(k)}_{p,n}+c\big) /2\big \rfloor \big)$ converges to the corresponding moment of the Poisson distribution.",2502.01424
proposition,"For every $n\in \mathbb N$, $m\in \mathbb Z_+$ and $k\in \llbracket 1; E_{p,n}(m)+1 \rrbracket$, 	\setlength{\jot}{10pt} 	       && \hspace{-1cm}\mathbb{P}\left( \Delta G_{p,n}(m)=k ~| ~ \mathbf{F}_{p,n}(m)\right) \\ 	  & =&\binom{V_{p,n}(m)}{k} \cdot k^{k-2} \cdot \frac{\#\mathcal{W}(V_{p,n}(m)-k,E_{p,n}(m)-k+1)}{\#\mathcal{W}(V_{p,n}(m),E_{p,n}(m))} \cdot \left(\frac{k(k-1)+2pkG_{p,n}(m)}{n(n-1)}\right), 	 	with the conventions $\#\mathcal{W}(0,0)=1$, $\#\mathcal{W}(N,N)=0$ for any $N \in \mathbb N$, $\#\mathcal{W}(-1,0)=0$, 	and  	$$\mathbb{P}\left(\Delta D_{p,n}(m)=1~| ~ \mathbf{F}_{p,n}(m)\right)=2(1-p) \cdot \frac{G_{p,n}(m)(n-G_{p,n}(m))}{n(n-1)}+\frac{G_{p,n}(m)(G_{p,n}(m)-1)}{n(n-1)}.$$",2502.01424
proposition,"[\cite{kolchin86},\cite{britikov88},\cite{ContatCurien23}]  Let $N \in \mathbb N$, $M \in \mathbb Z_+$ with $M\leq N-1$ and for $x\in (0,e^{-1}]$, \linebreak $\big(S_i^{(x)}:0\leq i\leq N-M\big)$ be a random walk with i.i.d. increments of law $\mu_x$, started from $S_0^{(x)}=0$. [topsep=0cm] \item[\emph{1)}] Whatever $x\in (0,e^{-1}]$, the cardinal of $\mathcal W(N,M)$ is given by 	$$\#\mathcal{W}(N,M)=\frac{N!}{(N-M)!} \cdot \frac{T(x)^{N-M}}{x^N} \cdot \mathbb{P}\big(S_{N-M}^{(x)}=N\big).$$ \item[\emph{2)}] If $W(N,M)$ is a uniform random forest of $\mathcal W(N,M)$ and $\mathcal{C}_1,\ldots,\mathcal{C}_{N-M}$ denote the sizes of its connected components indexed in a uniform random order, then, whatever $x\in (0,\mathrm{e}^{-1}]$, the vector $\left(\mathcal{C}_1,...,\mathcal{C}_{N-M}\right)$ has the same law as the increments of $\big(S_i^{(x)}:0\leq i\leq N-M\big)$ conditioned on $S_{N-M}^{(x)}=N$. Moreover, conditionally on their sizes, the connected components are independent uniform Cayley trees.",2502.01424
proposition,"[Britikov \cite{britikov88}]  Let $\omega=(2M-N)/N^{2/3}$, with $N \in \mathbb N$, $M \in \mathbb Z_+$, $M\leq N-1$. [topsep=0cm] \item[\emph{1)}] \emph{(Subcritical regime)} When $\omega \to -\infty$,   $$\#\mathcal{W}(N,M)=\left(1+o(1)\right)\cdot \frac{N^{2M}}{2^M M!} \cdot \left(1-\frac{2M}{N}\right)^{1/2}.$$ \item[\emph{2)}]  \emph{(Near-critical regime)} When $N \rightarrow \infty$ and $\omega$ is bounded, $$\#\mathcal{W}(N,M)=\left(1+o(1)\right)\cdot \frac{N^{N-1/6}}{2^{N-M}(N-M)!} \cdot \sqrt{2\pi} \cdot p_1\left(\omega\right).$$  \item[\emph{3)}]  \emph{(Supercritical regime)} When $\omega \to \infty$,  $$ \#\mathcal{W}(N,M)=\left(1+o(1)\right)\cdot  \frac{N^{N-2}}{2^{N-M-1}(N-M-1)!} \cdot \left(\frac{2M}{N}-1\right)^{-5/2}.$$",2502.01424
proposition,"[Luczak-Pittel \cite{LuczakPittel92}, Theorem 3.1 (ii)]  For $i\in \mathbb N$, let $L_i(N,M)$ denote the size of the $i$-th largest tree in a uniform random forest with $N$ vertices and $M$ edges. Then, when $\big(N,M/N\big) \rightarrow (\infty,c)$, with $c \in (0,1/2)$, $$ \frac{L_i(N,M)}{\ln(N)} \overset{\mathbb P}\longrightarrow \frac{1}{2c-1-\ln(2c)}. $$",2502.01424
proposition,"\item[\emph{1)}] For $t \in [0,1/2]$, $g_p(t)=d_p(t)=0$, $v_p(t)=1$, $e_p(t)=r_p(t)=t$. \item[\emph{2)}] The functions $g_p,d_p,v_p,e_p,r_p$ are infinitely differentiable on $(1/2,\infty)$, with \linebreak $g_p'(1/2^+)=2(1+p)=-v'_p(1/2^+)$,  $~  d_p'(1/2^+)=0$, $~  e_p'(1/2^+)=-1-2p$, $~  r_p'(1/2^+)=-p$.   \item[\emph{3)}] As $t \rightarrow \infty$,  $~ 1-g_p(t)=v_p(t) \sim e^{-2pt}$, $~ d_p(t)-t+1 \sim e^{-2pt}$, $~ e_p(t) \sim te^{-4pt}$, $~ r_p(t)  \sim te^{-2pt}$. \item[\emph{4)}] The ratio function rewrites $r_p(t)=t(1-g_p(t))$, and therefore $e_p(t)=t(1-g_p(t))^2$ and \newline $d_p(t)=t-g_p(t)-t(1-g_p(t))^2$, for $t\geq 0$. \item[\emph{5)}] While the functions $g_p,d_p,v_p$ are monotonic on $(0,\infty)$ ($g_p$ and $d_p$ are increasing, $v_p$ is decreasing), the functions $r_p$ and $e_p$ are increasing on $(0,1/2]$ and decreasing on $[1/2,\infty)$. In particular, $r_p(t)<1/2$ for $t\neq 1/2$. \item[\emph{6)}] The function $g_p$ is concave on $[0,\infty)$. The fonction $d_p$ is convex on $[0,\infty)$.",2502.01424
proposition,"The sequence of functions $(t_{p,k},k\geq 1)$ is the unique solution to the following system of differential equations:   	\left\{ 	{ll} 		t_k'(t)=\sum_{i+j=k}ijt_i(t)t_j(t)-2kt_k(t)\left(1-(1-p)g_p(t)\right),  \quad t\geq 0, \\ 		t_1(0)=1; \quad t_k(0)=0 \quad \text{for }k\geq 2. 	 	\right.",2502.01424
proposition,"For every $p\in (0,1]$, there are constants $c(p),C(p) \in (0,\infty)$ such that for $\varepsilon>0$ small enough 		$$\mathbb{P}\left(G_{p,n}\left(\left\lfloor\frac{n}{2}+\varepsilon n\right\rfloor\right) \in \big[(2+c(p))\varepsilon n~;~C(p)\varepsilon n \big]\right)~\underset{n\to \infty} \longrightarrow~1.  $$",2502.01424
proposition,"For $\varepsilon>0$ small enough, 	 $$\left(\left(\left\lvert \frac{G_{p,n}\left(\lfloor nt+\varepsilon n\rfloor\right)}{n}-g_{p,n}^{(\varepsilon)}(t) \right\vert, \left\lvert \frac{D_{p,n}\left(\lfloor nt+\varepsilon n\rfloor\right)}{n}-d_{p,n}^{(\varepsilon)}(t) \right\vert \right)\right)_{t\geq \frac{1}{2}}~\underset{n \rightarrow \infty }{\overset{\mathbb{P}}{\longrightarrow}}~0$$	 for the topology of uniform convergence on compacts.",2502.01424
proposition,"For all $k,k' \in \mathbb N$ and $c \in \mathbb R$, as $n\rightarrow \infty$ $$\mathbb E\left[\mathcal N_{p,n}^{(k')}\big(\mathsf t^{(k)}_{p,n}+c \big)\right] = O\left( \left(\frac{n}{\ln(n)} \right)^{1-k'/k} \right).$$",2502.01424
proposition,"For all $k \in \mathbb N$ and all $c \in \mathbb R$ $$ \mathcal N_{p,n}^{(k)}(\mathsf t^{(k)}_{p,n}+c) \; \underset{n \rightarrow \infty}{\overset{(\mathrm d)}\longrightarrow} \; \mathcal P\left(\frac{k^{k-2}e^{-kpc} e^{-k\left(\psi(1/p)+\gamma_{\mathrm E}\right)}}{k!} \right). $$ Additionally, we have the convergence of each positive moment of $~\mathcal N_{p,n}^{(k)}(\mathsf t^{(k)}_{p,n}+c)$ to the corresponding moment of the limit Poisson distribution.",2502.01424
lemma,"Fix $\varepsilon>0$ and consider  a function $B$ such that $B(N)\to \infty $ as $N\to \infty$. Then for $N$ large enough and all $M$ verifying $2M-N\leq -\varepsilon N$, $$\mathbb{P}\left(L_1(N,M)\geq B(N)\right)~\leq~\frac{C_{\varepsilon}\cdot N^{2}}{B(N)^2} \cdot \exp\left(-\frac{\varepsilon^2 B(N)}{2}\right)$$ where $C_{\varepsilon}\in (0,\infty)$ only depends on $\varepsilon$.",2502.01424
lemma,"[Britikov \cite{britikov88}, Lemma 5] 	Let $x=\theta\mathrm{e}^{-\theta}$ for some $\theta\in (0,1)$ which may depend on $N,M$. Assume that $N-M \rightarrow \infty$, 	$(N-M)\theta\to \infty$ and $(N-M)^{1/3}(1-\theta) \to \infty$. Then, if $z=\frac{N-m(\theta)(N-M)}{\sigma(\theta)(N-M)^{1/2}}$ lies in some finite interval, one has 	$$\sigma(\theta)(N-M)^{1/2}\mathbb{P}\left(S_{N-M}^{(x)}=N\right)=\left(1+o(1)\right)\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-z^2/2}.$$",2502.01424
lemma,"Consider two functions $\omega,g$ such that, as $N \rightarrow \infty$, $\omega(N)\to \infty $, $\omega(N)=o\big(N^{1/3}\big)$, $g(N)\to \infty$ and $g(N)=o\left(\omega(N)\right).$ Then, for $N$ large enough and every $M$ verifying $2M-N=\omega(N)N^{2/3}$, $$\mathbb{P}\big(L_1(N,M)<g(N)N^{2/3}\big)\leq C\cdot \omega(N)^{5/2}N^{2/3} \cdot \exp\left(-\frac{\omega(N)}{g(N)}\right),$$ for some $C\in (0,\infty)$ independent of $N$.",2502.01424
lemma,"Recalling that $\gamma_E$ denotes Euler's constant and $\psi$ the digamma function, defined by $\psi(x)=\frac{\Gamma'(x)}{\Gamma(x)}$ with $\Gamma$ the gamma function, we have $$ (1-p)\int_0^{\infty} (1-g_p(t)) \mathrm dt ~ = ~ \frac{\psi(1/p) +\gamma_E}{2}. $$ The function $\psi(1/p) +\gamma_E$ is decreasing in $p$, equal to 0 when $p=1$ and to $1$ when $p=1/2$, and $\psi(1/p) \sim -\ln p$ when $p \rightarrow 0$.",2502.01424
lemma,"[topsep=0cm] \item[\emph{1)}] For $\varepsilon \geq 0$ and $a\in \left(\frac{2\varepsilon}{1+2\varepsilon},1\right)$,  there exists a unique solution to $(E_{(\varepsilon)})$ starting from $a$. We denote it here by $g_p^{(\varepsilon,a)}$. \item[\emph{2)}] Let $\frac{2\varepsilon}{1+2\varepsilon}<a<b<1$, then $~g_p^{(\varepsilon,a)}(t)<g_p^{(\varepsilon,b)}(t)$ for all $t \geq \frac{1}{2}$ and  $$\sup_{t\geq {1}/{2}}\big\vert g_p^{(\varepsilon,a)}(t)-g_p^{(\varepsilon,b)}(t)\big\vert ~\leq ~\vert b-a\vert.$$  \vspace{-0.4cm}  \item[\emph{3)}] Take $0<\varepsilon_1<\varepsilon_2$ and $a>\frac{2\varepsilon_2}{1+2\varepsilon_2}$. Then $g^{(\varepsilon_1,a)}_{p}(t)< g^{(\varepsilon_2,a)}_{p}(t)$ for all $t\geq \frac{1}{2}$. \item[\emph{4)}] There exists a unique solution to $(E_{(0)})$ starting from $0$, which is our function $g_p$ defined as the inverse of the function $f_p$ (\ref{def:f_p}). In particular $g_{p}(\cdot+\varepsilon)$ is the solution to $(E_{(\varepsilon)})$ starting from $g_{p}({1}/{2}+\varepsilon)$.",2502.01424
lemma,"Consider $\varepsilon\geq0$ and $(a,b)\in [0,1)\times [0,\infty)$ such that $\delta_{(a,b)}(\varepsilon)\geq 0$. [topsep=0cm] \item[\emph{1)}] If $(g,d)$ is a solution to $(\tilde{E}_{(\varepsilon)})$ starting from $(a,b)$ then $g$ is a solution to $(E_{(\delta_{(a,b)}(\varepsilon))})$ starting from $a$. \item[\emph{2)}] If either $a>\frac{2\delta_{(a,b)}(\varepsilon)}{1+2\delta_{(a,b)}(\varepsilon)}$ or $a=0$ and $b=\varepsilon$, there exists a unique solution to $(\tilde{E}_{(\varepsilon)})$ starting from $\left(a,b\right)$. In particular, there exists a unique solution to $(\tilde{E}_{(0)})$ starting from $(0,0)$, denoted by $(g_p,d_p)$, with $g_p$ the inverse of $f_p$ (\ref{def:f_p}).",2502.01424
lemma,"Let $(u_n)_{n\in \mathbb N}$ be a deterministic sequence of positive real numbers. For each $n \in \mathbb N$, let $\left(Y_n(m)\right)_{m \in \mathbb Z_+}$ be a stochastic process starting from $Y_n(0)=0$ and such that $\left\vert \Delta Y_n(m)\right\vert \leq u_n~$ for every $m \in \mathbb Z_+$. Let then $(\mathbf{G}_n(m))_{m \in \mathbb Z_+}$ denote the filtration generated by the process $Y_n$, and consider $T_n$ a stopping time such that $T_n\leq An$ almost surely, for some deterministic $A>0$ independent of $n$. Then, for all $\varepsilon>0$, 	$$ \mathbb P\Bigg(\bigg|Y_n\left(\lfloor An\rfloor\right)-Y_n\left( T_n\right)-\sum_{m= T_n}^{\lfloor An\rfloor-1} \mathbb{E}\left[\Delta Y_n(m)|\mathbf{G}_n(m)\right]\bigg| \geq \varepsilon\Bigg) \leq 2 \exp\left(-\frac{\varepsilon^2}{8 An u_n^2} \right). 	$$ In particular, when $u_n=o(n^{1/2})$, 	 $$ \frac{Y_n\left(\lfloor An\rfloor\right)-Y_n\left( T_n\right)-\sum_{m= T_n}^{\lfloor An\rfloor-1} \mathbb{E}\left[\Delta Y_n(m)|\mathbf{G}_n(m) \right] }{n}~ \underset{n \rightarrow \infty}{\overset{\mathbb P}\longrightarrow}~ 0. $$",2502.01424
lemma,"For every $A\in \left(1/2,1\right)$, there exists $c_{A}>0$ such that for  $n$ large enough 		$$\mathbb{P}\left(\exists m\in \left[n/2,An\right]:\, 2E_{p,n}(m)-V_{p,n}(m)\geq \ln(n)^3 n^{2/3}\right) \leq \mathrm{e}^{-c_A\ln(n)^2}.$$",2502.01424
lemma,"There exists $c \in (0,\infty)$ such that for $\varepsilon>0$ small enough, and then $n$ large enough and every $m\in\left[\frac{n}{2}+\tilde{c}(p)\varepsilon n,\frac{n}{2}+\varepsilon n\right]$, 	$$	\mathbb{E}\left[\Delta G_{p,n}(m)\mathbbm{1}_{\{\Delta G_{p,n}(m)\leq n^{1/4}\}}\vert \mathbf{F}_{p,n}(m)   \right]\mathbbm{1}_{\tilde{A}_n(\varepsilon)}\geq  	\big(2(1+p)-{c}\varepsilon \big)\mathbbm{1}_{\tilde{A}_n(\varepsilon)}$$",2502.01424
lemma,"For $\varepsilon>0$ sufficiently small: [topsep=0cm] \item[\emph{1)}] For all $n\geq 1$, there exists on $I_n(\varepsilon)$ a unique solution to \eqref{eq:syst_EDO} starting at time $t=1/2$ from $\left(G_{p,n}\left(\left\lfloor\frac{n}{2}+\varepsilon n\right\rfloor\right)/n, D_{p,n}\left(\left\lfloor\frac{n}{2}+\varepsilon n\right\rfloor\right)/n\right)$, so the couples $\big(g_{p,n}^{(\varepsilon)},d_{p,n}^{(\varepsilon)}\big)$ of Definition \ref{def:f_nd_n_epsilon} and its shifted version $\big(\tilde{g}_{p,n}^{(\varepsilon)},\tilde{d}_{p,n}^{(\varepsilon)}\big)$ are indeed well-defined. \item[\emph{2)}] There exists a deterministic constant $\bar \kappa_{\varepsilon}>0$  and, for all $A>0$, a deterministic constant $\bar K_{\varepsilon,A}\in \left(C(p)\varepsilon,1\right)$ such that simultaneously for all $t\in \left[0,A+1\right]$ and all $n\geq 1$:    \emph{(a)} \hspace{0.1cm} $\tilde{g}_{p,n}^{(\varepsilon)}(t) < \bar K_{\varepsilon,A}$    \emph{(b)} \hspace{0.1cm} $\displaystyle \frac{1-\bar K_{\varepsilon,A}}{2}< \frac{t+1/2+\varepsilon-\tilde{g}_{p,n}^{(\varepsilon)}(t)-\tilde{d}_{p,n}^{(\varepsilon)}(t)}{1-\tilde{g}_{p,n}^{(\varepsilon)}(t)}< \frac{1}{2}-\bar \kappa_{\varepsilon}.$",2502.01424
lemma,"As $n\to \infty$, uniformly over $m\in \big[0,H_{D_{\varepsilon,A}}\big)$, one has 		$$\left\vert\mathbb{E}\left[\Delta \tilde{G}^{(\varepsilon)}_{p,n}(m) | {\mathbf{F}}^{(\varepsilon)}_{p,n}(m)  \right] - 		F_{\varepsilon}\left(\frac{m}{n},\frac{\tilde{G}^{(\varepsilon)}_{p,n}(m)}{n},\frac{\tilde{D}^{(\varepsilon)}_{p,n}(m)}{n}\right)\right\vert\leq \lambda(n)$$  		for a deterministic function $\lambda(n){=}o(1)$.",2502.01424
lemma,"Let $\sigma_n(1/2):=\inf\{t \geq 0: \mathcal G_{p,n}(t) \geq n/2\}$ and set for $t\geq 0$ $$k_n(t)=\mathbb E\left[1-\frac{\mathcal G_{p,n}(t+\sigma_n(1/2))}{n} \right].$$ Then, $k_n(t) \leq  e^{-pt/2}$ for all $t\geq 0$ and all $n\in \mathbb N$.",2502.01424
lemma,"For all $t\geq 0$,  P_n^{(k)}(\ell,t) &=& \left(1-e^{-t/n}\right)^{\ell (k-1)} \left(e^{-t/n} \right)^{\frac{\ell k(\ell k-1)}{2}-\ell(k-1)}e^{-\frac{\ell k(n-\ell k)}{n}pt} \\ && \times \; \mathbb E\left[e^{-\frac{\ell k(n-\ell k)}{n} (1-p)\int_0^t \left(1-\frac{\mathcal G_{p,n-\ell k}(u)}{n- \ell k} \right) \mathrm du} \right]  where $\mathcal G_{p,n-\ell k}$ is the gel mass process of a $\mathcal F_{p,n-\ell k}$ model.",2502.01424
lemma,"For all times $t\geq 0$ and all positive integers $j \leq n$   && \mathbb E\left[\prod_{i=0}^{j-1}(k\mathcal N_{p,n}^{(k)}(t)-i) \right] \\ &=&  \sum_{\substack{(n_1,\ldots,n_\ell) \in \mathcal P_j  \\ \text{ such that } n_i \leq k \: \forall i, \text{and }\ell k\leq n}} \frac{n!}{(n-k\ell)!} \binom{j}{n_1,\ldots,n_\ell} \cdot \prod_{i=1}^j \frac{1}{m_i!} \cdot \prod_{i=1}^l\frac{1}{(k-n_i)!} \cdot (k^{k-2})^\ell P^{(k)}_n(\ell,t),  whereas $\prod_{i=0}^{j-1}(k\mathcal N_{p,n}^{(k)}(t)-i)=0$ when $j>n$.",2502.01424
lemma,"Fix $\ell_1,\ell_2 \in \mathbb N$. For $n\geq \ell_1+\ell_2$,  consider $\mathrm t_1,\mathrm t_2$ two trees with vertices in $\{1,\ldots,n\}$ and no common vertices, with respective sizes $\ell_1,\ell_2$. Then for every stopping time $T>0$,  && \mathbb P\left(\mathrm t_1,\mathrm t_2 \text{ connect during the process to give a tree of size }\ell_1+\ell_2 \; | \; \mathrm t_1,\mathrm t_2 \text{ are c.c. of } \mathcal {F}_{p,n}(T)\right) \\ &\leq& \frac{\ell_1\ell_2}{p(n-1)}.",2502.01424
lemma,"Let $(\ell_1,\ldots,\ell_m)\in \mathbb N^m$, with $\sum_{j=1}^m \ell_j=i$. For $n\geq i$, consider $\mathrm t_1,\ldots,\mathrm t_m$ some trees with vertices in $\{1,\ldots,n\}$ and no common vertices, with respective sizes $\ell_1,\ldots,\ell_m \in \mathbb N$. Then for every time $t>0$,  && \mathbb P\left(\mathrm t_1,\ldots,\mathrm t_m \text{ connect during the process to give a tree of size }i \;  | \; \mathrm t_1,\ldots \mathrm t_m \text{ are c.c. of } \mathcal {F}_{p,n}(t)\right) \\ &=& O \left( \frac{1}{n^{m-1}}\right). \",2502.01424
lemma,"When $k\geq 2$, for any $c \in \mathbb R$, $$ \mathbb P \left(\text{a tree of size $\geq k$ is formed after time }\mathsf t^{(k)}_{p,n} +c \right)  \; \underset{n \rightarrow \infty}{\longrightarrow} \; 0. $$",2502.01424
lemma,"[topsep=0cm, itemsep=0cm] \item[\emph{1)}] The sum $S_N$ converges to $S$ uniformly on all compact subsets of $\left[0,1/2\right)$, and $S_N\left(1\right)\to \infty$ as $N \rightarrow \infty$. \item[\emph{2)}] For any $A>0$, there exists $N_0\geq 1$ and $\delta>0$ such that for every $N\geq N_0$ and $\theta \in \left[1-\delta,1\right]$, $S_N(\theta)\geq A.$",2502.01424
lemma,"If $x=\theta\mathrm{e}^{-\theta}$ with $\theta\in (0,1]$ then 	 $$T(x)=\theta\left(1-\theta/2\right) \quad, \quad \sum_{k=1}^{\infty} k\mu_x(k)=\frac{2}{2-\theta}, \quad \text{and} \quad \mathrm{Var}_{\mu_x}=\frac{2\theta}{(1-\theta)(2-\theta)^2}$$ 	\emph{(}the variance is infinite when $\theta=1$\emph{)}.",2502.01424
theorem,"[\textbf{Main Theorem}]     If Assumptions \ref{asp:g1} and \ref{asp:g2} are satisfied, equation \eqref{eq:g1}~(and equation \eqref{eqg:2}) has a unique classical solution in function class $\Gamma'$, and this solution is in function class $\Gamma''$. If Assumptions \ref{asp:g1}, \ref{asp:g2} and \ref{asp:g3} are satisfied, equation \eqref{eq:g1}~(and equation \eqref{eqg:2}) has a unique week solution, and this weak solution is in function class $\Gamma$.",2502.01434
theorem,"Let the objective $f$ satisfies condition \eqref{condition:f}, then the non-linear PDE \eqref{eq:gcbo} has a unique measure solution $\rho$, and this solution is in class $\Gamma$. If we further assume condition \eqref{condition:ff}, then $\rho(v,t)>0$, for any $t>0,v\in\mathbb{R}^d\setminus \{v_\alpha(\rho,t)\}$.",2502.01434
definition,"Function class $\Gamma$ is defined by      	 		\Gamma&:=\Big\{\phi:\forall T>0, \phi\in C^{2,1}(\mathbb{R}^d\times [0,T], \phi\in  W^{1,\infty}(0,T;H^m(\mathbb{R}^d)), \intd G^2\norm{\phi^{(m)}}^2dv<\infty,\\         &\forall t\in [0,T],m\geq 0\text{ and }\intt\intd G^3\norm{\phi^{(m)}}^2dvdt<\infty, \forall m\geq0\Big\}.",2502.01434
definition,"Function class $\Gamma'$ is defined by  	 		\Gamma'&:=\Big\{\phi:\forall T>0, \phi\in C^{2,1}(\mathbb{R}^d\times [0,T]): \phi\in  L^{\infty}(0,T;H^1(\mathbb{R}^d)),\text{ and }\\ 		&\quad \intt\intd G\norm{\nabla\phi}^2dvdt<\infty, \intt\intd G\sum_{i=1}^d\sum_{j=1}^d|\partial_i\partial_j\phi|^2dvdt<\infty\Big\}.",2502.01434
definition,"Function class $\Gamma''$ is defined by      	 		\Gamma''&:=\Big\{\phi: \forall T>0, \phi\in C^{2,1}(\mathbb{R}^d\times [0,T]): \phi\in  L^{\infty}(0,T;H^m(\mathbb{R}^d))\cap W^{1,\infty}(0,T;H^m_{loc}(\mathbb{R}^d)),\\         &\intt\intd G\norm{\nabla\phi^{(m)}}^2dv<\infty, \forall m\geq 0\Big\}.",2502.01434
definition,"We say $\rho$ is a weak solution to equation \eqref{eq:g1}, if $\rho(\cdot,t)$ is a Radon measure and for any test function $\psi\in \Gamma$, we have                   &\int_0^{s}\intd\Big(\partial_t\psi(v,t)+\div(G(v,t)\nabla\psi(v,t))-\div({\J(v,t)}{\psi(v,t)})+\psi(v,t)\Big)\rho(v,t)dvdt\\             &=\intd\rho(v,s)\psi(v,s)dv-\intd\varrho(v)\psi(v,0)dv-\intt\intd f(v,t)\psi(v,t)dvdt,                   for any $s\in [0,\infty)$. We say $\rho$ is a weak solution to equation \eqref{eqg:2}, if $\rho(\cdot,t)$ is a Radon measure and for any test function $\psi\in \Gamma$, we have               &\int_0^{s}\intd\Big(\partial_t\psi(v,t)+\div(G(v,t)\nabla\psi(v,t))+\inner{\J(v,t)}{\nabla\psi(v,t)})+\psi(v,t)\Big)\rho(v,t)dvdt\\             &=\intd\rho(v,s)\psi(v,s)dv-\intd\varrho(v)\psi(v,0)dv-\intt\intd f(v,t)\psi(v,t)dvdt,                   for any $s\in [0,\infty)$.",2502.01434
definition,"We say $\rho$ is a measure solution to the CBO dynamics, if $\rho\in\mathcal{C}(0,T;\mathcal{P}(\mathbb{R}^d)),\forall T>0$ and for any $\psi(v,t)\in \mathcal{C}^{2,1}(\mathbb{R}^d\times[0,\infty))$ with $\norm{\nabla\psi},\norm{\partial_i\partial_j\psi}$ bounded, we have                           &\int_{0}^{s}\intd\Big(\partial_t\psi(v,t)+\Delta \psi(v,t)\norm{v-v_\alpha(\rho,t)}^2d\rho(v,t)-\inner{\nabla \psi(v,t)}{v-v_\alpha(\rho,t)}\Big)d\rho(v,t)dt\\             &=\intd\psi(v,s)d\rho(v,s)-\intd\psi(v,0)d\varrho(v),                   for any $s\in [0,\infty)$.",2502.01434
proof,"When $|\boldsymbol{\nu}|=0$, the result is immediate; 	we will focus on the rest cases. Let us consider $v\in B^c_{R_i-1}(0)$. 			 			First, for each $\boldsymbol{\ell}_j\in\mathbb{N}_0^d$,  it is easy to verify that for each $k\in [d]$, we have  			 				\norm{\Big(\frac{R_i v_k}{\norm{v}}\Big)^{(\boldsymbol{\ell}_j)}}\leq C\frac{R_i}{\norm{v}^{|\boldsymbol{\ell}_j|}}, 			 			and thus let $\boldsymbol{g}(v):=\frac{R_i v}{\norm{v}}$ with $m=d$, we have  			 				\norm{ \prod_{j=1}^n \frac{\left[\mathbf{g}^{(\boldsymbol{\ell}_j)}\right]^{\mathbf{k}_j}}{\left(\mathbf{k}_{j}!\right)\left[\boldsymbol{\ell}_{j}!\right]^{\left|\mathbf{k}_j\right|}}}\leq  \prod_{j=1}^n\frac{CR^{|\boldsymbol{k}_j|}_i}{\norm{v}^{|\boldsymbol{\ell}_j||\boldsymbol{k}_j|}}\leq \frac{CR_i^{|\boldsymbol{\lambda}|}}{\norm{v}^{|\boldsymbol{\nu}|}}\leq C, 			 			since $|\boldsymbol{\lambda}| \leq n=|\boldsymbol{\nu}|$ and $v\in B_{R_i-1}^c(0)$. 			 			Second, by the Assumption \ref{asp:g1}, we have  			 				\norm{G^{(\boldsymbol{\lambda})}(\frac{R_i v}{\norm{v}})}\leq C\Big(1+G(\frac{R_i v}{\norm{v}})\Big). 			 			 			So using the Faa Di Bruno formula and the above two inequalities, we have 			 				\norm{\Big(G(\frac{R_i v}{\norm{v}})\Big)^{(\boldsymbol{\nu})}}\leq C\Big(1+G(\frac{R_i v}{\norm{v}})\Big). 			 			 			When $|\boldsymbol{\nu}|=1$, without loss of generality, we will assume $\Big(G(\frac{R_i v}{\norm{v}})\Big)^{(\boldsymbol{\nu})}=\frac{\partial}{\partial v_1}G(\frac{R_i v}{\norm{v}})$, then we have 			 				\frac{\partial}{\partial v_1}G(\frac{R_i v}{\norm{v}})=\sum_{k=1}^d\frac{\partial}{\partial v'_k}G(v')\mid_{v'=\frac{R_iv}{\norm{v}}}\frac{\partial}{\partial v_1}\frac{R_iv_k}{\norm{v}}, 			 			then using \eqref{eq:g74} and Assumption \ref{asp:g1}, we get $\norm{\Big(G(\frac{R_i v}{\norm{v}})\Big)^{(\boldsymbol{\nu})}}\leq CG^{1/2}(\frac{R_i v}{\norm{v}})\Big(1+G^{1/2}(\frac{R_i v}{\norm{v}})\Big)$.",2502.01434
proof,"When $\boldsymbol{\nu}=0$, the result is immediate; we will focus on the rest cases. Let us consider $v\in B^c_{R_i-1}(0)$. 			 			In this case, the Faa Di Bruno formula reads: 			 				\Big(\sqrt{G(\frac{R_i v}{\norm{v}})+1}\Big)^{(\boldsymbol{\nu})}=\sum_{1 \leq\lambda \leq n} f^{({\lambda})} \ \sum_{p(\boldsymbol{\nu}, {\lambda})}(\boldsymbol{\nu}!) \prod_{j=1}^n \frac{\left[{g}^{(\boldsymbol{\ell}_j)}\right]^{{k}_j}}{\left({k}_{j}!\right)\left[\boldsymbol{\ell}_{j}!\right]^{{k}_j}}, 			             here $f(\cdot)=\sqrt{\cdot}, g(v)=G(\frac{R_iv}{\norm{v}})+1$ and $m=1$.    %          , then 			% where $n=|\boldsymbol{\nu}|$ and 			%  			% 	 			% 		& p(\boldsymbol{\nu}, \boldsymbol{\lambda})=\Big\{\left({k}_1 \ldots, {k}_n ; \boldsymbol{\ell}_1, \ldots, \boldsymbol{\ell}_n\right): \text { for some } 1 \leq s \leq n, \\ 			% 		& \quad {k}_i=\mathbf{0} \text { and } \boldsymbol{\ell}_i=\mathbf{0} \text { for } 1 \leq i \leq n-s ;{k}_i>0 \text { for } n-s+1 \leq i \leq n ; \\ 			% 		& \quad \text { and } \mathbf{0} \prec \boldsymbol{\ell}_{n-s+1} \prec \cdots \prec \boldsymbol{\ell}_n \text { are such that } \\ 			% 		& \qquad \sum_{i=1}^n {k}_i=\lambda, \sum_{i=1}^n{k}_i \boldsymbol{\ell}_i=\boldsymbol{\nu}\Big\} . 			% 	 			%  			 			First, use Lemma \ref{lem:g1}, we have  			 				\norm{\prod_{j=1}^n \frac{\left[{g}^{(\boldsymbol{\ell}_j)}\right]^{{k}_j}}{\left({k}_{j}!\right)\left[\boldsymbol{\ell}_{j}!\right]^{{k}_j}}}\leq C\Big(1+G(\frac{R_i v}{\norm{v}})\Big)^{\sum_{j=1}^nk_j}=C\Big(1+G(\frac{R_i v}{\norm{v}})\Big)^{\lambda}. 			 			 			Second, we have 			 				\norm{f^{(\lambda)}(x)\mid_{x=G(\frac{R_i v}{\norm{v}})+1}}= C\Big(G(\frac{R_i v}{\norm{v}})+1\Big)^{\frac{1}{2}-\lambda}. 			 			 			 			So, finally, we have $\norm{\Big(\sqrt{G(\frac{R_i v}{\norm{v}})+1}\Big)^{(\boldsymbol{\nu})}}\leq C\sqrt{(1+G(\frac{R_i v}{\norm{v}}))}$.",2502.01434
proof,"When $v\in B_{R_i-1}(0)$ or $v\in B^c_{R_i}(0)$, the result is a direct consequence of Assumption \ref{asp:g1}, Lemma \ref{lem:g1}, and Lemma \ref{lem:g2}.  So in the next, we will only focus on the case when $v\in B_{R_i}(0)\setminus B_{R_i-1}(0)$. 			In the following , for simplicity, we will denote $G_i'(v):=1+G(\frac{R_iv}{\norm{v}})$. 			 			First, we have 			 				 					\norm{\overline{G}_i^{(1)}}&=\norm{G^{(1)}(1-S_i)-GS_i^{(1)}+G_i'^{(1)}S_i+G_i'S_i^{(1)}}\\ 					&\leq C\Big[\norm{G^{(1)}}+G+\norm{G_i'^{(1)}}+G_i'\Big]\\ 					&\leq C\Big[G^{\frac{1}{2}}(1+G^{\frac{1}{2}})+G_i'^{\frac{1}{2}}(1+G_i'^{\frac{1}{2}})\Big]\\ 					&\leq C\overline{G}^{\frac{1}{2}}_i\Big(1+\overline{G}^{\frac{1}{2}}_i\Big), 				 			 			the last inequality is due to Assumption \ref{asp:g2}: since by Assumption \ref{asp:g2}, we have  			 				G&\leq C\overline{G}_i,\\ 				G_i'&\leq C\overline{G}_i. 			 			 			Second, by the Leibniz rule, we have 			 				 					\norm{\overline{G}_i^{(k)}}&\leq C\Big[\sum_{s=0}^k\norm{{G}^{(s)}(1-S_i)^{(k-s)}}+\sum_{s=0}^k\norm{G_i'^{(s)}S_i^{(k-s)}}\Big]\\ 					&\leq C\Big[\sum_{s=0}^k\norm{{G}^{(s)}}+\sum_{s=0}^k\norm{G_i'^{(s)}}\Big]\\ 					&\leq C\Big[1+G+1+G_i'\Big]\\ 					&\leq C(1+\overline{G}_i). 				 			 			 			Third, by the convexity of $\norm{\cdot}^2$, we have 			 				 					\norm{\overline{\J}_i}^2&\leq \norm{\J}^2(1-S_i)+dG_i'S_i\\ 					&\leq CG(1-S_i)+dG_i'S_i\\ 					&\leq C\Big(G(1-S_i)+G_i'S_i\Big)\\ 					&\leq C\overline{G}_i, 				 			 			where we used Assumption \ref{asp:g1}. 			 			Lastly, we by the Leibniz rule, Assumption \ref{asp:g1} and Lemma \ref{lem:g2}, we have  			 				 					\norm{\overline{\J}_i^{(k)}}&\leq C\Big[\sum_{s=0}^k\norm{{\J}^{(s)}(1-S_i)^{(k-s)}}+\sum_{s=0}^k\norm{(\sqrt{G_i'})^{(s)}eS_i^{(k-s)}}\Big]\\ 					&\leq C\Big[\sum_{s=0}^k\norm{{\J}^{(s)}}+\sum_{s=0}^k\norm{(\sqrt{G_i'})^{(s)}}\Big]\\ 					&\leq C\Big[1+G^{\frac{1}{2}}+\sqrt{G_i'}\Big]\\ 					&\leq C\Big(1+\overline{G}_i^{\frac{1}{2}}\Big).",2502.01434
proof,"Remember $H_i\in [0,1]$  and $\norm{H_i^{(k)}}\leq \frac{C}{n_i^k}$. 			 			First, by Lemma \ref{lem:g25}, we have  			 				 					\norm{G_i^{(1)}}&\leq 2H_i\overline{G}_i \norm{H_i^{(1)}}+H_i^2\norm{\overline{G}^{(1)}_i}\\ 					&\leq CH_i\overline{G}_i^{\frac{1}{2}} \frac{\overline{G}_i^{\frac{1}{2}}}{n_i}+CH_i^2\overline{G}^{\frac{1}{2}}_i\Big(1+\overline{G}^{\frac{1}{2}}_i\Big)\\ 					&\leq CG_i^{\frac{1}{2}}\Big(1+G_i^{\frac{1}{2}}\Big), 				 			 			since $G\leq n_i,\forall v\in B_{R_i}(0)$, so $\overline{G}_i\leq n_i+1,\forall v\in\mathbb{R}^d$, and  			${\overline{G}_i^{{1}/{2}}}/{n_i}\leq C,\quad\forall v\in \mathbb{R}^d$. 			 			Second, by the Leibniz rule, we have by Lemma \ref{lem:g25} that 			 				 					\norm{G_i^{(k)}}&\leq C\Big[H_i^2\norm{\overline{G}_i^{(k)}}+\sum_{s=1}^k\norm{(H_i^2)^{(s)}\overline{G}_i^{(k-s)}}\Big]\\ 					&\leq C\Big[H_i^2(1+\overline{G}_i)+\sum_{s=1}^k\frac{1+\overline{G}_i}{n_i}\Big]\\ 					&\leq C(1+G_i). 				 			 			 			Third, we have 			 				\norm{\J_i}^2=H_i^2\norm{\overline{\J}_i}^2\leq CH_i^2\overline{G}_i=CG_i. 			 			 			Fourth, we have 			 				 					\norm{\J_i^{(k)}}&\leq C\Big[H_i\norm{\overline{\J}_i^{(k)}}+\sum_{s=1}^k\norm{H_i^{(s)}\overline{\J}_i^{(k-s)}}\Big]\\ 					&\leq C\Big[H_i(1+\overline{G}_i^{\frac{1}{2}})+\sum_{s=1}^k\frac{1+\overline{G}_i^{\frac{1}{2}}}{n_i}\Big]\\ 					&\leq C(1+G_i^{\frac{1}{2}}).",2502.01434
proof,"The first inequality is natural. We only focus on the rest equalities. For the second one, we use finite cube to approximate. For any $R>0$, let $Q_{R}(0):=[-R,R]^d$, then by the divergence theorem, we have      		\intt\int_{Q_R(0)} \div\left(\J\phi\right)\psi dvdt=\intt\int_{\partial Q_R(0)}\inner{\J}{n}\phi\psi dSdt-\intt\int_{Q_R(0)} \inner{\J}{\nabla\psi}\phi dvdt, 	 	here $n$ is the unit outer normal vector of $\partial Q_R(0)$. Next, we will show 	 		\lim_{R\to\infty}\Big|\intt\int_{\partial B_R(0)}\inner{\J}{n}\phi\psi dSdt\Big|=0, 	 	then the second one is proved by letting $R\to\infty$; we have 	 		 			&\Big|\intt\int_{\partial Q_R(0)}\inner{\J}{n}\phi\psi dSdt\Big|\\ 			&\leq \intt\int_{\partial Q_R(0)}\norm{\J}^2\phi^2dSdt+\intt\int_{\partial Q_R(0)}\psi^2dSdt\\ 			&\leq \intt\int_{\partial Q_R(0)\cup\partial Q_{R+1}(0)}\norm{\J}^2\phi^2dSdt+\intt\int_{\partial Q_R(0)\cup\partial Q_{R+1}(0)}\psi^2dSdt\\ 			&\leq C\Big(\intt\int_{Q_{R+1}(0)\setminus Q_R(0)}\norm{\J}^2\phi^2+\norm{\nabla(\J\phi)}^2dvdt+\intt\int_{Q_{R+1}(0)\setminus Q_R(0)}\psi^2+\norm{\nabla\psi}^2dvdt\Big)\\ 			&\leq C\Big(\intt\int_{Q_{R+1}(0)\setminus Q_R(0)}\phi^2+G\phi^2+G\norm{\nabla\phi}^2dvdt+\intt\int_{Q_{R+1}(0)\setminus Q_R(0)}\psi^2+\norm{\nabla\psi}^2dvdt\Big)\\ 			&\to 0,\quad \text{as } R\to\infty, 		 	 	since $\phi,\psi\in\Gamma$. In the above we used the trace theorem and the constant $C$ in the third inequality in the above is from the trace theorem, we want to comment that $C$ depends $Q_{1/2}(0)$ and does not depend on $R$ here, since we can decompose $Q_{R+1}(0)\setminus Q_R(0)$ into disjoint cubes with side length $1$, then on each this unit cube, we use the trace theorem then take summation to get the third inequality in the above; the fourth inequality in the above is by Assumption \ref{asp:g1}.  	 	The proof of the third one is similar, we have for any finite cube, that 	 		 			&\intt\int_{Q_R(0)} \Delta\left(G\phi\right)\psi dvdt=\intt\int_{\partial Q_R(0)}G\inner{\nabla\phi}{n}\psi dSdt\\ 			&\quad+\intt\int_{\partial Q_R(0)}\frac{\partial G}{\partial n}\phi\psi dSdt-\intt\int_{Q_R(0)} \inner{\nabla\left(G\phi\right)}{\nabla\psi}dvdt; 		 	 	the second term in the right hand side, that is $\intt\int_{\partial Q_R(0)}{\partial G}/{\partial n}\phi\psi dSdt$, we will show it converges to $0$ as $R\to\infty$; using $\norm{\frac{\partial G}{\partial n}}\leq CG^{1/2}(1+G^{1/2})$ and the Cauchy-Schwartz inequality, we have 	 		 			&\intt\int_{\partial Q_R(0)}\frac{\partial G}{\partial n}\phi\psi dSdt\\ 			&\leq C\Big(\intt \int_{\partial Q_R(0)}G\phi^2dvdt+\intt \int_{\partial Q_R(0)}\psi^2dvdt+\intt \int_{\partial Q_R(0)}G\psi^2dvdt\Big)\\ 			&\leq C\Big(\intt\int_{Q_{R+1}(0)\setminus Q_R(0)}G\phi^2+\norm{\nabla(G^{\frac{1}{2}}\phi)}^2dvdt+\intt\int_{Q_{R+1}(0)\setminus Q_R(0)}G\psi^2+\norm{\nabla(G^{\frac{1}{2}}\psi)}^2dvdt\Big)\\ 			&\quad+C\Big(\intt\int_{Q_{R+1}(0)\setminus Q_R(0)} \psi^2+\norm{\nabla\psi}^2dvdt\Big)\\ 			&\leq C\Big(\intt\int_{Q_{R+1}(0)\setminus Q_R(0)}\phi^2+\norm{\nabla\phi}^2+\psi^2+\norm{\nabla\psi}^2dvdt\Big)\\ 			&\quad+C\Big(\intt\int_{Q_{R+1}(0)\setminus Q_R(0)}G\phi^2+G\norm{\nabla\phi}^2+G\psi^2+G\norm{\nabla\psi}^2dvdt\Big)\\ 			&\to 0,\quad \text{as }R\to\infty, 		 	 	in the above we used the assumption $\norm{\nabla G}\leq CG^{1/2}(1+G^{1/2})$, which is equivalent to $\norm{\nabla G^{1/2}}\leq C(1+G^{1/2})$; for the first term, that is $\intt\int_{\partial Q_R(0)}G\inner{\nabla\phi}{n}\psi dSdt$, converges to $0$ as $R\to\infty$,  just denote $\phi':=\inner{\nabla\phi}{n}$, then $\intt\intd G\norm{\nabla\phi'}^2dvdt\leq C\sum_{i,j}\intt\intd G\norm{\partial_i\partial_j\phi}^2dvdt<\infty$ and the rest proof is similar as in the above; so we proved the third equality. 	 	For the last equality, it is enough to show  	 		\intt\int_{\partial Q_R(0)}G\phi\frac{\partial\psi}{\partial n}dvdt\to 0\quad \text{as } R\to\infty, 	 	which is true by following the proof of the third equality.",2502.01434
proof,"% 	The first one is easy to verify. We only verifty the second one for $v\in B_{R_i}(0)\setminus B_{R_i-1}(0)$. First on $ B_{R_i}(0)\setminus B_{R_i-1}(0)$, we have $C_1n_i\leq\Q_i(v)\leq C_2n_i$ and  	% 	 	% 		\nabla Q_i=\nabla H_i(v)\left[\norm{v}^2(1-S_i(v))+R_i^2S_i(v)\right]+H_i(v)\left[v(1-S_i(v))+\Big(R_i^2-\norm{v}^2\Big)\nabla S_i(v)\right], 	% 	 	% 	use $\norm{\nabla H_i(v)}\leq C/n_i$ and $R_i^2-\norm{v}^2\leq CR_i$ for $v\in B_{R_i}(0)\setminus B_{R_i-1}(0)$, we can derive the lemma. 	%",2502.01434
proof,"Use It\^o formula to function $e^{-\alpha f(v)},ve^{-\alpha f(v)}$, we have       \frac{d}{dt}\frac{\intd ve^{-\alpha f(v)}d\rho_t}{\intd e^{-\alpha f(v)}d\rho_t}=\frac{\frac{d}{dt}\intd ve^{-\alpha f(v)}d\rho_t}{\intd e^{-\alpha f(v)}d\rho_t}-v_{\alpha}(\rho_t)\frac{\frac{d}{dt}\intd e^{-\alpha f(v)}d\rho_t}{\intd e^{-\alpha f(v)}d\rho_t},  we have               \frac{d}{dt}\intd ve^{-\alpha f(v)}d\rho_t&=-\intd \inner{\nabla(ve^{-\alpha f(v)})}{v-v_{\alpha}(\rho_t)}d\rho_t+\intd\Delta(ve^{-\alpha f(v)})\norm{v-v_{\alpha}(\rho_t)}^2d\rho_t\\         &=-\intd (v-v_{\alpha}(\rho_t))e^{-\alpha f(v)}d\rho_t+\alpha\intd\inner{\nabla f(v)}{v-v_{\alpha}(\rho_t)}ve^{-\alpha f(v)}d\rho_t\\         &\quad+\alpha^2\intd v\norm{v-v_{\alpha}(\rho_t)}^2\norm{\nabla f(v)}^2e^{-\alpha f(v)}d\rho_t\\         &\quad-\alpha\intd v\norm{v-v_{\alpha}(\rho_t)}^2\Delta f(v)e^{-\alpha f(v)}d\rho_t-2\alpha\intd \norm{v-v_{\alpha}(\rho_t)}^2\nabla f(v)e^{-\alpha f(v)}d\rho_t,       and               \frac{d}{dt}\intd e^{-\alpha f(v)}d\rho_t&=-\intd \inner{\nabla(e^{-\alpha f(v)})}{v-v_{\alpha}(\rho_t)}d\rho_t+\intd\Delta(e^{-\alpha f(v)})\norm{v-v_{\alpha}(\rho_t)}^2d\rho_t\\         &=\alpha\intd\inner{\nabla f(v)}{v-v_{\alpha}(\rho_t)}e^{-\alpha f(v)}d\rho_t+\alpha^2\intd\norm{v-v_{\alpha}(\rho_t)}^2\norm{\nabla f(v)}^2e^{-\alpha f(v)}d\rho_t\\         &\quad -\alpha\intd\norm{v-v_{\alpha}(\rho_t)}^2\Delta f(v)e^{-\alpha f(v)}d\rho_t,       thus by a direct generalization of \cite[Lemma 3.3]{carrillo2018analytical}, see \cite[Theorem 2.3, Proposition A.3]{gerber2023propagation}, and the assumption on $\nabla f,\Delta f$, we have $\norm{\partial_tv_{\alpha}(t)}<C<\infty$.",2502.01434
lemma,"Under Assumptions \ref{asp:g1} and \ref{asp:g2}, we have $\norm{\Big(G(\frac{R_i v}{\norm{v}})\Big)^{(\boldsymbol{\nu})}}\leq C\Big(1+G(\frac{R_i v}{\norm{v}})\Big)$, for any $v\in B_{R_i-1}^c(0)$, for any vector $\boldsymbol{\nu}=\left(\nu_1, \ldots, \nu_d\right) \in \mathbb{N}_0^d$. When $|\boldsymbol{\nu}|=1$, we have $\norm{\Big(G(\frac{R_i v}{\norm{v}})\Big)^{(\boldsymbol{\nu})}}\leq CG^{1/2}(\frac{R_i v}{\norm{v}})\Big(1+G^{1/2}(\frac{R_i v}{\norm{v}})\Big)$.",2502.01434
lemma,"Under Assumptions \ref{asp:g1} and \ref{asp:g2}, we have $\norm{\Big(\sqrt{G(\frac{R_i v}{\norm{v}})+1}\Big)^{(\boldsymbol{\nu})}}\leq C\sqrt{(1+G(\frac{R_i v}{\norm{v}}))}$, for any $v\in B_{R_i-1}^c(0)$ and any vector $\boldsymbol{\nu}=\left(\nu_1, \ldots, \nu_d\right) \in \mathbb{N}_0^d$.",2502.01434
lemma,"Under Assumptions \ref{asp:g1} and \ref{asp:g2}, we have for any $v\in\mathbb{R}^d$ that 			 				&\norm{\overline{G}_i^{(1)}}\leq C\overline{G}^{\frac{1}{2}}_i\Big(1+\overline{G}^{\frac{1}{2}}_i\Big);\\ 				&\norm{\overline{G}_i^{(k)}}\leq C\Big(1+{\overline{G}_i}\Big),\quad \forall k\geq 2;\\ 				&\norm{\overline{\J}_i}^2\leq C\overline{G}_i;\\ 				&\norm{\overline{\J}_i^{(k)}}\leq C(1+\overline{G}^{\frac{1}{2}}_i)\quad \forall k\geq 1, 			             here constants are uniform for any $t\in [0,T]$ and may depend on $k$.",2502.01434
lemma,"Under Assumptions \ref{asp:g1} and \ref{asp:g2}, we have for any $v\in\mathbb{R}^d,t\in [0,T]$ that 			 				&\norm{{G}_i^{(1)}}\leq C{G}^{\frac{1}{2}}_i\Big(1+{G}^{\frac{1}{2}}_i\Big);\\ 				&\norm{{G}_i^{(k)}}\leq C\Big(1+{{G}_i}\Big),\quad \forall k\geq 2;\\ 				&\norm{{\J}_i}^2\leq C{G}_i;\\ 				&\norm{{\J}_i^{(k)}}\leq C(1+{G}^{\frac{1}{2}}_i)\quad \forall k\geq 1, 			             here constants are uniform for any $t\in [0,T]$ and may depend on $k$.",2502.01434
lemma,"Under Assumption \ref{asp:g1}, let $\phi,\psi\in\Gamma'''$, here   	 		\Gamma'''&:=\Big\{\phi\in C^{2,1}(\mathbb{R}^d\times [0,T]): \phi\in  L^{\infty}(0,T;H^1(\mathbb{R}^d)),\text{ and }\intt\intd G\norm{\phi}^2dvdt<\infty,\\ 		&\quad \intt\intd G\norm{\nabla\phi}^2dvdt<\infty, \intt\intd G\sum_{i=1}^d\sum_{j=1}^d|\partial_i\partial_j\phi|^2dvdt<\infty\Big\}. 	  Then we have 	 		&\intt\intd \partial_t\phi\psi dvdt=\intd \phi(v,T)\psi(v,T)dv-\intd \phi(v,0)\psi(v,0)dv-\intt\intd \partial_t\psi\phi dvdt;\\ 		&\intt\intd\div\left(\J\phi\right)\psi dvdt=-\intt\intd \inner{\J}{\nabla\psi}\phi dvdt;\\ 		&\intt\intd \Delta\left(G\phi\right)\psi dvdt=-\intt\intd \inner{\nabla\left(G\phi\right)}{\nabla\psi}dvdt;\\ 		&\intt\intd G\phi\Delta\psi dvdt=-\intt\intd \inner{\nabla\left(G\phi\right)}{\nabla\psi}dvdt.",2502.01434
lemma,%    we have  	% 	 	% 		&C_1(1+G_i)\leq \Q_i+1\leq C_2(1+G_i)\\ 	% 		&\norm{\nabla\Q_i}\leq C(1+\Q_i^{\frac{1}{2}}). 	% 	 	%,2502.01434
lemma,"Assume                &\norm{\Delta f}\leq C(1+\norm{v}^p),\\         &\norm{\nabla f}\leq C(1+\norm{v}^q),\text{ for some polynomial order of $p,q>0$},       we will have $\norm{\frac{d}{dt}v_{\alpha}(t)}<C<\infty$.",2502.01434
theorem,"\cite[Theorems 1-2-4]{li15} Let us suppose that Assumption \ref{assu} holds. Then, the sequence $(x_k,z_k,u_k)$ generated by ADMM converges to a point $(x^{\star},z^{\star},u^{\star})$, and $x^{\star}$ is a stationary point of $F(x)+G(x)$.",2502.01439
proposition,"Let us consider \eqref{relax_qop_admm_form}. The sequence $(x_k,z_k,u_k)$ generated by relaxed  ADMM4POP converges to a point $(x^{\star},z^{\star},u^{\star})$, and $x^{\star}$ is a stationary point of \eqref{relax_qop_admm_form}.",2502.01439
lemma,"%    If $\P_t(z)$ is closed for each $t \in \mathcal{B}$, then $\P$ is closed. In fact, it is direct consequence of the definition of topology and open set, that any finite union of closed sets is closed. %",2502.01439
example,"Let us consider the POP $$\min_{x\in\R^2}x_1^2 x_2.$$ By defining $x_3=x_1^2$, we obtain $\min_{x\in\R^2}x_3 x_2$ s.t. $x_1^2=x_3$. Following Remark \ref{rem:A}, we notice that $A=\frac{1}{2}\left({ccc}                                                  0&0&0\\                                                  0&0&1\\                                                  0&1&0\\                                                 \right)$ is not positive semi-definite. Therefore, we define $x_4=x_3x_2$.  Moreover, according to Remark \ref{rem:B},  we define $x_5=x_1$ to transform the constraint $x_1^2=x_3$ into $x_1x_5=x_3$. In this way, $\B=\{(3,2,4),(1,5,3)\}$. To fulfill the non-overlap assumption described in Remark \ref{rem:C}, we add $x_6=x_3$. % In conclusion, we obtain the QOP      \min_{x\in\R^5}&\quad x_4\\   &\quad\text{s.t. }\\   &\quad x_5=x_1, \qquad x_6=x_3\\   &\quad x_ix_j=x_k,~(i,j,k)\in\B=\{(3,2,4),(1,5,6)\}.",2502.01439
theorem,"[Kochol~\cite{KOCHOL}]  If every $5$-edge-connected graph admits a nowhere-zero $3$-flow, then the $3$-flow conjecture is true.",2502.01451
theorem,[L. M. Lovsz et al.~\cite{ltwz}]  Every $6$-edge-connected graph admits a nowhere-zero $3$-flow.,2502.01451
theorem,"[L. M. Lovsz et al.~\cite{ltwz}]  Let $(\g,z)$ be a canvas such that $\deg(z) \leq 4 + |\tau(z)|$. If for every non-empty $A \subsetneq V(G) \setminus \{z\}$ we have $\deg(A) \geq 4 + |\tau(A)|$, then every tip preflow extends to a nowhere-zero flow in $\g$.",2502.01451
theorem,"If $(\g,z)$ is a non-trivial flow-critical tame canvas, then every vertex other than $z$ has degree at most $\deg(z) -2$.",2502.01451
theorem,"Let $(\g,z)$ be a canvas such that $\deg(A)\ge 4+|\tau(A)|$ for every non-empty $A\subsetneq V(\g)\setminus\{z\}$. If there exists a vertex $x\in V(\g)\setminus \{z\}$ such that for every $X\subseteq V(\g)\setminus\{z\}$ containing $x$, we have $\deg(X)>\deg(z)-2$,  then every tip preflow extends to a nowhere-zero flow in $\g$.",2502.01451
theorem,Tall tame easels are not critical.,2502.01451
theorem,"For any positive integer $k$, there exists an algorithm that, given a positive integer $n$,  generates all non-trivial flow-critical tame canvases $(\g,z)$ with $\deg(z) \leq k$ and $|V(\g)|\le n$, using only a polynomial number (in $n$ and the number of such canvases) nowhere-zero flow existence tests and with polynomial time complexity if the time complexity of these tests is excluded.",2502.01451
theorem,"For any positive integer $k$ and non-negative integer $r$, there exists an algorithm that, given a positive integer $n$, generates all critical tame easels $(\g,z,x,\psi)$ such that $\deg(z) \leq k$, $x \neq z$ is a vertex of degree at least $k -2 -r$, and $|V(\g)|\le n$, using only a polynomial number (in $n$ and the number of such easels) nowhere-zero flow existence tests and with polynomial time complexity if the time complexity of these tests is excluded.",2502.01451
theorem,"Let $(\g,z)$ be a canvas with $\deg(z)\le 4+|\tau(z)|$.  If $\deg(A)\ge 4+|\tau(A)|$ for every non-empty $A\subsetneq V(\g)\setminus\{z\}$, then every tip preflow extends to a nowhere-zero flow in $\g$.",2502.01451
theorem,"Let $k$ be a positive integer.  For every canvas $(\g,z)\in\GG_k$, at least one of the following claims holds: [align=left] \item[(SMALL)] $|V(\g)|=3$; or, \item[(EXPA)] $\GG_k$ contains a canvas $(\g',z)\prec (\g,z)$ such that $(\g,z)$ is a $\GG_k$-expansion of $(\g',z)$ or a $\GG_k$-expansion of a 2-alteration of $(\g',z)$; or, \item[(EXPB)] $\GG_k$ contains a canvas $(\g',z)\prec (\g,z)$ such that $(\g,z)$ is a $\GG_k$-expansion of a 1-alteration of $(\g',z)$; or, \item[(ADD)] $(\g,z)$ is a tip-alteration of a canvas $(\g',z)\prec (\g,z)$ belonging to $\GG_k$; or, \item[(REM)] $(\g,z)$ is a tip-reduction of a canvas $(\g',z)\prec (\g,z)$ belonging to $\GG_k$.  Moreover, if $\g$ has minimum degree at most four, then (SMALL) or (EXPA) holds.",2502.01451
theorem,"Let $k$ and $r$ be integers.  For every easel $(\g,z,x,\psi)\in\GG_{k,r}$, at least one of the following claims holds:  %[leftmargin=1.5cm] \item (SMALL) $|V(\g)|=3$; or,  \item $\GG_{k,r}$ contains an easel $(\g',z,x',\psi')$ such that $(\g',z,x')\prec (\g,z,x)$ and  [align=left, leftmargin=3mm, labelwidth=1.5cm,itemindent=1.5cm,] \item[(EXP)] $(\g,z)$ is a $(\GG_k,x\to x',\GG_{k,r},\emptyset)$-expansion of $(\g',z)$; or, \item[(EXPA)] $(\g,z)$ is a $(\GG_k,x\to x',\GG_{k,r},\{y_1,y_2\})$-expansion of a 2-alteration of $(\g',z)$ on some vertices or edges $y_1$ and $y_2$; or, \item[(EXPX)] $\deg(z)=k+1$, $\deg(x)=k-2-r$, $\deg(x') \ge\deg(x)$, and $(\g,z)$ is a $(\GG_k,x\to x',\GG_{k,r},\{y,x'\})$-expansion of an $x'$-alteration of $(\g',z)$ on some vertex or edge $y$; or, \item[(EXPB)] $(\g,z)$ is a $(\GG_k,x\to x',\GG_{k,r},\emptyset)$-expansion of a 1-alteration of $(\g',z)$; or, \item[(ADD)] $(\g,z)$ is a tip-alteration of $(\g',z)$ at a vertex different from $x=x'$; or,  \item (REM) $\GG_{k,r}\cup \GG_{k+1,r}$ contains an easel $(\g',z,x,\psi')$ such that $(\g',z,x')\prec (\g,z,x)$ and $(\g,z)$ is a tip-reduction of $(\g',z)$ at a vertex different from $x=x'$.  Moreover:  \item If $\g$ contains a vertex other than $x$ of degree four, then (SMALL), (EXP), (EXPA), or (EXPX) holds. \item If $(\g,z)$ is not $\psi$-critical, then (EXP) holds.",2502.01451
definition,"Let $G$ be a graph and $\beta:V(G) \rightarrow \Z$ a function.  For $A\subseteq V(G)$, we define $\beta(A):=\sum_{v\in A} \beta(v)$. We say that $\beta$ is a \emph{$\Z$-boundary} for $G$ if for every component $C$ of $G$, we have that $\beta(V(C)) \equiv 0 \pmod 3$. If $\beta$ is a $\Z$-boundary for $G$, we say the pair $\g = (G,\beta)$ is a \emph{$\Z$-bordered graph}.",2502.01451
definition,"Let $\g = (G,\beta)$ be a $\Z$-bordered graph. A \emph{nowhere-zero flow} in $\g$ is an orientation such that for all $v \in V(G)$, we have $\deg^{+}(v) -\deg^{-}(v) \equiv \beta(v) \pmod 3$. We say that a graph $G$ is $\Z$-connected if $(G,\beta)$ admits a nowhere-zero flow for every $\Z$-boundary $\beta$.",2502.01451
definition,"A \emph{preflow} $\psi$ in $\g =(G,\beta)$ is a partial orientation of $G$, i.e., a directed graph with the same vertex set as $G$, and such that $uv\in E(G)$ for every $(u,v)\in E(\psi)$.  For a vertex $z$ of $G$, we say that $\psi$ is a \emph{preflow around $z$} if all arcs in $\psi$ are incident to $z$, and further $\deg^{+}(z) - \deg^{-}(z) \equiv \beta(z) \pmod 3$. We say that a preflow around $z$ \emph{extends to a nowhere-zero flow} of $\g$ if there exists a nowhere-zero flow of $\g$ for which the orientation of edges incident to $z$ agrees with the preflow around $z$.",2502.01451
definition,"Given a $\Z$-bordered graph $\g$, and a vertex $z \in V(G)$, a \emph{canvas} is a pair $(\g,z)$ and we will refer to $z$ as the \emph{tip} of the canvas. A \emph{tip preflow} of $(\g,z)$ is a preflow around~$z$.",2502.01451
definition,"Let $\g$ be a $\Z$-bordered graph. For a set $A \subseteq V(G)$, let the degree of $A$, denoted $\deg(A)$, be the number of edges with exactly one endpoint in $A$, and let $\beta(A) = \sum_{v \in A} \beta(v) \pmod 3$. Let $\tau(A)$ be defined by the following chart:   {c|ccc} \backslashbox{degree}{$\beta$} & $0$ & $1$ & $-1$\\ \hline even& $\{0\}$ & $\{-2\}$ & $\{2\}$\\ odd& $\{-3,3\}$ & $\{1\}$ & $\{-1\}$  \\  We write  $\tau(A)>0$ or $\tau(A)<0$ to mean that $\tau(A)$ contains only a single positive or negative element. Slightly abusing notation, we let $|\tau(A)|$ be defined by the following chart:  {c|cc} \backslashbox{degree}{$\beta$} & $0$ & $\pm 1$\\ \hline even& $0$ & $2$\\ odd& $3$ & $1$",2502.01451
definition,"Let $\g=(G,\beta)$ be a $\Z$-bordered graph. For a partition $\PP$ of $V(G)$, we define the $\Z$-boundary $\beta / \PP:V(G/\PP)\to\Z$ for the graph $G/\PP$ by letting  $$(\beta / \PP)(p) = \sum_{ v \in P} \beta(v) \pmod 3$$ for every part $P\in\PP$ and the corresponding vertex $p$ obtained by contracting $\PP$. We define $\g / \PP$ to be the $\Z$-bordered graph $(G/ \PP, \beta / \PP)$. As before, we call $\g / \PP$ a \emph{contraction} of $\g$.  Suppose now that $(\g,z)$ is a canvas. We say that $\PP$ is \emph{tip-respecting} if $\{z\}$ is a part of $\PP$. In this case, we abuse notation and use $z$ to refer to the vertex of $\g/\PP$ obtained by contracting the part $\{z\}$ of $\PP$; thus, $(\g/\PP, z)$ is a canvas. Moreover, we can view any tip preflow in $(\g,z)$ as a tip preflow in $(\g / \PP,z)$.  For a tip preflow $\psi$, we say that the canvas $(\g,z)$ is \emph{$\psi$-critical} if $\psi$ does not extend to a nowhere-zero flow in $(\g,z)$, but for every non-trivial tip-respecting partition $\PP$, $\psi$ extends to a nowhere-zero flow in $(\g / \PP,z)$. More generally, we say a canvas $(\g,z)$ is \emph{flow-critical} if for every non-trivial tip-respecting partition $\PP$, there exists a tip preflow that extends to a nowhere-zero flow in $(\g / \PP,z)$ but does not extend in $(\g,z)$.",2502.01451
definition,"Let $(\g,z)$ be a canvas. We say $(\g,z)$  is \emph{tame} if for all vertices $v \in V(G) \setminus \{z\}$, we have $\deg(v) \geq 4 + |\tau(v)|$.",2502.01451
definition,"An \emph{easel} is a tuple $(\g,z,x,\psi)$, where $(\g,z)$ is a canvas, $x$ is a vertex of $\g$ distinct from $z$, and $\psi$ is a tip preflow. The easel is \emph{tame} if $\deg(v)\ge 4+|\tau(v)|$ for every $v\in V(\g)\setminus\{x,z\}$. The easel is \emph{tall} if $\deg(z)\le \deg(x)+2$, and if $\deg(z)=\deg(x)+2$, then there additionally exists an edge in $\psi$ not incident with $x$ directed towards $z$ and another such edge directed away from $z$. It is \emph{critical} if the canvas $(g,z)$ is $\psi$-critical.",2502.01451
definition,"Let $(\g,z)$ be a canvas. The \emph{census} $C(\g,z)$ of $(\g,z)$ is the multiset $\{\deg(v) : v \in V(G) \setminus \{z\}, \deg(v) \neq 4\}$.",2502.01451
definition,"Given a canvas $(\g,z)$ and a set $A\subseteq V(\g)\setminus \{z\}$, the \emph{restriction} $(\g,z)\restriction A$ of $(\g,z)$ to $A$ is the canvas $(\g/B,b)$, where $B=V(\g)\setminus A$ and $b$ is the vertex resulting from the contraction of $B$.",2502.01451
definition,"We say that a vertex $v$ is \emph{in-friendly} if $\tau(v)$ contains a non-positive value, and \emph{out-friendly} if $\tau(v)$ contains a non-negative value.  Note that if $\beta(v)=0$, then $v$ is both in-friendly and out-friendly. An edge $uv$ of a canvas $(\g, z)$ is \emph{mixed} if $u\neq z\neq v$, one of $u$ and $v$ is in-friendly, and the other one is out-friendly. Let $x$ be a vertex of $\g$; we say that the canvas $(\g,z)$ is \emph{$x$-homogeneous} if all its mixed edges are incident with $x$. Note that $x=z$ is possible, and in that case equivalently $(\g,z)$ has no mixed edges.",2502.01451
definition,"For a canvas $(\g, z)$, we define $o(\g,z)=|V(\g)|+|E(\g-z)|$. For triples $(\g_1,z_1,x_1)$ and $(\g_2,z_2,x_2)$ where $(\g_i,z_i)$ is a canvas and $x_i$ is a vertex of $\g_i$ for $i\in\{1,2\}$, we write $(\g_1,z_1,x_1)\prec (\g_2,z_2,x_2)$ if  \item $o(\g_1,z_1)<o(\g_2,z_2)$; or, \item $o(\g_1,z_1)=o(\g_2,z_2)$, $(\g_1,z_1)$ is not $x_1$-homogeneous, and $(\g_2,z_2)$ is $x_2$-homogeneous; or, \item $o(\g_1,z_1)=o(\g_2,z_2)$, $(\g_i,z_i)$ is $x_i$-homogeneous for $i\in\{1,2\}$, and $\deg(z_1)<\deg(z_2)$.",2502.01451
definition,"Given a canvas $(\g,z)$ with $\deg(z)\le k+1$, we say that a tip preflow $\psi$ is a \emph{$k$-tallness-witnessing preflow} if $\psi$ does not extend to a nowhere-zero flow in $\g$ and if $\deg(z)=k+1$, then additionally $\psi$ does not direct all edges incident with $z$ in the same direction. If there exists a $k$-tallness-witnessing preflow in $(\g,z)$, then we say that $(\g,z)$ is \emph{$k$-tall}. For an integer $k$, let $\GG_k$ denote the class of all $k$-tall flow-critical tame canvases.",2502.01451
definition,"A \emph{minimal $k$-counterexample} is a triple $(\g,z,\psi)$, where $(\g,z)\in\GG_k$ is a minimal canvas in the $\prec$ ordering that does not satisfy the conclusion of Theorem~\ref{thm-gen} and $\psi$ is a $k$-tallness-witnessing preflow.",2502.01451
definition,"Let $(\g,z)$ be a canvas, let $\psi$ be a tip preflow, let $A$ be a subset of $V(\g)\setminus \{z\}$, and let $a$ be the vertex of $\g/A$ to which $A$ is contracted.  Let $x$ be a vertex of $A$.  We say that a nowhere-zero flow $\vec{G}$ in $\g/A$ is \emph{$(k,x,\psi,A)$-valid} if  \item $\vec{G}$ extends $\psi$, \item there exist edges $e_1$ and $e_2$ with exactly one end in $A$ (i.e., incident in $\g/A$ with $a$) which $\vec{G}$ orients in opposite directions (one of them to $a$ and the other one away from $a$), and moreover, \item $e_1$ and $e_2$ are not incident with $x$, unless $\deg(z)=k+1$ and $\psi$ orients all edges between $z$ and $V(\g)\setminus\{z,x\}$ in the same direction.",2502.01451
definition,"Let $k$ be a positive integer, $r$ an integer, and $(\g,z)$ a canvas with $\deg(z) \le k+1$.  We say that a pair $(x,\psi)$ is a \emph{witness of $(k,r)$-tallness} of $(\g,z)$ if  \item $\psi$ is a $k$-tallness-witnessing preflow, \item $x\neq z$ is a vertex of $\g$ of degree at least $k-2-r$, and \item if $\deg(x)=k-2-r$ and $\deg(z)=k+1$, then $\psi$ does not orient all edges between $z$ and $V(\g)\setminus\{z,x\}$ in the same direction (all towards $z$ or all away from $z$).",2502.01451
definition,"Suppose $(\g',z)$ is a canvas, $x\neq z$ is a vertex of $\g'$, and $y$ is either a vertex $v\in V(\g-\{x,z\})$, or an edge $uv\in E(\g-\{x,z\})$; in the former case, let $u=v$. A canvas $(\g_0,z)$ is the \emph{$x$-alteration} of $\g'$ on $y$ if $\g_0$ is obtained from $\g'$ by adding (possibly parallel) edges $ux$ and $vx$  and if $y$ is an edge, deleting it.",2502.01451
definition,"Let $\GG$ be a class of canvases and $\GG'$ be a class of easels.  If $(\g,z)$ is a canvas containing a vertex $x\neq z$, $(\g',z)$ is a canvas with a vertex $x'\neq z$, and $Y$ is a set of vertices and edges of $\g'$, we say that $(\g,z)$ is a \emph{$(\GG,x\to x',\GG',Y)$-expansion} of $(\g',z)$ if  \item $(\g,z)$ is a $\GG$-expansion of $(\g',z)$ and letting $\PP$ be the tip-respecting partition such that $\g'=\g/\PP$, \item the part $P\in \PP$ containing $x$ is contracted into the vertex $x'$; moreover, \item letting $(\g_1,b)=(\g,z)\restriction P$, if $|P|>1$ then there exists a tip preflow $\psi$ such that $(\g_1,b,x,\psi)\in \GG'$, and \item for every \emph{vertex} $y\in Y$ different from $z$, the part of $\PP$ contracted into $y$ has size at least two.",2502.01451
definition,"A \emph{minimal $(k,r)$-counterexample} is an easel $(\g,z,x,\psi)\in\GG_{k,r}$ not satisfying the conclusion of Theorem~\ref{thm-genladeg} with $(\g,z,x)$ minimal in the $\prec$ ordering.",2502.01451
proof,[Proof of claim]% }{%,2502.01451
proof,[Proof of subclaim]% }{%,2502.01451
proof,"Since the canvas $(\g,z)$ has at least three vertices, it has a proper tip-respecting contraction, and thus the definition of flow-criticality implies that there exists a tip preflow $\psi$ that does not extend to a nowhere-zero flow in $\g$.  Let $(\g',z)$ be a minimal tip-respecting contraction of $(\g,z)$ such that $\psi$ does not extend to a nowhere-zero flow in $\g'$, and observe that $(\g',z)$ is $\psi$-critical.",2502.01451
proof,"Let $B=V(\g)\setminus A$ and let $(\g',b)=(\g,z)\restriction A$. Consider any non-trivial tip-respecting partition $\PP'$ of $V(\g')$. To show that $(\g',b)$ is flow-critical, we need to find a tip preflow $\psi'$ extending to a nowhere-zero flow in $(\g'/\PP',b)$, but not in $(\g,b)$.  Let $\PP$ be the partition of $V(\g)$ obtained from $\g$ by replacing $b$ by singleton parts consisting of the vertices of $B$; since $\PP'$ is non-trivial, so is $\PP$.  Since $z\in B$, the partition $\PP$ is tip-respecting in $(\g,z)$.   Since $(\g,z)$ is flow-critical, there exists a tip preflow $\psi$ such that $\psi$ extends to a nowhere-zero flow $\varphi$ in $\g/\PP$ but not in $\g$. Let $\psi'$ be the restriction of $\varphi$ to the edges with exactly one end in $B$, which can be viewed as tip preflow in $(\g',b)$. The restriction of $\varphi$ to the edges incident with $B$ shows that $\psi'$ extends to a nowhere-zero flow in $\g'/\PP'$. On the other hand, $\psi'$ does not extend to a nowhere-zero flow $\varphi'$ in $\g'$, as otherwise we could combine $\varphi'$ with the restriction of $\varphi$ to the edges not incident with $B$ to obtain a nowhere-zero flow in $\g$ extending $\psi$ and get a contradiction.",2502.01451
proof,"Note that $\sum_{v\in V(\g)} (\deg^+(v) -\deg^-(v))=0$, since each edge is counted positively at its head and negatively at its tail in this sum. Moreover, since $\beta$ is a $\Z$-boundary, $\sum_{v\in V(\g)} \beta(v)\equiv 0\pmod 3$. Hence, we have       \deg^+(y)-\deg^-(y)&=-\sum_{v\in V(\g)\setminus\{y\}} (\deg^+(v) -\deg^-(v)) \\&\equiv -\sum_{v\in V(\g)\setminus\{y\}}\beta(v)\equiv \beta(y)\pmod 3,   and thus the flow conservation condition $\deg^+(v) -\deg^-(v) \equiv \beta(v)\pmod 3$ holds for $v=y$ as well.",2502.01451
proof,"Let $\g=(G,\beta)$. Suppose for a contradiction that distinct vertices $u,v\in V(\g)\setminus\{z\}$ are joined by an edge of multiplicity greater than one. Since the canvas $(\g,z)$ is flow-critical, there exists a tip preflow $\psi$ that extends to a nowhere-zero flow in $\g/\{u,v\}$ but not in $\g$. The nowhere-zero flow in $\g/\{u,v\}$ can be viewed as a partial orientation of $\g$ extending $\psi$ and such that only the edges between $u$ and $v$ are not oriented and $\deg^+(y)-\deg^-(y)\equiv \beta(y)\pmod 3$ holds for all $y\in V(\g)\setminus\{u,v\}$. However, since there are at least two edges between $u$ and $v$, it is possible to orient them so that this condition holds also for $y=u$, which by Observation~\ref{obs-allbutone} shows that the resulting orientation is a nowhere-zero flow in $\g$ extending $\psi$. This is a contradiction.",2502.01451
proof,"Suppose for a contradiction that $(\g,z)$ is a minimal counterexample, i.e., a tame non-trivial flow-critical canvas with the smallest number of vertices and such that $\deg(z) <6+|\tau(z)|$. Since $\deg(z)$ and $|\tau(z)|$ have the same parity, we have $\deg(z)\le 4+|\tau(z)|$. Since the canvas $(\g,z)$ is flow-critical and non-trivial, there exists a tip-respecting preflow $\psi$ does not extend to a nowhere-zero flow in $\g$. By Theorem~\ref{thm:lovaszrealtheorem}, there exists a non-empty set $A\subsetneq V(\g)\setminus\{z\}$ such that $\deg(A) < 4 + |\tau(A)|$. Since $(\g,z)$ is tame, we have $|A|\ge 2$.  The canvas $(\g',b)=(\g,z)\restriction A$ is flow-critical by Observation~\ref{obs-subcrit}, and tame by inspection. Since $\g'$ has fewer vertices than $\g$, $(\g',b)$ is not a counterexample to Corollary~\ref{cor-mainlov}, and thus $\deg(b) \ge 6+|\tau(b)|$.  However, $\deg(b)=\deg(A)< 4 + |\tau(A)|=4+|\tau(b)|$, which is a contradiction.",2502.01451
proof,"By Observation~\ref{obs-subcrit}, $(\g',b)=(\g,z)\restriction A$ is a flow-critical canvas.  Note that $(\g',b)$ is tame and has at least three vertices, and thus by Corollary~\ref{cor-mainlov}, we have $\deg(A)= \deg(b) \ge 6+|\tau(b)|=6+|\tau(A)|$.",2502.01451
proof,"The first claim follows by Lemma~\ref{lemma-cut}. If $(\g',z)$ is a tip-respecting contraction of $(\g,z)$ and $v\in V(\g')$, then consider the set $A\subseteq V(\g)$ contracted into $v$.  If $|A|\ge 2$, then $\deg(v)=\deg(A) \ge 6+|\tau(A)|=6+|\tau(v)|>4+|\tau(v)|$, as we have just proved. If $A$ consists of a single vertex $u\in V(\g)$, then $\deg(v)=\deg(u)\ge 4+|\tau(u)|=4+|\tau(v)|$, since $(\g,z)$ is tame.  Hence, $(\g',z)$ is also tame.",2502.01451
proof,"Suppose for a contradiction that $\g=(G,\beta)$ is not connected, and let $\comp$ be a component of $\g$ that does not contain $z$. We claim that $\comp$ has a nowhere-zero flow.  This is trivially the case if $|V(\comp)|=1$, and thus suppose that $\comp$ has at least two vertices. By Lemma~\ref{lemma-cut}, we have $\deg(A)\ge 4+|\tau(A)|$ for every non-empty $A\subseteq V(\comp)\setminus \{x\}$. Since $\beta$ is a $\Z$-boundary, we have $\beta(V(\comp))\equiv 0\pmod 3$, and consequently $|\tau(A)|=|\tau(V(\comp)\setminus A)|$. Since $\deg(A) =\deg(V(\comp)\setminus A)$, we conclude that $\deg(A')\ge 4+|\tau(A')|$ holds also for sets $A'\subseteq V(\comp)$ containing $x$ (in the case that $x\in V(\comp)$).  Let $\comp'$ be obtained from $\comp$ by adding an isolated vertex $z'$ with boundary value $0$. By Theorem~\ref{thm:lovaszrealtheorem} applied to the canvas $(\comp',z')$, we conclude that $\comp$ indeed has a nowhere-zero flow.  Since $(\g,z)$ is non-trivial, flow-critical, and $\comp$ has a nowhere-zero flow, there must exist a vertex $v\in V(\g)\setminus V(\comp)$ distinct from $z$. Since $(\g,z)$ is flow-critical, there exists a tip preflow $\psi$ that does not extend to a nowhere-zero flow in $\g$, but extends to a nowhere-zero flow $\varphi$ in the canvas $(\g',z)$ obtained from $(\g,z)$ by contracting $V(\comp)\cup\{v\}$.  However, the canvas $(\g',z)$ is isomorphic to $\g-V(\comp)$, and thus $\varphi$ combines with a nowhere-zero flow in $\comp$ to a nowhere-zero flow in $\g$ extending $\psi$, which is a contradiction.",2502.01451
proof,"Let $\g=(G,\beta)$. If $\g-z$ is not 2-connected, then since $|V(\g)|\ge 4$, there exists a partition $\{A_1,A_2,\{z\},\{x\}\}$ of $V(\g)$ such that $A_1$ and $A_2$ are non-empty and there are no edges between $A_1$ and $A_2$.  For $i\in\{1,2\}$, since $(\g,z)$ is $\psi$-critical, $\psi$ extends to a nowhere-zero flow $\vec{G}_i$ in $\g/(\{x\}\cup A_{3-i})$.  Let $\vec{G}$ be the orientation of $G$ matching $\vec{G}_i$ on the edges incident with $A_i$ for $i\in\{1,2\}$ and $\psi$ on the edges between $z$ and $x$.   Clearly, we have $\deg^+(v)-\deg^-(v)\equiv \beta(v)$ for every $v\in V(\g)\setminus\{x\}$,  and by Observation~\ref{obs-allbutone}, it follows that $\vec{G}$ is a nowhere-zero flow.  Since $\vec{G}$ extends $\psi$, this is a contradiction.",2502.01451
proof,"Let $(\g,z,x,\psi)$ be a tall tame critical easel with $\g=(G,\beta)$.  Since $\psi$ is not itself a nowhere-zero flow in $\g$, we have $|V(\g)|\ge 3$.  Suppose for a contradiction that $V(\g)=\{v,z,x\}$.  Let $m$ be the number of edges between $v$ and $x$; by Lemma~\ref{lemma-simple}, we have $m\le 1$.  Note that since the easel is tame, $\deg(v)\ge 4+|\tau(v)|$.  Since the easel is tall, we have $\deg(x)\ge \deg(z)-2=(\deg(x)+\deg(v)-2m)-2$, and thus $\deg(v)\le 2m+2$.  We conclude that $m=1$, $\deg(v)=4$ and $\beta(v)=0$. Since the easel is tall and $\deg(z)=\deg(x)+2$, the three edges between $v$ and $z$ are not all oriented by $\psi$ in the same direction (all towards $z$ or all away from $z$). Hence, it is possible to direct the edge $vx$ so that $v$ has the same indegree and outdegree. By Observation~\ref{obs-allbutone}, this extends $\psi$ to a nowhere-zero flow in $\g$. This is a contradiction, and thus $|V(\g)|\ge 4$.",2502.01451
proof,"Consider any edge $uv$ of $\g-\{x,z\}$.  Since this edge is not mixed, we either have $\tau(u),\tau(v)>0$, or $\tau(u),\tau(v)<0$. Since $\g-\{x,z\}$ is connected by Lemma~\ref{lemma-2con}, the claim of the observation follows.",2502.01451
proof,"[Proof of Theorem \ref{cor-tall}] Suppose for a contradiction that a tip preflow $\psi$ does not extend to a nowhere-zero flow in $\g$. Then $(\g,z)$ has a tip-respecting $\psi$-critical contraction $(\g/\PP,z)$.  Note that $|V(\g/\PP)|\ge 3$ by Observation~\ref{obs-ge3}. Since $\deg(A)\ge 4+|\tau(A)|$ for every non-empty $A\subsetneq V(\g)\setminus\{z\}$, we conclude that the canvas $(\g/\PP,z)$ is tame.  Let $x'$ be the vertex of $\g/\PP$ corresponding to the part $X\in \PP$ containing $x$. Since $\deg(X)>\deg(z)-2$ for every $X\subseteq V(\g)\setminus\{z\}$ containing $x$, we have $\deg(x')>\deg(z)-2$. This contradicts Theorem~\ref{thm-deg}.",2502.01451
proof,"We first argue that $\prec$ is transitive.  Suppose that  $$(\g_1,z_1,x_1)\prec (\g_2,z_2,x_2)\prec(\g_3,z_3,x_3).$$ This implies that $o(\g_1,z_1)\le o(\g_2,z_2)\le o(\g_3,z_3)$.  If $o(\g_1,z_1)<o(\g_2,z_2)$ or $o(\g_2,z_2)<o(\g_3,z_3)$, then $o(\g_1,z_1)<o(\g_3,z_3)$ and $(\g_1,z_1,x_1)\prec (\g_3,z_3,x_3)$.  Hence, suppose that $o(\g_1,z_1)=o(\g_2,z_2)=o(\g_3,z_3)$. Since $(\g_1,z_1,x_1)\prec (\g_2,z_2,x_2)\prec(\g_3,z_3,x_3)$, the canvases $(\g_i,z_i)$ for $i\in\{2,3\}$ are $x_i$-homogeneous and $\deg(z_2)<\deg(z_3)$.  If $(\g_1,z_1)$ is not $x_1$-homogeneous, then $(\g_1,z_1,x_1)\prec (\g_3,z_3,x_3)$ since $(\g_3,z_3)$ is $x_3$-homogeneous. If $(\g_1,z_1)$ is $x_1$-homogeneous, then $\deg(z_1)<\deg(z_2)<\deg(z_3)$ and $(\g_1,z_1,x_1)\prec (\g_3,z_3,x_3)$.  Next, suppose for a contradiction that  $$(\g_1,z_1,x_1)\succ (\g_2,z_2,x_2)\succ (\g_3,z_3,x_3) \succ \cdots$$ is an infinite decreasing chain. Since $o(\g_i,z_i)$ is a non-negative integer and  $$o(\g_1,z_1)\ge o(\g_2,z_2)\ge \cdots,$$ there exist $i_0$ and $m$ such that $o(\g_i,z_i)=m$ for every $i\ge i_0$.  For every $i\ge i_0$, since $o(\g_{i+1},z_{i+1})=o(\g_i,z_i)$ and $(\g_{i+1},z_{i+1},x_{i+1})\prec (\g_i,z_i,x_i)$, it follows that $(\g_i,z_i)$ is $x_i$-homogeneous.  Hence,  $$(\g_{i_0},z_{i_0},x_{i_0})\succ (\g_{i_0+1},z_{i_0+1},x_{i_0+1})\succ \cdots$$ implies $$\deg(z_{i_0}) > \deg(z_{i_0+1}) > \cdots,$$ which is a contradiction since degrees are non-negative integers.",2502.01451
proof,"Suppose for contradiction that $|A|\ge 2$ but $\deg(A)\le \deg(x)+1$, and let us choose a minimal set $A$ with this property. Let $(\g_0,b)=(\g,z)\restriction A$. By Observation~\ref{obs-subcrit}, $(\g_0, b)$ is flow-critical, and since $|V(\g_0)|=|A|+1>2$, there exists a tip preflow $\psi'$ and a tip-respecting partition $\PP$ of $V(\g_0)$ such that $\g'=\g_0/\PP$ is $\psi'$-critical. Let $x'$ be the vertex of $\g'$ corresponding to the part $X$ of $\PP$ containing $x$.   Corollary \ref{cor-contrtame} implies that $(\g',b,x',\psi')$ is tame.  Moreover, either $|X| =1$, in which case we have $\deg(x') = \deg(x) \geq \deg(z) -1$, or $|X| \geq 2$, in which case the minimality of $A$ implies $\deg(x') = \deg(X) \geq \deg(x)+2$. In both cases we have $\deg(x') \geq \deg(x) \geq \deg(A)-1 = \deg(b)-1$, and thus it follows that the easel $(\g',b,x',\psi')$ is a tall.  Moreover, $o(\g',b) < o(\g,z)$, and thus the tall tame critical easel $(\g',b,x',\psi')$ contradicts the minimality of $(\g,z,x,\psi)$.",2502.01451
proof,"Suppose for contradiction that $A\neq V(\g)\setminus\{z\}$ but $\deg(A)=\deg(x)+2$, and let us consider a maximal such set $A$.  Let $C=V(\g)\setminus (A\cup \{z\})$. Our goal is to find two edges $e_{1}$ and $e_{2}$ between $C$ and $A \setminus \{x\}$ such that the canvas obtained by contracting $A$ to a vertex and splitting off $e_{1}$ and $e_{2}$ has a flow extending $\psi$.   Since $\g-\{x,z\}$ is connected by Corollary~\ref{cor-2con} and $C\neq\emptyset$, there exists an edge $e_1$ between $C$ and $A\setminus\{x\}$. Let $u_1$ be the end of $e_1$ in $C$.  Let $Q$ be the set of edges of $\g$ between $C\cup\{z\}$ and $A\setminus\{x\}$; since $\deg(A)=\deg(x)+2$, we have $|Q|\ge 2$. Let us now describe how to choose an edge $e_2\in Q\setminus\{e_1\}$:  \item If $\psi$ directs all edges between $z$ and $C$ away from $z$ and there exists an edge $e$ between $A\setminus\{x\}$ and $z$ directed by $\psi$ towards $z$, then let $e_2=e$. \item Otherwise, if $\psi$ directs all edges between $z$ and $C$ towards $z$ and there exists an edge $e$ between $A\setminus\{x\}$ and $z$ directed by $\psi$ away from $z$, then let $e_2=e$. \item Otherwise, if there exists an edge in $Q$ not incident with $u_1$, choose $e_2$ as such an edge. \item Otherwise choose $e_2\in Q\setminus\{e_1\}$ arbitrarily.    See Figure \ref{fig:pickingedgescases} for an illustration of the cases. %start of picture        \node[blackvertexv2] at (0,.25) (u1) [label = left:$u_{1}$] {};     \node[dummywhite] at (-1.5,0) (case1) [label =right: $1)$] {};     \node[ellipsenodev1] at (0,0) (ellipse1) [label = above:$C$] {};     \node[ellipsenodev1] at (3,0) (ellipse2) [label = above:$A$] {};     \node[blackvertexv2] at (3,0) (x) [label = right:$x$] {};     \node[blackvertexv2] at (3,.75) (u2) {};     \node[blackvertexv2] at (.5,-2.5) (z) [label = left:$z$] {};     \node[blackvertexv2] at (3,-.75) (u3) {};     \node[dummywhite] at (1.5,1.25) (dummywhite1) [label = above: \small $\deg(x) +2$]  {};     \node[dummywhite] at (1.5,-1.25) (dummywhite2){};      \draw[ultra thin,dashed,gray] (dummywhite1) to (dummywhite2);      \draw[thick,black] (u2)--node[left,,yshift=.2cm]{$e_{1}$}(u1);      \draw[thick,black, ->] (z) to (ellipse1);      \draw[thick,black, bend left = 10,->] (z) to (ellipse1);      \draw[ thick,black, bend right = 10,->] (z) to (ellipse1);      \draw[thick,black] (ellipse1) to (ellipse2);      \draw[thick,black,bend right =10] (ellipse1) to (ellipse2);      \draw[thick,black,bend left =10] (ellipse1) to (ellipse2);      \draw[thick,black,->] (u3) to node[left,xshift=-.1cm]{$e_{2}$}(z);       [xshift =5.5cm]            \node[blackvertexv2] at (0,.25) (u1) [label = left:$u_{1}$] {};     \node[ellipsenodev1] at (0,0) (ellipse1) [label = above:$C$] {};     \node[ellipsenodev1] at (3,0) (ellipse2) [label = above:$A$] {};       \node[dummywhite] at (-1.5,0) (case1) [label =right:$2)$] {};     \node[blackvertexv2] at (3,0) (x) [label = right:$x$] {};     \node[blackvertexv2] at (3,.75) (u2) {};     \node[blackvertexv2] at (.5,-2.5) (z) [label = left:$z$] {};     \node[blackvertexv2] at (3,-.75) (u3) {};     \node[dummywhite] at (1.5,1.25) (dummywhite1) [label = above: \small $\deg(x) +2$]  {};     \node[dummywhite] at (1.5,-1.25) (dummywhite2){};      \draw[ultra thin,dashed,gray] (dummywhite1) to (dummywhite2);      \draw[thick,black] (u2)--node[left,,yshift=.2cm]{$e_{1}$}(u1);      \draw[thick,black,  postaction={decoration={markings,mark=at position 0.5 with {\arrow{<}}},decorate}] (z) to (ellipse1);      \draw[thick,black, bend left = 10,postaction={decoration={markings,mark=at position 0.5 with {\arrow{<}}},decorate}] (z) to (ellipse1);      \draw[ thick,black, bend right = 10,postaction={decoration={markings,mark=at position 0.5 with {\arrow{<}}},decorate}] (z) to (ellipse1);      \draw[thick,black] (ellipse1) to (ellipse2);      \draw[thick,black,bend right =10] (ellipse1) to (ellipse2);      \draw[thick,black,bend left =10] (ellipse1) to (ellipse2);      \draw[thick,black,<-] (u3) to node[left,xshift=-.1cm]{$e_{2}$}(z);              [xshift =5.5cm,yshift =-5cm]        \node[blackvertexv2] at (0,.25) (u1) [label = left:$u_{1}$] {};     \node[ellipsenodev1] at (0,0) (ellipse1) [label = above:$C$] {};     \node[ellipsenodev1] at (3,0) (ellipse2) [label = above:$A$] {};      \node[dummywhite] at (-1.5,0) (case1) [label =right:$4)$] {};     \node[blackvertexv2] at (3,0) (x) [label = right:$x$] {};     \node[blackvertexv2] at (3,.5) (u2) {};     \node[blackvertexv2] at (.5,-2.5) (z) [label = left:$z$] {};     \node[blackvertexv2] at (3,1) (u3) {};      \node[dummywhite] at (1.5,1.25) (dummywhite1) [label = above: \small $\deg(x) +2$]  {};     \node[dummywhite] at (1.5,-1.25) (dummywhite2){};      \draw[ultra thin,dashed,gray] (dummywhite1) to (dummywhite2);      \draw[thick, black] (u2)--node[above,yshift=.3cm,xshift=.2cm]{$e_{1}$}(u1);      \draw[thick,black,  postaction={decoration={markings,mark=at position 0.5 with {\arrow{<}}},decorate}] (z) to (ellipse1);      \draw[thick,black, bend left = 10,postaction={decoration={markings,mark=at position 0.5 with {\arrow{>}}},decorate}] (z) to (ellipse1);      \draw[ thick,black, bend right = 10,postaction={decoration={markings,mark=at position 0.5 with {\arrow{<}}},decorate}] (z) to (ellipse1);      \draw[thick,black] (ellipse1) to (ellipse2);      \draw[thick,black,bend right =10] (ellipse1) to (ellipse2);      \draw[thick,black,bend left =10] (ellipse1) to (ellipse2);     \draw[thick,black] (u1) to node[below,yshift =.2cm, xshift =.5cm]{$e_{2}$}(u3);                            [yshift =-5cm]  \node[blackvertexv2] at (0,.25) (u1) [label = left:$u_{1}$] {};     \node[ellipsenodev1] at (0,0) (ellipse1) [label = above:$C$] {};     \node[ellipsenodev1] at (3,0) (ellipse2) [label = above:$A$] {};         \node[dummywhite] at (-1.5,0) (case1) [label =right:$3)$] {};     \node[blackvertexv2] at (3,0) (x) [label = right:$x$] {};     \node[blackvertexv2] at (3,.75) (u2) {};     \node[blackvertexv2] at (.5,-2.5) (z) [label = left:$z$] {};     \node[blackvertexv2] at (3,-.75) (u3) {};      \node[blackvertexv2] at (0,-.75) (u4) {};     \node[dummywhite] at (1.5,1.25) (dummywhite1) [label = above: \small $\deg(x) +2$]  {};     \node[dummywhite] at (1.5,-1.25) (dummywhite2){};      \draw[ultra thin,dashed,gray] (dummywhite1) to (dummywhite2);      \draw[thick, black] (u2)--node[left,,yshift=.2cm]{$e_{1}$}(u1);      \draw[thick,black,  postaction={decoration={markings,mark=at position 0.5 with {\arrow{<}}},decorate}] (z) to (ellipse1);      \draw[thick,black, bend left = 10,postaction={decoration={markings,mark=at position 0.5 with {\arrow{>}}},decorate}] (z) to (ellipse1);      \draw[ thick,black, bend right = 10,postaction={decoration={markings,mark=at position 0.5 with {\arrow{<}}},decorate}] (z) to (ellipse1);      \draw[thick,black] (ellipse1) to (ellipse2);      \draw[thick,black,bend right =10] (ellipse1) to (ellipse2);      \draw[thick,black,bend left =10] (ellipse1) to (ellipse2);      \draw[thick,black] (u3)--node[left,yshift=.2cm, xshift=-.3cm]{$e_{2}$}(u4);        \caption{The four possible cases in Lemma \ref{lemma-sepx} for how we choose the edges $e_{1}$ and $e_{2}$. Note that in cases $1$ and $2$, we must have all of the edges from $z$ to $C$ oriented in the same direction, whereas in cases $3$ and $4$, either there is no edge from $z$ to $A$, or not all the edges go the same direction. Hence, these figures are merely examples of the four possible cases.}     %end of picture Let $\g_1$ be the $\Z$-bordered graph obtained from $\g$ by contracting $A$ to a single vertex $a$ and then splitting off the edges $e_1$ and $e_2$; let $e$ denote the resulting edge added in the case that $e_1$ and $e_2$ are not incident with the same vertex in $V(\g)\setminus A$. We can view $\psi$ as a tip preflow in $(\g_1,z)$ (in the case that $e_2$ is incident with $z$, $e$ inherits its orientation).    The preflow $\psi$ extends to a nowhere-zero flow $\vec{G}_{1}$ in $\g_1$.    If $\psi$ does not extend to a nowhere-zero flow in $\g_1$, then there exists a $\psi$-critical tip-respecting contraction $(\g'_1,z)$ of $(\g_1,z)$. Let $a'$ be the vertex of $\g'_1$ into which we contracted $a$, and consider the critical easel $(\g'_1,z,a',\psi)$. We aim to show that $(\g'_{1},z,a',\psi)$ is a tall tame critical easel, contradicting the minimality of $(\g,z,x,\psi)$.      The easel $(\g',z,a',\psi)$ is tame.     Let $u'$ be any vertex in $V(\g'_1)\setminus \{z,a'\}$, and let $U$ be the set of vertices of $\g$ contracted into $u'$.      Note that if both $e_1$ and $e_2$ have exactly one end in $U$, then $\deg_{\g'_1}(u')=\deg_{\g}(U)-2$, otherwise $\deg_{\g'_1}(u')=\deg_{\g}(U)$.     In particular, $\deg_{\g'_1}(u')$ and $\deg_{\g}(U)$ have the same parity, and thus $\tau(u')=\tau(U)$.     We now discuss three cases depending on the size of $U$ and the incidence of $e_1$ and $e_2$ with the vertices of $U$.   \item If $U$ contains at least two vertices, then by Lemma~\ref{lemma-cut} we have $\deg_{\g'_1}(u')\ge \deg_{\g}(U)-2\ge 4+|\tau(U)|=4+|\tau(u')|$. \item If $U$ consists of a single vertex, say $u$, and  $\deg_{\g'_1}(u')=\deg_{\g}(U)=\deg_{\g}(u)$, then $\deg_{\g'_1}(u')=\deg_{\g}(u)\ge 4+|\tau(u)|=4+|\tau(u')|$ by the tameness of $(\g,z,x,\psi)$.  \item If $|U|=1$ and $\deg_{\g'_1}(u')<\deg_{\g}(U)$, then $U=\{u_1\}$ and both $e_1$ and $e_2$ are incident with $u_{1}$.  By our choice of $e_2$, this means that all edges of $Q$ are incident with $u_{1}$. In $\g'_1$, all edges of $Q\setminus\{e_1,e_2\}$ join $u'$ with $a'$.  By Lemma~\ref{lemma-simple} applied to $(\g'_1,z)$, there is at most one edge between $u'$ and $a'$, and thus $|Q|\le 3$.  Since $\deg(A)=\deg(x)+2$, there are $\deg(A)-|Q|=\deg(x)+2-|Q|$ edges between $x$ and $C\cup\{z\}$, and thus there are $|Q|-2$ edges between $x$ and $A\setminus\{x\}$. Consequently, $\deg(A\setminus\{x\})=2|Q|-2\le 4$.  By Lemma~\ref{lemma-simple} for $(\g,z)$, the edges $e_1$ and $e_2$ are incident with distinct vertices of $A\setminus\{x\}$, and thus $|A\setminus \{x\}|\ge 2$.  This contradicts Lemma~\ref{lemma-cut} for the set $A\setminus\{x\}$ in $(\g,z)$, and thus this case does not happen.  Therefore, we have $\deg_{\g'_1}(u')\ge 4+|\tau(u')|$ for every $u'\in V(\g'_1)\setminus\{z,a'\}$, and thus the easel $(\g'_1,z,a',\psi)$ is tame.    Now we check that $(\g_{1}',z,a',\psi)$ is tall.   The easel $(\g_{1}',z,a',\psi)$ is tall.    Let $A'$ be the subset of vertices of $\g$ contracted into $a'$. Note that $A'$ is a superset of $A$.  \item If $A'\neq A$, then the maximality of $A$ implies $\deg_{\g'}(a')\ge \deg_{\g}(A')-2>\deg(x)\ge \deg(z)-2$. \item If $A'=A$, then $\deg(a')\ge \deg_{\g}(A)-2=\deg(x)\ge \deg(z)-2$.  Moreover, we claim that if $\deg(z)=\deg(x)+2$, then $\psi$ does not direct all edges between $z$ and $V(\g'_1)\setminus \{z,a'\}$ the same way.  Indeed, since $\deg(z)=\deg(x)+2=\deg(A)$ and at least the edge $e_1$ with exactly one end in $A$ is not incident with $z$, there exists at least one edge between $z$ and $C$.  If $\psi$ directs all edges from $z$ to $C$ in the same way, say away from $z$, and $\deg(z)=\deg(x)+2$, then the tallness of $(\g,z,x,\psi)$ implies that there exists an edge between $A\setminus\{x\}$ and $z$ directed by $\psi$ towards $z$, and $e_2$ is chosen as such an edge. Therefore, the edge $e$ of $\g'_1$ arising from the splitting off $e_1$ and $e_2$ is not incident with $a'$ and it is directed in the same way as $e_2$ by $\psi$, i.e., towards $z$.  We conclude that the easel $(\g'_1,z,a',\psi)$ is tall.       The above two subclaims contradict our assumption that $(\g,z,x,\psi)$ is a minimal tall tame critical easel, and thus $\psi$ extends to a nowhere-zero flow $\vec{G}_1$ in $\g_1$.   The claim implies that $\psi$ extends to a nowhere-zero flow $\vec{G}_a$ in $\g/A$ with one of the edges $e_1$ and $e_2$ directed towards $a$ and the other one away from $a$, obtained from $\vec{G}_1$ by directing $e_1$ and $e_2$ according to the orientation of $e$ (or arbitrarily in opposite directions in the case that $e_1$ and $e_2$ are incident with the same vertex of $C$, and thus the edge $e$ is not added when splitting off $e_1$ and $e_2$).  Let $(\g_2,z_2)=(\g,z)\restriction A$ and let $\psi_2$ be the tip preflow matching the orientations of the edges of $\vec{G}_a$ incident with $a$. If $\psi_2$ extended to a nowhere-zero flow in $\g_2$, then this nowhere-zero flow would combine with $\vec{G}_a$ to a nowhere-zero flow in $\g$ extending $\psi$, which is a contradiction.  Hence, there exists a $\psi_2$-critical tip-respecting contraction $\g'_2$ of $\g_2$.  Let $x_2$ be the vertex of $\g'_2$ into which we contracted $x$, and let $X_2$ be the set of vertices of $\g$ contracted to $x_2$. Then $(\g'_2,z_2,x_2,\psi_2)$ is a critical easel, and it is easy to see that this easel is tame by Lemma~\ref{lemma-cut}. We now show that it is tall:  \item If $|X_2|>1$, then Lemma~\ref{lemma-sepxsmall} implies $\deg(x_2)=\deg(X_2)\ge \deg(x)+2=\deg(A)=\deg(z_2)$. \item If $X_2=\{x\}$, then $\deg(x_2)=\deg(x)=\deg(z_2)-2$. The choice of $\psi_2$ implies that $\psi_2$ directs the edges $e_1$ and $e_2$ in the opposite direction.  Moreover, since neither $e_1$ nor $e_2$ are incident with $x$ in $\g$, they are also not incident with $x_2$ in $\g'_2$.  Now, since $o(\g'_2,z_2)<o(\g,z)$, this contradicts the assumption that $(\g,z,x,\psi)$ is a minimal tall tame critical easel.",2502.01451
proof,"Let $\g=(G,\beta)$.  Suppose for a contradiction that $\deg(v)\le 4$.  Since the easel is tame, we have $\deg(v)\ge 4+|\tau(v)|$, and thus $\deg(v)=4$, $|\tau(v)|=0$, and $\beta(v)=0$.  By Lemmas~\ref{lemma-2con} and \ref{lemma-at4}, there exists an edge $e_1$ between $v$ and a vertex $v_1\in V(\g)\setminus\{v,x,z\}$. Let us now distinguish several cases:  \item[(i)] If there are two edges between $v$ and $z$ that are directed oppositely by $\psi$, then let $e_3$ and $e_4$ be such edges and let $e_2$ be the edge incident with $v$ and distinct from $e_1$, $e_3$, and $e_4$. \item[(ii)] If $v$ is adjacent to $z$ but all edges between $v$ and $z$ are directed in the same way by $\psi$ (all towards $z$ or all away from $z$), then note that there are at most two such edges, as otherwise $\psi$ would not extend to a nowhere-zero flow in $\g/\{v_1,x\}$, contradicting the $\psi$-criticality of $(\g,z)$.  We let $e_2$ be an edge between $z$ and $v$, and let $e_3$ and $e_4$ be the edges incident with $v$ and distinct from $e_1$ and $e_2$. \item[(iii)] Finally, if $v$ is not adjacent to $z$, then we assign the labels $e_2$, $e_3$, and $e_4$ to the edges incident with $v$ and distinct from $e_1$ arbitrarily.  See Figure \ref{fig:deg4splitting} for an illustration of these cases. %start of picture     \node[blackvertexv2] at (0,0) (v) [label= above:$v$] {}; \node[blackvertexv2] at (1.5,-2) (z) [label = below:$z$] {}; \node[blackvertexv2] at (-1.5,-2) (v1) [label = below:$v_{1}$] {}; \node[blackvertexv2] at (0,-2) (v2) {}; \node[dummywhite] at (-.75,0) (dummywhite1) [label = left:$(i)$]  {}; \draw[thick,black] (v) -- node[left]{$e_{1}$}(v1); \draw[thick,black, bend left = 15,postaction={decoration={markings,mark=at position 0.6 with {\arrow{<}}},decorate}] (v) to node[right]{$e_{4}$}(z); \draw[thick,black, bend right = 15,postaction={decoration={markings,mark=at position 0.6 with {\arrow{>}}},decorate}] (v) to node[left]{$e_{3}$}(z); \draw[thick,black] (v) to node[left]{$e_{2}$} (v2);  [xshift = 4cm] \node[blackvertexv2] at (0,0) (v) [label= above:$v$] {}; \node[blackvertexv2] at (1.5,-2) (z) [label = below:$z$] {}; \node[blackvertexv2] at (-1.5,-2) (v1) [label = below:$v_{1}$] {}; \node[dummywhite] at (-.75,0) (dummywhite1) [label = left:$(ii)$]  {}; \node[blackvertexv2] at (0,-2) (v2) {}; \draw[thick,black] (v) -- node[left]{$e_{1}$}(v1); \draw[thick,black, bend left = 15,postaction={decoration={markings,mark=at position 0.7 with {\arrow{>}}},decorate}] (v) to node[right]{$e_{4}$}(z); \draw[thick,black, bend right = 15,postaction={decoration={markings,mark=at position 0.7 with {\arrow{>}}},decorate}] (v) to node[left]{$e_{2}$}(z); \draw[thick,black] (v) to node[left]{$e_{3}$} (v2);   [xshift = 8cm] \node[blackvertexv2] at (0,0) (v) [label= above:$v$] {}; \node[blackvertexv2] at (1,-2) (z) {}; \node[blackvertexv2] at (-1,-2) (v1) [label = below:$v_{1}$] {}; \node[blackvertexv2] at (0,-2) (v2) {}; \node[blackvertexv2] at (2,-2) (v3) {}; \node[dummywhite] at (-.75,0) (dummywhite1) [label = left:$(iii)$]  {}; \draw[thick,black] (v) -- node[left,yshift =-.1]{$e_{1}$}(v1); \draw[thick,black] (v) to node[left,yshift =-.1]{$e_{3}$}(z); \draw[thick,black] (v) to node[left,yshift=-.1]{$e_{4}$}(v3); \draw[thick,black] (v) to node[left,yshift =-.1]{$e_{2}$} (v2);   \caption{The three cases in Lemma \ref{lemma-no4}. Note in case (i), the edge $e_{2}$ may be incident to $z$, and in case (iii) there may be parallel edges.}     Let $\g'$ be obtained from $\g$ by splitting off $e_1$ with $e_2$ and $e_3$ with $e_4$ and deleting the now isolated vertex $v$. Note that if $e_3$ and $e_4$ are both directed by $\psi$, then they are directed in opposite directions. Hence, $\psi$ naturally corresponds to a tip preflow $\psi'$ in the canvas $(\g',z)$. Moreover, since $\psi$ does not extend to a nowhere-zero flow in $\g$, it is easy to see that $\psi'$ does not extend to a nowhere-zero flow in $\g'$, either.  Hence, there exists a $\psi'$-critical tip-respecting contraction $(\g'',z)$ of $(\g',z)$.  Let $x'$ be the vertex of $\g''$ into which we contracted $x$. Consider now the easel $(\g'',z,x',\psi')$. We will show it is tame and tall.     The easel $(\g'',z,x',\psi')$ is tame.     Consider any vertex $u\in V(\g'')\setminus\{z,x'\}$, and let $A_0$ be the set of vertices of $\g$ contracted into $u$.  If at least three of the edges $e_1$, \ldots, $e_4$ have an end in $A_0$, then let $A=A_0\cup\{v\}$; otherwise let $A=A_0$. Observe that not all four edges $e_{1},\ldots,e_{4}$ have an end in $A_{0}$, as otherwise we contradict criticality of $(\g,z,x,\psi)$.  Note that this ensures that either $\deg(u)=\deg_{\g}(A)$ or $\deg(u)=\deg_{\g}(A)-2$.  Moreover, in the latter case $v$ has either two or three neighbours in $A$, and thus by Lemma~\ref{lemma-simple}, we have $|A|\ge 2$.  Lemma~\ref{lemma-cut} and the tameness of the easel $(\g,z,x,\psi)$ then imply that $|\tau(u)|=|\tau(A)|\ge 4+\deg_{\g}(A)=4+\deg(u)$ in the former case, and $|\tau(u)|=|\tau(A)|\ge 6+\deg_{\g}(A)=4+\deg(u)$ in the latter case.    The easel $(\g'',z,x',\psi')$ is tall.    Consider the set $X_0$ of the vertices of $\g$ contracted into $x'$, and let $X=X_0\cup\{v\}$ if at least three of the edges $e_1$, \ldots, $e_4$ have an end in $X_0$ and $X=X_0$ otherwise. As before, not all four edges can have an end in $X_{0}$, as otherwise we contradict the criticality of $(\g,z,x,\psi)$. Thus either $\deg(x')=\deg_{\g}(X)$, or $\deg(x')=\deg_{\g}(X)-2$ and $|X|\ge 2$.  \item If $|X|\ge 2$, then Lemma~\ref{lemma-sepx} implies $\deg(x') \ge \deg_{\g}(X)-2>\deg(x)\ge \deg_{\g}(z)-2\ge \deg_{\g''}(z)-2$, and thus the easel $(\g'',z,x',\psi')$ is tall. \item If $X=\{x\}$, then $\deg(x')=\deg_{\g}(X)=\deg(x)$.  If $\deg(x)>\deg_{\g}(z)-2$ or $\deg_{\g}(z)>\deg_{\g''}(z)$, this again implies that the easel $(\g'',z,x',\psi')$ is tall. \item Finally, suppose that $X=\{x\}$, $\deg(x)=\deg_{\g}(z)-2$, and $\deg_{\g} (z)=\deg_{\g''}(z)$. In particular, the labels of $e_2$, $e_3$, and $e_4$ were not chosen according to (i), as in that case splitting off $e_3$ with $e_4$ decreases the degree of $z$. Since the easel $(\g,z,x,\psi)$ is tall and $\deg(x)=\deg_{\g}(z)-2$, there exist two edges $e_5$ and $e_6$ incident with $z$, not incident with $x$, and directed oppositely by $\psi$.  Since the labels were not chosen according to (i), we may assume without loss of generality that $e_6$ is not incident with $v$, and thus that $e_6$ is an edge of $\g''$ not incident with $x'$. If $e_5$ is incident with $v$, then case (iii) does not occur, and further the choice in (ii) ensures that $e_2$ is incident with $z$ and directed in the same way as $e_5$. Moreover, since $e_1$ is not incident with $x$, we have that $e_1$ and $e_2$ are split off to an edge not incident with $x$ and directed in the same way as $e_5$. Hence, in this case we again conclude that the easel $(\g'',z,x',\psi')$ is tall.    The above claims imply that $(\g'',z,x',\psi')$ is a tall tame critical easel, and since $o(\g'',z)<o(\g,z)$, this contradicts the assumption that $(\g,z,x,\psi)$ is a minimal tall tame critical easel,  which concludes the proof.",2502.01451
proof,"Suppose for a contradiction that $uv\in E(\g-\{x,z\})$ is a mixed edge where, say, $\tau(u)$ is out-friendly and $\tau(v)$ is in-friendly.  Let $\g=(G,\beta)$ and let $\g'=(G-uv,\beta')$, where $\beta'(y)=\beta(y)$ for $y\in V(G)\setminus\{u,v\}$, $\beta'(u)=\beta(u)-1$, and $\beta'(v)=\beta(v)+1$.  Note that $G-uv$ is connected by Corollary~\ref{cor-2con}, and since $\beta'(V(G))=\beta(V(G))=0$, $\beta'$ is a $\Z$-boundary for $G-uv$.  If $\g'$ had a nowhere-zero flow extending $\psi$, we could extend it to a nowhere-zero flow in $\g$ by directing the edge $uv$ towards $v$.  Hence, $\psi$ does not extend to a nowhere-zero flow in $\g'$, and thus $(\g',z)$ has a tip-respecting $\psi$-critical contraction $(\g'',z)$.  Let $x'$ be the vertex of $\g''$ into which we contracted $x$, and consider the easel $(\g'',z,x',\psi)$. We claim this easel is tame and tall.   The easel $(\g'',z,x',\psi)$ is tame.     Consider any vertex $y\in V(\g'')\setminus \{z,x'\}$, and let $Y$ be the set of vertices of $\g$ contracted into $y$.  If $|\{u,v\}\cap Y|\in\{0,2\}$, then $\deg(y)=\deg_{\g}(Y)$ and $\beta'(y)=\beta(Y)$, and thus $\deg(y)\ge 4+|\tau(y)|$ by the tameness of $(\g,z,x,\psi)$ and Lemma~\ref{lemma-cut}.  Hence, by symmetry we can assume that $u\in Y$ and $v\not\in Y$. Then $\deg(y)=\deg_{\g}(Y)-1$ and $\beta'(y)=\beta(Y)-1$, and thus $|\tau(y)|\le |\tau(Y)|+1$ by Observation~\ref{obs-tauprop}(b).  \item If $|Y|\ge 2$, then Lemma~\ref{lemma-cut} gives $\deg(y)=\deg_{\g}(Y)-1\ge 5+|\tau(Y)|\ge 4+|\tau(y)|$. \item Otherwise, $Y=\{u\}$.  If $\tau(u)$ contains a positive element $b$, then $\tau(y)=\{b-1\}$, $|\tau(y)|=|\tau(u)|-1$, and by the tameness of  $(\g,z,x,\psi)$ we have $\deg(y)=\deg(u)-1\ge (4+|\tau(u)|)-1\ge 4+|\tau(y)|$. \item Finally, if $Y=\{u\}$ and $\tau(u)=\{0\}$, then $\deg(u)$ is even, and Lemma~\ref{lemma-no4} gives $\deg(u)\ge 6$. Since $|\tau(y)|=1$, it follows that $\deg(y)=\deg(u)-1\ge 5=4+|\tau(y)|$.  Thus we conclude that $(\g'',z,x',\psi)$ is tame.    The easel $(\g'',z,x',\psi)$ is tall.     Let $X$ be the subset of $V(\g)$ contracted into $x'$.  If $|X|\ge 2$, then Lemma~\ref{lemma-sepx} implies $\deg(x') \ge \deg_{\g}(X) -1\ge \deg(x) + 2\ge \deg(z)$.  If $X=\{x\}$, then $\deg(x')=\deg(x)\ge \deg(z)-2$; and if $\deg(x)=\deg(z)-2$, the two oppositely directed edges witnessing that $(\g,z,x,\psi)$ is tall are not incident with $x'$ in $\g''$ and witness that $(\g'',z,x',\psi)$ is tall.   The above two claims imply $(\g'',z,x',\psi)$ is a critical tall tame easel, and further that $o(\g'',z)<o(\g,z)$. This contradicts the assumption that $(\g,z,x,\psi)$ is a minimal tall tame critical easel, completing the proof.",2502.01451
proof,"Lemma~\ref{lemma-norede} together with Observation~\ref{obs-allplusminus} imply that either $\tau(v)>0$ for every $v\in V(\g)\setminus\{x,z\}$, or $\tau(v)<0$ for every $v\in V(\g)\setminus\{x,z\}$.  By symmetry, we can assume the former.  First we claim that there are no edges between $x$ and $z$.   Suppose this is not true and let $e$ be be such an edge. Then deleting $e$ and adjusting the boundary at $x$ and $z$ accordingly (depending on which way $e$ is directed by $\psi$) would give a tall tame critical easel $(\g_0,z,x,\psi_0)$ such that $o(\g_0,z)=o(\g,z)$ and $\deg_{\g_0}(z)<\deg_{\g}(z)$. Since the canvas $(\g,z)$ is $x$-homogeneous, we would have $(\g_0,z,x)\prec (\g,z,x)$.  This is a contradiction, and thus $z$ and $x$ are non-adjacent.  Now we claim that $\psi$ orients all edges away from $z$. Suppose for a contradiction that $\psi$ orients an edge $e=uz$ towards $z$. Let $\g=(G,\beta)$ and let $\g'=(G-e,\beta')$, where $\beta'(y)=\beta(y)$ for $y\in V(G)\setminus\{u,z\}$, $\beta'(u)=\beta(u)-1$, and $\beta'(z)=\beta(z)+1$.  Note that $\beta'$ is a $\Z$-boundary for $G-e$: By Corollary~\ref{cor-2con}, $G-z$ is connected, and thus $G-e$ is disconnected only if $\deg(z)=1$.  But then the definition of a tip preflow ensures that $\beta(z)=-1$ and $\beta'(z)=0$, and thus also $\beta'(V(G-z))=0$.  Let $\psi'$ be obtained from $\psi$ by deleting the edge $e$. Note that $\psi'$ does not extend to a nowhere-zero flow in $\g'$, as otherwise adding $e$ oriented as in $\psi$ would give a nowhere-zero flow in $\g$ extending $\psi$. Conversely, $\psi'$ extends to a nowhere-zero flow in any proper tip-respecting contraction $(\g'/ \PP,z)$, since $\psi$ extends to a nowhere-zero flow in $(\g / \PP,z)$ which can be turned into a nowhere-zero flow in $(\g'/ \PP,z)$ by deleting $e$.  Therefore, $(\g',z,x,\psi')$ is a critical easel. Since $\deg_{\g'}(z)\le \deg_{\g}(z)-1\le \deg(x)+1$, this easel is tall.  As in the proof of Lemma~\ref{lemma-norede}, we can also show that this easel is tame. Note that $o(\g',z)=o(\g,z)$, the canvas $(\g,z)$ is $x$-homogeneous, and $\deg_{\g'}(z)<\deg_{\g}(z)$, and thus $(\g',z,x)\prec (\g,z,x)$.  This contradicts the assumption that $(\g,z,x,\psi)$ is a minimal tall tame critical easel.  Lastly, we need to show that $\deg(z) \leq \deg(x) +1$. This is the case by the definition of tallness, since $\psi$ directs all edges between $z$ and $V(\g)\setminus \{x,z\}$ in the same direction.",2502.01451
proof,"[Proof of Theorem~\ref{thm:tall}] Suppose for a contradiction that Theorem~\ref{thm:tall} is false, and thus there exists a minimal tall tame critical easel $(\g,z,x,\psi)$. By Lemma~\ref{lemma-sameor} and symmetry, we may assume that $xz\not\in E(\g)$, that $\tau(v)>0$ for every $v\in V(\g)\setminus\{x,z\}$, that $\psi$ directs all edges away from $z$, and that $\deg(z)\le \deg(x)+1$.  Since $\g$ is connected by Lemma~\ref{lemma-conn}, there exists at least one edge $e=vz$ incident with $z$. Let $\g=(G,\beta)$. Let $\g'=(G',\beta)$ where $G'$ is obtained from $G$ by adding an edge $e'$ parallel to $e$, and let $\psi'$ be the preflow around $z$ in $\g'$ obtained from $\psi$ by reversing $e$ and directing $e'$ towards $z$.  Note that $\psi'$ does not extend to a nowhere-zero flow in $\g'$, as otherwise the same orientation of the edges of $\g-z$ would together with $\psi$ give a nowhere-zero flow in $\g$. Moreover, note that $\psi'$ extends to a nowhere-zero flow in every proper tip-respecting contraction of $(\g',z)$, since $\psi$ extends to a nowhere-zero flow in the corresponding tip-respecting contraction of $(\g,z)$. Therefore, $(\g',z)$ is $\psi'$-critical, and $(\g',z,x,\psi')$ is a critical easel. We show below that $(\g',z,x,\psi')$ is tall and tame.   The easel $(\g',z,x,\psi')$ is tame.    The degree and boundary of all vertices that are not $v$ and $z$ are the same as in $\g$, and hence it suffices to show that $\deg_{\g'}(v) \geq 4 + |\tau_{\g'}(v)|$.  Since $\tau(v)>0$, we have $\beta(v)\neq 0$. Moreover, $\deg_{\g'} (v)=\deg_{\g}(v)+1$, and thus $|\tau_{\g'}(v)|\le |\tau_{\g}(v)|+1$ by Observation~\ref{obs-tauprop}(c).  Therefore, $\deg_{\g'}(v)=\deg_{\g}(v)+1\ge 5+|\tau_{\g}(v)|\ge 4+|\tau_{\g'}(v)|$.     The easel $(\g',z,x,\psi')$ is tall.    Since $\deg_{\g}(z)\le \deg(x)+1$, we have $\deg_{\g'}(z)\le \deg(x)+2$. Moreover, if $\deg_{\g'}(z)=\deg(x)+2$, then $\deg_{\g}(z) = \deg(x)+1\ge 2$ (we have $\deg(x)\ge 1$, since $\g$ is connected by Lemma~\ref{lemma-conn}), and thus $\g'$ contains both edges $e$ and $e'$ directed by $\psi'$ towards $z$ and an edge $e''\neq e$ of $\g$ directed by $\psi'$ away from $z$.     Note that $o(\g',z)=o(\g,z)$.  Since $\tau_{\g}(v)>0$ and the degree of $v$ in $\g'$ differs in parity, we have $\tau_{\g'}(v)<0$. By Lemmas~\ref{lemma-at4} and \ref{lemma-2con}, $v$ has a neighbour $u$ in $V(\g)\setminus \{x,z\}$, and $\tau_{\g'}(u)=\tau_{\g}(u)>0$. Therefore, the canvas $(\g',z)$ is not $x$-homogeneous.  It follows that $(\g',z,x)\prec (\g,z,x)$, contradicting the choice of $(\g,z,x,\psi)$ as a minimal tall tame critical easel. This completes the proof of Theorem \ref{thm:tall}.",2502.01451
proof,"The canvas $(\g_0,z_0)=(\g,z)\restriction A$ is flow-critical by Observation~\ref{obs-subcrit}, and clearly tame. Since $|V(\g_0)|\ge 3$ and $(\g_0,z_0)$ is flow-critical, there exists a tip preflow $\psi_0$ that does not extend to a nowhere-zero flow in $\g_0$. Since $\deg(z_0)=\deg(A)\le k$, $\psi_0$ is a $k$-tallness-witnessing preflow, and thus $(\g_0,z_0)\in \GG_k$. The second part of the observation follows immediately from the definition.",2502.01451
proof,"Since $\psi$ does not extend to a nowhere-zero flow in $\g$, there exists a $\psi$-critical tip-respecting contraction $(\g',z)$ of $(\g,z)$. Note that $(\g',z)$ is $k$-tall as witnessed by $\psi$ and tame by Corollary~\ref{cor-contrtame}, and thus $(\g',z)\in\GG_k$. By Theorem~\ref{thm-deg}, every vertex other than $z$ has degree at most $\deg(z)-2\le k-1$ in $\g'$.   By Observation~\ref{obs-inGk}, the canvas $(\g,z)$ is a $\GG_k$-expansion of $(\g',z)$.  Since $(\g,z)$ is not obtained according to Theorem~\ref{thm-gen} (EXPA), it follows that $(\g',z)\not\prec (\g,z)$, and thus $(\g',z)=(\g,z)$.  Therefore, $(\g,z)$ is $\psi$-critical.",2502.01451
proof,"Note that $\deg_{\g'}(B)\ge 4+|\tau(B)|$ for every non-empty $B\subsetneq V(\g')\setminus\{z\}$ by the tameness of $(\g,z)$ and Lemma~\ref{lemma-cut}. Let $x$ be the vertex of $(\g',z)$ to which $A$ is contracted; then $\deg(X')\ge \deg(z)-1$ for every $X'\subseteq V(\g')\setminus\{z\}$ containing $x$ by the assumptions.  Theorem~\ref{cor-tall} implies that every tip preflow extends to a nowhere-zero flow in $(\g',z)$.",2502.01451
proof,"We prove Lemma~\ref{lemma-extori} by induction on the number of vertices of $\g$.   Suppose for a contradiction that there exists a set $A\subseteq V(\g)\setminus \{z\}$ such that $\deg(A)=k+1$, $x\in A$, and $\psi$ extends to a nowhere-zero flow in $\g/A$, but no such flow is $(k, x,\psi,A)$-valid. Let us choose such a set $A$ of maximal size.  Note that $A\neq V(\g)\setminus \{z\}$: Otherwise, $\deg(z)=k+1$ and $\psi$ does not orient all edges between $z$ and $A$ in the same direction since it is $k$-tallness-witnessing, and consequently $\psi$ would give a $(k, x,\psi,A)$-valid nowhere-zero flow in $\g/A$.  First, let us show that all edge cuts separating $A$ from $z$ are large.   We have that $\deg(A')\ge k+2$ for every $A'\subsetneq V(\g)\setminus \{z\}$ such that $A\subsetneq A'$.   Suppose that there exists $A'\subsetneq V(\g)\setminus \{z\}$ such that $A\subsetneq A'$ and $\deg(A') \le k+1$, and let us choose such a set $A'$ of minimum size. Since $\psi$ extends to a nowhere-zero flow in $\g/A$, it also extends to a nowhere-zero flow $\vec{G}_0$ in $\g/A'$. Let $a'$ be the vertex resulting from the contraction of $A'$. If $\deg(A')=k+1$, then by the maximality of $A$, we can assume that $\vec{G}_0$ is $(k,x,\psi,A')$-valid; and in particular, $\vec{G}_0$ does not orient all edges between $V(\g)\setminus A'$ and $A'\setminus \{x\}$ in the same direction, unless $\deg(z)=k+1$ and $\psi$ orients all edges between $z$ and $V(\g)\setminus\{z,x\}$ in the same direction.  Let $(\g',b)=(\g,z)\restriction A'$ and let $\psi'$ be the tip preflow in which the edges incident with $b$ are directed the way $\vec{G}_0$ orients the corresponding edges incident with $a'$.  Since $\psi$ does not extend to a nowhere-zero flow in $\g$, we see that $\psi'$ does not extend to a nowhere-zero flow in $\g'$. Moreover, $\deg(b)\le k+1$, and if $\deg(b)=k+1$, then $\psi'$ does not orient all edges incident with $b$ in the same way. Therefore, $\psi'$ is a $k$-tallness-witnessing preflow in $(\g',b)$, and $(\g',b)\in\GG_k$.  Since $A'$ is a minimal superset of $A$ with $\deg(A')\le k+1$, and since $\deg(A)=k+1$, every set $X$ such that $A\subseteq X\subsetneq A'=V(\g')\setminus\{b\}$ satisfies $\deg(X)\ge k+1\ge \deg(A')=\deg(b)$. By Lemma~\ref{lemma-Gk-contr}, $\psi'$ extends to a nowhere-zero flow $\vec{G}_1$ in $(\g'/A,b)$. Note that $|V(\g')|<|V(\g)|$, and thus by the induction hypothesis, we can assume that $\vec{G}_1$ is $(k,x,\psi',A)$-valid.  The combination of $\vec{G}_0$ and $\vec{G}_1$ gives a $(k,x,\psi,A)$-valid nowhere-zero flow in $(\g /A,z)$: Note that $\vec{G}_1$ can only orient all edges between $V(\g')\setminus A$ and $A\setminus \{x\}$ in the same direction if $\deg(b)=\deg(A')=k+1$ and $\psi'$ orients all edges between $b$ and $V(\g')\setminus \{b,x\}=A'\setminus\{x\}$ in the same direction, which by the choice of $\vec{G}_0$ can only happen when $\deg(z)=k+1$ and $\psi$ orients all edges between $z$ and $V(\g)\setminus\{z,x\}$ in the same direction. This contradicts the existence~of~$A$.   Since $\deg(A)=k+1$ and $\deg(z)\le k+1$, Theorem~\ref{thm-deg} implies $|A|\ge 2$.  Moreover, since $A\neq V(\g-z)$, we have $C=V(\g)\setminus(A\cup\{z\})\neq\emptyset$ and $|V(\g)|\ge 4$.  Therefore, Lemma~\ref{lemma-2con} implies that $\g-\{z,x\}$ is connected, and thus there exists an edge $e_1$ with one end $u_1\in C$ and the other end in $A\setminus \{x\}$.  \item If $\deg(z)=k+1$ and $\psi$ directs all edges between $z$ and $C$ in one direction (there exists at least one such edge, since $\deg(A)=k+1=\deg(z)$ and $e_1$ is not incident with $z$), then since $\psi$ is a $k$-tallness-witnessing preflow, there exists an edge between $z$ and $A$ directed in the opposite direction; let $e_2$ be such an edge, not incident with $x$ if possible, and let $u_2=z$. \item Otherwise, since $\deg(x)\le \deg(z)-2\le k-1$ by Theorem~\ref{thm-deg} and $\deg(A)=k+1$, there exists an edge $e_2\neq e_1$ between $u_2\in C \cup \{z\}$ and $A\setminus\{x\}$.  If possible, choose $e_2$ so that $u_2\neq u_1$.    Let $\g_1$ be obtained from $\g/A$ by splitting off $e_1$ with $e_2$, and if $u_1\neq u_2$, then let $e$ be the resulting edge.  Note that $\psi$ can be naturally interpreted as a tip preflow $\psi_1$ in $(\g_1,z)$.  If $\psi_1$ extended to a nowhere-zero flow in $\g_1$, then, directing $e_1$ and $e_2$ according to $e$ (or arbitrarily in the opposite directions if $u_1=u_2$) would give a $(k, x,\psi,A)$-valid nowhere-zero flow in $\g/A$ (note that $e_2$ can be chosen to be incident with $x$ only if $\deg(z)=k+1$ and $\psi$ directs all edges not incident with $x$ in the same direction); this would contradict the choice of $A$.  Therefore, $\psi_1$ does not extend to a nowhere-zero flow in $\g_1$, and thus there exists a $\psi_1$-critical tip-respecting contraction $(\g'_1,z)$ of $(\g_1,z)$. Let $a'$ be the vertex of $\g'_1$ into which we contracted $A$, and let $A'\supseteq A$ be the set of vertices of $\g$ contracted into $a'$.  In the case that $u_1=u_2$, consider the set $U$ of vertices of $\g_1$ containing $u_1$ and contracted to a vertex $u$ of $\g'_1$, and suppose that $u\neq a'$.  If $|U|\ge 2$, then $\deg(u)\ge \deg(U)-2\ge 4+|\tau(U)|=4+|\tau(u)|$ by Corollary~\ref{cor-contrtame}. If $U=\{u_1\}$, then by Lemma~\ref{lemma-simple}, there is at most one edge between $u_1$ and $a'$ in $\g'_1$, and thus there are at most three edges between $u_1$ and $A$ in $\g$.  We only chose $e_2$ incident with $u_1$ because every edge with exactly one end in $A$ is incident with $u_1$ or $x$, and since $\deg(A)=k+1$, at least $k-2$ of these edges are incident with $x$.  By Theorem~\ref{thm:tall}, we have $\deg(x)\le \deg(z)-2\le k-1$, and thus there is at most one edge between $x$ and $A\setminus\{x\}$.  Consequently, $\deg(A\setminus \{x\})\le 4$, and Corollary~\ref{cor-mainlov} implies that $|A\setminus\{x\}|=1$.  However, since $e_1$ and $e_2$ both end in $A\setminus \{x\}$, this contradicts Lemma~\ref{lemma-simple} for $(\g,z)$. Therefore, if $u\neq a'$, then $\deg(u)\ge 4+|\tau(U)|=4+|\tau(u)|$.  Using Corollary~\ref{cor-contrtame}, it is now easy to see that $\deg_{\g'_1}(v)\ge 4+|\tau(v)|$ holds for every vertex $v\in V(\g'_1)\setminus\{z,a'\}$. Hence $(\g',z,a',\psi_{1})$ is a critical tame easel. We now argue that $(\g',z,a',\psi_{1})$ is tall.  We consider two cases:  \item If $A'\neq A$, then $\deg_{\g}(A')\ge k+2$ by the above claim, and thus $\deg_{\g'_1}(a') \ge k\ge \deg(z)-1$, and the easel $(\g'_1,z,a',\psi_1)$ is tall. \item If $A' = A$, then $\deg_{\g'_{1}}(a') = \deg_{\g}(A) -2 = k-1$.  If $\deg(z) \leq k$, this again implies that the easel $(\g'_{1},z,a',\psi_{1})$ is tall. Therefore, we can assume have $\deg(z)=k+1$. Since $\deg(A) = \deg(z)$ and $e_{1}$ is an edge between $A$ and $C$, there exists at least one edge $e_{0}$ of $\g$ between $z$ and $C$.  \item If $\psi$ does not direct all edges between $z$ and $C$ in the same way, then $\psi_{1}$ also does not direct the corresponding edges between $z$ and $V(\g'_{1}) \setminus \{a',z\}$ in the same way.  Therefore, the easel $(\g'_1,z,a',\psi_1)$ is tall.  \item If $\psi$ directs all edges between $z$ and $C$ in the same way, then since $\deg(z)=k+1$ and $\psi$ is $k$-tallness-witnessing, $\psi$ directs an edge between $z$ and $A$ in the opposite way, and such an edge was chosen as $e_2$. But then $e$ is an edge of $\g'_1$ between $z$ and $V(\g'_1)\setminus\{a',z\}$ directed opposite to $e_0$. Hence, we again conclude that the easel $(\g'_1,z,a',\psi_1)$ is tall.   However, this contradicts Theorem~\ref{thm:tall}.",2502.01451
proof,"By Observation~\ref{obs-inGk}, we can assume that $\deg(A)=k+1$. The canvas $(\g_1,b)=(\g,z)\restriction A$ is flow-critical by Observation~\ref{obs-subcrit} and it is clearly tame. Hence, it suffices to show that it is $k$-tall.  Since $(\g,z)$ is $\psi$-critical, $\psi$ extends to a nowhere-zero $\vec{G}_1$ flow in $(\g/A,z)$.  Let $a$ be the vertex arising from the contraction of $A$. By Lemma~\ref{lemma-extori} (with $x$ being any vertex of $A$), we can assume that $\vec{G}_1$ does not direct all edges incident with $a$ in the same way. The restriction of $\vec{G}_1$ to the edges incident with $a$ can be interpreted as preflow $\psi_1$ around $b$ in $\g_1$. Since $\psi$ does not extend to a nowhere-zero flow in $\g$, $\psi_1$ does not extend to a nowhere-zero flow in $\g_1$, and thus $\psi_1$ is $k$-tallness-witnessing in $(\g_1,b)$.  Therefore, $(\g_1,b)$ is indeed $k$-tall.",2502.01451
proof,"Suppose for a contradiction that $\g$ has a vertex $v$ of degree at most four.  Note that $v\neq z$ by Corollary~\ref{cor-mainlov}, and by the tameness of $(\g,z)$ we have further that $\deg(v)=4$ and $v$ has zero boundary. By Lemma~\ref{lemma-gen-psi}, the canvas $(\g, z)$ is $\psi$-critical.  Let $C=V(\g)\setminus\{v,z\}$; since $|V(\g)|\ge 4$, we have $|C|\ge 2$. Lemma~\ref{lemma-2con} implies that there exist two edges $e_1$ and $e_3$ between $v$ and vertices in $C$.  Label the remaining two edges incident with $v$ by $e_2$ and $e_4$ arbitrarily.  For $i\in\{1,\ldots,4\}$, let $v_i$ be the end of $e_i$ different from $v$, and let $N=\{v_1,\ldots, v_4\}$. By Lemma \ref{lemma-simple}, $v_1$ and $v_3$ are distinct.    %  %  %  % \node[dummywhite] at (-.75,0) (dummywhite1) [label = left:$(i)$]  {}; % \node[blackvertexv2] at (0,0) (v) [label= above:$v$] {}; % \node[blackvertexv2] at (1,-2) (z) [label = below:$z$] {}; % \node[blackvertexv2] at (-1,-2) (v1) {}; % \draw[thick,black, bend left = 45,postaction={decoration={markings,mark=at position 0.5 with {\arrow{<}}},decorate}] (z) to node[left]{$e_{2}$}(v); % \draw[thick,black, bend right = 45,postaction={decoration={markings,mark=at position 0.5 with {\arrow{<}}},decorate}] (z) to node[left]{$e_{4}$}(v); % \draw[thick,black,postaction={decoration={markings,mark=at position 0.5 with {\arrow{>}}},decorate}] (z) to node[left]{$e_{3}$}(v); % \draw[thick,black] (v) to node[left]{$e_{1}$}(v1); % [xshift = 4cm] % \node[blackvertexv2] at (0,0) (v) [label= above:$v$] {}; % \node[blackvertexv2] at (1,-2) (z) {}; % \node[blackvertexv2] at (-1,-2) (v1) [label = below:$v_{1}$] {}; % \node[blackvertexv2] at (0,-2) (v2) {}; % \node[blackvertexv2] at (2,-2) (v3) {}; % \node[dummywhite] at (-.75,0) (dummywhite1) [label = left:$(ii)$]  {}; % \draw[thick,black] (v) -- node[left,yshift =-.1]{$e_{1}$}(v1); % \draw[thick,black] (v) to node[left,yshift =-.1]{$e_{3}$}(z); % \draw[thick,black] (v) to node[left,yshift=-.1]{$e_{4}$}(v3); % \draw[thick,black] (v) to node[left,yshift =-.1]{$e_{2}$} (v2); %  %  % \caption{The two cases in Lemma \ref{lemma-gen-no4}.} %  %  %    Let $\g_1$ be the $\Z$-bordered graph obtained from $\g$ by splitting off $e_1$ with $e_2$ (giving an edge $e'_1$) and $e_3$ with $e_4$ (giving an edge $e'_3$) and deleting the now isolated vertex $v$. The preflow $\psi$ naturally corresponds to a tip preflow $\psi_1$ in $(\g_1,z)$, and $\psi_1$ does not extend to a nowhere-zero flow in $\g_1$. Hence, $(\g_1,z)$ has a tip-respecting $\psi_1$-critical contraction $(\g',z)$. Let $\PP'$ be the tip-respecting partition of $V(\g_1)$ such that $\g'=\g_1/\PP'$.  The canvas $(\g',z)$ is tame, $\psi_{1}$ is a $k$-tall-witnessing preflow and $(\g',z) \prec (\g,z)$.     We first argue that $(\g',z)$ is tame. Consider any $A'\in \PP'$ other than $\{z\}$, and let $a$ be the corresponding vertex of $\g'$. Let $A=A'\cup\{v\}$ if $|A'\cap N|\ge 3$ and $A=A'$ otherwise. If $|A|\ge 2$, then Corollary~\ref{cor-contrtame} implies $\deg(a)\ge \deg_{\g}(A)-2\ge 4+|\tau(A)|=4+|\tau(a)|$. If $|A|=1$, then by Lemma~\ref{lemma-simple} at most one of the edges $e_1$, \ldots, $e_4$ has an end in $A=A'$, and $\deg(a)=\deg_{\g}(A)\ge 4+|\tau(A)|=4+|\tau(a)|$ since $(\g,z)$ is tame.  Therefore, the canvas $(\g',z)$ is tame.  Now observe that if $\deg_{\g'}(z)=k+1$, then $\deg_{\g}(z)=k+1$ and $\psi$ directs two edges incident with $z$ in opposite ways, and thus so does $\psi_1$.  Therefore, $\psi_1$ is a $k$-tallness-witnessing preflow for $(\g', z)$, and $(\g',z)\in \GG_k$. Lastly, we also have $o(\g',z)<o(\g,z)$, and thus $(\g',z)\prec (\g,z)$.   For $i\in \{1,2\}$, define $x_i:=e'_{2i-1}$ if this edge is present in $\g'$, and otherwise, let $x_i$ be the vertex into which the part $X_i\in\PP'$ containing $v_{2i-1}$ and $v_{2i}$ was contracted.  \item If $x_1\neq x_2$, then let $(\g_0,z)$ be the $2$-alteration of $(\g',z)$ on $x_1$ and $x_2$, with the newly added vertex labelled $v$, and let $\PP=\PP'\cup\{\{v\}\}$. \item If $x_1=x_2$, then note that $x_1$ is a vertex other than $z$; let $(\g_0,z)=(\g',z)$ and let $\PP=(\PP'\setminus\{X_1\})\cup\{X_1\cup \{v\}\}$.  Observe that in either case, we have $(\g_0,z)=(\g / \PP,z)$. To finish, it suffices to show that $(\g,z)$ is a $\GG_{k}$-expansion of $(\g_{0},z)$.  Consider any part $P\in\PP$ of size at least two, and let $p$ be the corresponding vertex of $\g_0$. Since $(\g',z)\in \GG_k$, Theorem~\ref{thm-deg} implies $\deg_{\g'}(p)\le k-1$, and thus $\deg(P)\le \deg_{\g'}(p)+2\le k+1$. By Lemma~\ref{lemma-gen-sepx}, we have $(\g,z)\restriction P\in \GG_k$.   Therefore, $(\g,z)$ is $\GG_k$-expansion of $(\g_0,z)$, and thus $(\g,z)$ is obtained as in Theorem~\ref{thm-gen} (EXPA), contradicting our choice.",2502.01451
proof,"Let $\g=(G,\beta)$.  Recall that the canvas $(\g,z)$ is $\psi$-critical by Lemma~\ref{lemma-gen-psi}. Suppose for a contradiction that $e=uv\in E(\g-z)$ is a mixed edge, say with $v$ in-friendly and $u$ out-friendly.  Let $\g_1=(G-e,\beta')$, where $\beta'(y)=\beta(y)$ for $y\in V(G)\setminus\{u,v\}$, $\beta'(u)=\beta(u)-1$, and $\beta'(v)=\beta(v)+1$. Lemmas~\ref{lemma-conn} and \ref{lemma-2con} imply that $G-e$ is connected, and thus $\beta'$ is a $\Z$-boundary for $G-e$. If $\g_1$ had a nowhere-zero flow extending $\psi$, it would give a nowhere-zero flow in $\g$ extending $\psi$ by directing the edge $e$ towards $v$.  Hence, $\psi$ does not extend to a nowhere-zero flow in $\g_1$, and thus $(\g_1,z)$ has a tip-respecting $\psi$-critical contraction $(\g',z)$. Let $\g'=\g_1/\PP$.  Note that $o(\g',z)<o(\g,z)$, and thus $(\g',z)\prec (\g,z)$.  As in the proof of Lemma~\ref{lemma-norede}, observe that the assumptions on in-friendliness and out-friendliness of $u$ and $v$ together with Lemma~\ref{lemma-gen-no4} imply that $(\g_1,z)$ is tame, and together with Corollary~\ref{cor-contrtame}, it follows that $(\g',z)$ is tame.  Moreover, $(\g',z)$ is $k$-tall, since $\psi$ is a $k$-tallness-witnessing preflow around $z$ in $\g'$. Hence $(\g',z)\in\GG_k$.  If $u$ and $v$ are contained in the same part of $\PP$, then let $(\g_0,z)=(\g',z)$.  Otherwise, let $u'$ and $v'$ be the vertices of $\g'$ into which $u$ and $v$ were contracted, and let $(\g_0,z)$ be the $1$-alteration of $(\g',z)$ obtained by adding the edge $u'v'$, increasing the boundary at $u'$ by one, and decreasing it at $v'$ by one.  Note that in either case, $(\g_0,z)=(\g / \PP,z)$.  For every vertex $y\in V(\g_0)\setminus\{z\}$, if $A$ is the set of vertices of $\g$ contracted into $y$ and $|A|\ge 2$, then $\deg(A)\le \deg_{\g'}(y)+1\le \deg(z)-1\le k$ by Theorem~\ref{thm-deg}, and thus $(\g,z)\restriction A$ belongs to $\GG_k$ by Observation~\ref{obs-inGk}. Therefore, $(\g,z)$ is a $\GG_k$-expansion of $(\g_0,z)$ and it is obtained as in Theorem~\ref{thm-gen} (EXPA) or (EXPB), contradicting our choice.",2502.01451
proof,"Let $\g=(G,\beta)$.  Recall that the canvas $(\g,z)$ is $\psi$-critical by Lemma~\ref{lemma-gen-psi}. By Lemma~\ref{lemma-gen-norede2}, we can by symmetry assume that $\tau(v)>0$ for every $v\in V(\g)\setminus\{z\}$. Suppose for a contradiction that $\psi$ directs an edge $e=uz$ of $\g$ towards $z$. Let $\g'=(G-e,\beta')$, where $\beta'(y)=\beta(y)$ for $y\in V(G)\setminus\{z,v\}$, $\beta'(z)=\beta(z)+1$, and $\beta'(u)=\beta(u)-1$. Let $\psi'$ be obtained from $\psi$ by removing the edge $e$. As in the proof of Lemma~\ref{lemma-sameor}, we argue that $(\g',z)$ is a $\psi'$-critical tame canvas, and since $\deg_{\g'}(z)\le \deg_{\g}(z)-1\le k$, we have $(\g',z)\in \GG_k$. Note that $(\g,z)$ is a tip-alteration of $(\g',z)$. Since $o(\g',z)=o(\g,z)$, the canvas $(\g,z)$ is $z$-homogeneous, and $\deg_{\g'}(z)<\deg_{\g}(z)$, we have $(\g',z)\prec (\g,z)$.  Therefore, $(\g,z)$ is obtained as in Theorem~\ref{thm-gen} (ADD), which is a contradiction.",2502.01451
proof,"[Proof of Theorem~\ref{thm-gen}] Suppose for a contradiction that there exists a minimal $k$-counterexample $(\g,z,\psi)$ for a positive integer $k$. By Lemma~\ref{lemma-gen-norede1} and symmetry, we can assume that $\tau(v)>0$ for every $v\in V(\g)\setminus\{z\}$ and $\psi$ directs all edges away from $z$. Since $\psi$ is $k$-tallness-witnessing, it follows that $\deg(z)\le k$.  By Corollary~\ref{cor-mainlov}, we have $\deg(z)\ge 6$.  Consider any edge $e=zv$ incident with $z$ and let $e_0\neq e$ be another edge between $z$ and $V(\g)\setminus \{z\}$. Let $\g'$ be the $\Z$-boundaried graph obtained from $\g$ by adding an edge $e'$ parallel to $e$ and let $\psi'$ be the preflow around $z$ in $\g_1$ obtained from $\psi$ by directing $e$ and $e'$ towards $z$.  As in the proof of Theorem~\ref{thm:tall}, we argue that $(\g',z)$ is $\psi'$-critical and tame. Since $\deg_{\g'}(z)=\deg_{\g}(z)+1\le k+1$ and $\psi'$ directs $e$ and $e_0$ in the opposite ways, we have $(\g',z)\in\GG_k$. Note that $(\g,z)$ is a tip-reduction of $(\g',z)$.  By Lemma~\ref{lemma-2con}, $v$ has a neighbour $u \neq z$.  Since we changed the parity of the degree of $v$, we have $\tau_{\g'}(v)<0$, while $\tau_{\g'}(u)=\tau_{\g}(u)>0$. Hence, $(\g',z)$ is not $z$-homogeneous.  Since $o(\g',z)=o(\g,z)$ and $(\g,z)$ is $z$-homogeneous, it follows that $(\g',z)\prec (\g,z)$. Therefore, $(\g,z)$ is obtained as in Theorem~\ref{thm-gen} (REM), which is a contradiction.",2502.01451
proof,"Since $\psi$ does not extend to a nowhere-zero flow in $\g$, there exists a $\psi$-critical tip-respecting contraction $(\g',z)$ of $(\g,z)$. Note that $(\g',z)$ is tame by Corollary~\ref{cor-contrtame}, and $\psi$ is a $k$-tallness-witnessing preflow in $(\g',z)$. By Theorem~\ref{thm-deg}, every vertex other than $z$ has degree at most $\deg(z)-2\le k-1$ in $\g'$.   Let $x'$ be the vertex of $\g'$ to which we contracted the set $X\subseteq V(\g)\setminus\{z\}$ containing $x$.  If $|X|>1$, let $(\g_1,b)=(\g,z)\restriction X$ and $\psi'$ be any tip preflow that does not extend to a nowhere-zero flow in $\g_1$. Since $\deg(b)\le k-1$, the easel $(\g_1,b,x,\psi')$ belongs to $\GG_{k,r}$. By Observation~\ref{obs-inGk}, the canvas $(\g,z)$ is a $(\GG_k,x\to x',\GG_{k,r},\emptyset)$-expansion of $(\g',z)$.    Let us now argue that $(x',\psi)$ is a witness of $(k,r)$-tallness of $(\g',z)$.  To this end, if $|X|\ge 2$, then Theorem~\ref{thm-deg} applied to $(\g,z)\restriction X$ implies that $\deg(x')=\deg(X)\ge \deg(x)+2>k-2-r$. If $X=\{x\}$, then $\deg(x')=\deg(x)\ge k-2-r$ and the edges between $z$ and $x'$ in $\g'$ are exactly the same as those between $z$ and $x$ in $\g$. In either case, we conclude that $(x',\psi)$ is a witness of $(k,r)$-tallness of $(\g',z)$, and $(\g,z,x',\psi)\in \GG_{k,r}$.  Since $(\g,z,x,\psi)$ does not satisfy Theorem~\ref{thm-genladeg}(EXP), it follows that $(\g',z,x')\not\prec (\g,z,x)$, and thus $(\g',z)=(\g,z)$. Therefore, the canvas $(\g,z)$ is $\psi$-critical.",2502.01451
proof,"The claim follows from Observation~\ref{obs-inGk} when $\deg(A)\le k$, and thus suppose that $\deg(A)=k+1$. We have $(\g_1,b)\in \GG_k$ by Lemma~\ref{lemma-gen-sepx}.  Since $(\g,z)$ is $\psi$-critical, the tip preflow $\psi$ extends to a nowhere-zero flow $\vec{G}_1$ in $(\g/A,z)$.  Let $a$ be the vertex arising from the contraction of $A$. By Lemma~\ref{lemma-extori}, we can assume that $\vec{G}_1$ is $(k,x,\psi,A)$-valid (recall Definition \ref{def:validflow}).  Note that since $(\g,z,x,\psi)\in \GG_{k,r}$, if $\deg(z)=k+1$ and $\deg(x)=k-2-r$, then $\psi$ does not direct all edges between $z$ and $V(\g-\{z,x\})$ the same way, and thus $\vec{G}_1$ directs two edges not incident with $x$ in opposite directions. The restriction of $\vec{G}_1$ to the edges incident with $a$ can be interpreted as preflow $\psi_1$ around $b$ in $\g_1$. Since $\psi$ does not extend to a nowhere-zero flow in $\g$, $\psi_1$ does not extend to a nowhere-zero flow in $\g_1$, and thus $(x,\psi_1)$ is a witness of $(k,r)$-tallness of $(\g_1,b)$.  Therefore, $(\g_1,b,x,\psi_1)\in \GG_{k,r}$.",2502.01451
proof,"Suppose for a contradiction that there exists such a set $X$ with $\deg(X)\le \deg(x)+2$, and let us choose one of maximal size. Theorem~\ref{thm-deg} applied to $(\g,z)\restriction X$ implies that $\deg(X)=\deg(x)+2$.  Let $C=V(\g)\setminus (X\cup\{z\})$. By Lemma~\ref{lemma-2con}, there exists an edge $e_1$ between $C$ and $X\setminus\{x\}$; let $v_1$ be the end of $e_1$ in $C$. We have $\deg(z)=k+1>(k-2-r)+2=\deg(x)+2=\deg(X)$, and thus there exists at least one edge between $z$ and $C$. We now describe how to pick an edge $e_{2} \neq e_{1}$.  \item If $\psi$ directs all edges between $z$ and $C$ in the same way, then since $(x,\psi)$ is a witness of $(k,r)$-tallness, $\deg(x)=k-2-r$, and $\deg(z)=k+1$, we can choose $e_2$ as an edge between $z$ and $X\setminus\{x\}$ directed by $\psi$ in the opposite way. \item  Otherwise, if there exists an edge between $\{z\}\cup C\setminus \{v_1\}$ and $X\setminus\{x\}$, choose $e_2$ as such an edge arbitrarily. \item If no such edge exists, choose $e_2$ as an arbitrary edge between $v_1$ and $X\setminus\{x\}$ different from $e_1$  (which exists, since $\deg(X)=\deg(x)+2$).   Let $v_2$ be the end of $e_2$ in $\{z\}\cup C$. Let $(\g'_1,z)$ be obtained from $(\g/X,z)$ by splitting off $e_1$ with $e_2$, and if $v_1\neq v_2$, then denote by $e$ the resulting edge. Let $x'_1$ be the vertex of $\g'_1$ into which we contracted $X$. Let $\psi'$ be the tip preflow in $(\g'_1,z)$ obtained from $\psi$ by, in case that $e_2$ is incident with $z$, directing $e$ in the same way as $\psi$ directs $e_2$.   The preflow $\psi'$ does not extend to a nowhere-zero flow in $(\g'_1,z)$.    Suppose towards a contradiction that $\psi'$ extends to a nowhere-zero flow $\vec{G}_1$ in $(\g'_1,z)$.  Let $(\g'_2,b)=(\g,z)\restriction X$ and let $\psi_2$ be the tip preflow obtained from the restriction of $\vec{G}_1$ to the edges with exactly one end in $X$ by directing $e_1$ and $e_2$ according to the orientation of $e$ in $\vec{G}_1$ (or arbitrarily in opposite directions in case that $v_1=v_2$).  Since $\psi$ does not extend to a nowhere-zero flow in $(\g,z)$, we see that $\psi_2$ does not extend to a nowhere-zero flow in $(\g'_2,b)$.  Let $(\g_2,b)$ be a $\psi_2$-critical tip-respecting contraction of $(\g'_2,b)$, and let $a$ be the vertex into which we contracted the set $A$ of vertices of $\g_2$ containing $x$.  If $|A|\ge 2$, then Theorem~\ref{thm-deg} for $(\g,z)\restriction A$ implies that $\deg(a)=\deg(A)\ge \deg(x)+2=\deg(X)=\deg(b)$, but that contradicts Theorem~\ref{thm-deg} for $(\g_2,b)$. Therefore, we have $A=\{x\}$ and $\deg(a)=\deg(x)=\deg(X)-2=\deg(b)-2$.  Since neither $e_1$ nor $e_2$ is incident with $x$, the preflow $\psi_2$ directs two edges not incident with $a$ in opposite ways.  We conclude that $(\g_2,b,a,\psi_2)$ is a tall tame critical easel, contradicting Theorem~\ref{thm:tall}.  Since $\psi'$ does not extend to a nowhere-zero flow in $(\g'_1,z)$, there exists a $\psi'$-critical tip-respecting contraction $(\g',z)$ of $(\g'_1,z)$, where $\g'=\g'_1/\PP'$. Let $X'_1$ be the part of $\PP'$ containing $x'_1$, let $X'=(X'_1\setminus \{x'_1\})\cup X$, and let $\PP$ be obtained from $\PP'$ by replacing $X'_1$ by $X'$. Let $x'$ be the vertex of $\g'$ into which we contracted $X'_1$.  Note that the choice of $e_2$ implies that $\psi'$ does not direct all edges around $z$ in the same way, and thus $\psi'$ is a $k$-tallness-witnessing preflow in $(\g',z)$.  \item If $X'\neq X$, then by the maximality of $X$ we have $\deg(x')\ge \deg_{\g}(X')-2>\deg_{\g}(x)=k-2-r$, and thus $(x',\psi')$ is a witness of $(k,r)$-tallness of $(\g',z)$. \item If $X'=X$, then the choice of $e_2$ implies that $\psi'$ does not direct all edges between $z$ and $C$ in $\g'_1$ in the same way, and thus it also does not direct all edges between $z$ and $V(\g')\setminus \{x',z\}$ in $\g'$ in the same way.  Moreover, we have $\deg(x')=\deg_{\g}(X)-2=\deg(x)=k-2-r$. Hence, we again conclude that $(x',\psi')$ is a witness of $(k,r)$-tallness of $(\g',z)$.  Moreover, we claim that the canvas $(\g',z)$ is tame, and thus $(\g',z,x',\psi')\in \GG_{k,r}$.  To see that, we need the following observation.   If $v_1$ and $v_2$ are contained in the same part $P\in \PP$, then $|P|\ge 2$.     Suppose for a contradiction that $|P|=1$, and thus $v_1=v_2$ and $P\neq X'$. By the choice of $e_2$, this implies that every edge between $\{z\}\cup C$ and $X$ is incident with $v_1$ or $x$. Let $m$ be the number of edges between $v_1$ and $X\setminus \{x\}$. Since only $e_1$ and $e_2$ are split off, $\g'$ contains at least $m-2$ edges between the vertex corresponding to $P$ and $x'$, and by Lemma~\ref{lemma-simple} applied to $\g'$, we have $m\le 3$.  Since $\deg(X)=\deg(x)+2$ and there are $\deg(X)-m$ edges between $\{z\}\cup C$ and $X$ that are incident with $x$, there are $\deg(x)-(\deg(X)-m)=m-2$ edges between $x$ and $X\setminus\{x\}$.   We conclude that $\deg_{\g}(X)\setminus\{x\} = 2m-2\le 4$.  By Observation~\ref{obs-subcrit} applied to $(\g,z)\restriction (X\setminus\{x\})$, Corollary~\ref{cor-mainlov}, and the tameness of $(\g,z)$, we conclude that $m=3$ and $|X\setminus \{x\}|=1$. However, that implies that $\g$ contains a triple edge between $v_1$ and the vertex of $X\setminus\{x\}$, contradicting Lemma~\ref{lemma-simple}.   From this claim and Corollary~\ref{cor-contrtame}, it is easy to see that the canvas $(\g',z)$ is tame, and thus $(\g',z,x',\psi')\in \GG_{k,r}$.  Clearly $o(\g',z)<o(\g,z)$, implying that $(\g',z,x')\prec (\g,z,x)$.  If $\{v_1,v_2\}\cap X'\neq\emptyset$, then $(\g',z)$ is isomorphic to $(\g / \PP,z)$. By Theorem~\ref{thm-deg}, every vertex of $(\g',z)$ other than $z$ has degree at most $\deg(z)-2\le k-1$, and thus by Observation~\ref{obs-inGk}, $(\g,z)$ is a $(\GG_k,x\to x',\GG_{k,r},\emptyset)$-expansion of $(\g',z)$. Hence, $(\g,z,x,\psi)$ satisfies Theorem~\ref{thm-genladeg}(EXP), which is a contradiction.  It follows that $\{v_1,v_2\}\cap X'=\emptyset$.  If $v_1$ and $v_2$ are in the same part $P\in \PP$, then let $y$ be the vertex of $\g'$ corresponding to this part; otherwise, $e$ is an edge of $\g'$ and we let $y=e$. Let $(\g_0,z)$ be the $x'$-alteration of $(\g',z)$ on $y$, and observe that $(\g_0,z)=(\g / \PP,z)$. By Theorem~\ref{thm-deg} applied to $(\g',z)$, every part $A\neq\{z\}$ of $\PP$ other than $X'$ and $P$ (in case that $y$ is a vertex) satisfies $\deg_{\g}(A)\le k-1$, and $\deg_{\g}(X'),\deg_{\g}(P)\le k+1$.  Moreover, $|X'|\ge |X|\ge 2$, and by the claim above, if $y$ is a vertex, then $|P|\ge 2$. Since $(\g,z)$ is $\psi$-critical by Lemma~\ref{lemma-genladeg-psi}, Lemma~\ref{lemma-gen-sepx} implies that $(\g,z)\restriction P'\in \GG_k$ for every $P'\in \PP\setminus \{z\}$.  Together with Lemma~\ref{lemma-genladeg-sepx} applied to $X'$, this implies that $(\g,z)$ is a $(\GG_k,x\to x',\GG_{k,r},\{x',y\})$-expansion of $(\g_0,z)$. We conclude that $(\g,z,x,\psi)$ satisfies Theorem~\ref{thm-genladeg}(EXPX), which is a contradiction.",2502.01451
proof,"Suppose for a contradiction that $\g$ has a vertex $v\neq x$ of degree at most four.  Note that $v\neq z$ by Corollary~\ref{cor-mainlov}, and $\deg(v)=4$ and $v$ has zero boundary by tameness of $(\g,z)$. Lemma~\ref{lemma-genladeg-psi} implies that the canvas $(\g,z)$ is $\psi$-critical.  Let $C=V(\g)\setminus\{v,z,x\}$; since $|V(\g)|\ge 4$, we have $C\neq\emptyset$. Lemma~\ref{lemma-2con} implies that there exists an edge $e_1$ between $v$ and a vertex in $C$.  \item[(i)] If $\psi$ directs two edges between $z$ and $v$ in opposite ways, then let $e_3$ and $e_4$ be these edges and let $e_2$ be the edge incident with $v$ different from $e_1$, $e_3$, and $e_4$. \item[(ii)] If $v$ is adjacent to $z$ and $\psi$ directs all edges between $z$ and $v$ in the same way, then  since $\psi$ extends to a nowhere-zero flow in $\g/(C\cup \{x\})$, the edge between $z$ and $v$ has multiplicity at most two. Let $e_2$ be an edge between $z$ and $v$, and assign labels $e_3$ and $e_4$ arbitrarily to the edges incident with $v$ different from $e_1$ and $e_2$. \item[(iii)] If $v$ is not adjacent to $z$, then assign labels $e_2$, $e_3$, and $e_4$ to the edges incident with $v$ different from $e_1$ arbitrarily.  For $i\in\{1,\ldots,4\}$, let $v_i$ be the end of $e_i$ different from $v$, and let $N=\{v_1,\ldots, v_4\}$.  Let $\g_1$ be the $\Z$-bordered graph obtained from $\g$ by splitting off $e_1$ with $e_2$ (giving an edge $e'_1$) and $e_3$ with $e_4$ (giving an edge $e'_3$, unless $e_3$ and $e_4$ are both incident with $z$) and deleting the now isolated vertex $v$. The preflow $\psi$ naturally corresponds to a tip preflow $\psi_1$ in $(\g_1,z)$, and $\psi_1$ does not extend to a nowhere-zero flow in $\g_1$. Hence, $(\g_1,z)$ has a tip-respecting $\psi_1$-critical contraction $(\g',z)$. Let $\PP'$ be the tip-respecting partition of $V(\g_1)$ such that $\g'=\g_1/\PP'$.  Let $X'$ be the part of $\PP'$ containing $x$ and let $x'$ be the corresponding vertex of $\g'$.  The easel $(\g',z,x',\psi_1)$ belongs to $\GG_{k,r}$ and $(\g',z,x')\prec (\g,z,x)$.   Consider any part $A'\in \PP'$ other than $\{z\}$, and let $a$ be the corresponding vertex of $\g'$. Let $A=A'\cup\{v\}$ if $|A'\cap N|\ge 3$ and $A=A'$ otherwise. If $|A|\ge 2$, then Corollary~\ref{cor-contrtame} implies $\deg(a)\ge \deg_{\g}(A)-2\ge 4+|\tau(A)|=4+|\tau(a)|$. If $|A|=1$, then by Lemma~\ref{lemma-simple} at most one of the edges $e_1$, \ldots, $e_4$ has an end in $A=A'$, and $\deg(a)=\deg_{\g}(A)\ge 4+|\tau(A)|=4+|\tau(a)|$ since $(\g,z)$ is tame.  Therefore, the canvas $(\g',z)$ is tame.  Moreover, if $\deg_{\g'}(z)=k+1$, then $\deg_{\g}(z)=k+1$ and $\psi$ directs two edges incident with $z$ in opposite ways, and thus so does $\psi_1$.  Therefore, $\psi_1$ is a $k$-tallness-witnessing preflow for $(\g', z)$, and $(\g',z)\in \GG_k$. Clearly, we also have $o(\g',z)<o(\g,z)$, and thus $(\g',z,x')\prec (\g,z,x)$.  If $|X'\cap N|\ge 3$, then let $X=X'\cup\{v\}$, otherwise let $X=X'$.  If $|X|\ge 2$, then Theorem~\ref{thm-deg} applied to $(\g,z)\restriction X$ implies $\deg(x')\ge \deg_{\g}(X)-2\ge \deg(x)\ge k-2-r$. If $X=\{x\}$, then $\deg(x')=\deg(x)\ge k-2-r$.  Suppose now that $\deg_{\g'}(z)=k+1$ and $\deg(x')=k-2-r$. It follows that $\deg_{\g}(z)=k+1$ and the labels of edges incident with $v$ were not chosen according to (i).  Furthermore, since $\deg(x')\ge \deg(x)\ge k-2-r$, we have $\deg(x)=k-2-r$. If $|X|\ge 2$, then $\deg_{\g}(X)\le \deg(x')+2=\deg(x)+2$, contradicting Lemma~\ref{lemma-aroundx}; therefore, we have $X=\{x\}$. Moreover, since $(x,\psi)$ is a witness of $(k,r)$-tallness of $(\g,z)$, the tip preflow $\psi$ directs distinct edges between $z$ and $V(\g)\setminus \{z,x\}$ in opposite ways.  The choice of the labels in (ii) and (iii) ensures that $\psi_1$ also directs distinct edges between $z$ and $V(\g_1)\setminus \{z,x\}$ in opposite ways, and since $X=\{x\}$, the tip preflow $\psi_1$ directs distinct edges between $z$ and $V(\g')\setminus \{z,x'\}$ in $\g'$ in opposite ways as well.  Therefore, $(x',\psi_1)$ is a witness of $(k,r)$-tallness of $(\g',z)$, and $(\g',z,x',\psi_1)\in \GG_{k,r}$.  For $i\in \{1,2\}$, let $y_i$ be the edge $e'_{2i-1}$ if it is present in $\g'$, and let $y_i$ be the vertex into which the part $Y_i\in\PP'$ containing $v_{2i-1}$ and $v_{2i}$ was contracted otherwise.  Note that $v_3=v_4=y_2=z$ and $Y_2=\{z\}$ in the case (i); and that for $i\in\{1,2\}$, if $y_i\neq z$ is a vertex, then $v_{2i-1}\neq v_{2i}$ by Lemma~\ref{lemma-simple}, and thus $|Y_i|\ge 2$.  If $y_1\neq y_2$, then let $(\g_0,z)$ be the $2$-alteration of $(\g',z)$ on $y_1$ and $y_2$, with the newly added vertex labelled $v$, and let $\PP=\PP'\cup\{\{v\}\}$. If $y_1=y_2$, then note that $y_1$ is a vertex (different from $z$), and let $(\g_0,z)=(\g',z)$ and $\PP=(\PP'\setminus\{Y_1\})\cup\{Y_1\cup \{v\}\}$. Observe that in either case, we have $(\g_0/\PP,z)=(\g/\PP,z)$.  Consider any part $P\in\PP$ of size at least two, and let $p$ be the corresponding vertex of $\g_0$. Since $(\g',z)\in \GG_k$, Theorem~\ref{thm-deg} implies $\deg_{\g'}(p)\le k-1$, and thus $\deg_{\g}(P)\le \deg_{\g'}(p)+2\le k+1$. By Lemmas~\ref{lemma-gen-sepx} and \ref{lemma-genladeg-sepx}, we conclude that $(\g,z)$ is a $(\GG_k,x\to x',\GG_{k,r},\{y_1,y_2\})$-expansion of $(\g_0,z)$, and thus $(\g,z,x,\psi)$ satisfies Theorem~\ref{thm-genladeg}(EXP) or (EXPA). This is a contradiction.",2502.01451
proof,"Let $\g=(G,\beta)$.  Recall that the canvas $(\g,z)$ is $\psi$-critical by Lemma~\ref{lemma-genladeg-psi}. Suppose for a contradiction that $e=uv\in E(\g-\{z,x\})$ is a mixed edge, say with $v$ in-friendly and $u$ out-friendly.  Let $\g_1=(G-e,\beta')$, where $\beta'(y)=\beta(y)$ for $y\in V(G)\setminus\{u,v\}$, $\beta'(u)=\beta(u)-1$, and $\beta'(v)=\beta(v)+1$. Lemmas~\ref{lemma-conn} and \ref{lemma-2con} imply that $G-e$ is connected, and thus $\beta'$ is a $\Z$-boundary for $G-e$. If $\g_1$ had a nowhere-zero flow extending $\psi$, it would give a nowhere-zero flow in $\g$ extending $\psi$ by directing the edge $e$ towards $v$.  Hence, $\psi$ does not extend to a nowhere-zero flow in $\g_1$, and thus $(\g_1,z)$ has a tip-respecting $\psi$-critical contraction $(\g',z)$. Let $\PP$ be the tip-respecting partition such that $\g'=\g_1/\PP$, and let $x'$ be the vertex obtained by contracting the part $X\in \PP$ containing $x$. Note that $o(\g',z)<o(\g,z)$, and thus $(\g',z,x')\prec (\g,z,x)$.  As in the proof of Lemma~\ref{lemma-norede}, observe that the assumptions on in-friendliness and out-friendliness of $u$ and $v$ together with Lemma~\ref{lemma-genladeg-no4} imply that $(\g_1,z)$ is tame, and together with Corollary~\ref{cor-contrtame}, it follows that $(\g',z)$ is tame.  Moreover, $(\g',z)$ is $k$-tall, since $\psi$ is a $k$-tallness-witnessing preflow around $z$ in $\g'$. Hence $(\g',z)\in\GG_k$.  If $|X|\ge 2$, then Theorem~\ref{thm-deg} implies $\deg(x')\ge \deg_{\g}(X)-1 >\deg(x) \ge k-2-r$.  If $X=\{x\}$, then $\deg(x')=\deg(x)\ge k-2-r$; and moreover, if $\psi$ directs two edges not incident with $x$ in the opposite direction in $\g$, then it does so in $\g'$ as well.  Therefore, $(x',\psi)$ is a witness of $(k,r)$-tallness of $(\g',z)$, and we have $(\g',z,x',\psi)\in\GG_{k,r}$.  If $u$ and $v$ are contained in the same part of $\PP$, then let $(\g_0,z)=(\g',z)$.  Otherwise, let $u'$ and $v'$ be the vertices of $\g'$ into which the parts containing $u$ and $v$ were contracted, and let $(\g_0,z)$ be the $1$-alteration of $(\g',z)$ obtained by adding the edge $u'v'$, increasing the boundary at $u'$ by one, and decreasing it at $v'$ by one.  Note that in either case, $(\g_0,z)=(\g/\PP,z)$.  For every vertex $y\in V(\g_0)\setminus\{z\}$, if $A$ is the set of vertices of $\g$ contracted into $y$ and $|A|\ge 2$, then note that $\deg_{\g}(A)\le \deg_{\g'}(y)+1\le \deg(z)-1\le k$ by Theorem~\ref{thm-deg}. By Lemmas~\ref{lemma-gen-sepx} and \ref{lemma-genladeg-sepx}, we conclude that $(\g,z)$ is a $(\GG_k,x\to x',\GG_{k,r},\emptyset)$-expansion of $(\g_0,z)$. It follows that the easel $(\g,z,x,\psi)$ satisfies Theorem~\ref{thm-genladeg}(EXP) or (EXPB), which is a contradiction.",2502.01451
proof,"Let $\g=(G,\beta)$.  Recall that the canvas $(\g,z)$ is $\psi$-critical by Lemma~\ref{lemma-genladeg-psi}. By Lemma~\ref{lemma-genladeg-norede2}, we can by symmetry assume that $\tau(v)>0$ for every $v\in V(\g)\setminus\{x,z\}$. Suppose for a contradiction that $\psi$ directs an edge $e=uz$ of $\g$ with $u\neq x$ towards $z$. Let $\g'=(G-e,\beta')$, where $\beta'(y)=\beta(y)$ for $y\in V(G)\setminus\{z,v\}$, $\beta'(z)=\beta(z)+1$, and $\beta'(u)=\beta(u)-1$. Let $\psi'$ be obtained from $\psi$ by removing the edge $e$.  As in the proof of Lemma~\ref{lemma-sameor}, we argue that $(\g',z)$ is a $\psi'$-critical tame canvas, and since $\deg_{\g'}(z)\le \deg_{\g}(z)-1\le k$, we have $(\g',z)\in \GG_k$. Moreover, since $\deg_{\g'}(x)=\deg_{\g}(x)$, it follows that $(\g',z,x,\psi')\in\GG_{k,r}$.  Note that $(\g,z)$ is a tip-alteration of $(\g',z)$. Since $o(\g',z)=o(\g,z)$, the canvas $(\g,z)$ is $x$-homogeneous, and $\deg_{\g'}(z)<\deg_{\g}(z)$, we have $(\g',z,x)\prec (\g,z,x)$.  Therefore, $(\g,z,x,\psi)$ satisfies Theorem~\ref{thm-genladeg}(ADD), which is a contradiction.",2502.01451
proof,"[Proof of Theorem~\ref{thm-genladeg}] Let $k$ and $r$ be non-negative integers and suppose for a contradiction that there exists a minimal $(k,r)$-counterexample $(\g,z,x,\psi)$. By Lemma~\ref{lemma-genladeg-norede1} and symmetry, we can assume that $\tau(v)>0$ for every $v\in V(\g)\setminus\{x,z\}$ and that $\psi$ directs all edges not incident with $x$ away from $z$. Since $(x,\psi)$ is a witness of $(k,r)$-tallness of $(\g,z)$, it follows that $\deg(z) \le k$ or $\deg(x) >k-2-r$.  By Theorem~\ref{thm-deg}, we have $\deg(z)\ge \deg(x)+2$, and thus there exist distinct edges $e=zv$ and $e_0$ between $z$ and $V(\g)\setminus \{x,z\}$. Let $\g'$ be the $\Z$-boundaried graph obtained from $\g$ by adding an edge $e'$ parallel to $z$ and let $\psi'$ be the preflow around $z$ in $\g$ obtained from $\psi$ by directing $e$ and $e'$ towards $z$.  As in the proof of Theorem~\ref{thm:tall}, we argue that $(\g',z)$ is $\psi'$-critical and tame. Moreover, note that $\psi'$ directs the edges $e$ and $e_0$ between $z$ and $V(\g')\setminus \{x,z\}$ in the opposite ways. If $\deg_{\g}(z)\le k$, then $\deg_{\g'}(z)=\deg_{\g}(z)+1\le k+1$, and since $\deg_{\g'}(x)=\deg_{\g}(x)\ge k-2-r$, we have $(\g',z,x,\psi')\in\GG_{k,r}$. If $\deg_{\g}(z)=k+1$, then recall that $\deg(x) >k-2-r$; consequently $\deg_{\g'}(z)=\deg_{\g} (z)+1=k+2$ and $\deg_{\g'}(x)=\deg_{\g}(x)\ge (k+1)-2-r$, and $(\g',z,x,\psi')\in\GG_{k+1,r}$.  By Lemma~\ref{lemma-2con}, $v$ has a neighbour $u\neq x$.  Since we changed the parity of the degree of $v$, we have $\tau_{\g'}(v)<0$, while $\tau_{\g'}(u)=\tau_{\g}(u)>0$. Hence, $(\g',z)$ is not $x$-homogeneous.  Since $o(\g',z)=o(\g,z)$ and $(\g,z)$ is $x$-homogeneous, it follows that $(\g',z,x)\prec (\g,z,x)$. Therefore, $(\g,z,x,\psi)$ satisfies Theorem~\ref{thm-genladeg}(REM), which is a contradiction.",2502.01451
proof,"Since every vertex of $\g$ has degree at least five, we have $|C(\g,z)|=|V(\g-z)|$ and $$\sum_{d \in C(\g,z)}=\sum_{v\in V(\g)\setminus\{z\}} \deg_{\g} v=\deg z+2|E(\g-z)|.$$ The claim follows, since by Lemma~\ref{lemma-simple}, $\g-z$ does not have more edges than the complete graph.",2502.01451
proof,"The first point follows analogously to Lemma~\ref{lemma-simple}.  For the second point, since $G'$ is collapsible, the $\Z$-bordered graph $(G',\beta\restriction V(G'))$ has a nowhere-zero flow. We obtain a nowhere-zero flow in $(G,\beta)$ by directing both edges incident with $v$ according to the corresponding edge of $G'$.  For the third point, suppose by symmetry that $\beta(v)=1$.  Let $\beta'(v)=0$, $\beta'(u)=\beta(u)+1$ for the other endpoint $u$ of $e$, and let $\beta'(x)=\beta(x)$ for every other vertex $x$ of $G$.  The second point applied to $(G-e,\beta')$ gives a nowhere-zero flow which extends to a nowhere-zero flow in $(G,\beta)$ by directing the edge $e$ towards $u$.",2502.01451
proof,"If $G=K_4$, then deleting any edge and suppressing a resulting vertex of degree two gives a collapsible graph, and thus $\beta(v)=0$ for every $v\in V(G)$ by Observation~\ref{obs-collaps}.  Suppose now that $|V(G)|=5$ and $G$ has exactly two non-edges.  There are two possibilities:  \item The two non-edges form a matching, and thus $G$ consists of a $4$-cycle $K=v_1v_2v_3v_4$ and a vertex $v$ adjacent to all of its vertices. Deleting any edge of $K$ and suppressing a resulting vertex of degree two gives a collapsible graph, and thus $\beta(v_i)=0$ for $i\in\{1,\ldots,4\}$ by Observation~\ref{obs-collaps}.  It follows that $\beta(v)=0$, since $\beta$ is a $\Z$-boundary.  However, then it is easy to construct a nowhere-zero flow in $G$ by orienting all edges incident with $u \in \{v_1,v_3\}$ towards $u$, and all edges incident with $u \in \{v_2,v_4\}$ away from $u$. Hence, this graph $G$ is $\Z$-connected.  Moreover, note that this graph is contained as a subgraph of every simple graph with $5$ vertices and at most one non-edge, and thus all such graphs are $\Z$-connected as well.  \item The two non-edges do not form a matching.  It follows that $G$ consists of a complete graph on vertices $v_1$, \ldots, $v_4$ together with a vertex $v$ and edges $vv_1$ and $vv_2$. Suppressing $v$ results in a collapsible graph, and thus by Observation~\ref{obs-collaps}, we have $\beta(v)\neq 0$. Suppose by symmetry that $\beta(v)=1$.  Deleting the edge $v_3v_4$ and suppressing $v_3$ or $v_4$ results in a collapsible graph, and thus again by Observation~\ref{obs-collaps}, we have $\beta(v_3)=\beta(v_4)=0$. Since $\beta$ is a $\Z$-boundary, we have $(\beta(v_1),\beta(v_2))\in \{(-1,0),(0,-1),(1,1)\}$. The first two options lead to a $\Z$-bordered graph with a nowhere-zero flow, and thus we conclude that $\beta(v_1)=\beta(v_2)=\beta(v)=1$.   Suppose now that $|V(G)|=6$ and $G$ has exactly four non-edges and minimum degree at least two.  If $G$ contains a vertex $v$ of degree two, then $G-v$ has only one non-edge and by the previous point $G-v$ is $\Z$-connected.  Thus, we can orient the edges incident with $v$ to match the boundary $\beta(v)$ and extend the flow to a nowhere-zero flow in $G$.  Hence, $G$ has minimum degree three (since it has four non-edges, it cannot have minimum degree at least four). Let $v$ be a vertex of $G$ of degree three; then $G-v$ has two non-edges and analogously to the previous case, we can assume that $G-v$ is not $\Z$-connected. By the previous point, $G-v$ consists of a complete graph on vertices $v_1$, \ldots, $v_4$ and a vertex $v'$ adjacent to $v_1$ and $v_2$. Since $G$ has minimum degree at least three, $v$ is adjacent to $v'$.  It follows that every vertex of $G$ of degree three has a neighbour of degree three. Up to symmetry, there are the following possibilities for the neighbours of $v$ in $\{v_1,\ldots,v_4\}$:  \item If $v$ is adjacent to $v_2$ and $v_3$, then $v_4$ is a vertex of degree three with all neighbours of larger degree, a contradiction. \item If $v$ is adjacent to $v_3$ and $v_4$, then since deleting the edge $vv'$ and suppressing $v$ or $v'$ gives a collapsible graph, we have by Observation~\ref{obs-collaps} that $\beta(v)=\beta(v')=0$.  By symmetry, we can assume that $\beta(v_4)\neq -1$.  Let $\beta'(v_4)=\beta(v_4)+1$, $\beta'(v_3)=\beta(v_3)+1$, $\beta'(v_2)=\beta(v_2)-1$ and $\beta'(v_1)=\beta(v_1)-1$.  Since $\beta'(v_4)\neq 0$, $(G[\{v_1,\ldots,v_4\}],\beta')$ has a nowhere-zero flow, as we have observed at the beginning of the lemma.  Orienting the edges incident with $v$ towards $v$ and those incident with $v'$ away from $v'$ extends this to a nowhere-zero flow in $(G,\beta)$. \item Hence, $v$ is adjacent to $v_1$ and $v_2$.  Observation~\ref{obs-collaps} applied to edges $vv'$ and $v_3v_4$ gives $\beta(v)=\beta(v')=\beta(v_3)=\beta(v_4)=0$. It follows that $\beta(v_1)=-\beta(v_2)$.  If $\beta(v_1)\neq 0$, then $(G,\beta)$ has a nowhere-zero flow, and thus $\beta(v_1)=\beta(v_2)=0$.  Finally, if $|V(G)|=6$ and $G$ has at most three non-edges, then we can delete edges from $G$ so that the resulting graph $G'$ has exactly four non-edges, minimum degree at least two, and it is not the union of two $K_4$'s sharing an edge. By the previous analysis, this implies that $G'$ is $\Z$-connected, and thus $G$ is $\Z$-connected as well and $(G,\beta)$ has a nowhere-zero flow.",2502.01451
proof,"Suppose for a contradiction that there exists an integer $k\ge 7$ and an easel $(\g,z,x,\psi)\in \GG_{k,0}$ such that $(\deg(z), C(\g,z))\not\in \CC'_{k,0}$, and choose such an easel with $(\g,z,x)$ minimal in the $\prec$ ordering; such an easel exists, since $\prec$ does not have infinite decreasing chains by Observation~\ref{obs-precord}. We have $\deg(x) \ge k-2$, and thus $\deg(z)\ge k$ by Theorem~\ref{thm-deg}.  Moreover, $\deg(z)\le k+1$ since $(\g,z,x,\psi)\in \GG_{k,0}$.  We split into cases depending on the outcomes of Theorem~\ref{thm-genladeg} applied to $(\g,z,x,\psi)$.   The outcome (SMALL) does not occur.   Suppose it does, and in this case let $V(\g)=\{z,x,v\}$.  Since $(\g,z)$ is tame, we have $\deg(v) \ge 4$, and since $\deg(x)>\deg(z)-4$, the vertices $x$ and $v$ must be adjacent.  By Lemma~\ref{lemma-simple}, $x$ and $v$ are joined only by one edge, and thus $$(\deg(z),\deg(x),\deg(v))\in \{(k,k-2,4),(k+1,k-1,4),(k+1,k-2,5)\}.$$  In any of these cases, we have $(\deg(z),C(\g,z))\in \CC'_{k,0}$, which is a contradiction.   Let $(\g',z,x',\psi')$ be the easel that appears in the rest of the outcomes of Theorem~\ref{thm-genladeg} with $(\g',z,x')\prec (\g,z,x)$. By the minimality of $(\g,z,x,\psi)$, if $(\g',z,x',\psi')\in \GG_{k,r}$, then $(\deg_{\g'}(z),C(\g',z))\in \CC'_{k,0}$, and if $(\g',z,x',\psi')\in \GG_{k+1,0}$, then $(\deg_{\g'}(z), C(\g',z))\in \CC'_{k+1,0}$.  If $\deg_{\g'}(x')\ge 5$, then let $a_0$ denote the element of $C(\g',z)$ corresponding to $\deg_{\g'}(x')$.   The outcome (ADD) does not occur.    Suppose it does. Since $(\g,z)$ is a tip-alteration of $(\g',z)$ at a vertex $v\neq x$, $C(\g,z)$ is obtained from $C(\g',z)$ by either choosing an element $a$ different from $a_0$ and replacing it by $a+1$, or (in case that $\deg_{\g'}(v)=4$) by adding $5$ to $C(\g',z)$.  Moreover, since $\deg_{\g}(z)\le k+1$ and $\deg_{\g'}(x)=\deg_{\g}(x)\ge k-2$, Theorem~\ref{thm-deg} implies that $\deg_{\g'}(z)=k$, $\deg(x)=k-2$, and $\deg_{\g}(z)=k+1$. Since $(\deg_{\g'}(z), C(\g',z))\in \CC'_{k,0}$, it follows that $C(\g',z)=\{k-2\}$ and $C(\g,z)=\{k-2,5\}$. Let us remark that the case $C(\g,z)=\{k-1\}$ is not possible, since $a$ is different from $a_0$. However, then $(\deg_{\g}(z),C(\g,z))\in \CC'_{k,0}$, which is a contradiction.    The outcome (REM) does not occur.    Suppose it does. Since $(\g,z)$ is a tip-reduction of $(\g',z)$ at a vertex other than $x$ and all vertices of $\g$ other than $x$ have degree at least $5$, $C(\g,z)$ is obtained from $C(\g',z)$ by choosing an element $a\ge 6$ different from $a_0$ and replacing it by $a-1$. However, $(\deg_{\g'}(z),C(\g',z))\in \CC'_{k,0}\cup \CC'_{k+1,0}$, and the inspection of the definition of $\CC'_{k,0}$ shows that no such element $a$ exists.  This is a contradiction.   For the remaining outcomes ((EXP), (EXPA), (EXPX), and (EXPB)), let $(\g_0,z)$ be the canvas (equal to $(\g',z)$, or to a $2$-alteration, an $x'$-alteration, or a $1$-alteration of $(\g',z)$) such that $(\g,z)$ is a $(\GG_k,x\to x',\GG_{k,0},Y)$-expansion of $(\g_0,z)$ for a set $Y$. Let $\PP$ be the corresponding tip-respecting $\GG_k$-partition such that $(\g/\PP, z)=(\g_0,z)$. We say that a vertex $v\in V(\g_0)\setminus\{z\}$ (or $v\in V(\g')\setminus\{z\}$) \emph{contributes} degrees $d_1$, \ldots, $d_m$ to $C(\g,z)$ if the part $P\in\PP$ contracted to $v$ satisfies $$\{\deg_{\g}(u):u\in P,\deg_{\g}(u)\ge 5\}=\{d_i:i\in\{1,\ldots,m\}, d_i\ge 5\},$$ where both sides of the equality are multisets. The following observations will be sufficient to bound the census of $(\g,z)$ based on the census of $(\g_0,z)$:  \item[(i)] If a vertex $v\in V(\g_0)\setminus \{z\}$ has degree at most five in $\g_0$, then Observation~\ref{obs-subcrit} and Theorem~\ref{thm-deg} imply that the part of $\PP$ contracted to $v$ has size one, and thus it contributes $\deg_{\g_0}(v)$ to $C(\g,z)$. \item[(ii)] If a vertex $v\in V(\g_0)\setminus \{z\}$ has degree six in $\g_0$ and the part $P\in \PP$ contracted to $v$ has size at least two, then by Observation~\ref{obs-subcrit} and Theorem~\ref{thm-deg} all vertices in $P$ have degree four in $\g$, and thus $v$ does not contribute anything to $C(\g,z)$. \item[(iii)] Suppose a vertex $v\in V(\g_0)\setminus \{z\}$ has degree seven in $\g_0$ and the part $P\in \PP$ contracted to $v$ has size at least two. Let $(\g_1,b)=(\g,z) \restriction P$.  By Observation~\ref{obs-subcrit}, Theorem~\ref{thm-deg} and parity, there exists a vertex $x_1\in P$ such that $\deg_{\g}(x_1)=5$.  Consequently, letting $\psi_1$ be any tip preflow that does not extend to a nowhere-zero flow in $(\g_1,b)$, we have $(\g_1,b,x_1,\psi_1)\in\GG_{7,0}$. Clearly $o(\g_1,b)<o(\g,z)$ and $(\g_1,b,x_1)\prec (\g,z,x)$. Therefore, we have $(\deg(b),C(\g_1,b))\in \CC'_{7,0}$, and since $\deg(b)=7$, it follows that $C(\g_1,b)=\{5\}$. Hence, $v$ contributes $5$ to $C(\g,z)$. \item[(iv)] Finally, let us consider a contribution of the vertex $x'$ to $(\g,z)$.  Let $P\in\PP$ be the part contracted to the vertex $x'$; we have $x\in P$.  If $|P|=1$, then $x'$ contributes $\deg_{\g_0} x'=\deg_{\g} x$ to $(\g,z)$.  If $|P|\ge 2$, then let $(\g_1,b)=(\g,z) \restriction P$ and note that $\deg b=\deg_{\g_0} x'$. Since $(\g,z)$ is a $(\GG_k,x\to x',\GG_{k,0},Y)$-expansion of $(\g_0,z)$, there exists a tip preflow $\psi_1$ such that $(\g_1,b,x,\psi_1)\in\GG_{k,0}$.  Clearly $o(\g_1,b)<o(\g,z)$ and $(\g_1,b,x)\prec (\g,z,x)$. Therefore, we have $(\deg(b),C(\g_1,b))\in \CC'_{k,0}$.  We conclude that  \item $\deg_{\g_0}(x')=k$ and $x'$ contributes only $k-2=\deg_{\g}(x)=\deg_{\g_0}(x')-2$ to $C(\g,z)$; or, \item $\deg_{\g_0}(x')=k+1$ and $x'$ contributes only $k-1=\deg_{\g}(x)=\deg_{\g_0}(x')-2$ to $C(\g,z)$; or, \item $\deg_{\g_0}(x')=k+1$ and $x'$ contributes only $k-2=\deg_{\g}(x)=\deg_{\g_0}(x')-3$ and one or three $5$'s to $C(\g,z)$.    Let us now discuss each of the conclusions separately.  Note that in all the cases, we have $(\deg_{\g'}(z),C(\g',z))\in \CC'_{k,0}$, and $C(\g',z)$ consists of $\deg_{\g'}(x')\le k-1$ and possibly several fives.  The case (EXP) does not occur.    Suppose it does. Note that $C(\g_0,z)=C(\g',z)\in \CC'_{k,0}$ and $\deg_{\g_0}(x')=\deg_{\g'}(x')\le k-1$. By (i) and (iv), we have $C(\g,z)=C(\g',z)$, and thus $(\deg_{\g}(z), C(\g,z))\in \CC'_{k,0}$. This is a contradiction.    Neither (EXPA) nor (EXPX) occur.    In this case, $(\g_0,z)$ is a $2$-alteration of $(\g',z)$ on some $y_1$ and $y_2$ or an $x'$-alteration of $(\g',z)$ on some $y_1$. In the latter case, let $y_2=x'$, so that $Y=\{y_1,y_2\}$ in both cases.  If $z\in Y$, then we would be in the (EXPA) case and we would have $\deg_{\g'}(z)=\deg_{\g_0}(z)-2=\deg_{\g}(z)-2\le k-1$, which is not possible since $(\deg_{\g'}(z),C(\g',z))\in \CC'_{k,0}$. It follows that $z\not\in Y$, and $\deg_{\g'}(z)=\deg_{\g_0}(z)=\deg_{\g}(z)$.   Moreover, $C(\g_0,z)$ is obtained from $C(\g',z)$ by replacing $\deg_{\g'}(y)$ by $\deg_{\g'}(y)+2$ for each vertex $y\in Y$ (or adding $\deg_{\g'}(y)+2=6$ to $C(\g',z)$ when $\deg_{\g'}(y)=4$).   Consider any vertex $v\in V(\g')\setminus \{z,x'\}$.  If $v\not\in Y$, then $\deg_{\g_0}(v)=\deg_{\g'}(v)\in\{4,5\}$ and by (i), $v$ contributes $\deg_{\g'}(v)$ to $C(\g,z)$.  If $v\in Y$, then let $X_v$ be the part of $\PP$ contracted into $v$ and note that $|X_v|\ge 2$.  \item If $\deg_{\g'}(v)=4$, then $\deg_{\g_0}(v)=6$ and by (ii) $v$ does not contribute anything to $C(\g,z)$. \item If $\deg_{\g'}(v)=5$, then $\deg_{\g_0}(v)=7$ and by (iii) $v$ contributes $5$ to $C(\g,z)$.  In either case, we again conclude that $v$ contributes $\deg_{\g'}(v)$ to $C(\g,z)$.  Since $(\deg_{\g'}(z),C(\g',z))\in\CC'_{k,0}$, $\deg_{\g}(z)=\deg_{\g'}(z)$, and $(\deg_{\g}(z),C(\g,z))\not\in\CC'_{k,0}$, we have $C(\g,z)\neq C(\g',z)$.  It follows that $x'$ contributes something else than $\deg_{\g'}(x')$ to $C(\g,z)$. If $x'\not\in Y$, then $\deg_{\g_0}(x')=\deg_{\g'}(x')\le k-1$ and $x'$ would only contribute $\deg_{\g'}(x')$ to $C(\g,z)$ by (iv). Therefore, $x'\in Y$, and in particular the part of $\PP$ contracted to $x'$ has size at least two and $\deg_{\g_0}(x')=\deg_{\g'}(x')+2$.  Since $x'$ does not contribute only $\deg_{\g'}(x')=\deg_{\g_0}(x')-2$ to $C(\g,z)$, (iv) implies that $\deg_{\g_0}(x')=k+1$ and $x'$ contributes only $k-2$ and one or three $5$'s to $C(\g,z)$. Note that $\deg_{\g'}(x')=k-1$.  Recall that $(\deg_{\g'}(z),C(\g',z))\in \CC'_{k,0}$, and thus we have $(\deg_{\g'}(z),C(\g',z))=(k+1,\{k-1\})$. As we have argued above, this implies that no vertex of $V(\g')\setminus\{z,x'\}$ contributes anything to $C(\g,z)$, and thus $$(\deg_{\g}(z),C(\g,z))\in\{(k+1,\{k-2,5\}),(k+1,\{k-2,5,5,5\})\}\subset \CC'_{k,0};$$ this is a contradiction.   It follows that (EXPB) holds. In particular, $(\g_0,z)$ is obtained from $(\g',z)$ by adding an edge $y_1y_2$ not incident with $z$ (and adjusting the boundary), and thus $C(\g_0,z)$ is obtained from $C(\g',z)$ by replacing $\deg_{\g'}(y)$ by $\deg_{\g'}(y)+1$ for each vertex $y\in \{y_1,y_2\}$ (or adding $\deg_{\g'}(y)+1=5$ in case that $\deg_{\g'}(y)=4$).  By (ii), in case that the new element is $6$, the vertex $y$ can contribute either $6$ or nothing to $C(\g,z)$.  Consider now the vertex $x'$, and let $X$ be the part of $\PP$ contracted to $x'$ (and containing $x$). Since $(\g',z,x',\psi')\in\GG_{k,0}$, we have $\deg_{\g'}(x')\in\{k-2,k-1\}$.  \item If $x'\not\in \{y_1,y_2\}$, then $\deg_{\g_0}(x')=\deg_{\g}(x)\le k-1$, and by (iv), the vertex $x'$ contributes only $\deg_{\g'}(x)=\deg(x)$ to $C(\g,z)$. \item If $x'\in \{y_1,y_2\}$, then we have $\deg_{\g'}(x')+1=\deg_{\g_0}(x')=\deg_{\g}(X)\in\{k-1,k\}$.  \item If $|X|=1$, then $\deg_{\g_0}(x')=\deg_{\g}(x)$, and since $\deg_{\g}(x)\le k-1$, it follows that $\deg_{\g'}(x')=k-2$ and $x'$ contributes only $\deg(x)=k-1=\deg_{\g'}(x')+1$ to $C(\g,z)$. \item If $|X|\ge 2$, then note that Theorem~\ref{thm-deg} for $(\g,z)\restriction X$ implies that $k-2\le \deg_{\g}(x)\le \deg_{\g}(X)-2\le k-2$, and thus $\deg_{\g_0}(x')=\deg_{\g}(X)=k$, $\deg_{\g'}(x')=k-1$, and $\deg_{\g}(x)=k-2$.  By (iv), $x'$ contributes only $\deg(x)=k-2=\deg_{\g'}(x')-1$ to $C(\g,z)$.   Thus, $C(\g,z)$ is obtained from $C(\g',z)\in \CC'_{k,0}$ by choosing some number $m\le 2$ of distinct elements, increasing or decreasing them by one (and removing them if the result is $4$), and adding $2-m$ fives. The inspection of the definition of $\CC'_{k,0}$ gives us the following possibilities for $(\deg(z),C(\g,z))$, taking into the account that every vertex in $V(\g)\setminus\{z\}$ has degree at most $\deg(z)-2$ by Theorem~\ref{thm-deg}, that $\deg_{\g}(x)\in \{k-2,k-1\}$, and that $(\deg(z),C(\g,z))\not\in \CC'_{k,0}$:  (\deg(z),C(\g,z))\in\{&(k,\{k-2,5,5\}),(k+1,\{k-1,5,5\}), (k+1,\{k-2,6,5\}),\\ &(k+1,\{k-1,6\}), (k+1,\{k-2,5,5,5,5,5\}), (k+1,\{k-2,6,5,5,5\}),\\ &(k+1,\{k-2,6,6,5\}),(k+1,\{k-1,5,5,5,5\}), (k+1,\{k-1,6,5,5\})\}  Theorem~\ref{thm-genladeg} guarantees that in (EXPB), every vertex other than $x$ has degree at least five, and since $k\ge 7$, so does $x$. Observation~\ref{obs-sumdeg} excludes all the possibilities for $(\deg(z), C(\g,z))$ except for $$(k+1,\{k-2,5,5,5,5,5\}), (k+1,\{k-2,6,5,5,5\}),\text{ and }(k+1,\{k-1,5,5,5,5\}).$$ Let $\g=(G,\beta)$, and let $\beta'$ be the $\Z$-boundary for $G-z$ such that $\beta'(v)=\beta(v)-\deg^+_\psi(v)+\deg^-_\psi(v)$ for each $v\in V(G-z)$. Since $\psi$ does not extend to a nowhere-zero flow in $\g$, $(G-z,\beta')$ does not have a nowhere-zero flow.  \item If $\deg(z)=k+1$ and $C(\g,z)=\{k-2,5,5,5,5,5\}$, then $|V(G-z)|=6$ and $G-z$ has four non-edges.  By Lemma~\ref{lemma-small}, $G-z$ consists of two copies of $K_4$ whose intersection is $K_2$ and $\beta'(v)=0$ for $v\in V(G-z)$.  Note that $G-z$ has two vertices of degree five; let $v$ be one of these degree-five vertices different from the vertex of $G$ of degree $k-2$.  Then $v$ also has degree five in $\g$, $v$ is not adjacent to $z$, and $\beta(v)=\beta'(v)=0$.  This is a contradiction, since $\deg(v)<4+|\tau(v)|=7$. \item If $\deg(z)=k+1$ and $C(\g,z)=\{k-2,6,5,5,5\}$ or $C(\g,z)=(k+1,\{k-1,5,5,5,5\})$, then $|V(G-z)|=5$ and $G-z$ has only one non-edge. However, then $(G-z,\beta')$ has a nowhere-zero flow by Lemma~\ref{lemma-small}.  In any of the cases, we obtain a contradiction.",2502.01451
proof,"The graph $G'$ is obtained from $G$ by joining the vertex $z$ to each vertex of $G$ of degree two or three by a double edge and to each vertex of $G$ of degree four or five by a single edge. Let us define the $\Z$-boundary $\beta'$ and a tip preflow $\psi$ as follows:  \item If $v\in V(G)$ has degree two, then let $\beta'(v)=0$ and choose $\psi$ on the edges between $v$ and $z$ so that $\deg^+_\psi(v)-\deg^-_\psi(v)\equiv \beta(v)\pmod 3$. \item If $v\in V(G)$ has degree three, then let $\beta'(v)=1$ and choose $\psi$ on the edges between $v$ and $z$ so that $\deg^+_\psi(v)-\deg^-_\psi(v)\equiv \beta(v)-1\pmod 3$. \item If $v\in V(G)$ has degree four, then choose $\beta'(v)\neq 0$ different from $\beta(v)$, and choose $\psi$ on the edge between $v$ and $z$ so that $\deg^+_\psi(v)-\deg^-_\psi(v)\equiv \beta(v)-\beta'(v)\pmod 3$. \item If $v\in V(G)$ has degree five, then choose $\beta'(v)\neq \beta(v)$ arbitrarily, and choose $\psi$ on the edge between $v$ and $z$ so that $\deg^+_\psi(v)-\deg^-_\psi(v)\equiv \beta(v)-\beta'(v)\pmod 3$. \item If $v\in V(G)$ has degree at least six, then let $\beta'(v)=\beta(v)$.  Finally, we let $\beta'(z)\equiv \deg^+_\psi(z)-\deg^-_\psi(z)\pmod 3$. The choice of $G'$ and $\beta'$ implies that the canvas $((G',\beta'),z)$ is tame. Moreover, since $(G,\beta)$ is flow-critical, it is easy to see that the canvas $((G',\beta'),z)$ is $\psi$-critical. Since $$\deg(z) + \sum_{v\in V(G)} \deg_{G'}(v)=2|E(G')|=2|E(G)|+2\deg(z),$$ we have  |E(G)|&=-\frac{1}{2}\Bigl(\deg(z)-\sum_{v\in V(G)} \deg_{G'}(v)\Bigr)\\ &=3|V(G)| - \frac{1}{2}\Bigl(\deg(z) -\sum_{v\in V(G)} (\deg_{G'}(v)-6)\Bigr).",2502.01451
proof,"Let $((G',\beta'),z)$ be the tame flow-critical canvas obtained in Observation~\ref{obs-to-tame} for $G$ with zero boundary.  Let us first consider the case that $\Delta(G) \geq 6$. Let $v_0$ be a vertex of maximum degree in $G$. Note that by assumption, all other vertices have degree at most six.  Moreover, by Lemma~\ref{lemma-simple}, the graph $G$ is simple, and thus $|V(G)|\ge 7$.  The conclusions of Observation~\ref{obs-to-tame} imply that $\deg_{G'}(v_0)=\deg(v_0)$ and together with the assumptions of the theorem, that $\deg_{G'} (v)\le 6$ for every $v\in V(G')\setminus\{z,v_0\}$. By Theorem~\ref{thm-deg}, we have $\deg(z)\ge \deg(v_0)+2$.   \item If $\deg(z)=\deg(v_0)+2$, then Theorem~\ref{thm-degbetter} implies that all vertices in $V(G')\setminus\{z,v_0\}$ have degree four and       \deg(z)-\sum_{v\in V(G)} (\deg_{G'}(v)-6)&=\deg(z)-(\deg(z)-8)+2(|V(G)|-1)\\[-0.2cm]     & =2|V(G)|+6\ge 20.      \item On the other hand, if $\deg(z)\ge \deg(v_0)+3$, then since all vertices of $V(G')\setminus\{z,v_0\}$ have degree at most $6$, we have that $$\deg(z)-\sum_{v\in V(G)} (\deg_{G'}(v)-6)\ge \deg(z)-(\deg(z)-9)=9.$$  Therefore, by the last equality from the statement of Observation~\ref{obs-to-tame}, we have  $$|E(G)|\le 3|V(G)| - \lceil 9/2\rceil=3|V(G)|-5,$$ as desired. Next, let us consider the case that $\Delta(G) \leq 5$, and thus all vertices of $G'$ except for $z$ have degree at most six. Since $G$ is flow-critical, we have $|V(G)|\ge 4$, and Theorem~\ref{thm-deg} implies that $\deg(z)\ge 6$.  \item If $\deg(z)\ge 9$, then  $$\deg(z)-\sum_{v\in V(G)} (\deg_{G'}(v)-6)\ge \deg(z)\ge 9.$$ \item If $\deg(z)=8$, then Theorem~\ref{thm-degbetter} implies that $V(G')\setminus\{z\}$ contains at most one vertex of degree six, and thus $$\deg(z)-\sum_{v\in V(G)} (\deg_{G'}(v)-6)\ge \deg(z)+(|V(G)|-1)\ge 11.$$ \item If $\deg(z)=7$, then Theorem~\ref{thm-degbetter} implies that $V(G')\setminus\{z\}$ consists of a vertex of degree five and all other vertices have degree four, and $$\deg(z)-\sum_{v\in V(G)} (\deg_{G'}(v)-6)\ge \deg(z)+2(|V(G)|-1)+1\ge 14.$$ \item Finally, if $\deg(z)=6$, then Theorem~\ref{thm-deg} implies that $V(G')\setminus\{z\}$ consists of vertices of degree four, and $$\deg(z)-\sum_{v\in V(G)} (\deg_{G'}(v)-6)\ge \deg(z)+2|V(G)|\ge 14.$$  Therefore, the last equality from the statement of Observation~\ref{obs-to-tame} again implies $$|E(G)|\le 3|V(G)| - \lceil 9/2\rceil=3|V(G)|-5.$$",2502.01451
lemma,"If $(\g,z)$ is a flow-critical canvas, then every edge of multiplicity more than one is incident with $z$.",2502.01451
lemma,"Let $(\g,z)$ be a flow-critical canvas and let $A\subseteq V(\g)\setminus\{z\}$ be a set of size at least two. If $\deg(v)\ge 4+|\tau(v)|$ for every $v\in A$, then $\deg(A) \ge 6+|\tau(A)|$.",2502.01451
lemma,"Let $(\g,z)$ be a canvas and $x\in V(\g)\setminus \{z\}$ be a vertex such that $\deg(v)\ge 4+|\tau(v)|$ for every $v\in V(\g)\setminus\{x,z\}$. If $(\g,z)$ is non-trivial and flow-critical, then $\g$ is connected.",2502.01451
lemma,"Suppose $(\g,z)$ is a $\psi$-critical canvas for a tip preflow $\psi$.  If $|V(\g)|\ge 4$, then $\g-z$ is 2-connected.",2502.01451
lemma,Every tall tame critical easel has at least four vertices.,2502.01451
lemma,"Suppose $(\g,z,x,\psi)$ is a minimal tall tame critical easel.  If $A\subsetneq V(\g)\setminus\{z\}$ contains $x$ and $|A|\ge 2$, then $\deg(A) \ge \deg(x)+2$.",2502.01451
lemma,"Suppose $(\g,z,x,\psi)$ is a minimal tall tame critical easel.  If $A\subsetneq V(\g)\setminus\{z\}$ contains $x$ and $|A|\ge 2$, then $\deg(A) > \deg(x)+2$.",2502.01451
lemma,"If $(\g,z,x,\psi)$ is a minimal tall tame critical easel, then every vertex $v\in V(\g)\setminus\{x,z\}$ has degree at least five.",2502.01451
lemma,"If $(\g,z,x,\psi)$ is a minimal tall tame critical easel, then no edge in $E(\g-\{x,z\})$ is mixed, and thus the canvas $(\g,z)$ is $x$-homogeneous.",2502.01451
lemma,"If $(\g,z,x,\psi)$ is a minimal tall tame critical easel, then $z$ is not adjacent to $x$, and either $\tau(v)>0$ for every $v\in V(\g)\setminus\{x,z\}$ and $\psi$ directs all edges away from $z$, or $\tau(v)<0$ for every $v\in V(\g)\setminus\{x,z\}$ and $\psi$ directs all edges towards $z$. Moreover, $\deg(z)\le \deg(x)+1$.",2502.01451
lemma,"If $(\g,z,\psi)$ is a minimal $k$-counterexample for a positive integer $k$, then the canvas $(\g,z)$ is $\psi$-critical.",2502.01451
lemma,"Let $(\g,z)$ be a tame flow-critical canvas, and let $A\subseteq V(\g)\setminus \{z\}$ be a non-empty set of its vertices. If $\deg(X) \ge\deg(z)-1$ for every set $X$ such that $A\subseteq X\subsetneq V(\g)\setminus \{z\}$, then every tip preflow extends to a nowhere-zero flow in $(\g',z)=(\g / A,z)$.",2502.01451
lemma,"Let $k$ be a positive integer, $(\g,z)\in \GG_k$ a canvas, and $\psi$ a $k$-tallness-witnessing preflow in $(\g,z)$. Suppose $A\subseteq V(\g)\setminus \{z\}$ satisfies $\deg(A)=k+1$ and let $x$ be a vertex of $A$.  If $\psi$ extends to a nowhere-zero flow in $\g/A$, then it also extends to a $(k, x,\psi,A)$-valid one.",2502.01451
lemma,"Let $(\g,z)\in \GG_k$ be a canvas for a positive integer $k$, let $\psi$ be a $k$-tallness-witnessing preflow in $(\g,z)$, and suppose that $(\g,z)$ is $\psi$-critical.  If a set $A\subseteq V(\g)\setminus \{z\}$ of size at least two satisfies $\deg(A)\le k+1$, then $(\g,z)\restriction A\in \GG_k$.",2502.01451
lemma,"If $(\g,z,\psi)$ is a minimal $k$-counterexample for a positive integer $k$, then $\g$ has minimum degree at least five.",2502.01451
lemma,"If $(\g,z,\psi)$ is a minimal $k$-counterexample for a positive integer $k$, then there is no mixed edge $uv\in E(\g-z)$.",2502.01451
lemma,"If $(\g,z,\psi)$ is a minimal $k$-counterexample for a positive integer $k$, then either $\tau(v)>0$ for every $v\in V(\g)\setminus\{z\}$ and $\psi$ directs all edges away from $z$, or $\tau(v)<0$ for every $v\in V(\g)\setminus\{z\}$ and $\psi$ directs all edges towards $z$.",2502.01451
lemma,"If $(\g,z,x,\psi)$ is a minimal $(k,r)$-counterexample for non-negative integers $k$ and $r$, then the canvas $(\g,z)$ is $\psi$-critical.",2502.01451
lemma,"Let $k$ and $r$ be non-negative integers and let $(\g,z,x,\psi)\in \GG_{k,r}$ be an easel such that the canvas $(\g,z)$ is $\psi$-critical. If a set $A\subseteq V(\g)\setminus \{z\}$ of size at least two satisfies $\deg(A)\le k+1$ and $x\in A$, then letting $(\g_1,b)=(\g,z)\restriction A$, there exists a tip preflow $\psi_1$ such that $(\g_1,b,x,\psi_1)\in \GG_{k,r}$.",2502.01451
lemma,"Let $k$ and $r$ be non-negative integers.  If $(\g,z,x,\psi)$ is a minimal $(k,r)$-counter\-exam\-ple, $\deg(z)=k+1$, $\deg(x)=k-2-r$, and $X$ is a set of vertices of $\g$ such that $\{x\}\subsetneq X\subsetneq V(\g)\setminus \{z\}$, then $\deg(X) > \deg(x)+2$.",2502.01451
lemma,"Let $k$ and $r$ be non-negative integers.  If $(\g,z,x,\psi)$ is a minimal $(k,r)$-counter\-exam\-ple, then all vertices of $\g$ other than $x$ have degree at least five.",2502.01451
lemma,"Let $k$ and $r$ be non-negative integers.  If $(\g,z,x,\psi)$ is a minimal $(k,r)$-counter\-exam\-ple, then there is no mixed edge $uv\in E(\g-\{z,x\})$.",2502.01451
lemma,"Let $k$ and $r$ be non-negative integers.  If $(\g,z,x,\psi)$ is a minimal $(k,r)$-counter\-example, then either $\tau(v)>0$ for every $v\in V(\g)\setminus\{x,z\}$ and $\psi$ directs all edges not incident with $x$ away from $z$, or $\tau(v)<0$ for every $v\in V(\g)\setminus\{x,z\}$ and $\psi$ directs all edges not incident with $x$ towards $z$.",2502.01451
lemma,"Let $(G,\beta)$ be a $\Z$-bordered graph without a nowhere-zero flow and with no edges of multiplicity greater than one.  \item If $G=K_4$, then $\beta(v)=0$ for every $v\in V(G)$. \item If $|V(G)|=5$ and $G$ has at most two non-edges, then $G$ consists of a copy $H$ of $K_4$ together with a vertex $v$ of degree two with neighbours $v_1,v_2 \in V(H)$, $\beta(v)=\beta(v_1)=\beta(v_2)\neq 0$, and $\beta(x)=0$ for each $x\in V(G)\setminus \{v,v_1,v_2\}$. \item If $|V(G)|=6$ and $G$ has at most four non-edges and minimum degree at least two, then $G$ consists of two copies of $K_4$ whose intersection is $K_2$ and $\beta(x)=0$ for every $x\in V(G)$.",2502.01451
lemma,"For any integer $k\ge 7$, $\CC_{k,0}\subseteq \CC'_{k,0}$.",2502.01451
theorem,"\th Let $\G\rightrightarrows M$ be a proper Lie groupoid acting along $\alpha\colon P\to M$ given by $\mu$, where $\G$, $M$ and $P$ are compact. Denote by $\fol$ the singular foliation on $P$ induced by the orbits of the action. Then for any $g$ transversely $\mu$-invariant Riemannian metric on $P$ (see \th\ref{D: mu-transversly invariant}) there exist a Riemannian metric $Q$ on $\G$ such that for the Riemannian metric $\widehat{g}_t = (\frac{1}{t}Q\oplus g)|_{\G\times_M P}$ we have a Riemannian submersion \[ \bar{t}\colon (\G\times_M P,\widehat{g}_t)\to P. \]",2502.01460
theorem,"\th Let $\G\rightrightarrows M$ be a Lie groupoid acting along $\alpha\colon P\to M$, where $\G$, $M$ and $P$ are compact. Denote by $\fol$ the singular foliation on $P$ induced by the orbits of the action. Then there exist Riemannian metrics $Q$ on $\G$, and $g$ on $P$ for which there exists a family of Riemannian metrics $\{g_t\}_{t\in (0,\infty)}$  on $P$ such that $(P,g_t)$ converges in the Gromov-Hausdorff sense to $(P/\fol,d_g^\ast)$ as $t\to \infty$, and    K(g_t) = K(\widehat{g}_t)+3\|A(\cdot,\cdot)\|^2.   Here, $A$ denotes the the $A$-tensor of the submersion $\bar{t}\colon \G\times_M P\to P$ (\,see \cite{GromollWalschap}).",2502.01460
definition,"\th A \emph{singular Riemannian foliation} $\fol=\{L_p\mid p\in M\}$ on a Riemannian manifold $(M,g)$ is a partition of $M$ into injectively immersed submanifolds $L_p$, called leaves, such that it is: [(i)] \item a smooth singular foliation: There exists a family $\{X_\alpha\}$ of smooth vector fields of $M$ such that for any $p\in M$ with $p\in L_p$ we have $\mathrm{Span}\{X_\alpha(p)\} = T_p L_p$; \item a transnormal system: For any geodesic $\gamma\colon [0,1]\to M$ with $\gamma'(0)\perp T_{\gamma(0)} L_{\gamma(0)}$, we have that $\gamma'(t)\perp T_{\gamma(t)} L_{\gamma(t)}$.",2502.01460
definition,"\th The Riemannian metric $\eta^P$ is called \emph{transversely $\mu$-invariant} if for the  normal representation $N(\mu)$ of the action groupoid $(\G\times_M P)_L \rightrightarrows L$ on $\nu(L)\to L$  is by isometries, i.e. for $(g,p)\in (G\times_M P)_L$ the map $N(\mu)_{(g,p)}\colon \nu_{p}(L) \to \nu_{\mu(g,p)}(L)$ is an isometry.",2502.01460
definition,"Given $\G\rightrightarrows M$ a proper Lie groupoid acting on \linebreak$\alpha\colon  P\to M$ via $\mu$, an $\eta^{(1)}$ a $1$-metric on $\G$ induced by some $2$-metric, and a $\mu$-transversaly invariant metric $\eta^P$ on $P$, we define the \emph{Cheeger deformation} of $\eta^P$ with respect to $\eta^{(1)}$ as the Riemannian metric $\eta_\varepsilon$ on $P$ induced by the Riemannian submersion $(\G\times_{M} P,\widehat{\eta}_\varepsilon)\to P$ as in \th\ref{T: source map for the action groupoid is a Riemannian submersion}.",2502.01460
proof,"Recall  that $\overline{s}(g,q) = q$. Thus:   \overline{s}^{-1}(p) = \{(g,p)\mid s(g) = \alpha(p) \} =\{(g,p)\mid g\in s^{-1}(\alpha(p))\}= s^{-1}(\alpha(p))\times \{p\}.",2502.01460
proof,"Consider $(X,0)\in \kernel D\overline{s}$, and set $(\kernel D\overline{s})^\perp$ the orthogonal complement to $\kernel D\overline{s}$ with respect to $\eta_\varepsilon$. Consider $(U_1,A_1),(U_2,A_2)\in (\kernel D\overline{s})^\perp$. This implies that for $(Y,0)\in \kernel D\overline{s} = \kernel Ds\times \{0\}$, and $i=1,2$ we have \[ 0 = \widehat{\eta}_\varepsilon \big((Y,0),(U_i,A_i)\big) = \frac{1}{\varepsilon}\eta^{(1)}(Y,U_i)+\eta^{(P)}(0,A_i) = \frac{1}{\varepsilon}\eta^{(1)}(Y,U_i). \] From this it follows that $U_1,\: U_2\in (\kernel Ds)^\perp$, where $(\kernel Ds)^\perp$ is the orthogonal complement of $\kernel Ds$ with respect to $\eta^{(1)}$. Then, since $s\colon (\G,\eta^{(1)})\to M$ is a Riemannian submersion we obtain   \Lie_{(X,0)}\left(\frac{1}{\varepsilon}\eta^{(1)}+\eta^P\right )\big((U_1,A_1),(U_2,A_2)\big) =& \frac{1}{\varepsilon}\Lie_{X}(\eta^{(1)})(U_1,U_2)+\Lie_0(\eta^P)(A_1,A_2)\\ =&\frac{1}{\varepsilon}\Lie_{X}(\eta^{(1)})(U_1,U_2)\\ =&0.   Thus we conclude by \cite[Theorem~1.2.1]{GromollWalschap}, that $\overline{s}$ is a Riemannian submersion with respect to $\widehat{\eta}_\varepsilon$.",2502.01460
proof,"Recall that for $(g,p)\in\G\times_M P$ we have $\overline{t}(g,p) = \mu(g,p)$. Observe that \linebreak$\alpha(\mu(i(g),p)) = t(i(g)) = s(g)$, and thus $(g,\mu(i(g),p))\in \G\times_M P$.   Consider $g\in t^{-1}(\alpha(p))$, then    \overline{t}\big(g,\mu(i(g),p)\big) = \mu\big(g, \mu(i(g),p)\big) = \mu\big(\m(g,i(g)),p\big) = \mu(\1_{t(g)},p)= \mu(\1_{\alpha(p)},p) = p.   Thus $\{(g,\mu(i(g),p))\mid g\in t^{-1}(\alpha(p))\}\subset \overline{t}^{-1}(p)$.  Now consider $(g,q)\in \overline{t}^{-1}(p)$. That is $s(g) = \alpha(q)$, and $\mu(g,q) = p$. So we have $\mu(i(g),p) = \mu(i(g),\mu(g,q))$, but observe that   \[ \mu(i(g),\mu(g,q))=\mu\big(\mu(i(g),g),p\big)= \mu(\1_{s(g)},q) = q. \]  This implies that $(g,q) = (g,\mu(i(g),p))$, and thus  \[ \overline{t}^{-1}(p) = \{(g,\mu(i(g),p))\mid g\in t^{-1}(\alpha(p))\}. \]  Last we observe that the set $\{\mu(i(g),p)\mid g\in t^{-1}(\alpha(p))\} = \Or_\G(p) = \overline{t}(\overline{s}^{-1}(p))$: \[ \overline{t}(\overline{s}^{-1}(p)) = \overline{t}(s^{-1}(\alpha(p))\times\{p\}) = \{\mu(g,p)\mid g\in s^{-1}(\alpha(p))\}. \] Now observe that $i(i(g)) = g$; this follows for example from the uniqueness of the inverses (see \cite[Ex. 1.2, p. 9]{Meinrenken2017}, and  use the fact that the isotropy groups are Lie groups). Thus writing $h = i(g)$ we have that $t(h) = t(i(g)) = s(g) = \alpha(p)$ and  \[ \{\mu(g,p)\mid g\in s^{-1}(\alpha(p))\} = \{\mu(i(h),p)\mid h\in t^{-1}(\alpha(p))\}. \] So we conclude that  \[ \overline{t}^{-1}(p) = \{(g,\mu(i(g),p))\mid g\in t^{-1}(\alpha(p))\} = t^{-1}(\alpha(p))\times L_p. \]",2502.01460
proof,"We recall that for the partition $\fol_P = \{L_p\mid p\in P\}$ of $P$ given by the orbits of $\G\times_M P\rightrightarrows P$, the Riemannian metric $\eta^P$ gives a singular Riemannian foliation $(P,\eta^P,\fol_P)$.  We consider $(X,W)\in \kernel D_gt\times T_pL_p$. Also we consider the normal bundle $\nu(L_p)\to L_p$ of $L_p$ using the metric $\eta^{P}$, and denote by $(\eta^P)_p^\perp = \eta^P_p|_{T L_p^\perp}$ the Riemannian metric given by the restriction of $\eta^P$ to the normal spaces of the $\G \times_M P$-orbits.We now denote by $(\kernel Dt)^\perp$ the orthogonal complement of $\kernel Dt$ with respect to $\eta^{(1)}$, and by  $(\eta^{(1)})^\perp$ the restriction of $\eta^{(1)}$ to $(\kernel Dt)^\perp$.   We observe that along $W\in TL_p$, the Riemannian metric $(\eta^P)^\perp$ is invariant: i.e. \linebreak$\Lie_W((\eta^P)^\perp) = 0$, since the $\G\times_M P$-orbits in $P$ are locally $\eta^P$-equidistant. Also we observe, that since $t\colon (\G,\eta^{(1)})\to M$ is a Riemannian submersion, we have $\Lie_X((\eta^{(1)})^\perp) =0$. By observing that for the $\widehat{\eta}_\varepsilon$-orthogonal complement of $(\kernel D\overline{t})$, we have $(\kernel D\overline{t})^\perp = (\kernel Dt)^\perp \times \nu(L_p)$, it follows that  \[ \Lie_{(X,W)}(\widehat{\eta}_\varepsilon)^\perp = \frac{1}{\varepsilon}\Lie_X((\eta^{(1)})^\perp)+\Lie_W ((\eta^{(P)})^\perp) = 0. \] Thus we conclude by \cite[Theorem~1.2.1]{GromollWalschap} that $\overline{t}\colon (\G\times_M, \widehat{\eta}_\varepsilon)\to P$ is a Riemannian submersion.",2502.01460
proof,"By \th\ref{C: Kernel of bar(t)}, we have that $\V(\1_{\alpha(p)},p) = \kernel D t(\1_{\alpha(p)})\times T_pL_p$.  Recall that $L_p = \overline{t}(\overline{s}^{-1}(p)) = \{\overline{t}(g,p)\mid g\in s^{-1}(\alpha(p))\}$, thus we have that $TL_p = D\overline{t}(T\overline{s}^{-1}(p))$.  Thus we see that for any $X\in \kernel D_{\1_{\alpha(p)}} s = T_{\1_{\alpha(p)}}\overline{s}^{-1}(\alpha(p))$, that $X^\ast(p) = -D_{\1_{\alpha(p)}}\overline{t}(X,0)\in T_pL_p$.  We consider $\gamma\colon I\to s^{-1}(\alpha(p))$ a curve with $\gamma(0) = \1_{\alpha(p)}$ and $\gamma'(0) = X$ in \linebreak$\kernel Ds(\1_{\alpha(p)})$. Set $\widehat{\gamma}(t) = (\gamma(t),p)$. We point  that for any $t\in I$ $s(\gamma(t))= \alpha(p)$, and thus $\widehat{\gamma}(t) \in \G\times_M P$ for any $t\in I$. Moreover, $\widehat{\gamma}'(0) = (X,0)$. So the set $\{(x,X^\ast(p))\mid x\in \kernel Ds(\1_{\alpha(p)})\}$ spans $\kernel D_{(\1_{\alpha(p)},p)} \overline{t}$.",2502.01460
proof,"We consider a vector $(Y,X)\in T_{(\1_{\alpha(p)},p)}\, \G\times_M P$. We denote by $X^\top$ the component of $X$ tangent to the orbit $L_p\supset P$ of the action groupoid, and $X^\perp$ the complementary component of $X$ normal to $L_p$ with respect to $\eta^P$. In this way $X = X^\top+X^\perp$ in a unique way. But since $L_p = \overline{t}(\overline{s}^{-1}(p))$, then there exists $x\in \kernel D_{\1_{\alpha(p)}}s$, such that $X^\ast (p) = -D_{\1_{\alpha(p)}}\overline{t}(x,0) = X^\top$. And thus $X= X^\ast(p)+X^\perp$.   The vector $(Y,X^\ast(p)+X^\perp)$ is $(\frac{1}{\varepsilon}\eta^{(1)}+\eta^P)$-horizontal if and only if for all $z\in \kernel D_{\1_{\alpha(p)}} s$, we have   0 &=  \left(\frac{1}{\varepsilon}\eta^{(1)}+\eta^P\right)\Bigl((Y,X^\ast(p)+X^\perp),(z,Z^\ast(p))\Bigr)\\ &= \frac{1}{\varepsilon}\eta^{(1)}(Y,z)+\eta^P(X^\ast(p),Z^\ast(p))\\ & = \frac{1}{\varepsilon}\eta^{(1)}(Y,z)+\eta^{(1)}(\Sh(p)(x),z)\\ &= \eta^{(1)}\left(\frac{1}{\varepsilon}Y+\Sh(p)(x),z\right).    We write $Y = Y^\top+Y^\perp$, where $Y^\top\in \kernel D_{\1_{\alpha(p)}}s$ and \linebreak$Y^\perp\in \bigl(\kernel D_{\1_{\alpha(p)}}s\bigr)^\perp$ with respect to $\eta^{(1)}$. Since $\Sh(p)(x)\in \kernel D_{\1_{\alpha(p)}}s$, we conclude that for all $z\in \kernel D_{\1_{\alpha(p)}}s$ \[ 0=\eta^{(1)}\left(\frac{1}{\varepsilon}Y+\Sh(p)(x),z\right) = \eta^{(1)}\left(\frac{1}{\varepsilon}Y^\top+\Sh(p)(x),z\right). \]  Thus we conclude that $Y^\top = -t\Sh(p)(x)$, and thus the claim follows by setting $\xi = X^\perp$ and $\zeta = Y^\perp$.",2502.01460
proof,"We take $x,y\in  \kernel D_{\1_{\alpha(p)}} s$ with  \[-D_{(\1_{\alpha(p)},p)}\overline{t}(x,0) = X(p) = -D_{(\1_{\alpha(p)},p)}\overline{t}(y,0) \] for all $p\in P$. This is equivalent to  $x-y\in \kernel D_{(\1_{\alpha(p)},p)}\,\overline{t}$. Moreover since $L_p =\overline{t}(\overline{s}^{-1}(p)) = \overline{t}(s^{-1}(\alpha(p))\times\{p\})$, we have $T_p L_p = D_{(\1_{\alpha(p)},p)}\,\overline{t}(\kernel D_{\1_{\alpha(p)}} s\times \{0\})$. This implies that $x-y\in \kernel D_{\1_{\alpha(p)}} s$. Then we get that for any $z\in \kernel D_{\1_{\alpha(p)}} s$ the following \[ \eta^{(1)}(\Sh(p)(x-y),z) = \eta^{(P)}(-D_{(\1_{\alpha(p)},p)}\overline{t}(x-y,0), Z^\ast(p)) = 0. \] This implies that $\Sh(p)(x) = \Sh(p)(y)$. Thus we obtain that    -D_{(\1_{\alpha(p)},p)}\overline{t}(y+\varepsilon\Sh(p)(y),0) =&  -D_{(\1_{\alpha(p)},p)}\overline{t}(y+\varepsilon\Sh(p)(y),0)- D_{(\1_{\alpha(p)},p)}\overline{t}(x-y,0)\\ =& -D_{(\1_{\alpha(p)},p)}\overline{t}(y+x-y+\varepsilon\Sh(p)(y),0)\\ =& -D_{(\1_{\alpha(p)},p)}\overline{t}(x+\varepsilon\Sh(p)(y),0)\\ =& -D_{(\1_{\alpha(p)},p)}\overline{t}(x+\varepsilon\Sh(p)(x),0).",2502.01460
proof,"Consider any curve  $\gamma\colon I\to \alpha^{-1}(\alpha(p))$   with $\gamma(0) = p$ and $\gamma'(0)= \xi$. Then the curve $\widehat{\gamma}\colon I\to \G\times_M P$ given by $\widehat{\gamma}(r) = \big(\1_{\alpha(p)},\gamma(r)\big)$ is a curve in $\G\times_M P$, since $s(\1_{\alpha(p)}) =\alpha(p)= \alpha(\gamma(r))$, and $\widehat{\gamma}(0) = (\1_{\alpha(p)},p)$. Moreover, we have $\widehat{\gamma}'(0) =(0,\xi)$.  Now we simply evaluate $\overline{t}$ along $\widehat{\gamma}$:   \overline{t}(\widehat{\gamma}(r)) &= \mu(\1_{\alpha(p)},\gamma(r))\\ &= \mu(\1_{\alpha(\gamma(\ell))},\gamma(\ell))\\ &= \gamma(\ell).  Thus we conclude that  \[ D_{(\1_{\alpha(p)},p)}\overline{t}(0,\xi) = \frac{d}{dr} \overline{t}(\1_{\alpha(p)},\gamma(r))|_{r=0}= \frac{d}{dr} \gamma(r)|_{r=0} = \xi. \] Since $\nu_p (L_p)\subset T_p\, \alpha^{-1}(\alpha(p))$, for $\xi\in \nu_p (L_p)$ we may find a curve as above. This proves the result.",2502.01460
proof,"We consider $X\in T_p P$, and assume that $X = X^\ast(p)+X^\perp$ for some $x\in \kernel D_{\1_{\alpha(p)}} s$. Then we have    \Ch^{-1}_{\varepsilon}(p) (X) &= -D_{(\1_{\alpha(p)},p)} \overline{t}(x+\varepsilon \Sh(p)(x),0)+X^\perp\\ &=D_{(\1_{\alpha(p)},p)} \overline{t}(-x-\varepsilon \Sh(p)(x),0)+X^\perp\\ & = D_{(\1_{\alpha(p)},p)} \overline{t}(-x-\varepsilon \Sh(p)(x),X^\perp),   since by our hypothesis $\nu_p(L_p)\subset T_p\, \alpha^{-1}(\alpha(p))$ and \th\ref{L: target map of groupoid action is the identity on the normal part of the orbits}, we have \linebreak$D_{(\1_{\alpha(p)},p)}\overline{t}(0,X^\perp) = X^\perp$. Now we recall that by \th\ref{L: Vertical space of target map of action Lie groupoid}, we have that  \[ D_{(\1_{\alpha(p)},p)} \overline{t}(x,X^\ast(p)) =0. \] Thus we conclude that    \Ch^{-1}_{\varepsilon}(p) (X) &=D_{(\1_{\alpha(p)},p)} \overline{t}(-x-\varepsilon \Sh(p)(x),X^\perp) + D_{(\1_{\alpha(p)},p)} \overline{t}(x,X^\ast(p))\\ &= D_{(\1_{\alpha(p)},p)} \overline{t}(-x-\varepsilon \Sh(p)(x)+x,X^\ast(p)+X^\perp)\\ &= D_{(\1_{\alpha(p)},p)} \overline{t}(-\varepsilon\Sh(p)(x), X)\\ & =D_{(\1_{\alpha(p)},p)} \overline{t}\big( h(p)(X)\big).",2502.01460
proof,"By \th\ref{T: h is horizontal lift of cheeger}, writing $X=X^\ast(p)+X^\perp$ and $Y= Y^\ast(p)+Y^\perp$ for some $x,y\in \kernel D_{\1_{\alpha(p)}}s$, and using that \[ D_{(\1_{\alpha(p)},p)}\overline{t}\colon (\Hor(\1_{\alpha(p)},p),\widehat{\eta}_\varepsilon) \to (T_p P,\eta_\varepsilon) \] is an isometry, we have that    \eta_\varepsilon(\Ch^{-1}_\varepsilon(p)(X),\Ch^{-1}_\varepsilon(p)(Y)) &= \eta_\varepsilon\Big(D_{(\1_{\alpha(p)},p)}\overline{t}\big(h(p)(X)\big),D_{(\1_{\alpha(p)},p)}\overline{t}\big(h(p)(Y)\big)\Big)\\ &= \widehat{\eta}_\varepsilon \big(h(p)(X),h(p)(Y)\big)\\ &= \left(\frac{1}{\varepsilon}\eta^{(1)}+\eta^{(P)}\right)\Big(\big(-\varepsilon\Sh(p)(x),X\big),\big(-\varepsilon\Sh(p)(y),Y\big)\Big)\\ & = \left(\frac{1}{\varepsilon}\eta^{(1)}\Big(\varepsilon\Sh(p)(x),\varepsilon\Sh(p)(y)\Big)\right)+\eta^P(X,Y)\\ & = \eta^{(1)}\Big(\Sh(p)(x),\varepsilon\Sh(p)(y)\Big)+\eta^P (X,Y)\\ &= \eta^P\Big(X,\varepsilon(\Sh(p)(y))^\ast(p)\Big)+\eta^P(X,Y)\\ & = \eta^P\Big(X,\varepsilon(\Sh(p)(y))^\ast(p)+Y^\ast(p)+Y^\perp\Big)\\ & = \eta^P\Big(X,(y+\varepsilon(\Sh(p)(y))^\ast(p)+Y^\perp\Big)\\ &= \eta^P\big(X,\Ch^{-1}_\varepsilon(p)(Y)\big).   Now taking $\tilde{X}= \Ch_\varepsilon(p)(X)$ and $\tilde{Y} = \Ch_\varepsilon(p)(Y)$ we obtain   \eta_\varepsilon(X,Y) &= \eta_\varepsilon(\Ch^{-1}_\varepsilon(p)(\tilde{X}),\Ch^{-1}_\varepsilon(p)(\tilde{Y}))\\ &= \eta^P(\tilde{X},\Ch^{-1}_\varepsilon(p)(\tilde{Y}))\\ & = \eta^P(\Ch_\varepsilon(p)(X),Y).",2502.01460
proof,"We have that as $\varepsilon\to \infty$, then the space $(\G\times_M P,\frac{1}{\varepsilon}\eta^{(1)}+\eta^P)$ converges in the Gromov-Hausdorff sense to $(P,\eta^P)$. In particular the length of  vectors in $\kernel_{\1_{\alpha(p)}} s\times \{0\}$ goes to  $0$ as $\varepsilon \to \infty$. But since this vectors span the tangent spaces of the ($\G\times_M P\rightrightarrows P)$-orbits in $P$, then we conclude that the length of the vectors tangent to the orbits with respect to $\eta_\varepsilon$ goes to $0$. Now observe that for a vector $\xi\in T_pP$ perpendicular to the orbit $L_p$, we have by \th\ref{L: target map of groupoid action is the identity on the normal part of the orbits} and \th\ref{T: cheeger deformation controlled by cheeger tensor} that \[ \eta_\varepsilon(\xi,\xi) = \eta^{P}\Big(\Ch_\varepsilon(p)(\xi),\xi\Big) = \eta^{P}(\xi,\xi). \] This implies that the foliation $\fol = \{L_p\mid L_p \mbox{ is } (\G\times_M P\rightrightarrows P)-\mbox{orbit}\}$ is a singular Riemannian foliation with respect to $\eta_\varepsilon$. Thus the distance between the leaves of $\fol$ is constant with respect to $\varepsilon$. Thus we conclude that $(P,\eta^\varepsilon)$ converges in the Gromov-Hausdorff sense to $(P/\fol,d_{\eta^{P}}^\ast)$, where $d_{\eta^{P}}^\ast$ is the metric induced by the Riemannian distance $d_{\eta^{P}}$ on $P$.  Observe that the tensor $\Ch^{-1}_\varepsilon(p)$ converges in the $C^\infty$-topology to the identity as $\varepsilon\to 0$. Thus the second claim follows.",2502.01460
proof,"Observe that since $v$ and $w$ are linearly independent, so are $\Ch^{-1}(p)(v)$ and $\Ch^{-1}(p)(w)$. Taking $\widehat{\eta}_\varepsilon = \frac{1}{\varepsilon}\eta^{(1)}+\eta^{P}$, from \th\ref{T: h is horizontal lift of cheeger}, and \th\ref{T: ONeills formula} we have that    K_{\eta_\varepsilon}(\Ch^{-1}_\varepsilon(p)(v),\Ch^{-1}_\varepsilon(p)(w)) =& K_{\widehat{\eta}_\varepsilon}(h(p)(v),h(p)(w))\\  &+ 3\|A_{h(p)(v)} h(p)(w)\|^2_{\widehat{\eta}_\varepsilon}.   We now apply the Gauss-formula to compute that  K_{\widehat{\eta}_\varepsilon}\big(h(p)(v),h(p)(w)\big)=&K_{\widehat{\eta}_\varepsilon}\big((-\varepsilon \Sh(p)(v),v),(-\varepsilon \Sh(p)(w),w)\big)\\ =&\varepsilon^3 K_{\eta^{(1)}}\big(\Sh(p)(v),\Sh(p)(w)\big)+K_{\eta^{P}}(v,w)\\ &+\left(\frac{1}{\varepsilon}\eta^{(1)}+\eta^{P}\right)\bigg(\II_\varepsilon\big((-\varepsilon\Sh(p)(v),v\big),(-\varepsilon\Sh(p)(v),v)\big),\\ &\;\II_\varepsilon\big((-\varepsilon\Sh(p)(w),w),(-\varepsilon\Sh(p)(w),w)\big)\bigg)\\ &-\left(\frac{1}{\varepsilon}\eta^{(1)}+\eta^{P}\right)\bigg(\II_\varepsilon\big((-\varepsilon\Sh(p)(v),v\big),(-\varepsilon\Sh(p)(w),w)\big),\\ &\;\II_\varepsilon\big((-\varepsilon\Sh(p)(v),v),(-\varepsilon\Sh(p)(w),w)\big)\bigg)  Combining these two expressions we obtain the desired result.",2502.01460
proposition,[Proposition~3.5.5 in \cite{delHoyo2013}]\th There is a $1$--$1$ correspondence between linear representations of a Lie groupoid $G\rightrightarrows M$ and VB-groupoids $(\Gamma\rightrightarrows E) \to (\G\rightrightarrows M)$  with trivial core.,2502.01460
proposition,"Given $f\colon M\to N$ a submersion, a $0$-metric on the submersion groupoid $M\times_N M\rightrightarrows M$ is a Riemannian metric $\eta^{(0)}$ making $f$ into a Riemannian submersion (see \cite[Example 3.4]{delHoyoFernandes2018}.",2502.01460
proposition,"[Proposition 3.8 in \cite{delHoyoFernandes2018}]\th Given a Lie groupoid $\G\rightrightarrows M$, a $1$-metric $\eta^{(1)}$, there exists a Riemannian metric $\eta^{(0)}$ on $M$ such that: [(i)] \item The source and target maps $s,t\colon \G\to M$ are Riemannian submersions, and the submanifold $\1(M)\subset \G$ is a totally geodesic submanifold. \item The foliation $\fol_{\G}$ on $M$ induced by the orbits of the groupoid is a singular Riemannian foliation with respect to $\eta^{(0)}$. \item $\eta^{(0)}$ is  a $0$-metric.",2502.01460
proposition,"\th If $G\rightrightarrows M$ is a foliation groupoid and $\eta^{(0)}$ is a $0$-metric, then there exists a $1$-metric $\eta^{(1)}$ on $\G$, such that $\eta^{(0)}$ is  the metric induced in \th\ref{P: 1-metrics induce 0-metrics} by $\eta^{(1)}$.",2502.01460
proposition,[Proposition 3.16 in \cite{delHoyoFernandes2018}]\th Let $\G \rightrightarrows M$ be a Lie groupoid. A $2$-metric $\eta^{(2)}$ on $\G^{(2)}$ induces a $1$-metric $\eta^{(1)}$ on $\G$.,2502.01460
lemma,"Consider $\mu$ and  action of the proper Lie groupoid $\G\rightrightarrows M$ on $\alpha\colon P\to M$, and the action groupoid $\G\times_M P \rightrightarrows P$. Denote by $\overline{s}\colon \G\times_M P\to P$, and $s\colon \G\to M$ the source maps of $\G\times_M \rightrightarrows P$ and $\G\rightrightarrows P$ respectively. Then $\overline{s}^{-1}(p) = s^{-1}(\alpha(p))\times\{p\}$.",2502.01460
lemma,"\th Let the proper Lie groupoid $\G\rightrightarrows M$ act effectively and smoothly on $\alpha\colon P\to M$. Then we have  \[ 	\V(\1_{\alpha(p)},p) = \{(x,X^\ast(p))\mid x\in \kernel D_{\1_{\alpha(p)}} s\}. \]",2502.01460
lemma,"\th Let $\G\times_M P\rightrightarrows P$ be the groupoid action of a Lie groupoid action of the proper Lie groupoid $\G\rightrightarrows M$ on $\alpha\colon P\to M$. For $X\in TP$, such that $X(p)\in T_p L_p$ for all $p\in P$, the Cheeger tensor $\Ch^{-1}_\varepsilon(p)$ does not depend on the choice of $x\in \kernel D_{\1_{\alpha(p)}}\, s$ such that $-D_{\1_{\alpha(p)}}\overline{t}(x,0) = X(p)$.",2502.01460
lemma,"\th Consider a proper Lie groupoid  $\G\rightrightarrows M$ acting  on $\alpha\colon P\to M$ via $\mu\colon \G\times_M P \to P$. Let $\eta^{(1)}$ be a $1$-metric  on $\G$, and consider $\eta^P$ a $\G$-invariant Riemannian metric on $P$. Moreover, assume that $\nu_p(L_p)\subset T_p\, \alpha^{-1}(\alpha(p))$. Then for $\xi\in \nu_p (L_p)$ we have that  \[ D_{(\1_{\alpha(p)},p)}\overline{t}(0,\xi) = \xi. \]",2502.01460
example,"[Lie groups] A Lie group $\G=G$ is a Lie groupoid  $\G\rightrightarrows \{\ast\}$, with the set of objects a point. In this example, the unit map $\1\colon \{\ast\}\to \G$ is identify with the neutral element of $G$, the multiplication and inversion maps of the Lie groupoid are given by the multiplication and inverse maps of then Lie group. Moreover, there is only one orbit $L_\ast = \{\ast\}$, and the isotropy groups are the Lie group $G$.",2502.01460
example,"[Manifolds] A smooth manifold $M$, can be considered as the arrow and object space of a Lie gropoid $\G\rightrightarrows M$ as follows: We set $\G = M$, and the maps $s$, $t$, $\1$, and  $i$ to be the identity map $\Id_M\colon M\to M$. Observe that $\G^{(2)} = \{(p,q)\mid p= s(p)= t(q) = q\} = \Delta\subset M\times M$. By setting $\m = \proj_1\colon \G^{(2)} = \Delta\to M=\G$, the projection onto the first factor, we have that $\G\rightrightarrows M$ is a Lie groupoid. For any $p\in M$ we have $L_p = \{p\}$ and the isotropy groups are trivial, $\G_p = \{\1_p\}$.",2502.01460
example,"[Pair groupoid] Given a smooth manifold $M$, the \emph{pair groupoid of $M$} $\G\rightrightarrows M$ is defined by setting $\G = M\times M$, $s= \proj_1$ the projection onto the $1$st factor, $t=\proj_2$ the projection onto the $2$nd factor, $\1_p = (p,p)$, and $i(p,q) = (q,p)$. It remains to define the multiplication map. Observe that $\G^{(2)} = \{\big((p_3,p_2),(p_2,p_1)\big)\mid p_1,p_2,p_3\in M\}$, and we set $\m\big((p_3,p_2),(p_2,p_1)\big) = (p_3,p_1)$. For any $p\in M$ we have that the orbit is $L_p = \{M\}$, and the isotropy groups are trivial, $\G_p = \{(p,p)\}=\{\1_{p}\}$.",2502.01460
example,"[Submersion groupoid] Let $f\colon M\to N$ be a smooth submersion. The \emph{submersion groupoid of $f$}, denoted as $\G_f\rightrightarrows M$, is obtained by setting: \[ 	\G_f = M\times_N M = \{(p,q)\in M\times M\mid f(q) = f(p) \}, \] and $s,t\colon \G_f\to M$ by $s(p,q) = q$, $t(p,q) = p$, $i(p,q) = (q,p)$, and $\1\colon M\to \G_f$ as $\1_p = (p,p)$. Observe that  \[ \G_f^{(2)} = \left\{\big((p_3,p_2),(p_2,p_1)\big)\mid (p_3,p_2),(p_2,p_1)\in \G\right\}, \]  and we set $\m\big((p_3,p_2),(p_2,p_1)\big) = (p_3,p_1)$.  Here we have for any $p\in M$ that $L_p = t(\{(q,p)\in M\times M\mid q\in f^{-1}(p)\}) = f^{-1}(f(p))$, i.e. the orbits of $\G_f\rightrightarrows M$ is given by the fibers of the submersion $f$. Moreover $(\G_f)_p = \{\1_p\}$. When $N = \{\ast\}$, then the submersion groupoid $\G_f\rightrightarrows M$ is the pair groupoid.",2502.01460
example,"[Restriction groupoid] Let $\G\rightrightarrows M$ be a Lie groupoid, and let $S\subset M$ be a smooth submanifold $S\subset M$.  Since both $s$ and $t$ are submersions, we have that $s^{-1}(S)$ and $t^{-1}(S)$ are smooth submanifolds of $\G$. When $s^{-1}(S)\cap t^{-1}(S)$ is also a submanifold,  we can define the \emph{restriction groupoid} $\G_S\rightrightarrows S$ as follows: We set $\G_S = s^{-1}(S)\cap t^{-1}(S)$, with the structure maps given by setting  restricting the structure maps of $\G\rightrightarrows M$, to $\G_S$, $\G_S^{(2)}$, and $S$. For example, when  $U\subset M$ is an open subset,  $\G_U$ is an open subset of $\G$, and thus we can define the  restriction groupoid  $\G_U\rightrightarrows U$.  Observe that a subset  $S\subset M$  is a saturated subset if and only if  $s^{-1}(S)=t^{-1}(S)$. Thus we can define the restriction groupoid $\G_S\rightrightarrows S$ for saturated submanifold $S$, and the codimension of $\G_S$ in $\G$ is the same as the codimension of $S$ in $M$. Any leaf $L\subset M$ of $\G\rightrightarrows M$ is a saturated submanifold.",2502.01460
example,"[Tangent groupoid of a Lie groupoid] Given a Lie groupoid $\G\rightrightarrows M$ with structure maps $\{s,t,\1,i,\m\}$, we define the \emph{tangent groupoid} $T\G\rightrightarrows TM$, by setting the structure maps to be $\{s_\ast,t_\ast,\1_\ast,i_\ast,\m_\ast\}$, i.e. the derivatives of the structure maps of $\G\rightrightarrows M$.",2502.01460
example,"[Groupoid induced by a group action] Given $H$ a Lie group, $M$ a smooth manifold, and $\mu\colon H\times M\to M$ a smooth  group action of $H$ on $M$, we can encode the action in the \emph{groupoid induced by $\mu$},  $\G\rightrightarrows M$, as follows: We set $\G = H\times M$, and $s,t\colon \G\to M$ as $s(h,p) = p$, $t = (h,p) = \mu(h,p)$,  $i(h,p) = (h^{-1},\mu(h,p))$, and $\1\colon M\to \G$ as $\1_p = (e,p)$ where $e\in H$ is the neutral element of the group. Observe that $\G^{(2)} = \{((h_2,\mu(h_1,p)),(h_1,p))\mid p\in M,\ h_1,h_2\in H\}$. We set the multiplication map to be $\m \Big(\big(h_2,\mu(h_1,p)\big),(h_1,p)\Big) = (h_2h_1,p)$. Then $\G\rightrightarrows M$ is a Lie groupoid, and for $p\in M$ we have that the orbit of the Lie groupoid is the orbit of the group action, that is $L_p = H(p)$, and the isotropy groups of the Lie groupoid are the isotropy groupoids of the group action, i.e. $\G_p = H_p$.",2502.01460
example,"[Action groupoid] A left action of a Lie groupoid $\G\rightrightarrows M$ on $P$ along $\alpha\colon P\to M$ given by a map $\mu\colon \G\times_M P\to P$ induces a new Lie groupoid. We set the space of arrows to be $\G\times_M P$, the space of objects to be $P$, and define the source and target maps $\overline{s},\overline{t}\colon \G\times_M P\to P$ by setting $\overline{s}(g,p) = p$, and $\overline{t}(g,p) =\mu(g,p)$. The unit map $\overline{\1}\colon P\to \G\times_M P$ is given by $\overline{\1}_p = (\1_{\alpha(p)},p)$, and the inversion map $\overline{i}\colon \G\times_M P\to \G\times_M P$ as $\overline{i}(g,p) = (i(g),\mu(g,p))$. Moreover we have   (\G\times_M P)^{(2)} = \bigg\{\Big(\big(g_2,\mu(g_1,p)\big),(g_1,p)\Big)\mid& (g_2,g_1) \in \G^{(2)}\mbox{ and } (g_1,p)\in \G\times_M P\bigg\}.     We set the multiplication map $\overline{\m}\colon(\G\times_M P)^{(2)}\to \G$ as  \[ \overline{\m}\Big(\big(g_2,\mu(g_1,p)\big),(g_1,p)\Big) = \big(\m(g_2,g_1),p\big). \]  With these structure maps we have a Lie groupoid $\G\times_M P\rightrightarrows P$, called the \emph{action Lie groupoid}. Given $p\in P$ the orbit through $p$ is $L_p = \{\mu(g,p)\mid g\in s^{-1}(\alpha(p))\}$, and the isotropy groups are given by $(\G\times_M P)_p = \G_{\alpha(p)}\times \{p\}$.",2502.01460
example,"[Lie group actions as Lie groupoid actions] When we consider a Lie group $G=\G\rightrightarrows \{\ast\}$,  and a manifold $M$ with the trivial map $\alpha \colon M\to \{\ast\}$, then a Lie groupoid action of $\G\rightrightarrows \{\ast\}$ on $M$ along $\alpha$ is given by a group action $\mu\colon \G\times M\to M$. Moreover, the action groupoid of the action of $\G\rightrightarrows \{\ast\}$ on $M$ along $\alpha$ is the group action of $G$ on $M$.",2502.01460
example,"[Canonical Lie groupoid action]\th Given a Lie groupoid $\G\rightrightarrows M$, we define the \emph{canonical Lie groupoid action} of $\G\rightrightarrows M$ on $\Id\colon M\to M$ to be the map $\mu\colon \G\times_M M\to M $ given by  \[ \mu(g,s(g)) = t(g). \]",2502.01460
example,"[Left Lie groupoid action]\th Given a Lie groupoid $\G\rightrightarrows M$, we define the \emph{left Lie groupoid action} of $\G\rightrightarrows M$ on $t\colon \G\to M$, to be the map $\mu\colon \G\times_M \G\to M$ defined for $(g,h)\in \G^{(2)}$ as \[ \mu(g,h) = \m(g,h). \]",2502.01460
example,"A Lie groupoid $\G\rightrightarrows M$ together with its tangent groupoid $T\G\rightrightarrows TM$ and  the groupoid morphism $\pi\colon (T\G\rightrightarrows TM)\to \G\to M$ induced by the projections $\pi_{\G}\colon T\G\to \G$ and $\pi_M\colon TM\to M$, is a VB-groupoid.",2502.01460
example,"[Pair groupoid]\th Consider $M$ a compact manifold, and let $\G = M\times M\rightrightarrows M$ be the pair groupoid. Fix $g$ a Riemannian metric on $M$. We know observe that the pair groupoid is the submersion groupoid for the submersion $f\colon M\to \{\ast\}$. Moreover, the product metric $g\oplus g$ on $\G = M\times M$ is a $1$-metric. Since $M$ is compact, the pair groupoid $\G= M\times M\rightrightarrows M$ is a proper Hausdorff Lie groupoid. Thus by \cite[Theorem~4.13]{delHoyoFernandes2018} there exists a $2$-metric $\eta^{(2)}$ on $\G^{(2)}$ making the multiplication map $\m\colon (\G^{(2)},\eta^{(2)})\to (\G,g\oplus g)$, as well as the source and target maps $(\G^{(2)},\eta^{(2)})\rightrightarrows\G$ Riemannian submersions. From this example we see that the sectional curvature of a $1$-metric induced by a $2$-metric can be arbitrary.",2502.01460
theorem,"[Optimal type-II error of unitary subgroup hypothesis testing] For unitary subgroup hypothesis testing involving compact group $G$ and its subgroup $K$ with unitary representation $f$ and an error tolerance of $\epsilon$, the following holds,      \beta^{f}_{PAR}(\epsilon)     = \beta^{f}_{ICO}(\epsilon)      = \Bar{\beta}^{f}_{ICO}(\epsilon)      = (1-\epsilon)e^{-D_{\max} (\rho^f_{\mu_0}\|\rho^f_{\mu})}.  where $\rho^f_{\mu_0}$ and $\rho^f_{\mu}$ are performance operator of a representation $f$ on the Haar measure of group $G_0$ and $G$, respectively (cf.~Eq.~\eqref{eq:average performance state}).",2502.01464
theorem,"[General solutions]~ The optimal type-II error for unitary subgroup hypothesis testing of unitaries draw from $\mu$ and $\mu_{0}$ is given by,      e^{-D_{\max} (\rho^f_{\mu_0}\|\rho^f_{\mu})} = \min_{\eta\in\hat{G_0}_f}\frac{d_{\eta, G_0}}{\sum_{\lambda\in\hat G_f} d_\lambda n_{\eta, \lambda}},  where $\hat G_f$ and $\hat{G_0}_f$ denote the set of irreducible representation of group $G$ and $G_0$ appears in $f$, respectively; $d_\lambda$ and $d_{\eta, G_0}$ denote the dimensions of representation $\lambda$ and $\eta$, respectively; for fixed $\lambda,\eta$, $n_{\eta,\lambda}$ denotes the multiplicity of irreducible representation $\eta$ of group $G_0$ appears in an irreducible representation space corresponding to irreducible representation $\lambda$ of group $G$.",2502.01464
theorem,"[Optimal type-II error of unitary subgroup hypothesis testing] For unitary subgroup hypothesis testing involving compact group $G$ and its subgroup $G_0$ with unitary representation $f$ and an error tolerance of $\epsilon$, the following holds,  &\min_{|\psi\rangle\in {\cal H}\otimes{\cal K}} \min_{T:inv} \{  \Tr T {\cal T}_G( |\psi\rangle\langle \psi|) : \min_{g \in G_0} \Tr T f(g) |\psi\rangle\langle \psi| f(g)^\dagger \ge 1-\epsilon \} \\ =&\min_{T:ICO,inv} \{  \Tr T \rho_{\mu} : \min_{g \in G_0} \Tr T |f(g)\rangle\rangle \langle\langle f(g)| \ge 1-\epsilon \} \\ =&\min_{T:ICO} \{  \Tr T \rho_{\mu} : \min_{g \in G_0} \Tr T |f(g)\rangle\rangle \langle\langle f(g)| \ge 1-\epsilon \} \\ =&\min_{T:ICO} \{  \Tr T \rho_{\mu} :  \Tr T \rho_{\mu_0} \ge 1-\epsilon \} \\ =&\min_{T\ge 0} \{  \Tr T \rho_{\mu} :  \Tr T \rho_{\mu_0} \ge 1-\epsilon \} \\ =&(1-\epsilon) e^{-D_{\max} (\rho_{\mu_0}\|\rho_{\mu})}.",2502.01464
theorem,"[General solutions] The optimal type-II error for unitary subgroup hypothesis testing of unitaries draw from $\mu$ and $\mu_{0}$ is given by,  e^{D_{\max} (\rho_{\mu_0}\|\rho_{\mu})} = \max_{\eta} d_{\eta,G_0}^{-1}  \sum_{\lambda} d_\lambda n_{\eta,\lambda}.",2502.01464
theorem,"For unitary subgroup hypothesis testing involving compact group $G$ and its subgroup $G_0$ with unitary representation $f$, an error tolerance of $\epsilon$ and the irreducible space $U_\lambda$ corresponding to $f$ has the constraint \eqref{NMIY}, we have,  \min_{|\psi\rangle \in {\cal H}} \min_{T:inv} \{  \Tr T {\cal T}_G( |\psi\rangle\langle \psi|) : \min_{g \in G_0} \Tr T f(g) |\psi\rangle\langle \psi| f(g)^\dagger  \ge  1-\epsilon \} \le (1-\epsilon)\Big(\max_{\eta} d_{\eta,G_0}^{-1}  \sum_{\lambda:\eqref{NMIY} \hbox{ holds.}} d_\lambda n_{\eta,\lambda} \Big)^{-1}.",2502.01464
theorem,"Let $\eta_0$ be the optimal element in the sense of \eqref{BNX}. When the relation \eqref{NMIY}  holds for any $\lambda \in \hat{G}_f$ and the element $\eta=\eta_0 \in \hat{G}_0$, the optimal test in Theorem \ref{NMI} can be implemented by a parallel strategy without  any reference system.",2502.01464
proof,"We use the notation $%c_{\eta,\lambda} %\sqrt{n_{\eta,\lambda} (n_\lambda d-d_\lambda)} |v_{\eta,\lambda}\rangle:=  \frac{1}{n_\lambda}  |I_{n_{\eta,\lambda}}\rangle \rangle \otimes | I_{n_\lambda} \rangle\rangle$. %where $c_{\eta,\lambda}>0$ is the normalizing constant. and choose an orthonormal basis of ${\cal U}_{\eta,G_0}$ by $\{ |u_{j,\eta}\rangle \}_j$. We define the projection $P_{\eta} $ to the space spanned by $\{ |u_{j,\eta}\rangle|u_{j',\eta}\rangle  |v_{\eta,\lambda}\rangle \}_{\lambda,j,j'}$. We have  \rho_{\mu_0}= \bigoplus_{\eta} d_{\eta,G_0}^{-1}  %|u_{j,\eta}\rangle\langle u_{j,\eta}|  I_{\eta} \otimes I_{\eta} \otimes \sum_{\lambda,\lambda'} |I_{n_{\eta,\lambda}}\rangle \rangle  \langle \langle I_{n_{\eta,\lambda'}}| \otimes  | I_{n_\lambda} \rangle\rangle\langle\langle I_{n_{\lambda'}}| ,  and,  \rho_{\mu} =&\int_{G}|f(g)\rangle\rangle \langle\langle f(g)|\mu(dg) \notag\\ =&\bigoplus_{\lambda \in \hat{G}_f} d_\lambda^{-1} I_\lambda \otimes I_\lambda \otimes  | I_{n_\lambda} \rangle\rangle\langle\langle I_{n_\lambda}| \notag\\ =& \bigoplus_{\lambda} d_\lambda^{-1} (\bigoplus_{\eta}  I_\eta \otimes I_{n_{\eta,\lambda}})  \otimes (\bigoplus_{\eta'}  I_{\eta'} \otimes I_{n_{\eta',\lambda}})  \otimes | I_{n_\lambda} \rangle\rangle\langle\langle I_{n_\lambda}| \notag\\ =& \bigoplus_{\lambda} d_\lambda^{-1} \bigoplus_{\eta,\eta'}   I_\eta \otimes I_{\eta'} \otimes  I_{n_{\eta,\lambda}} \otimes I_{n_{\eta',\lambda}} \otimes | I_{n_\lambda} \rangle\rangle\langle\langle I_{n_\lambda}|    $\rho_{\mu_0}$ and $\rho_{\mu}$ are commutative $ P_\eta$. Also,  we have  \rho_{\mu_0}=  \rho_{\mu_0}\Big(\sum_\eta P_\eta\Big).  Thus, we have  e^{D_{\max} (\rho_{\mu_0}\|\rho_{\mu})} = \max_{\eta} e^{D_{\max} (\rho_{\mu_0}P_\eta\|P_\eta\rho_{\mu})}.  Since we have  \rho_{\mu_0}P_\eta =& d_{\eta,G_0}^{-1}  I_{\eta} \otimes I_{\eta} \otimes \sum_{\lambda,\lambda'} |I_{n_{\eta,\lambda}}\rangle \rangle \langle \langle I_{n_{\eta,\lambda'}}| \otimes  | I_{n_\lambda} \rangle\rangle\langle\langle I_{n_{\lambda'}}|  \\ \rho_{\mu}P_\eta =& I_\eta \otimes I_{\eta} \otimes  \bigoplus_{\lambda} d_\lambda^{-1} I_{n_{\eta,\lambda}} \otimes I_{n_{\eta,\lambda}} \otimes | I_{n_\lambda} \rangle\rangle\langle\langle I_{n_\lambda}| ,  we have  e^{D_{\max} (\rho_{\mu_0}P_\eta\|P_\eta\rho_{\mu})} = e^{D_{\max} (S_{\eta,1} \| S_{\eta,2} )}  where  S_{\eta,1}:=&d_{\eta,G_0}^{-1}  \sum_{\lambda,\lambda'} |I_{n_{\eta,\lambda}}\rangle \rangle \langle \langle I_{n_{\eta,\lambda'}}| \otimes  | I_{n_\lambda} \rangle\rangle\langle\langle I_{n_{\lambda'} }|  \\ S_{\eta,2}:=& \bigoplus_{\lambda} d_\lambda^{-1} I_{n_{\eta,\lambda}} \otimes I_{n_{\eta,\lambda}} \otimes | I_{n_\lambda } \rangle\rangle\langle\langle I_{n_\lambda}| .  % \YA{ % Here we could use the 1-dimensional projector $\kett{X_\eta}\braa{X_\eta}$, %  %     &e^{D_{\max} (S_{\eta,1} \| S_{\eta,2} )}= \frac{\tr[S_{\eta,1}^2]}{\tr[S_{\eta,1}S_{\eta,2}]} %     =\frac{d_{\eta,G_0}^{-2}\braa{X_\eta}\!\!\kett{X_\eta}^2}{ %     \sum_{\lambda:\eta}d_{\eta,G_0}^{-1}d_{\lambda}^{-1}\braa{X_\eta}\!\!\kett{X_\eta}^2}\\ %     =&\frac{d_{\eta,G_0}^{-1}}{ %     n_{\eta,\lambda}d_{\lambda}^{-1}} %  % } We define  the projection $P_{2,\eta}$ to the space spanned by $\{|v_{\eta,\lambda}\rangle\}_\lambda$. Since $S_{\eta,1}$ and  $S_{\eta,2}$ are commutative with $P_{2,\eta}$, we have  e^{D_{\max} (S_{\eta,1} \| S_{\eta,2} )} = e^{D_{\max} (S_{\eta,1} P_{2,\eta}\| S_{\eta,2} P_{2,\eta} )}.  We choose a vector $|y\rangle:=  \sum_{\lambda} y_\lambda |v_{\eta,\lambda}\rangle$. Then, we have  e^{D_{\max} (S_{\eta,1} P_{2,\eta}\| S_{\eta,2} P_{2,\eta} )} =&\max_{|y\rangle} \frac{\langle y| S_{\eta,1} P_{2,\eta} |y\rangle} {\langle y| S_{\eta,2} P_{2,\eta} |y\rangle} \\ =& \max_{|y\rangle} \frac{d_{\eta,G_0}^{-1} |\sum_{\lambda} y_\lambda n_{\eta,\lambda} |^2 }{ \sum_\lambda d_\lambda^{-1} n_{\eta,\lambda} |y_\lambda|^2} \\ =& d_{\eta,G_0}^{-1} \max_{|y\rangle} \frac{|\sum_{\lambda} d_\lambda^{-1} n_{\eta,\lambda} d_\lambda y_\lambda  |^2 }{ \sum_\lambda d_\lambda^{-1} n_{\eta,\lambda} |y_\lambda|^2} \\ \stackrel{(a)}{=} & d_{\eta,G_0}^{-1}  \max_{|y\rangle} \frac{ \sum_{\lambda} d_\lambda^{-1} n_{\eta,\lambda} d_\lambda^2 \sum_\lambda d_\lambda^{-1} n_{\eta,\lambda} |y_\lambda|^2 }{ \sum_\lambda d_\lambda^{-1} n_{\eta,\lambda} |y_\lambda|^2} \\ = & d_{\eta,G_0}^{-1}  \max_{|y\rangle} \sum_{\lambda} d_\lambda n_{\eta,\lambda} =  d_{\eta,G_0}^{-1}  \sum_{\lambda} d_\lambda n_{\eta,\lambda}.  where $(a)$ follows from Schwarz inequality for inner product $(x,y):= \sum_{\lambda} d_\lambda^{-1} n_{\eta,\lambda} \overline{x_\lambda} y_\lambda$ and choice $y_\lambda=d_\lambda$. Combining \eqref{VB1}, \eqref{VB2}, \eqref{VB3}, and \eqref{VB4}, we have,  e^{D_{\max} (\rho_{\mu_0}\|\rho_{\mu})} = \max_{\eta} d_{\eta,G_0}^{-1}  \sum_{\lambda} d_\lambda n_{\eta,\lambda}.",2502.01464
theorem,"The density $f_{p;\mu,\Sigma}$ of the wrapped Gaussian $\WG(p; \mu, \Sigma)$ exists and is:                                    &\forall x \in \P_d,~f_{p;\mu,\Sigma}(x) = \frac{g_{\mu,\Sigma}(\Vect_p(\Log_p(x))}{|J_p(\Log_p(x))|}                   where $g_{\mu, \Sigma}$ is the density of the multivariate Gaussian $\mathcal{N}(\mu, \Sigma)$ and $J_p(\cdot ) = \det(\mathrm{d} \Exp_p(\cdot))$ is the Jacobian determinant of the exponential map $\Exp_p$.",2502.01512
theorem,"[Wrapped CLT]          Let $(X_i)_{i \in \mathbb{N}^*}$ be a sequence of i.i.d. random variables on $\P_d$. We suppose that the sequence $(\Vect_{I_d}(\Log_{I_d}(X_i)))_{i \in \mathbb{N}^*}$ of random variables on $\R^{d(d+1)/2}$ admits a finite second order moment. We denote by $\mu$ the mean and by $\Sigma$ the covariance matrix of $\Vect_{I_d}(\Log_{I_d}(X_1))$. Then,      $$\left( \bigodot_{i = 1}^n (X_i \odot m^{-1})\right)^{\frac{1}{\sqrt{n}}} \xrightarrow[n \to \infty]{d} \WG(I_d, 0, \Sigma)$$      where $\xrightarrow[n \to \infty]{d}$ denotes the convergence in distribution and where $m = \Exp_{I_d}(\Vect_{I_d}^{-1}(\mu))$.",2502.01512
theorem,"[Change of variables]     Let $\mu$ be a non-negative measure. An $\Omega_{\mathcal{Y}}$-measurable function $g$ on $\mathcal{Y}$ is integrable with respect to the pushforward measure $f\#\mu$ if and only if the function $g \circ f$ is integrable with respect to the measure $\mu$. In this case, one has:     $$\int_{\mathcal{Y}} g(y) \mathrm{d}(f\#\mu)(y) = \int_{\mathcal{X}} (g \circ f )(x)\mathrm{d}\mu(x).$$",2502.01512
definition,"[Vectorization]          We start by defining the vectorization at identity for a symmetric matrix $u = [[u_{ij}]]$:                           \Vect_{I_d} \colon u \in T_{I_d} \P_d \mapsto &(u_{11}, \sqrt{2}u_{12}, u_{22}, \sqrt{2}u_{13}, \sqrt{2}u_{23}, u_{33} , \\             &\dots, \sqrt{2}u_{d-1,d}, u_{dd}) \in \R^{\nicefrac{d(d+1)}{2}}                   Then, for $p \in \P_d$, we define the vectorization at $p$:     $$\Vect_{p} \colon u \in T_{p} \P_d \mapsto \Vect_{I_d}(p^{-1/2}up^{-1/2}).$$",2502.01512
definition,"[Wrapped Gaussian]          Let $p \in \P_d$, $\mu \in \R^{\nicefrac{d(d+1)}{2}}$ and $\Sigma \in \P_{\nicefrac{d(d+1)}{2}}$. A random variable $X$ on $\P_d$ follows a wrapped Gaussian denoted $\WG(p; \mu, \Sigma)$ if      $$X = \Exp_p(\Vect_p^{-1}(\mathbf{t})),~ \mathbf{t} \sim \N(\mu, \Sigma).$$",2502.01512
definition,"[Logarithmic product]          Let $p,q \in \P_d$. The logarithmic product of $p$ and $q$ is defined as:     $$p \odot q = \exp\left(\log p + \log q \right).$$",2502.01512
definition,"Let $\theta_\alpha = (p_{\alpha}, \mu_{\alpha}, \Sigma_{\alpha}) \in \Theta$ and $\theta_\beta =(p_{\beta}, \mu_{\beta}, \Sigma_{\beta}) \in \Theta$ be two sets of parameters. Then, $\theta_\alpha$ and $\theta_\beta$ are equivalent, which we denote by $\theta_\alpha \cong \theta_\beta$, if they define the same wrapped Gaussian i.e.          $$\WG(p_{\alpha}; \mu_{\alpha}, \Sigma_{\alpha}) = \WG(p_{\beta}; \mu_{\beta}, \Sigma_{\beta}).$$      We denote by $[\theta_\alpha]$ the equivalence class of $\theta_\alpha$:     $$[\theta_\alpha] = \left\{\theta  = (p', \mu', \Sigma') \mid \theta \cong \theta_\alpha\right\}.$$",2502.01512
definition,"[Representative of an equivalence class]          We choose as representative of the class $[\theta]$, the tuple of parameters $\theta^\text{min} = (p^\text{min}, \mu^\text{min}, \Sigma^\text{min})$ such that $\mu^\text{min}$ is minimal in the sens of $\| \cdot \|_2$. We call it the \emph{minimal representative}.",2502.01512
definition,"[Pushforward measure]     Given two measurable spaces $(\mathcal{X}, \Omega_{\mathcal{X}})$ and $(\mathcal{Y}, \Omega_{\mathcal{Y}})$, a measurable map $f\colon \Omega_{\mathcal{X}}\to \Omega_{\mathcal{Y}}$ and a measure $\mu\colon\Omega_{\mathcal{X}}\to[0,+\infty]$, the \emph{pushforward} of $\mu$ is defined to be the measure $f \# \mu \colon\Omega_{\mathcal{Y}}\to[0,+\infty]$ given by     $$\forall B \in \Omega_{\mathcal{Y}},~(f\#\mu)(B) = \mu(f^{-1}[B]).$$     where $f^{-1}[B]$ is the preimage of $B$ by $f$.",2502.01512
definition,"[Elliptically Contoured Distribution]     A random vector $X \in \R^d$ follows an Elliptically Contoured distribution if there exists $\mu \in \R^d$, $\Sigma \in \P_d$ and a function $g$ such that $X$ has density      $$f_X(x) = k \det(\Sigma)^{-1/2}g\left((x-\mu)^\top \Sigma^{-1}(x - \mu)\right)$$     where $k$ is a normalizing factor. We denote $X \sim \EC(\mu,\Sigma,g)$.",2502.01512
definition,"[Wrapped Elliptically Contoured]     Let $p \in \P_d$, $\mu \in \R^{\nicefrac{d(d+1)}{2}}, \Sigma \in \P_{\nicefrac{d(d+1)}{2}}$ and $g$ be a function. Then, a random vector $X$ on $\P_d$ follows a Wrapped Elliptically Contoured denoted $\WEC(p;\mu,\Sigma,g)$ if              X = \Exp_p(\Vect_p^{-1}(\mathbf{t})),~  \mathbf{t} \sim \EC(\mu, \Sigma, g).",2502.01512
proof,"One has that $T_{I_d} \P_d \simeq \S_d$ and that $\langle \cdot, \cdot \rangle_{I_d}$ is the Frobenius inner product, so one can use the classical basis of $\S_d$ to build an orthonormal basis of $T_{I_d} \P_d$. Then, by transporting the basis of $T_{I_d} \P_d$ to $T_p \P_d$ using the isometry $x \mapsto p^{1/2}xp^{1/2}$, one has a basis of $T_p \P_d$. It is still orthonormal as $x \mapsto p^{1/2}xp^{1/2}$ is an isometry.",2502.01512
proof,"According to  Equation 22 of \citet{sraConicGeometricOptimisation2015}, in the case of $\P_d$, the parallel transport $\Gamma_{I_d \rightarrow p}$ from $T_{I_d} \P_d$ to $T_{p} \P_d$ is:     $$\forall u \in T_{I_d} \P_d,~ \Gamma_{I_d \rightarrow p}(u) = p^{1/2}up^{1/2}.$$     The result follows from the definition of $(E_{p, ij})_{i\leq j}$.",2502.01512
proof,"We start with the case where $p = I_d$.      Let $u = [[u_{ij}]] \in T_{I_d} \P_d \simeq \S_d$. We simply need to show that, for $i \leq j$, one has              \langle u, E_{I_d, ij} \rangle_{I_d} = u_{ii} \quad & \text{ if } i = j, \\ \sqrt{2} u_{ij} \quad & \text{ if } i < j.           One has, when $i=j$:     $$\langle u, E_{I_d, ii} \rangle_{I_d} = \langle u, e_{ii} \rangle_{I_d} = \tr(u e_{ii}) = u_{ii}.$$     And when $i < j$:     $$\langle u, E_{I_d, ij} \rangle_{I_d} = \langle u, \frac{1}{\sqrt{2}}(e_{ij} + e_{ji}) \rangle_{I_d} = \frac{1}{\sqrt{2}}(\tr(u e_{ij}) + \tr(u e_{ji})) = \sqrt{2} u_{ij}.$$     Therefore, one has the results for $\Vect_{I_d}$.      Now, in the general case of $p \in \P_d$, one has that, for $i \leq j$     $$\langle u, E_{p, ij} \rangle_p = \langle u, p^{1/2}E_{I_d, ij}p^{1/2} \rangle_p = \langle p^{-1/2}u p^{-1/2}, E_{I_d, ij} \rangle_{I_d}.$$     By using the definition of $\Vect_p(u) = \Vect_{I_n}(p^{-1/2}up^{-1/2})$ and the result for $p = I_d$, one has the result.",2502.01512
proof,"Let us prove the two points of the proposition.              \item Let $u \in T_{p} \P_d$. One has, using \cref{prop:vecto_to_basis},                   \|\Vect_{p}(u)\|_2^2 &= \Vect_{p}(u)^\top \Vect_{p}(u) = \sum_{i \leq j} \langle u, E_{p, ij} \rangle_p^2.                As $(E_{p, ij})_{i\leq j}$ is an orthonormal basis of the Euclidean space $(T_p \P_d, \langle \cdot, \cdot \rangle_p)$, one has that      $$\sum_{i \leq j} \langle u, E_{p, ij} \rangle_p^2  = \|x\|_p.$$     which proves the first point.     \item Let $u \in T_{p} \P_d$. One has, using the previous point, the definition of $\| \cdot \|_p$, the expression of the Riemannian logarithm given at \cref{eq:exp_log_riem} and the expression of the AIRM distance given at \cref{eq:distance_AIRM}:     $$\|\Vect_{p}(\Log_p u)\|_2^2 = \|\Log_p u\|_p^2 = \|p^{-1/2}\Log_p u ~ p^{-1/2}\|_F = \|\log(p^{-1/2}up^{-1/2})\|_F = \delta(p, u)^2.$$",2502.01512
proof,"In this proof, we will only show the first two points of the above definition, the third one being similar to them.               \item Let $Y = p^{-1/2}Xp^{-1/2}$. We want to show that $Y \sim  \WG(I_d; \mu, \Sigma)$. For this, let $\varphi \colon \P_d \rightarrow \R$ be a continuously bounded function. One has                           \mathbb{E}[\varphi(Y)] &= \int_{\P_d} \varphi( p^{-1/2}xp^{-1/2})f_{p; \mu, \Sigma}(x) \mathrm{d}\text{vol}(x) \\         &= \int_{\P_d} \varphi( p^{-1/2}xp^{-1/2}) \frac{1}{\sqrt{(2\pi)^d \det \Sigma}}\frac{\exp\left(-\frac{1}{2} (\Vect_p(\Log_{p}(x)) - \mu)^\top \Sigma^{-1}(\Vect_p(\Log_{p}(x)) - \mu)\right)}{|J_{I_d}(\log(p^{-1/2}xp^{-1/2}))|}\mathrm{d}\text{vol}(x).                                    Let us now define $\psi_p \colon x \mapsto p^{-1/2}xp^{-1/2}$. $\psi_p$ is a $\mathcal{C}^1$-diffeomorphisme between $\P_d$ and $\P_d$. Moreover,  as the volume element $\mathrm{d}\text{vol}$ is invariant by congruence of $\text{GL}(d, \R)$, the transformation $\psi_p$ does not imply any volume change. Therefore, by change of variables $y = \psi_p(x)$, one has:                           \mathbb{E}[\varphi(Y)] &= \int_{\P_d} \varphi( y) \frac{1}{\sqrt{(2\pi)^d \det \Sigma}}\frac{\exp\left(-\frac{1}{2} (\Vect_p(\Log_{p}(p^{1/2}yp^{1/2})) - \mu)^\top \Sigma^{-1}(\Vect_p(\Log_{p}(p^{1/2}yp^{1/2})) - \mu)\right)}{|J_{I_d}(\log(p^{-1/2}p^{1/2}yp^{1/2}p^{-1/2}))|}\mathrm{d}\text{vol}(y) \\         &= \int_{\P_d} \varphi( y) \frac{1}{\sqrt{(2\pi)^d \det \Sigma}}\frac{\exp\left(-\frac{1}{2} (\Vect_p(p^{1/2}\log(y)p^{1/2}) - \mu)^\top \Sigma^{-1}(\Vect_p(p^{1/2}\log(y)p^{1/2}) - \mu)\right)}{|J_{I_d}(\log(y))|}\mathrm{d}\text{vol}(y).                           Finally, using that $\Vect_p(p^{1/2}\log(y)p^{1/2}) = \Vect_{I_d}(p^{-1/2}p^{1/2}\log(y)p^{1/2}p^{-1/2}) = \Vect_{I_d}(\log(y))$ and $\Log_{I_d} = \log$, we have,           $$\mathbb{E}[\varphi(Y)] = \int_{\P_d} \varphi( y) \frac{1}{\sqrt{(2\pi)^d \det \Sigma}}\frac{\exp\left(-\frac{1}{2} (\Vect_{I_d}(\Log_{I_d}(y)) - \mu)^\top \Sigma^{-1}(\Vect_{I_d}(\Log_{I_d}(y)) - \mu)\right)}{|J_{I_d}(\log(y))|}\mathrm{d}\text{vol}(y).$$                  This shows us that $Y \sim \WG(I_d; \mu, \Sigma)$.         \item Let now $Y = \Exp_p(\Log_p - \Vect_{p}^{-1}(\mu))$. We want to show that $Y \sim \WG(p; 0_{d(d+1)/2}, \Sigma)$. Let $\varphi \colon \P_d \rightarrow \R$ be a bounded continuous function. One has                           \mathbb{E}[\varphi(Y)] &= \int_{\P_d} \varphi(\Exp_p(\Log_p x - \Vect_p^{-1}(\mu)))f_{p; \mu, \Sigma}(x) \mathrm{d}\text{vol}(x) \\         &= \int_{\P_d} \varphi( \Exp_p(\Log_p x - \Vect_p^{-1}(\mu))) \frac{1}{\sqrt{(2\pi)^d \det \Sigma}}\frac{\exp\left(-\frac{1}{2} (\Vect_p(\Log_{p}(x)) - \mu)^\top \Sigma^{-1}(\Vect_p(\Log_{p}(x)) - \mu)\right)}{|J_{p}(\Log_p(x))|}\mathrm{d}\text{vol}(x).                            Let us now define $\psi_p \colon x \mapsto \Exp_p(\Log_p x - \Vect_p^{-1}(\mu))$. $\psi_p$ is a $\mathcal{C}^1$-diffeomorphisme between $\P_d$ and $\P_d$ and its inverse is $\psi_p^{-1} \colon y \mapsto \Exp_p(\Log_p x + \Vect_p^{-1}(\mu))$. By change of variables $y = \psi_p(x)$, one has:                           \mathbb{E}[\varphi(Y)] &= \int_{\P_d} \varphi( y) \frac{1}{\sqrt{(2\pi)^d \det \Sigma}}\frac{\exp\left(-\frac{1}{2} \Vect_p(\Log_{p}(y))^\top \Sigma^{-1}\Vect_p(\Log_{p}(y))\right)}{|J_{p}(\Log_p(y) + \Vect_p^{-1}(\mu))|}\frac{\mathrm{d}\text{vol}(y)}{|\det \mathrm{d}\psi_p(\psi^{-1}(y))|}.                           We need to compute the change of volume term $\det \mathrm{d}\psi_p(\psi^{-1}(y))$. For this, let us start by saying that $\mathrm{d}\psi_p(x) = \mathrm{d}\Exp_p(\Log_p x - \Vect_p^{-1}(\mu)) \circ \mathrm{d}\Log_p x$ therefore, $\det \mathrm{d}\psi_p(x) = \det \mathrm{d}\Exp_p(\Log_p x - \Vect_p^{-1}(\mu)) \det \mathrm{d}\Log_p x$. Now using the fact that $\mathrm{d} \Log_{p}(y) = \left(\mathrm{d} \Exp_{p} (\Log_{p}(y))\right)^{-1}$ and the definition of $J_p(u) = \det \mathrm{d} \Exp_p(u)$ (see \cref{theo:density}), we have          $$\det \mathrm{d} \psi_p(x) = J_p(\Log_px - \Vect_p^{-1}(\mu)) \frac{1}{J_p(\Log_p x)}$$ and thus, plugging $\psi_p^{-1}(y)$ into the equation:         $$\det \mathrm{d} \psi_p(\psi_p^{-1}(y)) = J_p(\Log_p y) \frac{1}{J_p(\Log_p y + \Vect_p^{-1}(\mu))}.$$         Therefore,          $$ \mathbb{E}[\varphi(Y)] = \int_{\P_d} \varphi( y) \frac{1}{\sqrt{(2\pi)^d \det \Sigma}}\frac{\exp\left(-\frac{1}{2} \Vect_p(\Log_{p}(y))^\top \Sigma^{-1}\Vect_p(\Log_{p}(y))\right)}{|J_{p}(\Log_p(y))|}\mathrm{d}\text{vol}(y).$$         This shows us that $Y \sim \WG(p;0_{d(d+1)/2}, \Sigma)$.      \item For the third point, one can prove it similarly as the two previous one, having in mind that the vectorization $\Vect_p$ is an isometry (see \cref{prop:norm_vect}) therefore, neither $\Vect_p$ nor  $\Vect_p^{-1}$ implies any volume changes.",2502.01512
proof,"In this following, we denote by $\gamma$ the function $\gamma \colon t \mapsto e^t p$.     Let us denote by $\tilde{f}$ the density of $\WG(\gamma(t); \mu - t\nu, \Sigma)$ and by $f$ the density of $\WG(p; \mu, \Sigma)$. We want to show that $\tilde{f} = f$. Let $x \in \P_d$, by \cref{theo:density}, one has:     $$\tilde{f}(x) = \frac{1}{\sqrt{(2\pi)^d \det \Sigma}} \frac{\exp\left(-\frac{1}{2}\left(\Vect_{\gamma(t)}(\Log_{\gamma(t)}(x)) - \mu + t\nu \right)^\top \Sigma^{-1}\left(\Vect_{\gamma(t)}(\Log_{\gamma(t)}(x)) - \mu + t\nu\right)\right)}{|J_{\gamma(t)}(\Log_{\gamma(t)}(x))|}.$$     One has, that                            \Log_{\gamma(t)}(x) &= \gamma(t)^{1/2}\log(\gamma(t)^{-1/2}x\gamma(t)^{-1/2})\gamma(t)^{1/2} \\             &= e^{ t}p^{1/2}\log(e^{- t}p^{-1/2}x p^{-1/2})p^{1/2} \quad { \text{ using that } \gamma(t) = e^{ t}}\\             &= e^{ t}p^{1/2}\log(e^{- t}I_d)p^{1/2} + e^{ t}\Log_p(x) \quad { \text{ using that } e^{- t}I_d \text{ and } p^{-1/2}x p^{-1/2} \text{commute}} \\             &= - t e^{ t}p +  e^{ t}\Log_p(x).                   Furthermore, one has:                           \Vect_{\gamma(t)}(\Log_{\gamma(t)}(x)) &= - t e^{ t} \Vect_{\gamma(t)}( p) +  e^{ t}\Vect_{\gamma(t)}(\Log_p(x))  \quad { \text{ using the linearity of}  \Vect_{\gamma(t)}} \\             &= - t e^{ t} \Vect_{I_d}(\gamma(t)^{-1/2} p\gamma(t)^{-1/2}) + e^{ t}\Vect_{I_d}(\gamma(t)^{-1/2}\Log_p(x)\gamma(t)^{-1/2}) \\             &= -  t e^{ t} e^{- t} \Vect_{I_d}(p^{-1/2}  p p^{-1/2}) +  e^{ t} e^{- t}\Vect_{I_d}(p^{-1/2}\Log_p(x)p^{-1/2}) \\             &= - t \Vect_p( p) + \Vect_p(\Log_p(x)).                    Therefore, the numerator of the density $\tilde{f}$ can be rewritten as:     $$\exp\left(-\frac{1}{2}(\Vect_p(\Log_p(x)) - \mu)^\top \Sigma^{-1}(\Vect_p(\Log_p(x)) - \mu)\right).$$     which is the same numerator as $f$.      Let us now focus on the denominator. One has:                           J_{\gamma(t)}(\Log_{\gamma(t)}(x)) &= J_{I_d}(\gamma(t)^{-1/2}\Log_{\gamma(t)}(x)\gamma(t)^{-1/2}) \\             &= J_{I_d}(e^{- t}p^{-1/2}\Log_{\gamma(t)}(x)p^{-1/2}) \\             &=J_{I_d}(- t I_d + p^{-1/2}\Log_{p}(x)p^{-1/2}) \quad { \text{ using the computation of } \Log_{\gamma(t)}(x)}. \\                    We recall that the Jacobian determinant of the exponential map at the identity is:      $$J_{I_d}(u) = 2^d \prod_{i < j} \frac{\sinh\left(\frac{\lambda_i(u) - \lambda_j(u)}{2}\right)}{\lambda_i(u) - \lambda_j(u)}$$      where $(\lambda_i(u))_i$ are the eigenvalues of $u$. Moreover, the eigenvalues of $u := -\alpha t I_d + p^{-1/2}\Log_{p}(x)p^{-1/2}$ are      $$\lambda_i(u) = -\alpha t + \lambda_i\left(p^{-1/2}\Log_{p}(x)p^{-1/2}\right).$$     Thus, for all $i < j$, one has:     $$\lambda_i(u) - \lambda_j(u) = \lambda_i\left(p^{-1/2}\Log_{p}(x)p^{-1/2}\right) - \lambda_j\left(p^{-1/2}\Log_{p}(x)p^{-1/2}\right)$$     and therefore, this leads to:     $$J_{I_d}(u) = J_{I_d}\left(p^{-1/2}\Log_{p}(x)p^{-1/2}\right) = J_p\left(\Log_p(x)\right).$$     So the denominator of the density $\tilde{f}$ is the same as the denominator of the density $f$ and therefore, the two densities are equal.",2502.01512
proof,"We want to find the smallest $\mu^{\text{min}}$ in the sens of $\| \cdot \|_2$ and the corresponding $p^{\text{min}}$ such that $(p; \mu, \Sigma) \cong (p^{\text{min}}; \mu^{\text{min}}, \Sigma^{\text{min}})$. As all the $\mu$ in the equivalence class of $[\theta]$ are of the form $\mu - t\nu$ for $t\in \R$, to find the smallest $\mu^{\min}$, one needs to minimize the following function:     $$\varphi \colon t \mapsto \|\mu - t\nu\|^2_2 = \|\mu\|_2^2 - 2 t\langle \mu, \nu \rangle + t^2 \|\nu\|^2_2.$$      One thus has:      $$\varphi'(t) = -2\langle \mu, \nu \rangle + 2t\|\nu\|^2_2.$$     The minimum is reached at $t^{\text{min}}= \frac{\langle \mu, \nu \rangle}{\|\nu\|^2_2}$ with $\|\nu\|^2 = nd$ and $\langle \mu, \nu \rangle = \sum_{i=1}^d \mu_i$. Therefore, one has:              \left\{                              p^{\text{min}} &= e^{\frac{1}{d}\sum_{i=1}^d \mu_i}p \\                  \mu^{\text{min}} &= \mu - \frac{1}{d}\sum_{i=1}^d \mu_i\nu = \left(\mu_1 - \frac{1}{d}\sum_{i=1}^d \mu_i, \cdots, \mu_d - \frac{1}{d}\sum_{i=1}^d \mu_i, \mu_{d+1}, \cdots, \mu_{d(d+1)/2}\right).                      \right.",2502.01512
proposition,"The Jacobian determinant of the exponential map at the identity $\Exp_{I_d}$ is:     $$\forall u \in T_{I_d} \P_d,~ J_{I_d}(u) = 2^{\nicefrac{d(d-1)}{2}} \prod_{i < j} \frac{\sinh\left(\frac{\lambda_i(u) - \lambda_j(u)}{2}\right)}{\lambda_i(u) - \lambda_j(u)}$$     where the $\lambda_i(u)$ are the eigenvalues of $u$.     Then, one can use the previous formula to compute the Jacobian determinant of the exponential map at any point $p \in \P_d$:     $$\forall u \in T_{p} \P_d,~ J_p(u) = J_{I_d}(p^{-1/2}up^{-1/2}).$$",2502.01512
proposition,"Let $X \sim \WG(I_d; 0_{\nicefrac{d(d+1)}{2}}, I_{\nicefrac{d(d+1)}{2}})$ and let $(p, \mu, \Sigma) \in \Theta$. There exists a transformation of $X$ denoted $\Psi$ such that $$\Psi(X) \sim \WG(p; \mu, \Sigma).$$ Thus, the wrapped Gaussian $ \WG(I_d; 0_{\nicefrac{d(d+1)}{2}}, I_{\nicefrac{d(d+1)}{2}})$ is a building block of the wrapped Gaussians.",2502.01512
proposition,"A mean of $\WG(p; 0, \Sigma)$ is p.",2502.01512
proposition,"Let $(p, \mu, \Sigma) \in \Theta$ and $t \in \R$. One has that $\WG(p; \mu, \Sigma)$ and $\WG(e^{t}p;\mu - t\nu, \Sigma)$ are equal where $\nu = \Vect_p(p) = (1,\cdots,1,0,\cdots,0) \in \R^{\nicefrac{d(d+1)}{2}}$.",2502.01512
proposition,"Let $\theta = (p, \mu, \Sigma) \in \Theta$ be parameters. Then, the minimal representative of the class $[\theta]$  as defined at \cref{def:representative} is $\theta^\text{min} = (p^\text{min}, \mu^\text{min}, \Sigma^{\text{min}})$ where               p^{\text{min}} = e^{\frac{1}{d}\sum_{i=1}^d \mu_i}p, \quad \mu^{\text{min}} = \mu -  \frac{1}{d}\sum_{i=1}^d \mu_i \nu, \quad \Sigma^\text{min} = \Sigma          where we recall that $\nu = (1,\cdots,1,0,\cdots,0) \in \R^{\nicefrac{d(d+1)}{2}}$.",2502.01512
proposition,"The MLE $\hat{\mu}_N$ and $\hat{\Sigma}_N$ of the parameters $\mu$ and $\Sigma$ of the wrapped Gaussian are:                           \hat{\mu}_N &= \frac{1}{N}\sum_{i=1}^{N}\Vlog_{p^\star}(x_i), \\             \hat{\Sigma}_N &= \frac{1}{N}\sum_{i=1}^{N}\left(\Vlog_{p^\star}(x_i) - \hat{\mu}_N\right)\left(\Vlog_{p^\star}(x_i) - \hat{\mu}_N\right)^\top                   where  $\Vlog_{p^\star} = \Vect_{p^\star} \circ \Log_{p^\star}$.",2502.01512
proposition,"[Orthonormal basis of the tangent spaces]     Let $e_{ij}$ be the $d \times d$ matrix with a 1 at position $(i,j)$ and zeros everywhere else. Then               \item An orthonormal basis of $(T_{I_d} \P_d, \langle \cdot , \cdot \rangle_{I_d})$ is $(E_{I_d,ij})_{i\leq j}$ defined as follows:             \[             E_{I_d, ij} =              \frac{1}{\sqrt{2}} (e_{ij} + e_{ji}) & \text{for } i < j, \\             e_{ii} & \text{for } i = j.                          \]         \item An orthonormal basis of $(T_p \P_d, \langle \cdot , \cdot \rangle_p)$ is $(E_{p, ij})_{i\leq j}$ where $ E_{p, ij} = p^{1/2}E_{I_d, ij}p^{1/2}$.",2502.01512
proposition,"The basis $(E_{p, ij})_{i\leq j}$ of $(T_p \P_d, \langle \cdot , \cdot \rangle_p)$ given at \cref{prop:ortho_basis} is the parallel transport of the basis $(E_{I_d,ij})_{i \leq j}$ of $(T_{I_d} \P_d, \langle \cdot , \cdot \rangle_{I_d})$ from $T_{I_d} \P_d$ to $T_{p} \P_d$.",2502.01512
proposition,"Let $(E_{p, ij})_{i\leq j}$ be the orthonormal basis of the tangent space $T_p \P_d$ described at \cref{prop:ortho_basis}. Let $u \in T_p \P_d$. Then,      $$\Vect_p(u) = (\langle u, E_{p, 11} \rangle_p,\langle u, E_{p, 12} \rangle_p,\langle u, E_{p, 22} \rangle_p, \cdots, \langle u, E_{p, d-1 d} \rangle_p , \langle u, E_{p, dd} \rangle_p).$$",2502.01512
proposition,"\item Let $u \in T_{p} \P_d$, then $$\|\Vect_{p}(u)\|_2^2 = \Vect_{p}(u)^\top \Vect_{p}(u) = \|u\|_{p}^2 := \sqrt{\langle u, u\rangle}_p.$$ Therefore, $\Vect_p$ is not only an isomorphism, it is an isometry between $(T_p \P_d, \langle \cdot, \cdot \rangle_p)$ and $(\R^{\nicefrac{d(d+1)}{2}}, \|\cdot \|_2)$.         \item Let $u \in T_{p} \P_d$, then $$\|\Vect_{p}(\Log_p u)\|_2^2 = \Vect_{p}(\Log_p u)^\top \Vect_{p}(\Log_p u) = \delta(p,u)^2.$$",2502.01512
proposition,"Let $(p, \mu, \Sigma) \in \Theta$ and $X \sim \WG(p; \mu, \Sigma)$. Then,               \item $p^{-1/2}Xp^{-1/2} \sim \WG(I_d; \mu, \Sigma)$,         \item $\Exp_p(\Log_p - \Vect_{p}^{-1}(\mu)) \sim  \WG(p; 0_{d(d+1)/2}, \Sigma)$,         \item $\Exp_p( \Vect_p^{-1}(\Sigma^{-1/2}\Vect_{p}(\Log_p X))) \sim  \WG(p; \mu, I_{d(d+1)/2}).$",2502.01512
proposition,"Let $(p, \mu, \Sigma) \in \Theta$ and $t \in \R$. One has that $\text{WG}(p; \mu, \Sigma)$ and $\text{WG}(e^{t}p;\mu - t\nu, \Sigma)$ are equal where $\nu = \Vect_p(p) = (1,\cdots,1,0,\cdots,0) \in \R^{\nicefrac{d(d+1)}{2}}$.",2502.01512
proposition,"Let $\theta = (p; \mu, \Sigma) \in \Theta$ be a tuple of parameters. Then, the minimal representative of the class $[\theta]$  as defined at \cref{def:representative} is $\theta^\text{min} = (p^\text{min}; \mu^\text{min}, \Sigma^\text{min})$ where               \left\{                              p^{\text{min}} &= e^{\frac{1}{d}\sum_{i=1}^d \mu_i}p, \\                  \mu^{\text{min}} &= \mu -  \frac{1}{d}\sum_{i=1}^d \mu_i \nu,\\                 \Sigma^\text{min} &= \Sigma.                      \right.",2502.01512
theorem,"(Description of $st_{\uparrow}(v)$; cf. Proposition 2.16 and Theorem 2.22 from \cite{Farley}) Let $v = \{ b_{1}, \ldots, b_{k} \} \in \left( \Delta^{f}_{\mathcal{B}} \right)^{0}$.  The ascending star $st_{\uparrow}(v)$ is abstractly isomorphic to  $\mathcal{E}(b_{1}) \times \ldots \times \mathcal{E}(b_{k})$ as a partially ordered set. As a result, there is a homeomorphism \[ |st_{\uparrow}(v)| \cong \prod_{i=1}^{k} |\mathcal{E}(b_{i})|. \] \qed",2502.01544
theorem,"(CAT(0) cubical complexes) Let $\mathcal{B}$ be a simple expansion set. If the vertices of $\Delta^{f}_{\mathcal{B}}$ are a directed set with respect to $\preceq$, then $\Delta^{f}_{\mathcal{B}}$ is  a CAT(0) cubical complex with respect to the cubes from Definition \ref{definition:cubes}.",2502.01544
definition,"(Simple expansion sets; cf. Definition 2.1 from \cite{Farley})  A \emph{simple expansion set over $X$} is a $4$-tuple $(\mathcal{B}, X, supp, \mathcal{E})$, where $\mathcal{B}$ and $X$ are sets, and $supp: \mathcal{B} \rightarrow \mathcal{P}(X)$ and $\mathcal{E}$ are functions.   For each $b \in \mathcal{B}$, $supp(b)$ is required to be a non-empty subset of $X$. The function $supp$ is called the \emph{support function}, and $supp(b)$ is the \emph{support} of $b$.    A \emph{vertex} is a finite subset $v = \{ b_{1}, \ldots, b_{k}\} \subseteq \mathcal{B}$ such that $supp(b_{i}) \cap supp(b_{j}) = \emptyset$ when $i \neq j$. The set of all vertices is denoted $\mathcal{V}_{\mathcal{B}}$. For each $v \in \mathcal{V}_{\mathcal{B}}$, we define  \[ supp(v) = \bigcup_{\ell =1}^{k} supp(b_{\ell}); \quad \quad   P(v) = \{ supp(b_{\ell}) \mid \ell \in \{ 1, \ldots, k \} \}.  \] The collection $P(v)$ is the \emph{partition induced by $v$}. It is a partition of $supp(v)$.   The function $\mathcal{E}$ assigns a set of vertices, denoted $\mathcal{E}(b)$, to each $b \in \mathcal{B}$.   The sets $\mathcal{E}(b)$ are required to satisfy the following three conditions:  \item $|\mathcal{E}(b)| \leq 2$; \item $ \{ b \} \in \mathcal{E}(b)$; \item If $|\mathcal{E}(b)| = 2$ and $v \in \mathcal{E}(b) - \{ \{ b \} \}$,  then $P(v)$ is a proper refinement of $P(\{ b \})$.",2502.01544
definition,"(Restriction functions; cf. Definition 2.1 from \cite{Farley}) Let $b \in \mathcal{B}$. For a given vertex $v \in \mathcal{V}_{\mathcal{B}}$, we define \[ r_{b}(v) = \{ b' \in v \mid supp(b') \subseteq supp(b) \}. \] This is the \emph{restriction of $v$ to the support of $b$}.",2502.01544
definition,"(The full-support subcomplex $\Delta^{f}_{\mathcal{B}}$) For a given expansion set $\mathcal{B}$, we define a simplicial complex $\Delta^{f}_{\mathcal{B}}$ as follows:  \item The vertices of $\Delta^{f}_{\mathcal{B}}$ are the members $v$ of  $\mathcal{V}_{\mathcal{B}}$ such that $supp(v) = X$; \item A collection $\{ v_{0}, \ldots, v_{n} \}$ of vertices in $\Delta^{f}_{\mathcal{B}}$  span a simplex if and only if:  \item $|v_{i}| \neq |v_{j}|$ if $i \neq j$; \item if $|v_{0}| < |v_{1}| < \ldots < |v_{n}|$ and $v_{0} = \{ b_{1}, \ldots, b_{m} \}$, then  \[ r_{b_{i}}(v_{0}) = \{ b_{i} \} \leq r_{b_{i}}(v_{1}) \leq \ldots \leq r_{b_{i}}(v_{n}) \] is a chain in $\mathcal{E}(b_{i})$, for $i = 1, \ldots, m$.",2502.01544
definition,"(the height function and ascending stars) For a vertex $v \in \left(\Delta^{f}_{\mathcal{B}}\right)^{0}$, we call $|v|$ the \emph{height of $v$}. The \emph{ascending star of $v$}, denoted $st_{\uparrow}(v)$, is the subcomplex of  $\Delta^{f}_{\mathcal{B}}$ consisting of all simplices in which $v$ is the vertex of minimum height, and  the faces of such simplices.",2502.01544
definition,"(the ascending star as a partially ordered set; cf. Definition 2.15 from \cite{Farley}) Let $v = \{ b_{1}, \ldots, b_{k} \} \in \left( \Delta^{f}_{\mathcal{B}} \right)^{0}$. We define a partial order  on $st_{\uparrow}(v)$ as follows: $u \leq w$ if and only if  $r_{b_{i}}(u) \leq r_{b_{i}}(w)$ for all $b_{i} \in v$, where the latter inequality is with respect to the partial order on $\mathcal{E}(b_{i})$.",2502.01544
definition,"(Abstract cubes) Let $v_{1}, v_{2} \in \mathcal{V}_{\mathcal{B}}$, where $v_{2} \subseteq v_{1}$ and $|\mathcal{E}(b)| = 2$ for each $b \in v_{2}$. We let $\mathcal{C}(v_{1},v_{2})$ denote the \emph{cube determined by $(v_{1},v_{2})$}.  It is the portion of  $st_{\uparrow}(v_{1})$ corresponding to  \[ \prod_{b' \in v_{1}-v_{2}} \{ \{ b' \} \} \times \prod_{b'' \in v_{2}} \mathcal{E}(b'') \subseteq \prod_{b \in v_{1}} \mathcal{E}(b). \] Thus, it is the subcomplex of $st_{\uparrow}(v_{1})$ consisting of simplices that involve expansions only at members of $v_{2}$.",2502.01544
definition,"(Contraction basins) Let $\mathcal{B}$ be a simple expansion set. For a given $b \in \mathcal{B}$ such that $|\mathcal{E}(b)|=2$, we let $Bas(b)$ be the unique member of  $\mathcal{E}(b) - \{ \{b \} \}$. We say that $Bas(b)$ is the \emph{contraction basin of $b$}.",2502.01544
definition,"(Ascending path partial order)  Let $v_{1}, v_{2} \in \left(\Delta^{f}_{\mathcal{B}}\right)^{0}$. An  \emph{ascending path from $v_{1}$ to $v_{2}$} is an edge-path \[ e_{0}, \ldots, e_{m} \] such that $\iota(e_{0}) = v_{1}$, $\tau(e_{m}) = v_{2}$, and, for $i=0,1, \ldots, m$, $|\iota(e_{i})| < |\tau(e_{i})|$.  We write $v_{1} \preceq v_{2}$ if there is an ascending path from $v_{1}$ to $v_{2}$. It is clear that $\preceq$ is a partial order on the vertices of $\Delta^{f}_{\mathcal{B}}$.",2502.01544
definition,"(Directed set)  A partially ordered set $(P,\leq)$ is a \emph{directed set} if any two members of $P$ have a common upper bound with respect to $\leq$.",2502.01544
definition,"(Relative ascending links)  Let $u', u'' \in \mathcal{V}_{\mathcal{B}}$. We write  $u' \preceq u''$ if there is a sequence  \[ u' = v_{0}, v_{1}, v_{2}, \ldots, v_{m} = u'' \] such that, for $i=1, \ldots, m$, $v_{i}$ may be obtained from $v_{i-1}$ by replacing some $b' \in v_{i-1}$ with $Bas(b')$; i.e.,  \[ v_{i} = \left( v_{i-1} - \{ b' \} \right) \cup Bas(b'), \] for some $b' \in v_{i-1}$.   Let $b \in \mathcal{B}$. For $v \in \mathcal{V}_{\mathcal{B}}$, we let  $lk_{\uparrow}(\{ b \}, v)$ be the subcomplex of $\mathcal{E}(b)$ spanned  by  \[ \{ u \in \mathcal{E}(b) \mid u \neq \{ b \} \text { and } u \preceq v \}. \] The complex $lk_{\uparrow}(\{ b \}, v)$ is called the \emph{ascending link of $b$ relative to $v$}.",2502.01544
proof,"Definition \ref{definition:complexes} shows that each simplex $\{ v_{0}, \ldots, v_{m} \} \subseteq \Delta^{f}_{\mathcal{B}}$ is part of the ascending star of its minimal-height vertex. Theorem \ref{theorem:summary} shows that each such ascending star is a product $|\mathcal{E}(b_{1})| \times \ldots \times |\mathcal{E}(b_{k})|$. The definition of simple expansion set specifies that each factor in the above product is either a point or a line segment, so the product is a cube.",2502.01544
proof,"We assume $b \in v_{1}$ and $b \in Bas(b')$ for some $b' \in v'_{2}$.  Let $w \in \mathcal{C} \cap \mathcal{C}'$ be arbitrary, and suppose for a contradiction that $b \not \in w$. Since $w \in \mathcal{C}'$, we must have  either $\{ b' \} \subseteq w$ or $Bas(b') \subseteq w$. The latter is ruled out because $b \in Bas(b') - w$, so $b' \in w$. Similarly, since $b \in v_{1}$ and $w \in \mathcal{C}$, it must be that $\{ b \} \subseteq w$ or $Bas(b) \subseteq w$. The former possibility is ruled out by hypothesis, so  $Bas(b) \subseteq w$.   Thus, it must be that $Bas(b)$ and $\{ b' \}$ are both subsets of $w$. However, if $b'' \in Bas(b)$, then  \[ supp(b'') \subsetneq supp(Bas(b)) = supp(b)  \subsetneq supp(b'), \] which gives two distinct members $b'$ and $b''$ of $w$ with overlapping support. This is a contradiction.",2502.01544
proof,"We write $\mathcal{C}$ and $\mathcal{C}'$ for $\mathcal{C}(v_{1},v_{2})$ and $\mathcal{C}(v'_{1},v'_{2})$, respectively.  Assume that $\mathcal{C} \cap \mathcal{C}' \neq \emptyset$. Let $ \hat{v}$ be a vertex of minimal height in the intersection. We can write  \hat{v} &= (v_{1} - \tilde{v}_{2}) \cup \left( \cup_{b \in \tilde{v}_{2}} Bas(b) \right); \\ \hat{v} &= (v'_{1} - \tilde{v}'_{2}) \cup \left( \cup_{b' \in \tilde{v}'_{2}} Bas(b') \right),  where $\tilde{v}_{2} \subseteq v_{2}$ and $\tilde{v}'_{2} \subseteq v'_{2}$.  We claim that  \[ \mathcal{C} \cap \mathcal{C}' = \mathcal{C}\left( \hat{v}, \left( v_{2} - \tilde{v}_{2} \right) \cap \left( v'_{2} - \tilde{v}'_{2} \right)\right). \] Indeed, we will now prove the reverse inclusion. It follows directly from the definition of cubes that \[ \mathcal{C}\left( \hat{v}, \left( v_{2} - \tilde{v}_{2} \right) \cap \left( v'_{2} - \tilde{v}'_{2} \right)\right) \subseteq \mathcal{C}\left( \hat{v}, \left( v_{2} - \tilde{v}_{2} \right)\right).\] Next, we note that each member of the latter cube is a member of $\mathcal{C}$, since any vertex that may obtained  from $\hat{v}$ by expanding some subset of $w' \subseteq v_{2} - \tilde{v}_{2}$ may be  obtained from $v_{1}$ by expanding some subset of $v_{2}$: starting with $v_{1}$, one first expands each member of $\tilde{v}_{2}$ (resulting in $\hat{v}$), and then expands $w'$. It follows that \[ \mathcal{C}\left( \hat{v}, \left( v_{2} - \tilde{v}_{2} \right)\right) \subseteq \mathcal{C}. \] One similarly shows that \[ \mathcal{C}\left( \hat{v}, \left( v_{2} - \tilde{v}_{2} \right) \cap \left( v'_{2} - \tilde{v}'_{2} \right)\right)  \subseteq \mathcal{C}\left( \hat{v}, \left( v'_{2} - \tilde{v}'_{2} \right)\right) \subseteq \mathcal{C}', \] proving the reverse inclusion, as desired.  Let us now establish the forward inclusion. First, note that $\tilde{v}_{2} \cap \tilde{v}'_{2} = \emptyset$. Indeed, if $b'' \in  \tilde{v}_{2} \cap \tilde{v}'_{2}$, we could write  w &= \left( v_{1} - \tilde{v}_{2} \right) \cup \{ b'' \} \cup \left( \cup_{b \in \tilde{v}_{2} - \{ b'' \}} Bas(b) \right); \\ w &= \left(v'_{1} - \tilde{v}'_{2} \right) \cup \{ b'' \} \cup \left( \cup_{b' \in \tilde{v}'_{2} - \{ b'' \}} Bas(b') \right),  which exhibits a vertex $w \in \mathcal{C} \cap \mathcal{C}'$ such that $|w| < |\hat{v}|$. This contradicts the minimality of $|\hat{v}|$.   Now let $u$ be an arbitrary vertex of $\mathcal{C} \cap \mathcal{C}'$. We  can write  u &= (v_{1} - v_{2}) \cup B_{1} \cup \ldots \cup B_{k}, \\ u &= (v'_{1} - v'_{2}) \cup B'_{1} \cup \ldots \cup B'_{\ell}  where, in the first equation,  $v_{2} = \{ b_{1}, \ldots, b_{k} \}$ and  each $B_{i} \in \mathcal{E}(b_{i})$ (i.e., $B_{i} = \{ b_{i} \}$ or $Bas(b_{i})$). Similarly, in the second equation,  $v'_{2} = \{ b'_{1}, \ldots, b'_{\ell} \}$ and  each $B'_{i} \in \mathcal{E}(b'_{i})$.  We would now like to show that  \[ E_{\mathcal{C},u} := \{ b_{i} \in v_{2} \mid B_{i} = Bas(b_{i}) \} \supseteq \tilde{v}_{2}. \] Indeed, suppose for a contradiction that $b \in \tilde{v}_{2} - E_{\mathcal{C},u}$. Since $b \in \tilde{v}_{2}$, we must have $Bas(b) \subseteq \hat{v}$. In particular, $b \not \in \hat{v}$. However, since $b \in v_{2} - E_{\mathcal{C},u}$, it must be that $\{ b \} \subseteq u$, so $b \in u$. Also, Lemma \ref{lemma:intersection} and the facts that $b \not \in \hat{v}$ and $b \in v_{2} \subseteq v_{1}$ imply that $b \not \in Bas(b')$, for any $b' \in v'_{2}$.   Consider now the second representation of $u$, given above. Since $b \in u$, it must be that $b \in v'_{1} - v'_{2}$, or  $b \in B'_{j}$, for some $j$. The first possibility is ruled out by the fact that $v'_{1} - v'_{2} \subseteq v'_{1} - \tilde{v}'_{2}$, and, thus, were $b \in v'_{1} - v'_{2}$, we would have $b \in \hat{v}$, which we know is not true. Thus, $b \in B'_{j}$ for some $j$. It follows that $B'_{j} = \{ b'_{j} \}$, since the possibility $B'_{j} = Bas(b'_{j})$ is ruled out by the fact that $b \not \in Bas(b'_{j})$. Thus $b = b'_{j}$; i.e., $b \in v'_{2} \subseteq v'_{1}$. Furthermore, since $b \in \tilde{v}_{2}$,  $b \not \in \tilde{v}'_{2}$. It follows that $b \in v'_{1} - \tilde{v}'_{2} \subseteq \hat{v}$. Thus, $b \in \hat{v}$, a contradiction. This proves that $\tilde{v}_{2} \subseteq E_{\mathcal{C},u}$, as desired.    It follows that any given vertex $u \in \mathcal{C} \cap \mathcal{C}'$ may be obtained from $\hat{v}$ by some combination of expansions from $v_{2} - \tilde{v}_{2}$.  A similar line of reasoning shows that the same $u$ may be obtained from  $\hat{v}$ by some combination of expansions  from $v'_{2} - \tilde{v}'_{2}$. However, the expansions from $\hat{v}$ that lead to $u$ are unique, and so all must occur from the set $(v_{2}-\tilde{v}_{2}) \cap (v'_{2} - \tilde{v}'_{2})$.",2502.01544
proof,"Let $v \in \left(\Delta^{f}_{\mathcal{B}}\right)^{0}$. Let us assume that $v_{1}, \ldots, v_{m}$ are vertices in $lk(v)$ that are pairwise connected by edges. Since each $v_{j}$ is connected to $v$ by an edge, it must be that each $v_{j}$ is the result of replacing a single $b_{j} \in v$ by  $Bas(b_{j})$, or there is some $\hat{b} \in \mathcal{B}$ such that $v_{j}$ is the result of replacing the contraction basin $Bas(\hat{b}) \subseteq v$ by  $\hat{b}$. In the former case, we call $\{ b_{j} \}$ an \emph{expansion basin} for $v_{j}$ relative to $v$. In the latter case, we say that $Bas(\hat{b})$ is the \emph{contraction basin} for $v_{j}$ relative to $v$. Collectively, we refer to these as \emph{basins} for the $v_{j}$ relative to $v$.   Next, we note that the basins for the $v_{j}$ are pairwise disjoint. Indeed, consider two vertices $v_{i}$ and $v_{j}$ in $lk(v)$ that, by hypothesis, are connected by an edge in $lk(v)$. It follows that $v_{i}$, $v_{j}$, and $v$ are corners of a two-cube $\mathcal{C}(v',v'')$, where $v_{i}$ and $v_{j}$ are adjacent to $v$.  Since $\mathcal{C}(v',v'')$ is two-dimensional, it must be that  $|v''| = 2$. We can let \[ v' = \{ b'_{1}, \ldots, b'_{k} \}, \] where $v'' = \{ b'_{1}, b'_{2} \}$, without loss of generality. Now note that  \[ v = \{ b'_{3}, \ldots, b'_{k} \} \cup B'_{1} \cup B'_{2}, \] where $B'_{i}$ is either $\{ b'_{i} \}$ or $Bas(b'_{i})$, for $i=1,2$. The sets $B'_{i}$ are therefore disjoint (for instance, because their supports are disjoint). By the definition of cubes, $v_{i}$ and $v_{j}$ are obtained from $v$ by expanding or contracting at one or the other of $B'_{1}$ and $B'_{2}$. If $B'_{i} = \{ b'_{i} \}$, then the operation in question is an expansion, while if $B'_{i} = Bas(b'_{i})$, then only the contraction is possible. We note, therefore, that the basins for $v_{i}$ and $v_{j}$ are the sets $B'_{1}$ and $B'_{2}$. It follows that the basins for $v_{i}$ and $v_{j}$ are disjoint.  Finally, we consider the cube $\mathcal{C}(u_{1},u_{2})$, where $u_{1}$ is the result of simultaneously applying contractions to the contraction basins of the various $v_{j}$, and $u_{2}$ is the subset of $u_{1}$ consisting of all of the various $b$ at the bottoms of the contraction basins for the $v_{j}$ and all of the $b$ in expansion basins. The cube $\mathcal{C}(u_{1},u_{2})$ represents an $(m-1)$-simplex spanned by  $\{ v_{1}, \ldots, v_{m} \}$ in $lk(v)$.",2502.01544
proof,"By Proposition \ref{proposition:nonpos}, $\Delta^{f}_{\mathcal{B}}$ has non-positive curvature. It now suffices, by the Cartan-Hadamard Theorem \cite{BH}, to prove that $\Delta^{f}_{\mathcal{B}}$ is simply connected.   Here we can appeal to the results of \cite{Farley}. We note that the relative ascending link $lk_{\uparrow}(\{ b \}, v)$ is always a point when $\{ b \} \precneq v$, by Remark \ref{remark:ascending}. It follows that $\mathcal{B}$ is an $n$-connected expansion set for all $n$, by Definition 2.30 from \cite{Farley}. Thus, by Theorem 2.32 from \cite{Farley}, $\Delta^{f}_{\mathcal{B}}$ is contractible.",2502.01544
proof,"It suffices to show that each $v \in \left( \Delta^{f}_{\mathcal{B}} \right)$ is adjacent to only finitely many vertices. Now we note that any such adjacent vertex is either the result of expanding  at some $b \in v$, or contracting at some $Bas(b) \subseteq v$. These operations result in  either a vertex of greater height, or lesser height, respectively. It is not possible for two vertices of the same height to be adjacent.  Since $\mathcal{B}$ is simple, there are no more than $|v|$ adjacent vertices of greater height. This is because there is at most one expansion to be made at each $b \in v$. On the other hand, the hypothesis guarantees that there are only finitely many possible contractions, making  the number of adjacent vertices of lesser height finite, as well.",2502.01544
proposition,"(Intersection of cubes is a cube) If $\mathcal{C}(v_{1},v_{2})$ and $\mathcal{C}(v'_{1},v'_{2})$ are cubes, and $\mathcal{C}(v_{1},v_{2}) \cap \mathcal{C}(v'_{1},v'_{2}) \neq \emptyset$, then $\mathcal{C}(v_{1},v_{2}) \cap \mathcal{C}(v'_{1},v'_{2})$ is a cube $\mathcal{C}(v_{3},v_{4})$, for some $v_{3}$ and $v_{4}$.",2502.01544
proposition,"(Non-positive curvature)  The complex $\Delta^{f}_{\mathcal{B}}$, endowed with the cubes $\mathcal{C}$ from Definition \ref{definition:cubes}, is a cubical complex satisfying Gromov's link condition.",2502.01544
proposition,"(Local finiteness)  Assume the hypotheses of Theorem \ref{theorem:main}. Suppose that, for each  vertex $v \in \mathcal{V}_{\mathcal{B}}$, $v = Bas(b)$ for only finitely many $b \in \mathcal{B}$. Then $\Delta^{f}_{\mathcal{B}}$ is locally finite.",2502.01544
lemma,"(Intersection lemma)  Let $\mathcal{C} = \mathcal{C}(v_{1},v_{2})$ and $\mathcal{C}' = \mathcal{C}(v'_{1},v'_{2})$ be cubes. If $b \in v_{1}$ and $b \in Bas(b')$ for some $b' \in v'_{2}$,  then $b \in w$, for all $w \in \mathcal{C} \cap \mathcal{C}'$.",2502.01544
example,"(The expansion set construction for Thompson's group $V$)    We will assume that the reader is acquainted with Thompson's group $V$ in what follows.  The source \cite{CFP} contains a standard introduction. We note that the expansion set construction of $V$ (to be revisited here for the reader's convenience) has already appeared in \cite{Farley} and \cite{FH2}.  Let $X = \prod_{i=1}^{\infty} \{ 0, 1 \}$. This is the Cantor set, whose members are infinite binary sequences. For a given finite binary sequence $\omega$, we let $B_{\omega}$ denote the set of all infinite binary sequences beginning with the prefix $\omega$. We call the sets $B_{\omega}$ \emph{balls} since they are metric balls with respect to a natural ultrametric $d$.  Let $S_{V}$ denote the set of all transformations $\sigma_{\omega_{1}}^{\omega_{2}}: B_{\omega_{1}} \rightarrow B_{\omega_{2}}$ such that, for a given sequence $\omega' \in B_{\omega_{1}}$, the effect of applying  $\sigma_{\omega_{1}}^{\omega_{2}}$ is to remove the prefix $\omega_{1}$, and replace it with  $\omega_{2}$: \[ \omega' = \omega_{1}a_{1}a_{2}a_{3} \ldots  \quad \mapsto \quad \omega_{2}a_{1}a_{2}a_{3}\ldots. \] We also let $0$ denote the transformation with empty domain and codomain, and include $0$ as a member of $S_{V}$. With these conventions, $S_{V}$ is closed under compositions and inverses, making it an inverse semigroup. (Here composition is defined ``on overlaps"": the domain of $f \circ g$ is the collection  of all members of the domain of $g$ that map to members of the domain of $f$.)  Any member of $V$ is a finite disjoint union of transformations from $S_{V}$. Indeed, given  a finite collection $C = \{ \sigma_{1}, \sigma_{2}, \ldots, \sigma_{m} \}  \subseteq S_{V}$, $C$ determines a member $g_{C}$ of $V$ if and only if the domains of the $\sigma_{i}$ partition $\mathcal{C}$, and, likewise, the codomains of the $\sigma_{i}$ partition $\mathcal{C}$. Conversely,  every member of $V$ is equal to $g_{C}$, for some collection $C \subseteq S_{V}$. The collection $C$ is not unique (i.e., the map $C \mapsto g_{C}$ is many-to-one), for essentially the same reason that tree representatives of members  of $V$ are not unique.    Now we can define the expansion set construction for $V$. We consider all pairs $(f,B)$, where $B = B_{\omega}$ for some finite binary sequence $\omega$, and $f$ is a finite disjoint union of  members of $S_{V}$ such that $B$ is the domain of $f$. (This is equivalent to $f$ being the restriction of some member of $V$ to $B$ in the case when $B$ is a proper subset of $X$.) We write $(f_{1},B_{1}) \sim (f_{2},B_{2})$ if there is a transformation $\sigma \in S_{V}$ such that $\sigma(B_{1}) = B_{2}$, and $f_{2} \circ \sigma = f_{1}$. The relation $\sim$ is an equivalence relation on the set of pairs $(f,B)$. We let $[f,B]$ denote the equivalence class of $(f,B)$, and let $\mathcal{B}$ denote the set of all such equivalence classes. The set $\mathcal{B}$ is the required expansion set. For a given equivalence class $b=[f,B_{\omega}]$, we let $supp(b) = f(B_{\omega})$ and  \[ \mathcal{E}(b) = \{ \{ b \}, \{ [f_{\mid}, B_{\omega0}], [f_{\mid}, B_{\omega1}] \} \}. \] Thus, the allowable expansions from $b$ consist of the trivial expansion $\{ b \}$, and the subdivision  into left and right halves. It is straightforward to show that $\mathcal{E}$ and $supp$ are well-defined. Since $|\mathcal{E}(b)| = 2$ for all $b \in \mathcal{B}$, $\mathcal{B}$ is simple.",2502.01544
example,"(Cubes in the case of $V$) We consider an example of a cube in $\Delta^{f}_{\mathcal{B}}$, where $\mathcal{B}$ is the expansion set defined in Example \ref{example:Vpt1} for Thompson's group $V$.  For a pair $[id_{\mid B}, B] \in \mathcal{B}$, we will simply write $B$ for convenience. Thus, we may  consider the set $\{ B_{0}, B_{10}, B_{11} \}$, which is a vertex in $\Delta^{f}_{\mathcal{B}}$, and the cube   \[ \mathcal{C} := \mathcal{C}( \{ B_{0}, B_{10}, B_{11} \}, \{ B_{0}, B_{10} \}).\] By the definition of $\mathcal{B}$, the sets $\mathcal{E}(B_{0})$ and $\mathcal{E}(B_{10})$ are as follows:  \mathcal{E}(B_{0}) &= \{ \{ B_{0} \}, \{ B_{00}, B_{01} \} \}; \\ \mathcal{E}(B_{10}) &= \{ \{ B_{10} \}, \{ B_{100}, B_{101} \} \}.   The cube $\mathcal{C}$ is depicted in Figure \ref{figure:1}. The gray vertical line represents a $1$-simplex in $\Delta^{f}_{\mathcal{B}}$ that is not part of the cubical structure.    [!h]   \filldraw[lightgray](2,0) -- (0,2) -- (2,4) -- (4,2) -- cycle; \draw[black,thick](2,0) -- (0,2); \draw[black,thick](2,0) -- (4,2); \draw[black,thick](0,2) -- (2,4); \draw[black,thick](4,2) -- (2,4); \draw[gray](2,0) -- (2,4); \node at (2,4.3){$\{ B_{00}, B_{01}, B_{100}, B_{101}, B_{11} \}$}; \node at (-1.7,2){$\{ B_{00}, B_{01}, B_{10}, B_{11} \}$}; \node at (2,-.3){$\{ B_{0}, B_{10}, B_{11} \}$}; \node at (5.7,2){$\{ B_{0}, B_{100}, B_{101}, B_{11} \}$};   \caption{Here a cube in $\Delta^{f}_{\mathcal{B}}$ is pictured, where  $\mathcal{B}$ is the expansion set for Thompson's group $V$.}",2502.01544
example,"(A special instance of the link condition in the case of $V$)  %Consider the following vertex $v$ in the complex $\Delta^{f}_{\mathcal{B}}$ for Thompson's group $V$: %\[ v = \{ B_{00}, B_{01}, B_{10}, B_{11} \}. \] %We define $v_{1}$, $v_{2}$, and $v_{3}$ as follows: % %v_{1} &= \{ B_{000}, B_{001}, B_{01}, B_{10}, B_{11} \}; \\ %v_{2} &= \{ B_{00}, B_{01}, B_{10}, B_{110}, B_{111} \}; \\ %v_{3} &= \{ B_{00}, [f,X], B_{11} \}, % %where $f_{\mid B_{0}} = \sigma_{0}^{10}$ and $f_{\mid B_{1}} = \sigma_{1}^{01}$. It is clear from these definitions that % %\mathcal{C}_{1} &= \mathcal{C}(v, \{ B_{00} \}); \\ %\mathcal{C}_{2} &= \mathcal{C}(v, \{ B_{11} \}); \\ %\mathcal{C}_{3} &= \mathcal{C}(\{ B_{00}, [f,X], B_{11} \}, \{ [f,X] \}) % %are the edges connecting $v$ to $v_{1}$, $v_{2}$, and $v_{3}$, respectively. %(In the case of $\mathcal{C}_{3}$, one notes that  %\[ \mathcal{E}([f,X]) = \{ \{[f,X]\}, \{ [\sigma_{0}^{10}, B_{0}],  %[\sigma_{1}^{01}, B_{1}] \} \}, \] %by the definition (Example \ref{example:Vpt1}). The pair $[\sigma_{0}^{10}, B_{0}]$ is then equivalent to $[id_{B_{10}}, B_{10}]$ by the definition of the equivalence relation, and $[\sigma_{1}^{01},B_{1}] = [id_{B_{01}}, B_{01}]$.)  %Any two of the $v_{i}$ are connected by an edge in the link. Equivalently, there are squares $\mathcal{C}_{i,j}$ for each $\{ i, j \} \subseteq \{ 1, 2, 3 \}$ ($i \neq j$) having the edges $\mathcal{C}_{i}$ and $\mathcal{C}_{j}$ as faces: % %\mathcal{C}_{1,2} &= \mathcal{C}(v, \{ B_{00}, B_{11} \}); \\ %\mathcal{C}_{1,3} &= \mathcal{C}(\{ B_{00}, [f,X], B_{11} \}, \{ B_{00}, [f,X] \}); \\ %\mathcal{C}_{2,3} &= \mathcal{C}(\{ B_{00}, [f,X], B_{11} \}, \{ [f,X], B_{11} \}). %  %These squares represent edges $e_{1,2}, e_{1,3}, e_{2,3}$ in the link. To verify the link condition in this case, one needs to produce a triangle in the link whose edges are $e_{1,2}, e_{1,3}, e_{2,3}$. Equivalently, one wants a cube with the above three squares as faces. The required cube, which is constructed by the proof of Proposition \ref{proposition:nonpos}, is  %\[ \mathcal{C}_{1,2,3} = \mathcal{C}(\{ B_{00}, [f,X], B_{11} \}, \{ B_{00}, [f,X], B_{11} \}). \] %Indeed, using the binary $j$-tuple notation introduced in Remark \ref{remark:cubes}, and %letting $B_{00}$, $[f,X]$, and $B_{11}$ determine the first, second, and third coordinates (respectively) of $\mathcal{C}_{1,2,3}$, we have the following correspondence: % %\mathcal{C}_{1,2} &\sim [0,1] \times \{ 1 \} \times [0,1] \\ %\mathcal{C}_{1,3} &\sim [0,1] \times [0,1] \times \{ 0 \} \\ %\mathcal{C}_{2,3} &\sim \{ 0 \} \times [0,1] \times [0,1] % %",2502.01544
theorem,[\cite{GoosS16}] 		 		Non-3-colorability has local complexity~$\Omega(n^2/\log 			n)$.,2502.01551
theorem,Non-3-colorability of graphs of maximum degree~4 has                 local complexity~$\Omega(n/\log n)$.,2502.01551
theorem,Non-3-colorability of planar graphs of maximum                 degree~4 has local complexity~$\Omega(\sqrt{n}/\log^2 n)$.,2502.01551
theorem,"For any fixed $k\ge 3$, non-$k$-colorability has local                 complexity at least $\Omega(n^2/\log 			n)$ in general graphs, and at least $\Omega(n/\log 			n)$ in graphs of maximum degree~$5k-4$.",2502.01551
theorem,"Assume that: 		 			\item there exists a certification scheme for $\p'$ with certificates of size 			$s(n)$, where $s : \mathbb{N} \to \mathbb{N}$ is an increasing function satisfying $s(n) = \Omega(\log n)$, and 			\item there exists a local reduction from $\p$ to $\p'$ with local expansion 			$\alpha$ and global expansion~$\beta$. 		 		Then there exists a certification scheme for $\p$ with certificates of size 		$O\big(\alpha(n) \cdot s(\beta(n))\big)$.",2502.01551
theorem,"The property of having domatic number at most two has                 local complexity $\Omega(n/\log n)$, even in graphs of maximum degree 		at most~8.",2502.01551
theorem,"The local complexity of the property of not containing                 a cubic subgraph is $\Omega(n/\log n)$, even in graphs of maximum degree 		at most~7.",2502.01551
theorem,"For any fixed $k \geqslant 3$, the property that  the                 vertex set of a given graph $G$ cannot be partitioned into $k$                 induced forests has local complexity  $\Omega(n/\log n)$.",2502.01551
theorem,"The property of having no 2-edge-coloring without monochromatic triangles has local                 complexity $\Omega(n/\log n)$, even in graphs of maximum degree~40.",2502.01551
theorem,"Let $\C, \C'$ be two graph classes, and $\F$ be a class of 3-CNF formulae. Let 		$\p$ be a graph property on $\C$. If there exists a local reduction from 3-SAT 		(in $\F$) to $\p$ with local expansion $\alpha$ and global expansion $\beta$, and if $\varphi_G \in \F$ for all $G 		\in \C'$, then there exists a local reduction from 3-colorability in $\C'$ 		to $\p$ with local expansion~$\alpha'$ and global expansion~$\beta'$, where $\alpha'(n)=3\alpha(3n)$ and $\beta'(n)=\beta(3n)$.",2502.01551
theorem,"The property of not having a Hamiltonian cycle has                 local complexity  $\Omega(\sqrt{n}/\log n)$, even in graphs of 		maximum degree~at most~4.",2502.01551
theorem,"The property of  having chromatic                 index $\Delta+1$ (where $\Delta$ denotes the maximum degree) has local complexity $\Omega(n/\log                 n)$, even in cubic graphs	.",2502.01551
theorem,"Let $k \geqslant 3$. In graphs of maximum degree~$k + \lceil\sqrt{k}\rceil - 1$, non-$k$-colorability has local                 complexity $\Omega(n/\log n)$.",2502.01551
theorem,"Let $k$ be a sufficiently large integer. In graphs of maximum degree \mbox{$k + \lceil\sqrt{k}\rceil - 3$}, non-$k$-colorability has local                 complexity $O(\log n)$.",2502.01551
proof,"For a graph $G$, we construct a new graph $f(G)$ of maximum         degree~4 such that $G$ is 3-colorable if and only if $f(G)$ is         3-colorable (this is a classical construction~\cite{GareyJS76}). The graph $f(G)$ is constructed as follows: for every vertex $u$ of degree~$d$ in $G$, we consider the graph $G_u$ depicted in Figure~\ref{fig:3col4}, where the $d$ white vertices are indexed by the neighbors of $u$ in $G$. Observe that in any 3-coloring of $G_u$, all the white vertices receive the same color. The graph $f(G)$ is obtained by taking the disjoint union of all graphs $G_u$, for $u\in V(G)$, and adding, for every edge $uv\in E(G)$, an edge between the vertex of $G_u$ indexed by $v$ and the vertex of $G_v$ indexed by $u$. Note that $f(G)$ has maximum degree~$4$ and is 3-colorable if and only if $G$ is 3-colorable. As each graph $G_u$ contains at most $8d_G(u)$ vertices, $f(G)$ contains at most $16|E(G)|\le 8|V(G)|^2$ vertices.   \smallskip  [htb]   \centering   \includegraphics[scale=1.2]{4col}   \caption{The graph $G_u$.}        For any integer $k$, and any two subsets                   $A\subseteq [2^k]^2 $ and $B\subseteq [2^k]^2$, we                   consider the graph $G_{A,B}$ of G\""o\""os and Suomela                   \cite{GoosS16} introduced above, and we let                   $H_{A,B}=f(G_{A,B})$. Note that $H_{A,B}$ contains                   $n=\Theta(2^{2k})$ vertices, and moreover:                     \item $H_{A,B}$ can be partitioned into two parts $V_A$ (such that $H_{A,B}[V_A]$ depends   only on $A$) and $V_B$ (such that $H_{A,B}[V_B]$ depends   only on   $B$).   \item $V_A$ contains a set $S_A$ of $\Theta(\log n)$ special vertices, and     $V_B$ contains a set $S_B$ of $\Theta(\log n)$ special vertices.       \item Each edge between $V_A$ and $V_B$ in $G_{A,B}$, connects a     vertex of      $S_A$ to a vertex of $S_B$,      and the subgraph of $G_{A,B}$ induced by the special vertices     $S_A\cup S_B$ is independent of the     choice of $A$ and $B$.      \item $G_{A,B}$ is 3-colorable if and only if $A\cap B\ne \emptyset$.                    The fact that the sets $S_A$ and $S_B$ still have size $O(\log n)$ in $H_{A,B}$ follows from item 3 in the properties of $G_{A,B}$ (the fact that there are only $O(\log n)$ edges with one endpoint in $S_A$ and one endpoint in $S_B$).  As above, if non-3-colorability can be certified locally with                   certificates of size $o(n/\log n)$ in graphs of                   maximum degree~4, the total                   number of bits of certificates assigned to the                   special vertices of $H_{A,B}$ is $o(n)$.  Since there are $2^{(2^{k})^2}=2^{\Omega(n)}$ choices for the sets $A$,                   it follows from the pigeonhole principle that there exist                   two distinct sets $A,B$ such that the certificates of $G_{A,\bar{A}}$ and                   $G_{B,\bar{B}}$ agree on their special vertices. We                   then obtain a contradiction using the same fooling set argument as                   above.",2502.01551
proof,"We start with the graph $H_{A,B}$ constructed in the proof of Theorem \ref{thm:non3coldegmax4_lineaire}, and draw it in the plane with $V_A$ inside a region $R_A$, $V_B$ inside a region $R_B$ disjoint from $R_A$, with the vertices of $S_A$ lying on the boundary of $R_A$ and the vertices $S_B$ lying on the boundary of $R_B$. Moreover we make sure that the bipartite graph induced by the edge $E(S_A,S_B)$ with one endpoint in $S_A$ and the other in $S_B$ is drawn outside of the interior of $R_A$ and $R_B$ (so that the edges between $S_A$ and $S_B$ do not cross any other edge of $H_{A,B}[V_A]$ and $H_{A,B}[V_B]$), see Figure \ref{fig:ABplanar}. We call crossings between edges of $E(S_A,S_B)$ \emph{special crossings}.  [htb]   \centering   \includegraphics[scale=0.9]{ABplanar}   \caption{Drawing $H_{A,B}$ in the plane before the addition of uncrossing gadgets.}       We then use uncrossing gadgets introduced in \cite{GareyJS76} (see Figure \ref{fig:cross} for an illustration). Let $P_{A,B}$ be the resulting planar graph (which is 3-colorable if and only if $A\cap B\ne \emptyset$). Note that the number of vertices of $P_{A,B}$ is equal to the number of vertices of $H_{A,B}$ plus  a constant number of vertices per crossing. As $H_{A,B}$ has $n=\Theta(2^{2k})$ vertices and maximum degree~4, it has $\Theta(2^{2k})$ edges and thus at most $O(2^{4k})$ edge crossings. It follows that the planar graph $P_{A,B}$ has $O(2^{4k})$ vertices. Note that $P_{A,B}$ has maximum degree~$4\cdot 3=12$, as  $H_{A,B}$ has maximum degree~4. \smallskip  [htb]   \centering   \includegraphics[scale=0.8]{cross}   \caption{Uncrossing gadgets.}       As $S_A$ and $S_B$ have size $O(\log n)$ in $H_{A,B}$ and this graph has maximum degree~4, $E(S_A,S_B)$ contains $O(\log n)$ edges, and thus there are $O(\log^2 n)$ special crossings. It follows that there are $O(\log^2 n)$ special vertices in $P_{A,B}$ (as each new crossing of $H_{A,B}$ creates a constant number of new vertices in $P_{A,B}$).  We now consider $P'_{A,B}=f(P_{A,B})$ (the graph obtained from $P_{A,B}$ by applying the maximum degree~4 reduction of the proof of Theorem \ref{thm:non3coldegmax4_lineaire}). This graph is a planar graph with maximum degree~4, is 3-colorable if and only if $A\cap B\ne \emptyset$, has $n=O(2^{4k})$ vertices, but only contains $O(\log^2 n)$ special vertices. There are $2^{(2^k)^2}=2^{2^{2k}}=2^{\Omega(\sqrt{n})}$ choices for the set $A$, so if we can locally certify non-3-colorability with certificates of size $o(n^{1/2}/\log^2 n)$ then the total number of bits of certificates assigned to the special vertices is $o(n^{1/2})$ and thus there are two distinct sets $A,B$ such that the certificates of $P'_{A,\bar{A}}$ and $P'_{B,\bar{B}}$ agree on their special vertices. We then obtain a contradiction using the same fooling set argument as above.",2502.01551
proof,"\item By contradiction, assume that there exists a certification scheme for 			$\np$ with certificates of size $o\big(n^{(2-\delta)/\gamma}/\log n\big)$. 			By Theorem~\ref{thm:main theorem local reduction}, there exists a 			certification scheme for non-$k$-colorability with certificates of size 			\[o\left(n^\delta \cdot \frac{(n^{\gamma})^{(2-\delta)/\gamma}}{\log n}\right) = 			o\left(\frac{n^2}{\log n}\right),\] which contradicts 			Theorem~\ref{thm:nonkcol_quadratique} 			\item By contradiction, assume that there exists a certification scheme for 			$\np$ with certificates of size $o\big(n^{(1-\delta)/\gamma}/\log n\big)$. 			By Theorem~\ref{thm:main theorem local reduction}, there exists a 			certification scheme for non-$k$-colorability in graphs of maximum degree~$k + \lceil\sqrt{k}\rceil-1$ with 			certificates of size $o\big(n^\delta \cdot \frac{(n^{\gamma})^{(1-\delta)/\gamma}}{\log n}\big) = 			o\big(\frac{n}{\log n}\big)$, which contradicts Theorem~\ref{thm:nonkcol_quadratique} and Remark~\ref{rem:k+sqrtk-1}.",2502.01551
proof,"[Proof of Theorem~\ref{thm:main theorem local reduction}.] 	Let $G \in \C$ be an $n$-vertex graph in which the vertices are given 		unique identifiers on $O(\log n)$ bits. First, using a                 renaming technique from~\cite{BousquetEFZ24}, we can                 assume that the unique identifiers                 $(\mathrm{id}(u))_{u\in V(G)}$ of~$G$ are in $\{1,                 \ldots, n\}$, at a cost of $O(\log n)$ additional bits                 per certificates. Since $s(n) = \Omega(\log n)$ and $\beta(n) \geqslant n$, we                 have $\log n=O\big(\alpha(n) \cdot s(\beta(n))\big)$, so it                 does not affect the final bound. We also assume that                 every vertex knows~$n$ (because it can also be                 certified at a cost of $O(\log n)$ bits in the                 certificates using a spanning tree,                 see~\cite{Feuilloley21} for more details).                                   \medskip                  \noindent {\bf Certification.}		The certification of $\p$ for $G$ consists in the following. The certificate given by the prover to each vertex consists in a table. For every $u \in V(G)$, we will denote this table by $\tab(u)$. To construct this table, the prover first computes the graph $G'=f_{\p, \p'}(G)$, and for every vertex $u \in V(G)$, it determines the sets~$C_u$ and~$V_u$. The entries of $\tab(u)$ are indexed by the identifiers 		in~$G'$ of the vertices in~$C_u$. For every $t \in C_u$, we will 		denote by $\tab(u)[t]$ the entry of $\tab(u)$ indexed by the identifier of~$t$. 		The prover writes in $\tab(u)[t]$ the certificate that $t$ would get in the 		certification scheme for $\p'$ in~$G'$. 		 		 		Let us show that these certificates have size $O\big(\alpha(n) \cdot  s(\beta(n))\big)$. 		By definition of global expansion, the graph~$G'$ has at most $\beta(n)$ vertices. Thus, each 		certificate (corresponding to the proof labeling scheme for~$\p'$ 		in~$G'$) written in $\tab(u)$ has size at most $s(\beta(n))$. Since 		this table has at most $\alpha(n)$ entries (one for each vertex in $C_u$), its 		size is $O\big(\alpha(n) \cdot s(\beta(n))\big)$. 		 		\medskip 		 		\noindent {\bf Verification.} 		The verification procedure of each vertex $u\in V(G)$ consists in the following steps. 		At each step, if the verification fails, the procedure                 stops and $u$ rejects                 the instance. 		 		[(1)]%[label=(\roman*)] 			\item First, by condition \cref{l3f}, $u$ can compute the identifiers of all the 			vertices in~$C_u$. It checks that every vertex in $C_u$ has exactly one entry in 			$\tab(u)$, and conversely that every entry in $\tab(u)$ is indexed with the 			identifier of a vertex in $C_u$. 			 			\item Then, $u$ checks that, for every $t \in C_u$ and every $v \in N_G[u]$ having an entry indexed by $t$ in $\tab(v)$, we have $\tab(u)[t] = \tab(v)[t]$. 			 			 			\item Finally, $u$ does the following. By condition \cref{l3f}, $u$ can compute 			the set $V_u$ and the subgraph (with identifiers) of $G'$ 			formed by $V_u$ and the adjacent edges. In particular, for every $t_0 \in V_u$, $u$ can compute the 			subgraph  of $G'$ formed by $t_0$ and its incident edges. 			 			Let $t_0 \in V_u$. Since $V_u \subseteq C_u$, $u$ can determine the certificate 			that $t_0$ would have in the certification scheme for $\p'$ in $G'$, 			because it is written in $\tab(u)[t_0]$. 			Moreover, by condition \cref{l3e}, every neighbor $t$ of $t_0$ in $G'$ 			is in $\bigcup_{v \in N_G[u]} C_v$, so $u$ can also determine the certificate of 			$t$ because it is written in $\tab(v)[t]$ for some $v \in N_G[u]$. 			 			Thus, for all $t_0 \in V_u$, $u$ can recover the certificates of all the 			vertices in $N_{G'}[t_0]$, so $u$ can compute                         the local view of $t_0$ in $G'$, 			and can apply the verification procedure of                         the proof labeling scheme for $\p'$ in $G'$. If this fails for some $t_0 \in 			V_{u}$, then $u$ rejects. 			 			\item If $u$ did not reject at any previous                           step, $u$ accepts the instance. 		 		 		 		 		 		Let us prove that this proof labeling scheme for $\p$ is correct, by proving its 		completeness and its soundness.                  \medskip 		 		\noindent{\bf Completeness.} 		Assume that $G$ satisfies $\p$ (and thus $G'$                 satisfies $\p'$), and let us prove that with the assignment of 		the certificates described above, every vertex accepts                 the instance. 		First, no vertex can reject at steps~(i) or~(ii), because the prover correctly wrote in $\tab(u)$ the list of the certificates that all the vertices in $C_u$ would 		receive in the proof labeling scheme for $\p'$ in $G'$. 		Let us look at step~(iii). Since  		$G'$ satisfies $\p'$, all the vertices of $G'$ accept                 the instance in the labeling scheme for $\p'$ in $G'$. 		Hence, all the vertices in $V_u$ accept, and so $u$                 cannot reject the instance at 		step~(iii). 		Finally, since it did not reject before, $u$ accepts                 the instance at step~(iv). 		 		\medskip 		 		\noindent{\bf Soundness.} 		Assume now that all the vertices of $G$ accept the                 instance given some assignment of  		certificates, and let us show that in this case $G$                 satisfies~$\p$. By property~2 of the definition of a                 local reduction, it is enough to prove that $G'$ satisfies~$\p'$. 		By property \cref{l3f}, every vertex $u$ can indeed compute the sets $C_u$, 		$V_u$, and the subgraph of $G'$ formed by the vertices in $V_u$ and their incident edges. 		Since $u$ did not reject the instance at step~(i), $\tab(u)$ has exactly one entry for each 		vertex $t \in C_u$. 		 		To prove that $G'$ satisfies $\p$, it is sufficient to show that 		there exists an assignment of certificates to the vertices of 		$G'$ such that the verification procedure for $\p'$ accepts at every 		vertex. Let $t \in V(G')$. By property \cref{l3a} and \cref{l3b}, there exists 		$u \in V(G)$ such that $t \in C_u$. Let us show that, for every other vertex $w 		\in V(G)$ such that $t \in C_w$, we have $\tab(u)[t] = \tab(w)[t]$. 		By property \cref{l3d}, the subgraph of $G$ induced by the set $\{v \in V(G) \; | \; 		t \in C_v\}$ is connected. So there exists a path $u_1, \ldots, u_k$ in $G$ such 		that $u_1=u$, $u_k=w$, and $t \in C_{u_i}$ for every $i \in \{1, \ldots, k\}$. 		For every $i \in \{1, \ldots, k-1\}$, since $u_i$ did not reject at step~(ii) 		of the verification procedure, we have $\tab(u_i)[t]=\tab(u_{i+1})[t]$. This 		implies $\tab(u)[t]=\tab(w)[t]$. 		 		Hence, for every $t \in V(G')$, we can define $c(t)$ as the 		certificate of $t$ written in $\tab(u)[t]$ for all the vertices $u \in V(G)$ such 		that $t \in C_u$. By the previous discussion, $c(t)$                 exists and is well defined. 		Let us show that with the certificate assignment $c$, all the vertices in 		$G'$ accept the instance. 		Let $t \in V(G')$, and let $u \in V(G)$ such that $t \in V_u$ (such a 		vertex $u$ exists by property \cref{l3b}). At step~(iii), $u$ computes the view of $t$ 		in $G'$, with the certificate assignment $c$. 		Then, $u$ simulates the verification procedure of~$t$ (in the certification 		scheme for $\p'$ in $G'$). Since $u$ accepts, then $t$ must accept with the certificates 		given by $c$. Since this is the case for every $t \in V(G')$, this shows 		that $G'$ satisfies $\p'$, and thus $G$ satisfies $\p$, which concludes the proof. 		\qedhere",2502.01551
proof,"Let $\p$ be the property of having domatic number at least~3. We will show that 		there exists a local reduction from 3-colorability in graphs of maximum degree~4 		to $\p$ with local expansion~$O(1)$, and the result will follow from 		Corollary~\ref{cor:reduction3col}. Let $G$ be a graph of maximum degree~at 		most~4, with $n$ vertices having unique identifiers in $\{1, \ldots, n\}$. 		 		The construction of the graph $G'=f_{\text{3-col}, \p}(G)$ is the following. For each edge $uv\in 		E(G)$, we add a new vertex~$w$ connected only to $u$                 and $v$ (see 		Figure~\ref{fig:domatic_edge}). 		 		[h] 			\centering 			[x=0.75pt,y=0.75pt,yscale=-1,xscale=1] 				%uncomment if require: \path (0,429); %set diagram left start at 0, and has 				%height of 429 				 				%Straight Lines [id:da5937006283071847]  				\draw    (316.5,85.5) -- (350.5,122.5) ; 				%Straight Lines [id:da2216288388936053]  				\draw    (283.5,122.5) -- (316.5,85.5) ; 				%Straight Lines [id:da14164324658008887]  				\draw    (68.5,122.5) -- (135.5,122.5) ; 				%Shape: Circle [id:dp8265950408354881]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(64,122.5) .. controls (64,120.01) and (66.01,118) .. (68.5,118) .. controls 				(70.99,118) and (73,120.01) .. (73,122.5) .. controls (73,124.99) and 				(70.99,127) .. (68.5,127) .. controls (66.01,127) and (64,124.99) .. (64,122.5) 				-- cycle ; 				%Shape: Circle [id:dp16048633330678197]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(131,122.5) .. controls (131,120.01) and (133.01,118) .. (135.5,118) .. controls 				(137.99,118) and (140,120.01) .. (140,122.5) .. controls (140,124.99) and 				(137.99,127) .. (135.5,127) .. controls (133.01,127) and (131,124.99) .. 				(131,122.5) -- cycle ; 				%Straight Lines [id:da6017150229553048]  				\draw    (283.5,122.5) -- (350.5,122.5) ; 				%Shape: Circle [id:dp2725970565329351]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(279,122.5) .. controls (279,120.01) and (281.01,118) .. (283.5,118) .. controls 				(285.99,118) and (288,120.01) .. (288,122.5) .. controls (288,124.99) and 				(285.99,127) .. (283.5,127) .. controls (281.01,127) and (279,124.99) .. 				(279,122.5) -- cycle ; 				%Shape: Circle [id:dp25633931919865016]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(346,122.5) .. controls (346,120.01) and (348.01,118) .. (350.5,118) .. controls 				(352.99,118) and (355,120.01) .. (355,122.5) .. controls (355,124.99) and 				(352.99,127) .. (350.5,127) .. controls (348.01,127) and (346,124.99) .. 				(346,122.5) -- cycle ; 				%Shape: Circle [id:dp8884308920793911]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(312,85.5) .. controls (312,83.01) and (314.01,81) .. (316.5,81) .. controls 				(318.99,81) and (321,83.01) .. (321,85.5) .. controls (321,87.99) and 				(318.99,90) .. (316.5,90) .. controls (314.01,90) and (312,87.99) .. (312,85.5) 				-- cycle ; 				%Straight Lines [id:da5062904617143006]  				\draw [line width=1.5]    (178.5,104) -- (235.5,104) ; 				\draw [shift={(239.5,104)}, rotate = 180] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (11.61,-5.58) -- (0,0) -- 				(11.61,5.58) -- cycle    ; 				 				% Text Node 				\draw (72,130) node [anchor=north west][inner sep=0.75pt]    {$u$}; 				% Text Node 				\draw (137.5,130) node [anchor=north west][inner sep=0.75pt]    {$v$}; 				% Text Node 				\draw (286,130) node [anchor=north west][inner sep=0.75pt]    {$u$}; 				% Text Node 				\draw (354,130) node [anchor=north west][inner sep=0.75pt]    {$v$}; 				% Text Node 				\draw (320.5,68) node [anchor=north west][inner sep=0.75pt]    {$w$};	 			 			\caption{The reduction from 3-colorability to domatic number at least~3.} 			 		 		 		The identifier of each vertex in $G'$ indicates if it is a vertex 		of $G$ (and which one), or a vertex added for an edge of $G$ (and which edge). 		This information can be encoded on $O(\log n)$ bits. 		 		For each vertex $u$ of $G$, we define $C_u:=V_u$ as the set containing $u$ and 		all the vertices corresponding to an edge $uv$ in $G$ (see Figure~\ref{fig:domatic_graph}). 		 		[h] 			\centering 			[x=0.65pt,y=0.65pt,yscale=-1,xscale=1] 				%uncomment if require: \path (0,444); %set diagram left start at 0, and has 				%height of 444 				 				%Straight Lines [id:da18962705206665476]  				\draw    (332,58.5) -- (393,79.5) ; 				%Straight Lines [id:da11735320311912889]  				\draw    (393,79.5) -- (414,140.5) ; 				%Straight Lines [id:da018735395921172238]  				\draw    (373,24.5) -- (414,58.5) ; 				%Straight Lines [id:da9287129310159072]  				\draw    (373,24.5) -- (332,58.5) ; 				%Straight Lines [id:da058814572593892445]  				\draw    (297,99.5) -- (332,58.5) ; 				%Straight Lines [id:da46650971351261916]  				\draw    (297,99.5) -- (332,140.5) ; 				%Straight Lines [id:da413190086010898]  				\draw    (414,58.5) -- (449,98.5) ; 				%Straight Lines [id:da0918672232298342]  				\draw    (414,140.5) -- (449,98.5) ; 				%Straight Lines [id:da04368856803600163]  				\draw    (332,140.5) -- (373,173.5) ; 				%Straight Lines [id:da11842414938671375]  				\draw    (373,173.5) -- (414,140.5) ; 				%Straight Lines [id:da9743484290861458]  				\draw    (58.5,57.5) -- (140.5,57.5) ; 				%Straight Lines [id:da5438525941575618]  				\draw    (58.5,57.5) -- (58.5,139.5) ; 				%Straight Lines [id:da21539419928060088]  				\draw    (140.5,57.5) -- (140.5,139.5) ; 				%Straight Lines [id:da30083399948096]  				\draw    (58.5,139.5) -- (140.5,139.5) ; 				%Straight Lines [id:da6144878513432371]  				\draw    (58.5,57.5) -- (140.5,139.5) ; 				%Shape: Circle [id:dp7111489862005388]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(53,57.5) .. controls (53,54.46) and (55.46,52) .. (58.5,52) .. controls 				(61.54,52) and (64,54.46) .. (64,57.5) .. controls (64,60.54) and (61.54,63) .. 				(58.5,63) .. controls (55.46,63) and (53,60.54) .. (53,57.5) -- cycle ; 				%Shape: Circle [id:dp4261438095565895]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(135,57.5) .. controls (135,54.46) and (137.46,52) .. (140.5,52) .. controls 				(143.54,52) and (146,54.46) .. (146,57.5) .. controls (146,60.54) and 				(143.54,63) .. (140.5,63) .. controls (137.46,63) and (135,60.54) .. (135,57.5) 				-- cycle ; 				%Shape: Circle [id:dp38809901601025165]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(53,139.5) .. controls (53,136.46) and (55.46,134) .. (58.5,134) .. controls 				(61.54,134) and (64,136.46) .. (64,139.5) .. controls (64,142.54) and 				(61.54,145) .. (58.5,145) .. controls (55.46,145) and (53,142.54) .. (53,139.5) 				-- cycle ; 				%Shape: Circle [id:dp05710478557782761]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 , 				line width=1.5] (135,139.5) .. controls (135,136.46) and (137.46,134) .. 				(140.5,134) .. controls (143.54,134) and (146,136.46) .. (146,139.5) .. controls 				(146,142.54) and (143.54,145) .. (140.5,145) .. controls (137.46,145) and 				(135,142.54) .. (135,139.5) -- cycle ; 				%Straight Lines [id:da7873122010190594]  				\draw    (332,58.5) -- (414,58.5) ; 				%Straight Lines [id:da10653756355881205]  				\draw    (332,58.5) -- (332,140.5) ; 				%Straight Lines [id:da1854158887347621]  				\draw    (414,58.5) -- (414,140.5) ; 				%Straight Lines [id:da3474302608125487]  				\draw    (332,140.5) -- (414,140.5) ; 				%Straight Lines [id:da5090818454018725]  				\draw    (332,58.5) -- (414,140.5) ; 				%Shape: Circle [id:dp9033910417551686]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(326.5,58.5) .. controls (326.5,55.46) and (328.96,53) .. (332,53) .. controls 				(335.04,53) and (337.5,55.46) .. (337.5,58.5) .. controls (337.5,61.54) and 				(335.04,64) .. (332,64) .. controls (328.96,64) and (326.5,61.54) .. 				(326.5,58.5) -- cycle ; 				%Shape: Circle [id:dp3627766352172358]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(408.5,58.5) .. controls (408.5,55.46) and (410.96,53) .. (414,53) .. controls 				(417.04,53) and (419.5,55.46) .. (419.5,58.5) .. controls (419.5,61.54) and 				(417.04,64) .. (414,64) .. controls (410.96,64) and (408.5,61.54) .. 				(408.5,58.5) -- cycle ; 				%Shape: Circle [id:dp9049882031327144]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(326.5,140.5) .. controls (326.5,137.46) and (328.96,135) .. (332,135) .. 				controls (335.04,135) and (337.5,137.46) .. (337.5,140.5) .. controls 				(337.5,143.54) and (335.04,146) .. (332,146) .. controls (328.96,146) and 				(326.5,143.54) .. (326.5,140.5) -- cycle ; 				%Shape: Circle [id:dp5588179766908783]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(408.5,140.5) .. controls (408.5,137.46) and (410.96,135) .. (414,135) .. 				controls (417.04,135) and (419.5,137.46) .. (419.5,140.5) .. controls 				(419.5,143.54) and (417.04,146) .. (414,146) .. controls (410.96,146) and 				(408.5,143.54) .. (408.5,140.5) -- cycle ; 				%Shape: Circle [id:dp10431321639293145]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(367.5,24.5) .. controls (367.5,21.46) and (369.96,19) .. (373,19) .. controls 				(376.04,19) and (378.5,21.46) .. (378.5,24.5) .. controls (378.5,27.54) and 				(376.04,30) .. (373,30) .. controls (369.96,30) and (367.5,27.54) .. 				(367.5,24.5) -- cycle ; 				%Shape: Circle [id:dp6545023378426509]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(443.5,98.5) .. controls (443.5,95.46) and (445.96,93) .. (449,93) .. controls 				(452.04,93) and (454.5,95.46) .. (454.5,98.5) .. controls (454.5,101.54) and 				(452.04,104) .. (449,104) .. controls (445.96,104) and (443.5,101.54) .. 				(443.5,98.5) -- cycle ; 				%Shape: Circle [id:dp2950276905540239]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(291.5,99.5) .. controls (291.5,96.46) and (293.96,94) .. (297,94) .. controls 				(300.04,94) and (302.5,96.46) .. (302.5,99.5) .. controls (302.5,102.54) and 				(300.04,105) .. (297,105) .. controls (293.96,105) and (291.5,102.54) .. 				(291.5,99.5) -- cycle ; 				%Shape: Circle [id:dp7643533827507459]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(367.5,173.5) .. controls (367.5,170.46) and (369.96,168) .. (373,168) .. 				controls (376.04,168) and (378.5,170.46) .. (378.5,173.5) .. controls 				(378.5,176.54) and (376.04,179) .. (373,179) .. controls (369.96,179) and 				(367.5,176.54) .. (367.5,173.5) -- cycle ; 				%Shape: Circle [id:dp9859275545502788]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(387.5,79.5) .. controls (387.5,76.46) and (389.96,74) .. (393,74) .. controls 				(396.04,74) and (398.5,76.46) .. (398.5,79.5) .. controls (398.5,82.54) and 				(396.04,85) .. (393,85) .. controls (389.96,85) and (387.5,82.54) .. 				(387.5,79.5) -- cycle ; 				%Shape: Polygon Curved [id:ds682127764903248]  				\draw  [dash pattern={on 5.63pt off 4.5pt}][line width=1.5]  (394.5,135) .. controls (400.5,124) and (363.5,72) .. (389.5,63) .. controls (415.5,54) and (398.5,102) .. (413.5,113) .. controls (428.5,124) and (435.5,72) .. (456.5,83) .. controls (477.5,94) and (442.5,137.25) .. (425.5,150) .. controls (408.5,162.75) and (367.5,202) .. (357.5,185) .. controls (347.5,168) and (388.5,146) .. (394.5,135) -- cycle ; 				 				 				% Text Node 				\draw (142.5,148.4) node [anchor=north west][inner sep=0.75pt]    {$u$}; 				% Text Node 				\draw (450,140) node [anchor=north west][inner sep=0.75pt]    {$V_u$}; 				% Text Node 				\draw (92,162) node [anchor=north west][inner sep=0.75pt]  [font=\large]  				{$G$}; 				% Text Node 				\draw (332,195.4) node [anchor=north west][inner sep=0.75pt]  [font=\large]  				{$G'$}; 				 			 			\caption{Some graphs $G$ and $G'=f_{\text{3-col}, \p}(G)$. %The green vertices in $f_{3-col, \p}(G)$ are the vertices in $V_u$. 			} 			 		 		 		Let us show that $G$ admits a proper 3-coloring if and only if the domatic 		number of $G'$ is at least~3. Assume that $G$ is 3-colorable. Then, 		we create a partition of the vertices of $G'$ in the following 		way: we keep the partition into color classes, and for each new vertex $w$ 		corresponding to an edge $uv$ of~$G$, we assign it to the part to which 		neither $u$ nor $v$ belongs to. See Figure~\ref{fig:domatic_partition} for an 		example. Each part of the partition is a dominating set: indeed, each vertex of 		$G'$ belongs to some triangle formed by two original adjacent 		vertices of $G$ and the new vertex corresponding to the edge, and by 		construction, each of the three parts of the partition dominates this triangle. 		Conversely, assume that the vertices of $G'$ can be                 partitioned into at least 3 dominating sets. Then, we obtain a proper 3-coloring of $G$ by restricting 		this partition to the original vertices of~$G$: indeed, let $uv$ be an edge of $G$, 		and $w$ be the vertex of $G'$ corresponding to this edge. Since 		there are only three vertices in $N[w]$ (which are $u$, $v$ and $w$), these 		3 vertices are in different parts of the partition                 and the partition consists of exactly 3 dominating                 sets (otherwise, some part does not 		dominate~$w$). In particular, $u$ and $v$ are in different parts, and the corresponding 		3-coloring of $G$ is indeed proper. 		 		[h] 			\centering 			[x=0.65pt,y=0.65pt,yscale=-1,xscale=1] 				%uncomment if require: \path (0,444); %set diagram left start at 0, and has 				%height of 444 				 				%Straight Lines [id:da8203057539066206]  				\draw    (332,58.5) -- (393,79.5) ; 				%Straight Lines [id:da05388478202867819]  				\draw    (393,79.5) -- (414,140.5) ; 				%Straight Lines [id:da7027983488100632]  				\draw    (373,24.5) -- (414,58.5) ; 				%Straight Lines [id:da203308039010075]  				\draw    (373,24.5) -- (332,58.5) ; 				%Straight Lines [id:da5292957292409853]  				\draw    (297,99.5) -- (332,58.5) ; 				%Straight Lines [id:da7724600955931391]  				\draw    (297,99.5) -- (332,140.5) ; 				%Straight Lines [id:da6306424918061002]  				\draw    (414,58.5) -- (449,98.5) ; 				%Straight Lines [id:da17160394040441063]  				\draw    (414,140.5) -- (449,98.5) ; 				%Straight Lines [id:da07355145733100477]  				\draw    (332,140.5) -- (373,173.5) ; 				%Straight Lines [id:da08497952824149535]  				\draw    (373,173.5) -- (414,140.5) ; 				%Straight Lines [id:da72263825831237]  				\draw    (58.5,57.5) -- (140.5,57.5) ; 				%Straight Lines [id:da7163113969305926]  				\draw    (58.5,57.5) -- (58.5,139.5) ; 				%Straight Lines [id:da028493906717569906]  				\draw    (140.5,57.5) -- (140.5,139.5) ; 				%Straight Lines [id:da7868527759143722]  				\draw    (58.5,139.5) -- (140.5,139.5) ; 				%Straight Lines [id:da9635730731183374]  				\draw    (58.5,57.5) -- (140.5,139.5) ; 				%Shape: Circle [id:dp7483460837095256]  				\draw  [fill={rgb, 255:red, 80; green, 227; blue, 194 }  ,fill opacity=1 ] 				(53,57.5) .. controls (53,54.46) and (55.46,52) .. (58.5,52) .. controls 				(61.54,52) and (64,54.46) .. (64,57.5) .. controls (64,60.54) and (61.54,63) .. 				(58.5,63) .. controls (55.46,63) and (53,60.54) .. (53,57.5) -- cycle ; 				%Shape: Circle [id:dp49787800074234656]  				\draw  [fill={rgb, 255:red, 245; green, 166; blue, 35 }  ,fill opacity=1 ] 				(135,57.5) .. controls (135,54.46) and (137.46,52) .. (140.5,52) .. controls 				(143.54,52) and (146,54.46) .. (146,57.5) .. controls (146,60.54) and 				(143.54,63) .. (140.5,63) .. controls (137.46,63) and (135,60.54) .. (135,57.5) 				-- cycle ; 				%Shape: Circle [id:dp8053761312373717]  				\draw  [fill={rgb, 255:red, 245; green, 166; blue, 35 }  ,fill opacity=1 ] 				(53,139.5) .. controls (53,136.46) and (55.46,134) .. (58.5,134) .. controls 				(61.54,134) and (64,136.46) .. (64,139.5) .. controls (64,142.54) and 				(61.54,145) .. (58.5,145) .. controls (55.46,145) and (53,142.54) .. (53,139.5) 				-- cycle ; 				%Shape: Circle [id:dp18443207641458492]  				\draw  [fill={rgb, 255:red, 144; green, 19; blue, 254 }  ,fill opacity=1 ] 				(135,139.5) .. controls (135,136.46) and (137.46,134) .. (140.5,134) .. controls 				(143.54,134) and (146,136.46) .. (146,139.5) .. controls (146,142.54) and 				(143.54,145) .. (140.5,145) .. controls (137.46,145) and (135,142.54) .. 				(135,139.5) -- cycle ; 				%Straight Lines [id:da7155618773442066]  				\draw    (332,58.5) -- (414,58.5) ; 				%Straight Lines [id:da6420940618972127]  				\draw    (332,58.5) -- (332,140.5) ; 				%Straight Lines [id:da006917546031812383]  				\draw    (414,58.5) -- (414,140.5) ; 				%Straight Lines [id:da9777628475424845]  				\draw    (332,140.5) -- (414,140.5) ; 				%Straight Lines [id:da30968147969276627]  				\draw    (332,58.5) -- (414,140.5) ; 				%Shape: Circle [id:dp08816083668088259]  				\draw  [fill={rgb, 255:red, 80; green, 227; blue, 194 }  ,fill opacity=1 ] 				(326.5,58.5) .. controls (326.5,55.46) and (328.96,53) .. (332,53) .. controls 				(335.04,53) and (337.5,55.46) .. (337.5,58.5) .. controls (337.5,61.54) and 				(335.04,64) .. (332,64) .. controls (328.96,64) and (326.5,61.54) .. 				(326.5,58.5) -- cycle ; 				%Shape: Circle [id:dp32540825809317964]  				\draw  [fill={rgb, 255:red, 245; green, 166; blue, 35 }  ,fill opacity=1 ] 				(408.5,58.5) .. controls (408.5,55.46) and (410.96,53) .. (414,53) .. controls 				(417.04,53) and (419.5,55.46) .. (419.5,58.5) .. controls (419.5,61.54) and 				(417.04,64) .. (414,64) .. controls (410.96,64) and (408.5,61.54) .. 				(408.5,58.5) -- cycle ; 				%Shape: Circle [id:dp9205386896161238]  				\draw  [fill={rgb, 255:red, 245; green, 166; blue, 35 }  ,fill opacity=1 ] 				(326.5,140.5) .. controls (326.5,137.46) and (328.96,135) .. (332,135) .. 				controls (335.04,135) and (337.5,137.46) .. (337.5,140.5) .. controls 				(337.5,143.54) and (335.04,146) .. (332,146) .. controls (328.96,146) and 				(326.5,143.54) .. (326.5,140.5) -- cycle ; 				%Shape: Circle [id:dp03212280358917441]  				\draw  [fill={rgb, 255:red, 144; green, 19; blue, 254 }  ,fill opacity=1 ] 				(408.5,140.5) .. controls (408.5,137.46) and (410.96,135) .. (414,135) .. 				controls (417.04,135) and (419.5,137.46) .. (419.5,140.5) .. controls 				(419.5,143.54) and (417.04,146) .. (414,146) .. controls (410.96,146) and 				(408.5,143.54) .. (408.5,140.5) -- cycle ; 				%Shape: Circle [id:dp9697032655799873]  				\draw  [fill={rgb, 255:red, 144; green, 19; blue, 254 }  ,fill opacity=1 ] 				(367.5,24.5) .. controls (367.5,21.46) and (369.96,19) .. (373,19) .. controls 				(376.04,19) and (378.5,21.46) .. (378.5,24.5) .. controls (378.5,27.54) and 				(376.04,30) .. (373,30) .. controls (369.96,30) and (367.5,27.54) .. 				(367.5,24.5) -- cycle ; 				%Shape: Circle [id:dp5232723967307862]  				\draw  [fill={rgb, 255:red, 80; green, 227; blue, 194 }  ,fill opacity=1 ] 				(443.5,98.5) .. controls (443.5,95.46) and (445.96,93) .. (449,93) .. controls 				(452.04,93) and (454.5,95.46) .. (454.5,98.5) .. controls (454.5,101.54) and 				(452.04,104) .. (449,104) .. controls (445.96,104) and (443.5,101.54) .. 				(443.5,98.5) -- cycle ; 				%Shape: Circle [id:dp9877875589269723]  				\draw  [fill={rgb, 255:red, 144; green, 19; blue, 254 }  ,fill opacity=1 ] 				(291.5,99.5) .. controls (291.5,96.46) and (293.96,94) .. (297,94) .. controls 				(300.04,94) and (302.5,96.46) .. (302.5,99.5) .. controls (302.5,102.54) and 				(300.04,105) .. (297,105) .. controls (293.96,105) and (291.5,102.54) .. 				(291.5,99.5) -- cycle ; 				%Shape: Circle [id:dp4253241386342862]  				\draw  [fill={rgb, 255:red, 80; green, 227; blue, 194 }  ,fill opacity=1 ] 				(367.5,173.5) .. controls (367.5,170.46) and (369.96,168) .. (373,168) .. 				controls (376.04,168) and (378.5,170.46) .. (378.5,173.5) .. controls 				(378.5,176.54) and (376.04,179) .. (373,179) .. controls (369.96,179) and 				(367.5,176.54) .. (367.5,173.5) -- cycle ; 				%Shape: Circle [id:dp05949491880714308]  				\draw  [fill={rgb, 255:red, 245; green, 166; blue, 35 }  ,fill opacity=1 ] 				(387.5,79.5) .. controls (387.5,76.46) and (389.96,74) .. (393,74) .. controls 				(396.04,74) and (398.5,76.46) .. (398.5,79.5) .. controls (398.5,82.54) and 				(396.04,85) .. (393,85) .. controls (389.96,85) and (387.5,82.54) .. 				(387.5,79.5) -- cycle ; 				%Straight Lines [id:da13784601947046438]  				%			\draw [line width=1.5]    (185,101) -- (233.5,101) ; 				%			\draw [shift={(237.5,101)}, rotate = 180] [fill={rgb, 255:red, 0; green, 0; 					%blue, 0 }  ][line width=0.08]  [draw opacity=0] (11.61,-5.58) -- (0,0) -- 				%(11.61,5.58) -- cycle    ; 				 				% Text Node 				\draw (92,199.4) node [anchor=north west][inner sep=0.75pt]  [font=\large]  				{$G$}; 				% Text Node 				\draw (332,195.4) node [anchor=north west][inner sep=0.75pt]  [font=\large]  				{$G'$}; 				 			 			\caption{The transformation from a proper 3-coloring of~$G$ to a partition in 				3 dominating sets of~$G'=f_{\text{3-col},\p}(G)$. In the drawing of $G'$, the 				colors correspond to the parts of the partition.} 			 		 		 		Finally, let us show that the conditions of the                 definition of local reduction are satisfied. We have already seen that \cref{l1} and \cref{l2} both hold. Properties 		\cref{l3a}, \cref{l3b}, \cref{l3e} and \cref{l3f} simply follow from the definition of $V_u$ and $C_u$. 		For \cref{l3c}, since $G$ has maximum degree~at most~4,  for all $u \in V(G)$ we 		have $|C_u| \leqslant 5$ and thus $|C_u| = O(1)$. For \cref{l3d}, if $C_u \cap C_v \neq 		\emptyset$, then $u$ and $v$ are neighbors. So all                 conditions of a local reduction are verified, and 		Corollary~\ref{cor:reduction3col} gives us a lower                 bound of order $\Omega(n/\log 			n)$ on the local complexity of the problem. Since $G$ has maximum degree~at most~4,  $G'=f_{\text{3-col}, 			\p}(G)$ has maximum degree~at most~8. So this lower bound holds even for graphs 		of maximum degree~at most~8.",2502.01551
proof,"Let $\p$ be the property of having a cubic subgraph. We will show that there is 		a local reduction from 3-colorability in graphs of maximum degree~at most~4 to 		$\p$ with local expansion $O(1)$. The result will then follow from 		Corollary~\ref{cor:reduction3col}. Let $G$ be a graph of maximum degree~at 		most~4, with $n$ vertices having unique identifiers in $\{1, \ldots, n\}$. 		 		Let us describe the graph $G'=f_{\text{3-col}, \p}(G)$. First, we define a \emph{linking 			component with $d$ outputs}. It consists in a cycle of length $2d+1$, and for 		$d$ pairs of consecutive vertices, we add a new vertex linked to both vertices 		of this pair, to form a triangle. The vertex of the cycle which does not belong 		to these pairs is called the \emph{root}. The vertices which are not in the 		cycle are called the \emph{terminals}. The remaining vertices are called the 		\emph{internal vertices}. Note that all internal vertices have degree~3. See 		Figure~\ref{fig:linking} for an example. 		 		[h] 			\centering 			[x=0.6pt,y=0.6pt,yscale=-1,xscale=1] 				%uncomment if require: \path (0,555); %set diagram left start at 0, and has 				%height of 555 				 				%Rounded Rect [id:dp6791706375326444]  				\draw   (441,202.8) .. controls (441,199.04) and (444.04,196) .. (447.8,196) 				-- (597.7,196) .. controls (601.46,196) and (604.5,199.04) .. (604.5,202.8) -- 				(604.5,223.2) .. controls (604.5,226.96) and (601.46,230) .. (597.7,230) -- 				(447.8,230) .. controls (444.04,230) and (441,226.96) .. (441,223.2) -- cycle ; 				%Straight Lines [id:da16821178598436304]  				\draw    (447.8,230) -- (522.75,263) ; 				%Straight Lines [id:da7311947498904257]  				\draw    (522.75,263) -- (597.7,230) ; 				%Straight Lines [id:da49806142133544706]  				\draw    (12,184.5) -- (188.75,291.25) ; 				%Straight Lines [id:da5351890439294978]  				\draw    (188.75,291.25) -- (365.5,184.5) ; 				%Straight Lines [id:da7393167639442109]  				\draw    (12,184.5) -- (37.25,153) ; 				%Straight Lines [id:da5557624974392525]  				\draw    (113,184.5) -- (138.25,153) ; 				%Straight Lines [id:da6442698481051006]  				\draw    (214,184.5) -- (239.25,153) ; 				%Straight Lines [id:da340382348042639]  				\draw    (315,184.5) -- (340.25,153) ; 				%Straight Lines [id:da2540721076466157]  				\draw    (62.5,184.5) -- (37.25,153) ; 				%Straight Lines [id:da8472711375625552]  				\draw    (163.5,184.5) -- (138.25,153) ; 				%Straight Lines [id:da5202624898050305]  				\draw    (264.5,184.5) -- (239.25,153) ; 				%Straight Lines [id:da13215103392502747]  				\draw    (365.5,184.5) -- (340.25,153) ; 				%Straight Lines [id:da6678994296439263]  				\draw    (12,184.5) -- (365.5,184.5) ; 				%Shape: Circle [id:dp7688346742629796]  				\draw  [fill={rgb, 255:red, 208; green, 2; blue, 27 }  ,fill opacity=1 ] 				(181.5,291.25) .. controls (181.5,287.25) and (184.75,284) .. (188.75,284) .. 				controls (192.75,284) and (196,287.25) .. (196,291.25) .. controls (196,295.25) 				and (192.75,298.5) .. (188.75,298.5) .. controls (184.75,298.5) and 				(181.5,295.25) .. (181.5,291.25) -- cycle ; 				%Shape: Circle [id:dp7880574212688178]  				\draw  [fill={rgb, 255:red, 248; green, 231; blue, 28 }  ,fill opacity=1 ] 				(206.75,184.5) .. controls (206.75,180.5) and (210,177.25) .. (214,177.25) .. 				controls (218,177.25) and (221.25,180.5) .. (221.25,184.5) .. controls 				(221.25,188.5) and (218,191.75) .. (214,191.75) .. controls (210,191.75) and 				(206.75,188.5) .. (206.75,184.5) -- cycle ; 				%Shape: Circle [id:dp031758069104339426]  				\draw  [fill={rgb, 255:red, 248; green, 231; blue, 28 }  ,fill opacity=1 ] 				(156.25,184.5) .. controls (156.25,180.5) and (159.5,177.25) .. (163.5,177.25) 				.. controls (167.5,177.25) and (170.75,180.5) .. (170.75,184.5) .. controls 				(170.75,188.5) and (167.5,191.75) .. (163.5,191.75) .. controls (159.5,191.75) 				and (156.25,188.5) .. (156.25,184.5) -- cycle ; 				%Shape: Circle [id:dp40940285691308553]  				\draw  [fill={rgb, 255:red, 248; green, 231; blue, 28 }  ,fill opacity=1 ] 				(307.75,184.5) .. controls (307.75,180.5) and (311,177.25) .. (315,177.25) .. 				controls (319,177.25) and (322.25,180.5) .. (322.25,184.5) .. controls 				(322.25,188.5) and (319,191.75) .. (315,191.75) .. controls (311,191.75) and 				(307.75,188.5) .. (307.75,184.5) -- cycle ; 				%Shape: Circle [id:dp9803978605214323]  				\draw  [fill={rgb, 255:red, 248; green, 231; blue, 28 }  ,fill opacity=1 ] 				(257.25,184.5) .. controls (257.25,180.5) and (260.5,177.25) .. (264.5,177.25) 				.. controls (268.5,177.25) and (271.75,180.5) .. (271.75,184.5) .. controls 				(271.75,188.5) and (268.5,191.75) .. (264.5,191.75) .. controls (260.5,191.75) 				and (257.25,188.5) .. (257.25,184.5) -- cycle ; 				%Shape: Circle [id:dp5656790950937919]  				\draw  [fill={rgb, 255:red, 248; green, 231; blue, 28 }  ,fill opacity=1 ] 				(105.75,184.5) .. controls (105.75,180.5) and (109,177.25) .. (113,177.25) .. 				controls (117,177.25) and (120.25,180.5) .. (120.25,184.5) .. controls 				(120.25,188.5) and (117,191.75) .. (113,191.75) .. controls (109,191.75) and 				(105.75,188.5) .. (105.75,184.5) -- cycle ; 				%Shape: Circle [id:dp41944844224669253]  				\draw  [fill={rgb, 255:red, 248; green, 231; blue, 28 }  ,fill opacity=1 ] 				(55.25,184.5) .. controls (55.25,180.5) and (58.5,177.25) .. (62.5,177.25) .. 				controls (66.5,177.25) and (69.75,180.5) .. (69.75,184.5) .. controls 				(69.75,188.5) and (66.5,191.75) .. (62.5,191.75) .. controls (58.5,191.75) and 				(55.25,188.5) .. (55.25,184.5) -- cycle ; 				%Shape: Circle [id:dp4343148946645401]  				\draw  [fill={rgb, 255:red, 248; green, 231; blue, 28 }  ,fill opacity=1 ] 				(4.75,184.5) .. controls (4.75,180.5) and (8,177.25) .. (12,177.25) .. controls 				(16,177.25) and (19.25,180.5) .. (19.25,184.5) .. controls (19.25,188.5) and 				(16,191.75) .. (12,191.75) .. controls (8,191.75) and (4.75,188.5) .. 				(4.75,184.5) -- cycle ; 				%Shape: Circle [id:dp8037335475485512]  				\draw  [fill={rgb, 255:red, 248; green, 231; blue, 28 }  ,fill opacity=1 ] 				(358.25,184.5) .. controls (358.25,180.5) and (361.5,177.25) .. (365.5,177.25) 				.. controls (369.5,177.25) and (372.75,180.5) .. (372.75,184.5) .. controls 				(372.75,188.5) and (369.5,191.75) .. (365.5,191.75) .. controls (361.5,191.75) 				and (358.25,188.5) .. (358.25,184.5) -- cycle ; 				%Shape: Circle [id:dp3507483773145482]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(30,153) .. controls (30,149) and (33.25,145.75) .. (37.25,145.75) .. controls 				(41.25,145.75) and (44.5,149) .. (44.5,153) .. controls (44.5,157) and 				(41.25,160.25) .. (37.25,160.25) .. controls (33.25,160.25) and (30,157) .. 				(30,153) -- cycle ; 				%Shape: Circle [id:dp3914165894541274]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(131,153) .. controls (131,149) and (134.25,145.75) .. (138.25,145.75) .. 				controls (142.25,145.75) and (145.5,149) .. (145.5,153) .. controls (145.5,157) 				and (142.25,160.25) .. (138.25,160.25) .. controls (134.25,160.25) and (131,157) 				.. (131,153) -- cycle ; 				%Shape: Circle [id:dp8086278146524795]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(232,153) .. controls (232,149) and (235.25,145.75) .. (239.25,145.75) .. 				controls (243.25,145.75) and (246.5,149) .. (246.5,153) .. controls (246.5,157) 				and (243.25,160.25) .. (239.25,160.25) .. controls (235.25,160.25) and (232,157) 				.. (232,153) -- cycle ; 				%Shape: Circle [id:dp16928627874558666]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(333,153) .. controls (333,149) and (336.25,145.75) .. (340.25,145.75) .. 				controls (344.25,145.75) and (347.5,149) .. (347.5,153) .. controls (347.5,157) 				and (344.25,160.25) .. (340.25,160.25) .. controls (336.25,160.25) and (333,157) 				.. (333,153) -- cycle ; 				%Shape: Circle [id:dp4484768858962822]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(455,213) .. controls (455,209) and (458.25,205.75) .. (462.25,205.75) .. 				controls (466.25,205.75) and (469.5,209) .. (469.5,213) .. controls (469.5,217) 				and (466.25,220.25) .. (462.25,220.25) .. controls (458.25,220.25) and (455,217) 				.. (455,213) -- cycle ; 				%Shape: Circle [id:dp8001254876585561]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(494.25,213) .. controls (494.25,209) and (497.5,205.75) .. (501.5,205.75) .. 				controls (505.5,205.75) and (508.75,209) .. (508.75,213) .. controls 				(508.75,217) and (505.5,220.25) .. (501.5,220.25) .. controls (497.5,220.25) and 				(494.25,217) .. (494.25,213) -- cycle ; 				%Shape: Circle [id:dp5634357390550758]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(533.5,213) .. controls (533.5,209) and (536.75,205.75) .. (540.75,205.75) .. 				controls (544.75,205.75) and (548,209) .. (548,213) .. controls (548,217) and 				(544.75,220.25) .. (540.75,220.25) .. controls (536.75,220.25) and (533.5,217) 				.. (533.5,213) -- cycle ; 				%Shape: Circle [id:dp5014159656935173]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(572.75,213) .. controls (572.75,209) and (576,205.75) .. (580,205.75) .. 				controls (584,205.75) and (587.25,209) .. (587.25,213) .. controls (587.25,217) 				and (584,220.25) .. (580,220.25) .. controls (576,220.25) and (572.75,217) .. 				(572.75,213) -- cycle ; 				%Shape: Circle [id:dp32090076313875926]  				\draw  [fill={rgb, 255:red, 208; green, 2; blue, 27 }  ,fill opacity=1 ] 				(515.5,263) .. controls (515.5,259) and (518.75,255.75) .. (522.75,255.75) .. 				controls (526.75,255.75) and (530,259) .. (530,263) .. controls (530,267) and 				(526.75,270.25) .. (522.75,270.25) .. controls (518.75,270.25) and (515.5,267) 				.. (515.5,263) -- cycle ; 				 			 			\caption{A linking-component with four outputs, and its symbolic 				representation. The red vertex is the root. The white vertices are the 				terminals. The yellow vertices are the internal vertices (and do not appear in 				the symbolic representation).} 			 		 		 		Then, we define an \emph{tag}, represented on Figure~\ref{fig:tag} (this gadget 		has already been used in~\cite{Stewart94} in a                 different reduction, which was not sufficiently local                 for our purposes). A tag has 		only one vertex of degree~1, that we call the \emph{root}. All the other 		vertices have degree~3, and we call them the \emph{internal vertices}. 		 		[h] 			\centering 			[x=0.6pt,y=0.6pt,yscale=-1,xscale=1] 				%uncomment if require: \path (0,402); %set diagram left start at 0, and has 				%height of 402 				 				%Straight Lines [id:da2292027358435328]  				\draw    (379.5,135) -- (379.5,202.5) ; 				%Straight Lines [id:da6891883506088858]  				\draw    (264,97.5) -- (311.5,97.5) ; 				%Straight Lines [id:da9250098613206621]  				\draw    (216.5,97.5) -- (264,97.5) ; 				%Straight Lines [id:da16402239613590142]  				\draw    (264,45) -- (311.5,97.5) ; 				%Straight Lines [id:da11682254562238026]  				\draw    (264,45) -- (264,97.5) ; 				%Straight Lines [id:da3183292899433624]  				\draw    (216.5,97.5) -- (264,45) ; 				%Straight Lines [id:da8783337182855043]  				\draw    (216.5,97.5) -- (264,150) ; 				%Straight Lines [id:da5825197324265173]  				\draw    (264,150) -- (311.5,97.5) ; 				%Straight Lines [id:da9045839500708069]  				\draw    (264,150) -- (264,202.5) ; 				%Shape: Circle [id:dp2554298015765619]  				\draw  [fill={rgb, 255:red, 208; green, 2; blue, 27 }  ,fill opacity=1 ] 				(256.75,202.5) .. controls (256.75,198.5) and (260,195.25) .. (264,195.25) .. 				controls (268,195.25) and (271.25,198.5) .. (271.25,202.5) .. controls 				(271.25,206.5) and (268,209.75) .. (264,209.75) .. controls (260,209.75) and 				(256.75,206.5) .. (256.75,202.5) -- cycle ; 				%Shape: Circle [id:dp9181695271763124]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(256.75,150) .. controls (256.75,146) and (260,142.75) .. (264,142.75) .. 				controls (268,142.75) and (271.25,146) .. (271.25,150) .. controls (271.25,154) 				and (268,157.25) .. (264,157.25) .. controls (260,157.25) and (256.75,154) .. 				(256.75,150) -- cycle ; 				%Shape: Circle [id:dp32057628871757415]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(256.75,97.5) .. controls (256.75,93.5) and (260,90.25) .. (264,90.25) .. 				controls (268,90.25) and (271.25,93.5) .. (271.25,97.5) .. controls 				(271.25,101.5) and (268,104.75) .. (264,104.75) .. controls (260,104.75) and 				(256.75,101.5) .. (256.75,97.5) -- cycle ; 				%Shape: Circle [id:dp8018316124405188]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(256.75,45) .. controls (256.75,41) and (260,37.75) .. (264,37.75) .. controls 				(268,37.75) and (271.25,41) .. (271.25,45) .. controls (271.25,49) and 				(268,52.25) .. (264,52.25) .. controls (260,52.25) and (256.75,49) .. 				(256.75,45) -- cycle ; 				%Shape: Circle [id:dp9818065952619135]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(304.25,97.5) .. controls (304.25,93.5) and (307.5,90.25) .. (311.5,90.25) .. 				controls (315.5,90.25) and (318.75,93.5) .. (318.75,97.5) .. controls 				(318.75,101.5) and (315.5,104.75) .. (311.5,104.75) .. controls (307.5,104.75) 				and (304.25,101.5) .. (304.25,97.5) -- cycle ; 				%Shape: Circle [id:dp4535351913106709]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(209.25,97.5) .. controls (209.25,93.5) and (212.5,90.25) .. (216.5,90.25) .. 				controls (220.5,90.25) and (223.75,93.5) .. (223.75,97.5) .. controls 				(223.75,101.5) and (220.5,104.75) .. (216.5,104.75) .. controls (212.5,104.75) 				and (209.25,101.5) .. (209.25,97.5) -- cycle ; 				%Shape: Diamond [id:dp9316908800152304]  				\draw  [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ,fill opacity=1 ] 				(379.5,143.25) -- (387.75,135) -- (379.5,126.75) -- (371.25,135) -- cycle ; 				%Shape: Circle [id:dp9347834258401315]  				\draw  [fill={rgb, 255:red, 208; green, 2; blue, 27 }  ,fill opacity=1 ] 				(372.25,202.5) .. controls (372.25,198.5) and (375.5,195.25) .. (379.5,195.25) 				.. controls (383.5,195.25) and (386.75,198.5) .. (386.75,202.5) .. controls 				(386.75,206.5) and (383.5,209.75) .. (379.5,209.75) .. controls (375.5,209.75) 				and (372.25,206.5) .. (372.25,202.5) -- cycle ; 				 			 			\caption{A tag, and its symbolic representation. The red vertex is the root.} 			 		 		 		The graph $G'=f_{\text{3-col},\p}(G)$ is constructed as follows. For every vertex $u \in V(G)$ 		of degree~$d$ (with $d \in \{1, 2, 3, 4\}$), we create one tag and three 		linking-components with $d$ outputs associated to $u$, and we merge all the four 		roots into a single root vertex. 		We number from~1 to~3 the linking-components of~$u$. %Intuitively, each one 		%component corresponds to a color in a coloring. 		In each of the three linking components, we associate one terminal to each 		neighbor of $u$. For each $v \in N(u)$, we denote by $L_u[i,v]$ the terminal of 		the $i$-th linking component of~$u$ associated to~$v$. For each $i,j \in 		\{1,2,3\}$ such that $i \neq j$, and for all $v \in                 N(u)$, we put an edge 		between $L_u[i,v]$ and $L_v[j,u]$. These edges are called the \emph{connecting edges}. 		Note that since $G$ has maximum degree~at most~4, $G'$ has maximum degree~at most~7. 		For each $u \in V(G)$, we define $C_u:=V_u$ as the set of vertices which are in the three linking components and in 		the tag corresponding to $u$. 		Finally, the identifier of every vertex of $G'$ indicates if it belongs to a tag or a linking component, to which vertex of $G$ is it associated, and which vertex it is precisely in this tag or linking component. All this information can be encoded on $O(\log n)$ bits. 		See Figure~\ref{fig:cubicsubgraph_reduction} for an example of this reduction. 		 		 		[h] 			\centering 			[x=0.6pt,y=0.6pt,yscale=-1,xscale=1] 				%uncomment if require: \path (0,466); %set diagram left start at 0, and has 				%height of 466 				 				%Rounded Rect [id:dp3670535203216174]  				\draw  [fill={rgb, 255:red, 144; green, 19; blue, 254 }  ,fill opacity=0.3 ] 				(612.5,268.4) .. controls (609.98,266.42) and (609.55,262.77) .. (611.53,260.26) 				-- (626.31,241.48) .. controls (628.29,238.96) and (631.94,238.52) .. 				(634.45,240.5) -- (648.13,251.26) .. controls (650.65,253.25) and 				(651.08,256.89) .. (649.1,259.41) -- (634.32,278.19) .. controls (632.34,280.71) 				and (628.69,281.14) .. (626.17,279.16) -- cycle ; 				%Rounded Rect [id:dp6769837657212203]  				\draw  [fill={rgb, 255:red, 144; green, 19; blue, 254 }  ,fill opacity=0.3 ] 				(424.95,325.44) .. controls (427.21,323.17) and (430.88,323.16) .. 				(433.15,325.42) -- (450.1,342.27) .. controls (452.38,344.53) and (452.39,348.2) 				.. (450.13,350.47) -- (437.86,362.81) .. controls (435.6,365.08) and 				(431.93,365.09) .. (429.66,362.84) -- (412.71,345.99) .. controls 				(410.44,343.73) and (410.43,340.05) .. (412.68,337.78) -- cycle ; 				%Rounded Rect [id:dp13726836594840808]  				\draw  [fill={rgb, 255:red, 144; green, 19; blue, 254 }  ,fill opacity=0.3 ] 				(546,133.8) .. controls (546,130.6) and (548.6,128) .. (551.8,128) -- 				(605.7,128) .. controls (608.9,128) and (611.5,130.6) .. (611.5,133.8) -- 				(611.5,151.2) .. controls (611.5,154.4) and (608.9,157) .. (605.7,157) -- 				(551.8,157) .. controls (548.6,157) and (546,154.4) .. (546,151.2) -- cycle ; 				%Rounded Rect [id:dp25976642675215245]  				\draw  [fill={rgb, 255:red, 80; green, 227; blue, 194 }  ,fill opacity=0.3 ] 				(578.18,312.02) .. controls (575.66,310.04) and (575.23,306.39) .. 				(577.21,303.87) -- (591.99,285.09) .. controls (593.97,282.57) and 				(597.62,282.14) .. (600.13,284.12) -- (613.81,294.88) .. controls 				(616.32,296.86) and (616.76,300.51) .. (614.78,303.02) -- (600,321.81) .. 				controls (598.02,324.32) and (594.37,324.76) .. (591.85,322.78) -- cycle ; 				%Rounded Rect [id:dp7028772674044288]  				\draw  [fill={rgb, 255:red, 80; green, 227; blue, 194 }  ,fill opacity=0.3 ] 				(385.59,286.32) .. controls (387.85,284.04) and (391.52,284.03) .. 				(393.79,286.29) -- (410.74,303.14) .. controls (413.01,305.4) and 				(413.03,309.07) .. (410.77,311.34) -- (398.5,323.68) .. controls (396.24,325.95) 				and (392.57,325.97) .. (390.3,323.71) -- (373.35,306.86) .. controls 				(371.08,304.6) and (371.07,300.93) .. (373.32,298.66) -- cycle ; 				%Rounded Rect [id:dp5938640356262151]  				\draw  [fill={rgb, 255:red, 80; green, 227; blue, 194 }  ,fill opacity=0.3 ] 				(461,133.8) .. controls (461,130.6) and (463.6,128) .. (466.8,128) -- 				(520.7,128) .. controls (523.9,128) and (526.5,130.6) .. (526.5,133.8) -- 				(526.5,151.2) .. controls (526.5,154.4) and (523.9,157) .. (520.7,157) -- 				(466.8,157) .. controls (463.6,157) and (461,154.4) .. (461,151.2) -- cycle ; 				%Rounded Rect [id:dp5215619015668987]  				\draw  [fill={rgb, 255:red, 245; green, 166; blue, 35 }  ,fill opacity=0.3 ] 				(543.86,355.63) .. controls (541.34,353.65) and (540.91,350) .. (542.89,347.49) 				-- (557.67,328.71) .. controls (559.65,326.19) and (563.29,325.75) .. 				(565.81,327.73) -- (579.49,338.49) .. controls (582,340.48) and (582.44,344.12) 				.. (580.46,346.64) -- (565.68,365.42) .. controls (563.7,367.94) and 				(560.05,368.37) .. (557.53,366.39) -- cycle ; 				%Rounded Rect [id:dp9540381345744005]  				\draw  [fill={rgb, 255:red, 245; green, 166; blue, 35 }  ,fill opacity=0.3 ] 				(346.23,247.19) .. controls (348.49,244.92) and (352.16,244.9) .. 				(354.43,247.16) -- (371.38,264.01) .. controls (373.65,266.27) and 				(373.66,269.94) .. (371.41,272.22) -- (359.14,284.56) .. controls 				(356.88,286.83) and (353.21,286.84) .. (350.94,284.58) -- (333.99,267.73) .. 				controls (331.72,265.47) and (331.7,261.8) .. (333.96,259.53) -- cycle ; 				%Rounded Rect [id:dp9224464541712379]  				\draw  [fill={rgb, 255:red, 245; green, 166; blue, 35 }  ,fill opacity=0.3 ] 				(374,133.8) .. controls (374,130.6) and (376.6,128) .. (379.8,128) -- 				(433.7,128) .. controls (436.9,128) and (439.5,130.6) .. (439.5,133.8) -- 				(439.5,151.2) .. controls (439.5,154.4) and (436.9,157) .. (433.7,157) -- 				(379.8,157) .. controls (376.6,157) and (374,154.4) .. (374,151.2) -- cycle ; 				%Straight Lines [id:da5434823336161708]  				\draw[line width=1.2pt]    (391.25,143) -- (392.05,305) ; 				%Straight Lines [id:da9631386401052363]  				\draw[line width=1.2pt]    (391.25,143) -- (431.41,344.13) ; 				%Straight Lines [id:da8729667841799384]  				\draw[line width=1.2pt]    (423.25,143) -- (595.99,303.45) ; 				%Straight Lines [id:da9912804822607996]  				\draw[line width=1.2pt]    (423.25,143) -- (630.31,259.83) ; 				%Straight Lines [id:da9084912781174999]  				\draw[line width=1.2pt]    (477.5,143) -- (352.68,265.87) ; 				%Straight Lines [id:da6801883416782506]  				\draw[line width=1.2pt]    (477.5,143) -- (431.41,344.13) ; 				%Straight Lines [id:da7238290709827856]  				\draw[line width=1.2pt]    (509.5,143) -- (561.67,347.06) ; 				%Straight Lines [id:da812526789717721]  				\draw[line width=1.2pt]    (509.5,143) -- (630.31,259.83) ; 				%Straight Lines [id:da12972658717983987]  				\draw[line width=1.2pt]    (563.25,143) -- (352.68,265.87) ; 				%Straight Lines [id:da0541553737967817]  				\draw[line width=1.2pt]    (563.25,143) -- (392.05,305) ; 				%Straight Lines [id:da3975938012340242]  				\draw[line width=1.2pt]    (595.25,143) -- (561.67,347.06) ; 				%Straight Lines [id:da6553478586780926]  				\draw[line width=1.2pt]   (595.25,143) -- (595.99,303.45) ; 				%Straight Lines [id:da10449779973607864]  				\draw    (86.25,213) -- (131,213) ; 				%Straight Lines [id:da48164352352587647]  				\draw    (131,213) -- (175.75,213) ; 				%Straight Lines [id:da20591699504679373]  				\draw    (344.28,353.05) -- (318.55,378.93) ; 				%Straight Lines [id:da19306793760752594]  				\draw    (333.99,267.73) -- (344.28,353.05) ; 				%Straight Lines [id:da9033355956458508]  				\draw    (350.94,284.58) -- (344.28,353.05) ; 				%Straight Lines [id:da4616671798132034]  				\draw    (373.35,306.86) -- (344.28,353.05) ; 				%Straight Lines [id:da27081982611977484]  				\draw    (390.3,323.71) -- (344.28,353.05) ; 				%Straight Lines [id:da8060717572000073]  				\draw    (412.71,345.99) -- (344.28,353.05) ; 				%Straight Lines [id:da7877675724891784]  				\draw    (429.66,362.84) -- (344.28,353.05) ; 				%Shape: Circle [id:dp9788790153899121]  				\draw  [fill={rgb, 255:red, 255; green, 0; blue, 0 }  ,fill opacity=1 ] 				(339.14,347.94) .. controls (341.96,345.1) and (346.55,345.08) .. 				(349.39,347.91) .. controls (352.23,350.73) and (352.25,355.32) .. 				(349.42,358.16) .. controls (346.6,361) and (342.01,361.01) .. (339.17,358.19) 				.. controls (336.33,355.37) and (336.32,350.78) .. (339.14,347.94) -- cycle ; 				%Shape: Diamond [id:dp8049177778422616]  				\draw  [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ,fill opacity=1 ] 				(312.73,384.78) -- (324.4,384.75) -- (324.36,373.08) -- (312.7,373.12) -- cycle 				; 				%Shape: Circle [id:dp3383674603047392]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(386.9,299.89) .. controls (389.73,297.05) and (394.32,297.03) .. 				(397.16,299.86) .. controls (400,302.68) and (400.01,307.27) .. (397.19,310.11) 				.. controls (394.36,312.95) and (389.77,312.96) .. (386.93,310.14) .. controls 				(384.09,307.32) and (384.08,302.73) .. (386.9,299.89) -- cycle ; 				%Shape: Circle [id:dp3661030146280013]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(426.26,339.02) .. controls (429.09,336.18) and (433.68,336.16) .. 				(436.52,338.99) .. controls (439.36,341.81) and (439.37,346.4) .. 				(436.55,349.24) .. controls (433.72,352.08) and (429.13,352.09) .. 				(426.29,349.27) .. controls (423.45,346.45) and (423.44,341.86) .. 				(426.26,339.02) -- cycle ; 				%Shape: Circle [id:dp025793227112820394]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(347.54,260.76) .. controls (350.37,257.92) and (354.96,257.91) .. 				(357.8,260.73) .. controls (360.64,263.55) and (360.65,268.14) .. 				(357.83,270.98) .. controls (355,273.82) and (350.41,273.84) .. (347.57,271.01) 				.. controls (344.73,268.19) and (344.72,263.6) .. (347.54,260.76) -- cycle ; 				%Straight Lines [id:da7602148823782265]  				\draw    (493.5,33) -- (493.5,69.5) ; 				%Straight Lines [id:da13797227278652824]  				\draw    (493.5,69.5) -- (379.8,128) ; 				%Straight Lines [id:da3077627126205783]  				\draw    (493.5,69.5) -- (433.7,128) ; 				%Straight Lines [id:da09577394114490856]  				\draw    (493.5,69.5) -- (466.8,128) ; 				%Straight Lines [id:da5918242805364701]  				\draw    (493.5,69.5) -- (520.7,128) ; 				%Straight Lines [id:da04526422234660221]  				\draw    (493.5,69.5) -- (551.8,128) ; 				%Straight Lines [id:da8339191688858223]  				\draw    (493.5,69.5) -- (605.7,128) ; 				%Shape: Circle [id:dp9388511709531175]  				\draw  [fill={rgb, 255:red, 255; green, 0; blue, 0 }  ,fill opacity=1 ] 				(486.25,69.5) .. controls (486.25,65.5) and (489.5,62.25) .. (493.5,62.25) .. 				controls (497.5,62.25) and (500.75,65.5) .. (500.75,69.5) .. controls 				(500.75,73.5) and (497.5,76.75) .. (493.5,76.75) .. controls (489.5,76.75) and 				(486.25,73.5) .. (486.25,69.5) -- cycle ; 				%Shape: Diamond [id:dp3375023067013443]  				\draw  [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ,fill opacity=1 ] 				(493.5,41.25) -- (501.75,33) -- (493.5,24.75) -- (485.25,33) -- cycle ; 				%Shape: Circle [id:dp434616347227221]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(470.25,143) .. controls (470.25,139) and (473.5,135.75) .. (477.5,135.75) .. 				controls (481.5,135.75) and (484.75,139) .. (484.75,143) .. controls 				(484.75,147) and (481.5,150.25) .. (477.5,150.25) .. controls (473.5,150.25) and 				(470.25,147) .. (470.25,143) -- cycle ; 				%Shape: Circle [id:dp695427860583483]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(502.25,143) .. controls (502.25,139) and (505.5,135.75) .. (509.5,135.75) .. 				controls (513.5,135.75) and (516.75,139) .. (516.75,143) .. controls 				(516.75,147) and (513.5,150.25) .. (509.5,150.25) .. controls (505.5,150.25) and 				(502.25,147) .. (502.25,143) -- cycle ; 				%Shape: Circle [id:dp3004445557345178]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(556,143) .. controls (556,139) and (559.25,135.75) .. (563.25,135.75) .. 				controls (567.25,135.75) and (570.5,139) .. (570.5,143) .. controls (570.5,147) 				and (567.25,150.25) .. (563.25,150.25) .. controls (559.25,150.25) and (556,147) 				.. (556,143) -- cycle ; 				%Shape: Circle [id:dp7587513479927173]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(588,143) .. controls (588,139) and (591.25,135.75) .. (595.25,135.75) .. 				controls (599.25,135.75) and (602.5,139) .. (602.5,143) .. controls (602.5,147) 				and (599.25,150.25) .. (595.25,150.25) .. controls (591.25,150.25) and (588,147) 				.. (588,143) -- cycle ; 				%Shape: Circle [id:dp6844259814762571]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(416,143) .. controls (416,139) and (419.25,135.75) .. (423.25,135.75) .. 				controls (427.25,135.75) and (430.5,139) .. (430.5,143) .. controls (430.5,147) 				and (427.25,150.25) .. (423.25,150.25) .. controls (419.25,150.25) and (416,147) 				.. (416,143) -- cycle ; 				%Shape: Circle [id:dp13923893262850184]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(384,143) .. controls (384,139) and (387.25,135.75) .. (391.25,135.75) .. 				controls (395.25,135.75) and (398.5,139) .. (398.5,143) .. controls (398.5,147) 				and (395.25,150.25) .. (391.25,150.25) .. controls (387.25,150.25) and (384,147) 				.. (384,143) -- cycle ; 				%Straight Lines [id:da37818257661585497]  				\draw    (649.23,345.35) -- (677.92,367.92) ; 				%Straight Lines [id:da7104597048240737]  				\draw    (565.68,365.42) -- (649.23,345.35) ; 				%Straight Lines [id:da9011386787010475]  				\draw    (580.46,346.64) -- (649.23,345.35) ; 				%Straight Lines [id:da16085109753661664]  				\draw    (600,321.81) -- (649.23,345.35) ; 				%Straight Lines [id:da12963068979954928]  				\draw    (614.78,303.02) -- (649.23,345.35) ; 				%Straight Lines [id:da6315696356774969]  				\draw    (634.32,278.19) -- (649.23,345.35) ; 				%Straight Lines [id:da5267999697365511]  				\draw    (649.1,259.41) -- (649.23,345.35) ; 				%Shape: Circle [id:dp8649609171101205]  				\draw  [fill={rgb, 255:red, 255; green, 0; blue, 0 }  ,fill opacity=1 ] 				(644.75,351.04) .. controls (641.6,348.57) and (641.06,344.01) .. 				(643.54,340.86) .. controls (646.01,337.72) and (650.57,337.17) .. 				(653.72,339.65) .. controls (656.86,342.12) and (657.41,346.68) .. 				(654.93,349.83) .. controls (652.46,352.98) and (647.9,353.52) .. 				(644.75,351.04) -- cycle ; 				%Shape: Diamond [id:dp7654767591288067]  				\draw  [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ,fill opacity=1 ] 				(684.4,373.02) -- (683.02,361.43) -- (671.44,362.82) -- (672.82,374.4) -- cycle 				; 				%Shape: Circle [id:dp3367617867425048]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(591.51,309.15) .. controls (588.36,306.67) and (587.82,302.11) .. 				(590.3,298.96) .. controls (592.77,295.82) and (597.33,295.27) .. 				(600.48,297.75) .. controls (603.62,300.23) and (604.17,304.78) .. 				(601.69,307.93) .. controls (599.21,311.08) and (594.66,311.62) .. 				(591.51,309.15) -- cycle ; 				%Shape: Circle [id:dp17303708247517802]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(625.83,265.53) .. controls (622.68,263.05) and (622.14,258.5) .. 				(624.62,255.35) .. controls (627.09,252.2) and (631.65,251.66) .. (634.8,254.14) 				.. controls (637.94,256.61) and (638.49,261.17) .. (636.01,264.32) .. controls 				(633.54,267.46) and (628.98,268.01) .. (625.83,265.53) -- cycle ; 				%Shape: Circle [id:dp44973395178840314]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(557.19,352.76) .. controls (554.04,350.28) and (553.5,345.73) .. 				(555.97,342.58) .. controls (558.45,339.43) and (563.01,338.89) .. 				(566.15,341.37) .. controls (569.3,343.84) and (569.84,348.4) .. (567.37,351.55) 				.. controls (564.89,354.69) and (560.33,355.24) .. (557.19,352.76) -- cycle ; 				%Shape: Circle [id:dp09413437756886367]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(79,213) .. controls (79,209) and (82.25,205.75) .. (86.25,205.75) .. controls 				(90.25,205.75) and (93.5,209) .. (93.5,213) .. controls (93.5,217) and 				(90.25,220.25) .. (86.25,220.25) .. controls (82.25,220.25) and (79,217) .. 				(79,213) -- cycle ; 				%Shape: Circle [id:dp6510834230070257]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(123.75,213) .. controls (123.75,209) and (127,205.75) .. (131,205.75) .. 				controls (135,205.75) and (138.25,209) .. (138.25,213) .. controls (138.25,217) 				and (135,220.25) .. (131,220.25) .. controls (127,220.25) and (123.75,217) .. 				(123.75,213) -- cycle ; 				%Shape: Circle [id:dp9454026379092288]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(168.5,213) .. controls (168.5,209) and (171.75,205.75) .. (175.75,205.75) .. 				controls (179.75,205.75) and (183,209) .. (183,213) .. controls (183,217) and 				(179.75,220.25) .. (175.75,220.25) .. controls (171.75,220.25) and (168.5,217) 				.. (168.5,213) -- cycle ; 				 				%Shape: Polygon Curved [id:ds23751107618132306]  				\draw  [dash pattern={on 4.5pt off 4.5pt}] (282.5,292) .. controls (296.5,253) and (343.5,193) .. (420.5,271) .. controls (497.5,349) and (445.5,383) .. (413.5,401) .. controls (381.5,419) and (345.5,425) .. (308.5,393) .. controls (271.5,361) and (268.5,331) .. (282.5,292) -- cycle ; 				%Shape: Polygon Curved [id:ds2545170327324794]  				\draw  [dash pattern={on 4.5pt off 4.5pt}] (337.5,155) .. controls (324.5,105) and (401,15) .. (491.75,13) .. controls (582.5,11) and (655.5,101) .. (641.5,152) .. controls (627.5,203) and (548.5,197) .. (493.5,193) .. controls (438.5,189) and (350.5,205) .. (337.5,155) -- cycle ; 				%Shape: Polygon Curved [id:ds1210505981151303]  				\draw  [dash pattern={on 4.5pt off 4.5pt}] (540.5,280) .. controls (586.5,213) and (637.5,218) .. (678.5,259) .. controls (719.5,300) and (732.5,332) .. (697.5,379) .. controls (662.5,426) and (586.5,407) .. (563.5,391) .. controls (540.5,375) and (494.5,347) .. (540.5,280) -- cycle ; 				 				 				 				% Text Node 				\draw (88.25,223.65) node [anchor=north west][inner sep=0.75pt]    {$u$}; 				% Text Node 				\draw (133,223.65) node [anchor=north west][inner sep=0.75pt]    {$v$}; 				% Text Node 				\draw (177.75,223.65) node [anchor=north west][inner sep=0.75pt]    {$w$}; 				% Text Node 				\draw (346.17,364.59) node [anchor=north west][inner sep=0.75pt]    {$u$}; 				% Text Node 				\draw (504.25,53.65) node [anchor=north west][inner sep=0.75pt]    {$v$}; 				% Text Node 				\draw (646,359.44) node [anchor=north west][inner sep=0.75pt]    {$w$}; 				% Text Node 				\draw (122,277.4) node [anchor=north west][inner sep=0.75pt]    {\large $G$}; 				% Text Node 				\draw (445,404.4) node [anchor=north west][inner sep=0.75pt]    {\large 					$G'$}; 				% Text Node 				\draw (254,272.4) node [anchor=north west][inner sep=0.75pt]    {$V_{u}$}; 				% Text Node 				\draw (478,-15) node [anchor=north west][inner sep=0.75pt]    {$V_{v}$}; 				% Text Node 				\draw (712,270) node [anchor=north west][inner sep=0.75pt]    {$V_{w}$}; 				 				 				 			 			\caption{The graph $G'=f_{\text{3-col},\p}(G)$, where $G$ is a path on three vertices. 				The red vertices are the roots. The thick edges are the connecting edges. The colors of the linking components represent their number.} 			 		 		 		 		Let us prove that $G$ is 3-colorable if and only if $G'$ has a 		cubic subgraph. First, assume that $G$ is 3-colorable, and let $c : V(G) 		\to \{1,2,3\}$ be a proper 3-coloring of~$G$. Let us describe a 		cubic subgraph of $G'$. In fact, it will be an induced subgraph: 		for this reason, we just describe the subset $S \subseteq V(G')$ 		which defines it. 		For each vertex $u \in V(G)$, we put in $S$ all the                 vertices from its tag, and all 		the vertices from its $c(u)$-th linking component. Let us prove that the subgraph 		of $G'$ induced by $S$ is cubic. We already know that all the 		internal vertices of the tags and linking components have degree~3. In 		$G'[S]$, each root also has degree~3, because its tag and exactly 		one of its linking components is included in $S$. Finally, for every $u \in 		V(G)$, let us show that all the terminals of the $c(u)$-th linking component of 		$u$ also have degree~3. Let $v$ be a neighbor of $u$ in~$G$. The vertex 		$L_u[c(u),v]$ has already two neighbors inside the $c(u)$-th linking component 		of $u$. Moreover, since $c$ is a proper coloring of~$G$, we have $c(u) \neq 		c(v)$. By definition of $G'$, there is an edge between 		$L_u[c(u),v]$ and $L_v[c(v),u]$, so $L_u[c(u),v]$ has indeed degree~3 in 		$G'[S]$, which is thus a cubic (induced) subgraph 		of~$G'$. 		 		Conversely, assume that $G'$ has a cubic subgraph, and let us 		prove that $G$ is 3-colorable. Let $H$ be a cubic subgraph of $G'$. We will need 		the following lemma. 		 		 			 			For every vertex $u \in V(G)$, $H$ contains all the vertices and edges of the 			tag and exactly one linking component associated to it, and no other vertices in the two other linking components sharing the same root. 		 		 		Lemma~\ref{lem:cubic_subgraph main lemma} will itself be proved using the 		following claim. 		 		 			 The following holds. 			[(1)]%[label=(\roman*)] 				\item If $V(H)$ contains an internal vertex of a linking component (resp.\ of 				a tag), then $H$ contains all the vertices and edges of this linking component 				(resp.\ of this tag). 				 				\item If $V(H)$ contains a root vertex, then $H$ contains all the vertices 				and edges of the tag adjacent to it, and all the vertices and edges of exactly 				one linking component adjacent to it.  				 				\item If $V(H)$ contains a terminal vertex of some linking component, then 				$H$ contains all the vertices and edges of this linking component.  			 		 		 		[Proof of Claim~\ref{claim:cubic_subgraph}.] 			[(1)]%[label=(\roman*)] 				\item Assume that $V(H)$ contains an internal vertex $t$ of some linking 				component. Since $t$ has degree~3, and $H$ is cubic,  $H$ contains all the 				three edges adjacent to $t$, and all its three neighbors. 				Since some of the neighbors of $t$ are also internal vertices, we can apply 				the same argument for them. 				Finally, we obtain that $H$ contains all the internal vertices of this 				linking component, all the edges adjacent to them, and all their neighbors. 				Thus, it contains all the vertices and edges of the linking component. 				The same proof also holds for the tags. 				 				\item Assume that $V(H)$ contains a root vertex $t$. This vertex $t$ has two neighbors in every adjacent linking component, and one neighbor in the tag. Since $t$ has degree~3 in $H$,  $H$ should contain exactly one linking component adjacent to it, and the tag (by \eqref{5.7.1}, all the linking component and the tag are in $H$). 				 				\item Assume that $V(H)$ contains a terminal vertex $t$ of some linking component. Since $t$ is adjacent to only two connecting edges, $H$ contains at least one edge adjacent to $t$ which is in the linking component. It contains also the other endpoint of this edge, which is an internal vertex, so by \eqref{5.7.1} it contains the whole linking component.\qedhere",2502.01551
proof,"[Proof of Lemma~\ref{lem:cubic_subgraph main lemma}] 			By \eqref{5.7.1}, \eqref{5.7.2}, and                         \eqref{5.7.3} of                         Claim~\ref{claim:cubic_subgraph}, for every $u                         \in V(G)$, if \mbox{$H \cap V_u \neq                           \emptyset$}, then $H$ contains a whole                         linking component associated to $u$, it                         contains also the whole tag sharing the same                         root, and it has no other vertex from the two                         others linking components sharing the same                         root. Thus, to prove                         Lemma~\ref{lem:cubic_subgraph main lemma}, we                         just have to show that $H \cap V_u \neq                         \emptyset$ for all $u \in V(G)$. Since $G$ is                         connected, we just have to show that $H \cap                         V_u \neq \emptyset$ implies $H \cap V_v \neq                         \emptyset$ for every vertex neighbor $v$ of                         $u$ in $G$. So let $u \in V(G)$ such that $H \cap V_u \neq \emptyset$. Let $v$ be a neighbor of $u$, and let $i \in \{1,2,3\}$ such that $H$ contains a vertex in the $i$-th linking component associated to $u$. Then, $L_u[i,v] \in V(H)$, and since it has degree~3 in~$H$ but only two neighbors in this linking component, then $H$ contains some connecting edge adjacent to $L_u[i,v]$, which has $L_v[j,u]$ as the other endpoint, for some $j \in \{1,2,3\} \setminus \{i\}$. So $H \cap V_j \neq \emptyset$, which concludes the proof.",2502.01551
proof,"Let $\p$ be the property of having a partition of the                 vertex set into $k$ acyclic induced subgraphs (i.e.,                 $k$ induced forests). We will show that there is a local reduction from $k$-colorability to $\p$ with local expansion~$O(n)$ and global expansion~$O(n)$, and the result will then follow from Corollary~\ref{cor:reduction3col}. 		Let $G$ be an $n$-vertex graph having unique identifiers in~$\{1, \ldots, n\}$. The graph $G' = f_{k-col,\p}(G)$ is obtained by adding a set $U$ of $k$ universal vertices to~$G$. For every $u \in V(G)$, we define $V_u:=U \cup \{u\}$ and $C_u:=V(G')$. 		 		We only prove that Property~\cref{l2} of the definition of a                 local reduction  is satisfied, since the other                 properties are straightforward to verify. Assume that                 $G$ is $k$-colorable. Then, we can partition the                 vertex set of $G'$ into $k$ acyclic induced subgraphs,                 each of which corresponds to one color class together                 with one of the universal vertices in~$U$. Indeed, by                 doing so, each resulting induced subgraph is a star, which is acyclic. 		Conversely, assume that $V(G')$ can be partitioned                 into $k$ acyclic induced subgraphs. Then, $G'$ is                 $2k$-colorable (since each of these acyclic subgraphs                 is $2$-colorable). Consider any proper $2k$-coloring                 of $G'$. Then, its restriction to $G$ is a proper $k$-coloring of $G$, since each vertex in~$U$ must be alone in its color class (because it is a universal vertex), so $G$ is $k$-colorable.",2502.01551
proof,"Let $\p$ be the property of the existence of a $2$-edge-coloring without any monochromatic triangle. We will prove that there exists a local reduction of local expansion~$O(1)$ from 3-colorability in graphs of maximum degree~$4$ to $\p$. The result will then follow from Corollary~\ref{cor:reduction3col}. 		 		Let $G$ be a graph of maximum degree~at most~$4$, with $n$ vertices having unique identifiers in $\{1, \ldots, n\}$. 		Let us describe the graph $G' = f_{\text{3-col},                   \p}(G)$. This graph has two parts, denoted by $G_0$                 and $G_1$, which are the following. $G_0$ is obtained                 by taking a triangle~$T^0_u$ for each vertex~$u$                 of~$G$, and creating a new edge $e_{uv}$ that is                 complete to both $T^0_u$ and $T^0_v$ for every edge                 $uv$ of $G$. See Figure~\ref{fig:G0_triangles} for an example. 		 		 		[h!] 			\centering 			 			[x=0.75pt,y=0.75pt,yscale=-1,xscale=1] 				%uncomment if require: \path (0,416); %set diagram left start at 0, and has height of 416 				 				%Straight Lines [id:da12766418189270656]  				\draw    (479.5,97) -- (411.5,152) ; 				%Straight Lines [id:da0051421864068291745]  				\draw    (479.5,97) -- (411.5,97) ; 				%Straight Lines [id:da41507621598385347]  				\draw    (479.5,152) -- (411.5,152) ; 				%Straight Lines [id:da6823751350312675]  				\draw    (500.5,124) -- (411.5,97) ; 				%Straight Lines [id:da33798282163322657]  				\draw    (500.5,124) -- (411.5,152) ; 				%Straight Lines [id:da9341777642789596]  				\draw    (479.5,152) -- (411.5,97) ; 				%Straight Lines [id:da9129322729215263]  				\draw    (411.5,97) -- (309.5,97) ; 				%Straight Lines [id:da1187695270057717]  				\draw    (411.5,152) -- (309.5,97) ; 				%Straight Lines [id:da26444224039191755]  				\draw    (411.5,152) -- (330.5,124) ; 				%Straight Lines [id:da941587094802351]  				\draw    (411.5,97) -- (330.5,124) ; 				%Straight Lines [id:da7298307628711233]  				\draw    (411.5,97) -- (309.5,152) ; 				%Straight Lines [id:da29206988734635053]  				\draw    (411.5,152) -- (309.5,152) ; 				%Straight Lines [id:da6710896564491099]  				\draw    (330.5,124) -- (309.5,152) ; 				%Straight Lines [id:da5193005869898978]  				\draw    (309.5,97) -- (330.5,124) ; 				%Straight Lines [id:da008074656532407354]  				\draw    (479.5,152) -- (500.5,124) ; 				%Straight Lines [id:da43733535806930235]  				\draw    (87.5,119.5) -- (154.5,119.5) ; 				%Shape: Circle [id:dp3136656416904424]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (83,119.5) .. controls (83,117.01) and (85.01,115) .. (87.5,115) .. controls (89.99,115) and (92,117.01) .. (92,119.5) .. controls (92,121.99) and (89.99,124) .. (87.5,124) .. controls (85.01,124) and (83,121.99) .. (83,119.5) -- cycle ; 				%Shape: Circle [id:dp2442559076111771]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (150,119.5) .. controls (150,117.01) and (152.01,115) .. (154.5,115) .. controls (156.99,115) and (159,117.01) .. (159,119.5) .. controls (159,121.99) and (156.99,124) .. (154.5,124) .. controls (152.01,124) and (150,121.99) .. (150,119.5) -- cycle ; 				%Straight Lines [id:da8271792102648566]  				\draw    (309.5,97) -- (309.5,152) ; 				%Shape: Circle [id:dp5140235593359702]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (305,152) .. controls (305,149.51) and (307.01,147.5) .. (309.5,147.5) .. controls (311.99,147.5) and (314,149.51) .. (314,152) .. controls (314,154.49) and (311.99,156.5) .. (309.5,156.5) .. controls (307.01,156.5) and (305,154.49) .. (305,152) -- cycle ; 				%Shape: Circle [id:dp8294349763183843]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (326,124) .. controls (326,121.51) and (328.01,119.5) .. (330.5,119.5) .. controls (332.99,119.5) and (335,121.51) .. (335,124) .. controls (335,126.49) and (332.99,128.5) .. (330.5,128.5) .. controls (328.01,128.5) and (326,126.49) .. (326,124) -- cycle ; 				%Shape: Circle [id:dp32619433721980073]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (305,97) .. controls (305,94.51) and (307.01,92.5) .. (309.5,92.5) .. controls (311.99,92.5) and (314,94.51) .. (314,97) .. controls (314,99.49) and (311.99,101.5) .. (309.5,101.5) .. controls (307.01,101.5) and (305,99.49) .. (305,97) -- cycle ; 				%Straight Lines [id:da36851264758525326]  				\draw [line width=1.5]    (198.5,124) -- (255.5,124) ; 				\draw [shift={(259.5,124)}, rotate = 180] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (11.61,-5.58) -- (0,0) -- (11.61,5.58) -- cycle    ; 				%Straight Lines [id:da33986786114240564]  				\draw    (411.5,97) -- (411.5,152) ; 				%Straight Lines [id:da9770070299396416]  				\draw    (479.5,97) -- (479.5,152) ; 				%Straight Lines [id:da9471822734734879]  				\draw    (479.5,97) -- (500.5,124) ; 				%Shape: Circle [id:dp7764089900801231]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (407,97) .. controls (407,94.51) and (409.01,92.5) .. (411.5,92.5) .. controls (413.99,92.5) and (416,94.51) .. (416,97) .. controls (416,99.49) and (413.99,101.5) .. (411.5,101.5) .. controls (409.01,101.5) and (407,99.49) .. (407,97) -- cycle ; 				%Shape: Circle [id:dp9446325290990434]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (407,152) .. controls (407,149.51) and (409.01,147.5) .. (411.5,147.5) .. controls (413.99,147.5) and (416,149.51) .. (416,152) .. controls (416,154.49) and (413.99,156.5) .. (411.5,156.5) .. controls (409.01,156.5) and (407,154.49) .. (407,152) -- cycle ; 				%Shape: Circle [id:dp3017254828023027]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (475,97) .. controls (475,94.51) and (477.01,92.5) .. (479.5,92.5) .. controls (481.99,92.5) and (484,94.51) .. (484,97) .. controls (484,99.49) and (481.99,101.5) .. (479.5,101.5) .. controls (477.01,101.5) and (475,99.49) .. (475,97) -- cycle ; 				%Shape: Circle [id:dp014712822407684123]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (475,152) .. controls (475,149.51) and (477.01,147.5) .. (479.5,147.5) .. controls (481.99,147.5) and (484,149.51) .. (484,152) .. controls (484,154.49) and (481.99,156.5) .. (479.5,156.5) .. controls (477.01,156.5) and (475,154.49) .. (475,152) -- cycle ; 				%Shape: Circle [id:dp6313309860577108]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (496,124) .. controls (496,121.51) and (498.01,119.5) .. (500.5,119.5) .. controls (502.99,119.5) and (505,121.51) .. (505,124) .. controls (505,126.49) and (502.99,128.5) .. (500.5,128.5) .. controls (498.01,128.5) and (496,126.49) .. (496,124) -- cycle ; 				%Shape: Polygon Curved [id:ds1166802110933911]  				\draw  [dash pattern={on 5.63pt off 4.5pt}][line width=1.5]  (304.5,85) .. controls (324.5,75) and (351.5,99) .. (349.5,127) .. controls (347.5,155) and (332.5,179) .. (306.5,167) .. controls (280.5,155) and (284.5,95) .. (304.5,85) -- cycle ; 				%Shape: Polygon Curved [id:ds5680709758109541]  				\draw  [dash pattern={on 5.63pt off 4.5pt}][line width=1.5]  (411,78) .. controls (439.5,77) and (444,174) .. (411.5,173) .. controls (379,172) and (382.5,79) .. (411,78) -- cycle ; 				%Shape: Polygon Curved [id:ds07017722299190854]  				\draw  [dash pattern={on 5.63pt off 4.5pt}][line width=1.5]  (460.5,122) .. controls (461.5,100) and (468.5,77) .. (495.5,83) .. controls (522.5,89) and (522.5,162) .. (493.5,168) .. controls (464.5,174) and (459.5,144) .. (460.5,122) -- cycle ; 				 				% Text Node 				\draw (92.5,125.9) node [anchor=north west][inner sep=0.75pt]    {$u$}; 				% Text Node 				\draw (156.5,125.9) node [anchor=north west][inner sep=0.75pt]    {$v$}; 				% Text Node 				\draw (307,178.4) node [anchor=north west][inner sep=0.75pt]    {$T^0_{u}$}; 				% Text Node 				\draw (480,178.4) node [anchor=north west][inner sep=0.75pt]    {$T^0_{v}$}; 				% Text Node 				\draw (403,180.4) node [anchor=north west][inner sep=0.75pt]    {$e_{uv}$}; 				 				 			 			 			\caption{The construction of $G_0$.} 			 		 		 		Then, $G_1$ is obtained by taking seven triangles                 $T^1_u$, $T^2_u$, $T^3_u$, $T^{12}_u$, $T^{23}_u$,                 $T^{13}_u$, $T^{123}_u$ for every vertex~$u$ of~$G$,                 and adding three triangles $T^1_{uv}$, $T^2_{uv}$                 $T^3_{uv}$ for every edge $uv$ of $G$. Finally, we add the following edges in $G_1$, and between $G_0$ and $G_1$: 		 			\item for every $u \in V(G)$, we make one edge of $T^{123}_u$ complete to $T^1_u$, one complete to $T^2_u$ and one complete to $T^3_u$ (see Figure~\ref{fig:G1_triangles} for an illustration); 			\item for every $u \in V(G)$ and $1 \leqslant i < j \leqslant 3$, we make one edge of $T_u^{ij}$ complete to $T^i_u$, one complete to $T^j_u$, and one complete to $T^0_u$; 			\item for every $\{u,v\} \in E(G)$ and $i \in \{1,2,3\}$, we make one edge of $T^i_{uv}$ complete to $T^i_u$, one complete to $T^i_v$, and one complete to both $T^0_u$ and $T^0_v$. 		 		 		[h!] 			\centering 			 			[x=0.75pt,y=0.75pt,yscale=-1,xscale=1] 				%uncomment if require: \path (0,416); %set diagram left start at 0, and has height of 416 				 				%Straight Lines [id:da12068549433770437]  				\draw    (300.5,228) -- (358.48,317.37) ; 				%Straight Lines [id:da19417256591276388]  				\draw    (300.5,228) -- (362.72,283.43) ; 				%Straight Lines [id:da40653157810527707]  				\draw    (300.5,228) -- (397.37,278.48) ; 				%Straight Lines [id:da6187020761549238]  				\draw    (321.5,200) -- (358.48,317.37) ; 				%Straight Lines [id:da5052941526401697]  				\draw    (321.5,200) -- (362.72,283.43) ; 				%Straight Lines [id:da24884831751213932]  				\draw    (321.5,200) -- (397.37,278.48) ; 				%Straight Lines [id:da9431296403446423]  				\draw    (357.92,83.28) -- (300.5,173) ; 				%Straight Lines [id:da6303559305505145]  				\draw    (362.26,118.01) -- (300.5,173) ; 				%Straight Lines [id:da285408800214383]  				\draw    (396.12,122.84) -- (300.5,173) ; 				%Straight Lines [id:da7540666367077046]  				\draw    (357.92,83.28) -- (321.5,200) ; 				%Straight Lines [id:da21697233596888676]  				\draw    (362.26,118.01) -- (321.5,200) ; 				%Straight Lines [id:da24949883778224102]  				\draw    (396.12,122.84) -- (321.5,200) ; 				%Straight Lines [id:da45006830669224873]  				\draw    (211.5,173.5) -- (300.5,173) ; 				%Straight Lines [id:da9355309536445953]  				\draw    (232.5,200.5) -- (300.5,173) ; 				%Straight Lines [id:da7676859852830685]  				\draw    (211.5,228.5) -- (300.5,173) ; 				%Straight Lines [id:da6623672351929155]  				\draw    (211.5,173.5) -- (300.5,228) ; 				%Straight Lines [id:da22448692407054294]  				\draw    (232.5,200.5) -- (300.5,228) ; 				%Straight Lines [id:da5032041962243297]  				\draw    (211.5,228.5) -- (300.5,228) ; 				%Straight Lines [id:da9296298252708658]  				\draw    (232.5,200.5) -- (211.5,228.5) ; 				%Straight Lines [id:da5321440560028662]  				\draw    (211.5,173.5) -- (232.5,200.5) ; 				%Straight Lines [id:da4782434350450453]  				\draw    (211.5,173.5) -- (211.5,228.5) ; 				%Shape: Circle [id:dp7671326368811614]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (207,228.5) .. controls (207,226.01) and (209.01,224) .. (211.5,224) .. controls (213.99,224) and (216,226.01) .. (216,228.5) .. controls (216,230.99) and (213.99,233) .. (211.5,233) .. controls (209.01,233) and (207,230.99) .. (207,228.5) -- cycle ; 				%Shape: Circle [id:dp1179474376449976]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (228,200.5) .. controls (228,198.01) and (230.01,196) .. (232.5,196) .. controls (234.99,196) and (237,198.01) .. (237,200.5) .. controls (237,202.99) and (234.99,205) .. (232.5,205) .. controls (230.01,205) and (228,202.99) .. (228,200.5) -- cycle ; 				%Shape: Circle [id:dp3386854586396526]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (207,173.5) .. controls (207,171.01) and (209.01,169) .. (211.5,169) .. controls (213.99,169) and (216,171.01) .. (216,173.5) .. controls (216,175.99) and (213.99,178) .. (211.5,178) .. controls (209.01,178) and (207,175.99) .. (207,173.5) -- cycle ; 				%Straight Lines [id:da7688376609980243]  				\draw    (362.26,118.01) -- (357.92,83.28) ; 				%Straight Lines [id:da8944360159693389]  				\draw    (396.12,122.84) -- (362.26,118.01) ; 				%Straight Lines [id:da8800662358772469]  				\draw    (396.12,122.84) -- (357.92,83.28) ; 				%Shape: Circle [id:dp11940948145332464]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (361.16,80.15) .. controls (362.88,81.94) and (362.83,84.79) .. (361.04,86.52) .. controls (359.26,88.24) and (356.41,88.19) .. (354.68,86.4) .. controls (352.95,84.62) and (353,81.77) .. (354.79,80.04) .. controls (356.58,78.31) and (359.43,78.36) .. (361.16,80.15) -- cycle ; 				%Shape: Circle [id:dp5817816080823444]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (365.5,114.88) .. controls (367.23,116.67) and (367.18,119.52) .. (365.39,121.24) .. controls (363.6,122.97) and (360.75,122.92) .. (359.03,121.13) .. controls (357.3,119.35) and (357.35,116.5) .. (359.14,114.77) .. controls (360.92,113.04) and (363.77,113.09) .. (365.5,114.88) -- cycle ; 				%Shape: Circle [id:dp003016109612767437]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (399.36,119.72) .. controls (401.09,121.5) and (401.04,124.35) .. (399.25,126.08) .. controls (397.46,127.81) and (394.61,127.76) .. (392.89,125.97) .. controls (391.16,124.18) and (391.21,121.33) .. (393,119.6) .. controls (394.79,117.88) and (397.63,117.93) .. (399.36,119.72) -- cycle ; 				 				%Straight Lines [id:da645278495239311]  				\draw    (321.5,200) -- (300.5,228) ; 				%Straight Lines [id:da6801055880862126]  				\draw    (300.5,173) -- (321.5,200) ; 				%Straight Lines [id:da7044036843481135]  				\draw    (300.5,173) -- (300.5,228) ; 				%Shape: Circle [id:dp1942345466135028]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (296,228) .. controls (296,225.51) and (298.01,223.5) .. (300.5,223.5) .. controls (302.99,223.5) and (305,225.51) .. (305,228) .. controls (305,230.49) and (302.99,232.5) .. (300.5,232.5) .. controls (298.01,232.5) and (296,230.49) .. (296,228) -- cycle ; 				%Shape: Circle [id:dp6112129583768339]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (317,200) .. controls (317,197.51) and (319.01,195.5) .. (321.5,195.5) .. controls (323.99,195.5) and (326,197.51) .. (326,200) .. controls (326,202.49) and (323.99,204.5) .. (321.5,204.5) .. controls (319.01,204.5) and (317,202.49) .. (317,200) -- cycle ; 				%Shape: Circle [id:dp9527162082334386]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (296,173) .. controls (296,170.51) and (298.01,168.5) .. (300.5,168.5) .. controls (302.99,168.5) and (305,170.51) .. (305,173) .. controls (305,175.49) and (302.99,177.5) .. (300.5,177.5) .. controls (298.01,177.5) and (296,175.49) .. (296,173) -- cycle ; 				%Straight Lines [id:da7612367850066104]  				\draw    (362.72,283.43) -- (397.37,278.48) ; 				%Straight Lines [id:da3182860890837317]  				\draw    (358.48,317.37) -- (362.72,283.43) ; 				%Straight Lines [id:da56372522616054]  				\draw    (358.48,317.37) -- (397.37,278.48) ; 				%Shape: Circle [id:dp5143159766193952]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (400.55,281.66) .. controls (398.79,283.42) and (395.95,283.42) .. (394.19,281.66) .. controls (392.43,279.9) and (392.43,277.05) .. (394.19,275.3) .. controls (395.95,273.54) and (398.79,273.54) .. (400.55,275.3) .. controls (402.31,277.05) and (402.31,279.9) .. (400.55,281.66) -- cycle ; 				%Shape: Circle [id:dp9645668552442]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (365.9,286.61) .. controls (364.15,288.37) and (361.3,288.37) .. (359.54,286.61) .. controls (357.78,284.85) and (357.78,282) .. (359.54,280.25) .. controls (361.3,278.49) and (364.15,278.49) .. (365.9,280.25) .. controls (367.66,282) and (367.66,284.85) .. (365.9,286.61) -- cycle ; 				%Shape: Circle [id:dp5755693305214011]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (361.66,320.55) .. controls (359.9,322.31) and (357.05,322.31) .. (355.3,320.55) .. controls (353.54,318.79) and (353.54,315.95) .. (355.3,314.19) .. controls (357.05,312.43) and (359.9,312.43) .. (361.66,314.19) .. controls (363.42,315.95) and (363.42,318.79) .. (361.66,320.55) -- cycle ; 				 				%Shape: Polygon Curved [id:ds2569061534985001]  				\draw  [dash pattern={on 5.63pt off 4.5pt}][line width=1.5]  (248.5,201) .. controls (250.5,173) and (223.5,157) .. (204.5,162) .. controls (185.5,167) and (185.5,233) .. (205.5,240) .. controls (225.5,247) and (246.5,229) .. (248.5,201) -- cycle ; 				%Shape: Polygon Curved [id:ds014017085187056133]  				\draw  [dash pattern={on 5.63pt off 4.5pt}][line width=1.5]  (411.5,273) .. controls (401.5,256) and (370.5,255) .. (353.5,268) .. controls (336.5,281) and (336.5,319) .. (351.5,331) .. controls (366.5,343) and (421.5,290) .. (411.5,273) -- cycle ; 				%Shape: Polygon Curved [id:ds5955212444678195]  				\draw  [dash pattern={on 5.63pt off 4.5pt}][line width=1.5]  (407.5,115) .. controls (401.5,92) and (372.5,68) .. (353.5,73) .. controls (334.5,78) and (333.5,117) .. (350.5,131) .. controls (367.5,145) and (413.5,138) .. (407.5,115) -- cycle ; 				%Shape: Polygon Curved [id:ds5175462562615921]  				\draw  [dash pattern={on 5.63pt off 4.5pt}][line width=1.5]  (337.5,201) .. controls (338.5,177) and (312.5,157) .. (293.5,162) .. controls (274.5,167) and (274.5,233) .. (294.5,240) .. controls (314.5,247) and (336.5,225) .. (337.5,201) -- cycle ; 				 				% Text Node 				\draw (158,187.4) node [anchor=north west][inner sep=0.75pt]    {$T_{u}^{1}$}; 				% Text Node 				\draw (398,68.4) node [anchor=north west][inner sep=0.75pt]    {$T_{u}^{2}$}; 				% Text Node 				\draw (400,318.4) node [anchor=north west][inner sep=0.75pt]    {$T_{u}^{3}$}; 				% Text Node 				\draw (347,190.4) node [anchor=north west][inner sep=0.75pt]    {$T_{u}^{123}$}; 				 				 			 			 			\caption{Some of the edges in the construction of $G_1$.} 			 		 		 		 		Finally, for every vertex $u \in G$, we define $V_u$ and $C_u$ as being both equal to the set containing the vertices in $T^0_u$, $e_{uv}$, $T^i_u$,  $T^{ij}_u$, $T^{123}_u$, $T^i_{uv}$ for some $i,j \in \{1,2,3\}$ and $v \in N(u)$. 		 		Since $G$ has maximum degree~4, the size of $C_u$ is bounded by a constant for every $u \in V(G)$, so the local reduction has expansion~$O(1)$. Moreover, a simple verification shows that every vertex of $G'$ has degree~at most~40 (and the vertices that have degree~40 are the ones in the triangles $T^0_u$ for some $u \in V(G)$ which has degree~4). The only property of the definition of local reduction that is non-trivial to verify is Property~\cref{l2}: namely, we will show that $G$ is 3-colorable if and only if $G'$ admits a $2$-edge-coloring without monochromatic triangles. 		 		So, first, assume that $G'$ admits a $2$-edge-coloring                 without monochromatic triangles, and let us show that                 $G$ is $3$-colorable. Let us say that the edges of~$G'$ are colored \emph{red} and \emph{blue}. In a                 $2$-edge-coloring of a triangle $T$ which is not                 monochromatic, we will say that the color assigned to two out of the three edges of $T$ is the \emph{main color} of~$T$. We start by proving the following lemma:                    		 			 			Let us consider a clique $K_5$ on $5$ vertices, denoted by $s,t,u,v,w$. In any $2$-edge-coloring of $K_5$ without any monochromatic triangle, the color of the edge $st$ is the same as the main color of the triangle $uvw$. Conversely, any $2$-edge-coloring of the edge $st$ and of the triangle $uvw$ which makes $uvw$ non-monochromatic and which satisfies the previous condition can be completed into a $2$-edge-coloring of $K_5$ without any monochromatic triangle. 		 		 		 			Consider a $2$-edge-coloring of $K_5$ without                         any monochromatic triangle, with colors red                         and blue. By symmetry, assume that the main                         color of $uvw$ is blue, and that $uv$ is blue,                         $uw$ is blue, and $vw$ is red. Note that the                         blue-degree of every vertex is at most two                         (since otherwise there would be a                         monochromatic triangle), and similarly the                         red-degree of every vertex is at most two. As                         $K_5$ is 4-regular, the blue and red subgraphs                         are both 5-cycles. It remains to observe that                         any 5-cycle of $K_5$ containing the edges $uv$ and                         $uw$ also contains the edge $st$. 			See Figure~\ref{fig:coloring K5} for an illustration.",2502.01551
proof,"By Lemma~\ref{lem:coloring K5}, for every $1                         \leqslant i < j \leqslant 3$, the colors of                         the edges of $T^{ij}_u$ are respectively the                         main colors of $T^i_u$,  $T^j_u$ and $T^0_u$                         (which is blue). Since $T^{ij}_u$ is not                         monochromatic,  the main color of either                         $T^i_u$ or $T^j_u$ (or both) is red. Thus, at                         least two of the main colors of $T^1_u$,                         $T^2_u$, $T^3_u$ are red. But it cannot be red                         for the 3 triangles, since othewise the triangle $T^{123}_u$ would be monochromatic (because its edges are colored with the main colors of $T^1_u$, $T^2_u$, $T^3_u$). So exactly one has blue as its main color.",2502.01551
proof,"% 	By Theorem~\ref{thm:local reduction 3SAT}, there exists a local reduction from 	% 	non-3-colorability (in general graphs for (1), in graphs of maximum degree~4 for 	% 	(2)) to $\np$ with expansion $O(n^\delta)$. Thus, we can apply 	% 	Corollary~\ref{cor:reduction3col} to get the result. 	%",2502.01551
proof,"[Proof of Theorem~\ref{thm:local reduction 3SAT}.] 		Let $f_{\p}$ be the function corresponding to the local reduction from 3-SAT 		(in $\F$) to $\p$ with local expansion~$\alpha$ and global expansion~$\beta$. We show that there exists a local 		reduction from 3-colorability in $\C'$ to $\p$ with local expansion $\alpha'(n):=3\alpha(3n)$ and global expansion $\beta'(n):=\beta(3n)$, 		with the function $f_{\text{3-col}, \p}(G):=f_\p(\varphi_G)$ for every $G$, where for 		each vertex $u \in V(G)$ having its identifier in $\{1, \ldots, n\}$, the 		variable $u_i$ in $\varphi_G$ received the identifier $3(\mathrm{id}(u)-1)+i$, so that the 		variables of $\varphi_G$ have indeed identifiers in $\{1, \ldots, 3n\}$ and thus $\varphi_G$ satisfies property~\cref{p1} of the definition of local reduction from 3-SAT (see the beginning of Section~\ref{sec:red3SAT}). Note that $\varphi_G$ also satisfies property~\cref{p2} because $G$ is connected. 		 		Now, let us prove that $f_{\text{3-col}, \p}(G)$ satisfies all the conditions of 		the definition of local reduction from 3-colorability                 to $\p$ (see the beginning of                 Section~\ref{sec:reduc}). First, it has at most                 $\beta(3n)=\beta'(n)$ vertices. Then, it is                 straightforward to see that conditions~\cref{l1}                 and~\cref{l2}, are satisfied. Let us prove                 that~\cref{l3} holds as well. For every vertex~$u$, let us define 		$C_u:=C_{u_1} \cup C_{u_2} \cup C_{u_3}$, and $V_u:=V_{u_1} \cup V_{u_2} \cup 		V_{u_3}$, where $u_1, u_2, u_3$ are the variables of $\varphi_G$ corresponding 		to $u$. 		It is again straightforward that~\cref{l3a} and~\cref{l3b} both hold. 		For~\cref{l3c}, observe that $\varphi_G$ has $3n$ variables, and that for every $u 		\in G$ and every $i \in \{1,2,3\}$, $|C_{u_i}| \leqslant \alpha(3n)$. Thus, 		$|C_u| \leqslant 3\alpha(3n) = \alpha'(n)$. 		For~\cref{l3d}, let $t \in V(f_{\text{3-col}, \p}(G))$ and let $u, v \in V(G)$ such that 		$t \in C_u \cap C_v$. Without loss of generality, assume that $t \in C_{u_1} 		\cap C_{v_1}$. By condition~\cref{s3d} of the definition of local reduction from 3-SAT, there exists a sequence of variables $y_1, \ldots, y_k$ such that $y_1=u_1$, 		$y_k=v_1$, for every $i \in \{1, \ldots, k-1\}$, $y_i$ and $y_{i+1}$ have a 		clause in common, and $t \in \bigcap_{1 \leqslant i \leqslant k} C_{y_i}$. Thus, 		by construction of $\varphi_G$, for every $i \in \{1, \ldots, k-1\}$, one of the 		two following cases holds: 		 			\item there exists $w \in V(G)$ and $j,j'\in \{1,2,3\}$ such that $y_i = w_j$ 			and $y_{i+1}=w_{j'}$, or 			\item there exists $w,w' \in V(G)$ which are neighbors, and $j\in \{1,2,3\}$ 			such that $y_i=w_j$ and $y_{i+1}=w'_j$ 		 		So there is a path from $u$ to $v$ which is included in $\{w \in V(G) \; | \; t 		\in C_w\}$, which proves~\cref{l3d}. Then, \cref{l3e}~simply follows from the definition 		of $C_u$ and from~\cref{s3e} of the definition of local reduction from 3-SAT. Finally, 		for~\cref{l3f}, if $G'$ is another $n$-vertex graph with unique identifiers in $\{1, 		\ldots, n\}$ and if the subgraph formed by $u$ and its neighbors is the same in $G$ and $G'$, 		then for every $i \in \{1,2,3\}$ the clauses in which the variable $u_i$ appears 		in $\varphi_G$ and $\varphi_{G'}$ are the same, and we can just apply the 		property~\cref{s3f} of the definition of local reduction from 3-SAT to conclude.",2502.01551
proof,"Let $\p:=$ \ham{}. We prove that there exists a local reduction from 3-SAT (in 		$\F_0$) to $\p$ with local expansion $O(n)$, and then the result will follow from 		Corollary~\ref{cor:reduction3SAT}. Recall that $\F_0$                 was defined as the set of 3-CNF formulae $\varphi$ such that each variable 	appears in at most $|V(\varphi)|+1$ clauses. 		We use the reduction of~\cite{Sipser}. Let $\varphi$ be a 3-CNF formula with 		variables having identifiers in $\{1, \ldots, |V(\varphi)|\}$, and such that 		each variable appears in at most $|V(\varphi)|+1$ clauses. 		Let $n:=|V(\varphi)|$, and let $m$ be the number of clauses in $\varphi$. Let 		$x_1, \ldots, x_n$ be the variables of $\varphi$, and $C_1, \ldots, C_m$ be its 		clauses. 		 		The graph $f_\p(\varphi)$ is constructed in two steps. First, we construct a 		directed graph $f_\p^\ast(\varphi)$ which has a directed Hamiltonian cycle if 		and only if $\varphi$ if satisfiable. Then, we explain how to construct the 		undirected graph $f_\p(\varphi)$ from $f_\p^\ast(\varphi)$. 		 		The graph $f_\p^\ast(\varphi)$ is constructed as follows. For each variable 		$x_i$ such that $x_i$ or its negation appears in $d$ clauses, 		we create a horizontal row of $3d+3$ vertices, an entry node, and an exit node. The exit 		node of $x_i$ is the entry one of $x_{i+1}$, except the entry node of $x_1$ 		which is called $s$, and the exit node of $x_n$ which is called $t$. There is 		also an arc from~$t$ to~$s$. 		Finally, we add $m$ single vertices, one for each clause. This is depicted on 		Figure~\ref{fig:ham1}. We now specify how to connect the vertices corresponding 		to the clauses to the rest of the graph. 		For each $i \in \{1, \ldots, n\}$, the $3d+3$ vertices of the row corresponding 		to $x_i$ are divided as follows. Among the $3d+1$ vertices which are not the 		first and the last one, they are grouped by adjacent pairs, with one separator 		between each pair. 		Let us denote $C_{i_1}, \ldots, C_{i_d}$ the clauses in which $x_i$ or its negation appears. For every $j \in \{1, \ldots, d\}$, we add two edges between the $j$-th 		pair of the row of $x_i$ and the vertex corresponding to $C_{i_j}$, and their 		direction depends only on whether $x_i$ appears positively or negatively in 		$C_j$. See~\cite{Sipser} for more details and Figure~\ref{fig:ham2} for an 		example. 		 		 		 			\centering 			 			[x=0.55pt,y=0.55pt,yscale=-1,xscale=1] 				%uncomment if require: \path (0,779); %set diagram left start at 0, and has 				%height of 779 				 				%Curve Lines [id:da5158263562020934]  				\draw    (248.76,35.55) .. controls (93.62,21.91) and (50.44,116.43) .. 				(44.5,159) .. controls (38.5,202) and (35.5,274) .. (35.5,314) .. controls 				(35.5,354) and (38.5,428) .. (46.5,478) .. controls (54.5,528) and (86.5,622) .. 				(270.5,609) ; 				\draw [shift={(253.5,36)}, rotate = 185.75] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da6951009387497726]  				\draw    (129.97,331.51) .. controls (136.24,295.05) and (181.23,295.73) .. 				(269.5,287) ; 				\draw [shift={(129.5,335)}, rotate = 275.71] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da6732705178676021]  				\draw    (412.08,332.01) .. controls (405.95,294.24) and (374.8,298.7) .. 				(269.5,287) ; 				\draw [shift={(412.5,335)}, rotate = 263.05] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da0061887405623259895]  				\draw    (287.68,281.56) .. controls (378.22,272.2) and (401.64,278.18) .. 				(410.5,224.5) ; 				\draw [shift={(283.5,282)}, rotate = 353.93] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da350912453940727]  				\draw    (251.4,280.34) .. controls (162.58,266.29) and (132.44,275.23) .. 				(128.5,224.5) ; 				\draw [shift={(255.5,281)}, rotate = 189.26] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da5735122795349313]  				\draw    (128.97,209.51) .. controls (135.24,173.05) and (180.23,173.73) .. 				(268.5,165) ; 				\draw [shift={(128.5,213)}, rotate = 275.71] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da11742303296180223]  				\draw    (411.08,210.01) .. controls (404.95,172.24) and (373.8,176.7) .. 				(268.5,165) ; 				\draw [shift={(411.5,213)}, rotate = 263.05] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da4669164080087531]  				\draw    (175.5,224.5) .. controls (163.08,246.94) and (153.41,248.86) .. 				(138.62,236.8) ; 				\draw [shift={(136.5,235)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da15146731213232434]  				\draw    (128.5,224.5) .. controls (135.26,209.54) and (146.67,200.17) .. 				(165.43,215.26) ; 				\draw [shift={(167.5,217)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da4074358672367605]  				\draw    (175.5,224.5) .. controls (182.26,209.54) and (193.67,200.17) .. 				(212.43,215.26) ; 				\draw [shift={(214.5,217)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da16299552509537618]  				\draw    (222.5,224.5) .. controls (229.26,209.54) and (240.67,200.17) .. 				(259.43,215.26) ; 				\draw [shift={(261.5,217)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da28822023137819175]  				\draw    (269.5,224.5) .. controls (276.26,209.54) and (287.67,200.17) .. 				(306.43,215.26) ; 				\draw [shift={(308.5,217)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da6693456621561876]  				\draw    (316.5,224.5) .. controls (323.26,209.54) and (334.67,200.17) .. 				(353.43,215.26) ; 				\draw [shift={(355.5,217)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da8623441653962637]  				\draw    (363.5,224.5) .. controls (370.26,209.54) and (381.67,200.17) .. 				(400.43,215.26) ; 				\draw [shift={(402.5,217)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da579189411645259]  				\draw    (222.5,224.5) .. controls (210.08,246.94) and (200.41,248.86) .. 				(185.62,236.8) ; 				\draw [shift={(183.5,235)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da43302780227794624]  				\draw    (269.5,224.5) .. controls (257.08,246.94) and (247.41,248.86) .. 				(232.62,236.8) ; 				\draw [shift={(230.5,235)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da8887854254258015]  				\draw    (316.5,224.5) .. controls (304.08,246.94) and (294.41,248.86) .. 				(279.62,236.8) ; 				\draw [shift={(277.5,235)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da008954658345453614]  				\draw    (363.5,224.5) .. controls (351.09,246.94) and (341.41,248.86) .. 				(326.62,236.8) ; 				\draw [shift={(324.5,235)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da597498991929282]  				\draw    (410.5,224.5) .. controls (398.09,246.94) and (388.41,248.86) .. 				(373.62,236.8) ; 				\draw [shift={(371.5,235)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Shape: Circle [id:dp6924088712010317]  				\draw  [fill={rgb, 255:red, 0; green, 0; blue, 255 }  ,fill opacity=1 ] 				(119,224.5) .. controls (119,219.25) and (123.25,215) .. (128.5,215) .. controls 				(133.75,215) and (138,219.25) .. (138,224.5) .. controls (138,229.75) and 				(133.75,234) .. (128.5,234) .. controls (123.25,234) and (119,229.75) .. 				(119,224.5) -- cycle ; 				%Shape: Circle [id:dp2340072526661784]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(166,224.5) .. controls (166,219.25) and (170.25,215) .. (175.5,215) .. controls 				(180.75,215) and (185,219.25) .. (185,224.5) .. controls (185,229.75) and 				(180.75,234) .. (175.5,234) .. controls (170.25,234) and (166,229.75) .. 				(166,224.5) -- cycle ; 				%Shape: Circle [id:dp9481393040645493]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(213,224.5) .. controls (213,219.25) and (217.25,215) .. (222.5,215) .. controls 				(227.75,215) and (232,219.25) .. (232,224.5) .. controls (232,229.75) and 				(227.75,234) .. (222.5,234) .. controls (217.25,234) and (213,229.75) .. 				(213,224.5) -- cycle ; 				%Shape: Circle [id:dp822194236568099]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(260,224.5) .. controls (260,219.25) and (264.25,215) .. (269.5,215) .. controls 				(274.75,215) and (279,219.25) .. (279,224.5) .. controls (279,229.75) and 				(274.75,234) .. (269.5,234) .. controls (264.25,234) and (260,229.75) .. 				(260,224.5) -- cycle ; 				%Shape: Circle [id:dp5807873055759664]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(307,224.5) .. controls (307,219.25) and (311.25,215) .. (316.5,215) .. controls 				(321.75,215) and (326,219.25) .. (326,224.5) .. controls (326,229.75) and 				(321.75,234) .. (316.5,234) .. controls (311.25,234) and (307,229.75) .. 				(307,224.5) -- cycle ; 				%Shape: Circle [id:dp6662466496481644]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(354,224.5) .. controls (354,219.25) and (358.25,215) .. (363.5,215) .. controls 				(368.75,215) and (373,219.25) .. (373,224.5) .. controls (373,229.75) and 				(368.75,234) .. (363.5,234) .. controls (358.25,234) and (354,229.75) .. 				(354,224.5) -- cycle ; 				%Shape: Circle [id:dp12183197381304434]  				\draw  [fill={rgb, 255:red, 0; green, 0; blue, 255 }  ,fill opacity=1 ] 				(401,224.5) .. controls (401,219.25) and (405.25,215) .. (410.5,215) .. controls 				(415.75,215) and (420,219.25) .. (420,224.5) .. controls (420,229.75) and 				(415.75,234) .. (410.5,234) .. controls (405.25,234) and (401,229.75) .. 				(401,224.5) -- cycle ; 				%Shape: Circle [id:dp429967506253606]  				\draw  [fill={rgb, 255:red, 0; green, 0; blue, 255 }  ,fill opacity=1 ] 				(260,287) .. controls (260,281.75) and (264.25,277.5) .. (269.5,277.5) .. 				controls (274.75,277.5) and (279,281.75) .. (279,287) .. controls (279,292.25) 				and (274.75,296.5) .. (269.5,296.5) .. controls (264.25,296.5) and (260,292.25) 				.. (260,287) -- cycle ; 				%Curve Lines [id:da9286783730725067]  				\draw    (286.68,159.56) .. controls (377.22,150.2) and (400.64,156.18) .. 				(409.5,102.5) ; 				\draw [shift={(282.5,160)}, rotate = 353.93] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da8850549458813675]  				\draw    (128.97,84.51) .. controls (135.24,48.05) and (180.23,48.73) .. 				(268.5,40) ; 				\draw [shift={(128.5,88)}, rotate = 275.71] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da3909124250354792]  				\draw    (411.08,85.01) .. controls (404.95,47.24) and (373.8,51.7) .. 				(268.5,40) ; 				\draw [shift={(411.5,88)}, rotate = 263.05] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da6737364833099672]  				\draw    (250.4,158.34) .. controls (161.58,144.29) and (131.44,153.23) .. 				(127.5,102.5) ; 				\draw [shift={(254.5,159)}, rotate = 189.26] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da37836147566573985]  				\draw    (174.5,102.5) .. controls (162.08,124.94) and (152.41,126.86) .. 				(137.62,114.8) ; 				\draw [shift={(135.5,113)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da7731722596940602]  				\draw    (127.5,102.5) .. controls (134.26,87.54) and (145.67,78.17) .. 				(164.43,93.26) ; 				\draw [shift={(166.5,95)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da8051353371492228]  				\draw    (174.5,102.5) .. controls (181.26,87.54) and (192.67,78.17) .. 				(211.43,93.26) ; 				\draw [shift={(213.5,95)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da10189996908761945]  				\draw    (221.5,102.5) .. controls (228.26,87.54) and (239.67,78.17) .. 				(258.43,93.26) ; 				\draw [shift={(260.5,95)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da5077994354046187]  				\draw    (268.5,102.5) .. controls (275.26,87.54) and (286.67,78.17) .. 				(305.43,93.26) ; 				\draw [shift={(307.5,95)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da8313992907856331]  				\draw    (315.5,102.5) .. controls (322.26,87.54) and (333.67,78.17) .. 				(352.43,93.26) ; 				\draw [shift={(354.5,95)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da9126988940377668]  				\draw    (362.5,102.5) .. controls (369.26,87.54) and (380.67,78.17) .. 				(399.43,93.26) ; 				\draw [shift={(401.5,95)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da4112197243828456]  				\draw    (221.5,102.5) .. controls (209.08,124.94) and (199.41,126.86) .. 				(184.62,114.8) ; 				\draw [shift={(182.5,113)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da608788360549991]  				\draw    (268.5,102.5) .. controls (256.08,124.94) and (246.41,126.86) .. 				(231.62,114.8) ; 				\draw [shift={(229.5,113)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da5020670943704229]  				\draw    (315.5,102.5) .. controls (303.08,124.94) and (293.41,126.86) .. 				(278.62,114.8) ; 				\draw [shift={(276.5,113)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da7963885877725204]  				\draw    (362.5,102.5) .. controls (350.09,124.94) and (340.41,126.86) .. 				(325.62,114.8) ; 				\draw [shift={(323.5,113)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da2849598088341072]  				\draw    (409.5,102.5) .. controls (397.09,124.94) and (387.41,126.86) .. 				(372.62,114.8) ; 				\draw [shift={(370.5,113)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Shape: Circle [id:dp1261093240604687]  				\draw  [fill={rgb, 255:red, 0; green, 255; blue, 0 }  ,fill opacity=1 ] 				(259,40) .. controls (259,34.75) and (263.25,30.5) .. (268.5,30.5) .. controls 				(273.75,30.5) and (278,34.75) .. (278,40) .. controls (278,45.25) and 				(273.75,49.5) .. (268.5,49.5) .. controls (263.25,49.5) and (259,45.25) .. 				(259,40) -- cycle ; 				%Shape: Circle [id:dp6581842843585207]  				\draw  [fill={rgb, 255:red, 0; green, 255; blue, 0 }  ,fill opacity=1 ] 				(118,102.5) .. controls (118,97.25) and (122.25,93) .. (127.5,93) .. controls 				(132.75,93) and (137,97.25) .. (137,102.5) .. controls (137,107.75) and 				(132.75,112) .. (127.5,112) .. controls (122.25,112) and (118,107.75) .. 				(118,102.5) -- cycle ; 				%Shape: Circle [id:dp3098811598832202]  				\draw  [fill={rgb, 255:red, 0; green, 255; blue, 0 }  ,fill opacity=1 ] 				(165,102.5) .. controls (165,97.25) and (169.25,93) .. (174.5,93) .. controls 				(179.75,93) and (184,97.25) .. (184,102.5) .. controls (184,107.75) and 				(179.75,112) .. (174.5,112) .. controls (169.25,112) and (165,107.75) .. 				(165,102.5) -- cycle ; 				%Shape: Circle [id:dp1743606968163196]  				\draw  [fill={rgb, 255:red, 0; green, 255; blue, 0 }  ,fill opacity=1 ] 				(212,102.5) .. controls (212,97.25) and (216.25,93) .. (221.5,93) .. controls 				(226.75,93) and (231,97.25) .. (231,102.5) .. controls (231,107.75) and 				(226.75,112) .. (221.5,112) .. controls (216.25,112) and (212,107.75) .. 				(212,102.5) -- cycle ; 				%Shape: Circle [id:dp9428234144683866]  				\draw  [fill={rgb, 255:red, 0; green, 255; blue, 0 }  ,fill opacity=1 ] 				(259,102.5) .. controls (259,97.25) and (263.25,93) .. (268.5,93) .. controls 				(273.75,93) and (278,97.25) .. (278,102.5) .. controls (278,107.75) and 				(273.75,112) .. (268.5,112) .. controls (263.25,112) and (259,107.75) .. 				(259,102.5) -- cycle ; 				%Shape: Circle [id:dp7665719063856832]  				\draw  [fill={rgb, 255:red, 0; green, 255; blue, 0 }  ,fill opacity=1 ] 				(306,102.5) .. controls (306,97.25) and (310.25,93) .. (315.5,93) .. controls 				(320.75,93) and (325,97.25) .. (325,102.5) .. controls (325,107.75) and 				(320.75,112) .. (315.5,112) .. controls (310.25,112) and (306,107.75) .. 				(306,102.5) -- cycle ; 				%Shape: Circle [id:dp7908837197247668]  				\draw  [fill={rgb, 255:red, 0; green, 255; blue, 0 }  ,fill opacity=1 ] 				(353,102.5) .. controls (353,97.25) and (357.25,93) .. (362.5,93) .. controls 				(367.75,93) and (372,97.25) .. (372,102.5) .. controls (372,107.75) and 				(367.75,112) .. (362.5,112) .. controls (357.25,112) and (353,107.75) .. 				(353,102.5) -- cycle ; 				%Shape: Circle [id:dp7625937074895868]  				\draw  [fill={rgb, 255:red, 0; green, 255; blue, 0 }  ,fill opacity=1 ] 				(400,102.5) .. controls (400,97.25) and (404.25,93) .. (409.5,93) .. controls 				(414.75,93) and (419,97.25) .. (419,102.5) .. controls (419,107.75) and 				(414.75,112) .. (409.5,112) .. controls (404.25,112) and (400,107.75) .. 				(400,102.5) -- cycle ; 				%Shape: Circle [id:dp7889841473119084]  				\draw  [fill={rgb, 255:red, 0; green, 255; blue, 0 }  ,fill opacity=1 ] 				(259,165) .. controls (259,159.75) and (263.25,155.5) .. (268.5,155.5) .. 				controls (273.75,155.5) and (278,159.75) .. (278,165) .. controls (278,170.25) 				and (273.75,174.5) .. (268.5,174.5) .. controls (263.25,174.5) and (259,170.25) 				.. (259,165) -- cycle ; 				%Curve Lines [id:da7404393502583956]  				\draw    (288.68,603.56) .. controls (379.22,594.2) and (402.64,600.18) .. 				(411.5,546.5) ; 				\draw [shift={(284.5,604)}, rotate = 353.93] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da7706240527574225]  				\draw    (252.4,602.34) .. controls (163.58,588.29) and (133.44,597.23) .. 				(129.5,546.5) ; 				\draw [shift={(256.5,603)}, rotate = 189.26] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da5058272619908606]  				\draw    (129.97,531.51) .. controls (136.24,495.05) and (181.23,495.73) .. 				(269.5,487) ; 				\draw [shift={(129.5,535)}, rotate = 275.71] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da6332891533016745]  				\draw    (412.08,532.01) .. controls (405.95,494.24) and (374.8,498.7) .. 				(269.5,487) ; 				\draw [shift={(412.5,535)}, rotate = 263.05] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da5479803578784406]  				\draw    (176.5,546.5) .. controls (164.08,568.94) and (154.41,570.86) .. 				(139.62,558.8) ; 				\draw [shift={(137.5,557)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da3605404021427311]  				\draw    (129.5,546.5) .. controls (136.26,531.54) and (147.67,522.17) .. 				(166.43,537.26) ; 				\draw [shift={(168.5,539)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da08740840597455768]  				\draw    (176.5,546.5) .. controls (183.26,531.54) and (194.67,522.17) .. 				(213.43,537.26) ; 				\draw [shift={(215.5,539)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da822603442155299]  				\draw    (223.5,546.5) .. controls (230.26,531.54) and (241.67,522.17) .. 				(260.43,537.26) ; 				\draw [shift={(262.5,539)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da5843249449467047]  				\draw    (270.5,546.5) .. controls (277.26,531.54) and (288.67,522.17) .. 				(307.43,537.26) ; 				\draw [shift={(309.5,539)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da42880348256353007]  				\draw    (317.5,546.5) .. controls (324.26,531.54) and (335.67,522.17) .. 				(354.43,537.26) ; 				\draw [shift={(356.5,539)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da9283265810055624]  				\draw    (364.5,546.5) .. controls (371.26,531.54) and (382.67,522.17) .. 				(401.43,537.26) ; 				\draw [shift={(403.5,539)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da05778759947895917]  				\draw    (223.5,546.5) .. controls (211.08,568.94) and (201.41,570.86) .. 				(186.62,558.8) ; 				\draw [shift={(184.5,557)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da9659973534759966]  				\draw    (270.5,546.5) .. controls (258.08,568.94) and (248.41,570.86) .. 				(233.62,558.8) ; 				\draw [shift={(231.5,557)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da19229610516301865]  				\draw    (317.5,546.5) .. controls (305.08,568.94) and (295.41,570.86) .. 				(280.62,558.8) ; 				\draw [shift={(278.5,557)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da10304658250049437]  				\draw    (364.5,546.5) .. controls (352.09,568.94) and (342.41,570.86) .. 				(327.62,558.8) ; 				\draw [shift={(325.5,557)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da5631749899873638]  				\draw    (411.5,546.5) .. controls (399.09,568.94) and (389.41,570.86) .. 				(374.62,558.8) ; 				\draw [shift={(372.5,557)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Shape: Circle [id:dp059914313486222115]  				\draw  [fill={rgb, 255:red, 0; green, 0; blue, 255 }  ,fill opacity=1 ] 				(120,546.5) .. controls (120,541.25) and (124.25,537) .. (129.5,537) .. controls 				(134.75,537) and (139,541.25) .. (139,546.5) .. controls (139,551.75) and 				(134.75,556) .. (129.5,556) .. controls (124.25,556) and (120,551.75) .. 				(120,546.5) -- cycle ; 				%Shape: Circle [id:dp40719634947354877]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(167,546.5) .. controls (167,541.25) and (171.25,537) .. (176.5,537) .. controls 				(181.75,537) and (186,541.25) .. (186,546.5) .. controls (186,551.75) and 				(181.75,556) .. (176.5,556) .. controls (171.25,556) and (167,551.75) .. 				(167,546.5) -- cycle ; 				%Shape: Circle [id:dp033808415127278835]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(214,546.5) .. controls (214,541.25) and (218.25,537) .. (223.5,537) .. controls 				(228.75,537) and (233,541.25) .. (233,546.5) .. controls (233,551.75) and 				(228.75,556) .. (223.5,556) .. controls (218.25,556) and (214,551.75) .. 				(214,546.5) -- cycle ; 				%Shape: Circle [id:dp18544536071308904]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(261,546.5) .. controls (261,541.25) and (265.25,537) .. (270.5,537) .. controls 				(275.75,537) and (280,541.25) .. (280,546.5) .. controls (280,551.75) and 				(275.75,556) .. (270.5,556) .. controls (265.25,556) and (261,551.75) .. 				(261,546.5) -- cycle ; 				%Shape: Circle [id:dp6046935295904428]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(308,546.5) .. controls (308,541.25) and (312.25,537) .. (317.5,537) .. controls 				(322.75,537) and (327,541.25) .. (327,546.5) .. controls (327,551.75) and 				(322.75,556) .. (317.5,556) .. controls (312.25,556) and (308,551.75) .. 				(308,546.5) -- cycle ; 				%Shape: Circle [id:dp9859730038267814]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(355,546.5) .. controls (355,541.25) and (359.25,537) .. (364.5,537) .. controls 				(369.75,537) and (374,541.25) .. (374,546.5) .. controls (374,551.75) and 				(369.75,556) .. (364.5,556) .. controls (359.25,556) and (355,551.75) .. 				(355,546.5) -- cycle ; 				%Shape: Circle [id:dp3610148867773364]  				\draw  [fill={rgb, 255:red, 0; green, 0; blue, 255 }  ,fill opacity=1 ] 				(402,546.5) .. controls (402,541.25) and (406.25,537) .. (411.5,537) .. controls 				(416.75,537) and (421,541.25) .. (421,546.5) .. controls (421,551.75) and 				(416.75,556) .. (411.5,556) .. controls (406.25,556) and (402,551.75) .. 				(402,546.5) -- cycle ; 				%Shape: Circle [id:dp3356608098961872]  				\draw  [fill={rgb, 255:red, 0; green, 0; blue, 255 }  ,fill opacity=1 ] 				(261,609) .. controls (261,603.75) and (265.25,599.5) .. (270.5,599.5) .. 				controls (275.75,599.5) and (280,603.75) .. (280,609) .. controls (280,614.25) 				and (275.75,618.5) .. (270.5,618.5) .. controls (265.25,618.5) and (261,614.25) 				.. (261,609) -- cycle ; 				%Shape: Circle [id:dp43379074642608273]  				\draw  [fill={rgb, 255:red, 0; green, 0; blue, 255 }  ,fill opacity=1 ] 				(260,487) .. controls (260,481.75) and (264.25,477.5) .. (269.5,477.5) .. 				controls (274.75,477.5) and (279,481.75) .. (279,487) .. controls (279,492.25) 				and (274.75,496.5) .. (269.5,496.5) .. controls (264.25,496.5) and (260,492.25) 				.. (260,487) -- cycle ; 				%Curve Lines [id:da9543517598472332]  				\draw    (283.68,480.56) .. controls (374.22,471.2) and (397.64,477.18) .. 				(406.5,423.5) ; 				\draw [shift={(279.5,481)}, rotate = 353.93] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da5346750487101364]  				\draw    (253.4,479.34) .. controls (164.58,465.29) and (134.44,474.23) .. 				(130.5,423.5) ; 				\draw [shift={(257.5,480)}, rotate = 189.26] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Shape: Circle [id:dp3366263657248878]  				\draw  [fill={rgb, 255:red, 0; green, 255; blue, 0 }  ,fill opacity=1 ] 				(551,178.5) .. controls (551,173.25) and (555.25,169) .. (560.5,169) .. controls 				(565.75,169) and (570,173.25) .. (570,178.5) .. controls (570,183.75) and 				(565.75,188) .. (560.5,188) .. controls (555.25,188) and (551,183.75) .. 				(551,178.5) -- cycle ; 				%Shape: Circle [id:dp5794568744917776]  				\draw  [fill={rgb, 255:red, 0; green, 255; blue, 0 }  ,fill opacity=1 ] 				(551,238.75) .. controls (551,233.5) and (555.25,229.25) .. (560.5,229.25) .. 				controls (565.75,229.25) and (570,233.5) .. (570,238.75) .. controls (570,244) 				and (565.75,248.25) .. (560.5,248.25) .. controls (555.25,248.25) and (551,244) 				.. (551,238.75) -- cycle ; 				%Shape: Circle [id:dp8885175077359131]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(551,383) .. controls (551,377.75) and (555.25,373.5) .. (560.5,373.5) .. 				controls (565.75,373.5) and (570,377.75) .. (570,383) .. controls (570,388.25) 				and (565.75,392.5) .. (560.5,392.5) .. controls (555.25,392.5) and (551,388.25) 				.. (551,383) -- cycle ; 				 				% Text Node 				\draw (263,366.4) node [anchor=north west][inner sep=0.75pt]    {\Huge 					$\vdots $}; 				% Text Node 				\draw (92,91.4) node [anchor=north west][inner sep=0.75pt]    {$x_{1}$}; 				% Text Node 				\draw (90,214.4) node [anchor=north west][inner sep=0.75pt]    {$x_{2}$}; 				% Text Node 				\draw (92,536.4) node [anchor=north west][inner sep=0.75pt]    {$x_{n}$}; 				% Text Node 				\draw (260,10.4) node [anchor=north west][inner sep=0.75pt]    {$s$}; 				% Text Node 				\draw (266,623.4) node [anchor=north west][inner sep=0.75pt]    {$t$}; 				% Text Node 				\draw (552,297.4) node [anchor=north west][inner sep=0.75pt]    {\Huge 					$\vdots $}; 				% Text Node 				\draw (583,172.4) node [anchor=north west][inner sep=0.75pt]    {$C_{1}$}; 				% Text Node 				\draw (584,231.4) node [anchor=north west][inner sep=0.75pt]    {$C_{2}$}; 				% Text Node 				\draw (582,375.4) node [anchor=north west][inner sep=0.75pt]    {$C_{m}$}; 				 				 			 			 			 			\caption{The graph $f_\p^\ast(\varphi)$. There are $n$ rows (one per 				variable). The edges between the vertices corresponding to the clauses and the 				rest of the graph are not represented here. The green vertices are those in 				$V_{x_1}$ (assuming that $x_1$ or its negation belongs to $C_1$ and $C_2$, but 				not to $C_m$). The blue vertices are those in $C_{x_1} \setminus V_{x_1}$.} 			 		 		 		 		 		 			\centering 			 			[x=0.55pt,y=0.55pt,yscale=-1,xscale=1] 				%uncomment if require: \path (0,779); %set diagram left start at 0, and has 				%height of 779 				 				%Curve Lines [id:da5557797157875244]  				\draw    (410.5,224.5) .. controls (407.59,186.18) and (414.09,147.4) .. 				(424.52,116.81) ; 				\draw [shift={(425.5,114)}, rotate = 109.54] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da6054488966262607]  				\draw    (365.35,206.67) .. controls (379.5,152.69) and (404.02,120.6) .. 				(429.5,100.75) ; 				\draw [shift={(364.5,210)}, rotate = 284.04] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da7231639873562903]  				\draw    (222.5,215) .. controls (241.31,49.67) and (321.87,20.57) .. 				(412.74,38.44) ; 				\draw [shift={(415.5,39)}, rotate = 191.67] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da02152918818379468]  				\draw    (272.27,205.72) .. controls (265.29,98.34) and (304.76,65.78) .. 				(429.5,43.5) ; 				\draw [shift={(272.5,209)}, rotate = 265.84] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da6362218603195029]  				\draw    (410.5,224.5) .. controls (417.26,209.54) and (428.67,200.17) .. 				(447.43,215.26) ; 				\draw [shift={(449.5,217)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da9569788895971457]  				\draw    (175.5,224.5) .. controls (163.08,246.94) and (153.41,248.86) .. 				(138.62,236.8) ; 				\draw [shift={(136.5,235)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da33917190176837386]  				\draw    (128.5,224.5) .. controls (135.26,209.54) and (146.67,200.17) .. 				(165.43,215.26) ; 				\draw [shift={(167.5,217)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da17385952945843774]  				\draw    (175.5,224.5) .. controls (182.26,209.54) and (193.67,200.17) .. 				(212.43,215.26) ; 				\draw [shift={(214.5,217)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da9666569146055152]  				\draw    (222.5,224.5) .. controls (229.26,209.54) and (240.67,200.17) .. 				(259.43,215.26) ; 				\draw [shift={(261.5,217)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da22849768497254042]  				\draw    (269.5,224.5) .. controls (276.26,209.54) and (287.67,200.17) .. 				(306.43,215.26) ; 				\draw [shift={(308.5,217)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da6889879025510129]  				\draw    (316.5,224.5) .. controls (323.26,209.54) and (334.67,200.17) .. 				(353.43,215.26) ; 				\draw [shift={(355.5,217)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da057363696758943594]  				\draw    (363.5,224.5) .. controls (370.26,209.54) and (381.67,200.17) .. 				(400.43,215.26) ; 				\draw [shift={(402.5,217)}, rotate = 221.19] [fill={rgb, 255:red, 0; green, 					0; blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da05594049224034636]  				\draw    (222.5,224.5) .. controls (210.08,246.94) and (200.41,248.86) .. 				(185.62,236.8) ; 				\draw [shift={(183.5,235)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da5630128819006084]  				\draw    (269.5,224.5) .. controls (257.08,246.94) and (247.41,248.86) .. 				(232.62,236.8) ; 				\draw [shift={(230.5,235)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da6412166295519673]  				\draw    (316.5,224.5) .. controls (304.08,246.94) and (294.41,248.86) .. 				(279.62,236.8) ; 				\draw [shift={(277.5,235)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da45412685795691754]  				\draw    (363.5,224.5) .. controls (351.09,246.94) and (341.41,248.86) .. 				(326.62,236.8) ; 				\draw [shift={(324.5,235)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Curve Lines [id:da016994463289178863]  				\draw    (410.5,224.5) .. controls (398.09,246.94) and (388.41,248.86) .. 				(373.62,236.8) ; 				\draw [shift={(371.5,235)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Shape: Circle [id:dp38064413393674545]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(119,224.5) .. controls (119,219.25) and (123.25,215) .. (128.5,215) .. controls 				(133.75,215) and (138,219.25) .. (138,224.5) .. controls (138,229.75) and 				(133.75,234) .. (128.5,234) .. controls (123.25,234) and (119,229.75) .. 				(119,224.5) -- cycle ; 				%Shape: Circle [id:dp7174705700048332]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(166,224.5) .. controls (166,219.25) and (170.25,215) .. (175.5,215) .. controls 				(180.75,215) and (185,219.25) .. (185,224.5) .. controls (185,229.75) and 				(180.75,234) .. (175.5,234) .. controls (170.25,234) and (166,229.75) .. 				(166,224.5) -- cycle ; 				%Shape: Circle [id:dp5227134379658741]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(213,224.5) .. controls (213,219.25) and (217.25,215) .. (222.5,215) .. controls 				(227.75,215) and (232,219.25) .. (232,224.5) .. controls (232,229.75) and 				(227.75,234) .. (222.5,234) .. controls (217.25,234) and (213,229.75) .. 				(213,224.5) -- cycle ; 				%Shape: Circle [id:dp4394259471302915]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(260,224.5) .. controls (260,219.25) and (264.25,215) .. (269.5,215) .. controls 				(274.75,215) and (279,219.25) .. (279,224.5) .. controls (279,229.75) and 				(274.75,234) .. (269.5,234) .. controls (264.25,234) and (260,229.75) .. 				(260,224.5) -- cycle ; 				%Shape: Circle [id:dp03607001513336294]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(307,224.5) .. controls (307,219.25) and (311.25,215) .. (316.5,215) .. controls 				(321.75,215) and (326,219.25) .. (326,224.5) .. controls (326,229.75) and 				(321.75,234) .. (316.5,234) .. controls (311.25,234) and (307,229.75) .. 				(307,224.5) -- cycle ; 				%Shape: Circle [id:dp5789558599801519]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(354,224.5) .. controls (354,219.25) and (358.25,215) .. (363.5,215) .. controls 				(368.75,215) and (373,219.25) .. (373,224.5) .. controls (373,229.75) and 				(368.75,234) .. (363.5,234) .. controls (358.25,234) and (354,229.75) .. 				(354,224.5) -- cycle ; 				%Shape: Circle [id:dp27035450836021424]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(401,224.5) .. controls (401,219.25) and (405.25,215) .. (410.5,215) .. controls 				(415.75,215) and (420,219.25) .. (420,224.5) .. controls (420,229.75) and 				(415.75,234) .. (410.5,234) .. controls (405.25,234) and (401,229.75) .. 				(401,224.5) -- cycle ; 				%Shape: Circle [id:dp1961921695760236]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(420,43.5) .. controls (420,38.25) and (424.25,34) .. (429.5,34) .. controls 				(434.75,34) and (439,38.25) .. (439,43.5) .. controls (439,48.75) and 				(434.75,53) .. (429.5,53) .. controls (424.25,53) and (420,48.75) .. (420,43.5) 				-- cycle ; 				%Shape: Circle [id:dp250729763100219]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(420,100.75) .. controls (420,95.5) and (424.25,91.25) .. (429.5,91.25) .. 				controls (434.75,91.25) and (439,95.5) .. (439,100.75) .. controls (439,106) and 				(434.75,110.25) .. (429.5,110.25) .. controls (424.25,110.25) and (420,106) .. 				(420,100.75) -- cycle ; 				%Rounded Rect [id:dp57520495531582]  				\draw  [dash pattern={on 5.63pt off 4.5pt}][line width=1.5]  (207,216.8) .. 				controls (207,213.6) and (209.6,211) .. (212.8,211) -- (279.7,211) .. controls 				(282.9,211) and (285.5,213.6) .. (285.5,216.8) -- (285.5,234.2) .. controls 				(285.5,237.4) and (282.9,240) .. (279.7,240) -- (212.8,240) .. controls 				(209.6,240) and (207,237.4) .. (207,234.2) -- cycle ; 				%Curve Lines [id:da723535240886451]  				\draw    (457.5,224.5) .. controls (445.09,246.94) and (435.41,248.86) .. 				(420.62,236.8) ; 				\draw [shift={(418.5,235)}, rotate = 41.19] [fill={rgb, 255:red, 0; green, 0; 					blue, 0 }  ][line width=0.08]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- 				(8.93,4.29) -- cycle    ; 				%Shape: Circle [id:dp14660662522338552]  				\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] 				(448,224.5) .. controls (448,219.25) and (452.25,215) .. (457.5,215) .. controls 				(462.75,215) and (467,219.25) .. (467,224.5) .. controls (467,229.75) and 				(462.75,234) .. (457.5,234) .. controls (452.25,234) and (448,229.75) .. 				(448,224.5) -- cycle ; 				%Rounded Rect [id:dp34352841876600626]  				\draw  [dash pattern={on 5.63pt off 4.5pt}][line width=1.5]  (347,215.8) .. 				controls (347,212.6) and (349.6,210) .. (352.8,210) -- (419.7,210) .. controls 				(422.9,210) and (425.5,212.6) .. (425.5,215.8) -- (425.5,233.2) .. controls 				(425.5,236.4) and (422.9,239) .. (419.7,239) -- (352.8,239) .. controls 				(349.6,239) and (347,236.4) .. (347,233.2) -- cycle ; 				 				% Text Node 				\draw (90,214.4) node [anchor=north west][inner sep=0.75pt]    {$x_{1}$}; 				% Text Node 				\draw (448,35.4) node [anchor=north west][inner sep=0.75pt]    {$C_{1}$}; 				% Text Node 				\draw (447,93.4) node [anchor=north west][inner sep=0.75pt]    {$C_{2}$}; 				% Text Node 				\draw (484,216) node [anchor=north west][inner sep=0.75pt]    {\LARGE $\cdots 					$}; 				% Text Node 				\draw (236,247.4) node [anchor=north west][inner sep=0.75pt]    {$C_{1}$}; 				% Text Node 				\draw (380,247.4) node [anchor=north west][inner sep=0.75pt]    {$C_{2}$}; 				 				 			 			 			 			\caption{The connection between the nodes corresponding to clauses and the 				rest of the graph. On this example, $x_1$ appears in $C_1$, $\overline{x_1}$ 				appears in $C_2$.} 			 		 		 		 		 		Now, let us explain how to construct the graph $f_\p(\varphi)$ from 		$f_\p^\ast(\varphi)$. We proceed again as in~\cite{Sipser}, by replacing each 		vertex $u$ of $f_\p^\ast(\varphi)$ by three vertices $u_{\text{in}}$, 		$u_{\text{mid}}$, $u_{\text{out}}$. These three vertices form a path, in this 		order. Each (directed) edge from $u$ to $v$ is replaced an (undirected) edge 		from $u_{\text{out}}$ to $v_{\text{in}}$. 		 		The identifiers of the vertices of $f_\p(\varphi)$ consist in a pair: the 		first entry indicates the identifier of the corresponding vertex $u$ in 		$f_\p^\ast(\varphi)$ (see thereafter the definition), and the second entry 		indicates if it is $u_{\text{in}}$, $u_{\text{mid}}$ or $u_{\text{out}}$. In 		$f_\p^\ast(\varphi)$, the identifier of each vertex $u$ indicates if it is a 		vertex corresponding to a clause (by encoding the identifiers of the three 		variables in it), or to a variable, and in this latter case if it is linked to a 		clause vertex (and which one) or if it is a separator between two pairs (and the 		corresponding pairs it separates). All this information can be encoded with 		$O(\log n)$ bits. 		 		For every variable $x_i$ of $\varphi$, let us describe the sets $C_{x_i}$ and 		$V_{x_i}$ (and see Figure~\ref{fig:ham1} for an example). 		 			\item The set $V_{x_i}$ consists in all the vertices $u_{\text{in}}$, 			$u_{\text{mid}}$, $u_{\text{out}}$ for each vertex $u$ which is either the entry 			node corresponding to $x_i$, or the exit node, or a node in the row of $x_i$, or 			a node corresponding to a clause to which $x_i$ or its negation belongs. These 			vertices are colored in green on Figure~\ref{fig:ham1}. 			 			\item The set $C_{x_i}$ consists in $V_{x_i}$, plus all the vertices 			$u_{\text{in}}$, $u_{\text{mid}}$, $u_{\text{out}}$ for $u$ which is either an 			entry/exit node of any variable, or a first/last vertex in the row of any 			variable. These vertices are colored in blue on Figure~\ref{fig:ham1}. 		 		 		Let us verify that the properties of the definition of local reduction from 3-SAT (see the beginning of section~\ref{sec:red3SAT}) are satisfied. For \cref{s1}, the identifiers are indeed on $O(\log |V(\varphi)|)$ 		bits. For \cref{s2}, it is proved                 in~\cite{Sipser}. Properties \cref{s3a}, \cref{s3b}, \cref{s3d}, \cref{s3e}, and \cref{s3f} follow from the definition of $C_{x_i}$ and $V_{x_i}$. For \cref{s3c}, we indeed 		have $|C_{x_i}| = O(n)$ for every variable $x_i$: this holds because, by 		definition of $\F_0$, $x_i$ appears in at most $n$ clauses. 		 		Thus, we can apply Corollary~\ref{cor:reduction3SAT} which gives us the 		$\Omega\left(\frac{\sqrt{n}}{\log n}\right)$ lower bound. Since $f_\p(G)$ has 		maximum degree~at most~4, the lower bound holds even for this class of graphs.",2502.01551
proof,[Proof of Corollary~\ref{cor:4flow}] 	% 	A cubic graph has chromatic index~3 if and only if it admits a nowhere-zero 	% 	$\mathbb{Z}_4$-flow. 	%,2502.01551
proof,"[Proof of Theorem~\ref{thm:coloration aretes}] 		Let $\p$ be the property of having chromatic index $\Delta$. We will show that 		there exists a local reduction from 3-SAT in $\F_1$ to $\p$ with local expansion 		$O(1)$, and then the result will follow from                 Corollary~\ref{cor:reduction3SAT}. Recall that  $\F_1$                 was defined as the set of 3-CNF 	formulae $\varphi$ such that each variable appears in at most 7~clauses. 		Let $\varphi$ be a 3-CNF formula with variables having identifiers in 		$\{1, \ldots, |V(\varphi)|\}$, and such that each variable appears in at most 		7~clauses. Let $n:=|V(\varphi)|$, and let $m$ be the number of clauses in 		$\varphi$. Let $x_1, \ldots, x_n$ be the variables of $\varphi$, and $C_1, 		\ldots, C_m$ be its clauses. 		 		We use the reduction presented in~\cite{Holyer81}. For completeness, we recall 		this construction. First, we define an \emph{inverting component}, which is 		shown on Figure~\ref{fig:inverting}. 		 		[h] 			\centering 			\includegraphics[scale=1]{inverting} 			\caption{An inverting component and its symbolic representation.} 			 		 		 		In an edge-coloring, a pair of edges is said to be \emph{true} (resp.\ 		\emph{false}) if it is colored with the same colors (resp.\ with different 		colors). In any proper 3-edge-coloring of an inverting component, 		exactly one of the two pairs $(a,b)$ or $(c,d)$ is true, and the three other 		edges have different colors. Thus, regarding $(a,b)$ as the input and $(c,d)$ as 		the output, an inverting component changes true to false and vice-versa. 		 		Then, we define a \emph{variable-setting} component with $k$ outputs. It consists in a cycle of $k$ pairs of inverting components, as shown on 			Figure~\ref{fig:variable setting} with $k=4$. 		In any proper 3-coloring of the edges, all the output pairs must have the same 		value, either all true or all false. 		 		[h] 			\centering 			\includegraphics[scale=0.6]{variablecomp} 			\caption{A variable-setting component with four outputs.} 			 		 		 		Finally, for each clause, we will create a \emph{satisfaction-testing 			component}, represented on Figure~\ref{fig:satisfaction testing}. This component 		has a proper 3-coloring of the edges if and only if at least one of its three 		input pairs is true. 		 		[h] 			\centering 			\includegraphics[scale=0.6]{satisfactioncomp} 			\caption{A satisfaction-testing component.} 			 		 		 		The graph $f_\p(\varphi)$ is constructed as follows. 		For each variable $x_i$ such that $x_i$ or its negation belongs to $d$ clauses, 		we create a variable-setting component with $d$ outputs, numbered from~$1$ 		to~$d$. 		For each clause $C_j$, we create a satisfaction-testing component. Let 		$x_{j_1}, x_{j_2}, x_{j_3}$ be the variables which appear (positively or 		negatively) in $C_j$, by increasing order of their identifiers. Let $\ell$ be 		the index such that, by sorting the clauses containing $x_{j_1}$ or its negation 		by lexicographic order of the variables appearing inside, $C_j$ is the 		$\ell$-th. We connect the $\ell$-th output of the variable-setting component of 		$x_{j_1}$ to the input~1 of the satisfaction-testing component of $C_j$, and if 		$x_{j_1}$ appears negatively in $C_j$, we insert an inverting component in this 		branching. We do the same for $x_{j_2}$ and $x_{j_3}$ with inputs~2 and~3 of the 		satisfaction-testing component. 		This results in a graph $H$, which has some edges having an endpoint of 		degree~1 (in the satisfaction-testing components). 		The graph $f_\p(\varphi)$ is obtained by taking two copies of this graph $H$ 		and identifying these edges. It results in a cubic graph. 		 		The identifier of each vertex $u$ of $f_\p(G)$ is the following. First, it 		indicates to which of the two copies of the graph $H$ does $u$ belong to. 		Then, if $u$ belongs to a variable-setting component, it indicates to which 		variable it corresponds, its position in the variable-setting component, and if it is adjacent to an output, it also indicates the clause corresponding to the satisfaction-testing component to which it is adjacent. 		If $u$ belongs to a satisfaction-testing component, it indicates to which 		clause it corresponds, and its position in the satisfaction-testing component. 		All this information can be encoded on $O(\log n)$ bits. 		 		For every variable $x_i$ of $\varphi$, we define $C_{x_i} = V_{x_i}$ as being 		the set which contains all the vertices in the two copies of $H$ which are in 		the variable-setting component of $x_i$, in the satisfaction-testing of any 		clause to which $x_i$ belongs, and in an inverting component branched between 		its variable-setting component and the satisfaction-testing component of a 		clause in which it appears negatively. 		 		Let us verify that the properties of the definition of local reduction from 3-SAT (see the beginning of section~\ref{sec:red3SAT}) are satisfied. Property~\cref{s1} is true by definition of the identifiers of the 		vertices of $f_\p(\varphi)$, and~\cref{s2} comes from the correctness of the reduction 		in~\cite{Holyer81}. Properties \cref{s3a}, \cref{s3b}, \cref{s3e} and~\cref{s3f} follow from the 		definition of $V_{x_i}$ and $C_{x_i}$. For \cref{s3f}, we have $C_{x_i} = O(1)$ for 		every variable $x_i$, because by definition of $\F_1$, $x_i$ appears in a 		constant number of clauses (at most~7). Finally, \cref{s3d} is true because if 		$C_{x_i} \cap C_{x_j} \neq \emptyset$ then either $x_i=x_j$, or $x_i$ and $x_j$ 		have a clause in common. 		 		Thus, Corollary~\ref{cor:reduction3SAT} gives us a                 lower bound of order 		$\Omega(n/\log n)$ on the local complexity of                 of the problem, and the lower bound holds even for cubic 		graphs because $f_\p(\varphi)$ is a cubic graph.",2502.01551
proof,"Since $\C$ is a class of bounded-degree graphs, the set $N^{d-1}[u]$ has constant size for every vertex $u$. In the proof of Theorem~\ref{thm:main theorem local reduction}, the prover adds the following information in the certificate of each vertex~$u$: for every $v \in N^{d-1}[u]$, it writes the identifier of $v$, its distance to~$u$, and all the edges adjacent to $v$. This information has size $O(\log n)$ and its correctness can be checked by the vertices at the beginning of the verification procedure. Thus, we can assume that each vertex $u$ knows all the edges adjacent to the vertices in $N^{d-1}[u]$, and the rest of the proof of Theorem~\ref{thm:main theorem local reduction} is the same.",2502.01551
proof,"It was proved by Molloy and Reed \cite[Theorem 5]{MR14} that for sufficiently large~$k$,  a graph $G$ of maximum degree $k + \lceil\sqrt{k}\rceil - 3$ is not $k$-colorable if and only if there exists a vertex $v\in V(G)$ such that the subgraph of $G$ induced by $N[v]$ is not $k$-colorable. We use this to produce a proof labeling scheme for non-$k$-colorability as follows. The prover identifies a vertex $v$ such that the subgraph of $G$ induced by $N[v]$ is not $k$-colorable, and each vertex $u$ in the graph receives as a certificate  the list $L(u)$ of all neighbors of $u$ (as the graph has bounded maximum degree, this list of identifiers takes $O(\log n)$ bits). Using the lists $\{L(u):uv\in E(G) \}$, the vertex $v$ knows the subgraph of $G$ induced by $N[v]$, and can thus check that this subgraph is indeed not $k$-colorable.",2502.01551
proposition,"Let $\p$, $\p'$ be two graph properties, on two graph classes $\C$, $\C'$ respectively, and let $d \geqslant 1$. If $\C$ is a class of bounded-degree graphs, then Theorem~\ref{thm:main theorem local reduction} (and thus also Corollary~\ref{cor:reduction3col}) remains true even if we replace condition \cref{l3f} of the definition of local reduction (see Section~\ref{sec:reduc}) by the following one: 		 				\item[(R3f')] $V_u$ and its neighborhood (resp.\ $C_u$) only depends on $N^d[u]$. In 				other words: if $G'$ is another $n$-vertex graph with unique identifiers in 				$\{1, \ldots, n\}$, and if the subgraph with identifiers formed by the vertices in $N^{d-1}[u]$ and their adjacent edges is the same in $G$ and 				$G'$, then the sets $V_u$ and the subgraphs with identifiers formed by the vertices in $V_u$ and their adjacent edges in 				$f_{\p',\p}(G)$ and $f_{\p',\p}(G')$ are the same (resp.\ the sets $C_u$ in $f_{\p',\p}(G)$ 				and $f_{\p',\p}(G')$ are the same).",2502.01551
lemma,"For every vertex $u \in V(G)$, $H$ contains all the vertices and edges of the 			tag and exactly one linking component associated to it, and no other vertices in the two other linking components sharing the same root.",2502.01551
lemma,"Let us consider a clique $K_5$ on $5$ vertices, denoted by $s,t,u,v,w$. In any $2$-edge-coloring of $K_5$ without any monochromatic triangle, the color of the edge $st$ is the same as the main color of the triangle $uvw$. Conversely, any $2$-edge-coloring of the edge $st$ and of the triangle $uvw$ which makes $uvw$ non-monochromatic and which satisfies the previous condition can be completed into a $2$-edge-coloring of $K_5$ without any monochromatic triangle.",2502.01551
theorem,"(Backward contraction mappings principle) Let $T_{i}$ be a sequence of continuous self-maps of a complete metric space.     Assume      %that from some index $N$ onwards $i\geq N$,      $T_i$'s are uniform     contractions, with a certain $k<1$ in common, and for some $\theta$ there is a constant $D$ such that,              d(\theta,T_{i}(\theta))<D\quad \textrm{for all} \; i.          Then for any $\theta \in \Omega$ the backward iterates      $$\theta_n = T_{1} T_{2}\cdots T_{n}(\theta)$$     converge to a point $\theta^*$ as $n\rightarrow \infty$. Moreover, the convergence rate is exponential: i.e,  there is a constant $C$ depending on $\theta$ such that      $$     d(\theta^*, T_{1} T_{2}\cdots T_{n}(\theta))\leq C\cdot k^{n}.     $$",2502.01557
theorem,"Consider a sequence $\{T_i\}$, $i=1,2, \dots$ of independent and identically distributed random operators. Suppose that for $\theta_0\in \Omega$ the backward iterates converge to a random point (randomness is due to the sampling of the random operators $T_i$'s): $$  T_1T_2\cdots T_n(\theta_0) \longrightarrow \theta^* \quad\textrm{as}\quad n\rightarrow \infty. $$ Then the probability distribution of the forward iterates from $\theta_0$ converge (in distribution) to a stationary probability measure $\mu_{\theta^*}$. Moreover, the random point $\theta^*$ is distributed according to the same forward iterate stationary distribution $\mu_{\theta^*}$.",2502.01557
theorem,"Consider a sequence $\{T_i\}_{i > 0}$ of operators of the form $T_i(\theta) = \theta + h V_i(\theta)$, where $V_i(\theta)$ is a vector field on the parameter space. The backward and forward iterates of the sequence are related by the following identity:      T_1 \cdots T_n(\theta) = T_n \cdots T_1(\theta) + h^2 \sum_{1\leq i<j\leq n} [V_i, V_j](\theta) + \mathcal O(h^3)  where the $[V_i, V_j](\theta) = V_i'(\theta)V_j(\theta) - V_j'(\theta)V_i(\theta)$ is the Lie bracket between the vector fields $V_i$ and $V_j$.",2502.01557
definition,"Consider the SGD operators $T_i(\theta) = \theta - h \nabla L_i(\theta)$ obtained by taking the gradient of a loss function on a batch $B_i$ of data at step $i$. We denote by $\theta_n = T_n\cdots T_1(\theta_0) = \theta_{n-1} - h \nabla L_n(\theta_{n-1})$ the forward SGD iterate starting at initial point $\theta_0$ and by $\theta_n^B = T_1\cdots T_n(\theta_0)$ the corresponding backward iterate starting at the same initial point. Motivated by Theorem \ref{thm:approximate_backward}, we introduce the {\emph{approximate backward iterate}} $\tilde \theta_n$ as follows:      \tilde \theta_n = \theta_n + h^2 \sum_{1\leq i<j\leq n} [\nabla L_i, \nabla L_j] (\theta_0)",2502.01557
proof,"Condition \ref{condition:boundedness} expresses that the distance $d(\theta, T_i(\theta))$ is uniformly bounded by a constant $D$ for all $T_i's$ for a point $\theta$. Let us show that if this happens for a single point $\theta$, this happens for all points, provided we change the constant $D$. To see this, take another point $\tilde \theta$. We will compute another constant $\tilde D$ such that $d(\tilde \theta, T_i(\tilde \theta)) < \tilde D$. Namely, using the triangle inequality and the fact that $T_i$ are uniform contractions, we obtain that              d(\tilde \theta,T_i(\tilde \theta))          & \leq & d(\tilde \theta, \theta)+d(\theta,T_i(\theta))+d(T_i( \theta),T_i (\tilde \theta)) \\         & \leq & D+(1+k)d(\theta, \tilde \theta) = \tilde D.          Now, we want to prove that $\theta_n$ is a Cauchy sequence, i.e, that $d(\theta_n, \theta_m)$ tends to zero for $m>n$ as $n\rightarrow \infty$. Since $\Omega$ is assumed to be complete, this will mean that the backward iterates $\theta_n$ converge toward a point $\theta^*$.       The idea is to bound the quantity          A & = &  d(\theta_n, \theta_m) \\       & = & d(T_{1}T_{2}\cdots T_{n}(\theta),\,T_{1}T_{2}\cdots T_{m}(\theta)).          Because of the backward order (note: the forward order would not allow that), we can apply the contraction property $n$ times (since $m> n$), yielding:              A & \leq & k^{n}\cdot d(\theta,\,T_{n+1}\cdots T_{m}(\theta)).      Now a simple application of the triangle inequality produces              A & \leq &  k^{n}\Big(d(\theta,T_{n+1}(\theta)) \\           &      & + d(T_{n+1}(\theta),\,T_{n+1}T_{n+2}(\theta))+\cdots\\           &      & \cdots +d(T_{n+1}\cdots T_{m-1}(\theta),\,T_{n+1}\cdots T_{m}(\theta))\Big).      At this point, we can use the condition in \eqref{condition:boundedness} for the first term $d(\theta,T_{n+1}(\theta)) < D$ and in conjunction with the contraction property for the subsequent terms in the sum, yielding:              A  & \leq &  k^{n}\left(D+D\cdot k+\cdots + D\cdot k^{m-n+1}\right) \\            & \leq & D\cdot k^n  \cdot \left( \frac{1 - k^{n-m+2}}{1-k}\right) \\           & \leq & \frac{D\cdot k^{n}}{1-k},          where we used the sum of a geometric series. Now, this yields that $A\rightarrow 0$ as $n\rightarrow\infty$, meaning that the sequence $\theta_n$     is a Cauchy sequence and thus converges to a certain point $\theta^*$     since $\Omega$ is complete.      Then, taking the limit $m\rightarrow \infty$ we obtain     $$     d(\theta_n,\theta^*) \leq \frac{D\cdot k^{n}}{1-k} = C\cdot k^n,     $$     with $C:=\frac{D}{1-k}$, which shows the exponential convergence rate.",2502.01557
proof,"We proceed by induction. For the base case, $k=1$, this is trivial. Suppose now that this is true for any composition of $k-1$ operators. By definition of $T_{i_1}$ we have that              T_{i_1}\cdots T_{i_k}(\theta)          & = & T_{i_1}(T_{i_2}\cdots T_{i_k}(\theta)) \\         & = & X + h V_{i_1}(X)           with $X = T_{i_2}\cdots T_{i_k}(\theta)$. Now by induction hypothesis we have that              X = \theta + h\sum_{l=2}^{k} V_{i_l}(\theta) + h^2 \sum_{2\leq u < v \leq k} V_{i_u}'(\theta) V_{i_v}(\theta) + \mathcal O(h^3)          Therefore, taking a Taylor series for the second term of \eqref{eq:X}, we obtain          hV_{i_1}(X) = hV_{i_1}(\theta) + h^2 \sum_{l=2}^k V_{i_1}'(\theta) V_{i_l}(\theta) +\mathcal O(h^3).          Summing up in \eqref{eq:X} the expressions we have found for $X$ and $hV_{i_1}(X)$ above, we obtain that the composition $T_{i_1}\cdots T_{i_k}(\theta)$ has the form          \theta + h\sum_{l=1}^{k} V_{i_l}(\theta) + h^2 \sum_{1\leq u < v \leq k} V_{i_u}'(\theta) V_{i_v}(\theta) + \mathcal O(h^3),          which completes the proof.",2502.01557
proof,"By Lemma \ref{lemma:commutation}, we have that the backward iterate is       T_{1}  \cdots T_{n}=       \operatorname{id}     + h \sum_{l=1}^n V_{l}     + h^2 \sum_{1 \leq u < v\leq n} V_{u}' V_{v}     + \mathcal O(h^3)   while the forward iterate is obtained by reversing the indices:      T_{n}  \cdots T_{1}=       1     + h \sum_{l=1}^n V_{l}     + h^2 \sum_{1 \leq u < v\leq n} V_{v}' V_{u}     + \mathcal O(h^3).  We now see that the difference $$D(\theta) =  T_{1}  \cdots T_{n}(\theta) -  T_{n}  \cdots T_{1}(\theta)$$ between the backward and forward iterates is of the form       D(\theta)      & = & h^2 \sum_{1 \leq u < v\leq n} V_{u}'(\theta) V_{v}(\theta) - V_{v}'(\theta) V_{u}(\theta) + \mathcal O(h^3)\\      & = & h^2 \sum_{1 \leq u < v\leq n} [V_u, V_v](\theta)  + \mathcal O(h^3),  which completes the proof.",2502.01557
proof,"By Definition \ref{definition:backward_iterate} of the approximate backward iterates we have that $\tilde \theta_n = \theta_n + h^2 C_n$ with  $$ C_n = \sum_{1\leq i<j\leq n} [\nabla L_i, \nabla L_j] (\theta_0). $$  First observe that we can split $C_n$ into two parts  C_n  & = & \sum_{1\leq i<j\leq n-1} [\nabla L_i, \nabla L_j] (\theta_0) + \sum_{1\leq i \leq n-1} [\nabla L_i, \nabla L_n] (\theta_0)\\ & = & C_{n-1} + [\sum_{1\leq i \leq n-1} \nabla L_i, \nabla L_n](\theta_0) \\ & = & C_{n-1} + \left(\sum_{1\leq i \leq n-1} \nabla^2 L_i(\theta_0) \right)\nabla L_n(\theta_0) \\ &   & \quad - \nabla^2 L_n(\theta_0) \left(\sum_{1\leq i \leq n-1} \nabla L_i(\theta_0)\right) \\ & = & C_{n-1} + H_n \nabla L_n(\theta_0) -  \nabla^2 L_n(\theta_0) g_n,  where $H_n$ and $g_n$ are expressed recursively as in the theorem statement.",2502.01557
lemma,"Let $L(\theta)$ be a strictly convex function and define the map $T(\theta)=\theta-h\nabla L(\theta)$.     Then              \left \| T(\theta_1)-T(\theta_2) \right \| \leq \sqrt{1 - 2 h m + h^2 M^2} \left \| \theta_1-\theta_2 \right \|.          In particular, for small enough $h \in (0,1)$ (depending on $m$ and $M$) the map $T$ is a uniform contraction.",2502.01557
lemma,"Consider a sequence $\{T_i\}_{i > 0}$ of operators of the form $T_i(\theta) = \theta + h V_i(\theta)$, where $V_i(\theta)$ is a vector field on the parameter space. Then for any choice of indices $i_1, \dots, i_k$ we have that      T_{i_1}  \cdots T_{i_k}=       1     + h \sum_{l=1}^k V_{i_l}     + h^2 \sum_{1\leq u < v \leq k} V_{i_u}' V_{i_v}     + \mathcal O(h^3)",2502.01557
example,"{\bf (Full-batch gradient descent convergence.)} In this case the operator is $T(\theta) = \theta - h\nabla L(\theta)$ for a loss function $L$. The idea of the proof is to choose the learning rate $h$ small enough so that $T$ becomes a contraction. More precisely, around a minimum $\theta^*$ the operator $T$ can be approximated using a first-order expansion of the gradient around the minimum as $T(\theta) = \theta^* + (1 - hH)(\theta-\theta^*),$ where $H=\nabla^2 L(\theta^*)$. Now we have that       \|T(\theta_1) - T(\theta_2)\| \leq \|1 - hH\|_{\textrm{op}} \|\theta_1 - \theta_2\|,  where $\|1 - hH\|_{\textrm{op}}$ is the operator norm of $1 -hH$, that is the operator maximum eigenvalue: $\max_i | 1 - h\lambda_i|$ (here the $\lambda_i$'s are eigenvalues of $H$). It is easy to verify that $ \|1 - hH\|_{\textrm{op}} < 1$ if and only if the learning rate is strictly smaller than $2/\lambda_{\textrm{max}}$ where $\lambda_{\textrm{max}}$ is the largest eigenvalue of $H$. Convergence for that setting follows from the Banach fixed point theorem.",2502.01557
example,"({\bf Forward iterations counter-example.}) Here is an extreme example illustrating the convergence failure for the forward sequence of iterates (even when the maps are uniform contractions), while the backward sequence converges to a single point under the conditions of Theorem \ref{lemma:contraction_principle}. Consider the two constant maps $S(\theta)=x_0$, and $U(\theta)=y_0$, which are contractions with $k=0$. Assume that $x_{0}\neq y_{0}$, now also assume that each $T_{i}$ is either equal to $S$ or $U$ with equal probability to be selected. Then, independently of $\theta$, the forward iterates \[     T_{n}T_{n-1}\cdots T_{1}(\theta) \] will jump between $x_{0}$ and $y_{0}$, according to whether $T_{n}$ is $S$ or $U$ at that particular $n$. Thus no convergence to a single point is possible, although the sequence converges to a probability  uniformly distributed in the two outcomes, since for each forward iterate either outcome has probability $1/2$. On the contrary, the backward trajectory \[     T_1 T_2\cdots T_n(\theta) \] will always converge to a single point determined by the first element in the sequence: either to $x_0$ if $T_1 = S$ or to $y_0$ if $T_1 = U$.",2502.01557
theorem,"Let $ \cT \colon \bbR \to \bbR $ be a preprocessing function subject to \Cref{asmp:T}, and let $ D\in\bbR^{d\times d} $ be defined in \Cref{eqn:D}.     %    Let $ \cT \colon \bbR \to \bbR $ be a preprocessing function subject to \Cref{asmp:T}, and let $ D\in\bbR^{d\times d} $ be defined in \Cref{eqn:D}. Denote by     Let $\alpha_1\geq \dots\ \geq \alpha_j > \tau$ (for some $j\in[p]$) be all the solutions to           \det\paren{\zetadelta(\alpha)I-R^\infty(\alpha)}=0.              %to the equation     %         %        \det\paren{\zetadelta(\alpha)I_p-R^\infty(\alpha)}=0.     %         Then, for the top $j$ eigenvalues of $D$, it holds that              \lambda_1^D,\dots,\lambda_j^D \asconv \zetadelta(\alpha_1), \dots, \zetadelta(\alpha_j),          and for the remaining $p-j$ eigenvalues, it holds that     $$\lambda_{j+1}^D,\dots,\lambda_p^D \asconv \zetadelta(\lambdabardelta).$$",2502.01583
theorem,"In the setting of \Cref{thm:eigvalconv}, let $\alpha_k = \alpha_{k+1} = \cdots = \alpha_{k+m-1} $ be solutions to \Cref{eq:master_eq2} of multiplicity $m$, i.e., $ \alpha_{k-1} > \alpha_k > \alpha_{k+m-2} $ whenever $ k\ge2, k+m-2\le j $.      Let $E_k^\infty\subset\bbR^p$ be the corresponding $m$-dimensional eigenspace of $R^\infty(\alpha_k)$. If $\alpha_k>\lambdabardelta$, then %it holds               \max_{l\in[p]}\liminf_{d\to\infty}\sum_{i=k}^{k+m-1}\abs{\inprod{v_i^D}{e_l^{(d)}}}^2>0.          More precisely, under the additional assumption that either $m=1$ or the eigenspace $E_k^\infty$ stays invariant in a neighbourhood of $\alpha_k$, for any $ l\in[p] $,               \sum_{i=k}^{k+m-1}\abs{\inprod{v_i^D}{e_l^{(d)}}}^2\asconv \frac{\zetadelta'(\alpha_k) \sum_{i=k}^{k+m-1}\abs{\inprod{h_i^\infty}{e_l^{(p)}}}^2}{\zetadelta'(\alpha_k)+{h_k^\infty}^\top \frac{d}{d\alpha}R^\infty(\alpha_k)h_k^\infty},                   where $\brace{h_i^\infty : k \le i\le k+m-1}\subset\bbR^p$ is an orthonormal basis of $E_k^\infty$ and $\frac{d}{d\alpha}R^\infty(\cdot)$ denotes the entry-wise derivative of the matrix      $R^\infty(\cdot)$.",2502.01583
theorem,"The optimal weak recovery threshold $\delta_c$ equals               \delta_c &= \brack{ \max_{u\in\bbS^{p-1}}\int_{\bbR}\frac{\paren{\expt[s]{p(y \mathrel{\vert} s)\cdot(\inprod{s}{u}^2-1)}}^2}{\expt[s]{p(y \mathrel{\vert} s)}}dy }^{-1}         ,            where expectations are intended over $ s\sim\cN(0_p,I_p) $.         Furthermore, denote by $u_c\in\bbS^{p - 1}$ a maximizer in the above expression and let              \cT^*(y) &\coloneqq 1 - \frac{\expt[s]{p(y \mathrel{\vert} s)}}{\expt[s]{p(y \mathrel{\vert} s)\cdot\inprod{s}{u_c}^2}} , \qquad         \cT_\delta^*(y) \coloneqq \frac{\sqrt{\delta_c} \cdot \taustar(y)}{\sqrt{\delta}-(\sqrt{\delta}-\sqrt{\delta_c})\cdot \taustar(y)} .            Then, for any $ \delta > \delta_c $, $ \cT_\delta^* \in \sT_\delta $.",2502.01583
theorem,"%     Let $\alpha_1\geq \dots\ \geq \alpha_j > \tau$, for some $j\in[p]$, be all the solutions to the equation %     %        \det\paren{\zetadelta(\alpha)I_p-R^\infty(\alpha)}=0. %     %    Then, for the top $j$ eigenvalues of $D_n$, it holds that %     %        \lambda_1^D,\dots,\lambda_j^D \asconv \zetadelta(\alpha_1), \dots, \zetadelta(\alpha_j), %     %    and for the remaining $p-j$ eigenvalues, it holds that  %   $$\lambda_{j+1}^D,\dots,\lambda_p^D \asconv \zetadelta(\lambdabardelta).$$  %",2502.01583
definition,"[Weak recovery]          Consider the model \Cref{eq:multi}.      Let $ \wh{W} \equiv \wh{W}(A, y) = \matrix{\wh{w}_1, & \cdots, & \wh{w}_p} \in \bbR^{d\times p} $ be an estimator such that $ \normtwo{\wh{w}_i} = 1 $ for all $i\in[p]$.      We say that $ \wh{W} $ weakly recovers the subspace $ \spn\brace{ w_1^*, \cdots, w_p^* } $ if               \max_{v\in\bbS^{p-1}} \brace{ \liminf_{d\to\infty} \frac{\normtwo{\wh{W}^\top W^* v}}{\normtwo{W^* v}} } &> 0 , \notag           where the almost sure limit is taken with respect to the proportional scaling in \Cref{asmp:proportional}.",2502.01583
proof,"Transforming \eqref{eq:matrixRelements} with the matrix determinant lemma yields that, for any $\lambda>\lambda_1^P$,             R(\lambda)_{i,i} = a_{i,i}-q_i^\top(P-\lambda I_{d-p})^{-1}q_i=a_{i,i}+\frac{1}{\cLi^{-1}(\lambda)}.          Moreover, it holds that              R(\lambda)_{i,j} =a_{i,j}- \frac{(q_i+q_j)^\top(P-\lambda I_{d-p})^{-1}(q_i+q_j) - q_i^\top(P-\lambda I_{d-p})^{-1}q_i - q_j^\top(P-\lambda I_{d-p})^{-1}q_j}{2}. \notag           From the same transformation with the matrix determinant lemma, it follows that      $$(q_i+q_j)^\top(P-\lambda I_{d-p})^{-1}(q_i+q_j) = -\frac{1}{\cL_{i,j}^{-1}(\lambda)}.$$     Substituting the previous identity in \Cref{eq:ijelementmatrixR} gives \Cref{eq:matrixRminusoneoffdiag}.     Note that, for $\mu$ such that $\cLi(\mu)>\lambda_1^P$, it holds that $\cLi$ is an increasing differentiable function, so its inverse and derivative are well defined.      Finally, by differentiating %equations      \Cref{eq:matrixRminusonediag} and \Cref{eq:matrixRminusoneoffdiag}, we get the other two equations.",2502.01583
proof,"[Proof of \Cref{thm:eigvalconv}.]     Note that \eqref{eq:master_eq2} can be reformulated as              \det\paren{\zetadelta(\alpha)I_p-R^\infty(\alpha)}=\prod_{i=1}^p( \zetadelta(\alpha)-\lambda_i^\infty(\alpha))=0.          The assumption of the theorem implies that $\alpha_1\geq\dots \geq\alpha_j>\tau$ satisfy \eqref{eq:zetadeltalambda}.     Recall that each function $\zetadelta(\alpha) - \lambda_i^\infty(\alpha)$ is strictly increasing on $]\tau,+\infty[$, with the right edge limit $+\infty$. Therefore, the implicit assumption that $j\in[p]$ is justified as there could be at most $1$ solution to the equation     $$\zetadelta(\alpha) - \lambda_i^\infty(\alpha)=0,$$     for each $i\in[p]$.     Moreover, it holds by definition that $\lambda_1^\infty(\alpha)\geq\dots\geq\lambda_{p}^\infty(\alpha)$. Thus, it must be that each $\alpha_i$ is the unique solution to      $$\zetadelta(\alpha) - \lambda_i^\infty(\alpha)=0,$$     for $i\in[j]$ and $\alpha>\tau$.     Let us denote by $\mu_i^*\coloneq {\lambda_i^\infty}(\alpha_i)\in]\lambda_i^{a^\infty},\tau_i^\infty[$. Then $\mu_i^*$ is a solution to the equation     $$\tildeLiinfty(\mu)-\mu=0,$$     in the domain of definition $\tildeLiinfty(\mu)$, as $\tildeLiinfty(\mu_i^*) = \zetadelta((\lambda_i^\infty)^{-1}(\lambda_i^\infty(\alpha_i)))$. Moreover, $\mu_i^*$ is the unique such solution, due to the strict monotonicity of $\tildeLiinfty(\mu)-\mu$ on its domain $]\lambda_i^{a^\infty},\tau_i^\infty[$.          Furthermore, \Cref{prop:eigvalrec} implies that each $\lambda_i^D$ is the unique solution to \eqref{eq:eigvalrec}. For each $\mu$ where $\tildeLiinfty(\mu)$ is defined, it holds that              \tildeLi(\mu) - \mu \asconv\tildeLiinfty(\mu) - \mu,          by \Cref{prop:tildeLiconv} in \Cref{app:asymptotbehav}.          As both $\tildeLi(\mu)$ and $\tildeLiinfty(\mu)$ are non-increasing, the functions $\tildeLi(\mu) - \mu$ and  $\tildeLiinfty(\mu)-\mu$ are strictly decreasing. Hence, by \cite[Lemma A.1]{lu2020phase}, it holds that      \lambda_i^D\asconv\tildeLiinfty(\mu_i^*).          Substituting $\mu_i^* = {\lambda_i^\infty}(\alpha_i)$ in \Cref{eq:fplast} gives \eqref{eq:outsidebulkeigconv} for $i\in[j]$.          It remains to show the claim for the remaining $p-j$ eigenvalues. As \eqref{eq:master_eq2} has only $j$ solutions by assumption, it follows that     $$\zetadelta(\alpha) - \lambda_i^\infty(\alpha) = \tildeLiinfty(\lambda_i^\infty(\alpha))-\lambda_i^\infty(\alpha)=0$$     has no solutions for $\alpha>\tau$ and $i> j$. Denoting $\mu = \lambda_i^\infty(\alpha)$, it further holds that     $$\tildeLiinfty(\mu)-\mu=0$$     has no solutions for $\mu \in ]\lambda_i^{a^\infty},t_i^\infty[$. Since      $$\lim_{\mu\to\lambda_i^{a^\infty}} \tildeLiinfty(\mu) - \mu = +\infty, $$     it must be that $\tildeLiinfty(\mu)-\mu>0$ for all $\mu\in]\lambda_i^{a^\infty},t_i^\infty[$.     Using \eqref{eq:asconvtildeli}, we %can conclude that it holds      have that     $$\tildeLi(\mu)-\mu>0,$$     for all $\mu \in ]\lambda_i^{a^\infty},t_i^\infty[$ and $n$ large enough. As $\lambda_i^a\asconv \lambda_i^{a^\infty}$ and each $\tildeLi(\mu)$ is defined on $]\lambda_i^a,+\infty[$, the solution to the equation     $$\tildeLi(\mu) - \mu =0 $$     must be for $\mu>t_i^\infty$.     Then, applying \Cref{prop:tildeLiconv}, for any fixed $\mu$ it holds that      $$\tildeLi(\mu)\asconv \zetadelta(\lambdabardelta).$$     Lastly, as both $\mu-\tildeLi(\mu)$ and $\mu-\zetadelta(\lambdabardelta)$ are increasing functions, Lemma A.1 in \cite{lu2020phase} implies that      $$\lambda_i^D\asconv \zetadelta(\lambdabardelta),$$     for all $i>j$, which proves the claim.",2502.01583
proof,"By \Cref{lemma:matrixRchar}, %from subsection \Cref{subsubsec:deteigvec}  it suffices to understand the behavior of the functions in \Cref{eq:auxfun},  %$$\cLi(\mu)= \lambda_1(P+\mu q_iq_i^\top), \text{ and } \cL_{i,j}(\mu)= \lambda_1(P+\mu (q_i+q_j)(q_i+q_j)^\top),$$ as $n,d\to \infty$. However, we first need to verify the assumption that $\lambda_k^D>\lambda_1^P$ almost surely. From \Cref{thm:eigvalconv}, it follows that  $$\lambda_k^D\asconv \zetadelta(\alpha_k) ,$$ and $\zetadelta(\alpha_k)> \zetadelta(\lambdabardelta)$ as $\alpha_k>\lambdabardelta$ and $\zetadelta$ is strictly increasing on $]\lambdabardelta,+\infty[$.  Furthermore, $\lambda_1^P\asconv \zetadelta(\lambdabardelta)$, hence $\lambda_k^D>\lambda_1^P$ almost surely.  Let us denote by $G$ the function  $$G(\mu) = -\frac{1}{\mu},$$ which we will use in the continuation of the proof. Using \cite{bai-yao-2012} as in the proof of \Cref{prop:tildeLiconv},  we get that  $$\cLi(\mu)\asconv \zetadelta \circ {Q_i}^{-1}\circ G(\mu),$$ where $Q_i(\alpha) \coloneq \expt{\frac{s_i^2z^2}{z-\alpha}}$. Notice that $Q_i(\alpha)$ is invertible by \cite[Remark 3.3]{lu2020phase}, which is stated for the analogous function $Q$.  In the same manner, it holds that $$\cL_{i,j}(\mu)\asconv \zetadelta \circ {Q_{i,j}}^{-1}\circ G(\mu),$$ where $Q_{i,j}(\alpha) \coloneq \expt{\frac{(s_i+s_j)^2z^2}{z-\alpha}}$. As $\alpha_k>\lambdabardelta$, we have that $\zetadelta$ is strictly increasing and invertible, hence $$\cLi^{-1}(\lambda_k^D)\asconv G \circ Q_i \circ \zetadelta^{-1} \circ \zetadelta(\alpha_k) = G \circ Q_i (\alpha_k),$$ which follows from \cite[Lemma A.1]{lu2020phase}. Plugging this into \eqref{eq:matrixRminusonediag} we get      R(\lambda_k^D)_{i,i}\asconv a^{\infty}_{i,i}-Q_i (\alpha_k).  Note that  $$a^{\infty}_{i,i}-Q_i (\alpha_k) = \expt{s_i^2z} -  \expt{\frac{s_i^2z^2}{z-\alpha_k}} = \expt{\frac{\alpha_k s_i^2z}{\alpha_k-z}} = R^\infty(\alpha_k)_{i,i}.$$ Similarly, it holds that $$R(\lambda_k^D)_{i,j}\asconv a^{\infty}_{i,j}-Q_{i,j} (\alpha_k),$$ which combined with \eqref{eq:tempdiagconv} proves \eqref{eq:matrixRconv}.  Moreover, we have that $\cLi(\mu)$ is differentiable (see \Cref{lemma:matrixRchar}), so for its derivative it holds that $$\cLi'(\mu)\asconv \zetadelta' \circ {Q_i}^{-1}\circ G(\mu) \cdot \paren{Q_i^{-1}}'\circ G(\mu) \cdot G'(\mu),$$ which follows from \cite[Lemma A.2]{lu2020phase}. Plugging this into \eqref{eq:matrixRminustwodiag} we get  $$\frac{d}{d\lambda}R(\lambda_k^D)_{i,i}\asconv \frac{\frac{d}{d\alpha}(R^\infty(\alpha_k)_{i,i})}{\zetadelta'(\alpha_k)}.$$ Similarly, it holds that $$\frac{d}{d\lambda}R(\lambda_k^D)_{i,j}\asconv \frac{\frac{d}{d\alpha}(R^\infty(\alpha_k)_{i,j})}{\zetadelta'(\alpha_k)}.$$ Combining the last two equations we obtain \eqref{eq:matrixderRconv}.",2502.01583
proof,"[Proof of \Cref{thm:main}.]      Let $v_i^D=\matrix{h_i\\ g_i}$, for $i\in\{k,\dots, k+m-1\}$. Since $\alpha_k>\lambdabardelta$, the conditions of \Cref{prop:eigenvec} are satisfied as in the proof of \Cref{thm:matrixRconvergence}. Thus, it holds that              h_i = \frac{\tilde{h}_i}{\sqrt{1-\tilde{h}_i^\top\frac{d}{d\lambda}R(\lambda_i^D)\tilde{h}_i}},          where $\tilde{h}_i = \frac{h_i}{\norm{2}{h_i}}$ is the unit norm eigenvector of $R(\lambda_i^D)$. Note that the vectors $\tilde{h}_i$ are orthogonal. %The vectors $v_i^D$ are either orthogonal as eigenvectors corresponding to different eigenvalues, or should a multiplicity in $\lambda_i^D$ occur, through the choice of an orthogonal basis of the corresponding eigenspace. Consequently, the vectors $\tilde{h}_i$ will be orthogonal as eigenvectors of the matrix corresponding to eigenvalues of different value, or through choice of the orthogonal eigenbasis should there be eigenvalue multiplicty.      Furthermore, \Cref{thm:matrixRconvergence} gives that              R(\lambda_k^D)\asconv R^\infty(\alpha_k), \qquad \frac{d}{d\lambda}R(\lambda_k^D) \asconv \frac{1}{\zetadelta'(\alpha_k)}\frac{d}{d\alpha}R^\infty(\alpha_k).          Then, applying the results from \cite[II.1.4]{kato2013perturbation}, %(as proved in this StackExchange \href{https://math.stackexchange.com/questions/4054792/convergence-of-eigenvalues-and-spaces-of-sequence-of-compact-szmmetric-and-posi}{answer}).     it holds that the orthonormal projection to the eigenspace corresponding to the $k$-th eigenvalue also converges, that is               \Pi_{E_k} \asconv \Pi_{E^\infty_k},          where $E_k$ is the space spanned by the eigenvectors $h_k,\dots, h_{k+m-1}$ and $E^\infty_k$ is the eigenspace of the limiting matrix $R^\infty(\alpha_k)$, corresponding to the eigenvalue $\zetadelta(\alpha_k)$ of multiplicity $m$.     Due to orthonormality of $\tilde{h}_i$, we can write the orthonormal projection more explicitly as     $$\Pi_{E_k} = \sum_{i=k}^{k+m-1}\frac{h_ih_i^\top}{\norm{2}{h_i}^2} = \sum_{i=k}^{k+m-1}\tilde{h}_i\tilde{h}_i^\top,$$     and               \Pi_{E^\infty_k} = \sum_{i=k}^{k+m-1}\frac{h^\infty_i{h^\infty_i}^\top}{\norm{2}{h^\infty_i}^2}=\sum_{i=k}^{k+m-1}h^\infty_i{h^\infty_i}^\top,          where $h^\infty_k\dots, h^\infty_{k+j-1}$ is any choice of the orthonormal eigenbasis of $E^\infty_k$.      From \eqref{eq:hkhtildek}, it follows that      $$\sum_{i=k}^{k+m-1} \frac{1}{\norm{2}{h_i}^2} = m - \sum_{i=k}^{k+m-1}\tilde{h}_i^\top\frac{d}{d\lambda}R(\lambda_i^D)\tilde{h}_i\geq m - m\cdot\lambda_p\left(\frac{d}{d\lambda}R(\lambda_i^D)     \right).$$     Moreover, due to  \eqref{eq:rlambdaconv} and the continuity of eigenvalues, the RHS has a convergent limit          m - m\cdot\lambda_p\left(\frac{d}{d\lambda}R(\lambda_i^D)\right) \asconv m - m \frac{1}{\zetadelta'(\alpha_k)}\lambda_p\left(\frac{d}{d\alpha}R^\infty(\alpha_k)\right).                  Note that the matrix $\frac{d}{d\alpha}R^\infty(\alpha_k) = -\expt{\frac{ss^\top z^2}{(\alpha_k-z)^2}}$ is strictly negative definite for $\alpha_k>\tau$, which implies that $\lambda_p(\frac{d}{d\alpha}R^\infty(\alpha_k))<0$.     As $\alpha_k>\lambdabardelta$, it holds that $\zetadelta'(\alpha_k)>0$ and the RHS of \Cref{eq:convlimit} is finite. This further implies that, for each $i$ s.t.\ $k\leq i\leq k+m-1$, it must hold              \liminf_{d\to\infty}\norm{2}{h_i}>0.          Note that                   \sum_{i=k}^{k+m-1}\abs{\inprod{v_i^D}{e_l^{(d)}}}^2 = \sum_{i=k}^{k+m-1}\abs{\inprod{h_i}{e_l^{(p)}}}^2 &= \sum_{i=k}^{k+m-1} \norm{2}{h_i}^2\abs{\inprod{\tilde{h}_i}{e_l^{(p)}}}^2\\         &\geq \min_{t\in \{k, \ldots, k+m-1\}}\norm{2}{h_t}^2\sum_{i=k}^{k+m-1}\abs{\inprod{\tilde{h}_i}{e_l^{(p)}}}^2\\         &=  \min_{t\in \{k, \ldots, k+m-1\}}\norm{2}{h_t}^2 \cdot {e_l^{(p)}}^\top \Pi_{E_k}{e_l^{(p)}}.               Let us pick $e_l^{(d)}$ such that $\Pi_{E_k^\infty}(e_l^{(p)})\neq 0$. Then, \eqref{eq:rlambdaconv} implies that               \Pi_{E_k}(e_l^{(p)})\neq 0,          for all $d$ large enough.  Finally, combining \eqref{eq:liminfhi}, \eqref{eq:hiinequality} and \eqref{eq:pineq} proves     $$\liminf_{d\to\infty}\sum_{i=k}^{k+m-1}\abs{\inprod{v_i^D}{e_l^{(d)}}}^2>0,$$     which gives the claim in \eqref{eq:liminfconv}.          Let us now assume, as in the statement, that $E_k^\infty$ is also the eigenspace corresponding to the $k$-th eigenvalue of $R^\infty(\alpha+\Delta)$  for any small enough $\Delta$.      For arbitrary eigenvectors $h_{i_1}$ and $h_{i_2}$ from $E_k^\infty$, it holds that                    {h_{i_1}^\infty}^\top\frac{d}{d\alpha}R^\infty(\alpha_k)h_{i_1}^\infty &= \lim_{\Delta\to 0} \frac{{h_{i_1}^\infty}^\top R^\infty(\alpha_k+\Delta)h_{i_1}^\infty-{h_{i_1}^\infty}^\top R^\infty(\alpha_k)h_{i_1}^\infty }{\Delta}\\         &=\lim_{\Delta\to 0} \frac{{h_{i_2}^\infty}^\top R^\infty(\alpha_k+\Delta)h_{i_2}^\infty-{h_{i_2}^\infty}^\top R^\infty(\alpha_k)h_{i_2}^\infty}{\Delta}\\         &={h_{i_2}^\infty}^\top\frac{d}{d\alpha}R^\infty(\alpha_k)h_{i_2}^\infty,                since ${h_{i_1}^\infty}^\top R^\infty(\alpha_k+\Delta)h_{i_1}^\infty = {h_{i_2}^\infty}^\top R^\infty(\alpha_k+\Delta)h_{i_2}^\infty$ for any small enough $\Delta$.      Note that, for any $\epsilon$ and large enough $d$, it holds that                \norm{2}{\Pi_{E_k} - \Pi_{E_k^\infty}}<\epsilon.            due to \eqref{eq:pieqkconv}. Let us now fix  $\tilde{h}_i$, for some $i\in\{k,\dots,k+m-1\}$. As we can choose any orthonormal basis when writing out $\Pi_{E_k^\infty}$ in $\eqref{eq:orthonormalbasisinfty}$, let us choose one such that $h_i^\infty = \frac{\Pi_{E_k^\infty}(\tilde{h}_i)}{\norm{2}{\Pi_{E_k^\infty}(\tilde{h}_i)}}$. Then, \eqref{eq:epsinequal} implies that       $$\norm{2}{\sum_{i=k}^{k+m-1}\tilde{h}_i\tilde{h}_i^\top - \sum_{i=k}^{k+m-1}h_i^\infty{h_i^\infty}^\top}<\epsilon.$$      From the orthonormality of the chosen eigenbasis, it holds that                              \norm{2}{\tilde{h}_i - \Pi_{E_k^\infty}\tilde{h}_i} &= \norm{2}{(\Pi_{E_k} - \Pi_{E_k^\infty})(\tilde{h}_i)} \\              &\leq \norm{2}{\Pi_{E_k} - \Pi_{E_k^\infty}} \norm{2}{\tilde{h}_i} \\              &<\epsilon.                     This also implies $1+\epsilon>\norm{2}{\Pi_{E_k^\infty}\tilde{h}_i}\geq 1-\epsilon$, hence                               \norm{2}{\tilde{h}_i - h_i^\infty} &= \norm{2}{\tilde{h}_i - \frac{\Pi_{E_k^\infty}(\tilde{h}_i)}{\norm{2}{\Pi_{E_k^\infty}(\tilde{h}_i)}}} \\              &= \norm{2}{\frac{\tilde{h}_i - \Pi_{E_k^\infty}(\tilde{h}_i)}{\norm{2}{\Pi_{E_k^\infty}(\tilde{h}_i)}}+\tilde{h}_i\frac{1-\norm{2}{\Pi_{E_k^\infty}(\tilde{h}_i)}}{\norm{2}{\Pi_{E_k^\infty}(\tilde{h}_i)}}}\\              &\leq \frac{\epsilon}{1-\epsilon}+\frac{\epsilon}{1-\epsilon}<4\epsilon.           \notag            % As we have that $h_i^\infty\sim\tilde{h}_i$,      Thus, \eqref{eq:rlambdaconv} implies that, for large enough $d$,      $$\norm{2}{\tilde{h}_i^\top\frac{d}{d\lambda}R(\lambda_k^D)\tilde{h}_i - \frac{1}{\zetadelta'(\alpha_k)}{h_i^\infty}^\top\frac{d}{d\alpha}R^\infty(\alpha_k)h_i^\infty}<c\cdot \epsilon,$$      for some constant $c$ independent of $\epsilon$.      Plugging in the expression \eqref{eq:equalderivative} makes $h_i^\infty$ not depend on $\tilde{h}_i$ anymore, resulting in                 \tilde{h}_i^\top\frac{d}{d\lambda}R(\lambda_k^D)\tilde{h}_i\asconv \frac{1}{\zetadelta'(\alpha_k)}{h_{l}^\infty}^\top\frac{d}{d\alpha}R^\infty(\alpha_k)h_{l}^\infty,            for an arbitrary unit norm eigenvector $h_{l}^\infty\in E^\infty_k$.      Finally, combining \eqref{eq:hkhtildek} and \eqref{eq:normconv} with \eqref{eq:pieqkconv} implies       $$\sum_{i=k}^{k+m-1}\tilde{h}_i\tilde{h}_i^\top\asconv \frac{\zetadelta'(\alpha_k) \sum_{i=k}^{k+m-1}h_i^\infty {h_i^\infty}^\top}{\zetadelta'(\alpha_k)+{h_k^\infty}^\top \frac{d}{d\alpha}R^\infty(\alpha_k)h_k^\infty},$$      proving the claim. The case without multiplicity ($m=1$) is simpler and follows along similar lines. For completeness, we report the proof as that of \Cref{prop:mastereigenvectors} in \Cref{app:asymptotbehav}.",2502.01583
proof,"Notice first that, for all sufficiently large $n$, there are almost surely at least $p$ elements in the array $\brack{z_1 ,z_2 ,\dots}$ that are non-zero. This follows from \Cref{asmp:T} that $\prob{Z = 0}<1$, as done in the proof of \cite[Proposition 3.2]{lu2020phase}. Now, the $i$-th column of $ZS$ is obtained by scaling a standard $p$ dimensional Gaussian by $z_i$. As the columns of $S$ are almost surely independent and, for sufficiently large $n$, at least $p$ elements $z_i$'s are non-zero, it must be that at least $p$ columns of $ZS$ are linearly independent, which proves the claim.",2502.01583
proof,"By definition, it holds that $v_i^a\neq 0$. Thus, \Cref{lemma:fr} implies that almost surely $Z S v^a_i \neq 0$.     Furthermore, the elements of the matrix $U$ are sampled independently from $Z$ and $S$, so we can fix $x_i\coloneqq ZSv^a_i \neq 0$ and conclude      $$\prob{U^\top x_i=0} = 0,$$     for the probability measure associated to the elements of $U$. This is due to the fact that, for $x_i\neq 0$,      $$\prob{U^\top x_i=0}=\prob{\forall \,j\in [d-p],\ \inprod{u^j}{x_i} = 0} = \prod_{i=1}^{d-p}\prob{\inprod{u_j}{x_i} = 0}=0,$$     as each $u_j\in\bbR^n$ is sampled from a multi-variate Gaussian.      Lastly, using the union bound, we have %it holds almost surely that     $$\prob{\exists \,i\in [p], U^\top x_i=0} \leq \sum_{i=1}^p \prob{U^\top x_i=0}=0,$$     implying  that almost surely $qv^a_i\neq 0$ for every eigenvector of the matrix $a$.",2502.01583
proof,"To simplify exposition, let us denote by $M_\mu\coloneqq P-q(a-\mu I_p)^{-1}q^\top$, as well as by $r=\frac{qv_i^a}{\norm{2}{qv_i^a}}$ which is well defined as $qv_i^a\neq0$. Using Weyl's inequality (see e.g. \cite[Section 4.3]{horn2012matrix}), one has $$\lambda_{j}(M_{\mu_1}) \leq \lambda_{j-1}(M_{\mu_2}) + \lambda_2\paren{M_{\mu_1}-M_{\mu_2}}.$$ Note that $M_{\mu_1}-M_{\mu_2} = q\paren{(a-\mu_2 I_p)^{-1}-(a-\mu_1 I_p)^{-1}}q^\top$ and that the SVD decomposition of $(a-\mu I_d)^{-1}$ is $$(a-\mu I_p)^{-1} = \sum_{k=1}^p \frac{v_k^av_k^{a\top}}{\lambda_k^a - \mu}.$$ Plugging that in, we get $$(a-\mu_2 I_p)^{-1} - (a-\mu_1 I_p)^{-1} = v_i^av_i^{a\top}\paren{\frac{1}{\lambda_i^a - \mu_2}+\frac{1}{\mu_1-\lambda_i^a}}+\sum_{k\neq i}^p v_k^av_k^{a\top}\paren{\frac{\mu_2-\mu_1}{(\lambda_k^a - \mu_2)(\lambda_k^a - \mu_1)}}.$$  Taking the limits $\mu_1\to{\lambda^a_i}^+$ and $\mu_2\to{\lambda^a_i}^-$, one readily obtains that $\lambda_2(M_{\mu_1}-M_{\mu_2}):=\varepsilon_{\mu_2}\to 0$.  Before continuing, let us denote by $\Pi_{r}\coloneqq rr^\top$ the orthogonal projection to the subspace defined by $r$, and by $\Pi_{{r}^\perp}$ the orthogonal projection to the subspace $r^\perp$. Obviously it holds that $$\Pir+\Pirperp = I_{d-p}.$$ Thus,       \lambda_{j-1}(M_{\mu_2}) &=  \lambda_{j-1}\paren{(\Pir+\Pirperp)M_{\mu_2}(\Pir+\Pirperp)}\\                              &\leq \lambda_{j-1}\paren{\Pirperp M_{\mu_2}\Pirperp}+\lambda_1(\Pir M_{\mu_2}\Pir +\Pirperp M_{\mu_2}\Pir +\Pir M_{\mu_2}\Pirperp),  where the last line is due to the fact that the matrix $\Pir M_{\mu_2}\Pir +\Pirperp M_{\mu_2}\Pir +\Pir M_{\mu_2}\Pirperp$ is symmetric and through a subsequent application of Weyl's inequality. Let us analyze the eigenvector corresponding to the largest eigenvalue. Namely, for an eigenvector $t = \Pirperp t + \Pir t =: %t_r+t_{r^\perp}$ t_{r^\perp}+t_r$ of the discussed matrix with corresponding eigenvalue $\lambda$, we have that      \Pir M_{\mu_2}\Pir\ t_r +\Pir M_{\mu_2}\Pirperp\ t_{r^\perp} &= \lambda\ t_r,\\     \Pirperp M_{\mu_2}\Pir\ t_r &= \lambda\ t_{r^\perp}.  If $t_r$ is the 0 vector, then $\lambda=0$. Otherwise, as $\Pir M_{\mu_2}\Pirperp\ t_{r^\perp}$ has a convergent, finite limit as $\mu_2\to{\lambda^a_i}^-$ and $t_r^\top\Pir M_{\mu_2}\Pir\ t_r\to - \infty$, it must hold that $\lambda \to -\infty$. This gives the following inequality  $$\lambda_{j}(M_{\mu_1}) \leq \lambda_{j-1}(M_{\mu_2})+\epsilon_{\mu_2}\leq \lambda_{j-1}(\Pirperp M_{\mu_2}\Pirperp)+\epsilon_{\mu_2}',$$ where $\epsilon_{\mu_2}'\to 0$ as $\mu_2\to{\lambda^a_i}^-$.  Let us now lower bound $\lambda_{j}(M_{\mu_1})$. In a similar manner as before, we have that       \lambda_{j}(M_{\mu_1})&=\lambda_{j}\paren{(\Pir+\Pirperp)M_{\mu_1}(\Pir+\Pirperp)}\\     &\geq\lambda_{j}\paren{\frac{1}{2}\Pir M_{\mu_1}\Pir+\Pirperp M_{\mu_1}\Pirperp}                           +\lambda_{d-p}\paren{\frac{1}{2}\Pir M_{\mu_1}\Pir+\Pirperp M_{\mu_1}\Pir +\Pir M_{\mu_1}\Pirperp}\\                           &\geq \lambda_{j}\paren{\frac{1}{2}\Pir M_{\mu_1}\Pir+\Pirperp M_{\mu_1}\Pirperp} - \epsilon_{\mu_1},  where as $\mu_1\to{\lambda^a_i}^+$ it holds that $\epsilon_{\mu_1}\to 0$ with the same arguments as above.   Note that each of the eigenvectors of $\frac{1}{2}\Pir M_{\mu_1}\Pir$ corresponding to a non-zero eigenvalue is orthogonal to each of the eigenvectors of  $\Pirperp M_{\mu_1}\Pirperp$ corresponding to a non-zero eigenvalue. Furthermore, $\lambda_1\paren{\frac{1}{2}\Pir M_{\mu_1}\Pir}\to \infty$ as $\mu_1\to{\lambda^a_i}^+$. Lastly, since $\Pirperp M_{\mu_1}\Pirperp$ has a convergent, finite limit, it holds that  $$\lambda_{j}\paren{\frac{1}{2}\Pir M_{\mu_1}\Pir+\Pirperp M_{\mu_1}\Pirperp} = \lambda_{j-1}\paren{\Pirperp M_{\mu_1}\Pirperp},$$ as $\mu_1\to{\lambda^a_i}^+$. This allows us to conclude that $$\lambda_{j-1}\paren{\Pirperp M_{\mu_1}\Pirperp} - \epsilon_{\mu_1}\leq  \lambda_{j}(M_{\mu_1})\leq \lambda_{j-1}(M_{\mu_2})+\epsilon_{\mu_2}\leq\lambda_{j-1}(\Pirperp M_{\mu_2}\Pirperp)+\epsilon_{\mu_2}'.$$ Finally, by taking the limits $\mu_1\to{\lambda^a_i}^+$ and $\mu_2\to{\lambda^a_i}^-$ we get      \lim_{\mu_1\to{\lambda^a_i}^+}L_j(\mu_1) = \lim_{\mu_2\to{\lambda^a_i}^-}L_{j-1}(\mu_2) = \lambda_{j-1}\paren{\Pirperp M_{\lambda_i^a}\Pirperp}.",2502.01583
proof,"First, we prove that each $L_i(\mu)$ is non-increasing in an arbitrary domain $]\lambda_j^a,\lambda_{j-1}^a[$. In fact, for any $\mu_1>\mu_2$ in that interval, it holds that              L_i(\mu_1)-L_i(\mu_2) &= \lambda_i(P-q(a-\mu_1 I_p)^{-1}q^\top) - \lambda_i(P-q(a-\mu_2 I_p)^{-1}q^\top)\\         &\leq \lambda_{1}(q(a-\mu_2 I_p)^{-1}q^\top-q(a-\mu_1 I_p)^{-1}q^\top)\\         &= \lambda_{1}\left(q\sum_{k=1}^p v_k^av_k^{a\top}\paren{\frac{\mu_2-\mu_1}{(\lambda_k^a - \mu_2)(\lambda_k^a - \mu_1)}}q^\top\right)\\         &\leq 0,          where the first inequality is due to Weyl's inequality.          Thus, by the definition in \eqref{eq:defLtilde} and by \Cref{lemma:samelimits},  we have that the function $\tilde{L}_i$ is non-increasing in $]\lambda_i^a,+\infty[$, for $i\in[p]$. In the same manner, for $i>p$, it also holds that $\tilde{L}_i$ is non-increasing in $]\lambda_p^a,+\infty[$.     Moreover, since $qv_i^a\neq 0$ and     $$P-q(a-\mu I_p)^{-1}q^\top = P - \frac{(qv_i^a)(qv_i^a)^\top}{\lambda_i^a - \mu}-\sum_{k\neq i}^p \frac{(qv_k^a)(qv_k^a)^\top}{\lambda_k^a - \mu},$$     it holds that, for any $i\in[p]$,     $$\lim_{\mu\to{\lambda_{i}^a}^+}\tilde{L}_i(\mu) = \lim_{\mu\to{\lambda_{i}^a}^+}\lambda_1(P-q(a-\mu I_p)^{-1}q^\top) = +\infty.$$     Finally, using the same formula, one also obtains that, for $i\in [d-p]$,              \lim_{\mu\to\infty}\tilde{L}_i(\mu) &= \lim_{\mu\to\infty}\lambda_i(P-q(a-\mu I_p)^{-1}q^\top) = \lambda_i(P). \notag \qedhere       %   for any $i$.",2502.01583
proof,"All eigenvalues of $D$ are exactly the solutions to              \det\paren{D-\lambda I_{d}}=0.         Applying the formula for the determinant of a block matrix implies     $$\det\paren{D-\lambda I_{d}} = \det\paren{P-\lambda I_{d-p}-q(a-\lambda I_d)^{-1}q^\top}\det(a-\lambda I_d).$$     As by assumption $\det(a-\lambda I_d)\neq 0$, \eqref{eq:detwhole} is equivalent to     $$\det\paren{P-\lambda I_{d-p}-q(a-\lambda I_d)^{-1}q^\top}=0.$$      Moreover by definition of the determinant and the fact that the matrix in questions is symmetric, it holds that              \det\paren{P-\lambda I_{d-p}-q(a-\lambda I_d)^{-1}q^\top} &= \prod_{i=1}^{d-p}\lambda_i\paren{P-\lambda I_{d-p}-q(a-\lambda I_d)^{-1}q^\top}\\         &= \prod_{i=1}^{d-p}(L_i(\lambda)-\lambda).          Therefore, we have that $$\det\paren{P-\lambda I_{d-p}-q(a-\lambda I_d)^{-1}q^\top}=0,$$     if and only if there exists a $k$ and $\mu$ such that              L_k(\mu)&=\mu.\qedhere",2502.01583
proof,"Let us first prove the only if part of the statement. We denote the eigenvector corresponding to $\lambda_i^D$ as $v_i^D = \matrix{h_i \\ g_i}$, where $h_i\in \bbR^p$, $g\in \bbR^{d-p}$. It follows that $$ D v_i^D = \matrix{ a & q^\top\\                     q & P}\matrix{h_i \\ g_i} = \lambda^a_j \matrix{h_i \\ g_i}.$$ Splitting this equation into $p$ and $d-p$ coordinates gives      a h_i + q^\top g_i &= \lambda^a_j h_i,\\     q h_i + P g_i &= \lambda^a_j g_i.  Since $(a-\lambda^a_jI_p)$ is singular, its SVD decomposition is $$(a-\lambda^a_jI_p) = \sum_{k=1}^p (\lambda_k^a-\lambda_j^a)v_k^av_k^{a\top}= \sum_{k\neq j}^p (\lambda_k-\lambda_j)v_k^av_k^{a\top}.$$ From  \eqref{eq:firsteq}, it follows that $(a-\lambda^a_jI_p)h_i = -q^\top g_i$. Then, plugging in the SVD, it holds that $\sum_{k\neq j}^p (\lambda_k-\lambda_j)v_k^av_k^{a\top} h_i= -q^\top g_i$. Multiplying both sides by $v_j^a$, due to the matrix being symmetric and thus eigenvectors orthogonal, it holds that $$\sum_{k\neq j}^p (\lambda_k-\lambda_j)\inprod{v_k^a}{h_i}\inprod{v_k^a}{v_j^a} = 0 = -\inprod{q^\top g_i}{v_j^a}.$$ From there, we can conclude that $q^\top g_i \perp v_j^a$, which is equivalent to $g_i\perp qv_j^a$. Moreover, \eqref{eq:firsteq} can be rewritten as %out we can get that it is equivalent to having  $$h_i = -(a-\lambda^a_jI_p)^\dagger q^\top g_i + \alpha v_j^a,$$ for some $\alpha$. Plugging this result into \eqref{eq:secndeq} gives %one has that it is equivalent to having a solution to  -q (a-\lambda^a_j I_p)^\dagger q^\top g_i + \alpha qv_j^a + P g_i = \lambda^a_j g_i,  for some $\alpha$. Let us, as before, denote by $r =q v_j^a/\|q v_j^a\|_2$, and by $\Pirperp$ the orthogonal projection to the subspace defined by $r^\perp$. As noted before, $g_i\perp qv_j^a$, which implies that $g_i=\Pirperp g_i$. Plugging it into \Cref{eq:dc} gives $$ -q (a-\lambda^a_j I_p)^\dagger q^\top \Pirperp g_i + \alpha qv_j^a + P \Pirperp g_i = \lambda^a_j \Pirperp g_i.$$ Multiplying the previous equation on the left by $\Pirperp$ results in  $$ -\Pirperp q (a-\lambda^a_j I_p)^\dagger q^\top \Pirperp g_i + \Pirperp P \Pirperp g_i = \lambda^a_j \Pirperp g_i.$$ This means that $\Pirperp g_i$ is an eigenvector of the matrix $-\Pirperp q (a-\lambda^a_j I_p)^\dagger q^\top \Pirperp + \Pirperp P \Pirperp$ with the corresponding eigenvalue $\lambda^a_j$, i.e., $$\lambda_k(\Pirperp (P-q (a-\lambda^a_jI_p)^\dagger q^\top)\Pirperp) = \lambda_j^a,$$ for some $k$. From \eqref{eq:limitL_i} we can see the LHS is exactly $\lim_{\mu\to{\lambda_j^a}^+} L_k(\mu)$ for some $k$. As proved in \Cref{lem:eiglimits}, it holds that $\lim_{\mu\to{\lambda_j^a}^+} L_1(\mu) = +\infty$, so it must be that $k\geq 2$.  Conversely, by following the same steps in reverse, if  $\lim_{\mu\to{\lambda_j^a}^+} L_k(\mu)=\lambda_j^a$, then there is a vector $g_i$ that solves $$ -q (a-\lambda^a_j)^\dagger q^\top g_i + \alpha qv_j^a + P g_i = \lambda^a_j g_i,$$ for some $\alpha$. By setting  $$h_i = -(a-\lambda^a_jI_p)^\dagger q^\top g_i + \alpha v_j^a,$$ it follows that $w = \matrix{h_i \\ g_i}$ is an eigenvector of $D$ with eigenvalue $\lambda_j^a$ as stated.",2502.01583
proof,"[Proof of \Cref{prop:eigvalrec}.]     Let us first prove that \eqref{eq:eigvalrec} has a unique solution, for $i\in[p]$.      Since $\tilde{L}_i(\mu)$ is non-increasing and continuous, we have that $\tilde{L}_i(\mu) -\mu$ is decreasing and continuous. Moreover, for $i\in[p]$ it has limits     $$\lim_{\mu\to{\lambda_{i}^a}^+}\tilde{L}_i(\mu)-\mu=+\infty,\text{ and } \lim_{\mu\to\infty}\tilde{L}_i(\mu)-\mu=-\infty,$$     due to \Cref{lem:eiglimits}. Then, applying the intermediate value theorem implies that there must be a unique $\mu_i$ for which $\tilde{L}_i(\mu_i) - \mu_i=0$.          Next, let us prove that the unique solution $\mu_i$ of \eqref{eq:eigvalrec} is indeed an eigenvalue of $D$. First, suppose that $\mu_i=\lambda_j^a$, for some $j\in[p]$. Then, \eqref{eq:limitL_i} would imply that      $$\lim_{\mu\to{\lambda_j^a}^+} L_k(\mu) = \lambda_j^a,$$     for some $k\geq 2$.     Then, \Cref{lemma:iffeiga} implies that $\lambda_j^a$ is an eigenvalue of $D$. Next,  suppose  that $\mu_i\notin \Lambda^a$. Then, by definition of $\tilde{L}_i$, it holds that     $$L_k(\mu_i)=\mu_i,$$     for some $k$. \Cref{lemma:iffeig} then implies that $\mu_i$ must be an eigenvalue of $D$.          Finally, let us prove that $\mu_i$ is exactly the $i$-th eigenvalue of $D$. To do so, we first prove that every eigenvalue of $D$ that is larger or equal to $\lambda_p^a$ is a solution to the following equation in $\mu$:     $$\tilde{L}_m(\mu)=\mu,$$     for some $m\in [d-p]$. This follows from \Cref{lemma:iffeig,lemma:iffeiga}, which imply that any eigenvalue of $D$ is covered by checking the conditions       $$ L_k(\mu) = \mu \text{ or } \lim_{\mu\to{\lambda_j^a}^+} L_k(\mu) = \lambda_j^a,$$     which are all covered by considering $\tilde{L}_m(\mu)$ for $m\in [d-p]$.          As $\tilde{L}_1(\mu)\geq \tilde{L}_2(\mu) \geq \dots \geq  \tilde{L}_p(\mu) \geq\dots\geq\tilde{L}_{d-p}(\mu)$ and $\lambda_1^D\geq \lambda_2^D\geq \dots \lambda_p^D$,     it must be that the solution to \eqref{eq:eigvalrec} is exactly the $i$-th eigenvalue of the matrix $D$, and the proof is complete.",2502.01583
proof,"[Proof of \Cref{prop:eigenvec}.] Note that \eqref{eq:generaleigvec} is equivalent to the system of two equations              a h_i + q^\top g_i &= \lambda^D_i h_i,\\         q h_i + P g_i &= \lambda^D_i g_i.               As we consider only the eigenvectors $v_i^D$ for $i\leq j$, the matrix $(P-\lambda_i^DI_{d-p})$ is invertible, and solving \eqref{eq:eig1} gives     $$g_i = -(P-\lambda_i^DI_{d-p})^{-1}qh_i.$$     Substituting in \eqref{eq:eig2} yields         $$ah_i-q^\top(P-\lambda_i^DI_{d-p})^{-1}qh_i=\lambda_i^Dh_i.$$     Let us denote by $\tilde{h}_i=\frac{h_i}{\norm{2}{h_i}}$ the unit norm eigenvector of $a - q^\top(P-\lambda_i^DI_{d-p})^{-1}q$ corresponding to the eigenvalue $\lambda_i^D$, and also define $\tilde{g}_i := -(P-\lambda_i^DI_{d-p})^{-1}q\tilde{h}_i$. Then, $\tilde{h}_i$ and $\tilde{g}_i$ satisfy equations \eqref{eq:eig1} and \eqref{eq:eig2}, so $\tilde{v}_i^D = \matrix{\tilde{h}_i\\ \tilde{g}_i}$ is aligned with an eigenvector corresponding to eigenvalue $\lambda_i^D$. However, $\tilde{v}_i^D$  does not necessarily have unit norm. It holds that     $$\matrix{h_i\\ g_i} = v_i^D = \frac{\tilde{v}_i^D}{\norm{2}{\tilde{v}_i^D}} = \frac{\matrix{\tilde{h}_i\\ \tilde{g}_i}}{\sqrt{\tilde{h}_i^\top\tilde{h}_i+\tilde{g}_i^\top\tilde{g}_i}}=\frac{\matrix{\tilde{h}_i\\ \tilde{g}_i}}{\sqrt{1+\tilde{h}_i^\top q^\top(P-\lambda_i^DI_{d-p})^{-2}q\tilde{h}_i}},$$ from which follows that     $$h_i = \frac{\tilde{h}_i}{\sqrt{1+\tilde{h}_i^\top q^\top(P-\lambda_i^DI_{d-p})^{-2}q\tilde{h}_i}}.$$     The last thing to notice is that     $$q^\top(P-\lambda I_{d-p})^{-2}q = -\frac{d}{d\lambda}(a-q^\top(P-\lambda I_{d-p})^{-1}q),$$     from which the statement of the proposition follows.",2502.01583
proof,"Let us denote by $v\coloneqq ZS$.     An arbitrary eigenvalue $\lambda_k^M$ of $M_n$ satisfies the equation     $$\det\paren{Z-\frac{1}{n}v(a-\mu I_p)^{-1}v^\top-\lambda_k^M I_n}=0.$$     Thus, for $\alpha>\max\{z_i\}$, consider the following equation     $$\det\paren{Z-\frac{1}{n}v(a-\mu I_p)^{-1}v^\top-\alpha I_n}=0.$$     As $Z-\alpha I_n$ is invertible for $\alpha>\max\{z_i\}$, we can apply the matrix determinant lemma to obtain the equivalent equation               \det\paren{\mu I_p-a+\frac{1}{n}v^\top(Z-\alpha I_n)^{-1}v}=0.          Moreover,     $$ a - \frac{1}{n}v^\top(Z-\alpha I_n)^{-1}v = \frac{1}{n}\sum_{i=1}^n z_i s_i s_i^\top - \frac{1}{n}\sum_{i=1}^n \frac{z_i^2s_is_i^\top}{z_i-\alpha} = \frac{1}{n}\sum_{i=1}^n \frac{\alpha z_is_is_i^\top}{\alpha-z_i}.$$     Thus, \eqref{eq:matdetlemmu} becomes               \det\paren{\mu I_p -  \frac{1}{n}\sum_{i=1}^n \frac{\alpha z_is_is_i^\top}{\alpha-z_i}}=0.          Let us prove that, for $n$ large enough, this equation indeed has its top $j$ solutions for $\alpha>\max\{z_i\}$.     First, note that     $$\det\paren{\mu I_p -  \frac{1}{n}\sum_{i=1}^n \frac{\alpha z_is_is_i^\top}{\alpha-z_i}}=\prod_{i=1}^p\paren{\mu-\lambda_i(\alpha)},$$     where through abuse of notation we define $\lambda_i(\alpha):]\max\{z_i\},+\infty[\to \bbR$ as $ \lambda_i\paren{\frac{1}{n}\sum_{i=1}^n \frac{\alpha z_is_is_i^\top}{\alpha-z_i}}$. Each function $\lambda_i$ is continuous and strictly decreasing. This can be seen by taking arbitrary $\alpha_2>\alpha_1$ to get     $$\lambda_i(\alpha_1)-\lambda_i(\alpha_2)\geq \lambda_p\paren{(\alpha_2-\alpha_1)\frac{1}{n}\sum_{i=1}^n \frac{z_i^2s_is_i^\top}{(\alpha_1-z_i)(\alpha_2-z_i)}}>0,$$     by using Weyl's inequality and the fact that there are almost surely at least $p$ linearly independent vectors $z_is_i$ by \Cref{lemma:fr}.      Consequently, to prove that \eqref{eq:prodeigenval} has $j$ solutions for $\alpha>\max\{z_i\}$, it equivalent to prove that, for each $i$,               \lambda_i(\beta_i')>\mu>\lambda_i(\beta_i''),          for some $\beta_i''>\beta_i'>\max{z_i}$.           Note that, for any fixed $\alpha$, it holds that              \frac{1}{n}\sum_{i=1}^n \frac{\alpha z_is_is_i^\top}{\alpha-z_i}\asconv \expt{\frac{\alpha zss^\top}{\alpha-z}} = \Rinfty(\alpha),          due to the law of large numbers. Due to the continuity of eigenvalues, it further follows that      $$\lambda_i\paren{\frac{1}{n}\sum_{i=1}^n \frac{\alpha z_is_is_i^\top}{\alpha-z_i}}\asconv \lambda_i\paren{\expt{\frac{\alpha zss^\top}{\alpha-z}}}=\lambda_i^\infty(\alpha),$$     where $\lambda_i^\infty(\alpha)$ is continuous and strictly decreasing. This can be seen as, for any $\alpha>\tau$ and any arbitrary vector $x\in \bbR^p$, it holds that              \frac{d}{d\alpha}\paren{x^\top\paren{\expt{\frac{\alpha zss^\top}{\alpha-z}}}x} = -\expt{\frac{\inprod{x}{s}^2z^2}{(\alpha-z)^2}}<0,          since $\prob{z=0}<1$.      Moreover, for $i\in[p]$,     $$\lim_{\alpha\to\infty}\lambda_i^\infty(\alpha) = \lambda_i^{a^\infty},$$     where the matrix $a^\infty = \expt{zss^\top}$ is the limit of the matrix $a$.     The condition of the lemma states that there exist $\alpha_1\geq \dots\ \geq \alpha_j > \tau$ such that     $$\det\paren{\mu I_p-R^\infty(\alpha)}=0.$$     Let us denote by $k\in\{0,\dots, p\}$ the index such that $\lambda_{k+1}^{a^\infty}\leq\mu<\lambda_k^{a^\infty}$, with the abuse of notation $\lambda_0^{a^\infty}\coloneq +\infty$ and $\lambda_{p+1}^{a^\infty}\coloneq -\infty$.      By assumption %it holds               \det\paren{\mu I_p-R^\infty(\alpha)}=\prod_{i=0}^p(\mu-\lambda_i^\infty(\alpha)),          has $j$ solutions in $\alpha \in ]\tau,+\infty[$. Note that $\lambda_i^\infty$ is a strictly decreasing continuous function, so the only way that $\lambda_i^\infty-\mu$ does not have a solution in $\alpha\in]\tau,+\infty[$ is if either     $\lim_{\alpha\to\tau^+} \lambda_i^\infty(\alpha)<\mu$ or $\lim_{\alpha\to\infty} \lambda_i^\infty(\alpha)>\mu.$     Moreover, since $\lim_{\alpha\to\infty} \lambda_i^\infty(\alpha) = \lambda_i^{a^\infty}$, it will exactly hold for $i\in\{1,\dots k\}$ that               \lim_{\alpha\to\infty} \lambda_i^\infty(\alpha)\geq\lambda_k^{a^\infty}>\mu.          The fact that there are only $j$ solutions to \eqref{eq:deteq} and $\lambda_i^\infty(\alpha)>\lambda_{i+1}^\infty(\alpha)$ implies that      $$\lambda_{i+k}^\infty(\alpha_i) = \mu,$$     for $i\in [j]$,     as well as              \lim_{\alpha\to\infty} \lambda_i^\infty(\alpha)<\mu,          for $i\in\{j+k+1,\dots,p\}$.          As each $\lambda_i^\infty$ is a strictly decreasing continuous function, this further implies that there exists some constant $\epsilon>0$ and $\alpha_1',\dots, \alpha_j'>\tau$ such that      $$\lambda_{i+k}^\infty(\alpha_i') = \mu+\epsilon.$$     Applying the convergence of \eqref{eq:eigenvalconvergence} it further holds that      $$\lambda_{i+k}\paren{\frac{1}{n}\sum_{i=1}^n \frac{\alpha_i' z_is_is_i^\top}{\alpha_i'-z_i}} \asconv \lambda_{i+k}^\infty(\alpha_i')=\mu+\epsilon.$$     Thus, for each $i$ and $\epsilon>\epsilon_1>0$, there exists $n_0$ s.t.\ for $n>n_0$      $$\abs{\lambda_{i+k}\paren{\frac{1}{n}\sum_{i=1}^n \frac{\alpha_i' z_is_is_i^\top}{\alpha_i'-z_i}} - (\mu+\epsilon)}< \epsilon_1.$$     Developing the absolute value, it holds that      $$ \lambda_{i+k}\paren{\frac{1}{n}\sum_{i=1}^n \frac{\alpha_i' z_is_is_i^\top}{\alpha_i'-z_i}} > \mu+\epsilon-\epsilon_1>\mu,$$     e.g.\ by taking $\epsilon_1=\epsilon/2$.     As $\lambda_{i+k}(\alpha) = \lambda_{i+k}\paren{\frac{1}{n}\sum_{i=1}^n \frac{\alpha z_is_is_i^\top}{\alpha-z_i}}$ is a continuous decreasing function, starting from some $n_0$ there exists $\beta_i'>\tau$ s.t.\ $\lambda_{i+k}(\beta_i') > \mu$. Notice that by definition $\tau>\max{z_i}$ almost surely. In the same way as for $\beta_i'$ it can be proved that there exists $\beta_i''>\tau$ such that $\lambda_{i+k}(\beta_i'') < \mu$.          Thus, we conclude that, for large enough $n$,  $\lambda_{i+k}(\alpha)=\mu$ has $j$ solutions larger than $\max\{z_i\}$.     These are indeed $\lambda_i^M$ for $1\leq i\leq j$. Due to monotonicity, each $\lambda_i$ admits a functional inverse and it holds that      $$\lambda_i^M = \lambda_{i+k}^{-1}(\mu).$$     As $\lambda_{i+k} \asconv \lambda_{i+k}^\infty$, applying \cite[Lemma A.1]{lu2020phase} implies that              \lambda_i^M \asconv (\lambda_{i+k}^\infty)^{-1}(\mu),          for $1\leq i\leq j$, which is exactly the statement \eqref{conv:jeigconv} of the lemma.      Let us now prove the second part of the statement. To do so, we prove that, for large enough $n$, \eqref{eq:prodeigenval} has no more than $j$ solution for $\alpha>\max\{z_i\}$.      As stated in \eqref{eq:larberthanmu} and \eqref{eq:smallerthanmu}, it holds that $ \lim_{\alpha\to\infty}\lambda_i^\infty(\alpha)>\mu$ for $i$ s.t.\ $1\leq i\leq k$ and that $\lim_{\alpha\to\tau^+}\lambda_i^\infty(\alpha)<\mu$ for $i$ s.t.\ $j+1+k\leq i\leq p$. Thus, using the same argument as before, we also have that, for large enough $n$ and any $\alpha>\tau$, $\lambda_i(\alpha)>\mu$ for $i$ s.t.\ $1\leq i\leq k$ and $\lambda_i(\alpha)<\mu$ for $i$ s.t.\ $j+1+k\leq i\leq p$. Since  %    %        \lambda_i(\alpha)>\mu, \text{ or respectively } \lambda_i(\alpha)<\mu %     %    for any $\alpha>\tau$, and $1\leq i\leq k$, or respectively $j+1+k\leq i\leq p$.  %    Note that      $\max\{z_i\}\asconv \tau$ (see e.g.\ \cite[Section 4]{silverstein1995analysis}), such inequalities also hold for $\alpha>\max\{z_i\}$ (and $n$ large enough).     Hence, there cannot exist $\beta_i'$ and $\beta_i''$ that satisfy \eqref{eq:betas}, so \eqref{eq:prodeigenval} cannot have more than $j$ solutions in $\alpha> \max\{z_i\}$.           From this, it directly follows that, for $n$ large enough and any $l\in\{j+1\dots p\}$,       $$\lambda_l^M\leq \max\{z_i\},$$     almost surely. Furthermore, from the interlacing theorem, it holds that      $$\lambda_{p+1}^Z\leq\lambda_l^M,$$     for any $l\in\{j+1\dots p\}$. Thus, the $\lambda_l^M$'s are sandwiched between the first and the $p$-th eigenvalue of $Z$, both of which converge to the right edge of the bulk $\tau$ \cite[Section 4]{silverstein1995analysis}, which gives the desired result.",2502.01583
proof,"Let $k$ be such that $\lambda_{k+1}^{a^\infty}\leq\mu<\lambda_k^{a^\infty}$, with the abuse of notation $\lambda_0^{a^\infty}\coloneq +\infty$. Then, by the definition of $\tildeLi$ in \eqref{eq:defLtilde}, it holds that              \tildeLi(\mu) = L_{i-k}(\mu),          for $n$ large enough. This is true since $\lambda_i^a\asconv  \lambda_i^{a^\infty}$, as $a\asconv a^\infty$.          To obtain the convergence of the RHS in \eqref{eq:Likconv}, we rely on the results from \cite{bai-yao-2012}.     Towards this end, we recall the definition of $L_{i-k}(\mu) = \lambda_{i-k}(P-q(a-\mu I_p)^{-1}q^\top)$ as in \eqref{eq:defLi}. Given the equality in \eqref{eq:defM}, %it holds %    $$P-q(a-\mu I_p)^{-1}q^\top = \frac{1}{n} U^\top M U,$$ %    and      we turn our attention to the eigenvalues of $M_n$. Recall that the functions $\lambda^\infty_i(\alpha)$ are strictly decreasing with limits     $$\lim_{\alpha\to\tau^+} \lambda^\infty_i(\alpha) = t_i^\infty, \text{ and } \lim_{\alpha\to+\infty} \lambda^\infty_i(\alpha) = \lambda_i^{a^\infty}.$$     Then, as $\mu\in]\lambda_i^{a^\infty}, t_i^\infty[$, the equation     $$\lambda^\infty_i(\alpha)=\mu$$     has a unique solution in $\alpha>\tau$. Let us denote that solution by $\alpha_{i-k}$. Due to the fact that      $$\lambda_{i}^{a^\infty}\dots\leq\lambda_{k+1}^{a^\infty}\leq\mu<\lambda_k^{a^\infty} \text{ and } \mu < t_i^\infty\dots<t_{1}^\infty,$$ using the same argument as in the proof of \Cref{lemma:mueigvalconv} below \eqref{eq:deteq}, we conclude that there are unique solutions $\alpha_1,\dots,\alpha_{i-k}$ s.t.\ $\lambda_{j+k}(\alpha_j)=\mu$ for $j\in[i-k]$. Then, it holds that $\alpha_1, \dots,  \alpha_{i-k}$ satisfy the conditions of \Cref{lemma:mueigvalconv}. From its proof, specifically \eqref{eq:klimit}, it follows that     $$\lambda_{i-k}^M\asconv {\lambda_{i}^\infty}^{-1}(\mu) = \alpha_{i-k}.$$     Furthermore, the empirical spectral distribution of $M_n$ converges almost surely to the distribution of $z$.     This claim follows from Cauchy's interlacing theorem, using the same argument as in the proof of \cite[Proposition 3.2]{lu2020phase}. Assuming that the preprocessing function $\cT$ is positive, we can apply \cite[Theorems 4.1 and 4.2]{bai-yao-2012} to get     $$L_{i-k}(\mu)\asconv\zeta_\delta\paren{(\lambda^\infty_i)^{-1}(\mu)},$$     following the steps in \cite[Proposition 3.3]{lu2020phase}. Finally, the adjustment in  \cite[Lemma 3]{mondelli-montanari-2018-fundamental} covers the case in which the preprocessing function is not necessarily positive, and the proof of \Cref{eq:p1} is complete.   Let us now consider  $\mu\in]t_i^\infty,+\infty[$ and prove \Cref{eq:p2}.      Note that, in this interval of $\mu$, the equation     $$\lambda^\infty_i(\alpha)=\mu$$     has no solutions in $\alpha>\tau$. Let us examine the equation \eqref{eq:mueigvalmaster_eq} in \Cref{lemma:mueigvalconv}:     $$\det\paren{\mu I_p-R^\infty(\alpha)}=\prod_{l=1}^p(\mu-\lambda_l^\infty(\alpha))=0.$$     The previous equation has a solution $\mu-\lambda_l^\infty(\alpha)=0$, as long as              \lambda_l^{a^\infty}<\mu<t_l^\infty,          due to the monotonicity of each $\lambda_l^\infty(\alpha)$.     As      $$\lambda_{i}^{a^\infty}\dots\leq\lambda_{k+1}^{a^\infty}\leq\mu<\lambda_k^{a^\infty} \text{ and } \mu>  t_i^\infty\dots\geq t_{p}^\infty,$$      it follows that \eqref{eq:intervalinequal}, thus also \eqref{eq:mueigvalmaster_eq}, can have at most $i-(k+1)$ solutions. Thus, applying \Cref{lemma:mueigvalconv} it follows that      $$\lambda_{i-k}^M\asconv \tau.$$     As the empirical spectral distribution of $M_n$ converges almost surely to the distribution of $z$, we conclude that      $$\tildeLi(\mu) = L_{i-k}(\mu)\asconv \zetadelta(\lambdabardelta),$$     as the limit of the right edge of the bulk distribution  by      \cite[Lemma 3.1]{bai-yao-2012}.",2502.01583
proof,"As stated in the proof of \Cref{thm:eigvalconv}, it holds that              \det\paren{\zetadelta(\alpha)I-R^\infty(\alpha)}= \prod_{i=1}^p (\zetadelta(\alpha) - \lambda_i^\infty(\alpha)).          Note that the function $\zetadelta(\alpha) - \lambda_i^\infty(\alpha)$ is continous and strictly increasing for $\alpha\in]\tau,+\infty[$, so that      $$\lim_{\alpha\to\infty}\zetadelta(\alpha) - \lambda_i^\infty(\alpha) = +\infty.$$     Thus, the equation in \Cref{eq:master_eq2} has at most $p$ solutions. Furthermore, the assumption in \Cref{assmp:psol} implies that      $$\inf_{\norm{2}{x}=1}\lim_{\alpha\to\tau^+}x^\top R^\infty(\alpha)x = +\infty,$$     which is equivalent to     $$\lim_{\alpha\to\tau^+}\lambda_i^\infty(\alpha) = +\infty.$$     As $\lim_{\alpha\to\tau^+}\zetadelta(\alpha) = \lambdabardelta<+\infty$, it then holds that     $$\lim_{\alpha\to\tau^+}\zetadelta(\alpha) - \lambda_i^\infty(\alpha) = -\infty,$$     proving there must be exactly $p$ solutions to \Cref{eq:master_eq2} due to the intermediate  value theorem.",2502.01583
proof,"Let $v_k^D\coloneqq\matrix{h_k\\ g_k}$. Since $\alpha_k>\lambdabardelta$, the conditions of \Cref{prop:eigenvec} are satisfied as in the proof of \Cref{thm:matrixRconvergence}. Thus, it holds that     $$h_k = \frac{\tilde{h}_k}{\sqrt{1+\tilde{h}_k^\top\frac{d}{d\lambda}R(\lambda_k^D)\tilde{h}_k}},$$     where $\tilde{h}_k$ is the unit norm eigenvector of $R(\lambda_k^D)$. Furthermore, \Cref{thm:matrixRconvergence} gives that     $$R(\lambda_k^D)\asconv R^\infty(\alpha_k), \qquad \frac{d}{d\lambda}R(\lambda_k^D) \asconv \frac{1}{\zetadelta'(\alpha_k)}\frac{d}{d\alpha}R^\infty(\alpha_k).$$     Then, applying the results from \cite[II.1.4]{kato2013perturbation}, %(as proved in this StackExchange \href{https://math.stackexchange.com/questions/4054792/convergence-of-eigenvalues-and-spaces-of-sequence-of-compact-szmmetric-and-posi}{answer}).     it holds that the orthonormal projection to the eigenspace corresponding to the $k$-th eigenvalue also converges, that is      $$\Pi_{h_k} \asconv \Pi_{h^\infty_k},$$     where $\Pi_{h_k} = \frac{h_kh_k^\top}{\norm{2}{h_k}^2} = \tilde{h}_k\tilde{h}_k^\top$ and $\Pi_{h^\infty_k} = \frac{h^\infty_k{h^\infty_k}^\top}{\norm{2}{h^\infty_k}^2}=h^\infty_k{h^\infty_k}^\top$. As a consequence, it holds that     $$\norm{2}{h_k}=\frac{1}{\sqrt{1+\tilde{h}_k^\top\frac{d}{d\lambda}R(\lambda_k^D)\tilde{h}_k}}\asconv \frac{\sqrt{\zetadelta'(\alpha_k)}}{\sqrt{\zetadelta'(\alpha_k)+{h^\infty_k}^\top\frac{d}{d\lambda}R^\infty(\alpha_k)h^\infty_k}}.$$     Combining these results we obtain that     $$h_kh_k^\top\asconv \frac{\zetadelta'(\alpha_k)h^\infty_k {h^\infty_k}^\top}{\zetadelta'(\alpha_k)+{h^\infty_k}^\top\frac{d}{d\lambda}R^\infty(\alpha_k)h^\infty_k},$$     which proves the claim as              \abs{\inprod{v_k^D}{e_j^{(d)}}}^2 &= (e_j^{(p)})^\top h_kh_k^\top (e_j^{(p)}). \notag \qedhere",2502.01583
proof,"Let us denote by $w_i$ the $i$-th column of the matrix $\wt{W}^*$ as in \eqref{eqn:W*}, representing the top-$p$ entries of the reparametrized signal.     Without loss of generality, we can assume that $q$ is permutation invariant in the first $m$ coordinates, i.e.,     $$q(t_1,\dots, t_m,t_{m+1}\dots,t_p,\epsilon) = q(t_{\pi(1)},\dots, t_{\pi(m)},t_{m+1}\dots,t_p,\epsilon),$$ for any permutation $\pi:[m]\to[m]$.     Let $E$ be the span of $\{w_i-w_{i+1}\,:\, i\in[m-1]\}$. Note that $E$ has dimension $m-1$, due to the linear independence of the signals $w_i$. We will prove that $E$ is a direct sum of eigenspaces of $R^\infty(\alpha)$, neither of which depends on $\alpha$.          Let us define $u_i$ as the image of $w_i-w_{i+1}$ under $R^\infty(\alpha)$, that is              u_i \coloneq R^\infty(\alpha)(w_i-w_{i+1}) = \alpha \expt{ \frac{s \inprod{s}{w_i-w_{i+1}}\cT(y)}{\alpha -\cT(y)}},          for $i\in[m-1]$. Let us denote by $x_i$ the component of $u_i$ that is orthogonal to $w_i$ and $w_{i+1}$, i.e., $x_i \coloneq \Pi_{\{w_i,w_{i+1}\}^\perp}u_i$. Then, it holds that              u_i=a_1 w_i+ a_2 w_{i+1} + x_i,          for some coefficients $a_1$ and $a_2$. We will first prove that $x_i=0$. Towards that end, let $\cS_i:\bbR^p\to \bbR^p$ be an isometric reflection that sends $w_i$ to $w_{i+1}$, $w_{i+1}$ to $w_i$, and keeps $w_j$ fixed for $j\notin \{i,i+1\}$. Such a reflection exists due to the assumed linear independence of the $w_i$'s. Notice that the normal distribution in $\bbR^p$ is invariant to the transformation $\cS_i$. Thus, it follows that              \inprod{u_i}{x_i} &=\alpha \expt{ \frac{\inprod{s}{x_i} \inprod{s}{w_i-w_{i+1}}\cT(y)}{\alpha -\cT(y)}}\\         &=\alpha \expt{ \frac{\inprod{s}{x_i} \inprod{s}{w_i}\cT(y)}{\alpha -\cT(y)}} - \alpha \expt{ \frac{\inprod{s}{x_i} \inprod{s}{w_{i+1}}\cT(y)}{\alpha -\cT(y)}}\\         &=\alpha \expt{ \frac{\inprod{\cS_i s}{x_i} \inprod{\cS_i s}{w_i}\cT(q((\wt{W}^*)^\top \cS_i s, \eps))}{\alpha -\cT(q((\wt{W}^*)^\top \cS_i s, \eps))}} - \alpha \expt{ \frac{\inprod{s}{x_i} \inprod{s}{w_{i+1}}\cT(y)}{\alpha -\cT(y)}}\\         &=\alpha \expt{ \frac{\inprod{s}{x_i} \inprod{s}{w_{i+1}}\cT(q((\wt{W}^*)^\top s, \eps))}{\alpha -\cT(q((\wt{W}^*)^\top s, \eps))}} - \alpha \expt{ \frac{\inprod{s}{x_i} \inprod{s}{w_{i+1}}\cT(y)}{\alpha -\cT(y)}}\\         &= 0,          due to the permutation invariance of $q$, the fact that $\cS_i x_i = x_i$ and $\cS_i w_i = w_{i+1}$. Therefore, it must be that $x_i=0$.         Moreover,            \inprod{u_i}{w_i}&=\alpha \expt{ \frac{\inprod{s}{w_i} \inprod{s}{w_i-w_{i+1}}\cT(y)}{\alpha -\cT(y)}}\\        &=\alpha \expt{ \frac{\inprod{\cS_i s}{w_i} \inprod{\cS_i s}{w_i-w_{i+1}}\cT(q((\wt{W}^*)^\top \cS_i s)}{\alpha -\cT(q((\wt{W}^*)^\top \cS_i s)}}\\        &=\alpha \expt{ \frac{\inprod{s}{w_{i+1}} \inprod{s}{w_{i+1}-w_i}\cT(q((\wt{W}^*)^\top  s)}{\alpha -\cT(q((\wt{W}^*)^\top s)}}\\        &= \alpha \expt{ \frac{\inprod{s}{w_{i+1}} \inprod{s}{w_{i+1}-w_i}\cT(y)}{\alpha -\cT(y)}} \\        &= -\inprod{u_i}{w_{i+1}}.         Combining this with the decomposition in \eqref{eq:uidecomp} implies that     $a_1+a_2\inprod{w_i}{w_{i+1}} = -a_1\inprod{w_{i+1}}{w_i} - a_2.$     As by assumption the signals $w_i$ and $w_{i+1}$ are linearly independent, it cannot be that $\inprod{w_i}{w_{i+1}}=-1$, so it must be that $a_1=-a_2$. This proves that $w_i-w_{i+1}$ are indeed eigenvectors for every $\alpha$.      By definition, it holds that     $$E=\bigoplus_{i=1}^{m-1}\operatorname{span}\{u_i\}.$$     Thus, it is left to prove that any pair of eigenvectors $u_i$ and $u_j$, for $i,j\in[m-1]$, either have the same eigenvalue for all $\alpha$, or for no $\alpha$. We denote by $\lambda_{u_i}(\alpha)$ the eigenvalue that corresponds to the eigenvector $u_i$. Similar to before, let $\cS^{(i)}:\bbR^p\to \bbR^p$ be an isometric reflection that sends $w_i$ to $w_{i+2}$, $w_{i+2}$ to $w_i$, and keeps $w_j$ fixed for $j\notin \{i,i+2\}$. Such a reflection exists due to the assumed linear independence of the $w_i$'s. Also, the normal distribution is invariant to the transformation $\cS^{(i)}$. Then, it follows that              \lambda_{u_i}(\alpha)\cdot \norm{2}{w_i-w_{i+1}}^2 = \inprod{u_i}{w_i-w_{i+1}}&= \alpha \expt{ \frac{\inprod{s}{w_i-w_{i+1}}^2\cT(y)}{\alpha -\cT(y)}}\\                       &= \alpha \expt{ \frac{\inprod{\cS^{(i)} s}{w_i-w_{i+1}}^2\cT(q((\wt{W}^*)^\top \cS^{(i)} s, \eps))}{\alpha -\cT(q((\wt{W}^*)^\top \cS^{(i)} s, \eps))}}\\                       &= \alpha \expt{ \frac{\inprod{ s}{w_{i+2}-w_{i+1}}^2\cT(q((\wt{W}^*)^\top s, \eps))}{\alpha -\cT(q((\wt{W}^*)^\top s, \eps))}}\\                       &=\inprod{u_{i+1}}{w_{i+1}-w_{i+2}} = \lambda_{u_{i+1}}(\alpha)\cdot \norm{2}{w_{i+2}-w_{i+1}}^2.          This proves that $\lambda_{u_i}(\alpha)/\lambda_{u_{i+1}}(\alpha)$ does not depend on $\alpha$ and, hence, $\lambda_{u_i}(\alpha)/\lambda_{u_{j}}(\alpha)$ does not depend on $\alpha$ for all $i,j\in[m-1]$, implying  the existence of an eigenspace of dimension $m-1$ that does not change with $\alpha$.",2502.01583
proof,"%\paragraph{Proof of \Cref{thm:opt}} %We want to find a preprocessing function $\cT$ for a given $\delta$ satisfying \Cref{asmp:proportional}, such that the spectral estimator $\wh{W}^{\mathrm{s}} = \matrix{ v_1^D, & \cdots, & v_p^D } $  weakly recover the signals, as in the \Cref{def:weak_rec}. It is not too hard to see, that for the signals of the form in \eqref{eqn:W*}, %this is equivalent to finding a $\cT$ such that % %        \max_{j\in[p]} \brace{ \liminf_{d\to\infty} \sum_{i=1}^p \abs{\inprod{v_i^D}{e_j}}^2 } &> 0 .  % %As a consequence of \Cref{thm:main}, it would be sufficient to prove that there exists a solution $\alpha$ to the equation \eqref{eq:master_eq2} such that $\alpha>\lambdabardelta$. Note that $\zetadelta(\alpha)$ is a strictly monotone function for $\alpha>\lambdabardelta$, and it is constant for $\alpha\leq \lambdabardelta$. Thus, the existence of $\alpha$ solving \Cref{eq:master_eq2} s.t.\ $\alpha>\lambdabardelta$ is equivalent to $\zetadelta'(\alpha_1)>0$, where $\alpha_1$ is the largest solution of \eqref{eq:master_eq2}. Thus, $\alpha_1$ is the largest solution to  $$\det\paren{\zetadelta(\alpha)I_p-R^\infty(\alpha)}=0,$$  or equivalently  $$\lambda_1 (R^\infty(\alpha)) = \zetadelta(\alpha).$$  This means that, for \eqref{eq:master_eq2} to have solutions larger than $\lambdabardelta$, there has to exist $\alpha_1>\tau$ such that        \max_{\norm{2}{u}=1} u^\top R^\infty(\alpha_1)u &= \zetadelta(\alpha_1),\\      \zetadelta'(\alpha_1) &>0,   or equivalently        \max_{\norm{2}{u}=1} u^\top R^\infty(\lambdabardelta)u &> \zetadelta(\lambdabardelta).    This follows from the fact that $\zetadelta(\alpha)$ is strictly increasing for $\alpha>\lambdabardelta$, and $u^\top R^\infty(\alpha)u$ is strictly decreasing, as proved in \eqref{eq:matrixRdecreases}.  Recall that $\lambdabardelta$ is defined as the unique point that satisfies $ \psidelta'(\lambdabardelta) =0$. This is equivalent to        \expt{\frac{z^2}{(\lambdabardelta-z)^2}}=\frac{1}{\delta}.    By definition, it holds that $$R^\infty(\lambdabardelta) = \expt{\frac{\lambdabardelta z}{\lambdabardelta-z}s^\top s }.$$ Therefore, the condition in \eqref{eq:conditionlambdabar} becomes       \max_{\norm{2}{u}=1} \expt{\frac{\lambdabardelta z}{\lambdabardelta-z}\inprod{s}{u}^2 } > \lambdabardelta\paren{\frac{1}{\delta}+\expt{\frac{z}{\lambdabardelta-z}}}.  Note that $D_n$ and $D_n'\coloneqq D_n/\beta$ have the same principal eigenvector for an arbitrary scalar $\beta>0$ so, without loss of generality, we can take $\lambdabardelta=1$. This transforms \eqref{eq:conditioninequality} and \eqref{eq:lambdabardef} into       \max_{\norm{2}{u}=1} \expt{\frac{z(\inprod{s}{u}^2-1)}{1-z}} &> \frac{1}{\delta},\\     \expt{\frac{z^2}{(1-z)^2}}&=\frac{1}{\delta}.   We turn our attention to finding the critical threshold $\delta_c$ such that no preprocessing function $\cT$ exists which would satisfy these equations. To start, plugging in the definition of the expectation we get        \max_{\norm{2}{u}=1}  \int_{\bbR}\frac{\cT(y)}{1-\cT(y)} \expt[s]{p(y \mathrel{\vert} s)\cdot(\inprod{s}{u}^2-1)} dy &> \frac{1}{\delta},\\     \int_{\bbR}\paren{\frac{\cT(y)}{1-\cT(y)}}^2 \expt[s]{p(y \mathrel{\vert} s)} dy &=\frac{1}{\delta}.   Let us denote by $f(y)\coloneqq \frac{\cT(y)}{1-\cT(y)}$. Note that %it holds that      \frac{1}{\delta}&<\max_{\norm{2}{u}=1}\int_{\bbR}f(y) \expt[s]{p(y \mathrel{\vert} s)\cdot(\inprod{s}{u}^2-1)} dy \nonumber\\     &= \max_{\norm{2}{u}=1}     \int_{\bbR}f(y) \sqrt{\expt[s]{p(y \mathrel{\vert} s)}} \frac{\expt[s]{p(y \mathrel{\vert} s)\cdot(\inprod{s}{u}^2-1)}}{\sqrt{\expt[s]{p(y \mathrel{\vert} s)}}}dy \nonumber\\     &\leq \max_{\norm{2}{u}=1}\sqrt{\int_{\bbR} f^2(y) \expt[s]{p(y \mathrel{\vert} s)}dy}\sqrt{\int_{\bbR}\frac{\paren{\expt[s]{p(y \mathrel{\vert} s)\cdot(\inprod{s}{u}^2-1)}}^2}{\expt[s]{p(y \mathrel{\vert} s)}}dy}\\     &= \max_{\norm{2}{u}=1} \frac{1}{\sqrt{\delta}} \sqrt{\int_{\bbR}\frac{\paren{\expt[s]{p(y \mathrel{\vert} s)\cdot(\inprod{s}{u}^2-1)}}^2}{\expt[s]{p(y \mathrel{\vert} s)}}dy},\nonumber  where the third line follows from H\""older's inequality and the fourth line from the second condition in \eqref{eq:condrew}. This means that, regardless of which preprocessing function $\cT$ was chosen, if it satisfies \eqref{eq:condrew}, then it must hold that  $$ \frac{1}{\delta} < \max_{\norm{2}{u}=1}\int_{\bbR}\frac{\paren{\expt[s]{p(y \mathrel{\vert} s)\cdot(\inprod{s}{u}^2-1)}}^2}{\expt[s]{p(y \mathrel{\vert} s)}}dy =:\frac{1}{\delta_t}.$$ In other words, for any $\delta\leq \delta_t$, the set $\sT_\delta=\emptyset$. By the definition of $\delta_c$ in \eqref{eq:deltacdef}, it follows that      \delta_c \geq \delta_t.  Now, let us prove that, for any $\delta>\delta_t$, there exists a preprocessing function such that  $\sT_\delta\neq\emptyset$. Towards this end, we turn our attention to when equality holds in \eqref{ineq:Hoelders}, as this gives us the preprocessing function that exactly matches the upper bound. Namely, this is true if and only if almost everywhere $$ f^2(y) \expt[s]{p(y \mathrel{\vert} s)} = c\cdot\frac{\paren{\expt[s]{p(y \mathrel{\vert} s)\cdot(\inprod{s}{u_c}^2-1)}}^2}{\paren{\expt[s]{p(y \mathrel{\vert} s)}}^2},$$  where $u_c=\argmax_{\tilde u}\int_{\bbR}\frac{\paren{\expt[s]{p(y \mathrel{\vert} s)\cdot(\inprod{s}{\tilde u}^2-1)}}^2}{\expt[s]{p(y \mathrel{\vert} s)}}dy$ and $c$ is some constant. Thus, we have that $$ f(y) = \sqrt{c}\frac{\expt[s]{p(y \mathrel{\vert} s)\cdot(\inprod{s}{u_c}^2-1)}}{\expt[s]{p(y \mathrel{\vert} s)}},$$ which in turn gives the choice      \bar\cT:= \frac{\sqrt{c}  \taustar}{1-(1-\sqrt{c})  \taustar},  with $$\taustar(y) = 1 - \frac{\expt[s]{p(y \mathrel{\vert} s)}}{\expt[s]{p(y \mathrel{\vert} s)\cdot\inprod{s}{u_c}^2}}.$$ The second condition in \eqref{eq:condrew} determines $c$. Namely,      \frac{1}{\delta} = \int_{\bbR}\paren{\frac{\bar\cT(y)}{1-\bar\cT(y)}}^2 \expt[s]{p(y \mathrel{\vert} s)}dy = \int_{\bbR} c\cdot\frac{\paren{\expt[s]{p(y \mathrel{\vert} s)\cdot(\inprod{s}{u_c}^2-1)}}^2}{\expt[s]{p(y \mathrel{\vert} s)}} dy = c \frac{1}{\delta_t}.  Therefore,  $c = \frac{\delta_t}{\delta}$.  \eqref{eq:deltadletat} immediately proves that the second condition in \eqref{eq:condrew} is satisfied for $\bar\cT$. The first condition in \eqref{eq:condrew} is also satisfied since      \max_{\norm{2}{u}=1}  \int_{\bbR}\frac{\bar\cT}{1-\bar\cT} \expt[s]{p(y \mathrel{\vert} s)\cdot(\inprod{s}{u}^2-1)} dy & \ge \sqrt{c} \cdot \int_{\bbR}\frac{\paren{\expt[s]{p(y \mathrel{\vert} s)\cdot(\inprod{s}{u_c}^2-1)}}^2}{\expt[s]{p(y \mathrel{\vert} s)}}dy\\     &= \sqrt{\frac{\delta_t}{\delta}} \cdot \frac{1}{\delta_t}>\frac{1}{\delta}.  Thus, $\bar\cT\in\sT_\delta$ and $\sT_\delta\neq\emptyset$ for $\delta>\delta_t$. It follows that $$\delta_c\leq\delta_t,$$ which combined with \eqref{eq:ineqdelta} proves $\delta_c=\delta_t$. This also implies that the expression in \Cref{eq:taustardelta} coincides with  $\cT_\delta^*$ as defined in  \Cref{eq:opt}.  Lastly, we need to verify that $\taustardelta$ satisfies \Cref{asmp:T}. Let us first prove that $\taustardelta(y)$ is bounded. Since $\taustar(y)\leq 1$, it follows that $$\sqrt{\delta}-(\sqrt{\delta}-\sqrt{\delta_c})\cdot \taustar(y)\geq \sqrt{\delta_c},$$ and $$\cT_\delta^*(y) = \frac{\sqrt{\delta_c} \cdot \taustar(y)}{\sqrt{\delta}-(\sqrt{\delta}-\sqrt{\delta_c})\cdot \taustar(y)} \leq \frac{\sqrt{\delta_c}\taustar(y)}{\sqrt{\delta_c}}\leq 1.$$ Furthermore, for $\taustar(y)\neq 0$, we have $$\cT_\delta^*(y) = \frac{\sqrt{\delta_c}}{\frac{\sqrt{\delta}}{\taustar(y)}-(\sqrt{\delta}-\sqrt{\delta_c})},$$ and it holds that $\frac{\sqrt{\delta}}{\taustar(y)}-(\sqrt{\delta}-\sqrt{\delta_c})\in ]-\infty,-(\sqrt{\delta}-\sqrt{\delta_c})[\ \bigcup\ ]\sqrt{\delta_c},+\infty[.$ Thus, for $\taustar(y)\neq 0$,  $$\cT_\delta^*(y)\geq-\frac{\sqrt{\delta_c}}{\sqrt{\delta}-\sqrt{\delta_c}},$$ whereas $\taustardelta(y)=0$ for $\taustar(y)=0$. This proves that  $\taustardelta(y)$ is bounded.  Finally, by contradiction, suppose that $\prob{\taustardelta(y) = 0 }=1$. Note that $\taustardelta(y)=0$ if and only if $\taustar(y)=0$. This holds whenever    \prob{\expt[s]{p(y \mathrel{\vert} s)} = \expt[s]{p(y \mathrel{\vert} s)\cdot\inprod{s}{u_c}^2}}=1.      However, \Cref{eq:contr} implies that $$\prob{\expt[s]{p(y \mathrel{\vert} s)\cdot(\inprod{s}{u_c}^2-1)}=0}=1,$$ giving that $\delta_c=+\infty$, for which the statement of the theorem trivially holds. Consequently, $\prob{\taustar(y)=0}\neq 1$ and the proof is complete.",2502.01583
proposition,"For $i\in[p]$, the eigenvalue $\lambda_i^D$ is the unique solution to the equation               \tilde{L}_i(\mu) = \mu,            in the respective domain $]\lambda_i^a,\infty[$.",2502.01583
proposition,"Let $j\in[p]$ be s.t.\ $\lambda_i^D>\lambda_1^P$ for all $i\leq j$. Then, for all $i\leq j$, it holds that     $$h_i = \frac{\tilde{h}_i}{\sqrt{1-\tilde{h}_i^\top\frac{d}{d\lambda}R(\lambda_i^D)\tilde{h}_i}},$$     where $\tilde{h}_i$ is the %unit norm      eigenvector of $R(\lambda_i^D)$ and $\frac{d}{d\lambda}R(\lambda)$ is the entry-wise derivative of %the matrix      $R(\lambda)$.",2502.01583
proposition,"Let $k\in[p]$ be such that $\alpha_k>\lambdabardelta$, where $\alpha_k$ is the $k$-th largest solution of \Cref{eq:master_eq2}. %to the equation %     $$\det\paren{\zetadelta(\alpha)I-R^\infty(\alpha)}=0.$$      Then, it holds that                R(\lambda_k^D)\asconv R^\infty(\alpha_k),            and                \frac{d}{d\lambda}R(\lambda_k^D)\asconv \frac{1}{\zetadelta'(\alpha_k)}\frac{d}{d\alpha}R^\infty(\alpha_k).",2502.01583
proposition,"For any fixed $\mu\in]\lambda_i^{a^\infty}, t_i^\infty[$, it holds that          \tildeLi(\mu) \asconv \tildeLiinfty(\mu)=\zeta_\delta\paren{(\lambda^\infty_i)^{-1}(\mu)}.          Furthemore, for any fixed $\mu\in]t_i^\infty,+\infty[$, it holds that       \tildeLi(\mu) \asconv\zeta_\delta\paren{\lambdabardelta}.",2502.01583
proposition,"The equation in \Cref{eq:master_eq2} has at most $p$ solutions. Furthermore, if \Cref{assmp:psol} holds, then \Cref{eq:master_eq2} has exactly $p$ solutions.",2502.01583
proposition,"Let $\alpha_k$ be the $k$-th solution to the equation     $$\det\paren{\zetadelta(\alpha)I-a^\infty+R^\infty(\alpha)}=0,$$     with multiplicity one. If $\alpha_k>\lambdabardelta$, then for $j\in[p]$ it holds that     $$\abs{\inprod{v_k^D}{e_j^{(d)}}}^2\asconv \frac{\zetadelta'(\alpha_k)\cdot \abs{\inprod{h_k^\infty}{e_j^{(p)}}}^2}{\zetadelta'(\alpha_k)+{h_k^\infty}^\top \frac{d}{d\alpha}R^\infty(\alpha_k)h_k^\infty},$$     where $h_k^\infty$ is the unit norm eigenvector corresponding to the eigenvalue $\zetadelta(\alpha_k)$ of the matrix $R^\infty(\alpha_k)$.",2502.01583
proposition,"If the link function $q$ is permutation invariant in $m$ coordinates, then the matrix $R^\infty(\alpha)$  has eigenspaces that do not change with $\alpha$, of combined dimension $m-1$.",2502.01583
lemma,"Let us assume that $\lambda>\lambda_1^P$. Then, for the  diagonal elements of $R(\lambda)$, it holds that              R(\lambda)_{i,i} &= a_{i,i}+\frac{1}{\cLi^{-1}(\lambda)}, \\         \frac{d}{d\lambda}R(\lambda)_{i,i} &= -\frac{1}{\paren{\cLi^{-1}(\lambda)}^2\cLi'(\cLi^{-1}(\lambda))}.          Moreover, for the off-diagonal elements, we have              2R(\lambda)_{i,j} &=2a_{i,j} + \frac{1}{\cL_{i,j}^{-1}(\lambda)} - \frac{1}{\cL_i^{-1}(\lambda)} - \frac{1}{\cL_j^{-1}(\lambda)},\\         2\frac{d}{d\lambda}R(\lambda)_{i,j} &= \frac{1}{\paren{\cLi^{-1}(\lambda)}^2\cLi'(\cLi^{-1}(\lambda))}+\frac{1}{\paren{\cL_j^{-1}(\lambda)}^2\cL_j'(\cL_j^{-1}(\lambda))}-\frac{1}{\paren{\cL_{i,j}^{-1}(\lambda)}^2\cL_{i,j}'(\cL_{i,j}^{-1}(\lambda))} .",2502.01583
lemma,"Under \Cref{asmp:T}, almost surely for all sufficiently large $n$ it holds that $$\rk(ZS) = p.$$",2502.01583
lemma,"For every eigenvector $v_i^a$, it holds almost surely that      $$qv_i^a\neq 0.$$",2502.01583
lemma,"For $i \in[p]$ and $j\geq 2$, it holds that     $$\lim_{\mu_1\to{\lambda^a_i}^+}L_j(\mu_1) = \lim_{\mu_2\to{\lambda^a_i}^-}L_{j-1}(\mu_2).$$",2502.01583
lemma,"For $i\in [d-p]$, $\tilde{L}_i$ is non-increasing with the limit on the right edge of the domain given by      $$\lim_{\mu\to\infty}\tilde{L}_i(\mu)=\lambda_i(P).$$     Moreover, for $i\in[p]$, the limit on the left edge of the domain is     $$\lim_{\mu\to{\lambda_{i}^a}^+}\tilde{L}_i(\mu)=+\infty.$$",2502.01583
lemma,"An eigenvalue $\lambda_i^D\notin \Lambda^a$, $i\in [d-p]$, is a solution to               L_k(\mu) = \mu,          for some $k$.     Conversely, any solution to the previous equation is an eigenvalue of $D$ that is also not an eigenvalue of $a$.",2502.01583
lemma,"An arbitrary eigenvalue $\lambda_i^D\in \Lambda^a$ is equal to $\lambda_j^a$ if and only if                \lim_{\mu\to{\lambda_j^a}^+} L_k(\mu) = \lambda_j^a,          for some $k\geq 2$.",2502.01583
lemma,"For each $\mu>0$,    let $\alpha_1\geq \dots\ \geq \alpha_j > \tau$ be all the solutions to the equation               \det\paren{\mu I_p-R^\infty(\alpha)}=0.          Then, for the top $j$ eigenvalues of $M_n$, it holds that              \lambda_1^M,\dots,\lambda_j^M \asconv \alpha_1, \dots, \alpha_j,          and for the remaining $p-j$ eigenvalues, it holds that     $$\lambda_{j+1}^M,\dots,\lambda_p^M \asconv \tau.$$",2502.01583
proof,"[Proof of \cref{lemma:biasvariance}] Here we give the bias-variance decomposition of $\E_{\varepsilon}\|\hat{\bbeta}\|_2^2$. The formulation of $\E_{\varepsilon}\|\hat{\bbeta}\|_2^2$ is given by \[       \E_{\varepsilon}\|\hat{\bbeta}\|_2^2 =\|\left( \bX^\sT \bX + \lambda \id \right)^{-1} \bX^\sT \by \|_2^2\,,  \] which can be decomposed as \[      \E_{\varepsilon}\|\hat{\bbeta}\|_2^2 =&~ \E_{\varepsilon}\|\left( \bX^\sT \bX + \lambda \id \right)^{-1} \bX^\sT (\bX\bbeta_* + \bm\varepsilon) \|_2^2\\     =&~ \|\left( \bX^\sT \bX + \lambda \id \right)^{-1} \bX^\sT \bX\bbeta_* \|_2^2 + \E_{\varepsilon}\|\left( \bX^\sT \bX + \lambda \id \right)^{-1} \bX^\sT \bm\varepsilon \|_2^2\\     =&~\<\bbeta_*, (\bX^\sT\bX)^2(\bX^\sT\bX + \lambda\id)^{-2}\bbeta_*\> + \sigma^2\Tr(\bX^\sT\bX(\bX^\sT\bX + \lambda\id)^{-2})\\     =:&~ \mathcal{B}_{\mathcal{N},\lambda}^{\tt LS} + \mathcal{V}_{\mathcal{N},\lambda}^{\tt LS}\,.  \] Accordingly, we can see that it shares the similar spirit with the bias-variance decomposition.",2502.01585
proof,"[Proof of \cref{prop:asy_equiv_norm_LR}] We give the asymptotic deterministic equivalents for $\mathcal{B}_{\mathcal{N},\lambda}^{\tt LS}$ and $\mathcal{V}_{\mathcal{N},\lambda}^{\tt LS}$, respectively. For the bias term $\mathcal{B}_{\mathcal{N},\lambda}^{\tt LS}$, we use \cref{eq:trAB1} by taking $\bA = \bbeta_*\bbeta_*^\sT$ and $\bB = \id$ and thus obtain \[      \mathcal{B}_{\mathcal{N},\lambda}^{\tt LS} = &~ \<\bbeta_*, (\bX^\sT\bX)^2(\bX^\sT\bX + \lambda\id)^{-2}\bbeta_*\>\\     = &~ \Tr(\bbeta_*\bbeta_*^\sT(\bX^\sT\bX)^2(\bX^\sT\bX + \lambda\id)^{-2})\\     \sim &~ \Tr(\bbeta_*\bbeta_*^\sT\bSigma^2(\bSigma + \lambda_*\id)^{-2}) + \lambda_*^2 \Tr(\bbeta_*\bbeta_*^\sT\bSigma(\bSigma + \lambda_*\id)^{-2}) \cdot \Tr(\bSigma(\bSigma + \lambda_*\id)^{-2}) \cdot \frac{1}{n-\Tr(\bSigma^2(\bSigma + \lambda_*\id)^{-2})}\\     = &~ \<\bbeta_*, \bSigma^2(\bSigma + \lambda_*\id)^{-2}\bbeta_*\> + \frac{\Tr(\bSigma(\bSigma + \lambda_*\id)^{-2})}{n} \cdot \frac{\lambda_*^2 \<\bbeta_*,\bSigma(\bSigma + \lambda_*\id)^{-2}\bbeta_*\>}{1-n^{-1}\Tr(\bSigma^2(\bSigma + \lambda_*\id)^{-2})}\\     =: &~ \sB_{\sN, \lambda}^{\tt LS}\,.  \] For the variance term $\mathcal{V}_{\mathcal{N}}^{\tt LS}$, we use \cref{eq:trA3} by taking $\bA = \id$ and obtain \[      \mathcal{V}_{\mathcal{N}}^{\tt LS} = &~ \sigma^2\Tr(\bX^\sT\bX(\bX^\sT\bX + \lambda\id)^{-2}) \sim \frac{\sigma^2\Tr(\bSigma(\bSigma + \lambda_*\id)^{-2})}{n - \Tr(\bSigma^2(\bSigma + \lambda_*\id)^{-2})} =: \sV_{\sN, \lambda}^{\tt LS}\,.  \]",2502.01585
proof,"[Proof of \cref{prop:asy_equiv_norm_LR_minnorm}] We separate the results in the under-parameterized and over-parameterized regimes.  In the under-parameterized regime ($d<n$), for minimum norm estimator $\hat{\bbeta}_{\min}$, we have (for $\bX^\sT\bX$ is invertible) \[      \hat{\bbeta}_{\min} = \left(\bX^\sT\bX\right)^{-1}\bX^\sT\by = \left(\bX^\sT\bX\right)^{-1}\bX^\sT(\bX\bbeta_*+\bm\varepsilon) = \bbeta_* + \left(\bX^\sT\bX\right)^{-1}\bX^\sT\bm\varepsilon\,.  \] Accordingly, we can directly obtain the bias-variance decomposition as well as their deterministic equivalents \[      \mathcal{B}_{\mathcal{N},0}^{\tt LS} = \|\bbeta_*\|_2^2\,, \quad \mathcal{V}_{\mathcal{N},0}^{\tt LS} = \sigma^2\Tr(\bX^\sT\bX(\bX^\sT\bX)^{-2}) \sim \sigma^2\frac{\Tr(\bSigma^{-1})}{n-d}\,,  \] where we use \cref{eq:trA3} and take $\lambda \to 0$ for the variance term.  In the over-parameterized regime ($d>n$), we take the limit $\lambda \to 0$ within ridge regression and use \cref{prop:asy_equiv_norm_LR}. Define $\lambda_n$ as $\Tr(\bSigma(\bSigma+\lambda_n\id)^{-1}) \sim n$, we have for the bias term \[      \mathcal{B}_{\mathcal{N},0}^{\tt LS} \sim &~ \<\bbeta_*, \bSigma^2(\bSigma + \lambda_n\id)^{-2}\bbeta_*\> + \frac{\Tr(\bSigma(\bSigma + \lambda_n\id)^{-2})}{n} \cdot \frac{\lambda_n^2 \<\bbeta_*,\bSigma(\bSigma + \lambda_n\id)^{-2}\bbeta_*\>}{1-n^{-1}\Tr(\bSigma^2(\bSigma + \lambda_n\id)^{-2})}\\     =&~ \<\bbeta_*, \bSigma(\bSigma + \lambda_n\id)^{-1}\bbeta_*\> - \lambda_n \<\bbeta_*, \bSigma(\bSigma + \lambda_n\id)^{-2}\bbeta_*\> + \frac{\Tr(\bSigma(\bSigma + \lambda_n\id)^{-2})}{n} \cdot \frac{\lambda_n^2 \<\bbeta_*,\bSigma(\bSigma + \lambda_n\id)^{-2}\bbeta_*\>}{1-n^{-1}\Tr(\bSigma^2(\bSigma + \lambda_n\id)^{-2})}\\     =&~ \<\bbeta_*, \bSigma(\bSigma + \lambda_n\id)^{-1}\bbeta_*\>\,.  \] For the variance term, we have \[      \mathcal{V}_{\mathcal{N},0}^{\tt LS} \sim&~ \frac{\sigma^2\Tr(\bSigma(\bSigma+\lambda_n\id)^{-2})}{n-\Tr(\bSigma^2(\bSigma+\lambda_n\id)^{-2})}\,.  \] Finally we conclude the proof.",2502.01585
proposition,"[Asymptotic deterministic equivalence of the norm of ridge regression estimator]     Given the bias variance decomposition of $\E_{\varepsilon}\|\hat{\bbeta}\|_2^2$ in \cref{lemma:biasvariance},      under \cref{ass:asym}, we have the following asymptotic deterministic equivalents $\mathcal{N}^{\tt LS}_{\lambda}  \sim \sN^{\tt LS}_{\lambda} := \sB_{\sN,\lambda}^{\tt LS} + \sV_{\sN,\lambda}^{\tt LS}$ such that $\mathcal{B}^{\tt LS}_{\mathcal{N},\lambda} \sim \sB_{\sN,\lambda}^{\tt LS}$, $\mathcal{V}^{\tt LS}_{\mathcal{N},\lambda} \sim \sV_{\sN,\lambda}^{\tt LS}$, where $\sB_{\sN,\lambda}^{\tt LS}$ and $\sV_{\sN,\lambda}^{\tt LS}$ are defined by \cref{eq:equiv-linear}.",2502.01585
theorem,}{\hfill \interlinepenalty500 $\Box$,2502.01590
lemma,}{\hfill \interlinepenalty500 $\Box$,2502.01590
lemma,"The optimal solution to the problem \eqref{eq:optim} satisfies the power constraint with equality, i.e., $\tr{\mW_{\star}^{\her} \mW_{\star} } = P$, for any $\mW_\star$ that is a solution to \eqref{eq:optim}.",2502.01590
lemma,"For a given $\bl$, let $\bar{\mW}= [{\bar{\mathbf{w}}}_1,\ldots,{\bar{\mathbf{w}}}_K]$ denote a  solution to the following problem %unconstrained rate maximization problem  \max_{\mW}  \sum_{k} \lambda_k \log(1+\overline{\sinr}_k \brc{\mW,\bl}),  where $\overline{\sinr}_k\brc{\mW,\bl}$ for ${\mW}= [{{\mathbf{w}}}_1,\ldots,{{\mathbf{w}}}_K]$ is defined as  \overline{\rm{SINR}}_k \brc{\mW,\bl} =\frac{\abs{\bg_k^\trp\brc{\bl}  \bw_k}^2}{\sum_{j\neq k} \abs{\bg_k^\trp\brc{\bl}  \bw_j}^2 + \tfrac{\sigma^2}{P}\sum_{j}\norm{{{\mathbf{w}}}_j}^2 }.  Then, a solution to \eqref{eq:optim} is determined from $\bar{\mW}$ as %$= [\breve{{\mathbf{w}}}_1,\ldots,\breve{{\mathbf{w}}}_K]$ with  \breve{\mW} =\sqrt{{P}/{\tr{\bar{\mW}^{\her} \bar{\mW}}}} \bar{\mW}.",2502.01590
theorem,"[Informal]     Consider a function $f:\R^d\rightarrow \R$ and a sampling distribution $\rho$ satisfying Assumptions~\ref{assumption:sampling-distribution} and ~\ref{assume:Lipschitz-Hessian}. Let $\Delta_f \defeq f(\theta_0) - \inf_{\theta\in \R^d} f(\theta)$ for some initialization point $\theta_0$, and assume $\Delta_f$ is finite. Consider optimizing $f(\cdot)$ with Adagrad using step size $\eta$. Let $\{\ttheta_t\}_{t=1}^T$ denote the iterates produced by optimizing the reparameterizing objective $\tf \defeq f\circ V$ using Adagrad initialized at $V^\T \theta_0$, where $V$ denotes the eigenbasis of $\EGOP(f)$. Let $\beta \defeq \shortnorm{v_1}^2_1/d$ for $v_1$ the leading EGOP eigenvector. Then if the value $H$ in Assumption~\ref{assume:Lipschitz-Hessian} is sufficiently small, reparameterized Adagrad convergence is bounded by     \[         \frac{1}{T} \sum_{t=1}^T \norm{\nabla \tf(\ttheta_t)}_1 = \tilde{O}\left(\frac{\sr_f}{\beta d}\cdot \frac{\eta L_f}{\sqrt{T}} + \frac{\Delta_f}{\eta\sqrt{T}}\right)     \]     where $\sr_f$ denotes the stable rank (\ref{eq:def-stable-rank}).",2502.01594
theorem,The transitive closure of \(\erel\) is a poset.,2502.01604
theorem,"The transitive closure \(\transterel\) of the relation \(\terel\) is the restriction of \(\transerel\) to \(\twoanti{P}\); thus \((\twoanti{P}, \transterel)\) is the induced subposet of \((\Ppairs, \transerel)\). Furthermore, when \(P\) is neither a chain nor an antichain, \((\twoanti{P},  \transterel)\) is isomorphic to \((\Pqu,\pqurel)\) with the top and bottom elements removed.",2502.01604
theorem,"Let \((P,\le)\) be a finite poset, with \(|P|=n\), and let \(m\) denote the number of two-element antichains in \(P\), i.e. the cardinality of the set \[ \{(x,y) \in P \times P \mid x \parallel y\} \] is \(2m\). Assume that \(P\) is not a chain, so that \(m > 0\). Then the set of all probability functions on \(P\) form a convex polytope which can be realised inside \(\RR^{^{n^{2}}}\), or inside \(\RR^{^{n^{2}-n}}\), but also inside \(\RR^{2m}\).",2502.01604
theorem,"[Geissinger] Let \(Q\) be a finite poset, and let \(\orderpolytope{Q}\) be its order polytope. Then the face lattice of \(\orderpolytope{Q}\) is anti-isomorphic to the lattice of connected and compatible set partitions on \(Q\). In particular, the vertices of \(\orderpolytope{Q}\) correspond to characteristic functions on order filters of \(Q\).",2502.01604
theorem,"The probability functions polytope \(\prpolytope{P}\) is the intersection of the order polytope \(\orderpolytope{\twoanti{P}} \subset \RR^{\twoanti{P}}\) with the affine subspace \(H\) cut out by the equations corresponding to \(\pi(x,y) + \pi(y,x)=1\).",2502.01604
theorem,The vertices of \(\prpolytope{P}\) which have 0/1 coordinates corresponds to order filters \(S \subset \twoanti{P}\) with the property that \[S \ni u \iff \tau(u) \not \in S.\],2502.01604
definition,"A function \(\pi: P \times P \to [0,1]\) is called a \textbf{probability function} on \(P\) if for all \(x,y \in P\),  \item \(\pi(x,x)=1\), \item \(x \le y\) implies \(\pi(x,y)=1\), \item \(x \neq y\) implies \(\pi(x,y) + \pi(y,x)=1\), \item \(y < z\) implies \(\pi(x,y) \le \pi(x,z)\).",2502.01604
definition,"Let \((P,\le)\) be a finite poset with \(|P|=n\), and let \(x,y \in P\). Let \(\linexts{P}\) be the set of linear (total) extensions of \(P\), i.e. the set of all bijections \(\ell: P \to [n] = \{1,2,\dots,n\}\) that are order-preserving, and let \(\ell \in \linexts{P}\) is some total extension. Define     \probnull(x,y) & =                                          1 & x \le y, \\                      1/2 & x \parallel y, \\                      0 & x > y,                     \\ \problin{\ell}(x,y) &=          1 & \text{ if } \ell(x) < \ell(y), \\      1 & \text{ if  } x = y, \\      0 & \text{ otherwise}     \\ \problins(x,y) & = \frac{1}{|\linexts{P}|} \sum_{\ell \in \linexts{P}} \problin{\ell}(x,y)",2502.01604
definition,"Let \((P, \le)\) be a poset. Denote by \(\Delta = \{(x,y) \in P \times P \, \mid \, x \neq y\}\), and put  \(\Ppairs = (P \times P \setminus \Delta)\). A \textbf{reduced} probability function on \(P\) is a function \(\pi: \Ppairs \to [0,1]\) satisfying  \item \(x \le y\) implies \(\pi(x,y)=1\), \item \(x \neq y\) implies \(\pi(x,y) + \pi(y,x)=1\), \item \(y < z\) implies \(\pi(x,y) \le \pi(x,z)\), \item \(y < z\) implies \(\pi(z,x) \le \pi(y,x)\).",2502.01604
definition,"Let \((P,\le)\) be a finite poset. Suppose that \(P\) is not a chain. Define  binary relations on \(\Ppairs\) by          (x,y) & \arel (u,v) \iff x = u \text{ and } y \le v \\     (x,y) & \brel (u,v) \iff y = v \text{ and } u \le x \\     (x,y) & \erel (u,v) \iff (x,y) \arel (u,v) \text{ or } (x,y) \brel (u,v)",2502.01604
definition,"We denote by \((\Ppairs, \transerel)\) the poset which is the transitive closure of \(\erel\).",2502.01604
definition,"Let \((Q,\le)\) be a finite poset, and \(\gamma\) a set partition  on \(Q\). We say that \(\gamma\) is \textbf{compatible} if the following relation on the blocks of \(\gamma\) has a transitive closure which is a poset (in other words, the transitive closure should be antisymmetric): \[ B_{\iota} \le_{\gamma} B_{\nu} \quad \iff \quad \exists a \in B_{\iota}, b \in B_{\nu}, \, a \le b. \] In this case, the resulting poset of blocks, ordered by \(\le_{\gamma}\), is the called a \textbf{quotient} of \(Q\), and denoted by \(Q/\gamma\).",2502.01604
definition,"Let \((Q,\le)\) be a finite poset.  \item Let \(S \subset Q\). Then \(S\) is \emph{connected} as an induced subposet of \(Q\) (``connected inside \(Q\)'') if the undirected graph of the Hasse diagram of the induced subposet of \(Q\) is connected. Concretely, for any \(a,b \in S\) there is a sequence \(s_1,\dots, s_n \in S\) such that \(s_1=a\), \(s_n=b\) and for \(1 \le i < n\), either \(s_i \le s_{i+1}\) or \(s_i \ge s_{i+1}\). \item Let \(\gamma\) be a set partition  on \(Q\). Then \(\gamma\) is \emph{connected} if every block is connected as an induced subposet of \(Q\).",2502.01604
definition,"Let \((P,\le)\) be a finite poset. Construct a set partition \(\sigma\) on \(\Ppairs\) by  \item The ``bottom block''  consists of all \((x,y)\) with \(x < y\), \item the ``middle blocks'' consists of all \((x,y)\) with \(x \parallel y\); each such element of \(\Ppairs\) form a singleton block, \item the ``top block'' consists of all \((x,y)\) with \(x > y\).   This set partition is compatible with \((\Ppairs, \transerel)\), thus we can form the quotient \[(\Pqu, \pqurel) = \Ppairs/\sigma. \]",2502.01604
definition,"Let \[\twoanti{P} = \{(x,y) \in P \times P \mid x \parallel y\}\] and define the following binary relations on \(\twoanti{P}\):          (x,y) & \tarel (u,v) \iff x = u \text{ and } y \le v \\     (x,y) & \tbrel (u,v) \iff y = v \text{ and } u \le x \\     (x,y) & \terel (u,v) \iff (x,y) \tarel (u,v) \text{ or } (x,y) \tbrel (u,v)",2502.01604
definition,"Let \((P,\le)\) be a finite poset, with \(|P|=n\)  and containing \(m>0\) \emph{unordered} two-element antichains. We denote by \(\prpolytope{P} \subset \RR^{2m}\) the probability functions polytope, as described in Theorem (\ref{thm-embedd}).",2502.01604
proof,"Take \(x,y,z \in P\). Then \[\pi(x,x) = \sum_{j=1}^{n}c_{j}\pi_{j}(x,x) = \sum_{j=1}^{n}c_{j}\cdot 1 = 1. \] If \(x \le y\) then \[ \pi(x,y) = \sum_{j=1}^{n}c_{j}\pi_{j}(x,y) = \sum_{j=1}^{n}c_{j} = 1. \] If \(x \neq y\) then  \pi(x,y) + \pi(y,t) & = \sum_{j=1}^{n}c_{j}\pi_{j}(x,y) + \sum_{j=1}^{n}c_{j}\pi_{j}(y,x) \\ & = \sum_{j=1}^{n}c_{j}\bigl(\pi_{j}(x,y) + \pi_{j}(y,x) \bigr) \\ & = \sum_{j=1}^{n}c_{j}\cdot 1 \\ & = 1.  If \(y < z\) then \[ \pi(x,y) = \sum_{j=1}^{n}c_{j}\pi_{j}(x,y)  \le \sum_{j=1}^{n}c_{j}\pi_{j}(x,z) = \pi(x,z). \]",2502.01604
proof,"Reflexivity: \((x,y) \arel (x,y)\) since \(x=x\) and \(y \le y\).  No directed cycles: suppose that   (x_{1},y_{1}) \erel (x_{1},y_{1}) \erel \cdots \erel (x_{n},y_{n})  and that each comparison is strict, i.e. \[(x_{i},y_{i}) \neq (x_{i+1},y_{i+1}).\] If \[(x_{i},y_{i}) \arel (x_{i+1},y_{i+1})\] then \(y_{i} < y_{i+1}\), and if \[(x_{i},y_{i}) \brel (x_{i+1},y_{i+1})\] then \(x_{i+1} < x_{i}\). Hence either (or both) \(x_{n} < x_{1}\) or \(y_{n} > y_{1}\), so \[(x_{1},y_{1}) \neq (x_{n},y_{n}).\] Thus (\ref{eq-erelchain}) is no directed cycle.",2502.01604
proof,"Clearly \(\tau \circ \tau\) is the identity. If \((x,y) \arel (u,v)\) then \[(v,u) \brel (y,x),\] and if \((x,y) \brel (u,v)\) then \[(v,u) \arel (y,x).\] Thus if \((x,y) \erel (u,v)\) then \[\tau((u,v)) \erel \tau((x,y)).\] So by transitivity, if \((x,y) \transerel (u,v)\) then \[\tau((u,v)) \transerel \tau((x,y)).\]",2502.01604
proof,"In this case, the relations \(\arel,\brel\), and hence \(\erel\) and \(\transerel\) are all trivial, so only idential elements are related in \((\Ppairs, \transerel)\).",2502.01604
proof,"Define \(c((i,j)) = j - i\). Then \[c(\Ppairs)=\{1-n, 2-n, \dots - 1, 1,2, \dots, n-1\}.\] Since the cover relations in \(C_{n}\) are \(a \lessdot a+1\) the cover relations in \(\Ppairs\) are \((i,j) \lessdot (i,j+1)\) and \((i,j) \lessdot (i-1,j)\), provided that all these elements belong to \[\Ppairs = \{(i,j) \mid 1 \le i,j \le n, \, i \neq j\}.\] Each such cover relation \(u \lessdot v\) has \(c(u) = c(v)-1\). However, there are no elements with \(c((i,j))=0\), so the elements with \(c=-1\) are instead covered by those with \(c=+1\). The rank function \(r\) is shifted to take this into account.",2502.01604
proof,"The ``bottom block'' of \(\Ppairs\) consists of ordered pairs \((x,y)\) with \(x \le y\), the ``top block''  consists of ordered pairs \((x,y)\) with \(x \ge y\), and the ``middle block''  consists of ordered pairs \((x,y)\) with \(x \parallel y\).  In \(\twoanti{P}\) there are only the elements of the middle block, with the induced order.  In \(\Pqu\) there are the elements of the middle block, with the induced order, as well as the class of the top block, an element which is above all elements in the middle block, and also the class of the bottom block, which is below all elements of the middle block. The ordering of the elements in the middle block is once again induced from \(\Ppairs\).  Hence \(\twoanti{P}\) with \(\hat{0},\hat{1}\) adjoined is isomorphic to \(\Pqu\); equivalently, \[\Pqu \setminus \{\hat{0}, \hat{1}\} \simeq \twoanti{P}.\]",2502.01604
proof,"First, recall that \(\tau\) is antitone on \((\Ppairs,\transerel)\) and that \(\tau = \tau^{-1}\). Secondly, \((x,y) \in \twoanti{P}\) if and only if \((y,x) \in \twoanti{P}\), thus \(\tau(\twoanti{P}) = \twoanti{P}\). Furthermore, \((\twoanti{P},\transterel)\) is the induced subposet of \((\Ppairs,\transerel)\). It follows that the restriction of \(\tau\) is antitone on \((\twoanti{P},\transterel)\) and is equal to its own inverse; thus (\ref{tau-on-anti}) holds.",2502.01604
proof,"Let \(n = |P|\). Choose some linear extension \(\delta \in \linexts{P}\), to label the elements in \(P\). For any probability function \(\pi\) on \(P\), we define an \(n \times n\)-matrix \(A\) by \[A_{{\delta(x),\delta(y)}} = \pi(x,y).\] The set of all \(n \times n\)-matrices form an affine space of dimension \(n^{2}\). By Lemma (\ref{lemma-isconvex}) the subset of matrices arising from probability functions is convex. But this subset is also contained inside \([0,1]^{n^{2}}\), so it is bounded. Furthermore, the equalities and inequalities in Definition (\ref{def-probfunc}) are finite in number and cut out the prescribed subset of matrices, so this set is in fact a polytope \(\subset \RR^{n^{2}}\).  Since \(\pi(x,x)=1\) always, the corresponding entries in the matrix \(A\) are prescribed. We can thus project the polytope down to \(\RR^{n^{2} - n}\), by forgetting the coordinates \((i,i)\) .  Similarly, since \(\pi(x,y)=1\) for \(x \le y\), \(\pi(x,y)=0\) for \(x > y\), we can project the polytope down to \(\QQ^{2m}\), by forgetting the coordinates \((i,j)\) which are not associated with an \emph{ordered} antichain  \((x,y)\).",2502.01604
proof,"In fact, the linear maps    \mathbb{Proj}_{\lvert H}: H & \to \RR^{s} \\   (\vec{x},\vec{y}) & \mapsto \vec{x}  and    \mathbb{J}: \RR^{s} & \to H \\   (x_{1}.\dots,x_{n}) & \mapsto (x_{1},\dots, x_{n}; 1 - x_{1},\dots, 1 - x_{n})  are mutual inverses and thus shows that the polytopes are even \emph{affinely isomorphic}.",2502.01604
proof,"The equations stemming from \[\pi(a,b) + \pi(b,a)=1\] for all probability functions show that \[\prpolytope{P} \subset \{\vec{x} \mid x_{a,b} + x_{b,a}=1\},\] so Lemma \ref{lemma-project} applies. The inequalities \[0 \le \pi(x,y) \le 1\] ensures that the probability functions polytope lies within the respective unit hypercubes.",2502.01604
proof,"The value \(\pi(x,y) \in \{0,1\}\), since \(x < y\) or \(x > y\). Thus, there is only a single probability function on \(P\).  Alternatively, the set of ordered antichains is empty.",2502.01604
proof,"In this case, there are no restrictions on the value \(\pi(x,y)\) that a probability function on \(P\) may take on a given (ordered) antichain \((x,y)\) except that \[0 \le \pi(x,y) \le 1\] and \[\pi(x,y) + \pi(y,x)=1.\] Thus \(\prpolytope{P}\) is the unit hypercube \([0,1]^{2m}\) intersected with the affine subspace \(u_{i} + v_{i}=1\), where \[U=\{u_{1},\dots,u_{m}\}\] is a choice of variables (ordered two-element antichains) such that \[\twoanti{P} = U \sqcup \tau(U).\] From Lemma \ref{lemma-project} we have that this polytope is combinatorially equivalent with its projection onto the span of \(U\); this is a hypercube of dimension \(m = d^{2}-d\).",2502.01604
proof,"No \(S \subset P \sqcup Q\) containing elments from both \(P\) and \(Q\) can be an antichain in \(P \oplus Q\). Conversely, any induced subposet of \(S \subset P\) inside \(P+Q\) is isomorphic to the induced subset inside \(P\), so it is an antichain of \(P+Q\) iff it is an antichain of \(P\). The same goes for subsets of \(Q\).",2502.01604
proof,"Suppose that \[(x,y), (u,v) \in \twoanti{P \oplus Q}.\] By the previous Lemma, we may assume that either \[(x,y), (u,v) \in \twoanti{P},\] or \[(x,y)\in \twoanti{P},\quad (u,v)\in \twoanti{Q}.\]. In the first case, the relation between \((x,y), (u,v)\) is as in \((\twoanti{P}, \transterel)\). In the second case, \((x,y) \parallel (u,v)\) since no relations of the form (\ref{eq-trel}) apply, given that \(x,y\) and \(u,v\) belong to disjoint universes.  The second assertion also follows from the Lemma; any probability function \[\pi: \twoanti{P \oplus Q} \to [0,1]\] is determined by its restrictions to \(\twoanti{P}\) and to \(\twoanti{Q}\).",2502.01604
proof,"We regard the probability functions polytope  as the polytope \(\prpolytope{P} \subset \RR^{{\twoanti{P}}}\) of all functions \(f: \twoanti{P} \to \RR\), subject to  \item \(0 \le f(x,y) \le 1\), \item \(f((x,y)) \le f((u,v))\), if \(x=u\) and \(y \le v\) in \(P\), \item \(f((x,y)) \le f((u,v))\), if \(x \ge u\) in \(P\) and \(y =v\), \item \(f((x,y)) + f((u,v)) = 1\) if \((u,v) = (y,x)\).  The second and third conditions can be summarized as \(f((x,y)) \le f((u,v))\) if \((x,y) \transerel (u,v)\), hence the first three conditions are simply the inequalities cutting out the order polytope \(\orderpolytope{\twoanti{P}}\). The equations in condition 4 are the equations defining the affine subspace \(H\).",2502.01604
proof,"Let the ordered antichains of \(P\) be \[ \{(p_{i_{1}}, p_{j_{1}}), \dots, (p_{i_{m}}, p_{j_{m}}), (p_{j_{1}}, p_{i_{1}}), \dots, (p_{j_{m}}, p_{j_{1}}) \}. \] The order polytope \[\orderpolytope{\twoanti{P}} \subset [0,1]^{2m}\] have as vertices the characteristic functions on order filters of \(\twoanti{P}\), by Geissinger's theorem. To get \(\prpolytope{P}\), we intersect with the affine subspace \(H \subset \RR^{2m}\) cut out by by the \(m\) equations \[x_{a,b} + x_{b,a} = 1,\] where the variable \(x_{a,b}\) is associated with the ordered antichain \[(p_{i_{a}},p_{j_{b}}) \in \twoanti{P}.\]  The resulting polytope \[H \cap \prpolytope{P} \subset H\] has, as its vertices,  those vertices of \(\prpolytope{P}\) that belong to \(H\), and potentially new vertices arising from the fact that the hyperplanes defining \(H\) may not ``cut'' the order polytope in the sense of \autocite{HibiCutting}.  However, any vertex of \(\prpolytope{P}\) with 0/1 coordinates was already a vertex of \(\orderpolytope{\twoanti{P}}\). The characteristic function/vector of a such vertex in \(\prpolytope{P}\) is a zero-one vector, and belong to \(H\) iff the coordinate associated to the variable \(x_{a,b}\) is zero iff \(x_{b,a}\) is one. In other words, the filter of which the characteristic function is the characteristic function should contain precisely one of each pair \[ (p_{i_{a}},p_{j_{b}}), \, (p_{i_{b}},p_{j_{a}}). \]",2502.01604
lemma,"If \((P,\le\) is a poset, and \(x,y,z \in P\), then \[ y < z \quad \implies \quad   \pi(z,x) \le \pi(y,x). \]",2502.01604
lemma,"Let \((P,\le)\) be a poset, and let \(\pi_{1},\dots,\pi_{n}\) be probability functions on \(P\). Then any convex combination \[ \pi = \sum_{j=1}^{n} c_{j}\pi_{j}, \qquad \sum_{j=1}^{n} c_{j} =1, \qquad \forall j: \, c_{j} \ge 0 \] is a probability function on \(P\).",2502.01604
lemma,"The map          \tau: \Ppairs & \to \Ppairs \\     \tau((x,y)) & = (y,x)     is an antitone involution on the poset \((\Ppairs, \transerel)\).",2502.01604
lemma,"If \(P\) is an antichain with \(n\) elements, then \((\Ppairs, \transerel)\) is an antichain with \(n(n-1)\) elements.",2502.01604
lemma,"If \(P=C_{n}\) is a chain with \(n\) elements, which w.l.o.g. may be taken to be \(\{1,\dots,n\}\), with the natural order, then the elements of \((\Ppairs, \transerel)\) are \(\{(i,j) \mid i \neq j\}\), and the resulting poset is ranked with rank function  r((i,j)) =    n - i + j  & i > j \\   n - i + j - 1 & i < j   The cover relations are  \item \((i,j) \lessdot (i,j+1)\) and \((i,j) \lessdot (i-1,j)\), when \(i > j\), \(r((i,j)) < n - 1\), \item \((i,j) \lessdot (i,j+2)\), if \(j+2 \le n\), and \((i,j) \lessdot (i-2,j)\), if \(i-2 \ge 1\), when \(i > j\), \(r((i,j)) < n - 1\), \item \((i,j) \lessdot (i,j+1)\), if \(j+1 \le n\), and \((i,j) \lessdot (i-1,j)\), if \(i \ge 1\), when \(i < j\).",2502.01604
lemma,"If \((P,\le)\) is a finite  anti-chain, then the quotient poset \((\Pqu, \pqurel)\) is equal to \((\Ppairs, \transerel)\) and thus an antichain.  If \(P\) is a finite chain, then \((\Pqu, \pqurel)\) is a two-element chain.  For other finite \(P\), \((\Pqu, \pqurel)\) has a unique minimal element \(\hat{0}\) and a unique maximal element \(\hat{1}\), and some other elements in between.",2502.01604
lemma,"The antitone involution \(\tau\) restricts to an antitone involution on \(\twoanti{P}\); hence for  \((x,y)\) and \((u,v)\) in \(\twoanti{P}\) we have that   (x,y) \transterel (u,v) \quad \iff \quad (v,u) \transterel (y,x)",2502.01604
lemma,"Let \(H \subset \RR^{s} \times \RR^{s}\) be the affine subspace \[H = \{(\vec{x}, \vec{y}) \mid x_{i} + y_{i} = 1 \text{ for } 1 \le i \le s\}.\] Suppose that \(Q \subset H\) is a polytope. Then \[ Q  \simeq \mathbb{Proj}(Q), \]  where \(\mathbb{Proj}\) denotes the projection \((\vec{x},\vec{y}) \mapsto \vec{x}\), and \(Q \simeq \mathbb{Proj}(Q)\) means that the two polytopes are \emph{combinatorially equivalent}, i.e., their face lattices are isomorphic.",2502.01604
lemma,"When \(P\) is a chain, \(\prpolytope{P}\) is a point.",2502.01604
lemma,"Suppose that \(\twoanti{P}\) is an antichain poset with \(m\) antichains. Then \(\prpolytope{P}\) is combinatorially equivalent with the \(m\)-dimensional hypercube. In particular, the \(d\)-element antichain has a  probability functions polytope that is combinatorially equivalent with the \({\binom{d}{2}}\)-dimensional hypercube.",2502.01604
lemma,"Let \(P,Q\) be two finite posets. Then the antichains of \(P \oplus Q\) is the disjoint union of the antichains of \(P\) and the antichains of \(Q\).",2502.01604
theorem,"[Pisier's formula \cite{Book.Pisier.1998}]  Let $\mathcal{H}$ be a separable Hilbert space and $\mathcal{X}$ an operator space. Then for $1\leq p\leq\infty$ the following variational formulas hold for any $X\in \mathcal{S}_p[\mathcal{H},\mathcal{X}]$.      \|X\|_{\mathcal{S}_p[\mathcal{H},\mathcal{X}]}= \inf_{\underset{X=FYG}{F,G\in \mathcal{S}_{2p}(\mathcal{H}), Y\in \mathcal{S}_\infty[\mathcal{H},\mathcal{X}]}}\|F\|_{2p}\|Y\|_{\mathcal{S}_\infty[\mathcal{H},\mathcal{X}]}\|G\|_{2p}.",2502.01611
theorem,"[Theorem 4.5 in \cite{Book.Pisier.1998}]  Given an element $X\in \mathcal{S}_q[\mathcal{H}_1,\mathcal{S}_p(\mathcal{H}_2)]$ acting on the Hilbert space $\mathcal{H}_1\otimes\mathcal{H}_2$ it holds that  \|X_{12}\|_{\mathcal{S}_q[\mathcal{H}_1,\mathcal{S}_p(\mathcal{H}_2)]} =              \inf_{\underset{X_{12}=F_1Y_{12}G_1}{F,G\in \mathcal{S}_{2r}(\mathcal{H}_1),Y\in \mathcal{S}_{p}(\mathcal{H}_{12})}} \|F\|_{2r}\|G\|_{2r}\|Y\|_{p}\,, & \quad \textup{for } q\leq p \\         \|X_{12}\|_p\,, & \quad \textup{for } q=p \\         \sup_{F,G\in\mathcal{S}_{2r}(\mathcal{H}_1)} \|F\|^{-1}_{2r}\|G\|^{-1}_{2r}\|F_1X_{12}G_1\|_p, & \quad \textup{for } q\geq p       where the infimum and supremum are over $F,G\in \mathcal{S}_{2r}(\mathcal{H}_1)$ acting only on the first Hilbert space and $Y\in \mathcal{S}_q(\mathcal{H}_{12})$ with $\frac{1}{r}:=\left|\frac{1}{q}-\frac{1}{p}\right|$.",2502.01611
theorem,"[Variational formulas 1]      Consider $X_{123}\in \mathcal{S}_p[\mathcal{H}_1,\mathcal{S}_q[\mathcal{H}_2,\mathcal{S}_s(\mathcal{H}_3)]]$. For $1\leq p\leq q\leq s\leq \infty$ with $\frac{1}{r}:=\frac{1}{p}-\frac{1}{s}$ and $ \frac{1}{r^\prime}:=\frac{1}{q}-\frac{1}{s}$, it holds that    %\|X_{123}\|_{\mathcal{S}_p[\mathcal{H}_1,\mathcal{S}_q[\mathcal{H}_2,\mathcal{S}_s(\mathcal{H}_3)]]} \|X\|_{(1:p,2:q,3:s)} = \inf_{ X=G_{12}Y_{123}F_{12}}\|GG^*\|^{\frac{1}{2}}_{(1:r,2:r^\prime)}\|F^*F\|^{\frac{1}{2}}_{(1:r,2:r^\prime)}\|Y\|_s\,.    For $1\leq s\leq q\leq p\leq \infty$ with $\frac{1}{r}:=\frac{1}{s}-\frac{1}{p}$ and $\frac{1}{r^\prime}:=\frac{1}{s}-\frac{1}{q}$,     \|X\|_{(1:p,2:q,3:s)} = \sup_{G_{12},F_{12}}\|G^*G\|^{-\frac{1}{2}}_{(1:r,2:r^\prime)}\|FF^*\|^{-\frac{1}{2}}_{(1:r,2:r^\prime)}\|G_{12}X_{123}F_{12}\|_s.",2502.01611
theorem,"[Variational Formulas 2] Consider $X_{123}\in \mathcal{S}_p[\mathcal{H}_1,\mathcal{S}_q[\mathcal{H}_2,\mathcal{X}]]$ for any operator space $\mathcal{X}$, then for any $1\leq p,q\leq \infty$ it holds that         \|X\|_{(1:p,2:q;\mathcal{X})}\leq\inf_{ X=G_{12}Z_{123}F_{12}}\|GG^*\|^{\frac{1}{2}}_{(1:p,2:q)}\|F^*F\|^{\frac{1}{2}}_{(1:p,2:q)}\|Z\|_{(1:\infty,2:\infty;\mathcal{X})},   where $(1:q,2:p;\mathcal{X})$ is a shorthand for the norm on $\mathcal{S}_q[\mathcal{H}_1,\mathcal{S}_p[\mathcal{H}_2,\mathcal{X}]]$. Further for $1\leq p\leq q\leq \infty$ equality holds. %while for $1\leq q\leq p\leq \infty$  %   %       \|X\|_{(1:p,2:q;\mathcal{X})}\leq\inf_{ X=G_{12}Z_{123}F_{12}}\|GG^*\|^{\frac{1}{2}}_{(1:p,2:q)}\|F^*F\|^{\frac{1}{2}}_{(1:p,2:q)}\|Z\| %_{S_\infty[\mathcal{H}_1\otimes\mathcal{H}_2,\mathcal{X}]} %       _{(1:\infty,2:\infty;\mathcal{X})}\,, % where $(1:q,2:p;\mathcal{X})$ is a shorthand for the norm on $\mathcal{S}_q[\mathcal{H}_1,\mathcal{S}_p[\mathcal{H}_2,\mathcal{X}]]$. \jk{ok?} %\textcolor{red}{add last two together into an inequality for any $p,q$, and write a sentence on equality case for $p\le q$}",2502.01611
theorem,"Let $\Phi$ be a CP map $\Phi:QP\to RS$, $\mathcal{X}$ an operator space and $1\leq q\leq p\leq \infty,1\leq r,s\leq \infty$ then             \|\Phi\otimes\id_{\mathcal{X}}\|_{(Q:q,P:p;\mathcal{X})\to(R:r,S:s;\mathcal{X})} = \|\Phi\|^+_{(Q:q:P:p)\to (R:r,S:s)},      where the superscript $^+$ denotes optimization over positive semidefinite operators.",2502.01611
theorem,"[Multiplicativity of ordered CB norms] Let $\cX, \cY$ be operator spaces and $1 \leq p,q \leq \infty$. Let $\Phi:\cS_q(\mathcal{H}_Q)\to \cS_p(\mathcal{H}_P),\Psi:\mathcal{X}\to \mathcal{Y}$ be CP maps, then  \|\Phi\otimes\Psi\|_{cb,S_q[\mathcal{H}_Q,\mathcal{X}]\to S_p[\mathcal{H}_P,\mathcal{Y}]} = \|\Phi\|_{cb,(Q:q)\to (P:p)}\|\Psi\|_{cb,\mathcal{X}\to \mathcal{Y}}.  And as a direct consequence, it holds for CP maps $\{\Phi_i:Q_i\to P_i\}$ and numbers $1\leq q_i,p_i\leq\infty$ that      \|\bigotimes_{i=1}^n\Phi_i\|_{cb,(Q_1:q_1,...,Q_n:q_n)\to (P_1:p_1,...,P_n:p_n)} = \prod_{i=1}^n\|\Phi_i\|^+_{cb,(Q_i:q_i)\to (P_i:p_i)}.",2502.01611
theorem,"[Multiplicativity of $q \to (q,p)-$CB-norms]   Let $1 \leq q,p \leq \infty$. Let $\Phi:Q_1\to R_1S_1$ and $\Psi:Q_2\to R_2S_2$ be two CP maps, then writing $Q^2:=Q_1Q_2$, $R^2=R_1R_2$, and $S^2=S_1S_2$, it holds that              \|\Phi\otimes\Psi\|_{cb,(Q^2:q)\to (R^2:q,S^2:p)} \leq \|\Phi\|^{+}_{cb,(Q_1:q)\to({R_1}:q,{S_1}:p)} \cdot \|\Psi\|^{+}_{cb,(Q_2:q)\to(R_2:q,{S_2}:p)}.               As a direct consequence, it holds for CP maps $\{\Phi_i:Q_i\to R_iS_i\}$ that         \bigg\|\bigotimes^n_{i=1}\Phi_i\bigg\|_{cb,(Q^n:q)\to (R^n:q,S^n:p)}\leq \prod_{i=1}^n\|\Phi_i\|_{cb,{Q_i}:q\to ({R_i}:q, {S_i}:p)},          where we denoted $Q^n:=Q_1...Q_n$, $R^n:=R_1...R_n, S^n:=S_1...S_n$.",2502.01611
theorem,"[Sequential composition of maps] Let $\Phi:Q_1\to R_1Q_2S_1, \Psi:Q_2\to R_2S_2$ be two CP maps and write $R^2:=R_1R_2$, $S^2:=S_1S_2$, then for any $1\leq q,r,s\leq\infty$      \|\Psi\circ\Phi\|_{cb,(Q_1:q)\to(R^2:r,S^2:s)} &\leq \|\Psi\|^{+}_{cb,(Q_2:q)\to(R_2:r,S_2:s)} \cdot \|\Phi\|^{+}_{cb,(Q_1:q)\to(R_1:r,Q_2:q,S_1:s)}.",2502.01611
theorem,"[Multiplicativity of restricted CB $1\to (1,p)$ norms] Let $n$ CP maps $\Phi_i:Q_i\to R_iS_i$ such that $\|\Phi_i\|_{cb,(Q_i:1)\to(R_i:1,S_i:p)}<\infty$ and $n$ linear restrictions governed by triples $r_i:=(Q_i^\prime,\mathcal{N}_i,\tau_i)$ be given. Denote the combined spaces $Q^n:=Q_1...Q_n$, $R^n:=R_1...R_n$, and $S^n:=S_1...S_n$ and the combined linear restriction as $r^n:=(\otimes_{i=1}^n\mathcal{N}_i,\otimes_{i=1}^n\tau_i)$. Then it holds that                       \bigg\| \bigotimes_{i=1}^n \Phi_i\bigg\|_{r^n,cb,(Q^n:1)\to (R^n:1,S^n:p)}              &\leq \prod^n_{i=1} \| \Phi_i\|_{r_i,cb,(Q_i:1)\to (R_i:1,S_i:p)}\,.",2502.01611
theorem,"[Time-adaptive protocol]          Let $\mathcal{M}^n$ be a family of protocols as defined in subsection~\ref{subsec:protocol_definition} and let $\rho^{\mathrm{hon}}_{Q_t} \in \cD(\cH_{Q_t})$ for $t \in \mathbb{N}$ be a family of quantum states such that $\{(\mathcal M_t,\mathcal N_t,\mathcal \tau_i,q^{\mathrm{hon}}_{X_t})|t\in \mathbb N\}$ is a finite set and $\rho^{\mathrm{hon}}_{Q_t}> 0$ for all $t\in \mathbb N$. Then there exists a family of functions $g_n : \mathbb{X}^n\to \mathbb{R}$ which, for all $n$, lead to an $\epsilon_n$-secure protocol, so that $\lim_{n\to \infty} \epsilon_n = 0$ and                \lim_{n\to \infty} \mathrm{rate}(\mathcal P_n, g_n,q^{\mathrm{hon}}_{X^n}) = \lim_{n \to \infty} \frac{1}{n} \sum_{t=1}^n h(\mathcal M_t,\mathcal N_t,\tau_t,q_{X_t}^{\mathrm{hon}})= r_{ad}\,.",2502.01611
definition,"A linear space $\mathcal{X}$ with a family of norms $\|\cdot \|_{m,n}$ on $M_{m,n}(\mathcal X)$ that satisfy the above properties (i) and (ii) is called an \textit{(abstract) operator space}.",2502.01611
definition,"[Explicit operator space] %An (explicit) operator space $\mathcal{X}$ is a, in operator norm closed, subspace of $\mathcal{B}(\mathcal{K})$, where $\mathcal{K}$ is some Hilbert space.     %",2502.01611
definition,"[Explicit operator space] %An (explicit) operator space $\mathcal{X}$ is a, in operator norm closed, subspace of $\mathcal{B}(\mathcal{K})$, where $\mathcal{K}$ is some Hilbert space.     %",2502.01611
definition,"[Restricted state spaces]     Let $\mathcal{H}_Q$ be the Hilbert space of a quantum system. Then we specify a linear constraint on $\mathcal{D}(\mathcal{H}_Q)$ by a linear CPTP map $\mathcal{N}:Q\to Q^\prime$ and a state $\tau\in\mathcal{D}(\mathcal{H}_{Q^\prime})$, where $Q^\prime$ is some other quantum system.  Given such a tuple $r=(\mathcal{N},\tau)$ we define      \mathcal{D}_r(\cH_Q) := \{\rho \in \Pos(Q)|\mathcal N(\rho) = \tau\Tr[\rho]\}.          More generally, let $\{\mathcal{D}_{r_i}(\cH_{Q_i})\}_{i\leq n}$ be $n$ such restricted sets of states defined in terms of the tuples $r^n=\{r_i\}_{i=1}^n=\{(\mathcal N_i,\tau_i)\}^n_{i=1}$ and $E$ any other quantum system. Then we define      \mathcal{D}^E_{r^n}(\cH_{Q^n})= \left\{ \rho\in \Pos(EQ^n)|\textstyle\left(\bigotimes_{i\leq n}\mathcal N_i\right) \circ \tr_E[\rho] = \textstyle\bigotimes_{i\leq n}\tau_i\Tr[\rho]\right\}.",2502.01611
definition,"[Restricted CB-norms] Let $r:=(\mathcal{N},\tau)$ define a linear restriction and $\Phi:Q\to RS$ be a CP map, then we define the \textit{restricted completely bounded norm} of $\Phi$ as  \|\Phi\|_{r,cb,(Q:q)\to(R:r,S:s)}:=\sup_E\sup_{\rho\in \mathcal{D}_r^E(\cH_Q)}\frac{\|(\id_E\otimes\Phi)(\rho)\|_{(E:q,R:r,S:s)}}{\|\rho\|_{(E:q,Q:q)}}.",2502.01611
proof,"The first claim follows via isometric invariance of the Schatten norms,  \|UXV\|_{\mathcal{S}_p[\mathcal{K},\mathcal{X}]} &= \inf_{\underset{UXV=FYG}{F,G\in \mathcal{S}_{2p}(\mathcal{K}), Y\in \mathcal{S}_\infty[\mathcal{K},\mathcal{X}]}}\|F\|_{2p}\|Y\|_{\mathcal{S}_\infty[\mathcal{K},\mathcal{X}]}\|G\|_{2p} \\ &= \inf_{\underset{X=(U^*F)Y(GV^*)}{F,G\in \mathcal{S}_{2p}(\mathcal{K}), Y\in \mathcal{S}_\infty[\mathcal{K},\mathcal{X}]}}\|F\|_{2p}\|Y\|_{\mathcal{S}_\infty[\mathcal{K},\mathcal{X}]}\|G\|_{2p}  \\ &= \inf_{\underset{X=F^\prime YG^\prime}{F^\prime,G^{\prime*}\in \mathcal{S}_{2p}(\mathcal{K},\mathcal{H}), Y\in \mathcal{S}_\infty[\mathcal{H},\mathcal{X}]}}\|F^\prime\|_{2p}\|Y\|_{\mathcal{S}_\infty[\mathcal{K},\mathcal{X}]}\|G^\prime\|_{2p} \\   &= \|X\|_{\mathcal{S}_p[\mathcal{H},\mathcal{X}]},  where in the third line we redefined $F^\prime=U^*F\in\mathcal{S}_{2p}(\mathcal{K},\mathcal{H})$ and used that they have identical Schatten-$2p$-norms. The fourth line follows from the comment above on non-square $F,G$.  \medskip  \noindent To prove the second statement, we let $X\in\mathcal{S}_{p}[\mathcal{H},\mathcal{X}]$, assuming $\dim\mathcal{H}<\infty$. Then, similarly to above, observe that  \|X\|_{\mathcal{S}_p[\mathcal{H},\mathcal{X}]} &= \inf_{\underset{F,G,Y  \text{ s.t. } X=FYG}{F,G\in \mathcal{S}_{2p}(\mathcal{H}), Y\in \mathcal{S}_\infty[\mathcal{H},\mathcal{X}]}}\|F\|_{2p}\|Y\|_{\mathcal{S}_\infty[\mathcal{H},\mathcal{X}]}\|G\|_{2p} \\      &= \inf_{\underset{F,G,Y  \text{ s.t. }X=P_F(UYV)P_G}{F,G\in \mathcal{S}_{2p}(\mathcal{H}), Y\in \mathcal{S}_\infty[\mathcal{H},\mathcal{X}]}}\|P_F\|_{2p}\|Y\|_{\mathcal{S}_\infty[\mathcal{H},\mathcal{X}]}\|P_G\|_{2p} \\  &= \inf_{\underset{F,G,Y  \text{ s.t. }X=P_FYP_G}{F,G\in \mathcal{S}_{2p}(\mathcal{H}), Y\in \mathcal{S}_\infty[\mathcal{H},\mathcal{X}]}}\|P_F\|_{2p}\|Y\|_{\mathcal{S}_\infty[\mathcal{H},\mathcal{X}]}\|P_G\|_{2p},  where in the second line we set $F=P_FU$ and $G=VP_G$ to be the right-, respectively, left-polar decompositions of $F,G$, such that $P_F,P_G\geq 0$. For the third equality we used the above and renamed $UYV$ to $Y$. Denote with $P_F^{-1},P_G^{-1}$ their Moore-Penrose inverses and with $\Pi_F:=P_FP_F^{-1}=P_F^{-1}P_F$ the projection onto the support of $P_F$, and analogously for $G$.  Now for a triple $(F,G,Y)$ that occurs in the infimum we define $\tilde{Y}:=\Pi_FY\Pi_G$. Then by \cref{prop:central.properties.OSnorms} $i)$, see also \cite[Lemma 1.6]{Book.Pisier.1998}, it follows that  \|\Pi_FY\Pi_G\|_{\mathcal{S}_\infty[\mathcal{H},\mathcal{X}]} \leq \|Y\|_{\mathcal{S}_\infty[\mathcal{H},\mathcal{X}]},  since $\|\Pi_F\|,\|\Pi_G\|\leq 1$. Hence it holds that      \|X\|_{\mathcal{S}_p[\mathcal{H},\mathcal{X}]} \geq     \inf_{\underset{F,G,Y  \text{ s.t. }X=P_FYP_G}{F,G\in \mathcal{S}_{2p}(\mathcal{H}), Y\in \mathcal{S}_\infty[\mathcal{H},\mathcal{X}]}}\|P_F\|_{2p}\|\Pi_FY\Pi_G\|_{\mathcal{S}_\infty[\mathcal{H},\mathcal{X}]}\|P_G\|_{2p}.  On the other hand for any suitable triple $(F,G,Y)$ it follows that      X=P_FYP_G=P_F\Pi_FY\Pi_GP_G=P_F\tilde{Y}P_G,  hence $(F,G,\Pi_FY\Pi_G)$ is also a compatible triple. Since we have by definition an injection from suitable triples $(F,G,Y)$ to ones $(F,G,\Pi_FY\Pi_G)$ it follows that       \|X\|_{\mathcal{S}_p[\mathcal{H},\mathcal{X}]} \leq     \inf_{\underset{  X=P_FYP_G}{F,G\in \mathcal{S}_{2p}(\mathcal{H}), Y\in \mathcal{S}_\infty[\mathcal{H},\mathcal{X}]}}\|P_F\|_{2p}\|\Pi_FY\Pi_G\|_{\mathcal{S}_\infty[\mathcal{H},\mathcal{X}]}\|P_G\|_{2p}.  So overall we have shown equality. Now by construction we further have    P_F^{-1}XP_G^{-1} = \Pi_FY\Pi_G=\tilde{Y}   and in total we get     \|X\|_{\mathcal{S}_p[\mathcal{H},\mathcal{X}]} &= \inf_{P_F,P_G\in \mathcal{S}_{2p}(\mathcal{H}), P_F,P_G\geq 0}\|P_F\|_{2p}\|P_F^{-1}XP_G^{-1}\|_{\mathcal{S}_\infty[\mathcal{H},\mathcal{X}]}\|P_G\|_{2p} \\ &=\inf_{\underset{\|F\|_1=\|G\|_1=1}{F,G\ge 0}}\|F^{-\frac{1}{2p}}XG^{-\frac{1}{2p}}\|_{\mathcal{S}_\infty[\mathcal{H},\mathcal{X}]}\,,  which is what we wanted to show.",2502.01611
proof,"In case that $d:=\dim\mathcal{H}<\infty$ the first statement follows from \cref{cor:Pisier.Formula}:       \|A\otimes X\|_{S_q[\mathcal{H},\mathcal{X}]} &= \inf_{F,G\in\mathcal{S}_{2q}(\mathcal{H}), F,G\geq0}\|F\|_{2q}\|G\|_{2q}\|F^{-1}AG^{-1}\otimes X\|_{\mathcal{S}_\infty[\mathcal{H},\mathcal{X}]} \\     &=\inf_{F,G\in\mathcal{S}_{2q}(\mathcal{H}), F,G\geq0}\|F\|_{2q}\|G\|_{2q}\|F^{-1}AG^{-1}\|_\infty\|X\|_{\mathcal{X}} \\     &= \|A\|_q\|X\|_\mathcal{X}.   Here in the second line we used that $\|B\otimes X\|_{S_\infty[\mathcal{H},\mathcal{X}]}=\|B\otimes X\|_{M_d(\mathcal{X})}=\|B\|_{M_d(\mathbb{C})}\|X\|_\mathcal{X}= \|B\|_\infty\|X\|_\mathcal{X}$, which follows from \cref{prop:central.properties.OSnorms} and the definition of the $M_d(\mathcal{X})$ norm.  Alternatively this also follows by assuming without loss of generality that $A$ is block-diagonal, since else we may absorb SVD-unitaries into the norm by \cref{cor:Pisier.Formula}, and applying \cite[Corollary 1.3]{Book.Pisier.1998}. The second statement now follows directly by induction:     \bigg\|\bigotimes_{i=1}^k X_i\bigg\|_{(A_1:q_1,...,A_k:q_k)} &=   \bigg\|X_1\otimes \bigotimes_{i=2}^{k} X_i\bigg\|_{S_{q_1}[\mathcal{H}_{A_1},\,\mathcal{X}]}     = \|X_1\|_{q_1} \bigg\|\bigotimes_{i=2}^k X_i\bigg\|_{(A_2:q_2,...,A_k:q_k)},  where we used $\mathcal{X}=S_{q_2}[\mathcal{H}_{A_2}...\,\mathcal{S}_{q_k}(\mathcal{H}_{A_k})]...]$.",2502.01611
proof,"We have        \|\Phi\circ\Psi\|_{cb,\mathcal{X}\to\mathcal{Z}} &= \sup_{E,X}\frac{\|(\id_E\otimes\Phi)\circ(\id_E\otimes\Psi)(X)\|_{\mathcal{S}_t[\mathcal{H}_E,\mathcal{Z}]}}{\|X\|_{\mathcal{S}_t[\mathcal{H}_E,\mathcal{X}]}} \\    &= \sup_{E,X}\frac{\|(\id_E\otimes\Phi)(Y)\|_{\mathcal{S}_t[\mathcal{H}_E,\mathcal{Z}]}}{\|Y\|_{\mathcal{S}_t[\mathcal{H}_E,\mathcal{Y}]}} \frac{\|(\id_E\otimes \Psi)(X)\|_{\mathcal{S}_t[\mathcal{H}_E,\mathcal{Y}]}}{\|X\|_{\mathcal{S}_t[\mathcal{H}_E,\mathcal{X}]}} \\    &\leq \|\Phi\|_{cb,\mathcal{Y}\to\mathcal{Z}} \cdot \|\Psi\|_{cb,\mathcal{X}\to\mathcal{Y}} ,      where in the second line we set $Y:=(\id_E\otimes\Psi)(X)$, and in the last line we split the supremum and used the definition of the CB norms.",2502.01611
proof,"We will prove (i) by separately showing upper and lower bounds and (ii) will then follow by duality.  Note that to keep notations short and as done before, we omit writing identity operators, e.g. for $F,G\in \mathcal{S}_{2r}(\mathcal{H})$ and $Y\in \mathcal{S}_\infty[\mathcal{H},\mathcal{X}]$ we will write $FYG\equiv(F\otimes\1)Y(G\otimes\1)$.  \medskip      (i) Let $X=FYG\in \mathcal{S}_p[\mathcal{H},\mathcal{X}]$ with $F,G\in \mathcal{S}_{2r}(\mathcal{H}),Y\in \mathcal{S}_q[\mathcal{H},X]$ and suppose $Y=HZK$ with $H,K\in \mathcal{S}_{2q}(\mathcal{H}), Z\in \mathcal{S}_\infty[\mathcal{H},{\mathcal{X}}]$, then $X=FH Z KG$ and by H\""{o}lder's inequality $\|FH\|_{2p}\leq \|F\|_{2r}\|H\|_{2q}$, since $\frac{1}{p}=\frac{1}{r}+\frac{1}{q}$, we get $FH,KG\in \mathcal{S}_{2p}(\mathcal{H})$. Hence      \|X\|_{\mathcal{S}_p[\mathcal{H},\mathcal{X}]}&\leq \|FH\|_{2p}\|Z\|_{\mathcal{S}_\infty[\mathcal{H},\mathcal{X}]}\|KG\|_{2p} \\&\leq \|F\|_{2r}\|\|H\|_{2q}\|Z\|_{\mathcal{S}_\infty[\mathcal{H},\mathcal{X}]}\|K\|_{2q}\|G\|_{2r}\,.            After minimization over $H,K,Z$, we obtain      \|X\|_{\mathcal{S}_p[\mathcal{H},\mathcal{X}]} \leq \|F\|_{2r}\|Y\|_{\mathcal{S}_q[\mathcal{H},\mathcal{X}]}\|G\|_{2r} \implies  \|X\|_{\mathcal{S}_p[\mathcal{H},\mathcal{X}]} \leq \inf_{\substack{F,G\in \mathcal{S}_{2r}\\Y\in \mathcal{S}_q[\mathcal{H},\mathcal{X}]}}\|F\|_{2r}\|Y\|_{\mathcal{S}_q[\mathcal{H},\mathcal{X}]}\|G\|_{2r}\,.           On the other hand, let $\epsilon>0$. Then there exists $Y\in \mathcal{S}_\infty[\mathcal{H},\mathcal{X}]$ and $F,G\in \mathcal{S}_{2p}(\mathcal{H})$ such that $X=FYG$ and       \|X\|_{\mathcal{S}_p[\mathcal{H},\mathcal{X}]}+\epsilon=\|F\|_{2p}\|Y\|_{\mathcal{S}_\infty[\mathcal{H},\mathcal{X}]}\|G\|_{2p}\,.          By performing a polar decomposition of $F$ and $G$ and absorbing the unitaries into $Y$, which does not change the norm, we may assume $F,G$ to be positive semidefinite and thus $F^{\frac{p}{q}},G^{\frac{p}{q}}\in \mathcal{S}_{2q}(\mathcal{H})$ and $F^{\frac{p}{r}},G^{\frac{p}{r}}\in \mathcal{S}_{2r}(\mathcal{H})$. As a result, $X = F^{\frac{p}{r}} F^{\frac{p}{q}} Y G^{\frac{p}{q}} G^{\frac{p}{r}}$. Hence               \inf_{\substack{X=HWK\\H,K\in \mathcal{S}_{2r}(\mathcal{H}), W\in \mathcal{S}_q[\mathcal{H},\mathcal{X}], }}\|H\|_{2r}\|W\|_{\mathcal{S}_q[\mathcal{H},\mathcal{X}]}\|K\|_{2r} &\leq \|F^{\frac{p}{r}}\|_{2r}\|F^{\frac{p}{q}}YG^{\frac{p}{q}}\|_{\mathcal{S}_q[\mathcal{H},\mathcal{X}]}\|G^{\frac{p}{r}}\|_{2r} \\         &\leq \|F^{\frac{p}{r}}\|_{2r}\|F^{\frac{p}{q}}\|_{2q}\|Y\|_{\mathcal{S}_\infty[\mathcal{H},\mathcal{X}]}\|G^{\frac{p}{q}}\|_{2q}\|G^{\frac{p}{r}}\|_{2r} \\&=\|F\|_{2p}\|Y\|_{\mathcal{S}_\infty[\mathcal{H},\mathcal{X}]} \|G\|_{2p} = \|X\|_{\mathcal{S}_p[\mathcal{H},\mathcal{X}]}+\epsilon.          Since $\epsilon>0$ is arbitrary the claim follows.      \medskip      (ii) by the duality $\mathcal{S}_{q}[\mathcal{H},\mathcal{X}]^*=\mathcal{S}_{q^\prime}[\mathcal{H},\mathcal{X}^*]$, i.e. there is a complete isometry between these two operator spaces, where $1/q+1/q^\prime=1$ (see \cite[Proposition 4.3]{Beigi.2023}). For $1/p + 1/p^\prime = 1$, we have $1 \leq p^\prime \leq q^\prime$ and also $\frac{1}{r} = \frac{1}{p^\prime} - \frac{1}{q^\prime}$, we thus obtain          \|X\|_{\mathcal{S}_q[\mathcal{H},\mathcal{X}]}         &=\frac{|\Tr[Y^*X]|}{\|Y\|_{\mathcal{S}_{q\prime}[\mathcal{H},\mathcal{X}^*]}}\\         &\overset{\operatorname{(i)}}{=} \sup_Y\sup_{ Y = FZG}\frac{|\Tr[Y^*X]|}{\|F\|_{2r}\|G\|_{2r}\|Z\|_{\mathcal{S}_{p^\prime}[\mathcal{H},\mathcal{X}^*]}} \\ &=\sup_{F,G,Z}\frac{|\Tr[G^*Z^*F^*X]|}{\|F\|_{2r}\|G\|_{2r}\|Z\|_{\mathcal{S}_{p^\prime}[\mathcal{H},\mathcal{X}^*]}}\\         &=\sup_{F,G,Z}\frac{|\Tr[Z^*(F^*XG^*)]|}{\|F\|_{2r}\|G\|_{2r}\|Z\|_{\mathcal{S}_{p^\prime}[\mathcal{H},\mathcal{X}^*]}}\\ &=\sup_{F,G}\frac{\|FXG\|_{\mathcal{S}_p[\mathcal{H},\mathcal{X}]}}{\|F\|_{2r}\|G\|_{2r}}.",2502.01611
proof,"The proof follows from the multiplicativity of the Schatten-$s$-norm and the fact that relating the $(p,q,s)$ to the $(s,s,s)$ norm can be done by only affecting the first two systems.  Depending on the order of $p,q,s$ we apply the corresponding variational formula from \cref{cor:variationalFormula.2}. In the case of $1\leq s\leq q\leq p\leq \infty$ we get     \|Y_{12}\otimes Z_3\|_{(1:p,2:q,3:s)} &= \sup_{G_{12},F_{12}}\|G^*G\|^{-\frac{1}{2}}_{(1:r,2:r^\prime)}\|FF^*\|^{-\frac{1}{2}}_{(1:r,2:r^\prime)}\|G_{12}Y_{12}F_{12}\otimes Z_3\|_s \\&= \sup_{G_{12},F_{12}}\|G^*G\|^{-\frac{1}{2}}_{(1:r,2:r^\prime)}\|FF^*\|^{-\frac{1}{2}}_{(1:r,2:r^\prime)}\|G_{12}Y_{12}F_{12}\|_s \cdot\|Z_3\|_s \\ &= \|Y\|_{1:p,2:q}\|Z\|_s.  In the case $1\leq p\leq q\leq s$ we can by an argument as in \cref{cor:Pisier.Formula} assume $G,F\geq 0$ and apply the same as above now to $\|G_{12}^{-1}Y_{12}F^{-1}_{12}\otimes Z_3\|_s=\|G_{12}^{-1}Y_{12}F^{-1}_{12}\|_{s}\cdot\|Z_3\|_s$.",2502.01611
proof,"[Proof of \cref{cor:variationalFormula.2}] The proof consists of repeated applications of \cref{thm:VariationalSpOperatorspace} combined with simplifications due to \cref{thm:2.pisier.variational.expressions}. The first formula follows from \cref{thm:VariationalSpOperatorspace} (i), first with $\mathcal{X} = \mathcal{S}_q[\mathcal{H}_2,\mathcal{S}_s(\mathcal{H}_1)]$ and then with $\mathcal{X} = \mathcal{S}_s(\mathcal{H}_3)$: %Define $\frac{1}{\alpha}=\frac{1}{p}-\frac{1}{q}$ %$\frac{1}{r^\prime}=\frac{1}{q}-\frac{1}{s} $, %and apply \cref{thm:VariationalSpOperatorspace} i) with $\mathcal{X} = \mathcal{S}_q[\mathcal{H}_2,\mathcal{S}_s(\mathcal{H}_1)]$ to get    \notag \|X\|_{(1:p,2:q,3:s)} &= \inf_{X_{123} =F_1Y_{123}G_1} \|F\|_{2\alpha}\|G\|_{2\alpha}\|Y\|_{(q:1,q:2,s:3)} \\ &= \inf_{X_{123} =F_1Y_{123}G_1} \|F\|_{2\alpha}\|G\|_{2\alpha}\|Y\|_{(12:q,3:s)}  \\ &= \inf_{ X_{123}=F_1 H_{12} Z_{123} K_{12} G_1} \|F\|_{2\alpha} \|G\|_{2\alpha} \|H\|_{2r^\prime} \|K\|_{2r^\prime} \|Z\|_s  \\&= \inf_{\substack{X_{123}=F_1H_{12}Z_{123}K_{12}G_1\\F_1, G_1\geq 0,H_{12},K_{12} }} \|F\|_{2\alpha} \|G\|_{2\alpha} \|HH^*\|^{\frac{1}{2}}_{r^\prime} \|K^*K\|^{\frac{1}{2}}_{r^\prime} \|Z\|_s  \\ &= \inf_{\substack{X_{123}=M_{12} Z_{123} N_{12}\\F_1,G_1\geq 0 }} \|F\|_{2\alpha} \|G\|_{2\alpha} \|F_1^{-1}M_{12}M_{12}^*F_1^{-1}\|^{\frac{1}{2}}_{r^\prime} \|G_1^{-1}N_{12}^*N_{12}G_1^{-1}\|^{\frac{1}{2}}_{r^\prime} \|Z\|_s \\ &= \inf_{ X_{123}=M_{12}Y_{123}N_{12}}\|M_{12}M_{12}^*\|^{\frac{1}{2}}_{(1:r,2:r^\prime)}\|N_{12}^*N_{12}\|^{\frac{1}{2}}_{(1:r,2:r^\prime)}\|Z\|_s          where in the fourth line we restricted to positive $F,G$ by polar decomposition, absorbed unitaries into $H,K$ respectively, and set $M\equiv FH$, $N\equiv KG$ and thus $H=F^{-1}M$, $K=NG^{-1}$, where these inverses respectively are the generalized Moore-Penrose inverses of $F,G$. There we also used that the Schatten norms of $H^*H$ and $HH^*$ are equal, since their non-zero singular values, which are equal to their eigenvalues, are equal.      In the last line, we used the expression of $\|\cdot\|_{(1:r,2:r^\prime)}$ given in~\cref{thm:expression-pq} and the fact that $\frac{1}{\alpha}=\frac{1}{r}-\frac{1}{r^\prime}=\frac{1}{p}-\frac{1}{q}$.  \medskip   The second formula follows analogously after applying Lemma \ref{thm:VariationalSpOperatorspace} (ii). We %write $\mathcal{H}_{12}=\mathcal{H}_1\otimes\mathcal{H}_2$ and  define $\frac{1}{\alpha}=\frac{1}{q}-\frac{1}{p}$.  &\|X\|_{(1:p,2:q,3:s)} \\ &\qquad = \sup_{F_1,G_1} \|F\|^{-1}_{2\alpha}\|G\|^{-1}_{2\alpha}\|F_1 X_{123}G_1\|_{(1:q,2:q,3:s)} \\   &\qquad =\sup_{\substack{0\leq F_1,G_1\\H_{12},K_{12}}}\|F\|^{-1}_{2\alpha}\|G\|^{-1}_{2\alpha}\|H\|^{-1}_{2r^\prime}\|K\|^{-1}_{2r^\prime}  \|H_{12}F_1X_{123}G_1K_{12}\|_s \\ &\qquad = \sup_{\substack{0\leq F_1,G_1\\ M_{12},N_{12} }}\|F\|^{-1}_{2\alpha}\|G\|^{-1}_{2\alpha}\|F_1^{-1}M_{12}^*M_{12}F_1^{-1}\|^{-\frac{1}{2}}_{2r^\prime}\|G_1^{-1}N_{12}N^*_{12}G_1^{-1}\|^{-\frac{1}{2}}_{r^\prime}  \|M_{12}X_{123}N_{12}\|_s \\  &\qquad =\!\!\!\sup_{ M_{12},N_{12}}\!\!\!\left(\inf_{0<F_1}\!\!\!\|F\|^2_{2\alpha}\|F_1^{-1}M_{12}^*M_{12}F_1^{-1}\|_{r^\prime}\!\!\right)^{\!\!\!-\frac{1}{2}}\!\!\left(\inf_{0<G_1}\!\!\!\|G\|^2_{2\alpha}\|G_1^{-1}N_{12}N_{12}^*G^{-1}_1\|_{r^\prime}\!\!\right)^{\!\!\!\!-\frac{1}{2}} \, \!\!\|M_{12}X_{123}N_{12}\|_s \\  &\qquad = \sup_{M_{12},N_{12}}\|M^*M\|^{-\frac{1}{2}}_{(1:r,2:r^\prime)}\|FF^*\|^{-\frac{1}{2}}_{(1:r,2:r^\prime)} \|M_{12}X_{123}N_{12}\|_s.",2502.01611
proof,"[Proof of \cref{cor:variationalFormula}] We split the proof into the cases $p\leq q$ and $p\geq q$. In the first case the claimed formula follows analogously to the first one in \cref{cor:variationalFormula.2}, when using Theorem \ref{thm:PisierOriginal} instead of Lemma \ref{thm:VariationalSpOperatorspace} $(i)$. Given $\frac{1}{\alpha}=\frac{1}{p}-\frac{1}{q}$, we get  \|X\|_{(1:p,2:q;\mathcal{X})} &{=} \inf_{ X=F_1Y_{123}G_1} \|F\|_{2\alpha}\|G\|_{2\alpha}\|Y\|_{(1:q,2:q;\mathcal{X})} \\ &= \inf_{X=F_1H_{12}Z_{123}K_{12}G_1} \|F\|_{2\alpha} \|G\|_{2\alpha} \|H\|_{2q} \|K\|_{2q} \|Z\|_{(1:\infty,2:\infty;\mathcal{X})} \\ &=  \inf_{ X=M_{12}Z_{123}N_{12}}\|MM^*\|^{\frac{1}{2}}_{(1:p,2:q)}\|N^*N\|^{\frac{1}{2}}_{(1:p,2:q)}\|Z\|_{(1:\infty,2:\infty;\mathcal{X})},   where we used Lemma \ref{thm:VariationalSpOperatorspace} (i) in the first line above, and skipped some steps since they are identical to those in the proof of the first formula above upon replacing $r^\prime\leftrightarrow q$ and keeping the last operator space $\mathcal{X}$ instead of $\mathcal{S}_s(\mathcal{H}_3)$. The inequality in the setting $p\geq q$ follows similarly as the above. Setting $\frac{1}{r}=\frac{1}{q}-\frac{1}{p}$, we have  &\|X\|_{(1:p,2:q;\mathcal{X})} \\ &\qquad = \sup_{F_1,G_1}\|F\|_{2r}^{-1}\|G\|_{2r}^{-1}\|F_1X_{123}G_1\|_{(1:q,2:q;\mathcal{X})} \\ &\qquad= \sup_{F_1,G_1}\|F\|_{2r}^{-1}\|G\|_{2r}^{-1} \inf_{F_1X_{123}G_1=H_{12}Z_{123}K_{12}}\|H\|_{2q}\|K\|_{2q}\|Z\|_{(1:\infty,2:\infty;\mathcal{X})} \\ &\qquad = \sup_{F_1,G_1\ge 0}\|F\|_{2r}^{-1}\|G\|_{2r}^{-1} \inf_{ F_1X_{123}G_1=H_{12}Z_{123}K_{12}}\|H\|_{2q}\|K\|_{2q}\|Z\|_{(1:\infty,2:\infty;\mathcal{X})} \\ &\qquad = \sup_{F_1,G_1\ge  0}\|F\|_{2r}^{-1}\|G\|_{2r}^{-1} \inf_{ X_{123}=F^{-1}_1H_{12}Z_{123}K_{12}G_1^{-1}}\|HH^*\|^{\frac{1}{2}}_{q}\|K^*K\|^{\frac{1}{2}}_{q}\|Z\|_{(1:\infty,2:\infty;\mathcal{X})}     \\     &\qquad = \sup_{F_1,G_1\ge 0}\|F\|_{2r}^{-1}\|G\|_{2r}^{-1} \inf_{ X_{123}=M_{12}Z_{123}N_{12}}\!\!\!\!\|F_1M_{12}M^*_{12}F_1\|^{\frac{1}{2}}_{q}\|G_1N^*_{12}N_{12}G_1\|^{\frac{1}{2}}_{q}\|Z\|_{(1:\infty,2:\infty;\mathcal{X})}     \\ &\qquad \leq \inf_{X_{123}=M_{12}Z_{123}N_{12}}\sup_{F_1\ge 0}\|F\|_{2r}^{-1}\|F_1M_{12}M^*_{12}F_1\|^{\frac{1}{2}}_{q}\!\sup_{G_1\ge  0}\|G\|_{2r}^{-1}\|G_1N^*_{12}N_{12}G_1\|^{\frac{1}{2}}_{q}\!\|Z\|_{(1:\infty,2:\infty;\mathcal{X})}     \\&\qquad = \inf_{ X_{123}=M_{12}Z_{123}N_{12}}\|MM^*\|^{\frac{1}{2}}_{(1:p,2:q)}\|N^*N\|^{\frac{1}{2}}_{(1:p,2:q)}\|Z\|_{(1:\infty,2:\infty,3:s)},   where the inequality arises from switching the supremum and infimum.",2502.01611
proof,"[Proof of \cref{cor:Chain.Rules}]  \noindent This follows directly from \cref{lem:reductionLemma} by setting $P$ trivial, $\mathcal{X}=S_\alpha(\mathcal{H}_T)$, and $p=q=r=1, s=\alpha> 1$ and applying $\frac{\alpha}{1-\alpha}\log$. The right-hand side becomes $$\inf_{\sigma \in \mathcal{D}(\mathcal{H}_Q)}  H^{\uparrow}_\alpha(S|R)_{\Phi(\sigma_{Q})}$$ and the left-hand side becomes $$\inf_{\rho_{QT}\geq 0}\left(  H^{\uparrow}_\alpha(ST|R)_{(\Phi \otimes \id_T)(\rho_{QT})} - H^{\uparrow}_\alpha(T|Q)_{\rho_{QT}}\right).$$",2502.01611
proof,"[Proof sketch of \cref{lem:gereralized.eat.chain.rule}] %The proof will be essentially upper bounding the non-cb norm of interest by the cb norm and then showing that it tensorizes. This tensorization are the last two inequalities below, is proved in \cref{app:other.proofs}. % %\|\psi_{Q\to X}\otimes\phi_{R\to A}\otimes\id_B\|_{(Q:1,B:\alpha,R:1)\to(X:1,A:\alpha,B:\alpha)} &\leq \|\psi\otimes\phi\otimes\id_B\|_{cb,(Q:1,B:\alpha,R:1)\to(X:1,A:\alpha,B:\alpha)} \\ &= \|\psi\otimes\id_B\otimes\phi\|_{cb,(Q:1,B:\alpha,R:1)\to(X:1,B:\alpha,A:\alpha)} \\ &= \|\psi\|_{cb,Q:1\to X:1}\|\id_B\|_{cb,B:\alpha\to B:\alpha}\|\phi\|_{cb,R:1\to A:\alpha} \\ &= \|\psi\otimes\phi\|_{cb,(R:1,Q:1)\to (X:1,A:\alpha)}. % %",2502.01611
proof,"[Proof of \cref{lem:reductionLemma}] First of all notice that $\|\Phi\otimes\id_{\mathcal{X}}\|_{(Q:q,P:p;\mathcal{X})\to(R:r,S:s;\mathcal{X})} \geq \|\Phi\|^+_{(Q:q,P:p)\to (R:r,S:s)}$, since we can just restrict the supremum on the left hand side over product operators. In fact, consider $X_{QP}\otimes Y_{\mathcal{X}}$, then by \cref{thm:VariationalSpOperatorspace} and multiplicativity of the operator-valued Schatten norms \cref{prop:spliting.systems.left.}, we obtain both   \|(\Phi\otimes\id_{\mathcal{X}})(X_{QP}\otimes Y_{\mathcal{X}})\|_{(R:r,S:s;\mathcal{X})} &= \|\Phi(X_{QP})\otimes Y_{\mathcal{X}}\|_{(R:r,S:s;\mathcal{X})}= \|\Phi(X_{QP})\|_{(R:r,S:s)}\cdot \|Y_{\mathcal{X}}\|_{\mathcal{X}}, \\  \|X_{QP}\otimes Y_\mathcal{X}\|_{(Q:q,P:p;\mathcal{X})} &= \|X\|_{(Q:q,P:p)}\cdot\|Y_\mathcal{X}\|_{\mathcal{X}}.   Now let $\1_\mathcal{X}$ be the identity element of $\mathcal{X}$. To prove the non-trivial side of the inequality, inspired by \cite[Proof of Lemma 5]{Devetak.2006}, we consider a Kraus representation of $\Phi$: $\Phi(\rho)=\sum^\nu_{i=1}K_i \rho K_i^*$. Then for a given $\rho\in\mathcal{S}_q[\mathcal{H}_Q,\mathcal{S}_p[\mathcal{H}_P,\mathcal{X}]]$, there exist for any $\epsilon>0$, by our extension of Pisier's formula in \cref{cor:variationalFormula} for this norm with $q\leq p$, operators $A,B,Y$, s.t. $\rho=(A_{QP}\otimes\1_\mathcal{X})Y(B_{QP}\otimes \1_\mathcal{X})$ and $ \|\rho\|_{(Q:q,P:p;\mathcal{X})}\geq \|AA^*\|^{\frac{1}{2}}_{(Q:q,P:p)}\|B^*B\|^{\frac{1}{2}}_{(Q:q,P:p)}\|Y\|_{(Q:\infty,P:\infty;\mathcal{X})}-\epsilon$. We have      (\Phi\otimes\id_\mathcal{X})(\rho) = \sum_{i=1}^\nu(K_i\otimes\1_\mathcal{X})\rho(K_i^*\otimes\1_\mathcal{X})=\sum_{i=1}^\nu(K_iA\otimes\1_\mathcal{X})Y(BK_i^*\otimes\1_\mathcal{X}) = V_A(\1_{\mathbb{C}^\nu}\otimes Y)V^*_B,  where $V_A= (K_1A\otimes\1_\mathcal{X},K_2A\otimes\1_\mathcal{X},...,K_\nu A\otimes\1_\mathcal{X})$ is a block row-vector with blocks $K_iA\otimes \1_\mathcal{X}$, and $V_B^*$ a block-column vector with blocks $BK_i^*\otimes\1_\mathcal{X}$, where we denote with $\nu$ the number of blocks and with $N$ the system in which these block live and on which $\1_{\mathbb{C}^\nu}$ acts.   %Like in \cite{Devetak.2006}  These operators $V_A, V_B$ can be embedded into the space $\mathcal{B}(\mathbb{C}^\nu\otimes\mathcal{H}_Q\otimes\mathcal{H}_P\otimes\mathcal{X},\mathbb{C}^\nu\otimes\mathcal{H}_R\otimes\mathcal{H}_S\otimes\mathcal{X})$ by padding suitably with rows of $0$ operators. For $V^*_A, V^*_B$ similarly into $\mathcal{B}(\mathbb{C}^\nu\otimes\mathcal{H}_R\otimes\mathcal{H}_S\otimes\mathcal{X},\mathbb{C}^\nu\otimes\mathcal{H}_Q\otimes\mathcal{H}_P\otimes\mathcal{X})$, by padding with columns of $0$ operators. Call these extended operators, respectively, $V_A^\prime, V_B^\prime, V_A^{\prime*} , V_B^{\prime*}$. We get $V^\prime_A=\sum^{\nu}_{i,j=1}\delta_{i1}|i\rangle\langle j|_N\otimes K_jA\otimes\1_\mathcal{X} \in \mathcal{B}(\mathbb{C}^\nu\otimes\mathcal{H}_Q\otimes\mathcal{X},\mathbb{C}^\nu\otimes\mathcal{H}_R\otimes\mathcal{H}_S\otimes\mathcal{X})$.  Hence it holds that $V^\prime_AV_A^{\prime *}=|1\rangle\langle1|_N\otimes V_AV_A^*$, similarly for $B$ and $V^\prime_A(\1_N\otimes Y)V_B^{\prime *}=|1\rangle\langle 1|_N\otimes (\Phi\otimes\id_X)(\rho)$.  Now using \cref{cor:variationalFormula} on the space $\mathcal{S}_r[\mathbb{C}^\nu\otimes\mathcal{H}_R,\mathcal{S}_s[\mathcal{H}_R,\mathcal{X}]]$ we get      \|(\Phi\otimes\id_B)(\rho_{QB})\|_{(R:r,S:s;\mathcal{X})} &= \||1\rangle\langle 1|_N\otimes(\Phi\otimes\id_\mathcal{X})(\rho_{QT})\|_{(N:r,R:r,S:s;\mathcal{X})} \\ %&=\|V^\prime_A(\1_\nu\otimes Y)V_A^{\prime *}\|_{(1_\nu,1_X,p_Q,p_B)}      &= \|V^\prime_A(\1_N\otimes Y)V_B^{\prime *}\|_{(NR:r,S:s;\mathcal{X})}       \\ &\leq \|V^\prime_AV_A^{\prime *}\|^{\frac{1}{2}}_{(NR:r,S:s)}\|V^\prime_BV_B^{\prime *}\|^{\frac{1}{2}}_{(NR:r,S:s)}\|\1_N\otimes Y\|_{(N:\infty,Q:\infty,P:\infty;\mathcal{X})} \\ &= \|\sum_iK_iAA^*K_i^*\|^{\frac{1}{2}}_{(R:r,S:s)}\|\sum_iK_iB^*BK_i^*\|^{\frac{1}{2}}_{(R:r,S:s)}\|Y\|_{(Q:\infty,P:\infty;\mathcal{X})} \\&= \|\Phi(AA^*)\|^{\frac{1}{2}}_{(R:r,S:s)}\|\Phi(B^*B)\|^{\frac{1}{2}}_{(R:r,S:s)} \|Y\|_{(Q:\infty,P:\infty;\mathcal{X})} \\&\leq  \|\Phi\|^+_{(Q:q,P:p)\to(R:r,S:s)}\|AA^*\|^{\frac{1}{2}}_{(Q:q,P:p)}\|B^*B\|^{\frac{1}{2}}_{(Q:q,P:p)}\|Y\|_{(Q:\infty,P:\infty;\mathcal{X})}%\\&=  \|\Phi\|^+_{(Q:q,P:p)\to(R:r,S:s)}\|A\|_{2q}\|B\|_{2q}\|Y\|_{\mathcal{S}_\infty[\mathcal{H}_Q,\mathcal{X}]}     \\&\leq \|\Phi\|^+_{(Q:q,P:p)\to(R:r,S:s)}(\|\rho\|_{(Q:q,P:p;\mathcal{X})}+\epsilon).  In the first and third equality, we used the multiplicativity of the operator-valued Schatten norms~\cref{prop:spliting.systems.left.}. In the second line, we combined systems of equal indices. Since $\epsilon$ was arbitrary the claim follows.",2502.01611
proof,"We have, using the above Lemma \ref{lem:reductionLemma} that               \|\Phi\otimes\id_{\cX}\|_{cb,(Q:q;\cX)\to (R:q,S:p;\cX)} &= \sup_E\|\underbrace{\id_E\otimes\Phi}_{=:\Psi_E}\otimes\id_B\|_{(E:q,Q:q;\cX)\to(E:q,R:q,S:p;\cX)}\\ &\equiv \sup_E\|\Psi_E\otimes\id_{\cX}\|_{(EQ:q;\cX)\to(ER:q,S:p;\cX)} \\&{=} \sup_E\|\Psi_E\|^+_{(EQ:q)\to(ER:q,S:p)}=\sup_E\|\id_E\otimes\Phi\|^+_{(E:q,Q:q)\to(E:q,R:q,S:p)}\\&= \|\Phi\|^+_{cb,(Q:q)\to(R:q,S:p)}.",2502.01611
proof,"[Proof of \cref{thm:general.multiplicativity}] This proof of the upper bound follows from a combination of \cref{lem:cb.norm.splitting} and \cref{lem:reductionLemma}.  We apply the former to the maps $\Phi\otimes\id_{\mathcal{Y}}:\mathcal{S}_q[\mathcal{H}_Q,\mathcal{Y}]\to \mathcal{S}_p[\mathcal{H_P,\mathcal{Y}}]$ and $(\id_Q\otimes\Psi):\mathcal{S}_q[\mathcal{H}_Q,\mathcal{X}]\to \mathcal{S}_q[\mathcal{H_Q,\mathcal{Y}}]$ to get  \|\Phi\otimes\Psi\|_{cb,S_q[\mathcal{H}_Q,\mathcal{X}]\to S_p[\mathcal{H}_P,\mathcal{Y}]} &\leq \|\Phi\otimes\id_\mathcal{Y}\|_{cb,\mathcal{S}_q[\mathcal{H}_Q,\mathcal{Y}]\to \mathcal{S}_p[\mathcal{H_P,\mathcal{Y}}]} \cdot \|\id_Q\otimes\Psi\|_{cb,\mathcal{S}_q[\mathcal{H}_Q,\mathcal{X}]\to \mathcal{S}_q[\mathcal{H_Q,\mathcal{Y}}]} \\ &=  \|\Phi\|^+_{cb,Q:q\to P:p}\cdot \|\Psi\|_{cb,\mathcal{X}\to\mathcal{Y}},  where the last line follows from \cref{lem:reductionLemma} and the absorption of the $\id_Q$ on the left is due to the definition of the CB norm. For the other inequality, for some system $E_1, E_2$, let $X_{E_1Q} \in \cS_p[\cH_{E_1}, \cS_q(\cH_{Q})]$ and $Y_{E_2 \cX} \in \cS_{p}[\cH_{E_2}, \cX]$.   Let $E=E_1E_2$, then  \|\Phi\otimes\Psi\|_{cb,S_q[\mathcal{H}_Q,\mathcal{X}]\to S_p[\mathcal{H}_P,\mathcal{Y}]} &\geq \|(\id_{E_1}\otimes\id_{E_2}\otimes\Phi\otimes\Psi)(X_{E_1Q}\otimes Y_{E_2\mathcal{X}})\|_{(E_1:p,E_2:p,P:p;\mathcal{Y})} \\     &= \|(\id_{E_1}\otimes\Phi)(X_{E_1Q})\otimes(\id_{E_2}\otimes\Psi)( Y_{E_2\mathcal{X}})\|_{(E_1:p,P:p,E_2:p;\mathcal{Y})} \\&= \|(\id_{E_1}\otimes\Phi)(X_{EQ})\|_{(E_1:p,P:p)}\cdot \|(\id_{E_2}\otimes\Psi)( Y_{E_2\mathcal{X}})\|_{(E_2:p;\mathcal{Y})},  where the last equality follows from \cref{prop:spliting.systems.left.} applied to $E_1P,E_2\mathcal{Y}$. Now taking the supremum over $X,Y$ and $E_1,E_2$ yields the claim.  The multiplicativity result for $n$ tensored CP maps follows now directly via induction. For simplicity denote with $Q^n_j:=Q_j...Q_n$ and with $q_j^n:=(q_j,...,q_n)$ and similarly for $P, p$. Now the above is the induction start and the step follows via  \bigg\|\bigotimes_{i=1}^n\Phi_i\bigg\|_{cb,(Q^n:q^n)\to (P^n:p^n)} &= \bigg\|\Phi_1\otimes\bigotimes_{i=2}^n\Phi_i\bigg\|_{cb,(Q_1:q_1,Q_2^n:q_2^n)\to (P_1:p_1,P_2^n:p_2^n)} \\      &=\|\Phi_i\|_{cb,(Q_1:q_1)\to (P_1:p_1)}\cdot \bigg\|\bigotimes_{i=2}^n\Phi_i\bigg\|_{cb,(Q_2^n:q_2^n)\to (P_2^n:p_2^n)},  where in the second line we used the above with $\mathcal{X}=\mathcal{S}_{q_2}[...\mathcal{S}_{q_n}(\mathcal{H}_{Q_n})...]$ and $\mathcal{Y}=\mathcal{S}_{p_2}[...\mathcal{S}_{p_n}(\mathcal{H}_{P_n})...]$.",2502.01611
proof,"We first establish~\eqref{equ:Generalized.EAT.product.norm}. By the fact that we can combine systems with the same parameter (\cref{prop:combining.systems}) and that the completely bounded norm is multiplicative (\cref{thm:general.multiplicativity}), we have  \| \Phi \otimes \id_{T} \|_{(Q_1:1,T:\alpha,Q_2:1)\to(R:1,S:\alpha,T:\alpha)}  &= \|\phi_{Q_1\to R}\otimes\id_T\otimes\psi_{Q_2\to S}\|_{(Q_1:1,T:\alpha,Q_2:1)\to(R:1,S:\alpha,T:\alpha)} \\ &= \|\phi_{Q_1\to R}\otimes\id_T\otimes\psi_{Q_2\to S}\|_{(Q_1:1,T:\alpha,Q_2:1)\to(R:1,T:\alpha,S:\alpha)} \\ &\leq \|\phi_{Q_1\to R}\otimes\id_T\otimes\psi_{Q_2\to S}\|_{cb,(Q_1:1,T:\alpha,Q_2:1)\to(R:1,T:\alpha,S:\alpha)} \\ &= \|\phi\|_{cb,(Q_1:1) \to (R:1)} \|\id_T\|_{cb,T:\alpha \to T:\alpha} \|\psi_{Q_2\to S}\|_{cb,(Q_2:1) \to (S:\alpha)} \\ &= \|\phi \otimes \psi\|_{cb,(Q_1:1,Q_2:1) \to (R:1,S:\alpha)} \\ &= \| \Phi \|_{cb,(Q_1:1,Q_2:1) \to (R:1,S:\alpha)} = \| \Phi \|_{cb,(Q_1Q_2:1) \to (R:1,S:\alpha)}^+\,. %\leq \|\psi\otimes\phi\otimes\id_B\|_{cb,(Q:1,B:\alpha,R:1)\to(X:1,A:\alpha,B:\alpha)} \\ &= \|\psi\otimes\id_B\otimes\phi\|_{cb,(Q:1,B:\alpha,R:1)\to(X:1,B:\alpha,A:\alpha)} \\ &= \|\psi\|_{cb,Q:1\to X:1}\|\id_B\|_{cb,B:\alpha\to B:\alpha}\|\phi\|_{cb,R:1\to A:\alpha} \\ &= \|\psi\otimes\phi\|_{cb,(R:1,Q:1)\to (X:1,A:\alpha)}.  We now show how to deduce the chain rule~\eqref{equ:Generalized.EAT.product}. As before, $\frac{\alpha}{1-\alpha} \log \| \Phi \|_{cb,(Q_1:1,Q_2:1) \to (R:1,S:\alpha)} = \inf_{\sigma \in \mathcal{D}(\cH_{Q_1Q_2} \otimes \cH_{\tilde{Q}})} H_{\alpha}^{\uparrow}(S|R\tilde{Q})$. Moreover, given a positive semidefinite matrix $\rho_{Q_1Q_2T}$, we have that $H_{\alpha}^{\uparrow}(T|Q_1)_{\rho} = \frac{\alpha}{1-\alpha} \log \| \rho \|_{(Q_1:1,T:\alpha, Q_2:1)}$ because $\| \rho \|_{(Q_1:1,T:\alpha, Q_2:1)} = \|\tr_{Q_2} \rho_{Q_1TQ_2} \|_{(Q_1:1,T:\alpha)}$ as proved in~\cite[Section 3.5]{Devetak.2006}. Furthermore, $H_{\alpha}^{\uparrow}(ST|R)_{(\Phi \otimes \id_T)(\rho)} = \frac{\alpha}{1-\alpha} \log \|(\Phi \otimes \id_T)(\rho)\|_{(R:1,S:\alpha,T:\alpha)}$.",2502.01611
proof,"[Proof of \cref{thm:mainchainrule}] Note that we may assume that all the norms are finite, otherwise the equality clearly holds. We apply \cref{lem:cb.norm.splitting} and write $\Phi \otimes \Psi$ as a composition of four maps, since the order in the multi-index norm we are considering does not respect the tensor product structure of the maps: $\Phi \otimes \Psi.$ We write it as $(F_{R_1\leftrightarrow R_2}\otimes\id_{S_1S_2})\circ(\id_{R_2} \otimes \Phi \otimes \id_{S_2}) \circ (F_{Q_1 \leftrightarrow R_2} \otimes \id_{S_2}) \circ (\id_{Q_1} \otimes \Psi)$. Note that we wrote the swap explicitly to emphasize the order in the multi-index Schatten norms that we use. For additional clarity, we specify the operator spaces for each map: The input operator space for $(\id_{Q_1} \otimes \Psi)$ is $\cX_1 = \cS_q[\cH_{Q_1},\cS_q(\cH_{Q_2})]$ and the output is $\cX_2 = \cS_q[\cH_{Q_1}, \cS_{q}[\cH_{R_2}, \cS_{p}(\cH_{S_2})]]$. The output operator space of $(F_{Q_1 \leftrightarrow R_2} \otimes \id_{S_2})$ is $\cX_3 = \cS_q[\cH_{R_2}, \cS_{q}[\cH_{Q_1}, \cS_{p}(\cH_{S_2})]]$ and the output operator space of $(\id_{R_2} \otimes \Phi \otimes \id_{S_2})$ is $\cX_4 = \cS_q[\cH_{R_2}, \cS_{q}[\cH_{R_1}, \cS_{p}[\cH_{S_1}, \cS_{p}(\cH_{S_2})]]]$. The last map now maps $\mathcal{X}_4$ into $\mathcal{X}_5:=\cS_q[\cH_{R_1}, \cS_{q}[\cH_{R_2}, \cS_{p}[\cH_{S_1}, \cS_{p}(\cH_{S_2})]]]$. It now remains to bound the CB norm of each one of these three maps. First, by definition of the CB norm, we have \[ \| (\id_{Q_1} \otimes \Psi) \|_{cb,\cX_1 \to \cX_2} = \| \Psi \|_{cb, \cS_q(\cH_{Q_2}) \to \cS_{q}[\cH_{R_2}, \cS_{p}(\cH_{S_2})]}. \] Second, using the fact that the swap between systems of equal Schatten indices is a complete isometry and its CB norm is not affected by an identity on the right~\eqref{equ:SWAP.isometry} gives   \|F_{Q_1 \leftrightarrow R_2} \otimes \id_{S_2} \|_{cb, \cX_2 \to \cX_3} &= 1, \\  \|F_{R_1\leftrightarrow R_2}\otimes\id_{S_1S_2}\|_{cb,\mathcal{X}_4\to\mathcal{X}_5} &= 1.  Third, using \cref{Cor:rightIdentity} and also the definition of the completely bounded norm \[ \| \id_{R_2} \otimes \Phi \otimes \id_{S_2} \|_{cb,\cX_3 \to \cX_4} = \| \Phi \|_{cb,\cS_q(\cH_{Q_1}) \to \cS_{q}[\cH_{R_1},\cS_p(\cH_{S_1})]}. \] Finally, we get  \|\Phi\otimes\Psi\|_{cb,(Q_1:q,Q_2:q)\to(R_1:q,R_2:q,S_1:p,S_2:p)} %\\ &= \|F_{R_1\leftrightarrow R_2}\circ(\Phi\otimes\id_{R_2S_2})\circ F_{Q_1\leftrightarrow R_2}\circ(\id_{Q_1}\otimes\Psi)\|_{cb,(Q_1:1,Q_2:1)\to(R_1:1,R_2:1,S_1:p,S_2:p)}  \\  %&\leq \|F_{R_1\leftrightarrow R_2}\|_{cb,(R_2:1,R_1:1,S_1:p,S_2:p)\to(R_1:1,R_2:1,S_1:p,S_2:p)} \\ &\qquad\times\|(\id_{R_2}\otimes\Phi\otimes\id_{S_2})\|_{cb,(R_2:1,Q_1:1,S_2:p)\to(R_2:1,R_1:1,S_1:p,S_2:p)} \\ &\qquad\times\|F_{Q_1\leftrightarrow R_2}\|_{cb,(Q_1:1,R_2:1,S_2:p)\to(R_2:1,Q_1:1,S_2:p)} \\ &\qquad\times\|(\id_{Q_2}\otimes\Psi)\|_{cb,(Q:1)\to(Q_1:1,R_2:1,S_2:p)} \\ \leq \|\Phi\|_{cb,Q_1:q\to(R_1:q,S_1:p)} \cdot \|\Psi\|_{cb,Q_2:q\to(R_2:q,S_2:p)}.   %%% Old proof: %  %             \|\Phi\otimes\Psi\|&_{cb,(Q_1:1,Q_2:1)\to(R_1:1,R_2:1,S_1:p,S_2:p)} = \sup_d\sup_{\rho_d}\frac{\|(\id_d\otimes\Phi\otimes\Psi)(\rho_d)\|_{(E:1,R_1:1,R_2:1,S_1:p,S_2:p)}}{\|\rho_d\|_{(E:1,Q_1:1,Q_2:1)}}  %             \\&= \sup_d\sup_{\rho_d}\frac{\|(\id_d\otimes\Phi\otimes\id_{R_2}\otimes\id_{S_2})(\sigma_d)\|_{(E:1,R_1:1,R_2:1,S_1:p,S_2:p)}}{\|\sigma_d\|_{(E:1,R_2:1,Q_1:1,S_2:p)}}\frac{\|\sigma_d\|_{(E:1,R_2:1,Q_1:1,S_2:p)}}{\|\sigma_d\|_{(E:1,Q_1:1,R_2:1,S_2:p)}}\\ &\hspace{4cm} \times \frac{\|(\id_d\otimes\id_{Q_1}\otimes\Psi)(\rho_d)\|_{(E:1,Q_1:1,R_2:1,S_2:p)}}{\|\rho_d\|_{(E:1,Q_1:1,Q_2:1)}} \\ %             &=\sup_d\sup_{\rho_d}\frac{\|(\id_d\otimes\id_{R_2}\otimes\Phi\otimes\id_{S_2})(\sigma_d)\|_{(E:1,R_2:1,R_1:1,S_1:p,S_2:p)}}{\|\sigma_d\|_{(E:1,R_2:1,Q_1:1,S_2:p)}}  \\ &\hspace{4cm} \times\frac{\|(\id_d\otimes\id_{Q_1}\otimes\Psi)(\rho_d)\|_{(E:1,Q_1:1,R_2:1,S_2:p)}}{\|\rho_d\|_{(E:1,Q_1:1,Q_2:1)}}  %             \\ &\leq \|\Phi\otimes\id_{S_2}\|_{cb,(Q_1:1,S_2:p)\to(R_1:1,S_1:p,S_2:p)} \cdot \|\Psi\|_{cb,Q_2:1\to(R_2:1,S_2:p)} \\&\leq \|\Phi\|_{cb,Q_1:1\to(R_1:1,S_1:p)} \cdot \|\Psi\|_{cb,Q_2:1\to(R_2:1,S_2:p)}, %  where in the second line we defined $\sigma_d:=(\id_d\otimes \id_{Q_1}\otimes \Psi)(\rho_d)$, and in the third used that the swap operator is a complete contraction and in particular swapping two systems with the same Pisier-index is an isometry, see \eqref{equ:complete.contraction} %and \cite[Theorem 8 and Equation (3.14)]{Devetak.2006}, % hence ${\|\sigma_d\|_{(E:1,{A_2}:1,Q_1:1,S_2:p)}}={\|\sigma_d\|_{(E:1,Q_1:1,R_2:1,S_2:p)}}$. %\jk{Here, implicitly, the order of subsystems changes and is indicated by the one of the norms, i.e. the operator in the first $(E:1,R_2:1,Q_1:1,S_2:p)$ norm is $\sigma_{EA_2Q_1X_2}\neq \sigma_{EQ_1A_2X_2}$, where the latter is the operator in the second norm., NECESSARY?} % The second to last inequality follows from combining the ancilla systems $E$ and $A_2$, $Q_1$, respectively, and splitting the suprema over independent sets. The last line follows by the  \cref{Cor:rightIdentity}. \\  %Else consider two operators $X_{E_1Q_1}\in\mathcal{S}_1[\mathcal{H}_{E_1},\mathcal{S}_q(\mathcal{H}_{Q_1})],Y_{E_2Q_2}\in\mathcal{S}_1[\mathcal{H}_{E_1},\mathcal{S}_q(\mathcal{H}_{Q_1})]$, where $E_1,E_2$ are two $d$ dimensional quantum systems. Then  % %        \textup{LHS}&\geq \|(\id^{(E_1)}_d\otimes\id^{(E_1)}_d\otimes\Phi\otimes\Psi)(X_{E_1Q_1}\otimes Y_{E_2Q_2})\|_{(E_1:1,E_2:1,R_1:q,R_2:q,S_1:p,S_2:p)} \\ &\geq \|(\id^{(E_1)}_d\otimes\Phi)(X_{E_1Q_1})\otimes(\id^{(E_2)}_d\otimes\Psi)(Y_{E_2Q_2})\|_{(E_1:1,R_1:q,S_1:p,E_2:1,R_2:q,S_2:p)} \\&= \|(\id^{(E_1)}_d\otimes\Phi)(\rho_{E_1Q_1})\|_{(E_1:1,R_1:q,S_1:p)}\cdot\|(\id^{(E_2)}_d\otimes\Psi)(Y_{E_2Q_2})\|_{(E_2:1,R_2:q,S_2:p)}, % where the inequality comes from two applications of the swap operator (with identities to the right) and the fact that it is a complete contraction since $1\leq p,q$, see \cref{prop:swap.right.contraction}. Now taking the supremum over all such suitably normalized $X,Y$ and $d$ yields the achievability claim.  The proof of the $n$-fold statement follows similarly to in \cref{thm:general.multiplicativity} by induction over the multiplicativity statement. Denote with $Q^j:=Q_1...Q_j$ for $1\leq j\leq n$, and analogously $R^j,S^j$. The theorem is the induction start, for the induction step observe      \bigg\|\bigotimes^n_{i=1}\Phi_i\bigg\|_{cb,Q:1\to (R:1,S:p)} &= \left\|\bigotimes^{n-1}_{i=1}\Phi_i\otimes\Phi_n\right\|_{cb,({Q^{n-1}:1},{Q_n}:1)\to (R^{n-1}:1,{R_n}:1,S^{n-1}:p,S_n:p)} \\ &\leq \bigg\|\bigotimes^{n-1}_{i=1}\Phi_i\bigg\|_{cb,Q^{n-1}:1\to (R^{n-1}:1,S^{n-1}:p)}\cdot\big\|\Phi_n\big\|_{cb,Q_n:1\to (R_n:1,S_n:p)},   where the inequality in the second line follows from the \cref{thm:mainchainrule}.",2502.01611
proof,"Using the fact that consecutive systems with the same Schatten index can be swapped (\cref{prop:combining.systems}), we can write $\|\Psi\circ\Phi\|_{cb,(Q_1:q)\to(R^2:r,S^2:s)} = \|\Psi\circ\Phi\|_{cb,(Q_1:q)\to(R_1:r,R_2:r,S^2:s,S_1:s)}$. We then write the composition more explicitly including identities: $\Psi\circ\Phi =  (\id_{R_1} \otimes \Psi \otimes \id_{S_1}) \circ \Phi$ and then use~\cref{lem:cb.norm.splitting} to get  &\|\Psi\circ\Phi\|_{cb,(Q_1:q)\to(R_1:r,R_2:r,S^2:s,S_1:s)} \\ &\leq \| \id_{R_1} \otimes \Psi \otimes \id_{S_1} \|_{cb,(R_1:r,Q_2:q,S_1:s) \to (R_1:r,R_2:r,S_2:s,S_1:s)} \| \Phi \|_{cb,(Q_1:q) \to (R_1:r,Q_2:q,S_1:s)}.  Since $\Phi$ is CP, by \cref{lem:positivesufficiency} we have $\| \Phi \|_{cb,(Q_1:q) \to (R_1:r,Q_2:q,S_1:s)} = \| \Phi \|_{cb,(Q_1:q) \to (R_1:r,Q_2:q,S_1:s)}^+$. Then by definition of the CB norm and then using \cref{Cor:rightIdentity}, we have   \| \id_{R_1} \otimes \Psi \otimes \id_{S_1} \|_{cb,(R_1:r,Q_2:q,S_1:s) \to (R_1:r,R_2:r,S_2:s,S_1:s)}  &= \| \Psi \otimes \id_{S_1} \|_{cb,(Q_2:q,S_1:s) \to (R_2:r,S_2:s,S_1:s)} \\ &= \| \Psi \|^+_{cb,(Q_2:q) \to (R_2:r,S_2:s)}\,,  which proves the desired result.  % Its proof is similar to the one of \cref{thm:mainchainrule}, base on \cref{Cor:rightIdentity}. % We have %  %   \|\Psi\circ\Phi\|_{cb,Q_1:q\to(R^2:r,S^2:s)} &= \|\Psi\circ\Phi\|_{cb,Q_1:q\to(R_1:r,R_2:r,S_2:s,S_1:s)} \\ &= \|(\id_{R_1}\otimes\Psi\otimes\id_{S_1})\circ\Phi\|_{cb,Q_1:q\to(R^2:r,S_2:s,S_1:s)} \\ &\leq \|\id_{R_1}\otimes\Psi\otimes\id_{S_1}\|_{cb,(R_1:r,Q_2:q,S_1:s)\to(R_1:r,R_2:r,S_2:s,S_1:s)} \\ &\hspace{01cm} \times \|\Phi\|_{cb,(Q_1:q)\to(R_1:r,Q_2:q,S_1:s)} \\ & =  %   \|\Psi\|^{+}_{cb,(Q_2:q)\to(R_2:r,S_2:s)} \cdot \|\Phi\|_{cb,(Q_1:q)\to(R_1:r,Q_2:q,S_1:s)}, %  where in the first line we used that the SWAP map $F_{S_1\leftrightarrow S_2}$ is a complete isometry since these two systems have the same Schatten index $s$. The inequality is an application of \cref{lem:cb.norm.splitting} and the last line follows from \cref{lem:reductionLemma}.  %       \|\Psi\circ\Phi\|_{cb,Q_1:1\to(R:1,S:p)} &= \sup_d\sup_{\rho_d}\frac{\|(\id_d\otimes\Psi)\circ(\id_d\otimes\Phi)(\rho_d)\|_{(E:1,R:1,S:p)}}{\|\rho_d\|_{(E:1,Q_1:1)}} \\ %            &=\sup_d\sup_{\rho_d}\frac{\|(\id_d\otimes\id_{R_1}\otimes\Psi\otimes\id_{S_1})(\sigma_d)\|_{(E:1,R_1:1,R_2:1,S_1:p,S_2:p)}}{\|\sigma_d\|_{(E:1,R_1:1,Q_2:1,S_1:p)}}\\ &\hspace{2cm}\times\frac{\|(\id_d\otimes\Phi)(\rho_d)\|_{(E:1,R_1:1,Q_2:1,S_1:p)}}{\|\rho_d\|_{(E:1,Q_1:1)}} \\ %            &\leq \|\Psi\|_{cb,(Q_2:1,S_1:p)\to(R_2:1,S_2:p,S_1:p)}\cdot \|\Phi\|_{cb,Q_1:1\to(R_1:1,Q_2:1,S_1:p)} \\&\leq \|\Psi\|^+_{cb,Q_2:1\to(R_2:1,S_2:p)}\cdot \|\Phi\|^+_{cb,Q_1:1\to(R_1:1,Q_2:1,S_1:p)}  %         where in the second line we set $\sigma_d:=(\id_d\otimes\Phi)(\rho_d)$ and between the second and third swapped $S_1:p$ and $S_2:p$, which does not change the norms, to then separate the suprema in the third and apply Corollary \ref{Cor:rightIdentity} to get the last inequality. \\",2502.01611
proof,"The proof follows via lifting \cref{thm:mainchainrule} to the restricted setting, in the same manner as was done in \cite{Himbeeck.2025}. Hence it is repeated in \cref{app:Additivity.on.reduced.operator.spaces}.",2502.01611
proof,"Define the operators $f_{i,X_i} := \sum_{x \in \mathbb{X}} f_i(x) \ketbra{x}_{X_i}$ and $f^n_{X^n} = \sum_{x^n\in \mathbb{X}^n} f^n(x^n)\ketbra{x^n}_{X^n}$ and the maps $\Phi_i : Q_i \to X_i A_i $ defined by $\Phi_i(\rho) := 2^{\tfrac{\alpha-1}{2\alpha}f_{i,X_i}} \mathcal{M}_i(\rho) 2^{\tfrac{\alpha-1}{2\alpha}f_{i,X_i}}$, which are CP by construction, since $2^{\frac{\alpha-1}{2\alpha}f_{i,X_i}}$ are self-adjoint. Then, we can use Theorem~\ref{thm:Restricted.multiplicativity} for the maps $\Phi_i$ with the replacements $A_i \to S_i$ and $X_i \to R_i$  and by applying $\frac{\alpha}{1-\alpha}\log$ to each side of the equation \eqref{eq:multiplicativity.1to1P} and noting that $\bigotimes_{i=1}^n 2^{f_{i,X_i}} = 2^{f^n_{X^n}}$ we get that the LHS in upper bounded by the RHS. Equality follows from additivity of $H^\uparrow_\alpha$ under tensor products of states \cite[Corollary 5.9]{Book.Tomamichel.2016}.",2502.01611
proof,"%     Define the function  %      %         f^n(x^n,a^n) = \sum_i f(x_i,q_X^i)  %      %     where $q_X^i$ is the frequency distribution of the string of past outcomes $(x_1\cdots x_{i-1})$. The function $x\mapsto f(x,q_X)$ corresponds to the the optimal tradeoff-function for the statistics $q_x$ and satisfies $\mathbb E_x[f(x,q_X)] = h(q_X)$. Therefore %      %         \lim_{n\to \infty}rate(\mathcal P, \rho^{\otimes n}) = \lim_{n\to \infty} \frac{1}{n} \sum_i \mathbb E_x h(q_X^i) \to h(q) %      %    as the sequence $q_X^i$ converges to $q$ with probability $1$ by the weak law of large numbers. %",2502.01611
proof,"[Proof of \cref{thm:time_adaptive_protocol}] We first explain how to construct the functions $g_n$. %and then prove the security of the protocol.  %\emph{Construction:} It is a standard results in QKD that $ h(\mathcal M,\mathcal N,\tau,q_{X})$ is a convex function in $q_X$ (see for example \cite{Winick.2018}). For each $t\in \mathbb N$, the assumption $\rho^{\mathrm{hon}}_{Q_t} > 0$ ensures that $q_{X_t}^{\mathrm{hon}}$ is a strictly feasible distribution (i.e.\ the inequality constraints in the convex optimization problem \eqref{eq:as_rate} can be satisfied with strict inequalities). Consequently, there exists a  supporting hyperplane to the graph of the function $q_X \mapsto h(\mathcal M_t,\mathcal N_t,\tau_t, q_X)$ at the point $(q^{\mathrm{hon}}_{X_t},h(\mathcal M_t,\mathcal N_t,\tau_t, q^{\mathrm{hon}}_{X_t}))$. Moreover, we can chose the hyperplanes to be the same for all $t\in \mathbb N$ such that $(\mathcal M_t,\mathcal N_t,\mathcal \tau_t,q^{\mathrm{hon}}_{X_t})$ are the same.  Let $f_t:\mathbb{X}\to \mathbb R$ be a function parametrizing the hyperplanes, so that $\sum_x f_t(x) q_{X}(x) \leq h(\mathcal M_t,\mathcal N_t,\tau_t,q_{X})$ for all probability distributions $q_X$, and $\sum_x f_t(x) q^{\mathrm{hon}}_{X_t}(x) =h(\mathcal M,\mathcal N,\tau,q^{\mathrm{hon}}_{X_t})$. Note that a supporting hyperplane is given by an affine function, but the constant term can always be absorbed in the coefficients $f_t(x)$ since we require the inequality to hold for normalized probability distributions satisfying $\sum_{x} q_{X}(x) = 1$. %all feasible $q^{est}_X$ are normalized and $\sum_x q^{est}(x) = 1$.  %be the sequence of distributions given by the theorem and consider the corresponding functions $f^t(x)$ that parametrizing the hyperplanes at the points $q_{X_t}$. Recalling the definition of $h$, this guarantees that for every $t$ and every $\rho_{EXA} = \mathcal M_t(\rho_{EQ})$ with $\rho_{EQ}\in \cD_r^E(\cH_Q)$,      H(A|XE)_{\rho} \geq \mathbb E_{x \sim \rho_X}[f_t(x)]\,.  We define our post-processing function by $g_n(x^n) = \max(0, \lfloor f^n(x^n) - \delta(\epsilon,n)\rfloor)$ where      f^n(x^n) = \sum_{t=1}^n f_t(x_t)\,,  and $\delta(n,\epsilon)$ will be defined below.   We now have to show that this construction $g_n$ gives a correct lower-bound on the number of bits of randomness that can be extracted from $A^n$. Using the uniform continuity of $f$-weighted Rnyi entropies (Lemma~\ref{lem:continutity}), we find that for all $t \in [n]$ and all states of the form $\rho_{EXA} = \cM_t(\rho_{QE})$ with $\rho_{EQ} \in \cD_r^E(\cH_{Q})$      H_\alpha^{\uparrow,f_t}(A|XE)_{\rho} \geq -(\alpha-1) (\log \eta_t)^2 \,,  for $\alpha \in (1,1+1/\log \eta_t)$ where $\eta_t$ only depends on the dimension of $A$ and on $\max_x f_t(x)$ and $\min_x f_t(x)$. Moreover, since $\eta_t$ takes only a finite set of values, we can bound $\eta_t \leq \eta = \max_{t\in \mathbb N} \eta_t$.    Using~\cref{thm:IIDreduction}, this implies that       H_\alpha^{\uparrow, f_n}(A^n|X^nE)_{\rho} \geq - n (\alpha-1) (\log \eta)^2\,.  for all state of the form $\rho_{EX^nA^n} = \mathcal{M}^n(\rho_{EQ^n})$ with $\rho_{EQ^n}\in \cD_r^E(\cH_{Q^n})$. Finally, using~\cite[Theorem 1]{Himbeeck.2025}, this implies that the choice $\delta(n,\epsilon) = n (\alpha-1) (\log \eta)^2 - \frac{\alpha}{\alpha-1}\log{1/\epsilon}$ leads to an $\epsilon$-secure protocol.   We now choose $\alpha = 1 + \tfrac{1}{\sqrt{n}}$ and $\epsilon_n = \frac{1}{n}$. Then, the average rate given by our construction is      \frac{1}{n} \mathbb E_{x^n \sim \otimes_{t=1}^n q_{X_t}^{\mathrm{hon}}}[g(x^n)]         &\geq \frac{1}{n} \sum_{t=1}^n \sum_{x} f_t(x)q^{\mathrm{hon}}_{X_t}(x) - \frac{(\log \eta)^2}{\sqrt{n}} - \frac{2}{\sqrt{n}} \log{1/\epsilon_n} -O(1)\\         &= \frac{1}{n} \sum_{t=1}^n h(\mathcal M_t,\mathcal N_t,\tau_t,q^{\mathrm{hon}}_{X_t}) - O(\tfrac{\log n}{\sqrt{n}})  which yields the stated asymptotic limit.",2502.01611
proof,"[Proof of \cref{lem:finiteEnvironement}] For notational convenience, we denote the norm $\|.\|_{\mathcal{S}_p[\mathbb{C}^d,\mathcal{X}]}$ by $\|.\|_{\#}$ as well as the norm $\|.\|_{\mathcal{S}_1(\mathbb{C}^d\otimes \mathcal{H}_A)\to \mathcal{S}_p[\mathbb{C}^d,\mathcal{X}]}$ by $\|.\|_{1\to \#}$. Clearly $\|\id_d\otimes \Phi\|_{1\to \#}$ is a non-decreasing sequence in $d$, hence it suffices to show that for $d\geq d_A$ it is non-increasing. Fix some $d\geq d_A$, then $\rho\mapsto\|(\id_d\otimes \Phi)(\rho)\|_{\#}$ is convex, hence the maximum is achieved on the extremal operators in $\{\omega\in\mathcal{B}(\mathbb{C}^d\otimes \mathcal{H}_A)|\|\omega\|_1\leq 1\}$, which are just rank-1 operators of the form $\omega=|\psi\rangle\langle\varphi|$:      \sup_{\|\omega\|_1\le 1} \|(\id_d\otimes \Phi)(\omega)\|_{\#} = \sup_{|\varphi\rangle,|\psi\rangle\in\mathbb{C}^d\otimes\mathcal{H}_A, \||\varphi\rangle\|,\,\||\psi\rangle\|\leq 1} \|(\id_d\otimes \Phi)(|\psi\rangle\langle\varphi|)\|_{\#}\,.   Now for any such $|\psi\rangle\in\mathbb{C}^d\otimes\mathcal{H}_A$, by Schmidt decomposition there exists a positive trace-normalized operator $\omega\in\mathcal{S}(\mathcal{H}_A)$ and a local isometry $U:\mathbb{C}^{d_A}\to \mathbb{C}^d$, s.t.       |\psi\rangle=(U\otimes\1)\sum_{i=1}^{d_A}(\1\otimes\sqrt{\omega})|i\rangle_{\mathbb{C}^{d_A}}\otimes|i\rangle_{\mathcal{H}_A} \equiv (U\otimes\1)|\sqrt{\omega}\rangle,  i.e. $|\psi\rangle$ is a purification of some state $\omega$.  Since $\#$ is invariant under local isometries (cf. Corollary \ref{cor:Pisier.Formula}), it follows that      \sup_{\psi,\varphi} \|(\id_d\otimes\Phi)(|\psi\rangle\langle\varphi|)\|_{\#}=\sup_{\omega,\eta\in S(\mathcal{H}_A)}\|(\id_{d_A}\otimes\Phi)(|\sqrt{\omega}\rangle\langle\sqrt{\eta}|)\|_\# \leq \|\id_{d_A}\otimes\Phi\|_{1\to \#},  since $\||\sqrt{\omega}\rangle\langle\sqrt{\eta}|\|_1\le\|\omega\|_1\|\eta\|_1\le 1$.",2502.01611
proof,"By assumptions there exists, due to Lemma \ref{thm:VariationalSpOperatorspace}, $A,B\in S_{2x}(\mathcal{H}_1)$, with $\frac{1}{x}=\frac{1}{r}-\frac{1}{t}$ s.t. $\|A\|_{2x}=\|B\|_{2x}=1$, $A,B\geq 0$, and $Y,Z\geq 0$ such that      C^*C=(A_1\otimes\1_{23})Y(A_1\otimes\1_{23}) \quad \& \quad \|C^*C\|_{(r,t,s)}=\|Y\|_{(t,t,s)}, \\     D^*D=(B_1\otimes\1_{23})Z(B_1\otimes\1_{23}) \quad \& \quad \|D^*D\|_{(r,t,s)}=\|Z\|_{(t,t,s)}. \\  %Such $A,B,Y,Z$ exist due to \eqref{thm:VariationalSpOperatorspace}. There further exist an isometries $V, W$ s.t.      C=VY^{\frac{1}{2}}(A\otimes \1) \quad     D=WZ^{\frac{1}{2}}(B\otimes \1),  and hence $C^*XD=(A\otimes\1)Y^{\frac{1}{2}}V^*XWZ^{\frac{1}{2}}(B\otimes\1)$. So Lemma \ref{thm:VariationalSpOperatorspace} together with \cite{Devetak.2006}[Lemma 9] yield      \|C^*XD\|_{(r,t,s)}\leq \|Y^{\frac{1}{2}}V^*XWZ^{\frac{1}{2}}\|_{(t,t,s)}\leq \|Y\|^{\frac{1}{2}}_{(t,t,s)}\|Z\|^{\frac{1}{2}}_{(t,t,s)} = \|C^*C\|^{\frac{1}{2}}_{(r,t,s)}\|D^*D\|^{\frac{1}{2}}_{(r,t,s)},  which is what we wanted to prove.",2502.01611
proof,"We first proof the first part.  Fix some environment $E$ and let $Q\in B(EQ)$. Let $Q=U|Q|^{\frac{1}{2}}|Q|^{\frac{1}{2}}$ be its polar decomposition. Then     0 <      U|Q|^{\frac{1}{2}} \\     |Q|^{\frac{1}{2}}      (|Q|^{\frac{1}{2}}U^* \quad |Q|^{\frac{1}{2}}) =          U|Q|U^* \quad Q \\         Q^* \quad |Q|     .  Now since $\Phi$ is CP, $\id_2\otimes\id_E\otimes\Phi$ is positive and hence so is               (\id_E\otimes\Phi)(U|Q|U^*) \quad (\id_E\otimes\Phi)(Q) \\         (\id_E\otimes\Phi)(Q^*) \quad (\id_E\otimes\Phi)(|Q|)      >0.  Now it is well known \cite{Book.Hiai.2014} that this block matrix being positive is equivalent to        (\id_E\otimes\Phi)(Q) = (\id_E\otimes\Phi)(U|Q|U^*)^{\frac{1}{2}}X((\id_E\otimes\Phi)(|Q|))^{\frac{1}{2}}  for some contraction $X$. Now directly \eqref{equ:ineq1} and \cref{prop:ContractionInequality} yield the desired result, since $q\leq r\leq s$ and    \|(\id_E\otimes\Phi)(Q) \|_{(E:q,R:r,S:s)} &=  \|(\id_E\otimes\Phi)(U|Q|U^*)^{\frac{1}{2}}X((\id_E\otimes\Phi)(|Q|))^{\frac{1}{2}}\|_{(E:q,R:r,S:s)} \\ &\leq \|(\id_E\otimes\Phi)(U|Q|U^*)\|^{\frac{1}{2}}_{(E:q,R:r,S:s)}\|(\id_E\otimes\Phi)(|Q|)\|^{\frac{1}{2}}_{(E:q,R:r,S:s)} \\    &\leq \|\id_E\otimes\Phi\|^+_{(E:q,Q:q)\to (E:q,R:r,S:s)} \|U|Q|U^*\|^{\frac{1}{2}}_{(E:q,Q:q)}\||Q|\|^{\frac{1}{2}}_{(E:q,Q:q)}   \\ &=  \|\id_E\otimes\Phi\|^+_{(E:q,Q:q)\to (E:q,R:r,S:s)}\|Q\|_{q},  where in the last equality we used unitary invariance in of the Schatten-$p-$norm. Taking the supremum over $E$ gives the result. \\ To prove the second part we use the fact that the SWAP operator is a complete contraction, see \eqref{equ:complete.contraction}, hence since $q\geq r,s$      \|\Phi\|_{cb,Q:q\to (R:r,S:s)} &= \sup_E\sup_{X_{EQ}}\frac{\|(\id_E\otimes\Phi)(X_{EQ})\|_{(E:q,R:r,S:s)}}{\|X_{EQ}\|_{(E:q,Q:q)}} \\ &= \sup_E\sup_{X_{EQ}}\frac{\|(\id_E\otimes\Phi)(X_{EQ})\|_{(E:q,R:r,S:s)}}{\|X_{QE}\|_{q}} \\&\leq \sup_E\sup_{X_{QE}}\frac{\|(\Phi\otimes \id_E)(X_{QE})\|_{(R:r,S:s,E:q)}}{\|X_{QE}\|_{q}} \\ &\leq \|\Phi\|^+_{Q:q\to (R:r,S:s)},  where the first inequality are two applications of the SWAP operator and the last inequality is \cref{lem:reductionLemma}.",2502.01611
proof,"[Proof of \cref{cor:Chain.Rules}] %Recall that what remains to be shown is that  % %    \|\phi_{Q\to X}\otimes\id_B\otimes\psi_{R\to A}\|_{cb,(Q:1,B:\alpha,R:1)\to(X:1,B:\alpha,A:\alpha)} = \|\phi\otimes\psi\|_{cb,(Q:1,R:1)\to(X:1,A:\alpha)}, % where the order of the systems indicated by the Pisier norms is the one that matters, not the order of the channels as written within the norms. %We will show this statement, by the same strategy as \cref{thm:mainchainrule}. To simplify notation a bit we write $\Phi:=\phi\otimes\id_B$ % %    &\|\Phi_{QB\to XB}\otimes\psi_{R\to A}\|_{cb,(Q:1,B:\alpha,R:1)\to(X:1,B:\alpha,A:\alpha)} \\ = &\sup_d\sup_{\rho_d}\frac{\|(\id_d\otimes\Phi\otimes\psi)(\rho_d)\|_{(E:1,X:1,B:\alpha,A:\alpha)}}{\|\rho_d\|_{(E:1,Q:1,B:\alpha,R:1)}} \\= &\sup_d\sup_{\rho_d}\frac{\|(\id_d\otimes\Phi\otimes\id_{A})(\sigma_d)\|_{(E:1,X:1,B:\alpha,A:\alpha)}}{\|\sigma_d\|_{(E:1,Q:1,B:\alpha,A:\alpha)}} \frac{\|(\id_d\otimes\id_{Q}\otimes\id_B\otimes\psi)(\rho_d)\|_{(E:1,Q:1,B:\alpha,A:\alpha)}}{\|\rho_d\|_{(E:1,Q:1,B:\alpha,R:1)}} \\ \leq &\sup_d\sup_{\sigma_d}\frac{\|(\id_d\otimes\Phi\otimes\id_{A})(\sigma_d)\|_{(E:1,X:1,B:\alpha,A:\alpha)}}{\|\sigma_d\|_{(E:1,Q:1,B:\alpha,A:\alpha)}}  %    \sup_d\sup_{\rho_d}\frac{\|(\id_d\otimes\id_{Q}\otimes\id_B\otimes\psi)(\rho_d)\|_{(E:1,Q:1,B:\alpha,A:\alpha)}}{\|\rho_d\|_{(E:1,Q:1,B:\alpha,R:1)}} \\ = &\|\phi\otimes \id_{BA}\|_{cb,(Q:1,BA:\alpha)\to(X:1,BA:\alpha)}\|\phi\|_{cb,R:1\to A:\alpha} \\ = &\|\phi\|_{cb,Q:1\to X:1}\|\psi\|_{cb,R:1\to A:\alpha} = \|\psi\|_{cb,R:1\to A:\alpha} = \|\phi\otimes\psi\|_{cb,(Q:1,R:1)\to(X:1,A:\alpha)} % where we set $\sigma_d:=(\id_d\otimes\id_{Q}\otimes\id_B\otimes\phi)(\rho_d)$ in the second line. In the fourth line we used the cb norm is invariant under tensoring of identities on the left, as long as they are isometries acting on systems with the same Schatten index. The equality in the fourth line follows from \cref{Cor:rightIdentity} and the ones in the last line from \cref{thm:mainchainrule}.  %We get the desired equality by the same product state argument es in the proof of \cref{thm:mainchainrule} $1)$. %",2502.01611
proof,"%Let $X\in \mathcal{X}$ be an element of some operator space, then on the one hand we have by Pisier's formula,  \cref{thm:PisierOriginal} % %     \||1\rangle\langle1|\otimes X\|_{S_t[\mathbb{C}^d,\mathcal{X}]} &\leq    \||1\rangle\langle1|\otimes X\|_{S_\infty[\mathbb{C}^d,\mathcal{X}]} = \||1\rangle\langle1|\otimes X\|_{M_d(\mathcal{X})} \\ %     &= \|X\oplus 0...\oplus0\|_{M_d(\mathcal{X})} = \|X\|_{M_{1}(\mathcal{X})}= \|X\|_{\mathcal{X}}.      % \leq \||1\rangle\|_{d,1}\|\langle1|\|_{1,d}\|X\|_{M_1(\mathcal{X})}= \|X\|_{\mathcal{X}}, % where the second line follows from $ii)$ in \cref{prop:central.properties.OSnorms}. %On the other hand, also by \cref{thm:PisierOriginal} we have that % %    \||1\rangle\langle1|\otimes X\|_{S_t[\mathbb{C}^d,\mathcal{X}]} &= \inf_{|1\rangle\langle1|_1\otimes X_{2}=F_1Y_{12}G_1}\|F\|_{2t}\|G\|_{2t}\|Y\|_{\mathcal{S}_\infty[\mathbb{C}^d,\mathcal{X}]}  \\ &= \inf_{|1\rangle\langle1|_1\otimes X_{2}=F_1Y_{12}G_1}\|F\|_{2t}\|G\|_{2t}\|Y\|_{M_d(\mathcal{X})} \\ &= \inf_{\|F\|_{2t},\|G\|_{2t} = 1}\|F^{-1}|1\rangle\langle1|G^{-1}\otimes X\|_{M_d(\mathcal{X})} \\ &\geq  %\inf_{\|F\|_{2t},\|G\|_{2t}=1}\|F^{-1}|1\rangle\langle1|G^{-1}\|_{M_d(\mathbb{C})} \|X\|_{\mathcal{X}} \\  %&= \||1\rangle\langle1|\|_t\|X\|_{\mathcal{X}} = \|X\|_{\mathcal{X}}. % Here $F^{-1}$ and $G^{-1}$ denote the generalized inverses of $F,G$ and the inequality follows from restricting the supremum implicitly in the norm $\|\cdot\|_{M_d(\mathcal{X})}$ to vectors of the form $\alpha\otimes x$. \\ %For \eqref{equ:classical.quantum.norm.2} the proof is even a little simpler, since % %    \|\1\otimes X\|_{S_\infty[\mathbb{C}^d,\mathcal{X}]} &= \|\1\otimes X\|_{M_d(\mathcal{X})} = \|\oplus_{i=1}^d X\|_{M_d(\mathcal{X})} =\|X\|_\mathcal{X}, % which follows directly from $ii)$ in \cref{prop:central.properties.OSnorms}. %",2502.01611
proof,"[Proof of \cref{thm:Restricted.multiplicativity}] To fix $n$ linear constraints fix some CPTP channels $\{\mathcal{N}_i:Q_i\to Q^\prime_i\}_{i=1}^n$ and states $\{\tau_i\in\mathcal{D}(\cH_{Q^\prime_i})\}_{i=1}^n$. Recall the definitions of $Q^n:=Q_1...Q_n$, $\mathcal{D}_r(\cH_{Q})$ and $\mathcal{D}^E_r(\cH_{Q})$. WLOG assume that none of the $\Phi_i\neq 0,$ else the statement trivially holds.  To do this we first recall, that due to \cref{lem:finiteEnvironement} and its proof it holds that      \|\Phi\|_{r,cb,Q:1\to(R:1,S:p)} &= \sup_{E}\sup_{\rho_{EQ}\in\mathcal{D}^E_r(\cH_Q)}\|(\id_E\otimes\Phi)(\rho_{EQ})\|_{(E:1,R:1,S:p)} \\ &= \sup_{\rho\in\mathcal{D}_r(\cH_Q)}\|(\id_{\tilde{Q}}\otimes\Phi)(|\sqrt{\rho}\rangle\langle\sqrt{\rho}|_{\tilde{Q}Q})\|_{(\tilde{Q}:1,R:1,S:p)} \\    &=:\sup_{\rho_\in\mathcal{D}_r(\cH_{Q})}g_p^{\Phi}(\rho_Q) \\ &=\sup\{g_p^\Phi(\rho_Q)| \rho_Q\geq 0, \mathcal{N}(\rho_Q)=\tau\},  where $\tilde{Q}$ is isomorphic to $Q$ and $|\sqrt{\rho}\rangle_{\tilde{Q}Q}=(\1_{\tilde{Q}}\otimes\sqrt{\rho}_Q)\sum_{i}|ii\rangle_{\tilde{Q} Q}$ is a (canonical) purification of $\rho_Q\in\mathcal{D}_r(\cH_{Q})$ into $\tilde{Q} Q$. This is because the extremal points of the linear constrained $\mathcal{D}_r^E(\cH_{Q}):=\{\rho\in\mathcal{D}(\cH_{EQ})|(\mathcal{N}\circ \tr_E)(\rho_{EQ})=\tau\}$ are nothing but the set of purifications of all $\rho\in\mathcal{D}_r(\cH_{Q})$, by construction. To get the last line we used that the linear constraint already enforces $\Tr[\rho]=\Tr[\mathcal{N}(\rho)]=\Tr[\tau]=1$, since $\mathcal{N}$ is TP.  Hence the statement of the theorem is equivalent to  \sup_{\rho\in\mathcal{D}_r(\cH_{Q^n})}g_p^{\otimes_{i=1}^n\Phi_i}(\rho) = \prod_{i=1}^n \sup_{\rho_i\in\mathcal{D}_r(\cH_{Q_i})} g^{\Phi_i}_p(\rho_i).     Since for operators $\rho_i\in\mathcal{D}_r(\cH_{Q_i})$ it clearly holds that $\otimes_{i=1}^n\rho_i\in\mathcal{D}_r(\cH_{Q^n})$ it actually suffices to prove that the LHS in \eqref{equ:simplification.C} is upper bounded by the RHS. To do so the authors in \cite{Himbeeck.2025} have shown that in the finite dimensional setting,  %infinite dim in \cite{Martin.2016},  the above convex optimization problem is equal to its dual, i.e.       \sup_{\rho\in\Pos(\mathcal{H}_Q)}\{g^\Phi_p(\rho)|\mathcal{N}(\rho)=\tau\} = \inf_{\Sigma\in\Pos(\mathcal{H}_{Q^\prime})}\{\Tr[\Sigma\tau]| g^\Phi_p(\rho)\leq \Tr[\Sigma\mathcal{N}(\rho)] \forall \rho\in\Pos(\mathcal{H}_Q)\}.  This follows by showing that there exists a dual feasible $\Sigma\in\Pos(\mathcal{H}_{Q^\prime})$, i.e. one that satisfies      g_\alpha^\Phi(\rho)<\Tr[\Sigma \mathcal{N}(\rho)] \ \forall \rho\in\Pos(\mathcal{H}_Q).  For the convenience of the reader we will give a simple proof. Note first that both sides are positive homogeneous in $\rho$, hence it suffices to show it for all $\rho\in\mathcal{D}(\cH_{Q})$. Let $\Sigma=C\1_{Q^\prime}$, then the RHS becomes $\Tr[\Sigma \mathcal{N}(\rho)]=C$, since $\mathcal{N}$ is CPTP and this inequality holds strictly, by definition for $C =\|\Phi\|_{cb,Q:1\to(R:1,S:p)} + 1<\infty$ by assumption.  Now that we have strong duality, let $\Sigma_i$ be a feasible point of the dual problem, i.e. for any $0\neq \rho\in\Pos(\mathcal{H}_{Q_i})$, $0<g_p^{\Phi_i}(\rho)\leq \Tr[\mathcal{N}^*_i(\Sigma_i)\rho]$, since $\Phi_i\neq 0$. It follows that $\mathcal{N}^*(\Sigma_i) > 0$. Define the hence  strictly positive $V_i:=\sqrt{\mathcal{N}^*_i(\Sigma_i)}$ and with it the CP map $\Phi_i^\prime(\cdot):=\Phi_i(V_i^{-1}\cdot V_i^{-1})$.  Now we see that  g_p^{\Phi_i}(\rho) &\leq \Tr[\mathcal{N}^*_i(\Sigma)\rho] \quad &\forall \rho\in\Pos(\mathcal{H}_{Q_i}), \\  \Leftrightarrow  g_p^{\Phi^\prime_i}(\rho^\prime) &\leq  \Tr[\rho_i^\prime] \quad &\forall \rho^\prime \in \Pos(\mathcal{H}_{Q_i}), \\ \Leftrightarrow g_p^{\Phi^\prime_i}(\rho^\prime) &\leq 1 &\forall \rho^\prime\in\mathcal{D}(\cH_{Q_i}), \\ {\Rightarrow} g_p^{\otimes_{i=1}^n\Phi^\prime_i}(\rho_n^\prime) &\leq 1 \quad &\forall \rho_n^\prime\in \mathcal{D}(\cH_{Q^n}), \\  \Leftrightarrow g_p^{\otimes_{i=1}^n\Phi^\prime_i}(\rho_n^\prime) &\leq \Tr[\rho_n^\prime] \quad &\forall \rho_n^\prime\in\Pos(\mathcal{H}_{Q^n}), \\ \Leftrightarrow g_p^{\otimes_{i=1}^n\Phi_i}(\rho_n) &\leq \Tr[\otimes^n_{i=1}\mathcal{N}^*_i(\Sigma_i)\rho_n] = \Tr[(\otimes_{i=1}^n\Sigma_i)(\otimes_{i=1}^n\mathcal{N}_i)(\rho_n)]  \quad &\forall \rho_n\in\Pos(\mathcal{H}_{Q^n}).  where $\rho^\prime:=V_i\rho V_i$ and $\rho_n=(\bigotimes_{i=1}^nV_i^{-1})\rho^\prime_n(\bigotimes_{i=1}^nV_i^{-1})$\,,  % %    g_p^\Phi(\rho)= \|(\id\otimes\Phi)(|\sqrt{\rho}\rangle\langle\sqrt{\rho}|)\| = ... = g_p^{\Phi^\prime}(\rho^\prime). % where the implication above followed from \cref{thm:mainchainrule}.  % Making use of the last inequality, we see that for all $\rho_n\in \mathcal D_r(\mathcal H_{Q^n})$,  %  %      g_p^{\otimes_{i=1}^n\Phi_i}(\rho_n) \leq \Tr[(\otimes_{i=1}^n\Sigma_i)(\otimes_{i=1}^n\mathcal{N}_i)(\rho_n)] = \Tr[\otimes_{i=1}^n\Sigma_i\tau_i]=\prod_{i=1}^n\Tr[\Sigma_i\tau_i]. %  % Taking the infimum over all feasible $\Sigma_i$ for $i\in[n]$ yields the claim due to strong duality \eqref{equ:Strong.Duality}.  So we have shown that  $\otimes_{i=1}^n \Sigma_i$ is dual feasible. In addition, the objective value for $\otimes_{i=1}^n \Sigma_i$ is $\prod_{i=1}^n \Tr[\Sigma_i \tau_i]$. Taking the infimum over all feasible $\Sigma_i$ for $i\in[n]$ yields the claim due to strong duality \eqref{equ:Strong.Duality}.",2502.01611
proof,"% We need to show that there exists constants $C,\delta>1$ such that for all $\alpha\in (1,\delta)$,      %      %     H^{\uparrow,f}_\alpha(A|XE) \geq H(A|XE) - \mathbb E[f(X)] - C (\alpha-1)\,.     %      We can get this result from the uniform continuity of Rnyi divergences which are defined for $\alpha\in (0,1)\cup (1,\infty)$ as               D_\alpha(\rho \| \sigma) = \frac{\alpha}{1-\alpha} \log \|\sigma^{\tfrac{1-\alpha}{2\alpha}} \rho \sigma^{\tfrac{1-\alpha}{2\alpha}}\|_{\alpha}\\         D'_\alpha(\rho \| \sigma) = \frac{1}{\alpha-1} \log \Tr[\rho^{\alpha} \sigma^{1-\alpha}]          and for $\alpha=0$ as $D'_0(\rho \| \sigma) = \lim_{\alpha\to 0}D'_\alpha(\rho \| \sigma)$.     We note that \[     H^{\uparrow,f}_\alpha(A|XE)_{\rho} = - \min_{\sigma\in \cD(\cH_{XE})} D_\alpha(\rho_{AXE} \| 2^{-f_X}\cdot \sigma_{XE}) \geq - D_\alpha(\rho_{AXE} \| 2^{-f_X}\cdot \rho_{XE}) \]      and  $H(A|XE)_{\rho} - \mathbb E[f(X)] = - D(\rho_{AXE}\|2^{-f_X}\cdot \rho_{XE}) = - \min_{\sigma \in \cD(\cH_{XE})} D_{\alpha}(\rho_{AXE}\|2^{-f_X}\cdot \rho_{XE})$.          In \cite[Lemma B.8 and Eq. (82)]{Dupuis.2020}  it is proven that, for all $\alpha\in (1,1+\log(\eta))$,           D(\rho_{AXE} \| 2^{-f_X}\rho_{XE}) \leq D_\alpha(\rho_{AXE} \| 2^{-f_X}\rho_{XE}) \leq D(\rho_{AXE} \| 2^{-f_X}\rho_{XE}) + (\alpha-1) (\log \eta)^2          with $\eta = 2^{D'_2(\rho_{AXE} \| 2^{-f_X} \rho_{XE})} + 2^{-D_0(\rho_{AXE} \| 2^{-f_X} \rho_{XE})} + 1$.        This yields the desired continuity statement, provided we can bound $\eta$ in a state independent way. For this, observe that for all $\alpha \in (1,\infty)$,               D'_\alpha(\rho_{AXE}\| 2^{-f_{X}}\rho_{XE})              &= \frac{1}{\alpha-1} \log \Tr[\rho_{AXE}^{\alpha} \rho_{XE}^{1-\alpha} 2^{(\alpha-1)f_{X}} ]\\             &\leq \frac{1}{\alpha-1} \log( \Tr[\rho_{AXE}^{\alpha} \rho_{XE}^{1-\alpha} ] 2^{(\alpha - 1) \max_{x} f(x)}) \\             &\leq \log |A| + \max_x f(x)\,.          Similarly, $-D'_\alpha(\rho_{AXE} \| 2^{-f_X}\rho_{XE}) \leq \log \tr[2^{-f_X} \rho_{XE}] \leq \log |A| - \min_x f(x)$. This implies that               \log \eta \leq \log (|A|2^{\max_x |f(x)|} + |A|2^{-\min_x f(x)}+1).",2502.01611
proof,"%     The first two items are classical results in convex optimisation. The first follows directly from the definition of a convex function and the second is a consequence of strong duality, which holds for strictly feasible convex optimization problems.  %     To prove the last item, let $z$ be a minimizer of the optimisation problem defining $g(y)$ then $f(z)+ \lambda_y^T (x-z) \leq f(x)$ %",2502.01611
proof,"%     For all $t \in \mathbb R^d$, with $||t||_2\leq \delta$,  $x+t\in C$ and so $b-a\geq f(x+t)-f(x)\geq (t| \grad f_x)$. This implies the result. %",2502.01611
proposition,"The family of norms defined above satisfies the following two main properties, namely for any $m,n\in\mathbb{N}$,  \text{(i)} \quad & \|FXG\|_m \leq \|F\|_{m,n}\|X\|_n\|G\|_{n,m} \quad \forall F,G^*\in M_{m,n}(\mathbb{C}), X\in M_n(\mathcal{X}), \\ \text{(ii)} \quad & \|X\oplus Y\|_{m+n} = \max\{\|X\|_n,\|Y\|_m\} \quad \forall X\in M_n(\mathcal{X}), Y\in M_m(\mathcal{X}),  where  $X\oplus Y=      X & 0 \\     0 & Y $, and $FXG\equiv (F\otimes \1_\mathcal{K})X(G\otimes \1_\mathcal{K})$.",2502.01611
proposition,"Consecutive Schatten indices of the same value can be combined:   \|X\|_{(A_1:q_1,...,A_{m-1}:q_{m-1},A_{m}\,...\,A_{m+n}:p;\mathcal{X})} = \|X\|_{(A_1:q_1...,A_{m-1}:q_{m-1},A_{m}\cdots  A_{m+n}:p;\mathcal{X})},   This in particular implies that if all Schatten indices are equal, then the norm      \|X\|_{(A_1:p...\,A_k:p)}=\|X\|_p  reduces to the Schatten-$p$-norm of $X$.",2502.01611
proposition,"For any $A\otimes X\in S_q[\mathcal{H},\mathcal{X}]$,      \|A\otimes X\|_{S_q[\mathcal{H},\mathcal{X}]}=\|A\|_q\|X\|_{\mathcal{X}}\,.  %Let $X\in \mathcal{S}_q[\mathcal{H}_1,\mathcal{S}_p[\mathcal{H}_2],\mathcal{S}_r(\mathcal{H}_3)]$, such that $X_{123}=Y_{12}\otimes Z_3$, then % %    \|X\|_{(1:q,2:p,3:r)}= \|Y\|_{(1:q,2:p)}\|Z\|_{r}, %   More generally for $\bigotimes_{i=1}^k X_i\in \mathcal{S}_{q_1}[\mathcal{H}_{A_1}[\mathcal{S}_{q_2}[...\,\mathcal{S}_{q_k}(\mathcal{H}_{A_k})]...]$,   \bigg\|\bigotimes_{i=1}^k X_i\bigg\|_{(A_1:q_1,...,A_k:q_k)}= \prod_{i=1}^k \|X_i\|_{(A_i:q_i)}.",2502.01611
proposition,"[Non-linearly adaptive protocol] %     There exists a sequence of functions $f_n:X^n\to \mathbb R$ which leads to an $\epsilon_n$ security protocol with $\lim_{n\to \infty} \epsilon_n = 0$ and such that  %      %         \lim_{n\to \infty}rate(\mathcal P, \rho^{\otimes n}) = h(\rho) %      %",2502.01611
proposition,"Let $r\leq t\leq s$ and $X\in B(\mathcal{H}_{123})$ be a contraction, then      \|C^*XD\|_{(r,t,s)}\leq \|C^*C\|_{(r,t,s)}^{\frac{1}{2}}\|D^*D\|_{(r,t,s)}^{\frac{1}{2}},  where for notational simplicity we dropped the labeling in the notation, i.e. wrote $\|\cdot\|_{(r,t,s)}\equiv \|\cdot\|_{(1:r,2:t,3:s)}$, etc.",2502.01611
lemma,"Let $\Psi:\mathcal{X}\to\mathcal{Y}$ and $\Phi:\mathcal{Y}\to\mathcal{Z}$ be two maps between arbitary operator spaces $\mathcal{X},\mathcal{Y},\mathcal{Z}$, then  \|\Phi\circ\Psi\|_{cb,\mathcal{X}\to\mathcal{Z}} \leq \|\Psi\|_{cb,\mathcal{X}\to \mathcal{Y}}\cdot \|\Phi\|_{cb,\mathcal{Y}\to \mathcal{Z}}",2502.01611
lemma,"[Generalized variational expressions] Let $\mathcal{X}$ be an operator space. Then for $1\leq p\leq q\leq \infty$ and $\frac{1}{r}=\frac{1}{p}-\frac{1}{q}$, the following variational formulas hold for any $X\in \mathcal{S}_p[\mathcal{H},\mathcal{X}],\mathcal{S}_q[\mathcal{H},\mathcal{X}]$ respectively:  \operatorname{(i)}\qquad&\|X\|_{\mathcal{S}_p[\mathcal{H},\mathcal{X}]}=\inf_{\substack{X=FYG\\F,G\in \mathcal{S}_{2r}(\mathcal{H}), Y\in\mathcal{S}_q[\mathcal{H}, \mathcal{X}] }} \|F\|_{2r} \|Y\|_{\mathcal{S}_q[\cH,\mathcal{X}]}\|G\|_{2r}\\ \operatorname{(ii)}\qquad &\|X\|_{\mathcal{S}_q[\mathcal{H},\mathcal{X}]} = \sup_{F,G\in \mathcal{S}_{2r}(\mathcal{H})}\|F\|_{2r}^{-1}\|FXG\|_{\mathcal{S}_p[\mathcal{H},\mathcal{X}]}\|G\|_{2r}^{-1}\,.",2502.01611
lemma,"[Generalized EAT chain rule for product channels]  %Let $\phi:R\to A$ and $\psi:Q\to X$ be CP maps, then $\Phi:=\psi\otimes\phi$ satisfies the non-signaling condition since $\tr_A\circ\Phi=\psi\circ\tr_R$ and for any $\alpha>1$ it holds that % %\|\Phi\otimes\id_B\|_{(Q:1,B:\alpha,R:1)\to(X:1,A:\alpha,B:\alpha)} \leq \|\Phi\|_{cb,(R:1,Q:1)\to (X:1,A:\alpha)}  % %which is equivalent to % %H^{\uparrow}_\alpha(AB|X)_{(\Phi  %\otimes \id_B)(\rho_{QBR})} \geq H^{\uparrow}_\alpha(B|Q)_{\rho_{QBR}} + \inf_{\sigma \in \mathcal{D}(RQ{R^\prime Q^\prime})} H^{\uparrow}_\alpha(A|XR^\prime Q^\prime)_{\Phi(\sigma_{RQ{R^\prime Q^\prime}})}, % where $R^\prime,Q^\prime$ are purifying systems isomorphic to $R$ and $Q$ respectively.  %",2502.01611
lemma,"[Generalized EAT chain rule for product channels] Let $\phi:R\to A$ and $\psi:Q\to X$ be CP maps, then $\Phi:=\psi\otimes\phi$ satisfies the non-signaling condition since $\tr_A\circ\Phi=\psi\circ\tr_R$ and for any $\alpha>1$ \cref{Conjecture1} and \eqref{equ:conjecture} holds. %",2502.01611
lemma,"Let $\Phi:\mathcal{B}(\mathcal{H}_A)\to \mathcal{X}$ be a linear map onto an arbitrary operator space $\mathcal{X}$, with $d_A:=\dim(\mathcal{H}_A)<\infty$. Then, for any $p\ge 1$,     \sup_{d\in\mathbb{N}}\|\id_{d}\otimes \Phi\|_{\mathcal{S}_1(\mathbb{C}^d\otimes \mathcal{H}_A)\to \mathcal{S}_p[\mathbb{C}^d,\mathcal{X}]}=\|\id_{d_A}\otimes \Phi\|_{\mathcal{S}_1(\mathbb{C}^{d_A}\otimes \mathcal{H}_A)\to \mathcal{S}_p[\mathbb{C}^{d_A},\mathcal{X}]}        %     Let $\Phi:\mathcal{B}(\mathcal{H}_A)\to \mathcal{B}(\mathcal{H}_B)$ be a linear map, $d_A:=\dim(\mathcal{H}_A)<\infty$ and $\|\cdot\|_\#$ any norm on $\mathcal{B}(\mathbb{C}^d\otimes\mathcal{H}_B)$ that is unitarily invariant under unitaries that act only non-trivially on $\mathbb{C}^d$, then %  %     \sup_{d\in\mathbb{N}}\|\id_d\otimes \Phi\|_{1\to \#} = \|\id_{d_A}\otimes \Phi\|_{1\to \#}. %  %This holds in particular for $\#=(B_1:p_1,B_2:p_2,...,B_k:p_k)$ the canonical norm on $\mathcal{S}_{p_1}[\mathcal{H}_{B_1},\mathcal{S}_{p_2}[...\mathcal{S}_{p_k}(\mathcal{H}_{B_k})...]]$.",2502.01611
lemma,"Let $\Phi:Q\to RS$ be a CP map. Then for $q\leq r\leq s$      \|\Phi\|_{cb, (Q:q)\to (R:r,S:s)}= \|\Phi\|^+_{cb, (Q:q)\to (R:r,S:s)},  and moreover for $q \geq r,s$      \|\Phi\|_{cb,( Q:q)\to (R:r,S:s)}= \|\Phi\|^+_{(Q:q)\to (R:r,S:s)}.",2502.01611
lemma,"Consider systems $AE$ with finite-dimensional Hilbert spaces, a classical system $X$ with basis elements labeled by $\mathbb{X}$ and a function $f:\mathbb{X}\to \mathbb{R}$. Define $\eta_0 = |A| (2^{\max_x f(x)} + 2^{-\min_x f(x)}) + 1$. For $\alpha \in (1,1+\frac{1}{\log \eta_0})$, we have for all states $\rho \in \cD(\cH_{EXA})$          H(A|XE)_{\rho} - \mathbb E_{x \sim \rho_X}[f(X)] - (\alpha-1) (\log \eta_0)^2 \leq H^{\uparrow,f}_\alpha(A|XE)_{\rho} \leq H(A|XE)_{\rho} - \mathbb E_{x \sim \rho_X}[f(X)]\,.          %uniformly over the set of states $\cD(\cH_{AXE})$ classical on $X$.",2502.01611
lemma,"%     Let $f:C\subset \mathbb R^d\to \mathbb R$ be a convex function on a convex set $C$. Let $A\in \mathbb R^{d'\times d}$. Let $g=\mathbb R^{d'}\to \mathbb R \cup \{+\infty\}$ be the generalized function  %     {rLL} %         g(y) =& \min_{x\in C} & f(x)\\ %             & \mathrm{subject\ to\ } & Ax = y %      %     where $g(y) = + \infty$ when the problem is infeasible. Then  %      %         \item $g(y)$ is a convex function %         \item For any $y\in \mathbb R^{d'}$ such that the problem is strictly feasible, there exists $\lambda_y\in \mathbb R^{d'}$ such that for all $y'$, $g(y') \geq g(y) + \lambda_y^T A (y'- y)$. %         \item Moreover if $f$ is bounded ($a\leq f(x)\leq b$, for all $x\in C$) and $y$ is such that there exists $x$ such that $y = Ax$ with $B(x,\delta)\subset S$ and $\delta>0$, then $||\lambda_y^T A||_2 \leq \frac{b-a}{\delta}$. %      %",2502.01611
lemma,"%  % Let $C\subset \mathbb R^d$ be closed convex set. Let $\delta>0$ and $x\in C'$ be such that $B(x,\delta)\subset C$, where $B(x,\delta)$ is the ball of radius $\delta$ centered at $x$. Let $f:C\to \mathbb R$ be a convex bounded function such that $a \leq f(x)\leq b$, for all $t\in C$. Let $f'_x:\mathbb R^d\mathcal \mathbb R$ be an affine function such that $f'_x(x) = f(x)$, and $f'_x(y)\leq f(y)$ for all $y\in C$. Then $||\grad f'_x||_2\leq \frac{a-b}{t}$. In particular the bound does not depend on $x$. %",2502.01611
theorem,"For $p\geq \frac{\log^{15} n}{n}$ with high probability we have  		\[\psi\left(D_{n,p} \right) = \delta^{\pm}\left(D_{n,p} \right).\]",2502.01631
theorem,"[Chernoff bound] 		 		Let $X\sim \Bin(n, p)$ and let $\EE[X] = \mu$. 		Then 		 			\item $\Pr[X < (1-\eta)\mu]<e^{-\eta^2\mu/2}$ for every $0 < \eta < 1$; 			\item $\Pr[X>(1+\eta)\mu] < e^{-\eta^2\mu/(2+\eta)}$ for every $\eta > 0$.",2502.01631
theorem,"[Gale-Ryser] 		 		A bipartite graph $G = (X \cup Y, E)$ with $|X| = |Y| = n$ contains an $r$-factor if and only if for all $A \subseteq X$ and $B \subseteq Y$, the following holds, 		 		 		e_G(A, B) \ge r\left(|A| + |B| - n \right).",2502.01631
theorem,"Let $\omega\left(\frac{\log^2 n}{n}\right)= p_0 \leq 1/2$. 		Then with high probability we have 		 		\delta_2(B_{n,p_0}) - \delta(B_{n,p_0}) \ge \frac{\sqrt{np_0}}{\log n}.",2502.01631
definition,"Given a digraph $D$ on $n$ vertices, a subset $X \subset V(D)$ and a real number $c \in [0,1]$, we say that a vertex $v \in X$ is \emph{$(X,c)$-heavy} if it has either at least $c|X|$ many out-neighbours or at least $c|X|$ many in-neighbours in $X$.",2502.01631
proof,"Recall that we generate $D'$ in few steps: First we expose a random bipartite graph $B'$ with edge-probability $p_0$, then we we extend it to a bipartite graph $B$ by considering the minimum degree vertices in each part of $B'$, and exposing all the edges incident to them with probability $p_1$, and lastly, we take a random permutation $\pi$ to generate $D'$, as explained in the procedure. 		Observe that, with high probability, the last part does not affect the minimum degree. 		Therefore, it is enough to show that with high probability $\delta(B) = \delta^{\pm}\left(D_{n,p} \right)$. 		 		By \Cref{thm:DegGap}, with high probability there is a unique vertex of minimum degree in $B'$, denote it by $x$, and the second minimum degree is $\delta_2(B') \ge \delta(B') + \frac{\sqrt{np_0}}{\log n}$. 		Then with high probability, after exposing edges from $x$ with probability $p_1$, we have $\deg_B(x) = \delta(B') + O(np_1)$. 		If we have $\frac{\sqrt{np_0}}{\log n} = \omega\left(np_1 \right)$ then $\deg_B(x) \le \delta_2(B') \le \delta_2(B)$ which means that $x$ has minimum degree in $B$ as well. 		Indeed, since $p_0 = \frac{p - p_1}{1 - p_1} \ge p - p_1 \ge \frac{p}{2}$, we get that 		\[\frac{\sqrt{np_0}}{\log n} \ge \frac{\sqrt{np}}{2\log n} = \omega\left(\frac{\sqrt{np}}{\log^2 n} \right) = \omega(np_1). \] 		So we have $\delta^{\pm}(D') = \delta(B) = \deg_B(x)$. 		 		Moreover, with high probability, for any $v \in [n]$ we have 		 		\deg^{\pm}_{D_{n,p}}(x) = \deg^{\pm}_{D'}(x) \le \deg^{\pm}_{D'}(v) \le \deg^{\pm}_{D_{n,p}}(v), 		 		where $\deg^{\pm}_D(v) \coloneqq \min \{\deg^-_D(v), \deg^+_D(v)\}$. 		Thus, with high probability we have $\delta^{\pm}\left(D_{n,p} \right) = \deg^{\pm}_{D_{n,p}}(x) = \deg^{\pm}_{D'}(x) = \delta^{\pm}(D')$.",2502.01631
proof,"Firstly, note that the graph generated at Step $1$ of Procedure~\ref{procedure:D} is the random binomial bipartite graph $B_{n,p_0}$. 		Using \Cref{lem:GaleRyser} it is enough to prove the following claim. 		 			 			With high probability, for any $X' \subseteq X$ and $Y' \subseteq Y$ we have 			 			 			e_{B}\left(X', Y' \right) \ge \delta\left(|X'| + |Y'| - n \right). 			 		 		 		 			Trivially, (\ref{eq:step4claim}) holds for any $X', Y'$ with $|X'| + |Y'| \le n$. 			Hence, let $X' \subseteq X$ and $Y' \subseteq Y$ be such that $|X'| + |Y'| \ge n+1$. 			Denote $x\coloneqq |X'|$, $y\coloneqq |Y'|$, and assume, without loss of generality, that $x \le y$. 			Let $\delta_2 \coloneqq \delta_2(B)$ and $\gamma \coloneqq \delta_2 - \delta$. 			Note that $X'$ might contain the min-degree vertex, but yet, we always have $e_B(X', Y) \ge \delta_2(x-1) + \delta$. 			Let $Z' \coloneqq Y \setminus Y'$ and $z \coloneqq |Z'|$, and note that since $x+y\geq n+1$ we have that $z \le x-1$. Assume towards a contradiction that $e_B(X',Y')< \delta (x+y-n)$. This implies that 			 			 			 			e_B(X', Z') &= e_B(X', Y) - e_B(X', Y') \\ 			&> (\delta+\gamma)(x-1) + \delta - \delta(x-z) \\ 			&= \gamma(x-1) + \delta z. 			 			 			We show that with high probability, for every $X'$ and $Z'$ as above, the inequality (\ref{eq:eXZ}) does not hold. 			 			\paragraph*{Case 1:} $x \leq \delta_2$. Since $z\leq x-1$ and $x-\delta\leq \delta_2-\delta=\gamma$, we have that  			$z(x-\delta)\leq \gamma (x-1)$. 			By rearranging we obtain that 			$e_B(X', Z') \leq xz\leq \gamma(x-1) + \delta z$, which contradicts (\ref{eq:eXZ}). 			 			 			\paragraph*{Case 2:}  			$\delta_2 < x  < \frac{n}{2e}$. 			Note that in this case $x = \omega(\gamma)$ and therefore we have that $\gamma(x-1)=(1-o(1))\gamma x$. 			Using the union bound, the probability of having sets $X'$ and $Z'$ for which (\ref{eq:eXZ}) holds is at most  			 			\sum_{\delta_2 < x < \frac{n}{2e}} \sum_{z\le x} \binom{n}{x} \binom{n}{z} \binom{xz}{\gamma x + \delta z} p^{\gamma x + \delta z} &\le \sum_{\delta_2 < x < \frac{n}{2e}} \left(\frac{en}{x} \right)^{2x} \sum_{z \le x} \left(\frac{exzp}{\gamma x + \delta z} \right)^{\gamma x + \delta z} \\ 			&\le \sum_{\delta_2 < x < \frac{n}{2e}} \left(\frac{en}{x} \right)^{2x} \sum_{z \le x} \left(\frac{exp}{\delta} \right)^{\gamma x} \\ 			&\le \sum_{\delta_2 < x < \frac{n}{2e}} \left(\frac{en}{x} \right)^{2x} \sum_{z \le x} \left(\frac{1.5ex}{n} \right)^{\gamma x} 			&=o(1),		 			 			where the last inequality holds since $\delta\geq \frac{2np}{3}$ and the last equality holds since $\gamma=\omega(1)$.  			 			 			\paragraph*{Case 3:} 			$\frac{n}{2e} \le x$ and $z < \frac{\gamma}{3p}$. 			For given $X'$ and $Z'$ we have 			 			\Pr\left[e_B(X',Z') > \gamma x + \delta z \right] \le \Pr\left[e_B(X',Z') > \gamma x \right] \le \binom{xz}{\gamma x}p^{\gamma x} \le \left(\frac{ezp}{\gamma} \right)^{\gamma x} < \left(\frac{e}{3} \right)^{\gamma x}. 			 			Recall that $\gamma = \omega(1)$ and $x\geq n/2e$ (so in particular we have $\gamma x=\omega(n)$) and therefore, by applying the union bound we obtain that the probability for such $X',Z'$ to exist is at most 			$$2^n\cdot  2^n\cdot \left(\frac{e}{3}\right)^{\omega(n)}=o(1).$$ 			 			 			\paragraph*{Case 4:} 			$\frac{n}{2e} \le x < n-\frac{n}{\log \log n}$ and $z\geq \frac{\gamma}{3p}= \omega\left(\frac{1}{p} \right)$. 			By \Cref{lem:deltaUppr} we have $\delta= np - 2\sqrt{np\log n} \ge np-\frac{np}{\log^2\log n}$. 			In particular, for $\eta=(\log\log n)^{-1}$ we have $(1+\eta)xp < \delta$, and hence $(1+\eta)xzp < \delta z$. 			Moreover, by combining \Cref{lem:deltaUppr} and \Cref{thm:DegGap} we get $\gamma \ge \frac{\sqrt{np_0}}{2\log n} \ge \log^6 n$, so $\gamma \eta^2=\omega(1)$. 			Therefore, by \Cref{Chernoff}, for given $X', Z'$ we have that 			 			\Pr\left[e_B(X',Z') > \gamma x + \delta z \right] \le \Pr\left[e_B(X',Z') > (1+\eta)xzp \right] \le e^{-\frac{\eta^2}{2+\eta}xzp}=2^{-\omega(n)}. 			 			Taking a union bound over all possible subsets, the probability for such $X',Z'$ to exist is at most 			$$2^n\cdot  2^n\cdot 2^{-\omega(n)}=o(1).$$ 			 			\paragraph*{Case 5:} 			$x\geq n-\frac{n}{\log\log n}$. 			Recall that $y\ge x$, so we also have $y \ge n - \frac{n}{\log\log n}$. 			Note that 			 			\frac{\delta}{n}xy - \delta(x+y-n) = \frac{\delta}{n}(n-x)(n-y) \ge 0, 			 			hence it is sufficient to show that with high probability we have $e_B(X',Y') \ge \frac{\delta}{n}xy$ for all such $X', Y'$. 			By \Cref{lem:deltaUppr} we know that with high probability we have $\delta \le np - \frac{1}{3}\sqrt{np\log n}$. 			We write 			 			\frac{\delta}{n}xy = xyp(1-\eta), 			 			where 			 			\eta = \frac{np - \delta}{np} \ge \frac{1}{3}\sqrt{\frac{\log n}{np}} > 0. 			 			Given $X',Y'$ as above, by \Cref{Chernoff} we get that 			 			\Pr\left[e_B(X',Y') < \frac{\delta}{n}xy \right] &= \Pr\left[e_B(X',Y') < xyp(1-\eta) \right] \le e^{-\frac{\eta^2}{2}xyp}=2^{-\omega(n)}. 			 			Taking a union bound over all possible subsets, we obtain that the probability for such $X',Y'$ to exist is at most $2^n\cdot 2^n\cdot 2^{-\omega(n)}=o(1)$. This completes the proof of the claim.",2502.01631
proof,"Let $\mathcal M$ be a collection of $r \le n$ edge-disjoint perfect matchings in $B$, and observe that every $M\in \mathcal M$ is translated into a $1$-factor in $D'$. 		Moreover, for every $M\neq M' \in \mathcal M$, since $M$ and $M'$ are edge-disjoint, it follows that they are being translated to edge-disjoint $1$-factors in $D'$. 		 		Next, observe that for a given $M\in \mathcal M$, by choosing $\pi\in S_n$ uniformly at random we have that the $1$-factor that $M$ is being mapped to in $D'$ corresponds to the cyclic form of a uniformly chosen permutation. 		Denote by $\sigma(\pi)$ and $\sigma(M)$ the numbers of cycles in $\pi$ and in $M$, repsectively. 		We use the simple and very nice fact from~\cite{ford2021cycle} stating that $\mathbb E\left[2^{\sigma(\pi)} \right] = n+1$. 		Therefore, by Markov inequality, we have that 		\[\Pr\left[\sigma(M) \ge 4\log n \right] \le \Pr\left[2^{\sigma(\pi)} \ge (n+1)^3 \right] \le \frac{1}{(n+1)^2}. \] 		Taking a union bound over all $M\in \mathcal M$ concludes the proof.",2502.01631
proof,"Let $\cM = \{M_1,\ldots,M_r\}$ be the collection of $r$ edge-disjoint perfect matchings in $B$, and let $v \in X$.         Let $\cF = \{F_1, \ldots, F_r \}$ be the collection of $r$ edge-disjoint $1$-factors in $D'$ such that for each $i \in [r]$ the perfect matching $M_i$ was mapped to the $1$-factor $F_i$ under $\pi$.         Given $i\in [r]$, we want to bound from above the probability that $F_i$ contains a cycle $C$ of length $|C|=t\ge \frac{n}{\log^3 n}$, such that $v$ has at least $\frac{1}{9}t$ neighbors in $C$.         We will then take a union bound over all vertices and all matchings (or $1$-factors).          Fix $t\ge \frac{n}{\log^3 n}$.         There are at most $\binom{\deg(v)}{t/9} \le \binom{2np}{t/9}$ many ways to choose $\frac{1}{9}t$ neighbours of $v$ in $Y$, and at most $\binom{n}{8t/9}$ many ways to choose the remaining vertices in $C$.         Let $T_i$ denote this set of $t$ vertices chosen in $Y$, and let $S_i \subseteq X$ be their neighbors in $M_i$.         The probability that $T_i\cup S_i$ is mapped into a cycle under $\pi$ is at most $\frac{(t-1)!}{\binom{n}{t}t!}=\frac{1}{t\binom{n}{t}}$. Therefore, the probability that $v$ is $(C,\frac 19)$-heavy for some $C$ of length $t$ in $F_i$ is at most                  	\frac{\binom{2np}{t/9} \binom{n}{8t/9}}{t\binom{n}{t}} \le \frac{\left(\frac{2enp}{t/9} \right)^{\frac{1}{9}t} \left(\frac{en}{8t/9} \right)^{\frac{8}{9}t}}{t \left(\frac{n}{t} \right)^t} = \frac{1}{t} \left(\frac{2(9e)^9}{8^8} \cdot p \right)^{\frac{1}{9}t} = o\left(\frac{1}{n^3} \right),                  where the last inequality follows as $t \ge \frac{n}{\log^3 n}$.         Taking a union bound over all $\frac{n}{\log^3 n} \le t \le n$, and over all vertices and matchings, completes the proof.",2502.01631
proof,"We bound from above the probability to output a FAILURE in Procedure~\ref{procedure:2cycles} by bounding from above the probability to fail in each of the steps that can actually result in  FAILURE (that is, step $2$, step $4$ and step $5$). 		Denote $m \coloneqq a+b$. 		 		\paragraph*{FAILURE at step $2$:} First note that since $v_1$ is not $\left(V', \frac{1}{8} \right)$-heavy, we have 		 		\left|\left\{\overrightarrow{v_1u} \in E' ~:~ u_- \in V(C) \right\} \right| &\ge \left|E'(v_1, V') \right| - \left|V(C^*) \right| \\ 		&\ge \tfrac{7}{8}m - a\\ 		&\ge \tfrac{b \log^7 n}{\sqrt{np}}, 		 		so at step $1$ of the procedure we have $E_1 \neq \emptyset$. 		Now recall that step $2$ outputs FAILURE if and only if no edge in $E_1$ was successfully exposed at step $1$. 		Since $\frac{b \log^7 n}{\sqrt{np}}$ many edges were exposed, each with probability $q$, and since $b \ge \frac{n}{4\log n}$, we get that the probability of this event to occur is at most 		 		(1-q)^{\frac{b\log^7 n}{\sqrt{np}}} \le e^{-\frac{qb \log^7 n}{\sqrt{np}}} \le e^{-\frac{q\sqrt{n}\log^6 n}{\sqrt{p}}} = e^{-\frac{1}{4}\log^2 n} = e^{-\omega(\log(np\log n))} = o\left(\tfrac{1}{np\log n} \right). 			 		 		\paragraph*{FAILURE at step $4$:} The conditions of \Cref{lem:join2cycles} immediately imply that the conditions of \Cref{lem:ManyRotationPaths} are satisfied too. 		Hence, with probability $1 - o\left(\frac{1}{np\log n} \right)$ there exist integers $t_{\ell}, t_r$ as required, and we have $\left|\END_{\ell}^{t_{\ell}} \right|, \left|\END_r^{t_r} \right| = \Omega\left(\frac{\log n}{\sqrt{q}} \right)$. 		In particular, this means that with probability $1 - o\left(\frac{1}{np\log n} \right)$ Step $4$ does not output FAILURE. 		 		\paragraph*{FAILURE at step $5$:} As $\left|\END_{\ell}^{t_{\ell}} \right|, \left|\END_r^{t_r} \right| = \Omega\left(\frac{\log n}{\sqrt{q}} \right)$, by the assumption of the lemma we get that 		\[|E_2| = \left|E'\left(\END_r^{t_r}, \END_{\ell}^{t_{\ell}} \right) \right| \ge \tfrac{1}{2} \left|\END_{\ell}^{t_{\ell}} \right| \left|\END_r^{t_r} \right| =  \Omega\left(\tfrac{\log^2 n}{q} \right). \] 		Step $5$ outputs FAILURE if and only if no edge in $E_2$ was successfully exposed. 		But since each edge in $E_2$ was exposed independently with probability $q$, the probability of this event to occur is at most $(1-q)^{\Omega (\log^2 n / q)} \le e^{-\Omega (\log^2 n)} =n^{-\omega(1)}$.",2502.01631
proof,"Procedure~\ref{procedure:factor} outputs FAILURE if and only if Procedure~\ref{procedure:2cycles} outputs FAILURE when applied at step $3$ for some $i \in [N]$. 		Hence, it is enough to show that whenever Procedure~\ref{procedure:2cycles} is applied, the conditions of \Cref{lem:join2cycles} are satisfied. 		 		Let $i \in [N]$. 		At the $i$th iteration of Procedure~\ref{procedure:factor}, we apply Procedure~\ref{procedure:2cycles} to the cycles $C, C_i$ as $C, C^*$, with $v_{C_i}, E'_i, q$. 		Note that conditions $1$--$2$ of this lemma imply conditions $1$--$2$ of \Cref{lem:join2cycles}, and moreover, we have $|C_0| \ge \frac{n}{N} \ge \frac{n}{4\log n}$. 		Hence, we get that with probability $1 - o\left(\frac{1}{np\log n} \right)$, Procedure~\ref{procedure:2cycles} does not output FAILURE when applied to $C, C_i$ with $v_{C_i}, E'_i$ and $q$. 		Taking a union bound over all $N \le 4\log n$ iterations of Procedure~\ref{procedure:factor}, we get that with probability $1 - o\left(\frac{1}{np} \right)$ it does not output FAILURE when applied to $F$ with $\bar{v}, E', q$.",2502.01631
proof,"[Proof of \Cref{lem:keygnrl}] 		By a third moment calculation and using \Cref{lem:moment}, we have 		 		\Pr \left[\sum_{i \in [\delta]} \frac{1}{c_{w,i}} \ge f(n) \right] \le \frac{\mathbb E \left[\left(\sum_{i\in [\delta]}\frac{1}{c_{w,i}} \right)^3 \right]}{f(n)^3} 		= \frac{O\left(p\log^3 n \right)}{\omega \left(np \log^3 n \right)} 		= o\left(\frac{1}{n} \right). 		 		Taking a union bound over all $n$ vertices $w \in V$ finishes the proof.",2502.01631
proof,"Given two subsets $U_1, U_2 \subset [n]$ with $|U_1|, |U_2,| = t$, we have 		\[\Pr\left[e(U_1, U_2) \ge \tfrac{1}{2}t^2 \right] \le \binom{t^2}{t^2/2}p^{t^2/2} \le (2\sqrt{p})^{t^2} < \left(\tfrac{2}{\sqrt{5}} \right)^{t^2}. \] 		Taking a union bound over all pairs of subsets, we get that the probability of having a pair of subsets $(U_1, U_2)$ with $|U_1|=|U_2|=t = \omega(\log n)$ and $e(U_1, U_2) \ge \frac{1}{2}|U_1||U_2|$ is at most 		\[\binom{n}{t}^2 \left(\tfrac{2}{\sqrt{5}} \right)^{t^2} \le n^{2t} \left(\tfrac{2}{\sqrt{5}} \right)^{t^2} = o(1). \qedhere \]",2502.01631
proof,"Procedure~\ref{procedure:final} outputs FAILURE if and only if at step $2$ for some iteration $k \in [\delta]$ Procedure~\ref{procedure:factor} outputs FAILURE when applied to $F_k, \bar{v_k}, E'_k, q$. 		Hence, it is enough to show that whenever Procedure~\ref{procedure:factor} is applied, the conditions of \Cref{lem:factor} are satisfied. 		 		Firstly, by \Cref{lem:fewcycles} and \Cref{lem:longcycle}, with high probability we have $N_k \le 4\log n$ and $\big|C_{k,0} \big| \ge \frac{n}{4\log n}$ for all $k \in [\delta]$. 		By \Cref{prop:nonedges} we further get that, with high probability, every two subsets $U_1, U_2 \subset V(D')$ of size $|U_1|, |U_2| = \Omega\left(\frac{\log n}{\sqrt{q}} \right)$ satisfy $\left|E'(U_1, U_2) \right| \ge \frac{1}{2}|U_1||U_2|$. 		 		Next, we show that with high probability for all $k \in [\delta]$ condition $1$ of \Cref{lem:factor} holds for all $i \in [N_k]$. 		For all $k \in [\delta]$ and all $i \in [N_k]$, by the definition of a $\left(V_{k,i}, \frac{1}{9} \right)$-heavy vertex and by \Cref{prop:heavyvtx}, we know that with high probability every $u \in V_{k,i}$ satisfy 		 		 		\left|E'\left(V_{k,i}, u \right) \right| \ge \tfrac{8}{9}m_{k,i} && \text{ and } && \left|E'\left(u, V_{k,i} \right) \right| \ge \tfrac{8}{9}m_{k,i}. 		 		We show that condition $1$ from \Cref{lem:factor} holds for $E'_k$. 		In fact, we show the slightly stronger following statement. 		For $k \in [\delta]$ and $i \in [N_k]$ consider the $(k,i)$th iteration of Procedure~\ref{procedure:final}, that is, the $i$th iteration of Procedure~\ref{procedure:factor} in the $k$th iteration of Procedure~\ref{procedure:final}, where we apply Procedure~\ref{procedure:2cycles} to $C, C_{k,i}$ with $v_{k,i}, E'_{k,i}$ and $q$, where $E'_{i,k}$ is the set of available edge in the input. 		We show that, with high probability, for all $(k,i)$ and for all $u \in V_{k,i}$ we have 		 		 		\left|E'_{k,i}\left(V_{k,i}, u \right) \right| \ge \tfrac{7}{8}m_{k,i},  		 		and 		 		 		\left|E'_{k,i}\left(u, V_{k,i} \right) \right| \ge \tfrac{7}{8}m_{k,i}. 		 		 		Given a vertex $u \in V(D')$, the above quantities can decrease in an iteration of Procedure~\ref{procedure:2cycles} in one of the following cases. 		 			\item[(a)] At step $2$ if $u = v_1$. 			\item[(b)] At step $2$ if $u = u_1$. 			\item[(c)] At step $4$ if an edge going out of $u$ is in $E^*$. 			\item[(d)] At step $4$ if an edge going into $u$ is in $E^*$. 			\item[(e)] At step $6$ if $u=y$. 			\item[(f)] At step $6$ if $u=x$. 		 		Denote by $Y_a(u), Y_b(u), Y_c(u), Y_d(u), Y_e(u), Y_f(u)$ the random variables counting the numbers of times that cases (a) -- (f) occured, respectively. 		 		\paragraph*{Proof of (\ref{eq:inEkiu}).} 		Let $k \in [\delta]$ and $i \in [N_k]$, and consider the $(k,i)$th iteration of Procedure~\ref{procedure:2cycles}, where $E'_{k,i}$ is the set of available edges in the input. 		If $(k,i) = (1,1)$ then we have $E'_{1,1} = E'$ and then (\ref{eq:inEkiu}) follows immediately by (\ref{eq:E11u}). 		If $(k,i) \neq (1,1)$ then by Procedure~\ref{procedure:2cycles} we have 		 		 		\left|E'_{k,i}\left(V_{k,i}, u \right) \right| \ge \left|E'_{1,1}\left(V_{k,i}, u \right) \right| - \left(Y_a(u) + Y_c(u) + Y_e(u) \right). 		 		 		In a given iteration $(k,i)$, case (a) occurs at most once, and in particular it means that the edge $\overrightarrow{v_{k,i} u}$ was successfully expose. 		The probability for this event is at most 		\[q\cdot \tfrac{m_{k,i} \log^7 n}{\sqrt{np}} \cdot \tfrac{1}{m_{k,i}} \le \tfrac{\log^3 n}{n}. \] 		By \Cref{lem:fewcycles} and since $\delta = O(np)$, with high probability there are at most $O(np\log n)$ many iteration, and hence $Y_a(u)$ is stochastically dominated by a binomial random variable $Y_a \sim \Bin\left(O(np\log n), \frac{\log^3 n}{n} \right)$. 		by \Cref{Chernoff}, with $\eta = \frac{\log^2 n}{p} -1$, we get 		 		 		 		\Pr\left[Y_a(u) \ge \log^7 n \right] &\le \Pr\left[Y_a \ge \log^7 n \right] \\ 		&\le e^{-\eta^2\cdot O(p\log^5 n)/(2+\eta)} \\ 		&\le e^{-\log^6 n} \\ 		&= o\left(\tfrac{1}{n^2p\log^2 n} \right). 		 		 		 		Similarly, in a given iteration $(k,i)$, case (e) occurs at most once, and in particular it means that $u$ was chosen as a right enpoint in $\END^{t_r}_r$, for an appropriate $t_r$, which, by \Cref{lem:ManyRotationPaths}, happens with probability at most 		\[\Theta\left(\tfrac{\log n}{m_{k,i}\sqrt{q}} \right) = O\left(\tfrac{\log^2 n}{n\sqrt{q}} \right).\] 		In this case, we know that all edges from $\END_{\ell}^{t_{\ell}}$ into $u$ were exposed with probability $q$ to be successfully exposed. 		By \Cref{lem:ManyRotationPaths}, the probability of case (e) to occur on iteration $(k,i)$ is at most 		\[O\left(\tfrac{\log^2 n}{n\sqrt{q}} \right) \cdot \tfrac{\log n}{\sqrt{q}} \cdot q = O\left(\tfrac{\log^3 n}{n} \right). \] 		Considering all iterations, we get that with high probability $Y_e(u)$ is stochastically dominated by a binomial random variable $Y_e \sim \Bin\left(O(np\log n), O\left(\frac{\log^3 n}{n} \right) \right)$, and by a similar calculation to the one in the analysis above of case (a), we get that 		 		 		\Pr\left[Y_e(u) \ge \log^7 n \right] = o\left(\tfrac{1}{n^2p\log n} \right). 		 		 		As for case (c), in a given iteration $(k,i)$ it can occur more than once. 		This happens when $u$ is a pivot for online sprinkling double rotation, which by the proof of \Cref{lem:ManyRotationPaths} happens with probability at most 		\[\Theta\left(\tfrac{\log n}{m_{k,i}\sqrt{q}} \right) = O\left(\tfrac{\log^2 n}{n\sqrt{q}} \right). \] 		Then, by the proof of \Cref{lem:ManyRotationPaths}, we know that with high probability at most $\log^3 n$ edges are exposed, each independently with probability $q$. 		In total, the probability that edge is counted in $Y_c(u)$ is at most $\frac{\sqrt{q} \log^2 n}{n} = \frac{p^{1/4}}{n^{5/4}}$, and over all iterations this happens at most $O(np\log^5 n)$ many times. 		We get that $Y_c(u)$ is stochastically dominated by a binomial random variable $Y_c\sim \Bin\left(O(np\log^5 n), \frac{p^{1/4}}{n^{5/4}} \right)$. 		Again, by \Cref{Chernoff}, with $\eta = \frac{n^{1/4}\log^3 n}{p^{5/4}} - 1$, we get 		 		 		\Pr\left[Y_e(u) \ge \log^7 n \right] \le \Pr\left[Y_e \ge \log^7 n \right] \le e^{-\log^6 n} = o\left(\tfrac{1}{n^2p\log n} \right). 		 		 		By (\ref{eq:E11u}), (\ref{eq:inEk1-Y}), (\ref{eq:casea}), (\ref{eq:casee}), (\ref{eq:casec}) and since $m_{k,i} \ge \frac{n}{4\log n}$, and by taking a union bound over all iterations and vertices, we get that with high probability we have 		\[\left|E'_{k,i}\left(V_{k,i}, u \right) \right| \ge \tfrac{8}{9}m_{k,i} - 3\log^7 n \ge \tfrac{7}{8}m_{k,i}, \] 		for all $k \in [\delta]$, $i \in [N_k]$ and $u \in V_{k,i}$, as required. 		 		\paragraph*{Proof of (\ref{eq:outEkiu}).} 		Let $k \in [\delta]$ and $i \in [N_k]$, and consider the $(k,i)$th iteration of Procedure~\ref{procedure:2cycles}, where $E'_{k,i}$ is the set of available edges in the input. 		If $(k,i) = (1,1)$ then we have $E'_{1,1} = E'$ and then (\ref{eq:inEkiu}) follows immediately by (\ref{eq:E11u}). 		If $(k,i) \neq (1,1)$ then by Procedure~\ref{procedure:2cycles} we have 		 		 		\left|E'_{k,i}\left(u, V_{k,i} \right) \right| \ge \left|E'_{1,1}\left(u, V_{k,i} \right) \right| - \left(Y_b(u) + Y_d(u) + Y_f(u) \right). 		 		 		The rest of the proof is almost similar to the proof of (\ref{eq:inEkiu}), where the analysis of case (d) is similar to the analysis of case (c), and the analysis of case (f) is similar to the analysis of case (e). 		However, the analysis of case (b) is different to the analysis of case (a) so we include it here and omit the other two cases. 		 		In a given iteration $(k,i)$, case (b) occurs at most once, and in particular it means that $u = v_{k,i}$. 		Hence, $Y_b(u) \le \Des_{\mathcal F}(u)$, and by \Cref{lem:keygnrl}, we know that with high probability we have $Y_b(u) \le (np)^{1/3}\log^2 n$. 		 		In total we get that, with high probability, for all $k \in [\delta]$, $i \in [N_k]$ and $u \in V_{k,i}$ we have 		\[\left|E'_{k,i}\left(u, V_{k,i} \right) \right| \ge \tfrac{8}{9}m_{k,i} - 2\log^7 n - (np)^{1/3}\log^2 n \ge \tfrac{7}{8}m_{k,i}, \] 		as required. 		 		Hence, by \Cref{lem:factor} we get that with probability $1 - o\left(\frac{1}{np} \right)$ Procedure~\ref{procedure:factor} does not output FAILURE when applied on the $k$th iteration in step $2$ of Procedure~\ref{procedure:final}. 		Taking a union bound over all $\delta = (1+o(1))np$ iterations we get that with high probability Procedure~\ref{procedure:final} does not output FAILURE when applied to $\mathcal F$ with $(\bar{v_1}, \ldots, \bar{v_{\delta}}), E', q$ as in the statement.",2502.01631
proof,"[Proof of \Cref{lem:uvProb}] 		For a vertex $v \in V(D')$, we consider several quantities related to $v$ during Phase $2$. 		Denote by $\e_r(v)$ and $\e_{\ell}(v)$ the numbers of times $v$ was chosen as a right and left endpoint of a path when performing online sprinkling right and left rotations, respectively. 		Denote by $\m_r(v)$ and $\m_{\ell}(v)$ the numbers of times $v$ was chosen as a pitot vertex which is not an endpoint for right and left rotations of a path, respectively. 		Recall that by $\Des_{\mathcal F}(v)$ we denote the number of times where $v$ was chosen as a designated vertex in some cycle of some $1$-factor in $\mathcal F$. 		The following claim gives an estimation of these quantities. 		 			 			With high probablity for all $v \in V(D')$ we have 			\[\e_r(v), \e_{\ell}(v), \m_r(v), \m_{\ell}(v) \le n^{1/4}p^{3/4}\log^7 n. \] 		 		 		 			We prove the statement for $\e_{\ell}(u)$ and $\m_{\ell}(u)$, where the proofs for $\e_r(u)$ and $\m_r(u)$ are similar. 			By the proof of \Cref{lem:ManyRotationPaths}, we get that for each $k \in [\delta]$ and $i \in [N_k]$, both probabilities of $u$ to be an endpoint and a mid-point in a left rotation of the path on $V_{ik}$, are stochastically dominated by the uniform distribution of choosing a subset of vertices of size $\Theta\left(\frac{\log n}{\sqrt{q}} \right) = \Theta\left(\frac{n^{1/4}\log^3 n}{p^{1/4}} \right)$ out of at least $\frac{n}{8\log n}$ vertices. 			Recall that with high probability we have $\delta = O(np)$ and $N_k \le 4\log n < \log^2 n$ for all $k \in [\delta]$, then by considering all cycles in all $1$-factors we get that both $\e_{\ell}(u)$ and $\m_{\ell}(u)$ are stochastically dominated by the random variable $X \sim \Bin\left(np\log^2 n, \frac{\alpha\log^4 n}{n^{3/4}p^{1/4}} \right)$ for some positive constant $\alpha$. 			Hence, by \Cref{Chernoff}, taking $\eta = \frac{n^{1/12}}{2p^{5/12}\log^{11}n} - 1$, we get 			 			\Pr\left[\e_{\ell}(u) \ge n^{1/4}p^{3/4}\log^7 n \right] \le \Pr\left[X \ge n^{1/4}p^{3/4}\log^7 n \right]  			\le e^{-\frac{\eta^2 \mathbb E[X]}{2+\eta}}  			< e^{-\frac{(np)^{1/3}}{2\log^4 n}} 			= o\left(\tfrac{1}{n} \right), 			 			and similarly 			 			\Pr\left[\m_{\ell}(u) \ge n^{1/4}p^{3/4}\log^7 n \right] = o\left(\tfrac{1}{n} \right). 			 			The statement then follows by taking a union bound over all $u \in V(D')$.",2502.01631
proof,"We prove the statement for $\END_{\ell}^{t_{\ell}}$, and the proof for $\END_r^{t_r}$ is similar. 	In fact, we prove the following stronger statement and show that it implies (\ref{eq:ENDq}). 	 		 		Let $t \coloneqq t(n)$ be an integer satisfying 		 		 		\left(2\log n \right)^{2t} = O\left(\tfrac{\log n}{\sqrt{q}} \right). 		 		Then with probability $1 - o\left(\frac{1}{n \log n} \right)$ we have 		 		 		\left(2\log n \right)^{2t} \le \left|\END_{\ell}^t \right| \le \left(50\log n \right)^{2t}. 		 	 	 	[Proof of \Cref{cl:ENDqell}] 		We proceed by induction on $t$. 		If $t=0$ then (\ref{eq:ENDqell}) holds trivially, as $\END_{\ell}^0 = \{u_1 \}$. 		Let $t \ge 1$ and assume that the statement holds for all $0 \le t' \le t-1$. 		 		Observe that, using the notation introduced for online sprinkling left rotations of a path, one can write 		 		 		\END_{\ell}^t = \bigcup_{u \in \END_{\ell}^{t-1}} \END_{\ell}^1(P^u) = \bigcup_{u \in \END_{\ell}^{t-1}} \bigcup_{y \in \IN{u}{V_2(P^u)}} \left(\IN{y_+}{V_1(P^u)} \right)^+. 		 		We show that, with high probability, the union in (\ref{eq:ENDunion}) consists of sets which are ``almost'' pairwise disjoint. 		That is, we show that, with high probability, every vertex in $V(P)$ is the endpoint of at most two different paths obtained from $P$ after performing $t-1$ many rotations. 		Assuming that, it follows that the size of the union in (\ref{eq:ENDunion}) is at least half of the sum of the sizes of the sets. 		 		Recall that for any $u \in \END_{\ell}^{t-1}$ we have $V_1(P^u)\cup V_2(P^u) = V_1(P)\cup V_2(P)$, since performing left rotations to a path does not change its right half. 		To show that the union in (\ref{eq:ENDunion}) consists of sets which are almost pairwise disjoint, we want to count the number of such sets in which a given vertex in $V_1(P)\cup V_2(P)$ is contained. 		Then we can show that with high probability this count is at most $2$ for all relevant vertices. 		Given an integer $t'$ and a vertex $x \in V_1(P)\cup V_2(P)$ we let $Z^{x,t'}$ be the random variable that counts the number of pairs $(u,y)$, with $u \in \END_{\ell}^{t'}$ and $y \in \IN{u}{V_2(P^u)}$, such that $x \in \IN{y_+}{V_1(P^u)}$. 		For an integer $k \ge 1$, let $Z^{t'}_k$ be the random variable that counts the number of vertices $x \in V_1(P)\cup V_2(P)$ for which $Z^{x,t'} \ge k$. 		 		We show that the following two statements hold. 		 			\item[(1)] If (\ref{eq:ENDqell}) holds for $t-1$, then with probability $1 - o\left(\frac{1}{n\log^2 n} \right)$ we have that $Z^{t-1}_3 = 0$. 			\item[(2)] If (\ref{eq:ENDqell}) holds for $t-1$ and $Z^{t-1}_3 = 0$, then with probability $1 - o\left(\frac{1}{n\log n} \right)$ we have that (\ref{eq:ENDqell}) holds for $t$. 		 		Note that since $q \ge \frac{\log^3 n}{n}$ we get that (\ref{eq:qp}) implies $t \le \frac{\log n}{4\log\log n}$. 		Assuming (1), and by taking a union bound over all $t = o(\log n)$ steps we get that 		 		\Pr\left[Z^{t'}_3 = 0 ,\, \forall t' \in \{0, \ldots, t-1 \} \right] = 1 - t\cdot o\left(\tfrac{1}{n\log^2 n} \right) = 1 - o\left(\tfrac{1}{n\log n} \right). 		 		The induction step then follows immediately from (2). 		Hence it is left to prove (1) and (2). 		 		\paragraph*{Proof of (1).} 		Let $u \in \END_{\ell}^{t-1}$ and let $P^u \in \mathcal P_{\ell}^{t-1}$ be a path for which $u$ is its left endpoint (note that if $t=1$ then $u=u_1$ and $P^u=P$). 		Recall that $P$ contains no $\left(P, \frac{1}{8} \right)$-heavy vertices, implying that 		 		\tfrac{1}{8}m \le \left|E'\left(V_2(P^u), u \right) \right| \le \tfrac{1}{4}m && \text{ and } && \tfrac{1}{8}m \le \left|E'\left(V_1(P^u), y_+ \right) \right| \le \tfrac{1}{4}m. 		 		Moreover, when performing online sprinkling left rotations to $P^u$ with $E'$, we have that 		 		&\left|\IN{u}{V_2(P^u)} \right| \sim \Bin\left(\left|E'(V_2(P^u), u) \right|, \tfrac{100\log n}{m} \right) \\ 		&\left|\IN{y_+}{V_1(P^u)} \right| \sim \Bin\left(\left|E'(V_1(P^u), y_+) \right|, \tfrac{100\log n}{m} \right),     		 		for every $y \in \IN{u}{V_2(P^u)}$, and thus 		 		12 \log n &\le \mathbb E \left[\left|\IN{u}{V_2(P^u)} \right| \right] \le 25 \log n, \\ 		12 \log n &\le \mathbb E \left[\left|\IN{y_+}{V_1(P^u)} \right| \right] \le 25 \log n. 		 		By \Cref{Chernoff} with a suitable choice of $\eta$, given $u \in \END_{\ell}^{t-1}$ and $y \in \IN{u}{V_2(P^u)}$, we have 		 		 		 		&\Pr\left[3\log n \le \left|\IN{u}{V_2(P^u)} \right| \le 50\log n \right] \ge 1 - 2n^{-\frac{27}{8}}, \\ 		&\Pr\left[3\log n \le \left|\IN{y_+}{V_1(P^u)} \right| \le 50\log n \right] \ge 1 - 2n^{-\frac{27}{8}}. 		 		 		By taking a union bound over all $u \in \END_{\ell}^{t-1}$ we get 		 		\Pr\left[\forall u \in \END_{\ell}^{t-1},\; 3\log n \le \left|\IN{u}{V_2(P^u)} \right| \le 50 \log n \right] &\ge 1 - 2\left|\END_{\ell}^{t-1} \right| \cdot n^{-\frac{27}{8}}. 		 		Recall that (\ref{eq:qp}) implies $t \le \frac{\log n}{4\log\log n}$. 		Since (\ref{eq:ENDqell}) holds for $t-1$ we have that 		 		 		 		2\left|\END_{\ell}^{t-1} \right|\cdot n^{-\frac{27}{8}} &\le 2\left(50\log n \right)^{2(t-1)}\cdot n^{-\frac{27}{8}} \\ 		&\le \left(\log n \right)^{2t} n^{-\frac{27}{8} + o(1)} \\ 		&\le n^{-\frac{25}{8} + o(1)}, 		 		 		which with the above implies that 		 		 		\Pr\left[\forall u \in \END_{\ell}^{t-1},\; 3\log n \le \left|\IN{u}{V_2(P^u)} \right| \le 50\log n \right] \ge 1 - n^{-\frac{25}{8}+o(1)}. 		 		 		Now note that given $u \in \END_{\ell}^{t-1}$ and $y \in \IN{u}{V_2(P^u)}$, for every $x \in V_1(P^u)$ we have $\Pr\left[x \in \IN{y_+}{V_1(P^u)} \right] = \frac{100\log n}{m}$. 		Moreover, given $u_1, u_2 \in \END_{\ell}^{t-1}$, $y_1 \in \IN{u_1}{V_2(P^{u_1})}$ and $y_2 \in \IN{u_2}{V_2(P^{u_2})}$ such that $(u_1, y_1) \neq (u_2,y_2)$, the events $\left\{x \in \IN{(y_1)_+}{V_1(P^{u_1})} \right\}$ and $\left\{x \in \IN{(y_2)_+}{V_1(P^{u_2})} \right\}$ are independent. 		Hence, given $x \in V_1(P) \cup V_2(P)$, by taking a union bound over all $u_1, u_2, u_3 \in \END_{\ell}^{t-1}$ and $y_i \in \IN{u_i}{V_2(P^{u_i})}$ for $i=1,2,3$, by (\ref{eq:Pusize}) and since (\ref{eq:ENDqell}) holds for $t-1$, we have 		 		\Pr \left[Z^{x,t-1} \ge 3 \right] &\le \sum_{\substack{u_i \in \END_{\ell}^{t-1} \\ i=1,2,3}} \Pr\left[\forall i\in[3]\; \exists y_i \in \IN{u_i}{V_2(P^{u_i})} \text{ s.t. } x \in \bigcap_{i=1}^3 \IN{(y_i)_+}{V_1(P^{u_i})} \right] \\ 		&\le \sum_{\substack{u_i \in \END_{\ell}^{t-1} \\ i=1,2,3}} \sum_{\substack{y_i \in \IN{u_i}{V_2(P^{u_i})} \\i=1,2,3}} \Pr\left[x \in \bigcap_{i=1}^3 \IN{(y_i)_+}{V_1(P^{u_i})} \right] \\ 		&\le \sum_{\substack{u_i \in \END_{\ell}^{t-1} \\ i=1,2,3}} \left|\IN{u_1}{V_2(P^{u_1})} \right| \left|\IN{u_2}{V_2(P^{u_2})} \right| \left|\IN{u_3}{V_2(P^{u_3})} \right| \cdot \left(\tfrac{100\log n}{m} \right)^3 \\ 		&\le \left|\END_{\ell}^{t-1} \right|^3 \left(\left(50\log n \right)^3 +  \left(\tfrac{1}{4}m \right)^3 \cdot n^{-\frac{25}{8}+o(1)} \right) \left(\tfrac{100\log n}{m} \right)^3 \\ 		&\le 2\left(50\log n \right)^{6(t-1)} \left(100\log n \right)^3 \left(\tfrac{100\log n}{m} \right)^3 \\ 		&\le \tfrac{64}{m^3}\left(50\log n \right)^{6t}. 		 		 		Lastly, we take a union bound over all $x \in V_1(P)\cup V_2(P)$. 		Recall that $t \le \frac{\log n}{4\log\log n}$ and $m \ge \frac{n}{4\log n}$, so we get 		 		\Pr\left[Z^{t-1}_3 \ge 1 \right] &\le \sum_{x \in V_1\cup V_2} \Pr\left[Z^{x,t-1} \ge 3 \right] \\ 		&\le \tfrac{32}{m^2} \left(50\log n \right)^{6t} \\ 		&\le \tfrac{512\log^2 n}{n^2} \cdot n^{\frac{3}{4}+o(1)} \\ 		&= n^{-\frac{5}{4}+o(1)} \\ 		&= o\left(\tfrac{1}{n\log^2 n} \right), 		 		completing the proof of (1). 		 		 		\paragraph*{Proof of (2).} 		Having $Z^{t-1}_3 = 0$ is equivalent to having $Z^{x,t-1} \le 2$ for all $x \in V_1(P) \cup V_2(P)$. 		Thus, by (\ref{eq:ENDunion}) we have 		 		 		\left|\END_{\ell}^t \right| \ge \tfrac{1}{2} \sum_{u \in \END_{\ell}^{t-1}} \sum_{y \in \IN{u}{V_2(P^u)}} \left|\IN{y_+}{V_1(P^u)} \right| 		 		and 		 		 		\left|\END_{\ell}^t \right| \le \sum_{u \in \END_{\ell}^{t-1}} \sum_{y \in \IN{u}{V_2(P^u)}} \left|\IN{y_+}{V_1(P^u)} \right|. 		 		Hence, we wish to approximate the typical size of $\left|\IN{y_+}{V_1(P^u)} \right|$. 		 		Similarly to the argument yielding (\ref{eq:Pusize}), by (\ref{eq:Pexpsize}) we have that the probability 		\[\Pr\left[\forall u \in \END_{\ell}^{t-1} \; \forall y\in \IN{u}{V_2(P^u)} \; 3\log n \le \left|\IN{y_+}{V_1(P^u)} \right| \le 50\log n \right] \] 		is at least 		 		1 - 2\sum_{u\in \END_{\ell}^{t-1}} \sum_{y\in \IN{u}{V_2(P^u)}} n^{-\frac{27}{8}} &\ge 1 - 2n^{-\frac{27}{8}} \sum_{u \in \END_{\ell}^{t-1}}\left|\IN{u}{V_2(P^u)} \right|. 		 		By (\ref{eq:Pusize}) and since (\ref{eq:ENDqell}) holds for $t-1$ and $t \le \frac{\log n}{4\log\log n}$, we have 		 		2n^{-\frac{8}{27}}\sum_{u \in \END_{\ell}^{t-1}} \left|\IN{u}{V_2(P^u)} \right| &\le 2n^{-\frac{27}{8}}\left|\END_{\ell}^{t-1} \right| \left(50\log n + \tfrac{1}{4}m \cdot n^{-\frac{25}{8}+o(1)} \right) \\ 		&\le n^{-\frac{27}{8}}\left(50\log n \right)^{2(t-1)} 100\log n \\ 		&\le n^{-\frac{27}{8}} \left(50\log n \right)^{2t} \\ 		&\le n^{-\frac{25}{8}+o(1)}. 		 		With the above this implies 		 		 		 		\Pr\left[\forall u \in \END_{\ell}^{t-1} \; \forall y\in \IN{u}{V_2(P^u)} \; 3\log n \le \left|\IN{y_+}{V_1(P^u)} \right| \le 50\log n \right] \ge 1 - n^{-\frac{25}{8}+o(1)}. 		     		 		Hence, by (\ref{eq:Pusize}), (\ref{eq:unionuppr}) and (\ref{eq:Puvsize}) we get that 		 		\left|\END_{\ell}^t \right| &\le \sum_{u \in \END_{\ell}^{t-1}} \sum_{y \in \IN{u}{V_2(P^u)}} \left|\IN{y_+}{V_1(P^u)} \right| \\ 		&\le \sum_{u \in \END_{\ell}^{t-1}} \left|\IN{u}{V_2(P^u)} \right| \cdot 50\log n \\ 		&\le \left|\END_{\ell}^{t-1} \right| \left(50\log n \right)^2 		 		holds with probability $1 - n^{-\frac{25}{8}+o(1)} = 1 - o\left(\frac{1}{n\log n} \right)$. 		Similarly, by (\ref{eq:Pusize}), (\ref{eq:unionlwr}) and (\ref{eq:Puvsize}) we get that 		 		\left|\END_{\ell}^t \right| &\ge \tfrac{1}{2}\sum_{u \in \END_{\ell}^{t-1}} \sum_{y \in \IN{u}{V_2(P^u)}} \left|\IN{y_+}{V_1(P^u)} \right| \\ 		&\ge \sum_{u \in \END_{\ell}^{t-1}} \left|\IN{u}{V_2(P^u)} \right| \cdot \tfrac{3}{2}\log n \\ 		&\ge \left|\END_{\ell}^{t-1} \right| \left(\tfrac{3}{\sqrt{2}} \log n \right)^2 \\ 		&\ge \left|\END_{\ell}^{t-1} \right| \left(2\log n \right)^2 		 		also holds with probability $1 - o\left(\frac{1}{n\log n} \right)$. 		Together with the assumption that (\ref{eq:ENDqell}) holds for $t-1$, we get that with probability $1 - o\left(\frac{1}{n\log n} \right)$ we have 		\[ \left(2\log n \right)^{2t} \le \left|\END_{\ell}^t \right| \le \left(50\log n \right)^{2t}, \] 		finishing the proof of (2).",2502.01631
proof,"Fix $v \in [n]$. For simplicity, suppose that the collection of $k$ matchings is $M_1, \ldots, M_k$ and write $C_i$ and $c_i$ instead of $C_{v,i}$ and $c_{v,i}$. Throughout the proof we will only present the arguments for the case $k=3$. The corresponding claims for $k=2$ should follow similarly. Let $\cE(a_1,a_2,a_3)= (c_1=a_1)\cap (c_2=a_2) \cap (c_3=a_3)$ be the event that the cycle $c_i$ has length $a_i$ and let $\cE(a_1,a_2)=(c_1=a_1)\cap (c_2=a_2)$ the corresponding event for two cycles. Our goal is to prove that $\PP(\cE(a_1,a_2,a_3))=O(n^{-3})$ and $\PP(\cE(a_1,a_2))$.   Define the random subset $T:=V\left(C_i\cup C_j\cup C_k\right)\setminus \{v\}$. By a slight abuse of notation, we also consider $T$ to be a subset of $X$. Since the matchings $M_1,M_2$, and $M_3$ are edge-disjoint, we observe that in the bipartite graph $G:=M_1\cup M_2\cup M_3$, the following properties hold:        \item $e_G\left(T,\pi^{-1}(T)\right)\geq c_1+c_2+c_3$, and      \item the subgraph of $G$ induced by $(T\cup \{v\})\cup\pi^{-1}(T\cup\{v\})$ has no isolated vertices, and      \item $\pi^{-1}(v)\in Y \textrm{ has three neighbors in } T \cup \{v\}.$     These observations are sufficient to prove the following claim:       $\Prob(|T|=O(1))=O(n^{-3}).$         Conditioning on the size of $T$, we distinguish between two cases:      \paragraph{\bf{Case 1.}} $v\pi^{-1}(v)\notin E(G)$. In this case, there are $n-3$ possible choices for $y\in Y$, where $y=\pi^{-1}(v)$. The probability that $\pi(y)=v$ is $\frac{1}{n}$. Let $N\coloneqq N_G(y)$ denote the set of the three neighbors of $y$ in $G$. Next, choose a subset $S\subseteq X \setminus \left(\{v\}\cup N\right)$ of size $|T|-3$, and define $T:= N\cup S$.           For each $x\in T$, select a non-empty subset of neighbors $S_x\subseteq N_G(x)$, and let $T':=\cup_{x\in T} S_x\subseteq Y$ be the obtained set. Clearly, there are at most $7^T$ ways to choose $T'$ of size $|T|$ such that, if $\pi(T'\cup \{y\})=T\cup\{v\}$, then its image under $D_{\pi}$ will give us three cycles containing $v$ on $T$. The probability that $\pi(T')=T$ is at most $\frac{T!}{(n)_{T}}$. For $|T|=O(1)$ this is of order $O\left(\left(\frac{1}{n}\right)^{T}\right)$.  Therefore, the probability that the edges $E(T\cup \{v\},\pi^{-1}(T)\cup\{y\})$ map to $T\cup \{v\}$ in $D_{\pi}$, forming three cycles containing $v$, is at most  $$(n-3)\cdot \frac{1}{n}\cdot \binom{n}{|T|-3}\cdot 7^{|T|}\cdot O(n^{-|T|})=O(n^{-3})$$ as desired.  \paragraph{\bf{Case 2.}}  $v\pi^{-1}(v)\in E(G)$. This case is quite similar to the previous one, with a few notable differences. Here, there are only $3$ possible choices for $y=\pi^{-1}(v)$, since  $y$ must be chosen as a neighbor of $v$. After selecting $y$ and including its two additional neighbors in $T$, we need to choose a subset $S\subseteq X$ of size $|T|-2$ (instead of $|T|-3$ as in the previous case) extra vertices to complete the set $T$.    Thus, the probability that the edges $E(T\cup \{v\},\pi^{-1}(T)\cup\{y\})$ are mapped to $T\cup \{v\}$ in $D_{\pi}$, forming three cycles containing $v$, is at most  $$3\cdot \frac{1}{n}\cdot \binom{n}{|T|-2}\cdot 7^{|T|}\cdot O(n^{-|T|})=O(n^{-3})$$ as desired.   To complete the proof of the claim take an upper bound over all possible values of $|T|$. Since $|T|=O(1)$, the result follows.",2502.01631
proof,"Suppose that $|T|\leq a_1+a_2+a_3/2$ and $\mathcal E(a_1,a_2,a_3)$ holds. In this case, we must have $e_G(T,\pi^{-1}(T))\geq a_1+a_2+a_3.$ Let $x$ be the number of vertices of degree greater than $1$ in the subgraph of $G$ induced by $T\cup \pi^{-1}(T)$. Now, using the fact that the maximum degree in $G$ is $3$, we obtain that:  $$a_1+a_2+a_3\leq 3x+a_1+a_2+a_3/2-x,$$ which simplifies to  $$x\geq a_3/4.$$ Next, note that in this scenario, it is possible to greedily find a subset of $a_3/20=\omega(1)$ vertex-disjoint cherries (pairs of vertices sharing a common neighbor), with the centers of the cherries forming a subset $S\subseteq \pi^{-1}(T)$. This implies that $|N_G(S)|\geq 2|S|$.  Now, consider the number of pairs $(T,T')$ of subsets $T\subseteq X, T'\subseteq Y$ with $|T|=|T'|\leq a_1+a_2+a_3/2$ and there are at least $a_3/20$ vertices in $T'$ whose neighborhood in $T$ is of size at least $a_3/10$. This number is at most  $$\binom{n}{a_3/20}\binom{n}{|T|-a_3/10}\leq \left(\frac{Cn}{T}\right)^{|T|-a_3/20},$$ for some constant $C>0$.   Given $T$, there are at most $7^{|T|}$ ways to choose $T'$ (recall that the minimum degree in the graph induced by $T\cup \pi^{-1}(T)$ is at least $1$). Now, for each such pair $(T,T')$, the probability that $\pi(T')=T$ is at most $\binom{n}{|T|}^{-1}\leq (|T|/n)^{|T|}$. Therefore, we obtain that   $$ \Prob\left((|T|\leq a_1+a_2+a_3/2)\cap \mathcal E(a_1,a_2,a_3) \right)\leq \left(\frac{Cn}{T}\right)^{|T|-a_3/20}\cdot 7^{|T|}\cdot \left(\frac{|T|}{n}\right)^{|T|}=n^{-\omega(1)}. $$  This completes the proof.",2502.01631
proof,"Let $\cE^{(3)}:=\cE(a_1,a_2,a_3)\cap \cA$, $\cE^{(2)}:=\cE(a_1,a_2)\cap (t_1<t_2)$ and $\cE^{(1)}:=(c_1=a_1)$. Fix an instance of $\cE^{(3)}$. For $1\leq i\leq 3$, let $U_i$ be the ordered set of labels revealed from steps $t_{i-1}+1$ to $t_i-1$ (where $t_0=0$). Note by the description of the procedure and the observation preceding the claim, that such sets $U_1\cup U_2\cup U_3$ uniquely determines the instance of $\cE^{(3)}$.  Let $P_3$ be the path containing $v$ using the edges of $M_3$ during the procedure. Note that at each step of the process after $t_{2}$, the length of $P_3$ increases in at least one edge. Thus, conditioned on fixed $U_1$ and $U_2$, all the events leading to the possible sequence of vertices $U_{3}$ until step $t_{3}-1$ are disjoint. Moreover, as discussed earlier, the probability of closing the cycles at step $t_3$ conditioned on $U_3$ is at most $2/n$ (since, by assumption, there are always at least $n/2$ unlabeled vertices at any given stage of the procedure). Therefore,       \PP(\cE^{(3)}\mid U_1,U_2)=\sum_{U_3}\PP(\cE^{(3)}\mid U_1,U_2,U_3)\PP(U_3)\leq\frac{2}{n}\sum_{U_3}\PP(U_3)=\frac{2}{n}.  Consequently, we obtain that      \PP(\cE^{(3)})=\sum_{U_1,U_2}\PP(\cE(a_1,a_2,a_3)\mid U_1,U_2)\PP(U_1, U_2)=\frac{2}{n}\sum_{U_1,U_2}\PP(U_1, U_2)\leq\frac{2}{n}\PP(\cE^{(2)}).  A similar argument shows that      \PP(\cE^{(2)})\leq \frac{2}{n}\PP(\cE^{(1)}).  Since $\PP(\cE^{(1)})=\frac{1}{n}$, by putting together the two inequalities, we have that $\PP(\cE^{(3)})=O(n^{-3})$. This concludes the proof.",2502.01631
proof,"We compute the probability by splitting into several cases depending on the times that each cycle close. Indeed, note that since $t_1\leq t_2,t_3$, the event $\cE(a_1,a_2,a_3)$ can be written as the disjoint union of the events              \cE(a_1,a_2,a_3)=\cE_1\cup \cE_2 \cup \cE_3           where we define the events $\cE_i$ by              \cE_1&:=\cE(a_1,a_2,a_3)\cap (t_3\leq t_2)\\         \cE_2&:=\cE(a_1,a_2,a_3)\cap  (t_1=t_2<t_3)\\         \cE_3&:=\cE(a_1,a_2,a_3)\cap (t_1 < t_2 < t_3).          We bound $\PP(\cE_i)$ for $1\leq i \leq 3$.     \paragraph{\textbf{Case 1: $\cE_1$}} Let $S=V\left(C_1\cup C_2\cup C_3\right)$. Note that in this case $|S|\leq a_1+a_2<a_1+a_2+a_3/2$. Hence, by Claim \ref{clm:cyclesbig} and \ref{large intersection}, we obtain that              \PP(\cE_1)=\PP(\cE_1\cap (|S|=O(1)))+\PP(\cE_1\cap (|S|=\omega(1)))=O(n^{-3})+O(n^{-\omega(1)})=O(n^{-3}).           \paragraph{\textbf{Case 2: $\cE_2$}} Let $S=V\left(C_1\cup C_2\right)$. Note that in this case $|S|=a_1\leq a_1+a_2/2$. Let $\tilde{\cE}_2$ be the event $\cE(a_1,a_2)\cap (t_1=t_2)$. Thus, by Claim \ref{clm:big2} and \ref{cl:large2}, we obtain that              \PP(\tilde{\cE_2})=\PP(\tilde{\cE_2}\cap (|S|=O(1)))+\PP(\tilde{\cE_2}\cap (|S|=\omega(1)))=O(n^{-2}).          Let $U$ be the ordered set of labels revealed from steps $t_2$ to step $t_3-1$ conditioned on a instance $\omega \in \tilde{\cE_2}$. By a similar argument as in Claim \ref{clm:difclosing}, we obtain that              \PP(\cE_2\mid \omega)=\sum_{U}\PP(\cE_2\mid \omega, U)\PP(U)\leq \frac{2}{n}.           Therefore,              \PP(\cE_2)=\sum_{\omega \in \tilde{\cE_2}}\PP(\cE_2\mid \omega)\PP(\omega)\leq \frac{2}{n}\PP(\tilde{\cE_2})=O(n^{-3}).           \paragraph{\textbf{Case 3: $\cE_3$}}     We obtain that $\PP(\cE_3)=O(n^{-3})$ immediately from Claim \ref{clm:difclosing}.      By putting all the cases together, we obtain that           \PP(\cE(a_1,a_2,a_3))=O(n^{-3})          as desired.",2502.01631
proof,"[Proof of Lemma \ref{lem:moment}] Let $v \in [n]$. For simplicity, we will write $C_i$ and $c_i$ instead of $C_{v,i}$ and $c_{v,i}$, respectively. We begin with an auxiliary result.   The following three bound holds:  		\item For every $i \in [\delta]$,  		$\mathbb E\left(\frac{1}{c^3_{i}} \right) = O\left(\frac{1}{n} \right)$. 		\item For every distinct $i,j \in [\delta]$, 		$\mathbb E \left(\frac{1}{c^2_{i} c_{j}} \right) = O\left(\frac{\log^2 n}{n^2} \right).$ 		 		\item For every distinct $i,j,k \in [\delta]$, 		$\mathbb E \left(\frac{1}{c_{i} c_{j} c_{k}} \right) = O \left(\frac{\log^3 n}{n^3} \right)$.     We start by showing statement (1). Note that for a single cycle, the probability $\PP(c_i=t)=1/n$. Hence,      \EE\left(\frac{1}{c_i^3}\right)=\sum_{a_i\in [n]}\frac{1}{a_i^3}\PP(c_i=a_i)=\frac{1}{n}\sum_{a_i\in [n]}\frac{1}{a_i^3}=O\left(\frac{1}{n}\right).   To prove statement (2) and (3) we use Lemma \ref{lem:highmoments}. Indeed, for statement (2) we have that      \EE\left(\frac{1}{c_i^2c_j}\right)&=\sum_{a_i,a_j \in [n]}\frac{1}{a_i^2a_j}\PP\left((c_i=a_i)\cap(c_j=a_j)\right)\\ &\leq \sum_{a_i,a_j \in [n]}\frac{1}{a_ia_j}\PP\left((c_i=a_i)\cap(c_j=a_j)\right)\leq \sum_{a_i\leq a_j}\frac{2}{a_ia_j}\PP\left((c_i=a_i)\cap(c_j=a_j)\right)\\     &\leq\sum_{a_i\leq a_j\leq n/4}\frac{2}{a_ia_j}\PP\left((c_i=a_i)\cap(c_j=a_j)\right)+\sum_{a_i\in [n]}\frac{8}{na_i}\PP\left(c_i=a_i\right)\\     &=O(n^{-2})\left(\sum_{a_i\leq a_j\leq n/4}\frac{1}{a_ia_j}+\sum_{a_i\in [n]}\frac{1}{a_i}\right)=O\left(\frac{\log^2 n}{n^2}\right),  where we use Lemma \ref{lem:highmoments} for two cycles.  A similar computation holds for statement (3):      \EE\left(\frac{1}{c_ic_jc_k}\right)&=\sum_{a_i,a_j,a_k \in [n]}\frac{1}{a_ia_ja_k}\PP\left((c_i=a_i)\cap(c_j=a_j)\cap(c_k=a_k)\right)\\     &\leq \sum_{a_i\leq a_j\leq a_k}\frac{6}{a_ia_ja_k}\PP\left((c_i=a_i)\cap(c_j=a_j)\cap(c_k=a_k)\right)     =\Sigma_1+\Sigma_2+\Sigma_3,  where      &\Sigma_1:=\sum_{a_i\leq a_j\leq a_k\leq n/6}\frac{6}{a_ia_ja_k}\PP\left((c_i=a_i)\cap(c_j=a_j)\cap(c_k=a_k)\right)\\     &\Sigma_2:= \sum_{\substack{a_i\leq a_j\leq n/6\\ a_k>n/6}}\frac{6}{a_ia_ja_k}\PP\left((c_i=a_i)\cap(c_j=a_j)\cap(c_k=a_k)\right), \textrm{ and }\\     &\Sigma_3:=\sum_{\substack{a_i\in [n]\\ n/6<a_j\leq a_k}}\frac{6}{a_ia_ja_k}\PP\left((c_i=a_i)\cap(c_j=a_j)\cap(c_k=a_k)\right)    We bound each of the $\Sigma_i$s separately as follows:   By Lemma \ref{lem:highmoments} applied for three cycles, we know that for $a_1\leq a_2\leq a_3\leq n/6$, the probability $\PP((c_i=a_i)\cap (c_j=a_j)\cap (c_k=a_k))= O(n^{-3})$. Therefore,      \Sigma_1=O\left(n^{-3}\sum_{a_1\leq a_2\leq a_3\leq n/6}\frac{1}{a_1a_2a_3}\right)=O\left(\frac{\log^3 n}{n^3}\right)  Similarly, Lemma \ref{lem:highmoments} applied for two cycles gives that if $a_1\leq a_2\leq n/6$, then $\PP((c_i=a_i)\cap(c_j=a_j))=O(n^{-2})$. Hence      \Sigma_2\leq \sum_{a_i\leq a_j\leq n/6}\frac{36}{na_ia_j}\PP\left((c_i=a_i)\cap(c_j=a_j)\right)= O\left(n^{-3}\sum_{a_i\leq a_j\leq n/6}\frac{1}{a_ia_j}\right)=O\left(\frac{\log^2 n}{n^3}\right)  Finally, to bound $\Sigma_3$, we just need to use that $\PP(c_i=a_i)=1/n$. Therefore,  \Sigma_3 \leq \sum_{a_i\in [n]}\frac{216}{n^2a_i}\PP\left(c_i=a_i\right)=\frac{216}{n^3}\sum_{a_i\in [n]}\frac{1}{a_i}=O\left(\frac{\log n}{n^3}\right)  By summing everything together, we obtain       \EE\left(\frac{1}{c_ic_jc_k}\right)=O\left(\frac{\log^3 n}{n^3}\right).  This concludes the proof of the claim.",2502.01631
proposition,"Let $B = (X \cup Y, E)$ be a bipartite graph with $|X| = |Y| = n$ and with maximum degree at most $2np$ for some $0 \le p \le \varepsilon$, and suppose that $B$ contains a collection $\cM$ of $r \le n$ edge-disjoint perfect matchings. 		Let $\pi \in S_n$ be a permutation chosen uniformly at random, and consider $D' \coloneqq D_{\pi}(B)$. 		Then $D'$ contains a collection $\cF$ of $r$ edge-disjoint $1$-factors and with high probability contains no $\left(C, \frac{1}{9} \right)$-heavy vertices for all cycles $C$ of length at least $\frac{n}{\log^3 n}$ in all $1$-factors in $\cF$.",2502.01631
proposition,"Let $p \in \left(0, \frac{1}{5} \right)$. 		Let $n$ and $t \coloneqq t(n) = \omega(\log n)$. 		Then with high probability $D_{n,p}$ does not contain any two subsets $U_1, U_2 \subset [n]$ with $|U_1|, |U_2| = t$ such that $e(U_1, U_2) \ge \frac{1}{2}|U_1||U_2|$.",2502.01631
lemma,"[\cite{krivelevich2012optimal}] 		 		If $\frac{\log n}{n} \le p_0 < 1$ then with high probability 		\[np_0 - 2\sqrt{np\log n} \le \delta(B_{n,p_0}) \le np_0 - \frac{1}{3}\sqrt{np_0 \log n}. \]",2502.01631
lemma,"Let $D'$ be a digraphs generated by Procedure~\ref{procedure:D}. 		Then with high probability we have $\delta^{\pm}\left(D_{n,p} \right) = \delta^{\pm}\left(D' \right)$.",2502.01631
lemma,"Let $B$ be a random bipartite graph generated as in the description given in Steps 1-3 of Procedure~\ref{procedure:D}, and let $\delta \coloneqq \min\left\{\deg_{B}\left(x^+ \right), \deg_{B}\left(y^- \right) \right\}$. 		Then with high probability there are $\delta$ edge-disjoint perfect matchings in $B$.",2502.01631
lemma,"Let $B=(X\cup Y,E)$ be a bipartite graph with $|X|=|Y|=n$, and suppose that $B$ contains $r\leq n$ edge-disjoint perfect matchings. 		Let $\pi \in S_n$ be a permutation chosen uniformly at random, and consider the digraph $D' \coloneqq D_{\pi}(B)$. Then $D':=D_{\pi}(B)$ contains $r$ edge-disjoint $1$-factors and with high probability each of which consists of at most $4\log n$ directed cycles.",2502.01631
lemma,"Let $\frac{\log^{15}n}{n} \le p \in [0,1]$ and $q = \sqrt{\frac{p}{n \log^8 n}}$, and assume that $P$ contains no $\left(P, \frac{1}{8} \right)$-heavy vertices. 		Then with probability $1-o\left(\frac{1}{n \log n} \right)$ the following hold. 		There exist integers $t_{\ell} \coloneqq t_{\ell}(P)$ and $t_r \coloneqq t_r(P)$ satisfying $t_{\ell}, t_r \le \frac{\log n}{4\log\log n}$ and such that after performing online sprinkling double rotations to $P$ with $E'$ and $(t_{\ell},t_r)$, we have 		 		 		\left|\END_{\ell}^{t_{\ell}} \right|, \left|\END_r^{t_r} \right| = \Omega\left(\tfrac{\log n}{\sqrt{q}} \right).",2502.01631
lemma,"Let $n$ be an integer and let $\frac{\log^{15}n}{n} \le p \le \varepsilon$ and $q = \sqrt{\frac{p}{n \log^8 n}}$. 		Let $C, C^*$ be two cycles of lengths $b$ and $a$, respectively, with $b\ge a$ and $b \ge \frac{n}{4\log n}$. 		Denote $V' \coloneqq V(C) \cup V(C^*)$. 		Let $E'$ be a set of available edges. 		And assume that the following hold. 		 			\item $V'$ contains no $\left(V', \frac{1}{8} \right)$-heavy vertices. 			\item For any two subsets $U_1, U_2 \subset V'$ of sizes $|U_1|, |U_2|\geq  \frac{\log n}{100\sqrt{q}}$ we have $\left|E'(U_1, U_2) \right| \ge \frac{1}{2}|U_1||U_2|$. 		 		Then with probability $1 - o\left(\frac{1}{np\log n} \right)$, Procedure~\ref{procedure:2cycles} does not output FAILURE when applied to $C,C^*$ with $v_1, H, E', q$.",2502.01631
lemma,"Let $n$ be an integer and let $\frac{\log^{15}n}{n} \le p \le \varepsilon$ and $q = \sqrt{\frac{p}{n \log^8 n}}$ be probability parameters. 		Let $F = (C_0, \ldots, C_N)$ be a $1$-factor on a vertex set $V$ of size $n$ and such that $C_0$ is of maximum length, and assume that $1\le N \le 4\log n$. 		Let $E'$ be a subset of available edges. 		For each $i \in [N]$ write $V_i \coloneqq \bigcup_{j=0}^i V(C_j)$, 		and assume that the following hold. 		 			\item $V_i$ contains no $\left(V_i, \tfrac{1}{8} \right)$-heavy vertices. 			\item For any two subsets $U_1, U_2 \subset V$ of sizes $|U_1|, |U_2| = \Omega\left(\frac{\log n}{\sqrt{q}} \right)$ we have $\left|E'(U_1, U_2) \right| \ge \frac{1}{2}|U_1||U_2|$. 		 		Then with probability $1 - o\left(\frac{1}{np} \right)$, Procedure~\ref{procedure:factor} does not output FAILURE when applied to $F$ with $\bar{v}, E', q$.",2502.01631
lemma,Let $f(n)$ be a function satisfying $f(n) = \omega\left((np)^{1/3} \log n \right)$. 		Then with high probability we have $\Des_{\mathcal F}(v) \le f(n)$ for all $v \in V$.,2502.01631
lemma,"For every $w \in [n]$ we have 		 		\mathbb E \left[\left(\sum_{i \in [\delta]} \frac{1}{c_{w,i}} \right)^3 \right] = O\left(p \log^3 n \right).",2502.01631
lemma,"Let $D'$ be the digraph obtained at the end of Phase 1, let $E'$ be the set of available edges in it and let $\mathcal F = \left\{F_1, \ldots, F_{\delta} \right\}$ be the family of $1$-factors. 		Then using the notation above, with high probability Procedure~\ref{procedure:final} does not output FAILURE when applied to $\mathcal F$ with $\left(\bar{v}_1, \ldots, \bar{v}_{\delta} \right), E', q$.",2502.01631
lemma,With high probability for all $e \in E'$ we have $X_e = o(\log^2 n)$.,2502.01631
lemma,"Let $2\leq k\leq 3$ and $1\leq a_1\leq \ldots a_k \leq n/6$. Then for every $v \in [n]$ and collection of $k$ matchings $M_{i_1},\ldots, M_{i_k}$ we have that      \PP\left(\bigcap_{j=1}^k (c_{v,i_{j}}=a_j)\right)=O(n^{-k}).",2502.01631
theorem,"%Let be given $\lambda>0$ and $y\in H_1$. Then $J_{\lambda C^T\mathcal{M}C}y=y-\lambda C^T u$, where $u$ is the fixed point of the  operator $\mathcal{N}(u):=\mathcal{M}_\mu (Cy+(\mu I-\lambda CC^T)u)$, i.e.,  %\beq %u=\mathcal{M}_\mu (Cy+(\mu I-\lambda CC^T)u) %\eeq %for any $\mu>0$ and $\mathcal{M}_\mu$ denotes the Yosida approximation of $\mathcal{M}$ (of index $\mu$). In addition, if $\frac{\lambda}{\mu}\le 2/\Vert C\Vert^2$ then $\Vert I-\frac{\lambda}{\mu} CC^T \Vert \le 1$ and thus $\mathcal{N}$ is nonexpansive. %",2502.01664
theorem,"Let $\lambda > 0$ and $y \in H_1$ be given. Then, the operator $J_{\lambda C^T \mathcal{M} C} y$ can be expressed as $y - \lambda C^T v$, where $v$ is the fixed point of the operator $\mathcal{N}:H_2\to H_2$ defined by $$v\mapsto\mathcal{N}(v) := \mathcal{M}_{\frac{1}{\mu}} \Big(Cy + (\frac{1}{\mu} I - \lambda CC^T)v\Big),$$ % that is, % %u = \mathcal{M}_\mu (Cy + (\mu I - \lambda CC^T)u), % for any $\mu > 0$ and $\mathcal{M}_{\frac{1}{\mu}}$ denotes the Yosida approximation of $\mathcal{M}$ with index $\frac{1}{\mu}$.\\  Furthermore, if ${\lambda}{\mu} \leq \frac{2}{\|C\|^2}$, then $\left\|I - {\lambda}{\mu} CC^T\right\| \leq 1$, thereby ensuring that $\mathcal{N}$ is {nonexpansive}.",2502.01664
theorem,"%Let be given $\lambda>0$ and $y\in H_1$.  Choose $\mu$ such that $\frac{\lambda}{\mu}\in (0,2/\Vert C\Vert^2)$ and the sequence $(\alpha_k)\subset (0,1)$ satisfying $\sum_{k=1}^\infty \alpha_k(1-\alpha_k)=\infty$. We construct the sequence $(u_k)$ as follows %$$ %\bold{Algorithm \;1:} \;\;\;\;\; u_0\in H, \;\;u_{k+1}=(1-\alpha_k)u_k+\alpha_k\mathcal{N}(u_k),\;\;\; k=0, 1,2\ldots. %$$ %Then ($u_k$) converges weakly to a fixed point $u$ of $\mathcal{N}$ and  $J_{\lambda C^T\mathcal{M}C}y=y-\lambda C^T u$.\\ % In addition, if $\inf \alpha_k >0$ then the sequence $(x_k)$ defined by $x_k:=y-\lambda C^T u_k$ converges strongly to  $J_{\lambda C^T\mathcal{M}C}y$. %",2502.01664
theorem,"Let $\lambda > 0$ and $y \in H_1$ be given. Choose $\mu>0$ such that ${\lambda}{\mu} \in (0, 2/\|C\|^2)$, and let $(\alpha_k) \subset (0,1)$ satisfy $\sum_{k=1}^\infty \alpha_k (1 - \alpha_k) = \infty$. We construct the sequence $(v_k)$ as follows:  \textbf{Algorithm 1:} \quad v_0 \in H, \quad v_{k+1} = (1 - \alpha_k)v_k + \alpha_k \mathcal{N}(v_k), \quad k = 0, 1, 2, \ldots.  Then, the sequence $(v_k)$ converges weakly to a fixed point $v$ of $\mathcal{N}$, and $J_{\lambda C^T \mathcal{M} C} y = y - \lambda C^T v$.\\ Furthermore, if $\inf \alpha_k > 0$, then the sequence $(x_k)$ defined by $x_k := y - \lambda C^T v_k$ converges strongly to $J_{\lambda C^T \mathcal{M} C} y$.",2502.01664
theorem,"If  $\Vert I-{\lambda}{\mu} CC^T \Vert < 1$, then Algorithm 1  in Theorem \ref{algokm} converges with linear rate. Particularly, if  {$E:=CC^T\succ 0$}, we can choose $\lambda>0, \mu >0$ such that the convergence rate of Algorithm 1   is linear.",2502.01664
theorem,"%Let be given $\lambda>0$ and $y\in H_1$. Then $J_{\lambda (\mathcal{M}_1+ C^T\mathcal{M}_2C)}y=J_{\lambda\mathcal{M}_1}(y-\lambda C^T u)$, where $u$ is the fixed point of the  operator $\mathcal{P}(u):=(\mathcal{M}_2)_\mu (CJ_{\lambda\mathcal{M}_1}(y-\lambda C^Tu)+ \mu u))$, i.e.,  %\beq % u=(\mathcal{M}_2)_\mu (CJ_{\lambda\mathcal{M}_1}(y-\lambda C^Tu)+ \mu u)). %\eeq %for any $\mu>0$. In addition, if $\frac{\lambda}{\mu}\le 2/\Vert C\Vert^2$ then $\Vert I-\frac{\lambda}{\mu} CC^T \Vert \le 1$ and thus $\mathcal{P}$ is nonexpansive. %",2502.01664
theorem,"Let $\lambda > 0$ and $y \in H_1$ be given. Then we have $$J_{\lambda (\mathcal{M}_1 + C^T \mathcal{M}_2 C)} y=J_{\lambda \mathcal{M}_1}(y - \lambda C^T u),$$ where $u$ is the fixed point of the operator $\mathcal{P}: H_2 \to H_2$ defined by $$u\mapsto \mathcal{P}(u) := (\mathcal{M}_2)_\kappa \Big(C J_{\lambda \mathcal{M}_1}(y - \lambda C^T u) + \kappa u\Big),$$  that is for any $\kappa > 0$,  u = (\mathcal{M}_2)_\kappa \Big(C J_{\lambda \mathcal{M}_1}(y - \lambda C^T u) + \kappa u\Big).  Furthermore, if $\frac{\lambda}{\kappa} \leq \frac{2}{\|C\|^2}$, then $\|I - \frac{\lambda}{\kappa} CC^T \| \leq 1$, and thus $\mathcal{P}$ is {nonexpansive}.",2502.01664
theorem,"%Let be given $\lambda>0$ and $y\in H_1$.  Choose $\mu>0$ such that $\frac{\lambda}{\mu}\in (0,2/\Vert C\Vert^2)$ and the sequence $(\alpha_k)\subset (0,1)$ satisfying $\sum_{k=1}^\infty \alpha_k(1-\alpha_k)=\infty$. We construct the sequence $(u_k)$ as follows %$$ %\bold{Algorithm \;2:} \;\;\;\;\; u_0\in H, \;\;u_{k+1}=(1-\alpha_k)u_k+\alpha_k\mathcal{P}(u_k),\;\;\; k=0, 1,2\ldots %$$ %where $\mathcal{P}(u):=(\mathcal{M}_2)_\mu (CJ_{\lambda\mathcal{M}_1}(y-\lambda C^Tu)+ \mu u))$. %Then ($u_k$) converges weakly to a fixed point $u$ of $\mathcal{P}$ and  $J_{\lambda (\mathcal{M}_1+ C^T\mathcal{M}_2C)}(y)=J_{\lambda\mathcal{M}_1}(y-\lambda C^T u)$. %",2502.01664
theorem,"Let $\lambda > 0$ and $y \in H_1$ be given. Choose $\kappa > 0$ such that $\frac{\lambda}{\kappa} \in (0, 2/\|C\|^2)$, and let the sequence $(\alpha_k) \subset (0,1)$ such that $\sum_{k=1}^\infty \alpha_k(1 - \alpha_k) = \infty$. We construct the sequence $(u_k)$ as follows:  \textbf{Algorithm 3:} \quad u_0 \in H, \quad u_{k+1} = (1 - \alpha_k)u_k + \alpha_k\mathcal{P}(u_k), \quad k = 0, 1, 2, \ldots  where $\mathcal{P}(u) := (\mathcal{M}_2)_\kappa \Big(C J_{\lambda \mathcal{M}_1}(y - \lambda C^T u) + \kappa u\Big)$. Then, the sequence $(u_k)$ converges weakly to a fixed point $u$ of $\mathcal{P}$. In addition, if  $\inf \alpha_k > 0$, then $J_{\lambda \mathcal{M}_1}(y - \lambda C^T u_k)\to J_{\lambda (\mathcal{M}_1 + C^T \mathcal{M}_2 C)} (y)$ strongly.",2502.01664
definition,The resolvent  of $\mathcal{M}$ (of index $\lambda$) with respect to $E$ is defined by  %$$ %J^E_{\lambda\mathcal{M}}:=(I+\lambda E\mathcal{M})^{-1}. %$$ %,2502.01664
proof,"Let $y_i\in J_{\lambda E\mathcal{M}}x_i, i=1, 2.$ Then we have  $$ x_i\in y_i+\lambda E\mathcal{M} (y_i) \Leftrightarrow \frac{1}{\lambda}E^{-1}(x_i-y_i)\in \mathcal{M}(y_i). $$ The {operator} $E^{-1}$ is positive definite since $E$ is positive definite.  Using the monotonicity of $\mathcal{M}$, we have  $$ \langle E^{-1}(x_1-x_2-y_1+y_2), y_1-y_2 \rangle \ge 0. $$ Thus  $$ c\Vert y_1-y_2\Vert^2\le \langle E^{-1}(y_1-y_2), y_1-y_2\rangle\le \langle E^{-1}(x_1-x_2), y_1-y_2 \rangle \le \Vert  E^{-1}\Vert \Vert x_1-x_2\Vert \Vert y_1-y_2\Vert, $$ for some $c>0$ and the conclusion follows.",2502.01664
proof,"{It is easy to see that both operators in the last equality are single-valued}. Let $x\in H$ and $y:=\frac{1}{\lambda}E^{-1}(I-J_{\lambda E\mathcal{M}})(x)$.  {We have, %Indeed  \baqn (\mathcal{M}^{-1}+\lambda E)^{-1}(x)=y &\Leftrightarrow& x\in (\mathcal{M}^{-1}+\lambda E)(y).\\ &\Leftrightarrow&x\in (\mathcal{M}^{-1}+\lambda E)(\frac{1}{\lambda}E^{-1}-\frac{1}{\lambda}E^{-1}J_{\lambda E\mathcal{M}})(x)\\ &\Leftrightarrow& x\in x-J_{\lambda E\mathcal{M}}x+\mathcal{M}^{-1}(\frac{1}{\lambda}E^{-1}-\frac{1}{\lambda}E^{-1}J_{\lambda E\mathcal{M}})(x) \\ &\Leftrightarrow& E^{-1}x \in E^{-1}J_{\lambda E\mathcal{M}}x+ \lambda \mathcal{M} (J_{\lambda E\mathcal{M}}x) \\ &\Leftrightarrow& x\in J_{\lambda E\mathcal{M}}x+\lambda E\mathcal{M} (J_{\lambda E\mathcal{M}}x). \eaqn The last inclusion is valid as it directly follows from the definition of $J_{\lambda E\mathcal{M}}$. }",2502.01664
proof,"%Suppose that $\alpha \in [0,2/\Vert C \Vert^2]$. For all $x\in H_1$, we have  %\baqn %\Vert x-\alpha CC^T x\Vert^2&=&\Vert x\Vert^2-2\alpha \langle x, CC^T x \rangle+\alpha^2 \Vert CC^T x\Vert^2\\ %&\le&\Vert x\Vert^2-2\alpha \Vert C^T x\Vert^2+\alpha^2 \Vert C\Vert^2\Vert C^T x\Vert^2\\ %&\le&\Vert x\Vert^2 %\eaqn %and thus $\|I - \alpha CC^T\| \leq 1$.   % %\tcb{Next  suppose that if $H_1$ and $H_2$ are finite-dimensional Hilbert spaces (in which case C can be represented as a matrix) and $\|I - \alpha CC^T\|  \leq 1$, we will prove that $\alpha \in [0,2/\Vert C \Vert^2]$. Assume that $\alpha>2/\Vert C \Vert^2$. Let $B=CC^T$ then $B$ is a symmetric, positive semi-definite matrix and  $\Vert B \Vert=\Vert C \Vert^2$. There exists $x^*\in H_1$ such that $Bx^*=\Vert B \Vert x^*$. Then  %$$ %x^*-\alpha Bx^*=(1-\alpha \Vert B \Vert)x^* %$$ %where $1-\alpha \Vert B \Vert<1-\frac{2}{ \Vert B \Vert}{ \Vert B \Vert}=-1.$ Consequently $\|I - \alpha CC^T\|  > 1$, a contradiction and the conclusion follows. } %",2502.01664
proof,"First, suppose that $\alpha \in [0,2/\|C\|^2]$. For all $x\in H_1$, we have   \|x-\alpha CC^T x\|^2 &= \|x\|^2 - 2\alpha \langle x, CC^T x \rangle + \alpha^2 \|CC^T x\|^2 \\ &\leq \|x\|^2 - 2\alpha \|C^T x\|^2 + \alpha^2 \|C\|^2\|C^T x\|^2 \\ &= \|x\|^2 - \alpha \|C^T x\|^2 (2 - \alpha \|C\|^2) \\ &\leq \|x\|^2  where the last inequality follows from $\alpha \leq 2/\|C\|^2$. Thus, $\|I - \alpha CC^T\| \leq 1$.\\ Next, suppose that $H_1=\R^n$ and $H_2=\R^m$ and $\|I - \alpha CC^T\| \leq 1$. We will prove that $\alpha \in [0,2/\|C\|^2]$ by contradiction. Assume that $\alpha > 2/\|C\|^2$. Let $B = CC^T$; then $B$ is a symmetric, positive semi-definite matrix and $\|B\| = \|C\|^2$. By the spectral theorem, there exists a unit vector $x^* \in H_1$ such that $Bx^* = \|B\| x^*$. Then  \[ (I - \alpha B)x^* = (1 - \alpha \|B\|)x^* \] where $1 - \alpha \|B\| < 1 - \frac{2}{\|B\|}\|B\| = -1$. Consequently, \[ \|I - \alpha CC^T\| = \|I - \alpha B\| \geq \|(I - \alpha B)x^*\| = |1 - \alpha \|B\|| > 1. \] This contradicts our assumption that $\|I - \alpha CC^T\| \leq 1$. Therefore, we must have $\alpha \in [0,2/\|C\|^2]$.",2502.01664
proof,"%From (\ref{lmiso}), we deduce  that $u \in \mathcal{M}(Cy-\lambda CC^Tu)$.  %One has  %\baqn %&&u \in \mathcal{M}(Cy-\lambda CC^Tu) \Leftrightarrow Cy-\lambda CC^Tu \in \mathcal{M}^{-1}(u)\\ %&&\Leftrightarrow Cy+(\mu I-\lambda CC^T)u\in (\mathcal{M}^{-1}+\mu I)u  \Leftrightarrow u = (\mathcal{M}^{-1}+\mu I)^{-1}(Cy+(\mu I-\lambda CC^T)u)\\ %&& \Leftrightarrow u=\mathcal{M}_\mu (Cy+(\mu I-\lambda CC^T)u), %\eaqn {From (\ref{lmiso}), we deduce that $v \in \mathcal{M}(Cy - \lambda CC^T v)$. We have  v \in \mathcal{M}(Cy - \lambda CC^T v)  &\Leftrightarrow Cy - \lambda CC^T v \in \mathcal{M}^{-1}(v) \\ &\Leftrightarrow Cy + (\frac{1}{\mu} I - \lambda CC^T)v \in (\mathcal{M}^{-1} + \frac{1}{\mu} I)v \\ &\Leftrightarrow v = (\mathcal{M}^{-1} + \frac{1}{\mu} I)^{-1}(Cy + (\frac{1}{\mu} I - \lambda CC^T)v) \\ &\Leftrightarrow v = \mathcal{M}_{\frac{1}{\mu}} (Cy + (\frac{1}{\mu} I - \lambda CC^T)v),  where  $\mathcal{M}_{\frac{1}{\mu}}=(\mathcal{M}^{-1}+\frac{1}{\mu} I)^{-1}$ (see Proposition \ref{Yosida}).} \\ If ${\lambda}{\mu}\le 2/\Vert C\Vert^2$, then  $\Vert I-{\lambda}{\mu} CC^T \Vert \le 1$ (Lemma \ref{lem1}) and the mapping $L(u):=Cy+(\frac{1}{\mu} I-\lambda CC^T)u$ is $\frac{1}{\mu}$-Lipschitz continuous. Since $\mathcal{M}_{\frac{1}{\mu}}$ is ${\mu}$-Lipschitz continuous, $\mathcal{N}$ is {nonexpansive}.",2502.01664
proof,"Using Theorem  \ref{tmf} and Krasnoselskii-Mann algorithm (see, e.g., \cite{Bauschke}), the weak convergence of ($u_k$) to some  fixed point $u$ of $\mathcal{N}$ follows. It remains to prove the strong convergence of $(v_k)$. We have  \beq \Vert v_{k+1}-v\Vert\le(1-\alpha_k) \Vert v_{k}-v\Vert+\alpha_k\Vert \mathcal{N}(v_k)-\mathcal{N}(v)\Vert\le \Vert v_{k}-v\Vert, \eeq  where we use the fact that  $v=\mathcal{N}(v)$. Thus the sequence $( \Vert v_{k}-v\Vert)$ is decreasing and converges. On the other hand,  (\ref{udecre}) can be rewritten as follows  \baqn  \Vert v_{k+1}-v\Vert   & \le&  \Vert v_{k}-v\Vert+\alpha_k(\Vert \mathcal{N}(v_k)-\mathcal{N}(v)\Vert- \Vert v_{k}-v\Vert)\\  &\le&  \Vert v_{k}-v\Vert.  \eaqn {Let $k\to \infty$, we obtain  \baq \alpha_k(\Vert \mathcal{N}(v_k)-\mathcal{N}(v)\Vert- \Vert v_{k}-v\Vert)\to 0. \eaq Since $\inf \alpha_k =\alpha> 0$ and $\Vert \mathcal{N}(v_k)-\mathcal{N}(v)\Vert\le \Vert v_{k}-v\Vert$, we imply that \baq 0=\lim_{k\to \infty}\alpha_k( \Vert v_{k}-v\Vert-\Vert \mathcal{N}(v_k)-\mathcal{N}(v)\Vert)\ge \lim_{k\to \infty}\alpha( \Vert v_{k}-v\Vert-\Vert \mathcal{N}(v_k)-\mathcal{N}(v)\Vert)\ge 0, \eaq which deduces that $ \lim_{k\to \infty}\Vert \mathcal{N}(v_k)-\mathcal{N}(v)\Vert= \lim_{k\to \infty} \Vert v_{k}-v\Vert.$ Note that $$ \Vert CC^T(v_k-v)\Vert \le \Vert C \Vert \Vert C^T(v_k-v)\Vert.  $$ Thus  \baqn  \Vert \mathcal{N}(v_k)-\mathcal{N}(v)\Vert^2&\le& {\mu^2}\Vert (\frac{1}{\mu} I-\lambda CC^T)(v_k-v)\Vert^2\\   &\le& \Vert v_{k}-v\Vert^2- 2 {\lambda}{\mu} \Vert C^T(v_k-v)\Vert^2 + {\lambda^2}{\mu^2}\Vert CC^T(v_k-v)\Vert^2\\    &\le& \Vert v_{k}-v\Vert^2-  2 \frac{\lambda\mu}{ \Vert C \Vert^2}\Vert CC^T(v_k-v)\Vert^2+ {\lambda^2}{\mu^2}\Vert CC^T(v_k-v)\Vert^2\\  &\le& \Vert v_{k}-v\Vert^2-{\lambda^2}{\mu^2}(\frac{2}{\lambda\mu\Vert C\Vert^2}-1)\Vert CC^T(v_k-v)\Vert^2. \eaqn Let $k\to \infty$, since ${\lambda}{\mu} \in (0, 2/\|C\|^2)$ we obtain that $\Vert CC^T(v_k-v)\Vert\to 0$. \\ Note that $(v_k)$ is bounded, we infer that $\Vert C^T(v_k-v)\Vert^2=\langle CC^T(v_k-v), v_k-v \rangle\le   \Vert CC^T(v_k-v)\Vert \Vert  v_k-v \Vert \to 0$, {which means that $C^Tv_k\to C^Tv$ strongly}. Therefore $x_k= y - \lambda C^T v_k$ converges strongly to $J_{\lambda C^T\mathcal{M}C}y=y-\lambda C^T v$.}",2502.01664
proof,"If $\Vert I-{\lambda}{\mu} CC^T \Vert < 1$, then $\mathcal{N}$ is a contraction and thus Algorithm 1  in Theorem \ref{algokm} converges with linear rate.   If $CC^T$ is positive definite there exists $c>0$ such that  $$ \langle Ex,x \rangle \ge c \Vert x \Vert^2, \;\;\forall\;\;x\in H_1. $$ {Let  $\gamma:={\lambda}{\mu}$.  We choose $\mu>0$ such that  $\gamma=\frac{c}{\Vert E\Vert^2} \Leftrightarrow \mu=\frac{c}{\lambda \Vert E\Vert^2}$}. Then \baqn \Vert (I-\gamma E)x\Vert^2&=&x^2-2\gamma\langle Ex, x \rangle+\gamma^2\Vert Ex\Vert^2.\\ &\le & (1-2\gamma c+\gamma^2\Vert E\Vert^2)\Vert x\Vert^2\\ &\le & (1-\frac{c^2}{ \Vert E\Vert ^2})\Vert x \Vert^2, \eaqn where $\Vert E\Vert$ denotes the induced norm of the linear bounded operator $E$. It means that  $\Vert I-{\lambda}{\mu} CC^T \Vert < 1$, and the conclusion follows.",2502.01664
proof,"Note that (\ref{sum}) can be rewritten as follows    \left\{ {l} y\in  x+\lambda\mathcal{M}_1x+\lambda C^Tu\\ \\ u\in \mathcal{M}_2Cx, \right.  which is equivalent to  \left\{ {l}  x=J_{\lambda\mathcal{M}_1}(y-\lambda C^Tu)\\ \\ u\in \mathcal{M}_2(CJ_{\lambda\mathcal{M}_1}(y-\lambda C^Tu)).  \right.  Similarly as in the proof of Theorem \ref{tmf}, we have  \baqn u \in \mathcal{M}_2(CJ_{\lambda\mathcal{M}_1}(y-\lambda C^Tu)) &\Leftrightarrow& CJ_{\lambda\mathcal{M}_1}(y-\lambda C^Tu) \in   \mathcal{M}_2^{-1}(u)\\ &\Leftrightarrow& CJ_{\lambda\mathcal{M}_1}(y-\lambda C^Tu)+ \kappa u\in (\mathcal{M}_2^{-1}+\kappa I)u \\ & \Leftrightarrow& u=(\mathcal{M}_2)_\kappa \Big(CJ_{\lambda\mathcal{M}_1}(y-\lambda C^Tu)+ \kappa u\Big). \eaqn Let $P_1(u):=CJ_{\lambda\mathcal{M}_1}(y-\lambda C^Tu)$.  We prove that   $P_2(u):=P_1(u)+\kappa u$ is $\kappa$-Lipschitz continuous if $\frac{\lambda}{\kappa}\le 2/\Vert C\Vert^2$  . Indeed, since $J_{\lambda\mathcal{M}_1}$ is firmly-nonexpansive  we have  {  \baqn  \langle P_1(u_1)-P_1(u_2), u_1-u_2 \rangle  &=& \langle CJ_{\lambda\mathcal{M}_1}(y-\lambda C^Tu_1)-CJ_{\lambda\mathcal{M}_1}(y-\lambda C^Tu_2), u_1-u_2\rangle\\ &=&-\frac{1}{\lambda} \langle J_{\lambda\mathcal{M}_1}(y-\lambda C^Tu_1)-J_{\lambda\mathcal{M}_1}(y-\lambda C^Tu_2), (y-\lambda C^Tu_1)-(y-\lambda C^Tu_2)\rangle\\ &\le& -\frac{1}{\lambda} \Vert J_{\lambda\mathcal{M}_1}(y-\lambda C^Tu_1)-J_{\lambda\mathcal{M}_1}(y-\lambda C^Tu_2)\Vert^2. \eaqn  } Thus if $\frac{\lambda}{\kappa}\le 2/\Vert C\Vert^2$, one has  { \baq\nonumber \Vert P_2(u_1)-P_2(u_2)\Vert^2&=&\kappa^2\Vert u_1-u_2 \Vert^2+2\kappa \langle P_1(u_1)-P_1(u_2), u_1-u_2 \rangle+\Vert P_1(u_1)-P_1(u_2)\Vert^2\\\nonumber &\le&\kappa^2\Vert u_1-u_2 \Vert^2-(\frac{2\kappa}{\lambda}-\Vert C\Vert^2) \Vert J_{\lambda\mathcal{M}_1}(y-\lambda C^Tu_1)-J_{\lambda\mathcal{M}_1}(y-\lambda C^Tu_2)\Vert^2\\ &\le&\kappa^2\Vert u_1-u_2 \Vert^2.  \eaq } Consequently, $P_2$ is $\kappa$-Lipschitz continuous and hence $\mathcal{P}$ is {nonexpansive}.",2502.01664
proof,"{The weak convergence of $(u_k)$ is easily obtained. For the remain, we do similarly as in the proof of Theorem \ref{algokm}. The sequence $( \Vert u_{k}-u\Vert)$ is decreasing, converges and  $$ \lim_{k\to \infty}\Vert \mathcal{P}(u_k)-\mathcal{P}(u)\Vert= \lim_{k\to \infty} \Vert u_{k}-u\Vert.$$ Similarly as in (\ref{estsum}), we have  \baq\nonumber \Vert \mathcal{P}(u_k)-\mathcal{P}(u)\Vert^2&=&\Vert u_k-u \Vert^2+\frac{2}{\kappa} \langle P_1(u_k)-P_1(u), u_k-u \rangle+\frac{1}{\kappa^2}\Vert P_1(u_k)-P_1(u)\Vert^2\\\nonumber &\le&\Vert u_k-u \Vert^2-\frac{1}{\kappa^2}(\frac{2\kappa}{\lambda}-\Vert C\Vert^2) \Vert J_{\lambda\mathcal{M}_1}(y-\lambda C^Tu_k)-J_{\lambda\mathcal{M}_1}(y-\lambda C^Tu)\Vert^2\\ &\le&\Vert u_k-u \Vert^2.  \eaq Let $k\to\infty$, we must have $ \Vert J_{\lambda\mathcal{M}_1}(y-\lambda C^Tu_k)-J_{\lambda\mathcal{M}_1}(y-\lambda C^Tu)\Vert\to 0$ and the conclusion follows. }",2502.01664
proposition,"{\rm (\cite{AC})} Let $\mathcal{M}:  {H} \rightrightarrows  {H}$ be a maximal monotone operator and let $\lambda>0$. Then    \item[{\rm (i)}]  The {resolvent} $J_{\lambda \mathcal{M}}:=(I+\lambda \mathcal{M})^{-1} $ is a {nonexpansive}  and single-valued map from $ {H}$ to $ {H}$. \item[{\rm (i)}]  The {Yosida approximation} of $\mathcal{M}$  (of index $\lambda$) defined by $$\mathcal{M}_\lambda:=\frac{1}{\lambda}(I-J_{\lambda \mathcal{M}})=(\lambda I+\mathcal{M}^{-1})^{-1}$$ satisfies\\    \item[{\rm (a)}]  for all $x\in \mathcal{H}$, $\mathcal{M}_\lambda(x)\in \mathcal{M}(J_{\lambda \mathcal{M}} (x))$; \item[{\rm (b)}]  $\mathcal{M}_\lambda$ is $\frac{1}{\lambda}$-Lipschitz continuous   and also maximal monotone.",2502.01664
proposition,"Let {$E\succ 0$}, $\lambda >0$ and $\mathcal{M}:  {H} \rightrightarrows  {H}$ be a maximal monotone operator. Then  $J_{\lambda E\mathcal{M}}:=(I+\lambda E\mathcal{M})^{-1}$ is single-valued and Lipschitz continuous.",2502.01664
proposition,"If {$E\succ0, \lambda>0$} and $\mathcal{M}:  {H} \rightrightarrows  {H}$ is a maximal monotone operator,  then  $$ (\mathcal{M}^{-1}+\lambda E)^{-1}=\frac{1}{\lambda}E^{-1}(I-J_{\lambda E\mathcal{M}}). $$",2502.01664
proposition,"Let $C: H_1 \to H_2$ be a linear bounded mapping between Hilbert spaces. If $\alpha \in \left[0, \frac{2}{\|C\|^2}\right]$, then $\|I - \alpha CC^T\| \leq 1$. In addition, if $H_1=\R^n$ and $H_2=\R^m$ (i.e., $C$ can be represented as a matrix), then the two conditions are equivalent.",2502.01664
lemma,"%If $\alpha \in [0,2/\Vert C \Vert^2]$, then  $\Vert I-\alpha CC^T \Vert \le 1$. In addition, if $C$ is a matrix then two condition are equivalent.  %",2502.01664
lemma,"%If $\alpha \in \left[0, \frac{2}{\|C\|^2}\right]$, then $\|I - \alpha CC^T\| \leq 1$. \tcb{In addition, if $C$ is a linear operator on finite-dimensional Hilbert spaces (i.e., $C$ can be represented as a matrix)}, then the two conditions are equivalent. %",2502.01664
example,"Let us provide a simple example to show the advantage of our extension over the  Micchelli-Chen-Xu's approach. Let $\mathcal{M}=\partial \Vert \cdot \Vert_1$ and $$ C= 1\;\;\; 3\;\;\; 7\;\; \;0\;\; \;8 \\ 2 \;\;\;4 \;\;\;5 \;\;\;8\; \;\;7 \\ 7\;\;\; 9\; \;\;6\; \;\;0 \;\;\;1 \\ 2\;\;\; 0\;\; \;1\;\; \;4 \;\;\;7 \\ 2 \;\;\;5\; \;\;8\; \;\;3\; \;\;8 \\ . $$ Then  $$ CC^T= 123& 105 &84&65&137 \\ 105  &158 &87  & 90 & 144 \\  84  & 87 & 167  &27  & 115 \\  65&  90  & 27&  70&   80 \\ 137&144& 115&   80 & 166 . $$ and $\Vert CC^T\Vert=532.64.$ It is known that (see, e.g., \cite{Micchelli}) $$ J_{{\frac{1}{\mu}} \mathcal{M}}(x)=\Big(\max\big(\vert x_1 \vert-\frac{1}{\mu}, 0\big){ \rm sign}(x_1), \ldots, \max\big(\vert x_5 \vert-\frac{1}{\mu}, 0\big){ \rm sign}(x_5)\Big), $$ where $x=(x_1,\ldots,x_5).$ We want to calculate $J_{\lambda C^T \mathcal{M} C} y$ where $y=[2; 4; -5; 3; 9]$. First we consider   $\lambda=1$, our Algorithm 2 becomes Micchelli-Chen-Xu's algorithm. To find the fixed point $u$ of $\mathcal{Q}$, we use $\alpha_k=0.3$ in  Algorithm 2 and stop after $500$ iterations or $\Vert u_{k+1}-u_k\Vert \le 10^{-3}$. Although Micchelli-Chen-Xu's algorithm converges, its output are different with different $\mu$ while they must have the same value if the convergence condition   $ \left\|I - {}{\mu} CC^T\right\| \le 1$ is satisfied.        { | c | c | c | c |  c | }     \hline      $\mu$ & $10^{-2}$ &$10^{-3}$ \\     \hline   $ \left\|I - {}{\mu} CC^T\right\| $ & $4.33$ &$1$\\   \hline    % \multirow {3} {4em}      $J_{ C^T \mathcal{M} C} y$ & $( 8.73, 15.31, 9.13, 9.45, 22.85)$&$(-0.85, 3.66, -5.01, -1.26, 3.23)$ \\     \hline                      { | c | c | c | c |  c | }     \hline      $\mu$ & $10^{-4}$ &$10^{-5}$ \\     \hline   $ \left\|I - {}{\mu} CC^T\right\| $ & $1$ &$1$\\   \hline    % \multirow {3} {4em}      $J_{ C^T \mathcal{M} C} y$ & $( 0.25, 3.69, -5.76, -1.53, 3.34)$&$(0.99, 2.61, -7.20, 0.82, 5.45)$ \\     \hline               Next we use our Algorithm 2 with $\lambda=0.01$. Our algorithm converges and the outputs are the same with different values of $\mu$, even the convergence condition   $ \left\|I - {\lambda}{\mu} CC^T\right\| \le 1$ is not satisfied.            { | c | c | c | c |  c | }     \hline      $\mu$ & $1$ &$10^{-1}$ \\     \hline   $ \left\|I - {}{\lambda\mu} CC^T\right\| $ & $4.33$ &$1$\\   \hline    % \multirow {3} {4em}      $J_{ \lambda C^T \mathcal{M} C} y$ & $( 1.86, 3.79, -5.27, 2.85, 8.69)$&$( 1.86, 3.79, -5.27, 2.85, 8.69)$ \\     \hline                      { | c | c | c | c |  c | }     \hline      $\mu$ & $10^{-2}$ &$10^{-3}$ \\     \hline   $ \left\|I - {\lambda}{\mu} CC^T\right\| $ & $1$ &$1$\\   \hline    % \multirow {3} {4em}      $J_{ \lambda C^T \mathcal{M} C} y$ & $( 1.86, 3.79, -5.27, 2.85, 8.69)$&$( 1.86, 3.79, -5.27, 2.85, 8.69)$ \\     \hline               It means that our Algorithm 2 is not only more general but also more stable than Micchelli-Chen-Xu's algorithm. \qed",2502.01664
example,"Let us consider a class of set-valued Lur'e dynamical systems of the  following form     [left={({\mathcal L})}\empheqlbrace]{align}   & \dot{x}(t) = -f(x(t))+B\lambda(t),\; {\rm a.e.} \; t \in [0,+\infty); \\   & y(t)=Cx(t),\\   &  \lambda(t)   \in -\mathcal{M}(y(t)), \;t\ge 0;\\   & x(0) = x_0.   where $x: [0,\infty)\to H_1$ is the state variable and $f: H_1\to H_1$ is Lipschitz continuous. The operators $B:H_2\to H_1, C: H_1\to H_2$ are linear bounded and there exists a positive definite linear bounded operator $P$ such that $PB=C^T$ while the set-valued mapping $\mathcal{M}: H_2 \rightrightarrows H_2$ is maximal monotone. Set-valued Lur'e dynamical systems have been a  fundamental model in control theory, engineering and applied mathematics (see, e.g., \cite{ahl2,br0,BT,L1} and  references therein).    Note that  $({\mathcal L})$ can be rewritten as follows \beq \dot{x} \in -\mathcal{H}(x), \;\;\;x(t_0) = x_0, \eeq where $\mathcal{H}(x)=f(x)+BFCx$. An equilibrium point $x^*$ of $({\mathcal L})$ satisfies  \beq 0 \in f(x^*)+B\mathcal{M}(Cx^*)\Leftrightarrow 0\in Pf(x^*) + C^T\mathcal{M}(Cx^*). \eeq In order to solve (\ref{lure}), it requires to compute the resolvent of the composite operator $C^T\mathcal{M}C$.\qed",2502.01664
theorem,"With all the previous notation, assume that there exists constants $M,L_1,L_2\geq 0$ such that for each $\theta\in\Theta$, $x\in\mathcal X$  and $z\in\mathcal Z$,              \item $|g_\theta(x)|\leq M$, $|h_\theta(z)|\leq M$ .         \item $\|\nabla_\theta g_\theta(x)\|_2\leq L_1$, $\|\nabla_\theta h_\theta(z)\|_2\leq L_2$. \quad {\rm Then}                     \item[(a)]  Under the neighboring relation $\sim_1$ in $\mathcal D = \mathcal X^n$, if we define $\Phi_\theta(\vect X)= \nabla_{\theta} W_2^2(g_\theta\# P_{\vect X}, h_\theta\# P_{\vect Z})$, then $$ \Delta \Phi_\theta   \leq  4M\frac{3L_1+L_2}{n} \ .$$ \item[(b)] Under the neighboring relation $\sim_2$ in $\mathcal D = \mathcal X^n\times \mathcal Z^m$, if we define $\Psi_\theta(\vect X, \vect Z)= \nabla_{\theta} W_2^2(g_\theta\# P_{\vect X}, h_\theta\# P_{\vect Z})$, then $$ \Delta \Psi_\theta   \leq  4M\max\Bigl\{ \frac{3L_1+L_2}{n}  , \frac{L_1+3L_2}{m}  \Bigr\}\ .$$",2502.01701
theorem,"In both cases,  under the assumptions that $g_\theta$ verifies {$\|g_\theta(x)\|_2 \leq M$, $\|\mathcal J_\theta g_\theta(x)\|_2 \leq L$} and $\|\nabla_\theta \ell(g_\theta(x))\|_2 \leq C$, we obtain that      $\bullet$ For SP, under $\sim_2$, the sensitivity of  $\nabla_\theta \mathscr L^{SP}_\alpha(g_\theta)$ {or its MC approximation} is bounded by                (1-\alpha) \frac{2C}{n} + \alpha \frac{16 M L }{\min \{n_0,n_1\}} \ .              $\bullet $ For EO, under the relation $\sim_{2R}$, the sensitivity of $\nabla_\theta \mathscr L^{EO}_\alpha(g_\theta)$  {or its MC approximation} is bounded by                (1-\alpha) \frac{2C}{n} + \frac{\alpha}{R} \frac{16 M L }{\min_{j,k} \{n_{j,k}\}} \ .",2502.01701
theorem,"With all the previous notation, assume that there exists constants $M,L_1,L_2\geq 0$ such that for each $\theta\in\Theta$, $x\in\mathcal X$ and $z\in\mathcal Z$,              \item $\|g_\theta(x)\|\leq M$, $\|h_\theta(z)\|_2\leq M$ .       \item $\| \mathcal J_\theta g_\theta(x)\|_2= \sup_{\|\eta\|_2=1} \| J_\theta g_\theta(x) \eta \|_2  \leq L_1$, $\| \mathcal J_\theta h_\theta(z)\|_2= \sup_{\|\eta\|_2=1} \| J_\theta h_\theta(z) \eta \|_2  \leq L_2$.           Then,    \item[(a)]  Under neighboring relation $\sim_1$ in $\mathcal D = \mathcal X^n$, if we define $\Phi_\theta(\vect X)$ as $\nabla_{\theta} SW_{2}^2(g_\theta\# P_{\vect X}, h_\theta\# P_{\vect Z})$ or its Monte-Carlo approximation $\nabla_{\theta} SW_{2,k}^2(g_\theta\# P_{\vect X}, h_\theta\# P_{\vect Z})$  then $$ \Delta \Phi_\theta   \leq  4M\frac{3L_1+L_2}{n} \ .$$ \item[(b)] Under neighboring relation $\sim_2$ in $\mathcal D = \mathcal X^n\times \mathcal Z^m$, if we define $\Psi_\theta(\vect X, \vect Z)$ as $\nabla_{\theta} SW_{2}^2(g_\theta\# P_{\vect X}, h_\theta\# P_{\vect Z})$ or its Monte-Carlo approximation $\nabla_{\theta} SW_{2,k}^2(g_\theta\# P_{\vect X}, h_\theta\# P_{\vect Z})$, then $$ \Delta \Psi_\theta   \leq  4M\max\Bigl\{ \frac{3L_1+L_2}{n}  , \frac{L_1+3L_2}{m}  \Bigr\}\ .$$",2502.01701
definition,"{(k-end neighboring relation)}  Let $\mathcal D  = \mathcal D_1^{n_1} \times \ldots \times \mathcal D_k^{n_k}$ be the set of partitioned datasets with sizes $n_1,\ldots,n_k \geq 1$. Given two datasets $\vect D = (\vect{D^1},\ldots,\vect{D^k})$, $\vect{\Tilde D} =  (\vect{\Tilde D^1},\ldots,\vect{\Tilde D^k}) \in \mathcal D$, we say that $\vect D \sim_k \vect{\Tilde D}$ if there exist and index $j\in[k]$ such that $\vect{D^i}= (d^i_1,\ldots,d_{n_i}^i)$ and $\vect{\Tilde D^i}= (\Tilde d^i_1,\ldots,\Tilde d_{n_i}^i)$ coincide up to a permutation of the elements if $i\neq j$, and up to a permutation and a replacement of one of the $d_l^i$'s by any element in $\mathcal D_i$ if $i=j$.",2502.01701
definition,"[{$(\epsilon, \delta)$-DP \cite{dwork2006our}}]      A randomized mechanism $\mech{M} : \set{D} \rightarrow \set{O}$ is $(\epsilon, \delta)$-differentially private ($(\epsilon, \delta)$-DP) if $\forall \ \vect{D}\sim \vect{\Tilde D}$, and $\forall$ measurable $S \subset \set{O}$,   \Prob \p{M(\vect{D}) \in S} \leq e^{\epsilon} \Prob \p{M(\vect{\Tilde D}) \in S} + \delta \;,  where the randomness is taken on $M$ only.",2502.01701
proof,"[Proof of Proposition \ref{lemma:expression_W2}]  If we denote by $F$ and $G$ the distribution functions of $P_{\vect U}$ and $P_{\vect V}$, we know that    W_2^2(P_{\vect U},P_{\vect V}) & = \int_0^1 (F^{-1}(t)-G^{-1}(t))^2dt \\ & = \int_0^1 \Bigl(\sum_{i=1}^{n} U_{(i)} I\Bigl(\frac{i-1}{n}<t\leq \frac{i}{n}\Bigr) -\sum_{j=1}^{m} V_{(j)} I\Bigl(\frac{j-1}{m}<t\leq \frac{j}{n}\Bigr) \Bigr)^2dt \\ & = \sum_{i=1}^{n} \sum_{j=1}^{m} (U_{(i)}-V_{(j)} )^2 \int_0^1  I\Bigl(\frac{i-1}{n}<t\leq \frac{i}{n},\frac{j-1}{m}<t\leq \frac{j}{n}\Bigr) dt \\ & = \sum_{i=1}^{n} \sum_{j=1}^{m} (U_{(i)}-V_{(j)} )^2   R_{i,j}  \\ &= \sum_{i=1}^{n} \sum_{j=1}^{m} (U_{(\sigma(i))}-V_{(\sigma(j))} )^2   R_{\sigma(i),\sigma(j)}\\ &= \sum_{i=1}^{n} \sum_{j=1}^{m} (U_{i}-V_{j} )^2   R_{\sigma(i),\sigma(j)} \ ,  where the third equality follows from the fact that exactly one element in each sum is different from 0, and the fifth equality follows from reindexing the sum.",2502.01701
proof,"[Proof of Theorem \ref{theorem:gradient_sensitivity}] First of all, note that (b) follows  immediately from (a) and the definition of the neighboring relation $\sim_2$ in $\mathcal X^n\times \mathcal Z^m$. Consider two neighboring datasets $\vect X\sim \vect{\Tilde X}$ under the substitution  relation. We can assume without loss of generality that the datasets differ on the first observation $\Tilde x_1\neq x_1$. For ease of notation, denote $\vect{\Tilde{X}} = \{ \Tilde x_i\}_{i=1}^n$, even though $\Tilde x_i=x_i$ for $i\neq 1$. Along this proof, we will define $U_i:=g_\theta(x_i)$ and $\Tilde U_i := g_\theta(\Tilde x_i)$ for each  $i\in[n]$, and  $V_j:=h_\theta(z_j)$ for $j\in [m]$. Again, $U_i=\Tilde U_i$ for every $i\neq 1$. Define now the rank permutations $\sigma,\Tilde \sigma$ and $\tau$ such that      U_i &= U_{(\sigma(i))}\ ,  \quad \ &i \in [n] \ ,\\      \Tilde U_i &= \Tilde U_{(\Tilde \sigma(i))}\ ,  \quad \ &i \in [n] \ ,\\       V_j &= V_{(\tau(j))}\ ,  \quad \ &j \in [m]\ .  Denote $\vect U=(U_1,\ldots,U_n)$ and $\vect V=(V_1,\ldots,V_m)$. Corollary \ref{corollary:FormulaGradientsGeneral} ensures if we define  $P_{\vect{U}}= g_\theta \# P_{\vect{X}} =\frac{1}{n}\sum_{i=1}^n\delta_{U_i}$ and $P_{\vect V}= h_\theta \# P_{\vect Z}=\frac{1}{m}\sum_{i=1}^m \delta_{V_j}$ , then      \nabla_{U,V} W_2^2(P_{\vect U}, P_{\vect V}) = \Biggl( \Bigl( 2\sum_{j=1}^m R_{\sigma(i),\tau(j)} (U_i-V_j)\Bigr)_{i\in[n]}, \Bigl( 2\sum_{i=1}^n R_{\sigma(i),\tau(j)} (V_j-U_i)\Bigr)_{j\in[m]}\Biggr) \ \in \mathbb R^{n+m} \ .  Applying the chain rule, we obtain that       \nabla_\theta W_2^2(g_\theta\# P_{\vect{X}}, h_\theta \# P_{\vect{Z}})& = 2\sum_{i=1}^{n} \sum_{j=1}^{m} R_{\sigma(i),\tau(j)} (U_{i}-V_{j} ) \nabla_\theta g_\theta(x_i) + 2\sum_{j=1}^{m}\sum_{i=1}^{n}  R_{\sigma(i),\tau(j)} (V_{j}-U_{i} ) \nabla_\theta h_\theta(z_j)  Similarly, for the dataset $\vect{\Tilde X}$ we get          \nabla_\theta W_2^2(g_\theta\# P_{\vect{\Tilde X}}, h_\theta \# P_{\vect{Z}})& = 2\sum_{i=1}^{n} \sum_{j=1}^{m} R_{\Tilde \sigma(i),\tau(j)} (\Tilde U_i-V_{j} ) \nabla_\theta g_\theta(\Tilde x_i) + 2\sum_{j=1}^{m}\sum_{i=1}^{n}  R_{\Tilde \sigma(i),\tau(j)} (V_{j}-\Tilde U_i ) \nabla_\theta h_\theta(z_j)   Therefore,       \|\nabla_\theta W_2^2&(g_\theta\# P_{\vect{X}}, h_\theta \# P_{\vect{Z}})- \nabla_\theta W_2^2(g_\theta\# P_{\vect{\Tilde X}}, h_\theta \# P_{\vect{Z}}) \|_2 \leq \notag \\     &\leq  2\ \Big\| \sum_{i=1}^{n} \sum_{j=1}^{m} R_{\sigma(i),\tau(j)} (U_{i}-V_{j} ) \nabla_\theta g_\theta(x_i) - \sum_{i=1}^{n} \sum_{j=1}^{m} R_{\Tilde \sigma(i),\tau(j)} (\Tilde U_i-V_{j} ) \nabla_\theta g_\theta(\Tilde x_i) \Big\|_2  \\     & +2\  \Big \| \sum_{j=1}^{m}\sum_{i=1}^{n}  R_{\sigma(i),\tau(j)} (V_{j}-U_{i} ) \nabla_\theta h_\theta(z_j) - \sum_{j=1}^{m}\sum_{i=1}^{n}  R_{\Tilde \sigma(i),\tau(j)} (V_{j}-\Tilde U_i ) \nabla_\theta h_\theta(z_j) \Big\|_2   The term \eqref{eq:term2} is easier to bound, since the values inside $\nabla_\theta h_\theta(\cdot)$ coincide. First, note that       \sum_{j=1}^{m} R_{i,j} = \frac{1}{n} \ ,  \ \forall \ i\in [n] \quad \textnormal{and} \quad       \sum_{i=1}^{n} R_{i,j} = \frac{1}{m} \ ,\ \forall\  j\in [m] \ ,  The triangular inequality, the assumption $\|\nabla_\theta h_\theta(z)\|\leq L_2$ for every $z,\theta$ and the previous property allow us to derive the following inequalities      (\ref{eq:term2})  &=2\  \Big \| \sum_{j=1}^{m}V_{j} \nabla_\theta h_\theta(z_j)\Bigl( \sum_{i=1}^{n}  R_{\sigma(i),\tau(j)} -\sum_{i=1}^{n}  R_{\Tilde \sigma(i),\tau(j)}\Bigr) - \sum_{j=1}^{m} \nabla_\theta h_\theta(z_j)\Bigl( \sum_{i=1}^{n}  U_iR_{\sigma(i),\tau(j)} -\sum_{i=1}^{n}  \Tilde U_i R_{\Tilde \sigma(i),\tau(j)}\Bigr)\Big\|_2 \notag\\    &\leq 2 \sum_{j=1}^{m} \Bigl\|\nabla_\theta h_\theta(z_j)\Bigl( \sum_{i=1}^{n}  U_iR_{\sigma(i),\tau(j)} -\sum_{i=1}^{n}  \Tilde U_i R_{\Tilde \sigma(i),\tau(j)}\Bigr)\Big\|_2 \notag \\    &\leq 2L_2\sum_{j=1}^{m} \Bigl| \sum_{i=1}^{n}  U_iR_{\sigma(i),\tau(j)} -\sum_{i=1}^{n}  \Tilde U_i R_{\Tilde \sigma(i),\tau(j)}\Big|\notag \\    &=  2 L_2\sum_{j=1}^{m} \Bigl| \sum_{i=1}^{n}  U_{(i)}R_{i,\tau(j)} -\sum_{i=1}^{n}  \Tilde U_{(i)} R_{i,\tau(j)}\Big| \notag\\    &= 2L_2 \sum_{j=1}^{m} \Bigl| \sum_{i=1}^{n}  R_{i,\tau(j)}(U_{(i)} - \Tilde U_{(i)})\Big|    where the last lines follows from $U_i=U_{(\sigma(i))}$, $\Tilde U_i=\Tilde U_{(\Tilde \sigma(i))}$ and reindexing the sum. Since $U_i=\Tilde U_i$ for every $i\neq 1$, we know that      \item If $U_1\geq \Tilde U_1$, then $U_{(i)}\geq \Tilde U_{(i)}$ for every $i \in [n]$.     \item If $U_1< \Tilde U_1$, then $U_{(i)}\leq \Tilde U_{(i)}$ for every $i\in[n]$.  This monotonicity property and the fact that $R_{i,j}\geq 0$ for every $i,j$ ensures that      (\ref{eq:last_line_ineq})  &= 2L_2\ \Bigl| \sum_{j=1}^{m}  \sum_{i=1}^{n}  R_{i,\tau(j)}(U_{(i)} - \Tilde U_{(i)})\Big| \\     &= 2L_2\ \Bigl|  \sum_{i=1}^{n} (U_{(i)} - \Tilde U_{(i)}) \sum_{j=1}^{m}   R_{i,\tau(j)}\Big| \\  &=  \frac{2L_2}{n}\ \Bigl|  \sum_{i=1}^{n} (U_{(i)} - \Tilde U_{(i)}) \Big| \\  &  = \frac{2L_2}{n} \Bigl|  \sum_{i=1}^{n} (U_{i} - \Tilde U_i) \Big| \\  &= \frac{2L_2}{n} \bigr|U_{1} - \Tilde U_{1}\big| \\  &\leq \frac{4L_2M}{n}  By the triangular inequality, the term \eqref{eq:term1} can be bounded as follows     (\ref{eq:term1}) &\leq  2\  \Big \| \sum_{i=1}^{n} \nabla_\theta g_\theta(x_i)U_i\sum_{j=1}^{m} R_{\sigma(i),\tau(j)}   - \sum_{i=1}^{n} \nabla_\theta g_\theta(\Tilde x_i)\Tilde U_i\sum_{j=1}^{m} R_{\Tilde \sigma(i),\tau(j)} \Big\|_2 \\    & \quad +2\  \Big \| \nabla_\theta g_\theta(x_1)\sum_{j=1}^{m} R_{\sigma(1),\tau(j)} V_j  -  \nabla_\theta g_\theta(\Tilde x_1)\sum_{j=1}^{m} R_{\Tilde \sigma(1),\tau(j)}V_j \Big\|_2  \\    & \quad +  2\  \Big \| \sum_{i=2}^{n} \nabla_\theta g_\theta(x_i)\sum_{j=1}^{m} V_j (R_{\sigma(i),\tau(j)}   -  R_{\Tilde \sigma(i),\tau(j)} )\Big\|_2   We can bound independently each term in the decomposition,       (\ref{eq:decomp1}) &= \frac{2}{n} \Big\| \sum_{i=1}^{n} \nabla_\theta g_\theta(x_i)U_i   -  \nabla_\theta g_\theta(\Tilde x_i)\Tilde U_i \Big\|_2 \notag \\     &=\frac{2}{n}  \Big\| \nabla_\theta g_\theta(x_1)U_1   - \nabla_\theta g_\theta(\Tilde x_1)\Tilde U_1 \Big\|_2 \notag \\  &\leq \frac{2}{n}\Bigl(|U_1|\|\nabla_\theta g_\theta(x_1)\|_2 +|\Tilde U_1|\|\nabla_\theta g_\theta(\Tilde x_1)\|_2 \Bigr) \notag \\  &\leq \frac{4L_1M}{n}\notag \\   (\ref{eq:decomp2}) &\leq 2L_1M\Bigl(\sum_{j=1}^{m} R_{\sigma(1),\tau(j)}+\sum_{j=1}^{m} R_{\Tilde \sigma(1),\tau(j)}\Bigr)\notag \\  &= \frac{4L_1M}{n}\notag \\  (\ref{eq:decomp3})& \leq  2L_1\   \sum_{i=2}^{n} \Big |\sum_{j=1}^{m} V_j (R_{\sigma(i),\tau(j)}   -  R_{\Tilde \sigma(i),\tau(j)} )\Big| \notag\\  &=2L_1\   \sum_{i=2}^{n} \Big |\sum_{j=1}^{m} V_{(j)} (R_{\sigma(i),j)}   -  R_{\Tilde \sigma(i),j} )\Big|     The last equality is a simple consequence of $V_j=V_{(\tau(j))}$ and reindexing the sum. To bound the last expression, it is useful to see that all the terms $\sum_{j=1}^{m} V_{(j)} (R_{\sigma(i),j)}   -  R_{\Tilde \sigma(i),j} )$ have the same sign, for $i=2,\ldots,n$. This will follow from the relationship between the permutations $\sigma$ and $\Tilde \sigma$. For instance, if $\Tilde \sigma(1)<\sigma(1)$, it follows that        \item[a)] \textit{$\Tilde \sigma(i)\geq \sigma(i)$ for every $i\geq 2$}.          Remember that $\sigma(i)$ denotes the position of $U_i$ in the ordered statistic $(U_{(1)},\ldots,U_{(n)})$, and $\Tilde \sigma(i)$ denotes the position of $\Tilde U_i$ in the ordered statistic $(\Tilde U_{(1)},\ldots,\Tilde U_{(n)}')$. Recall also that $\Tilde U_i=U_i$ for every $i\geq 2$. Therefore, $\Tilde \sigma(1)<\sigma(1)$ implies that $\Tilde U_1 < U_1$, and                 \item If $\sigma(i)<\Tilde \sigma(1)$, then $ \Tilde \sigma(i)=\sigma(i)$.          \item If $\sigma(i)=\Tilde \sigma(1)$, then $ \Tilde \sigma(i)=\sigma(i)$ if $U_i<\Tilde U_1$, and $ \Tilde \sigma(i)=\sigma(i)+1$ if $U_i>\Tilde U_1$.           \item If $\Tilde \sigma(1)<\sigma(i)<\sigma(1)$, then $ \Tilde \sigma(i)=\sigma(i)+1$.            \item If $\sigma(i)>\sigma(1)$, then $ \Tilde \sigma(i)=\sigma(i)$.            \item[b)] \textit{$\sum_{j=1}^{m} V_{(j)} (R_{\sigma(i),j)}   -  R_{\Tilde \sigma(i),j} ) \leq 0$ for every $i=2,\ldots,n$}. If we denote by $G$ the empirical distribution function of $V_1,\ldots,V_{m}$, then by definition of $R_{i,j}$,                \sum_{j=1}^{m} V_{(j)} &(R_{\sigma(i),j)}   -  R_{\Tilde \sigma(i),j} ) = \\          &=\sum_{j=1}^{m} V_{(j)} \Biggl(\int_{\frac{\sigma(i)-1}{n}}^{\frac{\sigma(i)}{n}} I\Bigl( \frac{j-1}{m}<t\leq\frac{j}{m}\Bigr)dt-\int_{\frac{\Tilde \sigma(i)-1}{n}}^{\frac{\Tilde \sigma(i)}{n}} I\Bigl( \frac{j-1}{m}<t\leq\frac{j}{m}\Bigr)dt\Biggr)\\          &= \int_{\frac{\sigma(i)-1}{n}}^{\frac{\sigma(i)}{n}}\sum_{j=1}^{m} V_{(j)}  I\Bigl( \frac{j-1}{m}<t\leq\frac{j}{m}\Bigr)dt-\int_{\frac{\Tilde \sigma(i)-1}{n}}^{\frac{\Tilde \sigma(i)}{n}}\sum_{j=1}^{m} V_{(j)}  I\Bigl( \frac{j-1}{m}<t\leq\frac{j}{m}\Bigr)dt\\          &= \int_{\frac{\sigma(i)-1}{n}}^{\frac{\sigma(i)}{n}} G^{-1}(t)dt-\int_{\frac{\Tilde \sigma(i)-1}{n}}^{\frac{\Tilde \sigma(i)}{n}}G^{-1}(t)dt \\          &= \int_{\frac{\sigma(i)-1}{n}}^{\frac{\sigma(i)}{n}} G^{-1}(t)-G^{-1}\Bigl(t+\frac{\Tilde \sigma(i)-\sigma(i)}{n}\Bigr)dt \leq 0            for every $i=2,\ldots,n$, where the last bound is consequence of $(a)$ and the monotonicity of $G^{-1}$.    Similarly, if $\Tilde \sigma(1)>\sigma(1)$, then $\Tilde \sigma(i)\leq\sigma(i)$ for every $i\geq 2$, which implies  $\sum_{j=1}^{m} V_{(j)} (R_{\sigma(i),j)}   -  R_{\Tilde \sigma(i),j} ) \geq 0$. Finally, the case $\Tilde \sigma(1)=\sigma(1)$ is trivial, since this implies $\Tilde \sigma=\sigma$. Therefore, in any of the cases, the sign property implies that         (\ref{eq:last_inequality_2})& =  2L_1\  \Big | \sum_{i=2}^{n} \sum_{j=1}^{m} V_{(j)} (R_{\sigma(i),j)}   -  R_{\Tilde \sigma(i),j} )\Big| \\      &= 2L_1\  \Big |  \sum_{j=1}^{m} V_{(j)} \sum_{i=2}^{n}(R_{\sigma(i),j)}   -  R_{\Tilde \sigma(i),j} )\Big| \\      &= 2L_1\  \Big |  \sum_{j=1}^{m} V_{(j)} \sum_{i=1}^{n}(R_{\sigma(i),j)}   -  R_{\Tilde \sigma(i),j} ) - \sum_{j=1}^{m} V_{(j)} (R_{\sigma(1),j)}   -  R_{\Tilde \sigma(1),j} )\Big| \\      &=  2L_1\  \Big |  \sum_{j=1}^{m} V_{(j)} (R_{\sigma(1),j)}   -  R_{\Tilde \sigma(1),j} )\Big| \\      &\leq 2L_1M \Bigl( \sum_{j=1}^{m} R_{\sigma(1),\tau(j)}+\sum_{j=1}^{m} R_{\Tilde \sigma(1),\tau(j)}\Bigr) \\      &= \frac{4L_1M}{n}    Putting everything together, we can conclude that,       \|\nabla_\theta W_2^2&(g_\theta\# P_{\vect{X}}, h_\theta \# P_{\vect{Z}})- \nabla_\theta W_2^2(g_\theta\# P_{\vect{\Tilde X}}, h_\theta \# P_{\vect{Z}}) \|_2 \leq \frac{12L_1M}{n} + \frac{4L_2 M}{n} \ .",2502.01701
proof,"[Proof of Lemma~\ref{lemma:subsampling}]     See the proof of Theorem 29 in \cite{DBLP:journals/corr/abs-2210-00597} which gives the result up to a minor adaptation. The term $\max \p{\frac{n_{1}'}{n_1}, \dots,  \frac{n_k'}{n_k}}$ indeed comes from considering the worst case analysis depending on which category the differing point is in.",2502.01701
proof,"[Proof of Theorem~\ref{th:fairandprivate}]     Formally, with the notation of \Cref{definition:neighboring}, define for the first part $\mathcal D = \mathcal D_0^{n_0}\times \mathcal D_1^{n_1}$, where $\mathcal D_j = \mathcal X \times \mathcal Y \times \{j\}$ in the supervised case, and  $\mathcal D_j = \mathcal X  \times \{j\}$ in the unsupervised case, for $j=0,1$. Applying \cref{theorem:gradient_sensitivity_sliced} with $g_\theta = h_\theta$, we can bound the sensitivity of $\nabla_\theta \mathscr L^{SP}_\alpha(g_\theta)$ by \eqref{eq:sensitivity_SP}.          For the second part, consider $\mathcal D =\prod_{j,k} \mathcal D_{j,k}^{n_{j,k}}$, where $\mathcal D_{j,k} = \mathcal X \times \{j\} \times \{k\}$, for $j \in \{0,1\}, k\in\{0,\ldots,R-1\}$. Under the relation $\sim_{2R}$, given two neighboring datasets, all the terms except one are the same in the sum in \eqref{eq:loss_SP}, and similarly for the gradient expression. More precisely,  under the assumptions of the theorem, with the notation adopted in \cref{section:fairness},              &\sup_{\vect D \sim_{2R}   \vect{\Tilde D}} \Big\|  \frac{1}{R} \sum_{k=1}^K \nabla_\theta{SW}_2^2\Bigl(  g_\theta \# P_{\vect X_{0,k}}, g_\theta \# P_{\vect X_{1,k}} \Bigr) -  \frac{1}{R} \sum_{k=1}^K \nabla_\theta{SW}_2^2\Bigl(  g_\theta \# P_{\vect{\Tilde X}_{0,k}}, g_\theta \# P_{\vect{\Tilde X}_{1,k}} \Bigr) \Big\|_2 \\   &\leq \frac{1}{R}   \sup_{\vect D \sim_{2R}   \vect{\Tilde D}} \sum_{k=1}^K \Big\|  \nabla_\theta{SW}_2^2\Bigl(  g_\theta \# P_{\vect X_{0,k}}, g_\theta \# P_{\vect X_{1,k}} \Bigr) -   \nabla_\theta{SW}_2^2\Bigl(  g_\theta \# P_{\vect{\Tilde X}_{0,k}}, g_\theta \# P_{\vect{\Tilde X}_{1,k}} \Bigr) \Big\|_2 \\         &\leq \frac{1}{R} \max_{k=0,\ldots,R-1} \sup_{(\vect X_{0,k},\vect X_{1,k}) \sim_{2}   (\vect{\Tilde X}_{0,k},\vect{\Tilde X}_{1,k})} \Big\|  \nabla_\theta{SW}_2^2\Bigl(  g_\theta \# P_{\vect X_{0,k}}, g_\theta \# P_{\vect X_{1,k}} \Bigr) -\nabla_\theta{SW}_2^2\Bigl(  g_\theta \# P_{\vect{\Tilde X}_{0,k}}, g_\theta \# P_{\vect{\Tilde X}_{1,k}} \Bigr) \Big\|_2 \\    &\leq \frac{1}{R}\max_{k=0\ldots,R-1} \frac{16ML}{\min \{n_{0,k},n_{1,k}\}} = \frac{1}{R}\frac{16ML}{\min_{j,k} \{n_{j,k}\}}       which implies \eqref{eq:sensitivity_EO}.",2502.01701
proposition,"With the above notation,         W_2^2(P_{\vect U},P_{\vect V})  = \sum_{i=1}^{n} \sum_{j=1}^{m} R_{\sigma(i),\tau(j)}(U_{i}-V_{j} )^2     .",2502.01701
proposition,"With all the previous definitions,      $W_2^2(P_{\vect U},P_{\vect V})$ is differentiable as a function of $\vect U=(U_1,\ldots,U_n)$ in the set of points verifying $U_{(1)}<\ldots<U_{(n)}$, and its gradient is given by              \nabla_{U}W_2^2(P_{\vect U},P_{\vect V}) = \Bigl( 2\sum_{j=1}^m R_{\sigma(i),\tau(j)} (U_i-V_j)\Bigr)_{i\in[n]}          Similarly, as a function of $\vect V=(V_1,\ldots,V_m)$, $W_2^2(P_{\vect U},P_{\vect V})$  is differentiable in the set of points verifying $V_{(1)}<\ldots<V_{(m)}$, and               \nabla_{V}W_2^2(P_{\vect U},P_{\vect V}) = \Bigl( 2\sum_{i=1}^n R_{\sigma(i),\tau(j)} (V_j-U_i)\Bigr)_{j\in[m]}",2502.01701
lemma,"[Privacy of the Gaussian mechanism (Corollary of Theorem 2.7, Corollary 3.3 and Corollary 2.13 in \cite{dong2019gaussian})]      Given a deterministic function $h$ mapping a dataset to a quantity in $\R^{d'}$, one can define the $l_2$-sensitivity of $h$ as           \Delta_2 h \eqdef \sup_{\vect{D}\sim \vect{\Tilde D}} \big\| h (\vect{D})  - h (\vect{\Tilde D})\big\|_2 \;.   When this quantity is finite, for any $\sigma > 0$, the Gaussian mechanism defined as                \vect{D} \mapsto h(\vect{D}) + \sigma \mathcal{N}(0, I_{d'}) \;,       is $(\epsilon, \delta(\epsilon))$-DP for any $\epsilon \geq 0$ where, by noting $\mu = \frac{\Delta_2 h}{\sigma}$,      \delta(\epsilon) = \Phi \Bigl( - \frac{\epsilon}{\mu} + \frac{\mu}{2}\Bigr) - e^{\epsilon} \Phi \Bigl( - \frac{\epsilon}{\mu} - \frac{\mu}{2}\Bigr) \;,  where $\Phi$ denotes the standard normal CDF.",2502.01701
lemma,"[Privacy amplification by subsampling]      Let $n_1' \leq n_1, \dots, n_k' \leq n_k$. If a mechanism $M_{\text{batch}}$ is $(\epsilon, \delta)$-DP on $\mathcal D_1^{n_1'} \times \ldots \times \mathcal D_k^{n_k'}$, the mechanism $M$ that      (i) selects $n_{i}'$ among the $n_i$ points in each category without replacement, and then     (ii) applies $M_{\text{batch}}$ to the sampled dataset, is $(\epsilon', \delta')$-DP on $\mathcal D_1^{n_1} \times \ldots \times \mathcal D_k^{n_k}$ where $\epsilon' = \ln \p{1 + p\p{e^{\epsilon} - 1}} , \quad \delta' = p \delta$      and $p = \max \p{\frac{n_{1}'}{n_1}, \dots,  \frac{n_k'}{n_k}}$.",2502.01701
theorem,"\ {\rm (\cite{Gay-Kirby}, \cite{Spreer-Tillmann(Exp)}, \cite{Miller-Naylor})} \   Each smooth closed orientable (resp. non-orientable) $4$-manifold $M$ admits a decomposition $M = H_0 \cup H_1 \cup H_2$, such that:      \item [(a)]  $H_{0}, H_{1}, H_{2}$ are $4$-dimensional orientable (resp. non-orientable) handlebodies with pairwise disjoint interiors;   \item [(b)]  $H_{01}=H_{0}\cap H_{1},$  $H_{02}=H_{0}\cap H_{2}$ and $H_{12}=H_1\cap H_2$ are $3$-dimensional orientable (resp. non-orientable) handlebodies with the same genus;   \item [(c)]  $\Sigma = H_{0}\cap H_{1}\cap H_{2}$  is a closed connected orientable (resp. non-orientable) surface.",2502.01757
theorem,"{\em (\cite{Casali-Cristofori-Grasselli})}\    Any compact $n$-manifold $M$  admits a gem $\G$, that is bipartite if and only if $M$ is orientable. \par \noindent In particular, if  $M$ has empty or connected boundary:   \item $\G$ may be assumed to have color $n$ as its unique possible singular color, and exactly one $\hat n$-residue (in this case we will say that $\G$ belongs to the class $G^{(n)}_s$); \item $\G$ may be assumed to have exactly one $\hat c$-residue, $\forall c \in \Delta_n$ (in this case $\G$ is  called   a \emph{crystallization} of $M$).",2502.01757
theorem,"\ {\rm (\cite{Casali-Cristofori Kirby-diagrams})} \  Given a compact 4-manifold $M$, let $(L,d)$ be a connected Kirby diagram representing it, where all dotted components, if any, are in good position. Then, the 5-colored graph $\G(L,d)$ is a gem of $M.$",2502.01757
theorem,"\ {\rm (\cite{Casali-Cristofori Kirby-diagrams})} \    Let $M$ be a compact 4-manifold and let $(L,d)$ be a connected Kirby diagram representing $M$, with $l$ components %,   whose dotted ones, if any, are in good position. Then: $$\mathcal G(M)\leq  \  s + \bar s  + (l-m) +1$$  \noindent where $m \ge 0$ is the number of dotted components, $s$ the number of crossings of $(L,d)$ and $\bar s$ the number of undercrossings of its framed components. Moreover, if $L$ is different from the trivial knot:  $$k(M)\leq \ 2s + 2 \bar s  + 2 m -1 + 2\sum_{i=1}^{l-m} t_i  $$ \noindent where  $t_i=2$ if the writhe and the framing of the $i$-th framed component coincide, otherwise $t_i$ is the absolute value of their difference.",2502.01757
theorem,"\ {\rm (\cite{Casali-Cristofori Kirby-diagrams})} \    Let $M$ be a compact 4-manifold and let $(L,d)$ be a connected Kirby diagram  with no dotted components representing $M$. Then: $$\mathcal G(M)\leq m_{\alpha} + l$$ \noindent where $l$ is the number of components of $L$ and $m_\alpha$ is the number of $\alpha$-colored regions in a chess-board coloration of $L$, $\alpha$ being the color of the unbounded region.",2502.01757
theorem,"\ {\rm (\cite{Casali-Cristofori gem-induced}, \cite{Casali-Cristofori trisection bis})} \   For each 5-colored graph $\Gamma \in G_s^{(4)}$ representing a compact $4$-manifold with empty (resp. connected boundary) $M$ and for  each cyclic permutation $\varepsilon= (\e_0,\e_1,\e_2,\e_3, \e_4=4)$ of $\Delta_4,$  a  triple $\mathcal  T(\Gamma, \varepsilon) =(H_{0},H_{1},H_{2})$ of submanifolds of $M$ is constructed, such that    \item [(a)]  $M = H_{0}\cup H_{1}\cup H_{2}$ and $H_{0}, H_{1}, H_{2}$ have pairwise disjoint interiors   \item [(b)]  $H_{1},H_{2}$ are $4$-dimensional handlebodies; $H_{0}$ is a $4$-disk \  (resp. is  homeomorphic to $\partial M \times [0,1]$) \item [(c)] $H_{01}=H_{0}\cap H_{1},$  $H_{02}=H_{0}\cap H_{2}$ are $3$-dimensional handlebodies  \item [(d)] $\Sigma = H_{0}\cap H_{1}\cap H_{2}$  is a closed connected surface.       Moreover, if $H_{12}=H_1\cap H_2$ is a 3-dimensional handlebody, too, then all the above handlebodies, as well as the surface $\Sigma$, are orientable or not according to the orientability of $M$; in the first case $\Sigma$ has genus $\rho_{\varepsilon}(\G_{\hat 4})$, while in the second one it has genus $2\rho_{\varepsilon}(\G_{\hat 4}).$",2502.01757
theorem,"\ {\rm (\cite{Casali-Cristofori trisection bis})} \  \ Let \ $M$ \ be \ a \ compact \ \ orientable \ \ (resp. \ non-orientable) \ \ $4$-manifold \ with \ boundary  \  \  $\partial M \cong \#_m(\mathbb S^1 \otimes \mathbb S^2)$, $m>0$.            If $M$ admits a gem-induced trisection,  then $\bar M \cong M \cup {\mathbb Y}_m^{(\sim)}\!$   admits a trisection with the same central surface.    As a consequence, $$g_T(\bar M) \le g_{GT} (M).$$",2502.01757
theorem,"{\rm (\cite{Casali-Cristofori trisection ter})} \  Let $\G\in G_s^{(4)}$ be a gem of a compact $4$-manifold $M$ with $\partial M \cong \#_m(\mathbb S^1 \otimes \mathbb S^2)$,  $m \ge 0$.    For each cyclic permutation $\varepsilon$ of $\Delta_4$, the  triple $\mathcal  T(\Gamma, \varepsilon)$ gives rise to a trisection of $\bar M \cong M \cup{\mathbb Y}_m^{(\sim)}$  by applying $k$  stabilizations, with $0 \le k \le \rho_\e(\Gamma) - \rho_{\e}(\Gamma_{\hat 4})$. Hence:  $$g_T(\bar M) \le \rho_\e(\Gamma)$$",2502.01757
theorem,"\ {\rm (\cite{Casali-Cristofori trisection ter})} \  For each compact $4$-manifold $M$ with $\partial M \cong \#_m(\mathbb S^1 \otimes \mathbb S^2)$, $m \ge 0$,    then:  $$g_T(\bar M) \le \mathcal G(M)$$ where $\bar M \cong M \cup {\mathbb Y}_m^{(\sim)}$.",2502.01757
theorem,"\ {\rm (\cite{Casali-Cristofori trisection ter})} \  For each closed $4$-manifold $M$,  then:  $$g_T(M) \le \mathcal G(M).$$",2502.01757
theorem,"\ {\rm (\cite{Casali-Cristofori gem-induced})} \  Let $M$ be a compact %PL  $4$-manifold with empty or connected boundary admitting a handle decomposition with no $3$-handles.   \smallskip  \noindent  Then, from each (connected and with dotted components in ``good position"") Kirby diagram $(L,d)$ of $M$, a gem-induced trisection of $M$ can be algorithmically constructed, whose central surface has genus $s+1$, $s$ being the crossing number of the chosen diagram.  \noindent Furthermore, if $(L,d)$ has no dotted components (equivalently, if $1$-handles are missing, too), then a gem-induced trisection of $M$ can be obtained,  whose central surface has genus $m_\alpha$, where $m_{\alpha}$ is the number of $\alpha$-colored regions in a chess-board coloration of the diagram, $\alpha$ being the color of the unbounded region.",2502.01757
theorem,"\  {\rm (\cite{Casali-Cristofori trisection bis})} \   \item[(i)] For each closed orientable $4$-manifold $\bar M$,   $$g_T(\bar M) \le s+1,$$  $s$ being the crossing number of a (connected and with dotted components in ``good position"") Kirby diagram representing $\bar M$.  \item[(ii)] Furthermore, if  $\bar M$ admits a handle decomposition lacking in $1$-handles, then  $$g_T(\bar M) \le m_\alpha,$$ where $m_{\alpha}$ is  the number of $\alpha$-colored regions in a chess-board coloration of a (connected and with no dotted component) Kirby diagram representing  $\bar M$, $\alpha$ being the color of the unbounded region.",2502.01757
definition,"\ {\rm (\cite{Gay-Kirby}, \cite{Spreer-Tillmann(Exp)}, \cite{Miller-Naylor})} \   {\em A triple $(H_0, H_1, H_2)$ that satisfies the requirements of Theorem \ref{th: trisection} is said to be a {\it trisection} of $M$; the {\it genus} of such a trisection is defined as the common genus of the 3-dimensional handlebodies $H_{01}, H_{02}, H_{12}$, while the surface $\Sigma$ is called the {\it central surface} of the trisection.\footnote{Note that in the orientable (resp. non-orientable) case the genus of the central surface equals (resp. is the double of) the genus of the trisection.  Actually, many slightly different versions of the notions regarding trisections exist, also in the cited %quoted  papers, for example requiring that all $4$-dimensional handlebodies have the same genus (giving rise to the so-called {\it balanced trisections}), or considering the genus of the central surface as the genus of the trisection, also in the non-orientable case. However, no loss of generality occurs, and it is not difficult to translate one version into the others.}   The {\it trisection genus} of a smooth closed $4$-manifold $M$ is defined as the minimum genus of a trisection of $M$.  }",2502.01757
definition,"{\em A $(g; k_0; k_1; k_2)$-{\it trisection diagram} is a 4-tuple $(\Sigma; \alpha, \beta,\gamma)$ such that the triples $(\Sigma; \alpha, \beta)$, $(\Sigma; \alpha, \gamma)$ and $(\Sigma; \beta,\gamma)$ are genus $g$ Heegaard diagrams for $\#_{k_0}(\mathbb S^1 \otimes \mathbb S^2)$, $\#_{k_1}(\mathbb S^1 \otimes \mathbb S^2)$ and $\#_{k_2}(\mathbb S^1 \otimes \mathbb S^2)$ respectively.\footnote{Obviously, all $3$- and $4$-dimensional manifolds involved in Definition \ref{def. trisection-diagram}, as well as in the procedure to reconstruct the represented closed $4$-manifold, are orientable or not according to $\Sigma$.}  }",2502.01757
definition,"{\em An $(n+1)${\emph{-colored graph}}  ($n \ge 2$) is a pair $(\G,\g)$, where $\G=(V(\G), E(\G))$ is a multigraph (i.e. multiple edges are allowed, while loops are forbidden)  which is regular of degree  $n+1$, and $\g$ is an {\it edge-coloration}, that is a map  $\g: E(\G) \rightarrow \Delta_n=\{0,\ldots, n\}$ which is injective on adjacent edges.  For sake of concision, the coloration $\gamma$ is often understood, and the colored graph is simply denoted by $\G$. }",2502.01757
definition,"{\em An {\it $r$-dipole ($1\le r\le n$) of colors $c_1,\ldots,c_r$} of an $(n+1)$-colored graph $\G$ is a subgraph consisting of two vertices, belonging to different connected components of $\Gamma_{\hat c_1\ldots\hat c_r}$, that are joined by $r$ edges, colored by $c_1,\ldots,c_r.$  The {\it elimination} of an $r$-dipole in $\Gamma$ can be carried out by deleting the subgraph and welding the remaining hanging edges according to their colors; in this way another $(n+1)$-colored graph $\Gamma^\prime$ is obtained. The inverse operation is called the {\it addition} of the dipole to $\Gamma^\prime.$  }",2502.01757
definition,"{\em A $\rho_h${\it -pair} ($1\leq h\leq n$) of color $i\in\Delta_n$ in an $(n+1)$-colored graph $\Gamma$ is a pair of $i$-colored edges $(e,f)$ sharing the  same $\{i,c\}$-colored cycle for each $c\in\{c_1,\ldots,c_h\}\subseteq\Delta_n.$  \\ The {\it switching} of $(e,f)$ consists in canceling $e$ and $f$ and establishing new $i$-colored edges between their endpoints; the reversed operation is obviously the switching of a $\rho_{n-h}$-pair.   Although, in general, the switching can  be performed in two different ways, it is uniquely determined if $\G \in G^{(n)}_s,\ h\in \{n-1, n\}$ and the bipartition of each non-singular $\hat c$-residue is preserved.  }",2502.01757
definition,"{\em The \emph{regular genus} of  an $(n+1)$-colored graph $\G$ is defined as $$\rho(\G) = min\{\rho_\varepsilon(\G)\ \vert \ \varepsilon\ \text{cyclic permutation of \ } \Delta_n\},$$ while the  {\it regular genus} of a compact $n$-manifold $M$ is defined as $$\mathcal G (M) = min\{\rho(\G)\ \vert \ \G\ \text{gem of \ } M\}.$$  }",2502.01757
definition,"{\em For each compact $n$-manifold $M$, its \emph{gem-complexity} is the non-negative integer $k(M)= p - 1$,  where $2p$ is the minimum order of an $(n+1)$-colored graph representing $M$.  }",2502.01757
definition,"\ {\rm (\cite{Casali-Cristofori gem-induced}, \cite{Casali-Cristofori trisection bis})} \   {\em Let $M$ be a compact %PL  $4$-manifold with empty or connected boundary.  A {\it gem-induced trisection} of $M$ is a decomposition  $\mathcal  T(\Gamma, \varepsilon) =(H_{0},H_{1},H_{2})$ such that $H_{12}=H_1\cap H_2$ is a 3-dimensional handlebody, $\Gamma \in G_s^{(4)}$ being a 5-colored graph representing $M$ and $\e=(\e_0,\e_1,\e_2,\e_3,4)$ a cyclic permutation of $\Delta_4$.  }",2502.01757
definition,{\em A trisection of a closed (orientable or non-orientable) 4-manifold $\bar M$ is said to {\it arise from a colored triangulation} if it is either a gem-induced trisection of $\bar M$ or is obtained from a gem-induced trisection of $M$ (such that $\bar M \cong M \cup {\mathbb Y}_m^{(\sim)}$) according to Theorem \ref{trisection_from_gem-induced}.   },2502.01757
definition,"{\em A {\it G-trisection diagram}  of genus $g$ is a 4-tuple $(\Sigma; \alpha, \beta, \gamma)$, where $\Sigma$ is a genus $g$ orientable surface and $\alpha$, $\beta$, $\gamma$ are complete systems of curves on $\Sigma$, such that:       \item[-]    $(\Sigma; \alpha, \gamma)$ and $(\Sigma; \beta, \gamma)$ are (genus $g$) Heegaard diagrams of $\#_{k_1}(\mathbb S^1 \times \mathbb S^2)$ and $\#_{k_2}(\mathbb S^1 \times \mathbb S^2)$ respectively, with $0\le k_i \le g$, for $i=1,2$;   \item[-]   $(\Sigma; \alpha, \beta)$ is a (genus $g$) Heegaard diagram of a closed connected 3-manifold.       }",2502.01757
proposition,"Let $\G$ be a gem of a compact $n$-manifold $M$ with empty or connected boundary.  If $\Gamma^\prime$ is obtained from $\Gamma$ by eliminating an $r$ dipole ($1\le r\le n$), then $\Gamma^\prime$ is a gem of $M$, too.",2502.01757
proposition,"{\em (\cite{Ferri-Gagliardi-Grasselli})} Let $\G$ be a connected bipartite (resp. non-bipartite)  $(n+1)$-colored graph of order $2p$. Then for each cyclic permutation $\varepsilon = (\varepsilon_0,\ldots,\varepsilon_n)$ of $\Delta_n$, up to inverse, there exists a cellular embedding, called \emph{regular}, of $\G$   into an orientable (resp. non-orientable) closed surface $F_{\varepsilon}(\G)$ whose regions are bounded by the images of the $\{\varepsilon_j,\varepsilon_{j+1}\}$-colored cycles, for each $j \in \mathbb Z_{n+1}$. Moreover, the genus (resp. half of the genus)  of $F_{\varepsilon}(\G)$, denoted by $\rho_{\varepsilon} (\G)$,  satisfies   2 - 2\rho_\varepsilon(\G)= \sum_{j\in \mathbb{Z}_{n+1}} g_{\varepsilon_j, \varepsilon_{j+1}} + (1-n)p.",2502.01757
proposition,"\ Let $(L,d)$ be a connected Kirby diagram, with $s$ crossings, whose dotted components, if any, are in good position. If the cyclic permutation $\varepsilon = (1,0,2,3,4)$ is chosen, then: $$\rho_{\varepsilon}(\G_{\hat 4}(L,d))=\rho_{\varepsilon}(\Lambda(L,d)) = s + 1.$$ \smallskip Moreover, if dotted components are missing and $m_\alpha$ is the number of $\alpha$-colored regions in a chess-board coloration of $L$ (where $\alpha$ is the color of the unbounded region), then $$\rho_{\varepsilon}(\tilde\Omega_{\hat 4}(L,d))=\rho_{\varepsilon}(\Omega(L,d)) = \  m_\alpha.$$",2502.01757
proposition,"Let $M$ be a compact 4-manifold with $\partial M\cong\#_r(\mathbb S^1\times\mathbb S^2)$ and let $\bar M$ be its associated closed 4-manifold. If $\G\in G_s^{(4)}$ is a gem of $M$ such that $\G_{\hat 4}$ contains $r\geq 1$ $\rho_3$-pairs of color $i\in\Delta_3$, whose switchings yield a gem of $\mathbb S^3,$ then:  \item [(i)] if all $\rho_3$-pairs of $\G_{\hat 4}$ are $\rho_3$-pairs in $\G$, too, then their switchings yield a gem of $\bar M;$ \item [(ii)] if $r'\leq r$ of them are $\rho_4$-pairs in $\G$, then by switching all pairs a gem  of a closed 4-manifold $N$ is obtained such that: $\bar M\cong\#_{r'}(\mathbb S^1\times\mathbb S^3)\# N.$",2502.01757
proposition,"\ {\rm (\cite{Casali-Cristofori gem-induced}, \cite{Casali-Cristofori trisection bis})} \  Let $M$ be a compact $4$-manifold with empty or connected boundary and $\G\in G_s^{(4)}$ a gem of $M$ of order $2p$;  if  there exists an ordering $(e_1,\ldots,e_p)$ of the 4-colored edges of $\G$ such that for each $j\in\{1,\ldots,p\}$: $$ \text{there exists } i\in\Delta_3 \text{ such that} & \ \text{all 4-colored edges of  the }  \\ \{4,i\}\text{-colored cycle} \ \text{containing } e_j  & \ \text{belong to the set }\{e_1,\ldots,e_j\},\hskip 15pt (*)$$      then $\mathcal T(\G, \varepsilon)$ is a gem-induced trisection of $M$, for each cyclic permutation $\e$ of $\Delta_4.$",2502.01757
proposition,"\  {\rm \cite{Casali-Cristofori trisection bis} } \  Let $M$ be a compact $4$-manifold with empty or connected boundary.  A gem-induced trisection of $M$ is a trisection if and only if  $M$ is closed and orientable.   \noindent Moreover, a closed orientable $4$-manifold admits a gem-induced trisection if and only if it admits a handle decomposition lacking in 3-handles (or in 1-handles).",2502.01757
proposition,"\ {\rm (\cite{Casali-Cristofori trisection bis})} \  Let \  $\bar M\, \cong_{PL}\,(\#_p\mathbb {CP}^2)\,\#\,(\#_{p^{\prime}}(-\mathbb {CP}^2))\, \#\, (\#_q(\mathbb S^2\times \mathbb S^2)) \, \#  \, (\#_r K3) \,\#\,(\#_s(\mathbb S^1 \otimes \mathbb S^3))\, \# (\#_t\mathbb R \mathbb P^4)\,\# \, (\#_u  (\mathbb S^2 \times \mathbb {RP}^2 )),$  with $p,p^{\prime},q, r,s,t,u \geq 0$.   Then, its trisection genus \ $ g_T(\bar M)  = (p + p^{\prime} + 2q + 22r)+s+2t+3u$ \  is realized by a trisection arising from a colored triangulation.",2502.01757
proposition,"\ Let $\Gamma\in G_s^{(4)}$ be a gem of a compact $4$-manifold $M$ with $\partial M \cong \#_m(\mathbb S^1 \otimes \mathbb S^2)$, $m \ge 0$, satisfying condition (*) of Proposition \ref{CS gem-induced trisections}.   Then, for each cyclic permutation $\varepsilon=(\e_0,\e_1, \e_2, \e_3, 4)$ of $\Delta_4$, a trisection diagram for the associated closed $4$-manifold $\bar M$  is given by the following three systems of curves $\{ \alpha, \beta, \gamma\}$ on  $F_\e(\Gamma_{\hat 4}):$     \item[-] the $\alpha$ curves (resp. $\beta$ curves) consist of all $\{\e_0,\e_2\}$-colored cycles (resp. $\{\e_1,\e_3\}$-colored cycles) of $\Gamma$, but those corresponding to a maximal tree of the 1-dimensional subcomplex $K_{\e_1 \e_3}$ (resp. $K_{\e_0 \e_2}$), generated by the vertices labelled $\e_1$ and $\e_3$ (resp. $\e_0$ and $\e_2$) of $K(\Gamma).$     \item[-] the $\gamma$ curves are a subset of the $\{c,4\}$-colored cycles of $\Gamma$, with $c \in \Delta_3$, which can be combinatorially identified by following - via condition (*) - the collapsing sequence of the 3-dimensional handlebody $H_{12}$ (according to the notations of Section \ref{sss Gem-induced trisections}).",2502.01757
proposition,"With the above notations, let $\mathcal T$ be the trisection of $\bar M$ induced by $\Gamma(L,d)$ (resp. $\tilde \Omega(L,d)$). Then, a trisection diagram for $\mathcal  T$ is given by the following three system of curves $\{ \alpha, \beta, \gamma\}$ on $\Sigma$:   \item[-]   the $\alpha$ curves are all $\{1,2\}$-colored cycles of $\Gamma(L,d)$ (resp. $\tilde\Omega(L,d)$), but one arbitrarily chosen;     \item[-] the $\beta$ curves are all $\{0,3\}$-colored cycles of $\Gamma(L,d)$ (resp. $\tilde\Omega(L,d)$),  but $2l-1$ corresponding to a maximal tree of the 1-dimensional subcomplex $K_{12}$ generated by the vertices labelled $1$ and $2$;   \item[-] the $\gamma$ curves are all $\{2,4\}$-colored cycles of $\Gamma(L,d)$ (resp. $\tilde\Omega(L,d)$), but one arbitrarily chosen.",2502.01757
proposition,"Let $M$ be a simply-connected compact $4$-manifold with connected boundary, admitting a genus $g$ gem-induced trisection.       Then, $M$ is uniquely identified by a G-trisection diagram $(\Sigma; \alpha, \beta, \gamma)$ of genus $g$,       so that $(\Sigma; \alpha, \beta)$ is a Heegaard diagram of $\partial M$.",2502.01757
proposition,"\  Let $\Gamma\in G_s^{(4)}$ be a gem of a simply-connected compact $4$-manifold $M$ with connected boundary $\partial M$, satisfying condition (*) of Proposition \ref{CS gem-induced trisections}.   Then, for any cyclic permutation $\varepsilon$ of $\Delta_4$, a G-trisection diagram for $M$ is given by the following three system of curves $\{ \alpha, \beta, \gamma\}$ on $F_\e(\Gamma_{\hat 4})$:  \item[-] the $\alpha$ curves (resp. $\beta$ curves) consist of all $\{\e_0,\e_2\}$-colored cycles (resp. $\{\e_1,\e_3\}$-colored cycles) of $\Gamma$, but those corresponding to a maximal tree of the 1-dimensional subcomplex   $K_{\e_1 \e_3}$ (resp. $K_{\e_0 \e_2}$),  generated by the vertices labelled $\e_1$ and $\e_3$ (resp. $\e_0$ and $\e_2$) of $K(\Gamma).$     \item[-] the $\gamma$ curves are a subset of  $\{c,4\}$-colored cycles of $\Gamma$, with $c \in \Delta_3,$ which can be combinatorially identified by following - via condition (*) - the collapsing sequence for the 3-dimensional handlebody $H_{12}$ (according to the notations of Section \ref{sss Gem-induced trisections}).",2502.01757
proposition,"Let $(L,d)$ be a (connected) framed link representing a (simply-connected) $4$-manifold $M$ with non-empty boundary, and let $\mathcal T$ be the gem-induced trisection of $M$ induced by $\Gamma(L,d)$ (resp. $\tilde \Omega(L,d)$).  Then, a G-trisection diagram for $\mathcal  T$ is given by the following three system of curves $\{ \alpha, \beta, \gamma\}$ on $\Sigma$:      \item[-]  the $\alpha$ curves are all $\{1,2\}$-colored cycles of $\Gamma(L,d)$ (resp. $\tilde\Omega(L,d)$), but one arbitrarily chosen;    \item[-]  the $\beta$ curves are all $\{0,3\}$-colored cycles of $\Gamma(L,d)$ (resp. $\tilde\Omega(L,d)$),  but $2l-1$ corresponding to a maximal tree of the 1-dimensional subcomplex $K_{12}$    generated by the vertices labelled $1$ and $2$;  \item[-]  the $\gamma$ curves are all $\{2,4\}$-colored cycles of $\Gamma(L,d)$ (resp. $\tilde\Omega(L,d)$), but one arbitrarily chosen.",2502.01757
proposition,"\  {\rm (\cite{Casali-Cristofori gem-induced})} \ $$g_T(M)\ =\ \beta_2(M)$$ for each closed  (simply-connected) $4$-manifold $M$  which admits a $5$-colored graph $\G\in G_s^{(4)}$ representing $M$ with   $g_{\varepsilon_0,\varepsilon_{2},\varepsilon_{4}} = 1 $ and  $g_{\varepsilon_1,\varepsilon_{3},\varepsilon_{4}} = 1 $  ($\varepsilon$ being a cyclic permutation of $\Delta_4$), so that $\mathcal T(\G,\varepsilon)$ is a gem-induced trisection.  \par \noindent  In particular:  $$g_T(M)\ =\ \beta_2(M) =\frac 1 2   \, \mathcal G(M)$$       for each closed  (simply-connected) $4$-manifold $M$ admitting a  crystallization $\G$ with $g_{\varepsilon_i,\varepsilon_{i+2},\varepsilon_{i+4}} = 1 \ \ \forall i \in \Delta_4$ ($\varepsilon$ being a cyclic permutation of $\Delta_4$)\footnote{This condition is usually referred to by saying that  $\G$ is {\it weak simple} with respect to $\varepsilon$.} and such that $\mathcal T(\G,\varepsilon)$ is a gem-induced trisection.",2502.01757
example,"{\em Figures \ref{fig:S^xS^2} and \ref{fig:S^xS^2_trisection-diagram} show how to apply Proposition \ref{trisection_diagrams_gem-induced}: the gem of $\mathbb S^2 \times \mathbb S^2$ in Figure \ref{fig:S^xS^2} admits the depicted ordering of its $4$-colored edges, $(e_1, e_2, e_3, e_4, e_5, e_6, e_7)$,  which corresponds to a sequence of collapses of the squares of $\bar H(\G, \e)$ ($\e$ being the identity permutation) from their free edges corresponding respectively to $\{c_i,4\}$-colored cycles, $\forall i = 1, \dots, 7$ (with $c_1=1$, $c_2=1$, $c_3=3$, $c_4=2$, $c_5=3$, $c_6=2$, $c_7=1$). The result is a 1-dimensional complex $\bar{\bar H}$ consisting only of five edges: three corresponding to all $\{0,4\}$-colored cycles of $\Gamma$, one corresponding to the $\{2,4\}$-colored cycle containing $\{e_1, e_2, e_5, e_7\}$ and one corresponding to the $\{3,4\}$-colored cycle containing $\{e_2, e_4, e_6, e_7\}$.   By shrinking to a point one of the edges of $\bar{\bar H}$ corresponding to a $\{0,4\}$-colored cycle (for example the one containing $e_2$, $e_5$ and $e_4$), and both edges corresponding to $\{2,4\}$- and $\{3,4\}$-colored cycles, the system $\gamma$ of curves depicted in red in Figure \ref{fig:S^xS^2_trisection-diagram}  is identified; it gives rise to a trisection diagram of $\mathbb S^2 \times \mathbb S^2$, together with the system $\alpha$ of curves depicted in green (all $\{0,2\}$-colored cycles of $\Gamma$, but one arbitrarily chosen, since $K_{\e_1 \e_3}$  contains exactly two vertices) and the system $\beta$ of curves depicted in  blue (all $\{1,3\}$-colored cycles of $\Gamma$, but one arbitrarily chosen, since $K_{\e_0 \e_2}$ contains exactly two vertices).    Note that the three systems of curves on the (genus two) surface where $\G_{\hat 4}$ regularly embeds, in pairs give rise to genus two Heegaard diagrams of the boundaries of the 4-dimensional pieces of the trisection of $\mathbb S^2 \times \mathbb S^2$ (which are actually $3$-spheres).    [ht]  %[h]     \centering     \includegraphics[width=0.7\linewidth]{S2xS2_trisection-diagram_dic2024_bis-arxiv.pdf}    \caption{A gem of $\mathbb S^2 \times \mathbb S^2$, with an ordering of $4$-colored edges giving rise to a gem-induced trisection}         [ht]  %[h]     \centering     \includegraphics[width=0.7\linewidth]{S2xS2_trisection-diagram_evidenziato_dicembre2024_ter-arxiv.pdf}     \caption{The associated trisection diagram  of $\mathbb S^2 \times \mathbb S^2$}       }",2502.01757
example,"{\em Figures \ref{fig:M4(trefoil,1)} and \ref{fig:M4(trefoil,1)_trisection-diagram} show an application of Proposition \ref{trisection_diagrams_gem-induced_framed-links} to the framed link consisting of a trefoil knot $K_T$ with framing 1: the gem $\tilde\Omega(K_T,1)$ of Figure \ref{fig:M4(trefoil,1)} represents a (simply-connected) compact $4$-manifold $M$ (whose boundary is the Poincar\'e homology sphere), has regular genus $m_\alpha +1 = 3$ and gives rise to a gem-induced trisection of genus $m_\alpha=2$. The associated G-trisection diagram is depicted in Figure \ref{fig:M4(trefoil,1)_trisection-diagram}.  Note that by considering blue and yellow (resp. blue and green) curves, a genus two Heegaard diagram of the boundary of one of the 4-dimensional handlebody of the trisection  of $M$ is obtained, while yellow and green curves give rise to a genus two Heegaard diagram of the Poincar\'e homology sphere.  }",2502.01757
theorem,Let $\langle \ka_\alpha \mid \alpha < \ka_0\rangle$ be an continuous increasing sequence of cardinals with the following properties: 	 			\item $\ka_{\alpha+1} = \ka_\alpha^+$ for all limit ordinals $\alpha$ 			\item $\ka_n$ is indestructibly supercompact for all $n<\w$ 			\item $\ka_{\alpha+2}$ is indestructibly supercompact for all $\w\leq \alpha < \ka_0$. 		  	Then there is a generic extension in which the tree property holds at $\aleph_{\w+\w+1}$ and at $\aleph_{\w_n+1}$ for all $0<n<\w$.,2502.01762
theorem,Let $\langle \ka_\alpha \mid \alpha < \ka_0\rangle$ be an continuous increasing sequence of cardinals with the following properties: 	 		\item $\ka_{\alpha+1} = \ka_\alpha^+$ for all limit ordinals $\alpha$ 		\item $\ka_n$ is indestructibly supercompact for all $n<\w$ 		\item $\ka_{\alpha+2}$ is indestructibly supercompact for all $\w\leq \alpha < \ka_0$. 	 	 	Then there is a generic extension in which the strong tree property holds at $\aleph_{\w+\w+1}$ and at $\aleph_{\w_n+1}$ for all $0<n<\w$.,2502.01762
proof,"Let $\dot{b}$ be a name for an cofinal branch, and let $z \in (\mc{P}_\ka(\la))^V$. Since $\dot{b}$ is forced to be cofinal, it must meet every level; that is, the empty condition forces that $\dot{b} \cap z \in L_z$, for all $z \in \mc{P}_\ka(\la)$. Since $L_z$ is in $V$, $\dot{b}\cap z$ is likewise forced to be in $V$. Since the list is thin, $|L_z| < \ka$, and so there are fewer than $\ka$ possibilities for $\dot{b}\cap z$.",2502.01762
proof,"Define the poset $\HH$ as follows: 	\[\HH\defeq \left(\prod_{n<\w} \Coll(\ka_n, <\ka_{n+1})\right) \times \left( \prod_{\w\leq\rho<\tau} \Coll(\ka_{\rho+1}, <\ka_{\rho+2})\right).\] Let $H$ be generic for $\HH$, and work in $V[H]$. Note that in $V[H]$, requirements (2) and (3) of Lemma \ref{lem:strtp} are satisfied. 	 	Let $I$ be the collection of all strictly increasing sequences $\langle \mu_i \mid i<\w\rangle$, where $\mu_i <\ka_0$ is a singular cardinal of cofinality $\mu_{i-1}^+$. For each sequence $s = \langle \mu_i \mid i<\w\rangle \in I$, define  	\[\LL_s \defeq \Coll(\w, \mu_0) \times \left(\prod_{n<\w} \Coll(\mu_{n}^+, \mu_{n+1})\right)\times \Coll\left((\sup_{n<\w}\mu_n)^+, <\ka_0\right).\] 	 	Given such a sequence $s$, for all $i$ with $0<i<\w$, define $\nu_i(s) \defeq \sup_{\rho < \mu_{i-1}^+} \ka_\rho$. Let $\nu_0(s) = \ka_0^{+\w}$. In the extension of $V[H]$ by $\LL_s$, $\nu_i(s)$ will become $\aleph_{\w+\w_i}$. Note that $\nu_i(s)$ only depends on the initial segment $\langle \nu_n \mid n<i\rangle$; when these values are fixed, as they will be throughout our argument, we will usually omit the parameter $s$. 	 	Our goal is to inductively build a sequence $s$ such that in the extension of $V[H]$ by a generic for $\LL_s$, the tree property will hold at every $\nu_{i}^+(s)$. We will start at $\mu_0$ and work our way up. 	 	 		There is $\mu^*_0 < \ka_0$ such that for all $s = \langle \mu_i \mid i<\w\rangle \in I$ with $\mu_0 = \mu^*_0$, the tree property holds at $\nu_0^+(s)$ in $V[H][\LL_s]$. 	 	 	For all $\mu_0 < \ka_0$, define 	\[\LL_0^*(\mu_0) = \Coll(\w, \mu_0) \times \Coll(\mu_0^+, <\ka_0) \times  \left(\prod_{\mu_0 < \alpha < \ka_0} \Coll(\alpha^+, <\ka_0)\right),\] 	where the final product has $\mu_0^{++}$-support.  	%Full support will collapse $\ka$; but that is fine, I think. Nonetheless, might as well do minimal damage. Anything above $\mu_0^+$ works fine. Can also switch to Easton collapses. 	Let $L_0^*(\mu_0)$ be generic for $\LL_0^*(\mu_0)$.   	 	Let us examine the properties of this poset. The first component, $\Coll(\w, \mu_0)$ has size $< \mu_0^+$, while the remainder of the forcing is $\mu_0^+$-closed. The full poset has size $<\ka_0^{++} = \ka_2$. Thus $\LL_0^*(\mu_0)$ satisfies the first condition for Lemma \ref{lem:strtp}. 	 	It follows that there is some $\mu^*_0 < \ka_0$ such that in $V[H][L^*_0(\mu^*_0)]$, the tree property holds at $\nu_0^+$. 	 	Now, let $s = \langle \mu_i \mid i < \w\rangle \in I$ be a sequence such that $\mu_0 = \mu^*_0$, and let $\dot{T}$ be a $\LL_s$-name for a $\nu_0^+$-tree with no branch. We claim that $\LL_0^*(\mu^*_0)$ projects to $\LL_s$. Clearly $\Coll(\w,\mu^*_0)$ projects to itself via the identity. By Lemma \ref{lem:colabsorption}, since $\prod_{n<\w} \Coll(\mu_{n}^+, \mu_{n+1})$ is $(\mu^*_0)^+$-closed and has size $<\ka_0$, it is absorbed by $\Coll((\mu^*_0)^+, <\ka_0)$. Furthermore, the quotient is isomorphic to $\Coll((\mu^*_0)^+, <\ka_0)$. Finally, since $\sup_{i<\w}(\mu_i)$ is in the interval $(\mu_0, \ka_0)$, $\prod_{\mu_0 < \alpha < \ka_0} \Coll(\alpha^+, <\ka_0)$ projects to $\Coll((\sup_{i<\w}\mu_i)^+, <\ka_0)$. The quotient of this projection is the full product, without whichever coordinate happened to correspond to the supremum of the $\mu_i$'s. 	 	Let $L_s$ be generic for $\LL_s$ over $V[H]$, and let $L^*(\mu_0^*)$ be a generic for $\LL_0^*(\mu_0^*)$ over $V[H]$ projecting to $L_s$. Let $T$ be the interpretation of $\dot{T}$ using the generic $L_s$. Since $T$ is in $V[H][L_s]$, and $\LL_0^*(\mu^*_0)$ projects to $\LL_s$, $T$ must be in $V[H][L_0^*(\mu^*_0)]$. Being a tree is upwards absolute, and $\nu_0^+$ is preserved by this quotient, so $T$ remains a $\nu_0^+$-tree in $V[H][L_0^*(\mu_0^*)]$. Since the tree property holds in $V[H][L_0^*(\mu^*_0)]$, there is a branch $b$ through $T$ in $V[H][L_0^*(\mu^*_0)]$. 	 	Note that the quotient of the projection from $\LL_0^*(\mu^*_0)$ to $\LL_s$ has size $<\nu_0^+$, since $\nu_0$ is a strong limit cardinal. By Corollary \ref{cor:smallbranch} this means that the quotient cannot add branches to $\nu_0^+$-trees, so $b$ must be in $V[H][L_s]$. 	 	We conclude that the tree property holds at $\nu_0^+$ in $V[H][L_s]$ for all sequences $s \in I$ starting with $\mu^*_0$.",2502.01762
proof,"For all $\mu_i$ with $\mu^*_i < \mu_i < \ka_0$, define 		\[\PP^*_k(\mu_k) \defeq \Coll(\w, \mu_0^*) \times \left(\prod_{n<k-1}\Coll((\mu^*_n)^+, \mu^*_{n+1})\right)\times \Coll((\mu^*_{k-1})^+, \mu_k)\] 		and 		\[\Q^*_k(\mu_k) \defeq \Coll(\mu_k^+, <\ka_0) \times \left(\prod_{\mu_k < \alpha < \ka_0} \Coll(\alpha^+, <\ka_0)\right),\] 		where the product has $\mu_k^{++}$-support. Finally, we define 		 		\[\LL^*_k(\mu_k) \defeq \PP^*_k(\mu_k) \times \Q^*_k(\mu_k).\] 		 		Note that $|\PP^*_{k}(\mu_k)| = \mu_k$, and $\Q^*_k(\mu_k)$ is $\mu_k^+$-closed; $|\LL^*_k(\mu_k)| < \ka_0^{++} = \ka_2$. Thus it meets the first hypothesis of Lemma \ref{lem:strtp}. 		 		We apply Lemma \ref{lem:strtp} to conclude that there is some $\mu^*_k$ such that in the extension of $V[H]$ by a generic $L$ for $\LL^*_k(\mu^*_k)$, the tree property holds at $\nu_k^+$. 		 		Now, let $s = \langle \mu_i \mid i<\w\rangle$ with $\mu_n = \mu_n^*$ for $n \leq k$. In $V[H]$, let $\dot{T}$ be a $\LL_s$-name for a $\nu_k^+$-tree. 		 		As before, we wish to show that $\LL^*_k(\mu^*_k)$ projects to $\LL_s$. Note that $\LL_s = \PP_s \times \Q_s$, where 		\[\PP_s = \Coll(\w, \mu_0) \times \left(\prod_{n<k} \Coll(\mu_{n}^+, \mu_{n+1})\right)\] 		and 		\[\Q_s = \left(\prod_{k\leq n<\w} \Coll(\mu_{n}^+, \mu_{i+1})\right)\times \Coll\left((\sup_{i<\w}\mu_i)^+, <\ka_0\right).\] 		 		Note that since $\mu^*_n = \mu_n$ for $n \leq k$, $\PP_s = \PP^*_k(\mu^*_k)$. 		 		By Lemma \ref{lem:colabsorption}, noting that $\prod_{k<n<\w} \Coll(\mu_{n}^+, \mu_{i+1})$ is $(\mu^*_k)^+$-closed and has size less than $\ka_0$, the first component of $\Q^*_k(\mu^*_k)$ projects onto the first component of $\Q_s$. The second component of $\Q_k^*(\mu^*_k)$ projects onto the second component of $\Q_s$ by restricting to the coordinate indexed by $\alpha = \sup_{i<\w}\mu_i$. 		 		Let $L_s$ be generic for $\LL_s$ over $V[H]$, and let $L_k^*(\mu_k^*)$ be a generic for $\LL^*_k(\mu^*_k)$ over $V[H]$ projecting to $L_s$. Let $T$ be the interpretation of $\dot{T}$ by this generic. Then $T \in V[H][L_s]$. Being a $\nu_k^+$-tree is upwards absolute, so $T$ remains a tree in $V[H][L^*_k(\mu^*_k)]$. As before, since the tree property holds in this model, there must be a cofinal branch through $T$ in $V[H][L^*_k(\mu^*_k)]$. The quotient has size $<\nu_k^+$, so it cannot have added the branch. We conclude that $T$ must have a cofinal branch in $V[H][L_s]$.",2502.01762
proof,"Define the poset $\HH$ as before: 	\[\HH\defeq \left(\prod_{n<\w} \Coll(\ka_n, <\ka_{n+1})\right) \times \left( \prod_{\w\leq\rho<\ka_0} \Coll(\ka_{\rho+1}, <\ka_{\rho+2})\right).\] Let $H$ be generic for $\HH$. As before, $V[H]$ meets the requirements given in Lemma \ref{lem:strtp}. 	 	Let $I$ be the collection of all strictly increasing sequences $\langle \mu_i \mid i<\w\rangle$, where $\mu_i <\ka_0$ is a singular cardinal of cofinality $\mu_{i-1}^+$. For each sequence $s = \langle \mu_i \mid i<\w\rangle \in I$, define  	\[\LL_s \defeq \Coll(\w, \mu_0) \times \left(\prod_{n<\w} \Coll(\mu_{n}^+, \mu_{n+1})\right)\times \Coll\left((\sup_{n<\w}\mu_n)^+, <\ka_0\right).\] 	 	Given such a sequence $s$, for all $i$ with $0<i<\w$, define $\nu_i(s) \defeq \sup_{\rho < \mu_{i-1}^+} \ka_\rho$. As before, we will freely omit the parameter $s$. Let $\nu_0 = \ka_0^{+\w}$. In the extension of $V[H]$ by $\LL_s$, $\nu_i$ will become $\aleph_{\w+\w_i}$. 	 	As before, we inductively build a sequence $s$ such that in the extension of $V[H]$ by a generic for $\LL_s$, the strong tree property will hold at every $\nu_{i}^+$. To do this, we will need to make use of an auxiliary collapse. 	 	 		There is $\mu^*_0 < \ka_0$ such that for all $s = \langle \mu_i \mid i<\w\rangle \in I$ with $\mu_0 = \mu^*_0$, the strong tree property holds at $\nu_0^+$ in $V[H][\LL_s]$. 	 	 		Fix $\la \geq \nu_0^+$. 		Let $K_\la$ be generic for $\Coll(\nu_0^+, \la)^{V[H]}$. In $V[H][K_\la]$, $\la$ is collapsed to an ordinal with cardinality and cofinality $\nu_0^+$. Note that $V[H][K_\la]$ still satisfies the second and third criteria of Lemma \ref{lem:strtp}. 		 		For all $\mu_0 < \ka_0$, working in $V[H]$, define 		\[\LL_0^*(\mu_0) = \Coll(\w, \mu_0) \times \Coll(\mu_0^+, <\ka_0) \times  \left(\prod_{\mu_0 < \alpha < \ka_0} \Coll(\alpha^+, <\ka_0)\right),\] 		where the final product has $\mu_0^{++}$-support.  		 		As before, the first component $\Coll(\w, \mu_0)$ has size $< \mu_0^+$, while the remainder of the forcing is $\mu_0^+$-closed. The full poset has size $<\ka_0^{++} = \ka_2$. Thus $\LL_0^*(\mu_0)$ satisfies the conditions for Lemma \ref{lem:strtp}, with $V[H][K_\la]$ as the ground model. Applying this lemma, we obtain $\mu^*_0(\la) < \ka_0$ such that in $V[H][K_\la][L^*_0(\mu^*_0(\la))]$, every thin $\nu_0^+$-list has a cofinal branch. 		 		Now, returning to $V[H]$ for a moment, let $s = \langle \mu_i \mid i < \w\rangle \in I$ be a sequence such that $\mu_0 = \mu^*_0(\la)$. Let $\dot{d}$ be a $\LL_s$-name for a thin $\mc{P}_{\nu_0^+}(\la)$-list with no branch. Let $L_s$ be generic for $\LL_s$. Note that $\Coll(\nu_0^+, \la)^{V[H]}$ is $\nu_0^+$-distributive in $V[H][L_s]$ by Easton's Lemma. In particular, $\mc{P}_{\nu_0^+}(\la)^{V[H][L_s]} = \mc{P}_{\nu_0^+}(\la)^{V[H][L_s][K_\la]}$. 		 		Move to $V[H][L_s][K_\la]$, and let $d$ be the interpretation of $\dot{d}$. By assumption $d$ is a thin $\mc{P}_{\nu_0^+}(\la)$-list in $V[H][L_s]$; it remains a thin $\mc{P}_{\nu_0^+}(\la)$-list in $V[H][L_s][K_\la]$, since $\mc{P}_{\nu_0^+}(\la)$ is the same in both models. In $V[H][L_s][K_\la]$, since $|\la| = \nu_0^+$, there is an order isomorphism from $\mc{P}_{\nu_0^+}(\la)$ to $\mc{P}_{\nu_0^+}(\nu_0^+)$. Thus there is a thin $\mc{P}_{\nu_0^+}(\nu_0^+)$-list $d'$ that is isomorphic to $d$. 		 		By Fact\ref{fact:ka-lists2}, we can build a thin $\ka$-list $d^*$ such that $d'$ has a cofinal branch if $d^*$ does. Since $d'$ is isomorphic to $d$, we conclude that if $d^*$ has a cofinal branch, so does $d$. 		 		Our goal now is to bring $d^*$ up to $V[H][K_\la][L^*_0(\mu^*_0(\la))]$, where we can obtain a branch for this list. We claim that $\LL_0^*(\mu^*_0(\la))$ projects to $\LL_s$. Clearly $\Coll(\w,\mu^*_0)$ projects to itself via the identity. By Lemma \ref{lem:colabsorption}, since $\prod_{n<\w} \Coll(\mu_{n}^+, \mu_{n+1})$ is $(\mu^*_0(\la))^+$-closed and has size $<\ka_0$, it is absorbed by $\Coll((\mu^*_0(\la))^+, <\ka_0)$, with a quotient isomorphic to $\Coll((\mu^*_0(\la))^+, <\ka_0)$. Finally, since $\sup_{i<\w}(\mu_i)$ is in the interval $(\mu^*_0(\la), \ka_0)$, the final product $\prod_{\mu^*_0(\la) < \alpha < \ka_0} \Coll(\alpha^+, <\ka_0)$ projects to $\Coll((\sup_{i<\w}\mu_i)^+, <\ka_0)$ via restricting to the appropriate coordinate of the product. The quotient of this projection is the product with that coordinate removed. 		 		Since the list $d^*$ is in $V[H][L_s]$, and $\LL_0^*(\mu^*_0(\la))$ projects to $\LL_s$, $d^*$ must be in $V[H][L_0^*(\mu^*_0(\la))]$. Since the levels of $d^*$ are indexed by ordinals, and $\nu^+$ is preserved by this quotient, $d^*$ remains a thin $\nu_0^+$-list in this model. Every thin $\nu_0^+$-list in $V[H][K_\la][L_0^*(\mu_0^*(\la))]$ has cofinal branch, so we obtain a branch $b^*$ through $d^*$ in $V[H][L_0^*(\mu^*_0(\la))]$. 		 		As before, the quotient of the projection from $\LL_0^*(\mu^*_0(\la))$ to $\LL_s$ has size $<\nu_0^+$. By Corollary \ref{cor:smallbranch} this means that the quotient has the $\nu_0^+$-approximation property over $V[H][L_s][K_\la]$, and thus cannot add cofinal branches through thin $\nu^+$-lists. We conclude that $b^*$ must be in $V[H][L_s][K_\la]$. Since $d^*$ has a cofinal branch in $V[H][L_s][K_\la]$, $d$ must also have a cofinal branch $b$ in that model. 		 		Since $\Coll(\nu_0^+, \la)^{V[H]}$ is $\nu^+$-closed in $V[H]$, and $\LL_s$ has size $<\nu_0^+$, by Lemma \ref{lem:cc+closed=approx}, $\Coll(\nu_0^+, \la)^{V[H]}$ has the thin $\nu_0^+$-approximation property over $V[H][L_s]$. It follows that $\Coll(\nu_0^+, \la)^{V[H]}$ could not have added $b$, so $b \in V[H][L_s]$. We conclude that for all sequences $s \in I$ starting with $\mu^*_0(\la)$, in $V[H][L_s]$ every thin $\mc{P}_{\nu_0^+}(\la)$-list has a cofinal branch. 		 		Since there are only $\ka_0$ options for each $\mu^*_0(\la)$, there must be a fixed $\mu_0^*$ such that for unboundedly many $\la \geq \ka_0$, $\mu_0^*(\la) = \mu_0^*$.  		By Fact \ref{fact:tpgoesdown}, to check the strong tree property we only need to verify that it holds for unboundedly many $\la$. So for all sequences $s\in I$ starting with $\mu_0^*$, the strong tree property holds at $\nu_0^+$ in $V[H][L_s]$.",2502.01762
proof,"Fix $\la \geq \nu_k^+$. Let $K_\la$ be generic for $\Coll(\nu_k, \la)^{V[H]}$. Note that in $V[H][K_\la]$, $\la$ is collapsed to an ordinal with cardinality and cofinality $\nu_k^+$. 		 		For all $\mu_k$ with $\mu^*_{k-1} < \mu_k < \ka_0$, in $V[H]$ define 		\[\PP^*_k(\mu_k) \defeq \Coll(\w, \mu_0^*) \times \left(\prod_{n<k-1}\Coll((\mu^*_n)^+, \mu^*_{n+1})\right)\times \Coll((\mu^*_{k-1})^+, \mu_k)\] 		and 		\[\Q^*_k(\mu_k) \defeq \Coll(\mu_k^+, <\ka_0) \times \left(\prod_{\mu_k < \alpha < \ka_0} \Coll(\alpha^+, <\ka_0)\right),\] 		where the product has $\mu_k^{++}$-support. Define 		 		\[\LL^*_k(\mu_k) \defeq \PP^*_k(\mu_k) \times \Q^*_k(\mu_k).\] 		 		Note that $|\PP^*_{k}(\mu_k)| = \mu_k$, $\Q^*_k(\mu_k)$ is $\mu_k^+$-closed, and $|\LL^*_k(\mu_k)| < \ka_0^{++} = \ka_2$. So $\LL^*_k(\mu_k)$ meets the hypotheses of Lemma \ref{lem:strtp}, applied in $V[H][K_\la]$. 		 		We apply Lemma \ref{lem:strtp} to conclude that there is some $\mu^*_k(\la)$ such that in the extension of $V[H][K_\la]$ by a generic $L$ for $\LL^*_k(\mu^*_k(\la))$, every thin $\nu_k^+$-list has a cofinal branch. 		 		In $V[H]$, let $s = \langle \mu_i \mid i<\w\rangle$ with $\mu_n = \mu_n^*$ for $n < k$ and $\mu_k = \mu_k^*(\la)$, and let $\dot{d}$ be a $\LL_s$-name for a thin $\mc{P}_{\nu_k^+}(\la)$-list. Let $L_s$ be generic for $\LL_s$. Once again, $\mc{P}_{\nu_k^+}(\la)^{V[H][K_\la]}=\mc{P}_{\nu_k^+}(\la)^{V[H]}$, and $\la$ is collapsed to $\nu_k^+$. As before, applying Fact \ref{fact:ka-lists2}, we obtain a thin $\nu_k^+$-list $d^*$ that has a cofinal branch if and only if $d$ has a cofinal branch. 		 		Working in $V[H][K_\la]$, we wish to show that $\LL^*_k(\mu^*_k(\la))$ projects to $\LL_s$. Note that $\LL_s = \PP_s \times \Q_s$, where 		\[\PP_s = \Coll(\w, \mu_0) \times \left(\prod_{n<k} \Coll(\mu_{n}^+, \mu_{n+1})\right)\] 		and 		\[\Q_s = \left(\prod_{k<n<\w} \Coll(\mu_{n}^+, \mu_{i+1})\right)\times \Coll\left((\sup_{i<\w}\mu_i)^+, <\ka_0\right).\] 		 		Note that since $\mu^*_n = \mu_n$ for $n < k$ and $\mu^*_k(\la) = \mu_k$, $\PP_{s} = \PP^*_k(\mu^*_k)$. 		By Lemma \ref{lem:colabsorption}, noting that $\prod_{k<n<\w} \Coll(\mu_{n}^+, \mu_{i+1})$ is $(\mu^*_k(\la))^+$-closed and has size less than $\ka_0$, the first component of $\Q^*_k(\mu^*_k(\la))$ projects onto the first component of $\Q_s$. The second component of $\Q_k^*(\mu^*_k(\la))$ projects onto the second component of $\Q_s$ by restricting to the coordinate indexed by $\alpha = \sup_{i<\w}\mu_i$. 		 		Let $L_k^*(\mu_k^*)$ be a generic for $\LL_k^*(\mu_k^*)$ projecting to $L_s$. Since the levels of $d^*$ are indexed by ordinals and $\nu^+_k$ is preserved, $d^*$ remains a thin $\nu_k^+$-tree in $V[H][L^*_k(\mu^*_k(\la))]$. Every thin $\nu_k^+$-list has a cofinal branch in this model, so there must be a cofinal branch through $d^*$ in $V[H][L^*_k(\mu_k(\la))]$. Since the quotient has size $<\nu_k^+$, it cannot have added the branch by Lemma \ref{lem:approxprop}, so $d^*$ must have a cofinal branch in $V[H][K_\la][L_s]$. 		 		Since we have found such a cofinal branch for $d^*$, we conclude that $d$ has a cofinal branch $b$ in $V[H][K_\la][L_s]$. Since $\LL_s$ has size less than $\nu$, and $\Coll(\nu^+, \la)^{V[H]}$ is $\nu^+$-closed in $V[H]$, applying Lemma \ref{lem:cc+closed=approx} we conclude that $\Coll(\nu^+, \la)^{V[H]}$ could not have added a branch through $d$ over $V[H][L_s]$. 		 		It follows that for any sequence $s\in I$ starting with $\langle \mu^*_n \mid n < k\rangle \cat \mu^*_k(\la)$, any thin $\mc{P}_{\nu_k^+(s)}(\la)$-list in $V[H][L_s]$ has a cofinal branch. 		 		Since there are at most $\ka_0$ many options for $\mu^*_k(\la)$, there is a fixed $\mu^*_k$ such that for unboundedly many $\la$, $\mu^*_k(\la) = \mu^*_k$. We conclude (using Fact \ref{fact:tpgoesdown}) that for any sequence $s\in I$ starting with with $\langle \mu^*_n \mid n < k\rangle \cat \mu^*_k(\la)$, the strong tree property holds at $\nu_k^+(s)$ in $V[H][L_s]$.",2502.01762
proof,"Our construction is as before. 	 	Define the poset $\HH$ as follows: 	\[\HH\defeq \left(\prod_{n<\w} \Coll(\ka_n, <\ka_{n+1})\right) \times \left( \prod_{\w\leq\rho<\ka_0} \Coll(\ka_{\rho+1}, <\ka_{\rho+2})\right).\] 	 	Let $I$ be the collection of all continuous strictly increasing sequences $\langle \mu_{\alpha} \mid \alpha < \tau\rangle$. For all sequences $s = \langle \mu_{\alpha} \mid \alpha < \tau\rangle\in I$, define:  	\[\LL_s \defeq \Coll(\w, \mu_0) \times \left( \prod_{\alpha < \tau } \Coll(\mu_{\alpha}^+, \mu_{\alpha+1})\right) \times \Coll((\sup_{\alpha < \tau} \mu_{\alpha+1})^+,<\ka_0).\] 	 	Note that after forcing with $\LL_s$, $\mu_\alpha^+$ will become $\aleph_{\w_\alpha+1}$. 	We inductively select $\mu^*_\alpha$ such that for any sequence $s\in I$ beginning with $\langle \mu^*_\beta \mid \beta \leq \alpha\rangle$, the strong tree property will hold at $\aleph_{\tau+\alpha+1}$ in $V[H][L_s]$. 	The base case is more or less identical to Lemma \ref{lem:basestp}, using  	\[\LL^*_0(\mu_0) = \Coll(\w,\mu_0)\times \Coll(\mu_0^+, <\ka_0) \times \left(\prod_{\mu_0<\beta < \ka_0} \Coll(\beta^+, <\ka_0)\right).\] 	At limit stages $\gamma$, since the sequence must be continuous, we set $\mu^*_\gamma = \sup_{\alpha < \gamma} \mu^*_{\alpha}$. 	At successor stages, we follow the argument of Lemma \ref{lem:indstp}, using 	\[\PP^*_{\alpha+1}(\mu_{\alpha+1}) \defeq \Coll(\w, \mu_0^*)\times \left(\prod_{\beta < \alpha} \Coll((\mu^*_{\beta})^+, \mu^*_{\beta+1})\right)\times\Coll(\mu^*_{\alpha}, \mu_{\alpha+1}),\] 	\[\Q^*_{\alpha+1}(\mu_{\alpha+1}) \defeq \Coll(\mu_{\alpha+1}^+, <\ka_0) \times \left(\prod_{\mu_{\alpha+1} < \beta < \ka_0}\Coll(\beta^+, <\ka_0)\right),\] 	and 	\[\LL_{\alpha+1}^*(\mu_{\alpha+1})\defeq \PP^*_{\alpha+1}(\mu_{\alpha+1}) \times \Q^*_{\alpha+1}(\mu_{\alpha+1}).\] 	When this induction concludes, we will have a sequence $s\in I$ such that in $V[H][L_s]$, the strong tree property holds at $\aleph_{\tau+\w_{\alpha}+1}$ for all successor ordinals $\alpha < \tau$.",2502.01762
lemma,"Let $\tau$ be a regular cardinal. Let $\langle \ka_\rho \mid \rho < \tau\rangle$ be a continuous increasing sequence of regular cardinals above $\tau$, with supremum $\nu$. Let $I \subseteq \ka_0$, and fix $\rho' < \tau$. For each $\mu \in I$, let $\LL_\mu$ be a forcing poset of size $\leq \ka_{\rho'}$. Suppose the following hold: 	 		\item For each $\mu \in I$, $\LL_\mu$ is the product of forcings $\PP_\mu$ and $\Q_\mu$, where $|\PP_\mu|< \mu^+$ and $\Q_\mu$ is $\mu^+$-closed. 		\item $\ka_0$ is $\nu^+$-supercompact, with a normal measure $U_0$ on $\mc{P}_{\ka_0}(\nu^+)$ and a corresponding embedding $i$ such that $\nu \in i(I)$. 		\item For all ordinals $\rho < \tau$ there is a generic $\nu^+$-supercompactness embedding $j_{\rho+2}$ with domain $V$ and critical point $\ka_{\rho+2}$, added by a poset $\FF$ whose full support power $\FF^{\ka_\rho}$ is $<\ka_\rho$-distributive in $V$. 	 	Then there exists $\mu \in I$ such that in the extension of $V$ by $\LL_\mu$, every thin $\nu^+$-list has a cofinal branch.",2502.01762
lemma,"Let $d$ be a thin $\mc{P}_\ka(\la)$ list in $V$, and let $\mathbb{P}$ be a notion of forcing over $V$. Suppose $\dot{b}$ is a $\PP$-name for a cofinal branch through this list. Then $\dot{b}$ is thinly $\ka$-approximated by $\PP$ over $V$.",2502.01762
lemma,\cite[Lemma 2.4]{UngerAtrees} 	Let $\ka$ be a regular cardinal. Suppose that $\PP$ is a forcing poset such that $\PP\times \PP$ is $\ka$-cc. Then $\PP$ has the $\ka$-approximation property.,2502.01762
lemma,"\cite[Lemma 2.20]{adkisson:ITP} 	Suppose $\nu$ is a singular strong limit cardinal with cofinality $\tau$. Let $\Q$ be a $\mu^+$-closed forcing over a model $V$ for some $\mu<\nu$ with $\tau \leq \mu$, and let $\PP\in V$ be a forcing poset with $|\PP|\leq \mu$. Then $\Q$ has the $\nu^+$-approximation property in the generic extension of $V$ by $\PP$.",2502.01762
lemma,"\cite[Theorem 14.3]{cummings:handbook} 	Let $\ka$ be an inaccessible cardinal, and let $\delta < \ka$ be regular. Let $\PP$ be a $\delta$-closed forcing poset with $|\PP| < \ka$. Then there is a forcing projection from $\Coll(\delta, <\ka)$ to $\PP$ whose quotient is $\Coll(\delta, <\ka)$.",2502.01762
lemma,"There is $\mu^*_0 < \ka_0$ such that for all $s = \langle \mu_i \mid i<\w\rangle \in I$ with $\mu_0 = \mu^*_0$, the tree property holds at $\nu_0^+(s)$ in $V[H][\LL_s]$.",2502.01762
lemma,"Fix $\langle \mu^*_i \mid i<k\rangle$. There exists $\mu_k^*$ such that for all sequences $s = \langle \mu_i \mid i<\w\rangle$ with $\mu_i = \mu_i^*$ for $i \leq k$, the tree property holds at $\nu_k^+(s)$ in $V[H][L_s]$.",2502.01762
lemma,"There is $\mu^*_0 < \ka_0$ such that for all $s = \langle \mu_i \mid i<\w\rangle \in I$ with $\mu_0 = \mu^*_0$, the strong tree property holds at $\nu_0^+$ in $V[H][\LL_s]$.",2502.01762
lemma,"Fix $\langle \mu^*_i \mid i<k\rangle$. There exists $\mu_k^*$ such that for all sequences $s = \langle \mu_i \mid i<\w\rangle$ with $\mu_i = \mu_i^*$ for $i \leq k$, the strong tree property holds at $\nu_k^+$ in $V[H][L_s]$.",2502.01762
definition,"[Subspace Distance {\citep{stewart1990matrix}}]     Let $\bG, \Gstar \in \R^{k \times \dx}$ be matrices whose rows are orthonormal.     Let $\Gperp \in \R^{\dx \times \dx}$ be the projection matrix onto $\rowsp(\Gstar)^\perp$. Define the distance between the subspaces spanned by the rows of $\bG$ and $\Gstar$ by              \dist(\bG, \Gstar) &\triangleq \norm{\bG \Gperp}_{\rm op}",2502.01763
lemma,"Given $\bG$, define the least-squares estimator:              \Fls &\triangleq \argmin_{\widehat{\bF}} \frac{1}{2}\hatEx\big[\norm{\bfy - \widehat{\bF} \underbrace{\sigma(\bG \bfx)}_{\bfz}}^2\big]= \bY^\top \bZ \, (\bZ^\top \bZ)^{-1}          Given $\eta_\sbF \in (0, 1]$, then the $\bF$-update in \eqref{eq:KFAC_update} can be re-written as an EMA of $\Fls$; i.e., $$\bF_+ = (1 - \eta_\sbF) \bF + \eta_\sbF \Fls.$$",2502.01763
proof,"Because $v$ is odd and periodic, for any $k \in \mathbb{Z}$, $x \in [0,\ell]$ 	 		\int_{x-\ell k}^{x + \ell k} v(y)dy = 0. 	 	Furthermore, by odd periodicity we have, for any $t \in [0,\ell],$ 	 		\int_{x-2\ell k -t}^{x + 2\ell k + t} v(y)dy = \int_{x - t}^{x + t }v(y)dy. 	 	and 	 		\int_{x-(2k + 1)\ell  -t}^{x + (2k+1)\ell  + t} v(y)dy = -\int_{x - t}^{x + t }v(y)dy.",2502.01783
proof,"By odd periodicity in time (Lemma \ref{lem:I-periodic}), 	 		\sup_{t>0} \sup_{x \in [0,\ell]}|I_v(t,x)| = \sup_{t \in [0,\ell]} \sup_{x \in [0,\ell]} |I_v(t,x)|. 	 	By H\""older's inequality, for any $t \in [0,\ell]$ and $x \in [0,\ell]$, 	 		|I_v(t,x)| &= \left|\frac{1}{2}\int_{x - t}^{x + t} v(y)dy \right|\nonumber \leq \frac{\sqrt{ 2t}}{2} |v|_{L^2[x-t,x+t]} \nonumber\leq \frac{\sqrt{2\ell}}{2} |v|_{L^2[-\ell,\ell]} \nonumber \leq \sqrt{\ell} |v|_{H} .",2502.01783
proof,"[Proof of Theorem \ref{thm:Linftydecay}] 	Let $q = e^{\frac{\alpha t}{2}}u$ so that, in view of \eqref{eq:q-mild}, \eqref{eq:Iv_definition}, $q$ satisfies 	 		q(t,x) = &\frac{1}{2}\left(q^o(0,x - t) + q^o(0,x+t)\right) + \frac{1}{2}I_{(\partial_tq)^o(0)}(t,x)\nonumber+ \frac{\alpha^2}{4}\int_0^t I_{q^o(s)}(t-s,x)ds,\;\;(x,t)\in [0,\ell]\times(0,\infty). 	 	By definition of $C$ and $C^{-1}$ norms the first two terms satisfy 	 	\left|	\frac{1}{2}\left(q^o(0,x - t) + q^o(0,x+t)\right) \right|\leq |q(0)|_\infty, 	 	 	\left|	\frac{1}{2}I_{(\partial_tq)^o(0)}(t,x)\right| \leq |\partial_tq(0)|_{C^{-1}}. 	 	By Lemma \ref{lem:integral-bound}, 	 		\left| \int_0^t I_{q^o(s)}(t-s,x)ds\right| \leq \sqrt{2 \ell}\int_0^t |q(s)|_{H}ds. 	 	Using the definition of $q$ and Proposition \ref{prop:L2-decay} it follows that  	 	    \left| \int_0^t I_{q^o(s)}(t-s,x)ds\right| &\leq \sqrt{2 \ell}\int_0^t |u(s)|_{H}e^{\frac{\alpha s}{2}}ds\nonumber\\&        \leq \sqrt{2 \ell}\int_0^t M|(u(0), \partial_tu(0))|_{\h}e^{\left(\frac{\alpha }{2} - \theta \right)s}ds.\nonumber 		 	These estimates prove that 	 	\sup_{x \in [0,\ell]} |q(t,x)| \leq |Q(0)|_\mathcal{E} + \frac{M \alpha^2 \sqrt{2 \ell}}{4 \left(\frac{\alpha}{2} - \theta \right)} |(u(0), \partial_tu(0))|_{\h} e^{\left(\frac{\alpha}{2} - \theta\right)t} 	 	where $Q(0) = (q(0),\partial_tq(0)) = (u(0), \alpha u(0)/2  + \partial_tu(0)).$ 	Finally we multiply by $e^{-\frac{\alpha t}{2}}$ to conclude that for any $t>0$, 	 		 \sup_{x \in [0,\ell]} |u(t,x)| &\leq e^{-\frac{\alpha t}{2}} |Q(0)|_{\e} + \frac{M \alpha^2 \sqrt{2 \ell}}{4\left(\frac{\alpha}{2} - \theta \right)}e^{-\theta t}|(u(0), \partial_tu(0))|_\h \nonumber \\ 		&\leq \tilde{M} e^{-\theta t} |(u(0), \partial_tu(0))|_{\e}. 	 	A similar estimate is true for the velocity component. Indeed,         \partial_tu=\Pi_2u=\partial_t(e^{-\frac{\alpha t}{2}}q)=-\frac{\alpha }{2}e^{-\frac{\alpha t}{2}}q+e^{-\frac{\alpha t}{2}}\partial_tq.        \noindent From \eqref{eq:q-mild} we have   	\partial_tq(t,x)=  \Pi_2 S_0(t)  q(0) \\ \partial_tq(0)  + \frac{\alpha^2}{8}\int_0^t\Pi_2S_0(t-s) 0 \\ q(s) ds.  From \eqref{equation:D'Alembert2} and for each $t>0$       \widehat{\Pi_2S_0}(t) q(0) \\ \partial_tq(0) (x)=\frac{1}{2}\big(q^o(0, x-t)-q^o(0, x+t)\big)-\frac{1}{2}\big(\widehat{(\partial_t q)^o }(0, x+t)+\widehat{(\partial_t q)^o }(0, x-t)\big),  (recall here that $\hat{\cdot}, \cdot^o $ denote anti-differentiation and odd periodic extension respectively)  hence   \bigg|\Pi_2S_0(t) q(0) \\ \partial_tq(0) \bigg|_{C^{-1}}=\bigg|\widehat{\Pi_2S_0}(t) q(0) \\ \partial_tq(0) \bigg|_{\infty}\leq |q(0)|_{\infty}+|\partial_tq(0)|_{C^{-1}}.  Turning to the convolution term,  -2\widehat{\Pi_2S_0}(t-s) 0 \\ q(s) (x)=\int_0^{x+(t-s)}q^o(s,y)dy+\int_0^{x-(t-s)}q^o(s,y)dy  From the latter, along with  the odd periodicity of $q^0$ and Proposition \ref{prop:L2-decay} we obtain   $$ \bigg|\Pi_2S_0(t-s) 0 \\ q(s) \bigg|_{C^{-1}}\leq  x\wedge (t-s) |q^o(s)|_\infty\leq \ell e^{(\frac{\alpha}{2}-\theta) s}|Q(0)|_\e.$$ Combining these estimates with \eqref{eq:uvelocity}, \eqref{eq:qvelocity} we deduce $$ |\partial_t u(t)|_{C^{-1}}\leq C e^{-\theta t}|(u(0),\partial_tu(0))|_\e.   $$ The proof is complete.",2502.01783
proof,"\item This follows once again by \cite[Chapter IV, Proposition 1.2]{temam2012infinite} by setting $A=\partial_x+b'(x^*)$ and $\lambda_1=\lambda_b.$     \item Apart from the presence of an additional linear term, the proof is nearly identical to that of Theorem \ref{thm:Linftydecay} above. In particular, we perform the transformation $q := e^{\frac{\alpha t}{2}}u,$ where $\partial_t^2u+\alpha\partial_tu=\partial_x^2u+b'(x^*)u.$ Then $q$ satisfies the linear wave equation         	\partial_t^2q = \partial_x^2 + \bigg(\frac{\alpha^2}{4}+b'(x^*)\bigg)q.  Writing the latter in mild form and using the $L^2-$bound from part (1), as we did in Theorem \ref{thm:Linftydecay}, yields the desired estimate for a constant $M$ that depends on $|b'(x^*)|_{\infty}.$",2502.01783
proof,"Let $R>0$ and consider the ansatz            Z^0_z(t)=\sum_{n=0}^{\infty}R^nZ_n(t),        where $Z^0_z=(u^0_z,\partial_tu^0_z)$ is the solution with initial data $z\in B_\e(z^*,R)$ and $\{Z_n\}_{n\in\N}$ a sequence of functions in $C([0,\infty);\e)$ to be determined. From the latter, in combination with the mild formulation, we obtain          \sum_{n=0}^{\infty}R^nZ_n(t)=S_\alpha(t)z^*+RS_\alpha(t)z_0+\int_{0}^{t}S_\alpha(t-s)\bigg(0, b\bigg(\sum_{n=0}^{\infty}R^n\Pi_1Z_n(s)\bigg)\bigg)ds,        where we wrote $z=z^*+Rz_0,$ for some $z_0\in B_\e(0,1).$ From a (pointwise for every $x\in(0,\ell)$) Taylor expansion of $b$ around $\Pi_1Z_0(s)$               b\bigg(\sum_{n=0}^{\infty}R^n\Pi_1Z_n(s)\bigg)&=\sum_{k=0}^{\infty}\frac{b^{(k)}(\Pi_1Z_0(s))}{k!}\bigg(\sum_{n=1}^{\infty}R^n\Pi_1Z_n(s)\bigg)^k\\&     =b(\Pi_1Z_0(s))+\sum_{k=1}^{\infty}\frac{b^{(k)}(\Pi_1Z_0(s))}{k!}\sum_{n=k}^{\infty}R^n\sum_{i_1+\dots+i_k=n}\Pi_1Z_{i_1}(s)\dots \Pi_1Z_{i_k}(s)\\&    =b(\Pi_1Z_0(s))+\sum_{n=1}^{\infty}R^n\sum_{k=1}^{n}\frac{b^{(k)}(\Pi_1Z_0(s))}{k!}\sum_{i_1+\dots+i_k=n}\Pi_1Z_{i_1}(s)\dots \Pi_1Z_{i_k}(s),       where the change in the order of summation on the last line will be justified from the absolute convergence of the series. The last two displays allow to determine the functions $Z_n$ by identifying terms of the same order in $R.$ Indeed, from the zeroth order terms we see that  $$Z_0(s)=S_\alpha(t)z^*+\int_0^tS_\alpha(t-s)\bigg(0, b(\Pi_1Z_0(s))\bigg)ds.    $$ Since $z^*$ is an equilibrium, it follows that $Z_0(s)=z^*$ for all $s.$ From the first order terms it follows that                Z_1(s)=S_\alpha(t)z_0+\int_{0}^{t}S(t-s)\bigg(0, b'(\Pi_1Z_0(s))\Pi_1Z_1(s)\bigg)ds,       i.e. $Z_1(s)=\bar{S}_\alpha(s) z_0,$ where $\bar{S}_\alpha$ is the semigroup generated by the linearisation of  \eqref{eq:deterministicnonlinearwave} around $x^*.$ In view of Lemma \ref{lem:linearizedsemigroup}(2), we have the estimate $$|Z_1(s)|_\e\leq Ce^{-\theta s}|z_0|_\e\leq Me^{-\theta s}.$$ Turning to $n-$th order terms for $n\geq 1$ we have      Z_n(t)=\int_{0}^{t}\bar{S}_\alpha(t-s)\bigg(0, \sum_{k=2}^{N}\frac{b^{(k)}(x^*)}{k!}\sum_{i_1+\dots+i_k=n}\Pi_1Z_{i_1}(s)\dots \Pi_1Z_{i_k}(s)\bigg) ds,  where we used Assumption \ref{Assumption:b} which implies that all derivatives $b^{(k)}$ of order $k>N$ vanish. With $A_1:=M,$ we assume that for each $k=1,\dots,n-1$ there is a constant $A_k>0$ such that      |Z_k(s)|_\e\leq A_ke^{-\theta s}.   Notice that $Z_n$ satisfies a non-homogeneous linear equation with a source term that is independent of $Z_k, k\geq n. $ From the induction assumption, and with $\gamma$ from Assumption \ref{Assumption:b}, we thus have                  |Z_n(t)|_{\e}&\leq A_1\int_{0}^{t} e^{-\theta (t-s)}\sum_{k=2}^{\gamma}\frac{|b^{(k)}(x^*)|_{\infty}}{k!}\sum_{i_1+\dots+i_k=n}|\Pi_1Z_{i_1}(s)\dots \Pi_1Z_{i_k}(s)|_{C^{-1}} ds\\&\leq          \ell A_1 \sum_{k=2}^{\gamma}\frac{|b^{(k)}(x^*)|_{\infty}}{k!}\int_{0}^{t}e^{-\theta (t-s)}\sum_{i_1+\dots+i_k=n}|\Pi_1Z_{i_1}(s)\dots \Pi_1Z_{i_k}(s)|_{\infty} ds\\&         \leq \ell A_1 \sum_{k=2}^{\gamma}\sum_{i_1+\dots+i_k=n}A_{i_1}\dots A_{i_k}\frac{|b^{(k)}(x^*)|_{\infty}}{k!}\int_{0}^{t}e^{-\theta (t-s)}e^{-k\theta s} ds\\&         \leq \ell A_1 e^{-\theta t}\sum_{k=2}^{\gamma}\sum_{i_1+\dots+i_k=n}A_{i_1}\dots A_{i_k}\frac{|b^{(k)}(x^*)|_{L^\infty}}{k!(k-1)}.       \noindent Thus, one can take            A_{n}:=\ell A_1 \sum_{k=2}^{\gamma}R_k\sum_{i_1+\dots+i_k=n}A_{i_1}\dots A_{i_k},\;\; R_k:=\frac{|b^{(k)}(x^*)|_{\infty}}{k!(k-1)}.  We claim that, in order to obtain \eqref{eq:Nonlinearstabilitybound}, it remains to identify a lower bound $\rho_0>0$ for the radius of convergence of the series  $$  F(\zeta)=\sum_{n=1}^{\infty} A_n \zeta^n.$$ Indeed, from \eqref{eq:ansatz}                |Z^0_z(t)-z^*|_\e=\bigg|\sum_{n=0}^\infty R^nZ_n(t)-Z_0(t)\bigg|_\e\leq \sum_{n=1}^\infty R^n|Z_n(t)|_\e\leq e^{-\theta t} \sum_{n=1}^\infty R^nA_n        i.e. the desired estimate holds provided that $R<\rho_0.$ To find the latter, note that $F$ is invertible around $0$ (since $F'(0)=A_1\neq 0$) and from the recursive relations \eqref{eq:Recursion} its inverse is given by $$F^{-1}(\zeta)=\frac{\zeta}{A_1}-\ell\sum_{k=2}^{\gamma} R_k\zeta^k.$$ The radius of convergence of $F$ can then be determined by the largest interval  around $0$ where $(F^{-1})'$ is non-zero. Since $F^{-1}$ is an $\gamma-$th degree polynomial with a root at $0$ there must exist $\rho_0>0$ such that $F^{-1}$ does not change monotonicity in $(-\rho_0, \rho_0).$ The proof is complete.",2502.01783
proof,"Let $(t,z)\longmapsto\mathcal{Z}(t,z):=Z^0_z(t)$ denote the induced flow map. With $\rho_0$ as in Theorem \ref{thm:domainofattraction}, let      D:=\bigcup_{t\geq 0} \mathcal{Z}\bigg(t,B_\e(z^*, \rho_0)\bigg).    From \eqref{eq:Nonlinearstabilitybound} it is straightforward to deduce that $D$ is bounded and satisfies (1). Indeed,  $$\sup_{z\in D}|z|_\e=\sup_{t\geq 0, z\in B_\e(z^*,\rho_0)}|Z^0_z(t)|_\e\leq C_{\rho_0}<\infty.$$ Moreover, from the flow property and definition of $D$ it follows that for each $z\in D$ there exist $z'\in B_\e(z^*, \rho_0), t'\geq 0$ such that for each $t\geq 0,$ $$Z^0_z(t)=Z^0_{Z^0_{z'}(t')}(t)=Z^0_{z'}(t+t')\in\mathcal{Z}( t+t', B_\e(z^*, \rho_0))\subset D.$$ It remains to show that $D$ is open. To this end, we have from time-reversibility and continuity of the wave flow that $\mathcal{Z}\big(t,B_\e(z^*, \rho_0)\big)= \mathcal{Z}^{-1}\big((-t),B_\e(z^*, \rho_0)\big),$ where, for each $z\in B_\e(z^*, \rho_0), $ $u=\Pi_1Z^0_z(-t)$ solves  $$\partial_t^2u-\alpha\partial_tu=\partial^2_xu+b(u), u(0)=\Pi_1z.     $$ As in the proof of Theorem \ref{thm:Linftydecay}, we let $q(t):=e^{-\alpha t/2}u(t)$ and note that $\partial^2_tq=\partial^2_xq-\tfrac{\alpha^2}{4}q+e^{-\alpha t/2}b(e^{\alpha t/2}q).$ Letting $\{z_n\}\subset\e$ such that $z_n\rightarrow z\in\e$ and $T\geq t$ we set $R=\sup_{t\in[0,T]}|u_z(t)|_{\e}\vee \sup_{n\in\N, t\in[0,T]}|u_{z_n}(t)|_{\e}.$ Using the local Lipschitz continuity of $b$ on $B_{\e}(0,R),$  along with Gr\""onwall's inequality, we can then show   $$  |Z^0_{z_n}(-t)-Z^0_{z}(-t)|_{\e}\leq e^{CT}|z_n-z|_{\e}\rightarrow 0   $$ as $n\to\infty.$ Hence, for each $t \geq 0$ the time-reversed flow map  $$ \e\ni z\longmapsto Z^0_{z}(-t)\in\e      $$ is continuous. The latter proves that, for each $t,$ $\mathcal{Z}\big(t,B_\e(z^*, \rho_0)\big)$ is the continuous inverse image of an open set hence an open set itself. The latter is also true for $D$ as an arbitrary union of open sets. The proof is complete.",2502.01783
proof,"It suffices to prove well-posedness for $\epsilon=1.$ Moreover, from Definition \ref{dfn:local mild solutions} it suffices to prove global well-posedness for $Z^{1,h}_{z,n}$ for each $n\in\N.$ The local solution to \eqref{eq:controlledequation} is then defined by patching up such global solutions up to the explosion time.  In turn, since we are working on $\e,$ this reduces to the case when $b, \sigma$ are bounded and Lipschitz continuous.       To this end we consider the map $ \mathscr{S}:\e\times L^p(\Omega;     C([0,T]; \e))\rightarrow  L^p(\Omega;     C([0,T]; \e))$                  \mathscr{S}(z, Z)(t)&=S(t)z+\int_0^tS_\alpha(t-s) B(Z(s)\big)ds+\int_0^tS_\alpha(t-s) \Sigma(Z(s)\big)h(s)ds+\int_0^tS_\alpha(t-s) \Sigma(Z(s)\big)dW(s)\\&          =:S(t)z+\rho_{Z}(t)+H_{Z}(t)+\Gamma_Z(t).          For $Z_1, Z_2\in  L^p(\Omega;     C([0,T]; \e)),$ Theorem \ref{thm:Linftydecay} yields the almost sure estimates    	  	|\rho_{Z_1}(t)-  \rho_{Z_2}(t) |_{\e}& \leq \int_0^t \big|S_\alpha(t-s)\big( B(Z_1(s)\big)-B(Z_2(s)\big)|_\e ds\\&  	\leq \int_0^t e^{-\theta (t-s)} |b(\Pi_1 Z_1(s))- b(\Pi_1 Z_2(s))|_{C^{-1}}ds\\&  	\leq C\int_0^t  |b(\Pi_1 Z_1(s))- b(\Pi_1 Z_2(s))|_{\infty}ds\\&  	\leq C|b|_{Lip}T \sup_{t\in[0,T]}|Z_1(t)-Z_2(t)|_{\e},  	           	  			|H_{Z_1}(t)-H_{Z_2}(t)|_\e&\leq  		\int_0^t e^{-\theta (t-s)} \big|\big(\sigma(\Pi_1 Z_1(s))- \sigma(\Pi_1 Z_2(s))\big)h(s)\big|_{C^{-1}}ds\\&  		\leq C \int_0^t \big|\big(\sigma(\Pi_1 Z_1(s))- \sigma(\Pi_1 Z_2(s))\big)h(s)\big|_{H}ds\\&  		\leq  C|\sigma|_{Lip} \sqrt{T}\sup_{t\in[0,T]}|Z_1(t)-Z_2(t)|_{\e}|h|_{L^2([0,T];H)}.  	    In view of Lemma \ref{lem:StochasticConvolutionApriori} we also have   $$  \ex| \Gamma_{Z_1}-\Gamma_{Z_2}|_{C([0,T];\e)}^p\leq C_T\ex|Z_1-Z_2|^p_{ C([0,T];C_0(0,\ell))}   $$  for a constant $C=C_T$ that is increasing in $T.$ From these estimates we deduce that   $$\big| \mathscr{S}(z, Z_1)-\mathscr{S}(z, Z_2)\big|_{ L^p(\Omega;     C([0,T]; \e)}    \leq C_T| Z_1-Z_2|_{ L^p(\Omega;     C([0,T]; \e)} .$$ In particular, for $T\leq T_0$ sufficiently small the map $\mathscr{S}(z,\cdot)$ is a contraction. From a classical fixed-point argument it follows that, for each $\epsilon>0,$ \eqref{eq:controlledequation} has a unique mild solution  $Z^{\epsilon,h}\in L^p(\Omega;     C([0,T_0]; \e)).$ The restriction on $T$ can then be lifted by repeating this argument on time-intervals of the form $[kT_0,  (k+1)T_0], k\in\N$. Thus for each $n\in\N$ $Z^{\epsilon, h}_{z,n}$ is globally well-posed and the proof is complete.",2502.01783
proof,"Let $\mathcal{U}\subset L^2([0,T];H)$ be a bounded set. The statement follows by showing that $K(\mathcal{U})$ is relatively compact in $C([0,T];\e).$ First note that, from Lemma \ref{lem:StochasticConvolutionApriori} (with $\epsilon=1, \Psi^\epsilon_2=0$ and $\Psi^\epsilon_1=\Sigma(Z)$) we obtain the bound 	 	 	\sup_{u\in\mathcal{U}}\sup_{t\in[0,T]}\bigg|\int_{0}^{t}S_\alpha(t-s)\Sigma_n(Z(s))u(s)ds\bigg|_{\h_1}\leq C_n, 	 		 	for some constant $C_n$ that depends on $T, |\sigma_n|_\infty$ and the diameter of $\mathcal{U}.$	We claim now that $\h_1$ is relatively compact in $\mathcal{E}.$ Indeed, the inclusion $H^1\subset C_0$ is compact by Sobolev embedding. Turning to the inclusion $L^2\subset C^{-1}$ we have , for any $\phi\in H,$ 	$$|\phi|_{C^{-1}}=\big|\hat{\phi}\big|_{\infty}:=\sup_{r\in(0,\ell)}\bigg|\int_{0}^{r}\phi(\xi)d\xi\bigg|.$$ 	Hence, for any bounded sequence $\{\phi_m\}_{m\in\N}\subset{H},$ the sequence of anti-derivatives $\{\hat{\phi}_m\}_{m\in\N}\subset C_0(0,\ell)$ is uniformly bounded and uniformly $1/2-$H\""older continuous. From the classical Arzel\`a-Ascoli theorem it follows that, up to a subsequence, $\hat{\phi}_m$ converges uniformly to a function $\hat{\phi}\in C_0.$ Passing if necessary to a further subsequence and without changing the notation, the weak $L^2-$compactness of $\{\phi_m\}_m$ and uniqueness of the limit imply that $\hat{\phi}$ has a weak derivative $\hat{\phi}'\in H.$ From the latter we deduce that $\lim_{m\to\infty}\phi_m=\hat{\phi}'$ in $C^{-1},$ which allows us to conclude our initial claim. 	 	It remains to show that $K(\mathcal{U})\subset C([0,T];\e)$ is uniformly equicontinuous. To this end, note that for any $s<t\in[0,T], u\in\mathcal{U}$ we have  	 	K(u)(t)-K(u)(s)=\int_{s}^{t}S_\alpha(t-r)\Sigma_n(Z(r))u(r)dr+\int_{0}^{s}[S_\alpha(t-r)-S_\alpha(s-r)]\Sigma_n(Z(r))u(r)dr. 	 	From continuity of the semigroup $S$ in $\h_1$ (\ref{prop:L2-decay}) and the local boundedness of $\sigma, u$ we obtain  	 	 	\big|K(u)(t)-K(u)(s)\big|_{\e}&\leq C\int_{s}^{t}|\Sigma_n(Z(r))u(r)|_{\e}dr\\&+C\int_{0}^{s}|S_\alpha(s-r)[S_\alpha(t-s)-I]|_{\mathscr{L}(\h_1)}|\sigma_n(\Pi_1Z(r))u(r)|_{H}dr\\& 	\leq C_{\sigma_n}(t-s)^{1/2}|u|_{L^2([0,T];H)}+C_n\int_{0}^{s}e^{-\omega(s-r)}|S_\alpha(t-s)-I|_{\mathscr{L}(\h_1)}|u(r)|_{H}dr\\& 	\leq C_{\sigma_n, \mathcal{U}}(t-s)^{1/2}+C_{n,T,\mathcal{U}}|S_\alpha(t-s)-I|_{\mathscr{L}(\h_1)}, 	 	 	where the latter holds uniformly over $u\in\mathcal{U}$ and $s,t\in[0,T].$ 	Next, let $\epsilon>0.$ From the strong continuity of $S_\alpha,$  there exists $\delta_1=\delta_1(T,\mathcal{U})>0$ such that for all $s,t$ with $|t-s|<\delta_1$ the second term in the last display is below $\epsilon/2.$ Thus, the choice $\delta_n:=\min\{\delta_1, (\epsilon/2C_{\sigma_n, \mathcal{U}})^2\}$ satisfies the $\epsilon-$challenge for uniform equicontinuity of $K(\mathcal{U}).$ The proof is complete in view of the latter, \eqref{Kcomp} and an infinite-dimensional version of Arzel\`a-Ascoli theorem.",2502.01783
proof,"Throughout the proof and for the sake of lighter notation we shall drop the subcript $n$ and work instead in the case of bounded, Lipschitz continuous coefficients $b,\sigma.$      \item \noindent Since the weak topology on bounded sets is metrizable, it suffices to consider a sequence $\{(z_m, u_m)\}_{m\in\N}\subset\mathcal{U}_N\times\e$ that converges weakly, as $m\to\infty,$ to a pair $(z, u)\in\mathcal{U}_N\times\e.$ For $t\in[0,T]$ we have    |Z^{u_m}_{z_m}(t)-Z^{u}_{z}(t)\big|_{\e}&\leq \big| S_\alpha(t)(z_m-z)\big|_{\e}+\int_{0}^{t}\bigg| S_\alpha(t-s)\big[B(Z^{u_m}_{z_m}(s))- B(Z^{u}_{z}(s))\big]\bigg|_{\e}ds\\& +\bigg|\int_{0}^{t} S_\alpha(t-s)\big[\Sigma(Z^{u_m}_{z_m}(s))u_m(s)- \Sigma(Z^{u}_{z}(s))u(s)\big]ds\bigg|_{\e}   From Assumption \ref{Assumption:b}, Assumption \ref{Assumption:sigma} and Theorem \ref{thm:Linftydecay} we obtain    |Z^{u_m}_{z_m}(t)-Z^{u}_{z}(t)\big|_{\e}&\leq C| z_m-z|_{\e}+C\int_{0}^{t} \big|b(\Pi_1Z^{u_m}_{z_m}(s))- b(\Pi_1Z^{u}_{z}(s))\big|_{H}ds\\& +C\int_{0}^{t}\big|\big[\sigma(\Pi_1Z^{u_m}_{z_m}(s))-\sigma(\Pi_1Z^{u}_{z}(s))\big]u_m(s)\big|_{H}ds\\&+C\bigg|\int_{0}^{t}S_\alpha(t-s) \Sigma(Z^{u}_{z}(s))\big[u_m(s)-u(s)\big]ds\bigg|_{\e}\\& \leq C| z_m-z|_{\e}+C|b|_{Lip}\int_{0}^{t}\big|\Pi_1Z^{u_m}_{z_m}(s)-\Pi_1Z^{u}_{z}(s)|_{H}ds\\& +|\sigma|_{Lip}\int_{0}^{t}\big|\Pi_1Z^{u_m}_{z_m}(s)-\Pi_1Z^{u}_{z}(s)|_{C_0(0,\ell)}|u_m(s)|_{H}ds\\& +C\sup_{t\in[0,T]}\bigg|\int_{0}^{t}S_\alpha(t-s) \Sigma(Z^{u}_{z}(s))\big[u_m(s)-u(s)\big]ds\bigg|_{\e}.   Thus, from an application of the Cauchy-Schwarz inequality for the control term we obtain   |Z^{u_m}_{z_m}(t)-Z^{u}_{z}(t)\big|^2_{\e}& \leq C| z_m-z|^2_{\e}+CT^{1/2}\int_{0}^{T}\big|Z^{u_m}_{z_m}(s)-Z^{u}_{z}(s)|^2_{\e}ds\\&+\tilde{C}T^{1/2}\int_{0}^{T} |Z^{u_m}_{z_m}(s)-Z^{u}_{z}(s)\big|^2_{\e}ds\\& +|\sigma|_{Lip}\sup_{m\in\N}|u_m|^2_{L^2([0,T];H)}\int_{0}^{T}\big|Z^{u_m}_{z_m}(s)-Z^{u}_{z}(s)|^2_{\e}ds\\& +C\sup_{t\in[0,T]}\bigg|\int_{0}^{t}S_\alpha(t-s) \Sigma(Z^{u}_{z}(s))\big[u_m(s)-u(s)\big]ds\bigg|^2_{\e}.   Gr\""onwall's inequality then furnishes   \sup_{t\in[0,T]}|Z^{u_m}_{z_m}(t)-Z^{u}_{z}(t)\big|^2_{\e}& \leq Ce^{C_{\sigma, b, N, T}}\bigg(| z_m-z|^2_{\e}+\sup_{t\in[0,T]}\bigg|\int_{0}^{t}S_\alpha(t-s) \Sigma(Z^{u}_{z}(s))\big[u_m(s)-u(s)\big]ds\bigg|^2_{\e}\bigg).   In view of Lemma \ref{lem:Zaprioricompactnesslem} with $Z=Z^{u}_{z},$ the right-hands side vanishes as $n\to\infty$ and the conclusion follows. \item  For $t\leq T$ we have      Z_z^u(t)-Z_z^0(t)=\int_{0}^tS_\alpha(t-s)\big[b(  \Pi_1Z_z^u(s))- b(\Pi_1  Z_z^0(s))\big]ds+\int_{0}^tS_\alpha(t-s)\sigma( \Pi_1 Z_z^u(s))u(s)ds.  From the local boundedness of $\sigma$, the second term on the right hand side satisfies                 \bigg|\int_{0}^tS_\alpha(t-s)\sigma(  Z_z^u(t))u(t)dt\bigg|_{\e}&\leq C \bigg|\int_{0}^tS_\alpha(t-s)\sigma( Z_z^u(t))u(t)dt\bigg|_{\h_1}\\&\leq C|\sigma|_{\infty}\int_{0}^{t}e^{-\theta(t-s)} |u(s)|_{H}ds\leq C|\sigma|_{\infty} T^{1/2}|u|_{L^2([0,T];H)}.       As for the first term, we use the (local) Lipschitz continuity of $b$ to obtain       \bigg|\int_{0}^{t}S_\alpha(t-s)\big[b(  Z_z^u(s))&- b(  Z_z^0(s))\big]ds\bigg|_{\e}\leq C\int_{0}^{T}\sup_{r\leq s}|Z^{u}_{z}(r)-Z^{0}_{z}(r)|_{\e} ds.     From the last two estimates along with Gr\""onwall's inequality we may conclude   | Z_z^u-Z_z^0|_{C([0,T];\e)}\leq C'T^{1/2}|u|_{L^2([0,T];H)}\exp(CT)  for constants $C, C'>0.$  The proof is complete upon observing that the function $$\Lambda(x)=C'T^{1/2}\exp(CT)x, x\geq 0$$ satisfies the desired properties.",2502.01783
proof,"Let $T>0, n\in\N$                  and $Z^\epsilon_{z,n}$ be a localized mild solution, per Definition \ref{dfn:local mild solutions}, with control $h=0.$ We shall rely on the equivalence of the ULDP and Equicontinuous Uniform Laplace Principle (EULP); see e.g. \cite[Theorem 2.9]{salins2019equivalences}).  In view of  \cite[Theorem 2.12]{salins2019equivalences}, the latter holds over bounded subsets of initial data, provided that for any $\delta>0,$ $D\subset\e$ bounded and $M>0,$     	        	                    \lim_{\epsilon\to 0}\sup_{z\in D}\sup_{u\in\mathcal{P}_2^M}\pr\bigg[\sup_{t\in[0,T]}\big|Z_{z, n}^{\epsilon,u}(t)-Z_{z, n}^{u}(t)\big|_{\e}\geq \delta \bigg]=0.     	      Here, $\mathcal{P}_2^M$ is the collection of adapted, $H-$valued stochastic controls $u$ such that $\pr( |u|^2_{L^2([0,T];H)}\leq M)=1.$ Moreover, $Z^{\epsilon,u}_{z,n}$ is a localized mild solution, per Definition \ref{dfn:local mild solutions}, with control $h=u.$       \noindent We can now estimate the latter using the local Lipschitz continuity of $b,\sigma$ and Gr\""onwall's inequality. Indeed,     	        	        	    \big|Z_{z,n}^{\epsilon,u}(t)-Z_{z,n}^{0,u}(t)\big|_{\e}&\leq \bigg|\int_{0}^{t}S_{\alpha}(t-s)\big[B_n(Z_{z,n}^{\epsilon,u}(s))-B_n(Z_{z,n}^{0,u}(s))\big]ds\bigg|_{\e}\\&+ \bigg|\int_{0}^{t}S_{\alpha}(t-s)\big[\Sigma_n(Z_{z,n}^{\epsilon,u}(s))-\Sigma_n(Z_{z,n}^{0,u}(s))\big]u(s)ds\bigg|_{\e}\\& +\epsilon\bigg|\int_{0}^{t}S_{\alpha}(t-s)\Sigma_n(Z_{z,n}^{\epsilon,u}(s))dW(s)\bigg|_{\e}\\&\leq C\int_{0}^{t}\big|b_{n}(\Pi_1Z_{z,n}^{\epsilon,u}(s))-b_{n}(\Pi_1Z_{z,n}^{0,u}(s))\big|_{H}ds\\& +C\int_{0}^{t}\big|\big[\sigma_n(\Pi_1Z_{z,n}^{\epsilon,u}(s))-\sigma_n(\Pi_1Z_{z,n}^{0,u}(s))\big]u(s)\big|_{H}ds+2C\epsilon\sup_{t\in[0,T]}\big|\Gamma_{n}^\epsilon(t)\big|_\e     	        	    where $\Gamma^\epsilon_{n}(t)$ is the stochastic convolution term.  From Assumption \ref{Assumption:b}, \ref{Assumption:sigma}, there exists $L_{n}$ such that    \big|Z_{z,n}^{\epsilon,u}(t)-Z_{z,n}^{0,u}(t)\big|_{\e}&\leq L_n\int_{0}^{t}\big|\Pi_1Z_{z,n}^{\epsilon,u}(s))-\Pi_1Z_{z,n}^{0,u}(s))\big|_{\infty}ds\\& +C_{\sigma_n}\int_{0}^{t}\big|\Pi_1Z_{z,n}^{\epsilon,u}(s)-\Pi_1Z_{z,n}^{0,u}(s)\big|_{\infty}|u(s)|_{H}ds+C\epsilon\sup_{t\in[0,T]}|\Gamma_{n}^\epsilon(t)|_\e.    \noindent From the $L^2-$bound on $u$ and Gr\""onwall's inequality we get    \ex\sup_{t\in[0,T]}\big|Z_{z,n}^{\epsilon,u}(t)-Z_{z,n}^{0,u}(t)\big|^2_{\e}\leq C \epsilon^2e^{C_{n}T}\sup_{\epsilon\in(0,1), n\in\N}\ex\sup_{t\in[0,T]}\big|\Gamma_{n}^\epsilon(t)\big|^2_\e\leq C\epsilon^2e^{C_{n}T},    \noindent where the last estimate follows by applying Lemma \ref{lem:StochasticConvolutionApriori} with $\Psi_2=0, p=2$ and using the boundedness of $\sigma_n.$  Taking $\epsilon\to 0$ we see that \eqref{eq:EULPsufficient} holds true for any $\delta, T>0$ and any bounded set $D\subset\e$ of initial data.    From the previous argument we deduce that the family of random elements  $\{Z^{\epsilon}_{z, n}; \epsilon>0\}$ satisfies a ULDP with rate function given in variational form by  $$ \inf_{u\in L^2([0,T];H)} \left\{ \frac{1}{2}\int_0^T \int_0^\ell |u(s,y)|^2 dyds: \phi=Z^{u}_{z, n}  \right\},$$ where $Z^u_{z,n}$ is a localization of the skeleton equation.  Finally, $I^n_{z,T}$ is a good rate function since its sublevel sets $\Phi^{n}_{z,T}(s_0)$   are compact as a consequence of lower semicontinuity. The proof is complete.",2502.01783
proof,"The equality $V_{\bar{D}}(z, \partial D)=V_D(z, \partial D)$ is clear, so we focus on showing $V_D(z, \partial D)= V(z, \partial D)$. On the one hand, the inequality $V(z, \partial D)\leq V_D(z, \partial D)$ is trivial since $V_D$ is an infimum over a smaller set than the one used for $V.$ For the reverse inequality, let $\eta>0,$ $T>0, z'\in\partial D, u\in L^2([0,T];H)$ and $\phi=Z^u_z$ such that $Z^u_z(T)=z'$ and  $$  \frac{1}{2}|u|^2_{L^2([0,T];H)}<V(z, \partial D)+\eta.$$ Next let $\tau=\inf\{ t>0 : \phi(t)\in\partial D \}$ be the first time that $\phi$ hits the boundary and note that $\tau\leq T.$ Since the restriction of $\phi$ on $[0, \tau]$ is in  $C([0,\tau];\e)$ and $\phi(t)\in D$ for any $t<\tau$ we conclude that  $$  V_D(z, \partial D)\leq \frac{1}{2}|u|^2_{L^2([0,\tau];H)}<V(z, \partial D)+\eta.$$ Since $\eta$ is arbitrary, the proof is complete.",2502.01783
proof,"For $T_0>0$ to be chosen later, define the linear operator $L_{T_0}:L^2([0,T_0];H) \to \h_1$ by              L_{T_0} u := \int_0^{T_0} S_{\alpha}(T_0 - s)0\\ u(s) ds.               This operator maps $L^2([0,T_0]; H)$ \textit{onto} $\h_1$ when $T_0$ is sufficiently large. Indeed, the adjoint operator      $L^\star_{T_0}: \h_1\to L^2([0,T];H)$ is given by              [L^\star_{T_0} z](t,x) = [\Pi_2 S_\alpha^\star(T_0-t) z](x).           In view of \cite[Proposition 2.3]{cerrai2006PTRFsmoluchowski1} and Proposition \ref{prop:L2-decay} it follows that the operator $S_\alpha^\star$ is of negative type with the same exponent as $S.$ From direct calculations (see e.g. \cite[Lemma 3.2]{cerrai2014smoluchowski}) we have              &|L^\star_{T_0} z|_{L^2([0,T_0];H)}^2 \nonumber= \int_0^{T_0} \int_0^\ell |[\Pi_2 S_\alpha^\star(T_0-t) z](x)|^2 dxdt \nonumber= \frac{1}{2 \alpha} \left( |z|_{\h_1}^2 - |S_\alpha^\star(T_0) z|_{\h_1}^2 \right)         \geq \frac{1}{2 \alpha}(1-M^2e^{-2\theta t})|z|^2_{\h_1}.          Choosing $T_0$ big enough so that          M^2e^{-2\theta T_0} = \frac{1}{2}          yields                  |z|^2_{\h_1} \leq 4\alpha |L^\star_{T_0} z|^2_{L^2([0,T_0];H)}=4\alpha |(L_{T_0}L^\star_{T_0})^{1/2}z|^2_{\h_1}.          By \cite[Corollary B7]{da2014stochastic}, this proves that the image              \left\{ z \in H^1 \times H : |z|_{\h_1 }\leq 1\right\} \subset \left\{L_{T_0} u : |u|_{L^2([0,T_0];H)} \leq 2 \sqrt{\alpha} \right\}.        In particular, this proves that for any $z \in\h_1$, there exists a control $u \in L^2([0,T_0];H)$ such that               z = \int_0^{T_0} S_\alpha(T_0-t) 0 \\u(t) dt          and               |u|_{L^2([0,T_0];H)} \leq 2 \sqrt{\alpha} |z|_{\h_1}.         Now let $\delta>0$  to be specified later. Given any $z \in\h_1$ such that     $|z-z^*|_{\h_1} < \delta$, let $|u_1|_{L^2([0,T_0];H)} \leq 2 \sqrt{\alpha} \delta$ be a control such that     $L_{T_0} u_1 = z-z^*$. Next,      define $Z(t) := z^* + \int_0^t S_\alpha(t-s)  0 \\u_1(s) ds.$ Since $z^*$ is an equilbrium and $\sigma$ is non-degenerate we can write              Z(t) = S_\alpha(t)z^* + \int_0^t S_\alpha(t-s) B(Z(s))ds  + \int_0^t S_\alpha(t-s)  0 \\\sigma(\Pi_1 Z(s))u(s) ds,          where               u(s,x) := \frac{1}{\sigma(\Pi_1 Z(s,x))} \bigg(u_1(s,x) + b(\Pi_1 z^*(x)) - b( \Pi_1 Z(s,x)) \bigg),\; (s,x)\in[0,t]\times(0,\ell).              In particular, $Z=Z_{z^*}^{u}$ and moreover $Z(T_0)=z.$ Notice that the path $Z$ exists for all times even though $Z_{z^*}^{u}$ is understood as a local solution.              It remains to estimate the $L^2$ norm of $u.$ By contractivity of the semigroup in $\h_1$ (Proposition \ref{prop:L2-decay}) and choice of $u_1$ we have               \sup_{t \in [0,T_0]} |Z(t) - z^*|_{\h_1 } \leq C  \delta.          The latter, along with Assumption \ref{Assumption:sigmaNondeg} and the choice of $u_1$ yield                \int_0^{T_0} \int_0^\ell |u(s,x)|^2 ds         \leq C' \sup_{t \in [0,T_0]} |b( \Pi_1 z^*(x)) - b(\Pi_1 Z(s))|^2_{\infty} + C \delta^2.          By \eqref{eq:Z-bounded}, the Sobolev embedding $ H^1\subset C_0$ and the continuity of $b$, we can take $\delta$ small enough so that the right-hand side is less than $\eta.$ The proof is complete.",2502.01783
proof,"Assume by contradiction that  \[\lim_{(\rho, \delta)\rightarrow (0,0)} V_{\bar{D}}\big(B_\e(z^*,\rho), B_\e(N,\delta)\big) < V_{\bar{D}}(z^*,N).\] This means that there exist a sequence of initial data $\{z_n;n\in\N\}\subset \e$ such that $\lim_n|z_n - z^*|_\e =0,$ a sequence of time horizons $T_n>0 $, a sequence of controls  $u_n \in L^2([0,T_n]; H)$, and a distance $\eta>0$ such that      \frac{1}{2}|u_n|_{L^2([0,T_n]; H)}^2 \leq V_{\bar{D}}(z^*,N) - \eta,  such that the controlled processes $Z^{u_n}_{z_n}(t)$ have the properties that $ Z^{u_n}_{z_n}(t) \in \bar{D}$  for all $t \in [0,T_n)$ and   $\textnormal{dist}(Z^{u_n}(T_n) ,N) \to 0.$ Since $Z^{u_n}_{z_n}(t) \in \bar{D}$ for all $t,$ there exists $N_0=N_0(D)\in\N$ (independent of $n$) such that the local $Z^{u_n}_{z_n}$ coincides with the process $Z^{u_n}_{z_n,N_0}$ (see Definition \ref{dfn:local mild solutions}). Hence, without loss of generality, we shall assume that $b, \sigma$ are bounded, Lipschitz continuous. Moreover, we drop the subscript $N$ and write $Z^{u_n}_{z_n}$ instead of $Z^{u_n}_{z_n,N_0}$ for the sake of lighter notation.  We separate the analysis into two cases; first where there exists a bounded subsequence of time horizons $\{T_n; n\in\N\}$ and second where $T_n \uparrow +\infty$.  \noindent \underline{\textbf{Case 1}}: (A subsequence of $\{T_n; n\in\N\}$ is upper bounded). Notice that \eqref{eq:VDcontradiction} provides a uniform $L^2$ bound for the controls, hence the sequence $\{u_n; n\in\N\}$ is weakly pre-compact. Thus, there exists a further subsequence (relabeled by $n$) such that $T_n \to T$ and $u_n$ converges weakly in $L^2([0,T];H)$ to $u$. Then by Lemma \ref{lem:controliccontinuity}(1), $$     |Z^{u_n}_{z_n}(T_n) - Z^{u}_{z^*}(T)|_\e\rightarrow 0.$$  Because $\textnormal{dist}(Z^{u_n}_{z_n}(T_n) ,N) \to 0$ and $N$ is closed this proves that $Z^{u}_{z^*}(T) \in N.$ But \[    V_{\bar{D}}(z^*,N) \leq \frac{1}{2}|u|_{L^2([0,T];H)}^2 \leq V_{\bar{D}}(z^*,N) - \eta\] which is a contradiction.  \noindent \underline{\textbf{Case 2}}: ($T_n\uparrow \infty$). We want to show that we also have a kind of convergence in this case. To guarantee convergence, we translate these processes to the negative half line $(-\infty,0]$. Define for $t<0$      \varphi_n(t) =          Z^{u_n}_{z_n}(T_n + t) & \text{ for } t \in [-T_n,0] \\         z_n & \text{ for } t < -T_n       and      h_n(t) =                u_n(t + T_n) &\text{ for } t \in [-T_n,0], \\         0 &\text{ for } t<-T_n.       For $t \in [-T_n,0]$, $\varphi_n(t)$ solves      \varphi_n(t) = &S_\alpha(T_n + t)z_n + \int_{-T_n}^t S_\alpha(t-s)          0 \\ b(\Pi_1 \varphi_n(s))          ds \nonumber+ \int_{-T_n}^t S_\alpha(t-s)   0 \\ \sigma(\Pi_1 \varphi_n(s))h_n(s) ds \nonumber\\     = &S_\alpha(T_n + t)(z_n-z^*) + z^* + \int_{-T_n}^t S_\alpha(t-s)          0 \\ (b(\Pi_1 \varphi_n(s)) - b(\Pi_1 z^*))          ds \nonumber\\     &+ \int_{-T_n}^t S_\alpha(t-s)   0 \\ \sigma(\Pi_1 \varphi_n(s))h_n(s)  ds\nonumber\\     =:& z^* +  S_\alpha(T_n + t) (z_n - z^*) + I_n(t) + Y_n(t).  The second to last line is a consequence of the assumption that $z^*$ is invariant,  implying that \[z^* = S_\alpha(t)z^* + \int_0^t S_\alpha(t-s)  0 \\ b(\Pi_1 z^*)  ds.\] We shall proceed to the asymptotic analysis of the paths $\{\phi_n(t);t\in[-\infty, 0]\}$.   \noindent{\textit{Step 1}: \textit{Pre-compactness in} $C([-T,0];\e)$}. We shall use a functional analytic version of Arzel\`a-Ascoli to prove that a subsequence $I_n(t) + Y_n(t)$ converges in $\e$ for all $t \in (-\infty,0]$. The fact that $\varphi_n(t) \in \bar{D}$ for all $t <0$ guarantees that $|b(\Pi_1 \varphi(s)) - b(\Pi_1z^*)|_H$ is uniformly bounded in $s<0$. In particular, from Proposition \ref{prop:L2-decay} there exist $M,\theta>0$ such that      |I_n(t)|_{\h_1} \leq  M\int_{-T_n}^t   e^{-\theta(t-s)} ds \leq \frac{M}{\theta}.  Because $\h_1$ is compactly embedded into $\e$ (as was shown e.g. in the proof of Lemma \ref{lem:Zaprioricompactnesslem}), this proves that for fixed $t<0$, the family $\{I_n(t)\}_n$ is compact. As for the control term, \eqref{eq:VDcontradiction} furnishes      |Y_n(t)|_{\h_1} \leq C |h_n|_{L^2([-T_n,0];H)} \leq C \sqrt{V_{\bar{D}}(z^*,N) - \eta}.  We turn to temporal equicontinuity estimates for $I_n, Y_n.$ A direct consequence of the compact inclusion $\h_1\subset\e$ is that      \lim_{t \rightarrow 0}|S_\alpha(t) - I|_{\mathscr{L}(\h_1; \e)} = 0.   Now for $s<t<0$,      &\left|I_n(t) - I_n(s) \right|_\e \nonumber\\     &\leq \int_{-T_n}^s \left| (S_\alpha(t-r)-S_\alpha(s-r))       0 \\ (b(\Pi_1 \varphi_n(r)) - b(\Pi_1 z^*)) \right|_\e dr \nonumber\\     &\quad+ \int_{s}^t \left|S_\alpha(t-r)  0 \\ (b(\Pi_1 \varphi_n(r)) - b(\Pi_1 z^*)) \right|_\e dr\nonumber\\     &\leq \int_{-T_n}^s M e^{-\theta(s-r)} |S_\alpha(t-s) - I|_{\mathscr{L}(\h_1;\e)} | (b(\Pi_1 \varphi_n(r)) - b(\Pi_1 z^*))|_H dr\nonumber\\     &\quad+ \int_s^t M e^{-\theta (t-r)} | (b(\Pi_1 \varphi_n(r)) - b(\Pi_1 z^*))|_H dr \nonumber\\     &\leq C |S_\alpha(t-s) - I|_{\mathscr{L}(\h_1; \e)} + C(t-s),  which proves equicontinuity for $I_n$. The constant $C$ depends on $M$, $\theta$ and $\sup_{z \in \bar{D}} |b(z) - b(z^*)|_H.$  Equicontinuity for the $Y_n(t)$ terms is similar. For $s<t<0$,      &\left|Y_n(t) - Y_n(s) \right|_\e \nonumber\\     &\leq \int_{-T_n}^s \left| (S_\alpha(t-r)-S_\alpha(s-r))       0 \\ \sigma(\Pi_1 \varphi_n(r))h_n(r) \right|_\e dr \nonumber\\     &\quad+ \int_{s}^t \left|S_\alpha(t-r)  0 \\ \sigma(\Pi_1 \varphi_n(r))h_n(r) \right|_\e dr\nonumber\\     &\leq \int_{-T_n}^s M e^{-\theta(s-r)} |S_\alpha(t-s) - I|_{\mathscr{L}(H^1\times H, \e)} | \sigma(\Pi_1 \varphi_n(r))h_n(r)|_H dr\nonumber\\     &\quad+ \int_s^t M e^{-\theta (t-r)} | \sigma(\Pi_1 \varphi_n(r))h_n(r)|_H dr.  Now we use the fact that $\sup_{z \in \bar{D}} |\sigma(\Pi_1 z)|_{\infty}<+\infty$ and a Cauchy-Schwarz inequality in time to bound the above expression by      \left|Y_n(t) - Y_n(s) \right|_\e \nonumber     &\leq |S_\alpha(t-s) - I|_{\mathscr{L}(\h_1; \e)} C | h_n|_{L^2([-T_n,0];H)} +  \sqrt{t-s} | h_n|_{L^2([-T_n,0];H)}\\&     \leq C \sqrt{V_{\bar{D}}(z^*,N) - \eta}     \bigg(|S_\alpha(t-s) - I|_{\mathscr{L}(\h_1; \e)}+   \sqrt{t-s} \bigg),  where the last line follows from \eqref{eq:hnbound}. This proves equicontinuity for  the $Y_n$ terms.   \noindent{\textit{Step 2}: \textit{Identification of limiting paths}}. By the Arzel\`a-Ascoli Theorem (see e.g. \cite[Theorem 47.1]{Munkres}, there exists a subsequence (relabeled as $Y_n$, $I_n$) and limits $I(t)$ and $Y(t)$ such that for any $-T<0$      \lim_{n \to \infty} \sup_{t \in [-T,0]} |I_n(t) - I(t)|_\e =\lim_{n \to \infty} \sup_{t \in [-T,0]} |Y_n(t) - Y(t)|_\e=0,  i.e. we have uniform convergence on compact time intervals.   Because $T_n \uparrow \infty$ and $|z_n - z^*|_\e \to 0$, it follows that \[\lim_{n \to \infty}\sup_{t\in [-T_n,0]} |S_\alpha(t + T_n)(z_n - z^*)|_\e = 0.\] Therefore, a subsequence of  $\varphi_n(t)$ converges  to a limit $\varphi(t)$ uniformly on compact time intervals. In order to charactherize $\varphi$ we use the dominated convergence theorem and uniqueness of the limit to conclude that      I_n(t) \longrightarrow \int_{-\infty}^t S_\alpha(t-s)          0 \\ b(\Pi_2 \varphi(s)) - b(z^*))     ds=:I(t),\;\;n\to\infty.  In view of \eqref{eq:VDcontradiction}, \eqref{eq:hnDefinition}, the sequence $\{h_n\mathds{1}_{[-T_n,t]};n\in\N\}\subset L^2((-\infty, 0);H)$ is weakly pre-compact. Passing if necessary to a further subsequence so that  $h_n\mathds{1}_{[-T_n,t]} \rightarrow h\mathds{1}_{[-\infty,t]}$ weakly, it follows that       Y_n(t) \longrightarrow \int_{-\infty}^t S_\alpha(t-s)          0 \\ \sigma( \Pi_1 \varphi(s))h(s)     =:Y(t),\;\;n\to\infty.   Hence, for $t<0$ the limiting path $\varphi$ satisfies      \varphi(t) = &z^* + \int_{-\infty}^t S_\alpha(t-s)  0 \\ (b(\Pi_1\varphi(s)) - b(\Pi_1 z^*))  ds \nonumber\\&+ \int_{-\infty}^t S_\alpha(t-s)  0 \\ \sigma(\Pi_1 \varphi(s))h(s)  ds.    \noindent{\textit{Step 3}: \textit{Long-time behaviour of the limiting path in $\e$}}. The next step is to prove that $\lim_{t \downarrow -\infty} |\varphi(t)-z^*|_\e = 0$. For any $T<t<0$, a representation for $\varphi(t)$ is      \varphi(t) = &S_\alpha(t-T)\varphi(T)  + \int_T^t S_\alpha(t-s) 0 \\ (b(\Pi_1\varphi(s)) )  ds \nonumber+ \int_{T}^t S_\alpha(t-s)  0 \\ \sigma(\Pi_1 \varphi(s))h(s)  ds.  By the proof of Lemma \ref{lem:controliccontinuity}(2), given $\rho>0$, there exists $T_{\rho}>0$ and $\alpha_\rho>0$ such that       |Z^{u}_z(T_\rho) -z^*|_\e < \rho  if $z \in D$ and $|u|_{L^2([0,T_ \rho];H)}\leq \alpha_\rho$. Because $h \in L^2((-\infty,0);H)$, there exists $-T'_\rho<0$ such that       |h|_{L^2((-\infty,-T'_\rho);H)}< \alpha_\rho.  Then for any $t<-T'_\rho$, $\varphi(t)$ can be written as      \varphi(t) = &S_\alpha(T'_\rho) \varphi(t-T'_\rho)     + \int_{t-T'_\rho}^t S_\alpha(t-s) 0 \\ (b(\Pi_1\varphi(s)) )  ds \nonumber\\     &+ \int_{t-T'_\rho}^t S_\alpha(t-s)  0 \\ \sigma(\Pi_1 \varphi(s))h(s)  ds.  Therefore, because $|h|_{L^2((t-T'_\rho,t);H)}< \alpha_\rho$, it follow that $|\varphi(t)-z^*|_\e< \rho$. This is true for all $t<-T'_\rho$. We can do this argument for arbitrarily small $\rho>0$, proving that      \lim_{t \downarrow -\infty} |\varphi(t) - z^*|_\e = 0.   \noindent{\textit{Step 4}: \textit{Long-time behaviour of the limiting path in $\h_1.$}} Next, we argue that, because we know that $|\varphi(t) - z^*|_\e \to 0$ as $t \downarrow -\infty$, the stronger $\h_1$ convergence holds      \lim_{t \downarrow -\infty} |\varphi(t) - z^*|_{\h_1}  =0.  For this we use the representation \eqref{eq:varphi-infinite-integrals}.  From Proposition \ref{prop:L2-decay}, for any $t<0$,      &\left|\int_{-\infty}^t S_\alpha(t-s)  0 \\ (b(\Pi_1\varphi(s))- b(\Pi_1 z^*)) ds \right|_{\h_1}\nonumber\leq \frac{M}{\theta} \sup_{s \leq t} |(b(\Pi_1\varphi(s))- b(\Pi_1 z^*))|_H.  This converges to 0 as $t \downarrow -\infty$ because $\varphi(s) \to z^*$ in $\e$.  For the second term,      &\left|\int_{-\infty}^t S_\alpha(t-s)  0 \\ \sigma(\varphi(s))h(s) ds \right|_{\h_1}     \nonumber\leq \int_{-\infty}^t Me^{-\omega(t-s)} |\sigma(\varphi(s))h(s)|_Hds \nonumber\leq \frac{|\sigma|_\infty M}{\sqrt{2\omega}} |h|_{L^2((-\infty,t);H)},  where the final inequality is the Cauchy-Schwarz inequality with respect to the time variable. This expression converges to $0$ as $t \downarrow -\infty$ because $h \in L^2((-\infty,0);H)$.    \noindent{\textit{Step 4}: \textit{Exact controllability}}. Now that $\varphi(t) \to z^*$ in $\h_1$, we can use exact controllability Lemma \ref{lem:exact-control}. Given $\eta>0$, there exists $T_0>0$ and $\delta>0$ such that when $|z-z^*|_{\h_1}< \delta_0$ there exists a controlled path that connects $z^*$ to $z$ with action less than $\frac{\eta}{2}$. Because $\varphi(t) \to z^*$ in $\h_1$, we can find $-t_0<0$ such that $|\varphi(-t_0) - z^*|_{\h_1}<\delta_0$. Therefore, we can find a controlled path $Z^{u_0}_{z^*}$ such that      Z^{u_0}_{z^*}(T_0) = \varphi(-t_0)  and      \frac{1}{2}|u_0|_{L^2([0,T_0];H)}^2 < \frac{\eta}{2}.  Finally, we build a path by concatenation for $t>0$      \varphi_1(t) =               Z^{u_0} (t), & \text{ for } t \in [0,T_0],\\         \varphi(-t_0 + t - T_0), & \text{ for } t \in [T_0, T_0  + t_0].       We have that $\varphi_1 = Z^{u}_{z^*}$ is a path controlled by      u(t) =               u_0(t), & \text{ for } t \in [0,T_0],\\         h(-t_0 + t - T_0),  &\text{ for } t \in [T_0, T_0 + t_0]        such that      \frac{1}{2}|u|_{L^2([0,T_0 + t_0];H)}^2 \leq \frac{1}{2}|h|_{L^2((-\infty,0);H)}^2 + \frac{\eta}{2} \leq V_{\bar{D}}(z^*, N) - \frac{\eta}{2}  and $Z^{u}_{z^*}(T_0 + t_0) \in N.$ This is a contradiction. Therefore, in this case we must have      \lim_{(\rho, \delta)\rightarrow (0,0)} V_{\bar{D}}(B(z^*,\rho),N) = V_{\bar{D}}(z^*, N).  The proof is complete.",2502.01783
proof,"Without loss of generality we assume that $V(z^*,  \bar{D}^c)<\infty$ (otherwise there is nothing to prove). By definition of the quasipotential and rate function there exists $T_1>0$, $y \in \bar{D}^c$ and a control $v\in L^2([0,T_1];H)$ such that  $Z_{z^*}^v(T_1)=y$ and $\tfrac{1}{2}|v|^2_{L^2([0,T_1];H)}<V(z^*, \bar{D}^c)+\delta.$ Letting $d:=\textnormal{dist}_{\e}(y, \partial D)$ and using the flow continuity of the skeleton equation (Lemma \ref{lem:controliccontinuity}(1)), there exists $\rho>0$ such that for all initial data $z\in\e$ with $|z-z^*|_\e<\rho$ we have $|Z_{z}^v-Z_{z^*}^v   |_{C([0,T_1];\e)}<d/2.$ By uniform attraction to $x^*$ we can find a time $T_2>0$ such that $\sup_{z\in D}|Z_{z}^v(T_2)-z^*    |_{\e}<\rho.$ Next we define a control $u$ by $$  u(t)= 0,&\;\; t\in [0, T_2]\\                        v(t-T_2),&\;\; t\in [T_2, T_1+T_2].         $$ Letting $T:=T_1+T_2$ we see that $$\frac{1}{2}|u|^2_{L^2([0,T];H)}=\frac{1}{2}|v|^2_{L^2([0,T_1];H)}<V(z^*, \bar{D}^c)+\delta.$$ Moreover, a direct application of the reverse triangle inequality yields  $$ \textnormal{dist}_{\e}(Z^u_{z}(T), \partial D)\geq  \textnormal{dist}_{\e}(Z^u_{z^*}(T), \partial D)-|Z_{z}^v-Z_{z^*}^v   |_{C([0,T_1];\e)}>d-d/2=d/2.      $$  The latter, along with another triangle inequality, furnishes the inclusion $$\big\{ |Z_{z}^{\epsilon}-Z_{z}^u   |_{C([0,T];\e)}<d/4   \big\}\subset \big\{\textnormal{dist}_{\e}(Z_z^{\epsilon}(T), \partial D)>d/4\big\}.$$ Hence  $$\pr\bigg[  |Z_{z}^{\epsilon}-Z_{z}^{u}   |_{C([0,T];\e)}<d/4    \bigg]\leq \pr[  \tau_D^{\epsilon, z}\leq T   ].   $$ Since $Z_z^u$ has finite energy and remains bounded in $\e$ uniformly over $t\in[0,T],$ there exists $s_0>0$ such that $Z_z^u\in\Phi_{z,T}(s_0)$ (with the sublevel set notation introduced in \eqref{eq:SublevelSets}). From the ULDP lower bound \eqref{eq:LULDP-lower}, we conclude that              \liminf_{\epsilon\to 0}\inf_{z\in D}\epsilon^2\log\pr\big[ \tau_D^{\epsilon, z}\leq T  \big]&\geq-\frac{1}{2}|u|^2_{L^2([0,T];H)} >-V(z^*, \bar{D}^c)-\delta.",2502.01783
proof,"{\textit{(Of Theorem \ref{thm:ExitTimeUpperBnd})}}         \item Let $\delta>0$ and take $T>0$ from Lemma \ref{lem:preupperbound}. By virtue of the Markov property of $Z^\epsilon_z$, for any $k \in \mathbb{N},$ we have    \sup_{z \in D} \pr(\tau^{\epsilon,z}_D > kT) \leq \left(\sup_{z \in D} \pr(\tau^{\epsilon,z}_D > T) \right)^k \leq \left(   1 - \inf_{z \in D} \pr(\tau^{\epsilon,z}_D \leq T)\right)^k.   Thus, by the tail probability formula $$\ex[ \tau_D^{\epsilon,z}]\leq T\bigg(      1+   \sum_{k=1}^{\infty}\pr\big( \tau_D^{\epsilon,z}\geq kT  \big)\bigg).    $$ From the combination of the last two displays, along with the geometric series formula, we have  $$ \sup_{z \in D}\ex[ \tau_D^{\epsilon,z}]\leq\frac{T}{1-\left(1 - \inf_{z \in D} \pr(\tau^{\epsilon,z}_D \leq T) \right)} = \frac{T}{ \inf_{z \in D} \pr(\tau^{\epsilon,z}_D \leq T)}.$$  From Lemma \ref{lem:preupperbound} it follows that  $$   \limsup_{\epsilon\to 0} \sup_{z \in D}\epsilon^2\log\ex\big[ \tau_D^{\epsilon,z}\big]\leq    -\liminf_{\epsilon \to 0} \inf_{z \in D} \epsilon^2\log\pr( \tau_D^{\epsilon,z}\leq T)\leq  V(z^*, \bar{D}^c)+\delta.  $$ Since $\delta>0$ was arbitrary, this concludes the proof of the first assertion.  \item We have by Chebyshev's inequality               \pr\bigg[ \epsilon^2\log\tau_D^{\epsilon,z}>V_D(z^*, \bar{D}^c)+\delta \bigg]&=  \pr\bigg[ \tau_D^{\epsilon,z}>\exp\bigg(\frac{V(z^*, \bar{D}^c)+\delta}{\epsilon^2}\bigg)                              \bigg]\\&\leq \ex\big[ \tau_D^{\epsilon,z}\big]\exp\bigg(-\frac{V(z^*, \bar{D}^c)+\delta}{\epsilon^2}\bigg).           By (1), the right-hand side converges to $0$ as $\epsilon\to 0$ and the proof is complete.",2502.01783
proof,"Let $\rho$ be small enough for \eqref{eq:gammarhodef} to hold. By the uniform attraction shown in Theorem \ref{thm:domainofattraction} there exists $T_0=T_0(\rho)>0$ such that $\sup_{z\in D}|Z_z^0(T_0)-z^*|_\e<\rho/2.$ In view of the latter, Lemma \ref{lem:controliccontinuity}(2)  and a triangle inequality imply that, if there exists a control $u$ such that $|Z^u_z(T_0)-z^*|_{\e}> 3\rho/4$  then  $$  \frac{\rho}{4}< |Z^{u}_z(T_0)-Z^0_z(T_0)|_{\e}\leq \Lambda\big(|u|_{L^2([0,T_0];H)}\big).$$ Since $\Lambda$ is invertible with a non-decreasing inverse it follows that  $$  0<\frac{1}{2}\bigg(\Lambda^{-1}(\tfrac{\rho}{4})\bigg)^2\leq \frac{1}{2}|u|^2_{L^2([0,T_0];H)}.      $$  Hence there exists $s_0>0$ such that the set of trajectories $\phi\in C([0,T_0];\e)$ such that 1) $\phi(0)=z,$ $2)$ $\phi(t)\in D$ for all $t\in[0,T_0],$ and 3) $|\phi(T_0)-z^*|_{\e}> 3\rho/4$ is disjoint from the sublevel set $\Phi_{ T_0, z}(s_0)$ (recall the notation \eqref{eq:SublevelSets}). Hence all trajectories that satisfy 1), 2) and $\phi(t)\in D\setminus (\gamma_\rho\cup\partial D)$ for all $t\in [0,T_0]$ must also satisfy $$ \textnormal{dist}_{C([0,T_0];\e)}\big(\phi; \Phi_{T_0, z}(s_0)\big)\geq \rho/4. $$   From the ULDP upper bound %\eqref{eq:LULDP-upper} it follows that      &\limsup_{\epsilon\to 0}\sup_{z\in D}\epsilon^2\log\pr\bigg[ \tau^{\epsilon, z}_{\rho}>T_0  \bigg]\leq    \limsup_{\epsilon\to 0}\sup_{z\in D}\epsilon^2\log\pr\bigg[\forall t\in [0, T_0]\;   Z_z^{\epsilon}(t)\in D\setminus(\gamma_\rho\cup\partial D )\bigg]\\&   \leq  \limsup_{\epsilon\to 0}\sup_{z\in D}\epsilon^2\log\pr\bigg[ Z^\epsilon_z(t) \in \mathcal{D}, t \in [0,T_0] \text{ and }  \textnormal{dist}_{C([0,T_0];\e)}(Z_z^{\epsilon}; \Phi_{T_0, z}(s_0))\geq \rho/4\bigg]   \\& \leq -s_0.      This bound can then be bootstrapped via the Markov property so that for all $k\in\N$ \[\sup_{z\in D}\pr\bigg[ \tau^{\epsilon, z}_{\rho}>kT_0   \bigg] \leq \left( \sup_{z\in D}\pr\bigg[ \tau^{\epsilon, z}_{\rho}>T_0   \bigg]\right)^k.\] We conclude that       \limsup_{\epsilon\to 0}\sup_{z\in D}\epsilon^2\log\pr\bigg[ \tau^{\epsilon, z}_{\rho}>kT_0   \bigg]\leq -ks_0  and the proof is complete upon taking $k\to\infty.$",2502.01783
proof,"For any $z \in \gamma_\rho,$ $u \in L^2([0,T];H)$ and $Z_z^u$ a controlled path we have              |Z^{u}_z(t) - z^*|_\e \leq &|S_\alpha(t)(z - z^*)|_\e + \left| \int_0^t S_\alpha(t-s) ( B(Z^{u}_z(s)) - B(z^*))ds\right|_\e \nonumber\\         &+ \left| \int_0^t S_\alpha(t-s) \Sigma(Z^{u}_z(s))u(s)ds \right| \nonumber\\         &\leq M \rho + Ct + C \sqrt{t}|u|_{L^2([0,t];H)},          where $M$ as in \eqref{eq:Mdefinition}, $C$ a constant independent of $z,T$ and we used the local Lipschitz continuity of $b, \sigma$.     Notice that if $Z^u_z(t)\notin B_\e(z^*, 3M\rho/2)$ then               |u|_{L^2([0,t];H)} \geq \frac{\frac{ M\rho}{2} - Ct}{C\sqrt{t}} =: E(t).            In other words, recalling the sublevel set notation \eqref{eq:SublevelSets}, we have the inclusion     $$\Phi_{z,T}\big(\tfrac{1}{2}E^2(T)\big)\subset\bigg\{ \phi\in C([0,T];\e): \phi(t)\in    B_\e(z^*, 3M\rho/2)\;\textnormal{for some}\;t\in[0,T]\bigg\}.$$    Therefore, because $\Gamma_\rho$ is a sphere of radius $2M\rho$              \sup_{z \in \gamma_\rho} \pr \bigg[ Z^\epsilon_z(t) \in \Gamma_\rho \text{ for some } t \in [0,T] \bigg]          \leq \sup_{z \in \gamma_\rho} \pr  \bigg[\textnormal{dist}\big(Z^\epsilon_z, \Phi_{z,T}(E^2(T)/2)\big) \geq \frac{M\rho}{2} \bigg] .               By the ULDP upper bound \eqref{eq:LULDP-upper},              \limsup_{\epsilon \to 0} \sup_{z \in \gamma_\rho} \epsilon^2 \log \pr\bigg[Z^{\epsilon}_z(t) \in \Gamma_\rho \text{ for some } t \in [0,T] \bigg]  \leq -\frac{1}{2}E^2(T).          The conclusion follows because $E(T) \to \infty$ as $T \to 0$.",2502.01783
proof,"This follows from the convergence in probability  $Z^{\epsilon}_z\rightarrow Z_z^0, \epsilon\to 0,$ which holds uniformly over compact time intervals, and the asymptotic stability of $z^*.$  In particular, for $z\in\gamma_\rho$ there is nothing to prove. Thus, we fix $z\in D\setminus\gamma_\rho.$ By virtue of asymptotic stability, the deterministic hitting time $\tau^z:=\inf\{ t>0 : |Z^0_z(t)-z^*|_\e=\rho/2  \}$ is finite. By invariance of $D$ (due to Proposition \ref{corr:DExistence}) and path continuity of $Z_z^0$ we have $$d=\textnormal{dist}_{\e}\big(\{Z_z^0(t); t\in[0,\tau^z]\}, \partial D    \big)>0.        $$ An application of the triangle inequality and the aforementioned convergence then yield $$\pr\bigg[ Z^{\epsilon}_z(\tau_{\rho}^{\epsilon, z}  )\in\gamma_\rho \bigg]\geq \pr\bigg[ \big|Z^\epsilon_z-Z^0_z\big|_{C([0,\tau^z];\e)}  <\frac{d\wedge\rho}{2} \bigg]\longrightarrow 1\;,\epsilon\to 0.    $$ The proof is complete.",2502.01783
proof,"Let $s_0<V_{\bar{D}}(z^*, N).$ For $T>0, \rho>0, z\in\Gamma_\rho$ we have             \pr\bigg[Z^\epsilon_z(\tau^{\epsilon,z}_\rho) \in N\bigg]=\pr\bigg[ Z^\epsilon_z(\tau^{\epsilon,z}_\rho) \in N, \tau^{\epsilon,z}_\rho\leq T\bigg]+\pr\bigg[ Z^\epsilon_z(\tau^{\epsilon,z}_\rho) \in N, \tau^{\epsilon,z}_\rho>T\bigg].       From Lemma \ref{lem:innerregularity}, there exist $\rho_0, \delta_0>0$ such that for all $\rho<\rho_0, \delta<\delta_0$ we have                V_{\bar{D}}(B(z^*,\rho), B(N, \delta) )>s_0.       By choosing a possibly smaller $\rho$, Lemma \ref{lem:meandering} furnishes a sufficiently large $T_0$ such that              \limsup_{\epsilon\to 0}\sup_{z\in\Gamma_\rho}\epsilon^2\log\pr\bigg[ Z^\epsilon_z(\tau^{\epsilon,z}_\rho) \in N, \tau^{\epsilon,z}_\rho>T_0\bigg]\leq \limsup_{\epsilon\to 0}\sup_{z\in\Gamma_\rho}\epsilon^2\log\pr\bigg[\tau^{\epsilon, z}_\rho>T_0\bigg]\leq -s_0.       In view of \eqref{eq:lsc},  any path $\psi\in C ([0,T_0];\e)$ with $\psi(0)\in\Gamma_{\rho}$ and $\textnormal{dist}_{\e}(\psi(T_0), N)=\delta$ will satisfy        \textnormal{dist}_{C([0,T_0]; \e)}(\psi, \Phi_{z, T_0}(s_0))>0.       The latter, along with the triangle inequality, implies that for all paths $\phi$ that exit $D$ through $N$ by time $T_0$        \textnormal{dist}_{C([0,T_0]; \e)}(\phi, \Phi_{z, T_0}(s_0))\geq |\phi-\psi|_{C([0,T_0]; \e)}+\textnormal{dist}_{C([0,T_0]; \e)}(\psi, \Phi_{z, T_0}(s_0))\geq \delta.         From \eqref{eq:contradiction} and the ULDP upper bound \eqref{eq:LULDP-upper} it follows that              \limsup_{\epsilon\to 0}\sup_{z\in\Gamma_\rho}\epsilon^2\log\pr\bigg[ Z^\epsilon_z(\tau^{\epsilon,z}_\rho) \in N, \tau^{\epsilon,z}_\rho\leq T_0\bigg]\leq \limsup_{\epsilon\to 0}\sup_{z\in\Gamma_\rho}\epsilon^2\log\pr\bigg[   \textnormal{dist}_{C([0,T_0]; \e)}(Z^{\epsilon}_z, \Phi_{z, T_0}(s_0))>         \delta      \bigg]\leq -s_0.       \noindent From the latter, along with \eqref{eq:largetime}, we conclude that        \limsup_{\rho \to 0} &\limsup_{\epsilon \to 0} \sup_{z \in \Gamma_\rho} \epsilon^2\log \pr\bigg[Z^\epsilon_z(\tau^{\epsilon,z}_\rho) \in N\bigg]\\& \leq          \limsup_{\rho \to 0} \limsup_{\epsilon \to 0} \sup_{z \in \Gamma_\rho}\max\bigg\{   \epsilon^2\log\pr\bigg[\tau^{\epsilon, z}_\rho>T_0\bigg], \epsilon^2\log\pr\bigg[   \textnormal{dist}_{C([0,T_0]; \e)}(Z^{\epsilon}_z, \Phi_{z, T_0}(s_0))>         \delta      \bigg]  \bigg\}\leq -s_0.              Since $s_0< V_{\bar{D}}(z^*, N)$ was arbitrary, the proof is complete.",2502.01783
proof,"{\textit{(Of Theorem \ref{thm:ExitTimeLowerBnd})}}      \item Let $\delta>0, m\geq 1.$ From Lemma \ref{lem:rhoupperbound} with $N=\partial D$ and Lemma \ref{lem:VDequality} there exists $\rho_0$ such that for all $\rho<\rho_0$                    \limsup_{\epsilon \to 0} \sup_{z \in \Gamma_\rho} \epsilon^2 \log \pr\left( Z^\epsilon_z(\tau^{\epsilon,z}_0) \in \partial D\right) &\leq -  V_{\bar{D}}(z^*,\partial D)+\frac{\delta}{2}          =-  V(z^*,\partial D)+\frac{\delta}{2}.                  The latter and the Markov property of $Z^\epsilon_z$ then furnish                \sup_{z\in D}\pr[\tau_D^{\epsilon,z}=\tau^{\epsilon,z}_{m}]&\leq \sup_{z\in D}\pr\bigg[\bigcap_{k=0}^{m-1}\tau_D^{\epsilon,z}\neq\tau^{\epsilon,z}_{k}\bigg]\sup_{z\in \Gamma_\rho}\pr\big[ Z^\epsilon_z(\tau^{\epsilon,z}_{0})\in\partial D\big]\\&         \leq \sup_{z\in \Gamma_\rho}\pr\big[ Z^\epsilon_z(\tau^{\epsilon,z}_{0})\in\partial D\big]\leq \exp\bigg\{-\frac{1}{\epsilon^2}\bigg( V(z^*,\partial D)-\frac{\delta}{2}\bigg)\bigg\},       which holds for $\epsilon$ sufficiently small. Next, from Lemma \ref{lem:fastexcursions}, we choose $T_0$ small enough such that           \limsup_{\epsilon \to 0} \sup_{z \in \gamma_\rho} \epsilon^2 \log \pr\bigg[Z^{\epsilon}_z(t) \in \Gamma_\rho \text{ for some } t \in [0,T_0]\bigg]\leq-V(z^*,\partial D).      The latter, along with the Markov property, implies that for each $m\in\N$           \limsup_{\epsilon \to 0} \sup_{z \in G} \epsilon^2 \log \pr\left(\theta^{\epsilon,z}_{m+1}-\tau^{\epsilon,z}_{m} \leq T_0\right)\leq-V(z^*,\partial D).      Next notice that for each $k\in\N, m\leq k, z\in D$               \{\tau_D^{\epsilon,z}\leq kT_0 \}\subset\bigcup_{m=0}^{k}\{\tau_D^{\epsilon,z}=\tau^{\epsilon,z}_{m}   \}\cup\bigcup_{m=0}^{k}\{ \tau^{\epsilon,z}_{m+1}-\tau^{\epsilon,z}_{m} \leq T_0  \}       ( see e.g. the proof of \cite[Theorem 5.7.11(a)]{dembo2009large} for a similar argument). Thus,                \pr\big[  \tau_D^{\epsilon,z}\leq kT_0   \big]&\leq \sum_{m=0}^{k}\bigg(\pr\big[\tau_D^{\epsilon,z}=\tau^{\epsilon,z}_{m}      \big]+\pr\big[ \theta^{\epsilon,z}_{m+1}-\tau^{\epsilon,z}_{m} \leq T_0  \big]    \bigg)\\&         \leq \pr\big[\tau_D^{\epsilon,z}=\tau^{\epsilon,z}_{0}      \big]+ 2k\exp\bigg\{-\frac{1}{\epsilon^2}\bigg( V(z^*,\partial D)-\frac{\delta}{2}\bigg)\bigg\}\\&         \leq \pr\big[ Z^{\epsilon}_z(\tau_{\rho}^{\epsilon, z}  )\in\partial D\big]+2k\exp\bigg\{-\frac{1}{\epsilon^2}\bigg( V(z^*,\partial D)-\frac{\delta}{2}\bigg)\bigg\},       where we used \eqref{eq:lbaux1}, \eqref{eq:lbaux2} and the fact that $\theta^{\epsilon,z}_{m+1}\leq\tau^{\epsilon,z}_{m+1} $ almost surely. Letting $$k=k_0(\epsilon):=\bigg[\frac{1}{T_0}\exp\bigg\{ \frac{V( z^*,\partial D)-\delta      }{\epsilon^2} \bigg\}  \bigg]+1,$$ where $[\cdot]$ here is the integer part, we obtain the estimate      \pr\big[  \tau_D^{\epsilon,z}\leq e^{\frac{1}{\epsilon^2}(V( z^*,\partial D)-\delta  )     }  \big]\leq \pr\big[  \tau_D^{\epsilon,z}\leq k_0T_0   \big]\leq \pr\big[ Z^{\epsilon}_z(\tau_{\rho}^{\epsilon, z}  )\in\partial D\big]+Ce^{-\frac{\delta}{2\epsilon^2}}  which holds for $\epsilon$ sufficiently small. From an application of Lemma \ref{lem:smallballlimit} we conclude that the right-hand side converges to $0$ as $\epsilon\to 0.$ The argument is complete. \item Let $\delta>0.$ By Chebyshev's inequality we have     \epsilon^2\log\pr\bigg[  \tau_D^{\epsilon,z}>e^{\frac{1}{\epsilon^2}(V( z^*,\partial D)-\delta  )     }  \bigg] +V( z^*,\partial D)-\delta \leq \epsilon^2\log\ex[ \tau_D^{\epsilon,z}].        The statement follows by an application of part (1).",2502.01783
proof,"{\textit{(Of Theorem \ref{thm:exitshapeldp})}} Let $\tau^{\epsilon,z}_k$ be defined by \eqref{eq:donutStoppingtimes}         \item Given Lemmas \ref{lem:fastexcursions}-\ref{lem:rhoupperbound}, the proof is analogous to that of \cite[Theorem 5.7.11(b)]{dembo2009large}. For $z\in D, k\in\N, T>0$ we have                \pr\bigg[  Z^\epsilon_z(\tau_D^{\epsilon, z})&\in N   \bigg]= \pr\bigg[  Z^\epsilon_z(\tau_D^{\epsilon, z})\in N, \tau_D^{\epsilon, z}>\tau^{\epsilon, z}_k\bigg]\\&+\pr\bigg[  Z^\epsilon_z(\tau_D^{\epsilon, z})\in N, \tau_D^{\epsilon, z}=\tau_{m}^{\epsilon, z}         \;\text{for some}\;m\in\{0,\dots, k         \}\bigg]\\&         \leq \pr\bigg[ \tau_D^{\epsilon, z}>k T\bigg]+\pr\bigg[ \tau_k^{\epsilon, z}\leq k T \bigg]+\pr\bigg[ Z^\epsilon_z(\tau_{0}^{\epsilon, z})\in N   \bigg]\\&+\sum_{m=1}^{k}\pr\big[\tau_D^{\epsilon, z}> \tau^{\epsilon, z}_{m-1}    \big]\pr\bigg[ Z^\epsilon_z(\tau_{m}^{\epsilon, z})\in N  \bigg|\tau_D^{\epsilon, z}> \tau^{\epsilon, z}_{m-1}    \bigg]\\&         \leq \frac{1}{kT}\ex\big[ \tau_D^{\epsilon, z}\big]+ \pr\bigg[ Z^\epsilon_z(\tau_{0}^{\epsilon, z})\in N \bigg]\\&+k\sup_{z\in\gamma_{\rho}}\pr\bigg[ Z^{\epsilon}_z(t) \in \Gamma_\rho \text{ for some } t \in [0,T]   \bigg]+k\sup_{z\in\Gamma_\rho}\pr\bigg[Z^\epsilon_z(\tau_{0}^{\epsilon, z})\in N   \bigg],       where we used Chebyshev's inequality and the Markov property on the last line. Next let $\delta>0.$ From Lemma \ref{lem:fastexcursions}, we can find $T_0$ such that          \limsup_{\epsilon \to 0} \sup_{z \in \gamma_\rho} \epsilon^2 \log \pr\bigg[Z^{\epsilon}_z(t) \in \Gamma_\rho \text{ for some } t \in [0,T_0] \bigg]\leq -V_{\bar{D}}( z^*,N)+\delta.          Moreover, from Lemma \ref{lem:rhoupperbound} we can find $\rho$ such that               \limsup_{\epsilon \to 0} \sup_{z \in \Gamma_\rho} \epsilon^2 \log \pr\bigg[Z^\epsilon_z(\tau^{\epsilon,z}_0) \in N\bigg] \leq - V_{\bar{D}}(z^*,N)+\delta         (recall that $\tau^{\epsilon,z}_\rho=\tau^{\epsilon,z}_0).$  A combination of the last three displays, along with the exit time upper bound from Theorem \ref{thm:ExitTimeUpperBnd}(1)     implies                \pr\bigg[  Z^\epsilon_z(\tau_D^{\epsilon, z})\in N   \bigg]&\leq \frac{1}{kT_0}e^{(V(z^*, \bar{D}^c)+\delta   )/\epsilon^2}  \\&  +    2k\exp\bigg\{-\frac{1}{\epsilon^2}\bigg( V_{\bar{D}}(z^*,N)-\delta\bigg)\bigg\}+ \pr\bigg[ Z^\epsilon_z(\tau_{0}^{\epsilon, z})\in N \bigg].       Choosing $k=[e^{(V(z^*,\bar{D}^c)+2\delta   )/\epsilon^2}],$ (with $[\cdot]$ being the integer part), $$  0<\delta<\frac{V_{\bar{D}}(z^*, N)- V(z^*,\bar{D}^c)}{3}$$ and invoking Lemma \ref{lem:smallballlimit} we conclude that                   \limsup_{\epsilon\to 0} \pr\bigg[  Z^\epsilon_z(\tau_D^{\epsilon, z})\in N   \bigg]&\leq \limsup_{\epsilon\to 0}\pr\bigg[ Z^\epsilon_z(\tau_{0}^{\epsilon, z})\in N \bigg]\\&+\limsup_{\epsilon\to 0}\exp\bigg(-\frac{1}{\epsilon^2}(V_{\bar{D}}(z^*, N)-V(z^*,\bar{D}^c)-3\delta   )\bigg)=0.        The proof is complete.                                        \item The upper bound essentially follows from the estimates in  \eqref{eq:exitshapemainestimates}. In particular, for any initial condition $z\in\gamma_\rho$ we have $\pr[Z_z^\epsilon(\tau_1^{\epsilon, z})\in N]=0.$ Hence, using the exact same arguments as in the proof of part (1) we get for any $\delta>0$     $$\limsup_{\epsilon\to 0}\epsilon^2\log\sup_{z\in\gamma_\rho}\pr\bigg[Z^\epsilon_z(\tau^{\epsilon, z}_{D})\in N\bigg]\leq -V_{\bar{D}}(z^*,N)+V(z^*,\bar{D}^{c})+3\delta=     -\inf_{y\in N}J_1(y)+3\delta.$$    For $z\in D\setminus\gamma_\rho,$ Lemma \ref{lem:smallballlimit} and the strong Markov property furnish the asymptotic estimates     $$ \lim_{\epsilon\to 0}\pr\bigg[Z^\epsilon_z(\tau^{\epsilon, z}_{\rho})\in \gamma_\rho   \bigg]=1$$     and                \limsup_{\epsilon\to 0}\epsilon^2\log\pr\bigg[Z^\epsilon_z(\tau^{\epsilon, z}_{D})\in N\bigg]&\leq \limsup_{\epsilon\to 0}\epsilon^2\log\bigg(\pr\bigg[Z^\epsilon_z(\tau^{\epsilon, z}_{\rho})\in \gamma_\rho   \bigg]\sup_{y\in\gamma_\rho}\pr\bigg[Z^\epsilon_y(\tau^{\epsilon, z}_{D})\in N\bigg]\bigg) \\&\leq -\inf_{y\in N}J_1(y)+3\delta.               Since $\delta$ is arbitrary, the argument is complete. \item  \noindent We break the proof in two steps. In \textbf{Step 1} we discuss the case of initial data $z\in\gamma_\rho$, while in \textbf{Step 2} we consider initial data $z\in D\setminus\gamma_\rho$.   \noindent \textbf{Step 1:} We start by showing that \eqref{eq:exitshapelb} holds uniformly over initial data $z\in\gamma_\rho$ and $\rho$ sufficiently small. Recalling the Markov chain \eqref{eq:Markovchain}, let $$\zeta^{\epsilon, z}=\inf\big\{ n\in\N: Z^{\epsilon,z}_n\notin\gamma_\rho \big\}$$ and note that        \pr\bigg[\big|Z^\epsilon_z(\tau^{\epsilon, z}_{D})-y\big|_{\e}<\eta\bigg]=\pr\bigg[Z^{\epsilon, z}_{\zeta^{\epsilon,z}}\in B_{\partial D}(y, \eta)\bigg],       where the subscript $\partial D$ indicates that the ball is taken in the subspace topology of $\partial D.$ By virtue of the strong Markov property we have (with $Z^{\epsilon, z}_{0}\equiv  Z_z^{\epsilon, z}(\tau^{\epsilon,z}_\rho)$)             \pr\bigg[\big|Z^\epsilon_z(\tau^{\epsilon, z}_{D})-y\big|_{\e}<\eta\bigg]&=\sum_{k=0}^{\infty}\pr\bigg[\zeta^{\epsilon,z}=k,\;Z^{\epsilon, z}_{\zeta^{\epsilon,z}}\in B_{\partial D}(y, \eta)\bigg]\\&     \geq \sum_{k=1}^{\infty}\inf_{z\in\gamma_\rho}\pr\bigg[ Z^{\epsilon, z}_{0}\in \gamma_\rho \bigg]^{k-1}\inf_{z\in\gamma_\rho}\pr\bigg[Z^{\epsilon, z}_{0}\in B_{\partial D}(y, \eta) \bigg] \\&=\frac{\inf_{z\in\gamma_\rho}\pr\bigg[Z^{\epsilon, z}_{0}\in B_{\partial D}(y, \eta)  \bigg]}{1-\inf_{z\in\gamma_\rho}\pr\bigg[ Z^{\epsilon, z}_{0}\in \gamma_\rho \bigg]} \\&  \geq \frac{\inf_{z\in\gamma_\rho}\pr\bigg[Z^{\epsilon, z}_{0}\in B_{\partial D}(y, \eta)  \bigg]}{\sup_{z\in\gamma_\rho}\pr\bigg[ Z^{\epsilon, z}_0\notin \gamma_\rho \bigg]}.    An upper bound for the denominator follows from Lemma \ref{lem:rhoupperbound} with $N=\partial D.$ Indeed, for $\delta>0,$ there exist $\rho, \epsilon$ sufficiently small such that                \sup_{z\in\gamma_\rho}\pr\bigg[ Z^{\epsilon, z}_{0}\notin \gamma_\rho \bigg]=\sup_{z\in\gamma_\rho}\pr\bigg[ Z^{\epsilon, z}_{0}\in\partial D \bigg]=\sup_{z\in\gamma_\rho}\pr\bigg[ Z^{\epsilon}_z(\tau^{\epsilon, z}_\rho)\in\partial D \bigg]\leq e^{ -\big(V(z^*, \partial D)+\delta\big)/\epsilon^2}.       \noindent In order to obtain a lower bound for the numerator we make use of the following:\\ \noindent \textbf{Claim:} For any $\delta>0$, there exist $T_0>0, r>0$, and $\rho>0$ such that for any $ z \in \gamma_\rho$ there exists a controlled path $\phi_z \in C([0,T_0];\e)$ such that  $\phi_z(0)=z$, %$\phi(t)\in D$ for all $t\in [0,T_0]$  $$I_{z,T_0}(\phi_z)<V_D(z^*, y)+\delta$$  and $$\big\{|Z^{\epsilon}_z-\phi_z|_{C([0,T_0];\e)}<r\big\}\subset \big\{Z^{\epsilon, z}_{0}\in B_{\partial D}(y, \eta)   \big\}.  $$ \noindent The latter, along with the LULDP lower bound \eqref{eq:LULDP-lower}, immediately yield               \liminf_{\epsilon\to 0}\inf_{z\in\gamma_\rho}\bigg\{\epsilon^2\log\pr\bigg[Z^{\epsilon, z}_{0}\in B_{\partial D}(y, \eta)  \bigg]+I_{z,T_0}(\phi_z)\bigg\} \geq 0.       Then, the combination of \eqref{eq:exitshapeLB:numerator} and \eqref{eq:exitshapeLB:denominator} furnishes             \liminf_{\epsilon\to 0}\inf_{z\in\gamma_\rho}\epsilon^2\log \pr\bigg[\big|Z^\epsilon_z(\tau^{\epsilon, z}_{D})-y\big|_{\e}<\eta\bigg]&\geq V(z^*, \partial D)-  V_D(z^*, y)   -    2\delta=-J_2(y)-2\delta   which concludes the proof of Step 1 since $\delta$ can be taken to be arbitrarily small.       \textit{Proof of Claim:} Turning to the construction of $\phi_z,$ we assume without loss of generality that $V_D(z^*, y)<\infty$ (otherwise the lower bound holds trivially). Thus, there exists $T>0$ a control $v_1$ with        \frac{1}{2}|v_1|^2_{L^2([0, T];H)}<V_D(z^*, y)+\delta/2    and a controlled path $\phi_1:=Z^{v_1}_{z^*}\in C([0,T];\e)$ with  $\phi_1(0)=z^*, \phi_1(T)=y$ and $\phi_1(t)\in D$ for all $t\in[0, T ).$ From the regularity of the boundary point $y,$ there exists a controlled path $\phi_2:=Z_y^{v_2}$ such that $\{\phi_2(t);\;t\in[0,t_0]\}\subset\bar{D}^c$ and      \frac{1}{2}|v_2|^2_{L^2([0,t_0];H)}<\frac{\delta}{2}.   Because $\phi_2(t)$ is continuous in $\e$, there exists $T_1 \in (0,t_0)$ such that for all $t \in (0,T_1)$,  $|\phi_2(t)-y|_{\e}<\eta/3.     $  Define $\phi_{z^*}\in C([0,T+T_1];\e),$ as the concatenation of $\phi_1$ and  $\phi_2$. This trajectory has the properties that $\phi_{z^*}(0)=z^*, \phi_{z^*}(T+T_1)=\phi_2(T_1)=:y'\in \bar{D}^c,$                 |\phi_{z^*}(t)-y|_{\e}<\eta/3,\;\; \text{ for all } t\in[T, T+T_1]       and in view of \eqref{eq:v1action}, \eqref{eq:v2action}      I_{z^*, T+t_0}(\phi_{z^*})<V_D(z^*,  y)+\delta.   Because $\phi_{z^*}(t) \in D$ for all $t \in [0,T)$,  $|\phi_{z^*}(t) -y|< \frac{\eta}{3}$ for $t \in [T, T+T_1]$, and $\phi_{z*}(T+T_1) \in \bar{D}^c$ there exists a small $\tilde{\eta} \in \left(0,\frac{\eta}{3} \wedge \textnormal{dist}_\e(y',D) \right)$ such that any trajectory $\psi \in C([0,T + T_1];\e)$ with the property that       \sup_{t \in [0,T + T_1]}|\phi_{z^*}(t) - \psi(t)|_\e< \tilde{\eta},  will have the properties that $\psi$ exits $D$ and its exit location is within $\eta$ of $y$.  %Next, let $$\tilde\eta:=\frac{1}{2}\bigg(\textnormal{dist}_{\e}(y', \bar D)\wedge\frac{\eta}{3}\bigg) $$ and  Define a control      u(t)=            v_1(t),&\;\;t\in[0,T]\\            v_2(t-T),&\;\;t\in[T,T+T_1]       so that $\phi_{z^*}=Z_{z^*}^u.$ We use the continuity of the skeleton equation with respect to initial conditions, Lemma \ref{lem:controliccontinuity}, to deduce that there exists $\rho>0$ such that for any $z\in\gamma_{\rho}$         \sup_{t\in[0,T+T_1]}|Z^u_{z^*}(t)-Z^u_{z}(t)|_{\e}= \sup_{t\in[0,T+T_1]}|\phi_{z^*}(t)-Z^u_{z}(t)|_{\e}<\frac{\tilde\eta}{3}.  Then $T_0 := T + T_1$, $r := \frac{\tilde \eta}{3}$, and $\phi_z:= Z^u_z$ are the quantities that we claimed existed. From \eqref{eq:phiaction}, $I_{z,T_0}(\phi_z)< V_D(z^*, y) + \delta$. If a random trajectory $Z^\epsilon_z$ has the properties that       \sup_{t \in [0,T_0]} | Z^\epsilon_z - \phi_z|_\e<r,  then by the triangle inequality,     \sup_{t \in [0,T_0]} |Z^\epsilon_z(t) - \phi_{z^*}(T)|_\e < \sup_{t \in [0,T_0]} |Z^\epsilon_z(t) - \phi_{z}(t)|_\e + \sup_{t \in [0,T_0]} |\phi_z(t) - \phi_{z^*}(t)|_\e < \tilde{\eta}.  Therefore, by \eqref{eq:exit-tube}, the random path must exit $D$ and its exit location must be within $\eta$ of $y$.  \noindent \textbf{Step 2:} It remains to prove \eqref{eq:exitshapelb} for initial data $z\in D\setminus\gamma_\rho.$ This follows by uniform attraction to $z^*,$  the strong Markov property and the previous step. Indeed, from Lemma \ref{lem:smallballlimit}, for $\rho$ sufficiently small we have  $$\lim_{\epsilon\to 0}\pr\bigg[Z^\epsilon_0\in \gamma_\rho   \bigg]= \lim_{\epsilon\to 0}\pr\bigg[Z^\epsilon_z(\tau^{\epsilon, z}_{\rho})\in \gamma_\rho   \bigg]=1$$     and                     \liminf_{\epsilon\to 0}\epsilon^2\log\pr\bigg[ |Z^\epsilon_z(\tau^{\epsilon, z}_{D})-y|_{\e}<\eta \bigg]         &\geq \liminf_{\epsilon\to 0}\epsilon^2\log\bigg(\pr\bigg[Z^\epsilon_0\in \gamma_\rho   \bigg]\inf_{z\in\gamma_\rho}\pr\bigg[ |Z^\epsilon_z(\tau^{\epsilon, z}_{D})-y|_{\e}<\eta \bigg] \bigg)\\&         \geq -J_2(y)-2\delta.                       The proof is complete.",2502.01783
proof,"By continuity of controlled paths and monotonicity of $I_{z^*, T}$ in $T$ it is clear that $V(z^*, \bar{D}^c)\geq V(z^*, \partial D).$ In order to show the reverse inequality       $V(z^*, \bar{D}^c)\leq V(z^*, \partial D)$       let $\eta>0.$ By Assumption \ref{Assumption:MinimizingRegularPoints} there exist $T>0,$ a regular boundary point $ z\in\partial D\cap\mathcal{R}$ and $\phi_1\in C([0,T];\e)$ such that $\phi_1(0)=z^*, \phi_1(T)=z$ such that        $$  I_{z^*,T}(\phi_1)\leq V(z^*, \partial D)+\eta/3.     $$       In turn, there exists  $u\in L^2([0,T];H)$ such that $\phi_1=Z_{z^*}^u$ and        $$ \frac{1}{2} |u|^2_{L^2([0,T];H)}<V(z^*, \partial D)+2\eta/3.$$       Since $z^*\in\h_1,$ it follows by regularity properties of the skeleton equation that $z=\phi_1(T)=Z_{z^*}^u(T)\in\h_1\cap\partial D.$ In order to conclude, we use the regularity of $z$ to find an exterior point $z''\in\bar{D}^c$ and a controlled path $\phi_2=Z_z^v$ and $T_1>0$ with $\phi_2(T_1)=Z_z^v(T_1)=z''$ and $\frac{1}{2}|v|_{L^2([0,T];H)}^2<\eta/3.$ Therefore, letting $\phi\in C([0,T+T_1];\e)$ be the concatenation of $\phi_1, \phi_2$ we see that        $\phi(0)=z^*, \phi(T+T_1)=z''\in\bar{D}^c$ and            $$  V(z^*, \bar{D}^c)\leq I_{0,T+T_1}(\phi)< \frac{1}{2}|v|_{L^2([0,T];H)}^2+V(z^*, \partial D)+2\eta/3<  V(z^*, \partial D)+\eta.$$",2502.01783
proof,"It suffices to prove well-posedness for $\epsilon=1.$ To this end, we recall the localization $b_n$ \eqref{eq:bnlocalization}. As in Proposition \ref{prop:WellPosedness} we consider the localized problem    	  		dZ^{h}_n(t)=A_\alpha Z^{h}_n(t)dt+B_n(Z_n^{ h}(t))dt+\Sigma\big(Z^{h}_n(t)\big)h(t)dt+\Sigma\big(Z^{h}_n(t)\big)dW(t)\;, Z^{h}_n(0)=z\in\e  	   which, from the same proposition, has a unique solution $Z^{h}_n\in L^p(\Omega;     C([0,T_0]; \e).$ Next we consider the family of stopping times   	\tau_{n}:=\inf\{t>0 : |\Pi_1 Z^{h}_{n}(t)|_{\infty}\geq n\}  and aim to show that $$ \pr\bigg( \tau:=	\sup_{n\in\N}\tau_n<\infty\bigg)=\lim_{T\to\infty}\lim_{n\to\infty}\pr(\tau_n\leq T)=0.$$ This in turn implies that \eqref{eq:controlledequation} admits a unique, global mild solution per Definition \ref{dfn:mild solutions}.   To this end, we pass to the mild formulation       	        	        	        	   \Pi_1Z_{n}^{h}(t)&=\Pi_1S_\alpha(t)z+\int_{0}^{t}\Pi_1S_\alpha(t-s)B_n(Z_{n}^{h}(s))ds+\int_{0}^{t}\Pi_1S_\alpha(t-s)\Sigma(Z_{n}^{h}(s))h(s)ds\\&+\Pi_1\int_{0}^{t}S_\alpha(t-s)\Sigma(Z_{n}^{h}(s))dW(z)\\&     	   =:\Pi_1S_\alpha(t)z+\Pi_1\rho_{n}(t)+\Pi_1H_{n}(t)+\Pi_1\Gamma_{n}(t).     	        	        	  In view of Lemma \ref{lem:StochasticConvolutionApriori} and using the boundedness of $\sigma$ (Assumption \ref{Assumption:sigmaGlobal}) we have the estimate     	        	   \sup_{n\in\N}\ex|\Pi_1\Gamma_{n}|^p_{\infty}\leq C.     	        	   Moreover, from the continuity of $S$ in $\h_{1}$ and Theorem \ref{thm:Linftydecay} we have      	        	        	   |\Pi_1H_{n}(t)|_{H^1}&\leq \int_{0}^{t}\big| S_\alpha(t-s)\Sigma(Z_{n}^{h}(s))h(s)   \big|_{\h_1}ds%\\&\leq \int_{0}^{t}\big| S(t-s)\Sigma(Z_{n}^{h}(s))h(s)   \big|_{\h_1}ds     	   \\&     	   \leq C\int_{0}^{t}e^{-\theta(t-s)}\big|\Sigma(Z_{n}^{h}(s))h(s)   \big|_{\h_1}ds\\&=C\int_{0}^{t}e^{-\theta(t-s)}\big|\sigma(\Pi_1Z_{n}^{h}(s))h(s)   \big|_{L^2}ds\leq C_T|\sigma|_{\infty}|h|_{L^2([0,T];H)}     	         	        	 and      	       	      	    |\Pi_1S_\alpha(t)z|_{\infty}\leq Ce^{-\theta t}|z|_{\e}.     	      	      	   The term $\Pi_1\rho_{n}$ solves the nonlinear wave equation     	         	   \left\{     	   &\partial_t^2\Pi_1 \rho_{n}(t,\xi)=     	   \partial_\xi^2 \Pi_1\rho_{n}(t,\xi)-\alpha\partial_t\Pi_1 \rho_{n}(t,\xi) +b_n\big(\Pi_1 Z_{n}^{h}(t,\xi)\big)\;,\;\;(t,\xi)\in [0,\infty)\times(0,\ell)     	   \\&\Pi_1\rho_{n}(0,\xi)=0, \partial_t \Pi_1\rho_{n}(0,\xi)=0,\;  \xi\in(0,\ell),\; \Pi_1\rho_{n}(t,\xi)=0,\; (t,\xi)\in[0,\infty)\times\{0,\ell\}.     	   \right.     	        	   Multiplying throughout by $\partial_t\Pi_1 \rho_{n}$ and integrating over $[0,\ell]$ we obtain the estimate     	        	        	       	   \frac{d}{dt}\big|\partial^2_t\Pi_1 \rho_{n}(t)\big|^2_{H}&+	\frac{d}{dt}\big| \Pi_1\rho_{n}(t)\big|     	   ^2_{H^1}+2\alpha \big|\partial_t\Pi_1 \rho_{n}(t)\big|^2_{H}\\&\leq 2C_2\frac{d}{dt}\int_{0}^{\ell}\hat{\beta}_n\big( \Pi_1\rho_n(\xi, t) \big)d\xi\\&+\big|b_n\big(\Pi_1 \rho_n(t)+\Pi_1S_\alpha(t)z+\Pi_1H_{n}(t)+\Pi_1\Gamma_{n}(t)\big)-b_n\big(\Pi_1 \rho_n(t)\big)     	   \big|^2_{H}+\big|  \partial_t\Pi_1\rho_{n}(t) \big|^2_{H}     	        	        	   which holds for any $n\in\N$ and $\hat{\beta}_n$ is a Lipschitz approximation of the function     	        	        -\hat\beta(x):=1-\beta(x)/C_2\geq |x|^{\lambda+1},     	             	        $\lambda \in(1,3]$     	   and $\beta, C_2$ are given in \eqref{antidercond}. Now, for $n\geq n_0$ sufficiently large we can proceed as in \cite[pp. 678-679 ]{cerrai2006smoluchowski} to obtain      	        	        	  \frac{d}{dt}\big|\partial^2_t\Pi_1 \rho_{n}(t)\big|^2_{H}&+	\frac{d}{dt}\big| \Pi_1\rho_{n}(t)\big|^2_{H^1}+2\alpha \big|\partial_t\Pi_1 \rho_{n}(t)\big|^2_{H}\\&-2C_2\frac{d}{dt}\int_{0}^{\ell}\hat{\beta}_n\big(\Pi_1 \rho_n(\xi, t) \big)d\xi\leq C\bigg[1+(\Lambda_n)^{2\lambda}   \bigg]+C(\Lambda_n)^2\bigg(-\int_{0}^{\ell}\hat{\beta}_n\big( \Pi_1\rho_n(\xi, t) \big)d\xi\ \bigg),     	        	        	        	   \noindent where $$ \Lambda_n=\sup_{t\in[0,T]}|\Pi_1S_\alpha(t)z|_{\infty}+\sup_{t\in[0,T]}|\Pi_1H_{n}(t)|_{\infty}+\sup_{t\in[0,T]}|\Pi_1\Gamma_{n}(t)|_{\infty}.$$     	   In view of Assumption \ref{Assumption:bGlobal} and in particular the fact that      	   $$\sup_{n\in\N}|b_n(x)|\leq c(1+|x|^{\lambda}),$$     	   we can integrate the previous inequality over $t\in[0,T]$ and apply Gr\""onwall's lemma to  obtain     	          	        	  \sup_{t\in[0,T]}\bigg(\big|\partial^2_t\Pi_1 \rho_{n}(t)\big|^2_{H}&+\big| \Pi_1\rho_{n}(t)\big|^2_{H^1}-2C_2\frac{d}{dt}\int_{0}^{\ell}\hat{\beta}_n\big( \Pi_1\rho_n(\xi, t) \big)d\xi\bigg)     	  +\int_{0}^{T}\big|\partial_t\Pi_1 \rho_{n}(t)\big|^2_{H}dt\\&\leq C\bigg[1+(\Lambda_n)^{2\lambda}   \bigg]\exp\bigg( c(\Lambda_n)^{2}T   \bigg),     	        	        	   where the constants are independent of the initial conditions and $n$. In particular,     	        	   \big| \Pi_1\rho_{n}(t)\big|^2_{\infty}\leq c\big|  \Pi_1\rho_{n}(t)\big|^2_{H^1}\leq     	   C\bigg[1+(\Lambda_n)^{2\lambda}   \bigg]\exp\bigg( c(\Lambda_n)^{2}T   \bigg).     	        	   Thus, for any $n\geq n_0$ we have      	        	         	   \pr\bigg[  \sup_{t\in[0,T]}\big|   \Pi_1Z_{n}^{h}(t)\big|_{\infty}\geq n   \bigg]&\leq \pr\bigg[ \sup_{t\in[0,T]}|\Pi_1\Gamma_{n}(t)|_{\infty}\geq n/4 \bigg]+\pr\bigg[  \sup_{t\in[0,T]}|\Pi_1H_{n}(t)|_{\infty}\geq n/4 \bigg]\\&     	   +\pr\bigg[\sup_{t\in[0,T]}|\Pi_1S_\alpha(t)z|_{\infty}\geq n/4\bigg]+\pr\bigg[C\bigg[1+(\Lambda_n)^{2\lambda}   \bigg]\exp\bigg( c(\Lambda_n)^{2}T\bigg)\geq n/4\bigg]\\&     	   \leq \frac{4}{n}\ex[\Lambda_n ]+\pr[  \Lambda_n\geq f_T(n)   ]\leq \bigg(\frac{4}{n}+\frac{1}{f_T(n)}\bigg)\ex[\Lambda_n]     	        	        	   where $f_T$ is the inverse of the function $x\mapsto C[1+x^{2\lambda } ]\exp( cx^{2}T)$     	   which diverges to $\infty$ as $x\to\infty.$ In view of \eqref{Ubnd}, \eqref{zbnd}, \eqref{convobnd} we deduce that      	        	         	  \pr\bigg[  \sup_{t\in[0,T]}|\Pi_1Z_{n}^{h}(t)|_{\infty}\geq n   \bigg]&\leq C \bigg(\frac{4}{n}+\frac{1}{f_T(n)}\bigg)\big(  1+|h|_{H}+|z|_{\e}\big).     	        	        	   Hence,      	   $$\lim_{T\to\infty}\lim_{n\to\infty}\pr[ \tau_n\leq T   ]=\lim_{T\to\infty}\lim_{n\to\infty}\pr\bigg[  \sup_{t\in[0,T]}\big|   \Pi_1Z_{n}^{h}(t)\big|_{\infty}\geq n   \bigg]=0$$     	    and the proof is complete.",2502.01783
proof,"\item  Let $G(t):= \Pi_1S_\alpha(t)z$ and $$\rho=\Pi_1Z^u_{z}-G$$ solve the skeleton equation starting from $0$. From an energy estimate similar to the one used in Proposition \ref{prop:WellPosednessGlobal} (notice that here we require that the growth exponent of $b$ satisfies $\lambda\in(1,3]$) we have          \frac{d}{dt}\big|\partial_t\rho(t)\big|^2_{H}&+\frac{d}{dt}\big|\rho(t)\big|^2_{H^1}+2\big|\partial_t\rho(t)\big|^2_{H}=2\langle b(\Pi_1Z^u_{z}(t)),\; \partial_t\rho(t)\rangle_{H}+2\langle \sigma(\Pi_1Z^u_{z}(t))u(t),\; \partial_t\rho(t)\rangle_{H}\\& \leq 2c_2\frac{d}{dt}\int_{0}^{\ell}\hat{\beta}(\rho(\xi, t))d\xi+\big| b(\rho(t)+G(t))-b(G(t)) \big|^2_{H}+|\sigma|^2_\infty|u(t)|^2_{H}+2\big|\partial_t\rho(t)\big|^2_{H},   where we used the chain rule, the inequality $2\langle x, y\rangle\leq |x|^2+|y|^2$ and Assumption \ref{Assumption:sigmaGlobal}. In view of Assumption \ref{Assumption:bGlobal}, we can then follow the same line of reasoning to obtain    \sup_{t\leq T}\big|\rho(t)\big|^2_{H^1}&+\sup_{t\leq T}\big|\partial_t\rho(t)\big|^2_{H}\\&\leq \bigg[C\bigg(T+T\sup_{t\in[0,T]}|G(t)|^{2\lambda}_{\infty}+|\sigma|^2_\infty\int_{0}^{T}|u(t)|^2_{H}dt\bigg)\bigg]\exp\big(cT\sup_{t\in[0,T]}|G(t)|^{2}_{\infty}\big)   and from Theorem \ref{thm:Linftydecay} we obtain   \sup_{t\in[0,T]}|G(t)|^{2}_{\infty}\leq C\sup_{t\in[0,T]}e^{-\theta t}|z|_{\mathcal{E}}\leq C|z|_{\mathcal{E}}.    Thus, by Sobolev embedding we have    &\sup_{t\leq T}\big|Z^{u}_{z}(t)\big|^2_{\mathcal{E}}\leq 2\sup_{t\leq T}\big|\Pi_1Z^{u}_{z}(t)\big|^2_{\infty}+2\sup_{t\leq T}\big|\partial_t\Pi_1Z^{u}_{z}(t)\big|^2_{C^{-1}}\\&\leq C\bigg(\sup_{t\leq T}\big|\rho(t)\big|^2_{H^1}+\sup_{t\leq T}\big|\partial_t\rho(t)\big|^2_{H}\bigg)+ \sup_{t\leq T}\big|\Pi_1S_\alpha(t)z\big|^2_{\infty}+\sup_{t\leq T}\big|\Pi_2S_\alpha(t)z\big|^2_{C^{-1}}\\& \leq C\bigg[T(1+|z|^{2\lambda}_{\e})+|\sigma|^2_\infty N\bigg]\exp\big(cT|z|^2_\mathcal{E}\big)+C |z|^2_{\e}.   The proof is complete.     \item  	Since the weak topology on bounded sets is metrizable, it suffices to consider a sequence $\{(z_n, u_n)\}_{n\in\N}\subset\mathcal{U}_N\times\e$ that converges weakly, as $n\to\infty,$ to a pair $(z, u)\in\mathcal{U}_N\times\e.$ For $t\in[0,T]$ we have    |Z^{u_n}_{z_n}(t)-Z^{u}_{z}(t)\big|_{\e}&\leq \big| S_\alpha(t)(z_n-z)\big|_{\e}+\int_{0}^{t}\bigg| S_\alpha(t-s)\big[B(Z^{u_n}_{z_n}(s))- B(Z^{u}_{z}(s))\big]\bigg|_{\e}ds\\& +\bigg|\int_{0}^{t} S_\alpha(t-s)\big[\Sigma(Z^{u_n}_{z_n}(s))u_n(s)- \Sigma(Z^{u}_{z}(s))u(s)\big]ds\bigg|_{\e}   From Assumption \ref{Assumption:bGlobal}, Assumption \ref{Assumption:sigmaGlobal} and Theorem \ref{thm:Linftydecay} we obtain    |Z^{u_n}_{z_n}(t)-Z^{u}_{z}(t)\big|_{\e}& \leq C| z_n-z|_{\e}+C|b_1|_{Lip}\int_{0}^{t}\big|\Pi_1Z^{u_n}_{z_n}(s)-\Pi_1Z^{u}_{z}(s)|_{H}ds\\&+C\int_{0}^{t} \big|b_2(\Pi_1Z^{u_n}_{z_n}(s))- b_2(\Pi_1Z^{u}_{z}(s))\big|_{H}ds\\& +|\sigma|_{\infty}\int_{0}^{t}\big|\Pi_1Z^{u_n}_{z_n}(s)-\Pi_1Z^{u}_{z}(s)|_{C_0(0,\ell)}|u_n(s)|_{H}ds\\& +C\sup_{t\in[0,T]}\bigg|\int_{0}^{t}S_\alpha(t-s) \Sigma(Z^{u}_{z}(s))\big[u_n(s)-u(s)\big]ds\bigg|_{\e}.    \noindent Now from \cite{cerrai2006smoluchowski}, Lemma 2.4 (notice that the latter requires Assumption \ref{Assumption:bGlobal};see also pp.678 of the same reference), along with the a-priori bound \eqref{ZaprioriGlobal} and the uniform bound on $u_n$ we have    \big|b_2(\Pi_1Z^{u_n}_{z_n}(s))&- b_2(\Pi_1Z^{u}_{z}(s))\big|^2_{H}\\&\leq c\int_{0}^{\ell}\bigg(1-\hat{\beta}\big(\Pi_1Z^{u_n}_{z_n}( \xi,s)\big)+|\Pi_1Z^{u_n}_{z_n}(\xi,s)-\Pi_1Z^{u}_{z}(\xi,s) |^{2(\lambda-1)}\bigg)|\Pi_1Z^{u_n}_{z_n}(\xi,s)-\Pi_1Z^{u}_{z}(\xi,s) |^2d\xi\\& \leq C\bigg(1+\sup_{t\in[0,T]}|\Pi_1Z^{u_n}_{z_n}(t)|^{\lambda+1}_{\infty}+\sup_{t\in[0,T]}|\Pi_1Z^{u_n}_{z_n}-\Pi_1Z^{u}_{z}(t)|^{2(\lambda-1)}_{\infty}\bigg)|\Pi_1Z^{u_n}_{z_n}(s)-\Pi_1Z^{u}_{z}(s)\big|^2_{H}\\& \leq C_{\lambda}\bigg(1+\sup_{t\in[0,T]}|Z^{u_n}_{z_n}(t)|^{\lambda+1}_{\e}+\sup_{t\in[0,T]}|Z^{u}_{z}(t)|^{2(\lambda-1)}_{\e}       \bigg)|\Pi_1Z^{u_n}_{z_n}(s)-\Pi_1Z^{u}_{z}(s)\big|^2_{H}\\& \leq \tilde{C}|\Pi_1Z^{u_n}_{z_n}(s)-\Pi_1Z^{u}_{z}(s)\big|^2_{H},   \noindent with $\lambda$ as in Assumption \ref{Assumption:b},  $\hat{\beta}$ as in (\ref{Eq:betahat}) and  the constant $\tilde{C}$ in the last line takes the form  $$C_{\sigma, N, \lambda, T }\bigg[ 1+(1+\sup_n|z_n|^{\lambda(\lambda+1)}+|z|^{2\lambda(\lambda-1)})\bigg(e^{cT\sup_n|z_n|^2_{\e}}+ e^{cT|z|^2_{\e}}     \bigg)+C\big(\sup_n|z_n|^{\lambda+1}_\e+|z|^{2\lambda(\lambda-1)}_\e\big)     \bigg].$$  In view of this estimate, \eqref{Zcontbnd1Global} yields   |Z^{u_n}_{z_n}(t)-Z^{u}_{z}(t)\big|^2_{\e}& \leq C| z_n-z|^2_{\e}+CT^{1/2}\int_{0}^{T}\big|Z^{u_n}_{z_n}(s)-Z^{u}_{z}(s)|^2_{\e}ds\\&+\tilde{C}T^{1/2}\int_{0}^{T} |Z^{u_n}_{z_n}(s)-Z^{u}_{z}(s)\big|^2_{\e}ds\\& +|\sigma|_{\infty}\sup_{n\in\N}|u_n|^2_{L^2([0,T];H)}\int_{0}^{T}\big|Z^{u_n}_{z_n}(s)-Z^{u}_{z}(s)|^2_{\e}ds\\& +C\sup_{t\in[0,T]}\bigg|\int_{0}^{t}S_\alpha(t-s) \Sigma(Z^{u}_{z}(s))\big[u_n(s)-u(s)\big]ds\bigg|^2_{\e}.   Thus, Gr\""onwall's inequality furnishes   \sup_{t\in[0,T]}|Z^{u_n}_{z_n}(t)-Z^{u}_{z}(t)\big|^2_{\e}& \leq Ce^{C_{\sigma, b_1, \lambda, N, T}}\bigg(| z_n-z|^2_{\e}+\sup_{t\in[0,T]}\bigg|\int_{0}^{t}S_\alpha(t-s) \Sigma(Z^{u}_{z}(s))\big[u_n(s)-u(s)\big]ds\bigg|^2_{\e}\bigg).   From Lemma \ref{lem:Zaprioricompactnesslem} with $Z=Z^{u}_{z},$ the latter vanishes as $n\to\infty$ and the conclusion follows. \item  For $t\leq T$ we have      Z_z^u(t)-Z_z^0(t)=\int_{0}^tS_\alpha(t-s)\big[b(  Z_z^u(s))- b(  Z_z^0(s))\big]ds+\int_{0}^tS_\alpha(t-s)\sigma(  Z_z^u(s))u(s)ds.  Since $\sigma$ is bounded, the second term on the right hand side satisfies                 \bigg|\int_{0}^tS_\alpha(t-s)\sigma(  Z_z^u(t))u(t)dt\bigg|_{\e}&\leq C \bigg|\int_{0}^tS_\alpha(t-s)\sigma( Z_z^u(t))u(t)dt\bigg|_{\h_1}\\&\leq C|\sigma|_{\infty}\int_{0}^{t}e^{-\theta(t-s)} |u(s)|^2_{\h}ds\leq C|\sigma|_{\infty} |u|^2_{L^2([0,T];H)}.       As for the first term, a bound similar to \eqref{eq:bdifferencebound} yields        \bigg|\int_{0}^{t}S_\alpha(t-s)\big[b(  Z_z^u(s))&- b(  Z_z^0(s))\big]ds\bigg|^2_{\e}\\&\leq \bigg(1+\sup_{t\in[0,T]}|Z^{u}_{z}(t)|^{\lambda+1}_{\e}+\sup_{t\in[0,T]}|Z^{0}_{z}(s)|^{2(\lambda-1)}_{\e}       \bigg)\int_{0}^{T}\sup_{r\leq s}|Z^{u}_{z}(r)-Z^{0}_{z}(r)|^2_{\e} ds,     with $\lambda$ as in Assumption \ref{Assumption:bGlobal}.  From the boundedness of $D$ and the estimates in Lemma \ref{lem:Zaprioricompactnesslem} (see in particular \eqref{eq:skeletonBound}) we obtain the bound   &\sup_{z\in D}\bigg(  \sup_{t\in[0,T] }\big|Z^{u}_{z}(t)\big|^2_{\mathcal{E}}+         \sup_{t\in[0,T] }\big|Z^{0}_{z}(t)\big|^2_{\mathcal{E}}\bigg) \leq C_{D, T}\bigg[1+|u|^2_{L^2([0,T];H)} \bigg].   Combining the last two displays it follows that       \bigg|\int_{0}^{t}S_\alpha(t-s)\big[b(  Z_z^u(s))&- b(  Z_z^0(s))\big]ds\bigg|^2_{\e}\\&\leq C_{T, D, \lambda }\bigg(1+|u|_{L^2([0,T];H)}^{2\lambda+2}+|u|_{L^2([0,T];H)}^{4(\lambda-1)}     \bigg)\int_{0}^{T}\sup_{r\leq s}|Z^{u}_{z}(r)-Z^{0}_{z}(r)|^2_{\e} ds.     The latter along with \eqref{eq:sigmacontrol} then furnish  $$| Z_z^u-Z_z^0|^2_{C([0,T];\e)}\leq C_1\bigg(1+|u|_{L^2([0,T];H)}^{2\lambda+2}+|u|_{L^2([0,T];H)}^{4(\lambda-1)}     \bigg)\int_{0}^{T}\sup_{r\leq s}|Z^{u}_{z}(r)-Z^{0}_{z}(r)|^2_{\e}ds+C_2 |u|^4_{L^2([0,T];H)}.   $$ From Gr\""onwall's inequality we may conclude   | Z_z^u-Z_z^0|^2_{C([0,T];\e)}\leq C|u|^4_{L^2([0,T];H)}\exp\bigg\{C'\bigg(|u|_{L^2([0,T];H)}^{2\lambda+2}+|u|_{L^2([0,T];H)}^{4(\lambda-1)}\bigg)     \bigg\}  for some constants $C, C'>0.$  The proof is complete upon observing that the function $$\Lambda(x)=Cx^4\exp(C'(x^{2\lambda+2}+x^{4(\lambda-1)})/2), x\geq 0$$ satisfies the desired properties.",2502.01783
proof,"The (global) ULDP is equivalent to an Equicontinuous Uniform Laplace Principle (EULP) \cite[Theorem 2.9]{salins2019equivalences}. In view of  \cite[Theorem 2.12]{salins2019equivalences}, the latter holds over bounded subsets of initial data, provided that for any $\delta>0,$ $D\subset\e$ bounded and $N>0,$     	        	                    \lim_{\epsilon\to 0}\sup_{z\in D}\sup_{u\in\mathcal{P}_2^N}\pr\bigg[\sup_{t\in[0,T]}\big|Z_z^{\epsilon,u}(t)-Z_z^{u}(t)\big|_{\e}\geq \delta \bigg]=0.     	            Here, $\mathcal{P}_2^N$ is the collection of adapted, $H-$valued stochastic controls $u(t)$ such that $\pr( |u(t)|^2_H\leq N)=1.  $             	   In order to prove the latter, we use the localizing sequences of stopping times $$\tau^{\epsilon,u}_{z,n}:=\inf\{t>0 : |\Pi_1 Z^{\epsilon,u}_{z,n}(t)|_{\infty}\geq n\},\;\;\tau^\epsilon_n:=\tau^{\epsilon,u}_{z,n}\wedge \tau^{0,u}_{z,n},\;\;n\in\N,$$         where, for each $\epsilon\geq 0$ $Z^{\epsilon,u}_{z,n}$ is the corresponding solution of the localized problem \eqref{eq:controlledquationLipGlobal} (with $W$ replaced by $\epsilon W$). Next, we write     	        	        	      \pr\bigg[  \sup_{t\in[0,T]}            \big|Z_z^{\epsilon,u}(t)-Z_z^{u}(t)\big|_{\e}\geq \delta   \bigg]&=\pr\bigg[  \sup_{t\in[0,T]}\big|Z_z^{\epsilon,u}(t)-Z_z^{u}(t)\big|_{\e}\geq \delta\;,\;\; \tau^{\epsilon}_{n}>T\bigg]\\&+\pr\bigg[  \sup_{t\in[0,T]}\big|Z_{z}^{\epsilon,u}(t)-Z_z^{u}(t)\big|_{\e}\geq \delta\;,\;\; \tau^{\epsilon}_{n}\leq T\bigg]\\&=:p^{\epsilon,u,z}_1+p^{\epsilon,u,z}_2.     	        	        	  The arguments leading to \eqref{Znbnd} can be used (mutatis mutandis) to obtain     	         	        	   \sup_{\epsilon\in(0,1)}\sup_{z\in D}\sup_{u\in\mathcal{P}_2^N}p^{\epsilon,u,z}_2\leq \sup_{\epsilon\in(0,1)}\sup_{z\in D}\sup_{u\in\mathcal{P}_2^N}\bigg(\pr[\tau^{\epsilon,u}_{z,n}\leq T]+\pr[\tau^{0,u}_{z,n}\leq T]\bigg)\longrightarrow 0\;,\text{as}\;\;n\to\infty.     	        	                     Turning to $p_1$, Chebyshev's inequality  and the fact that on $\{ \tau^{\epsilon}_{n}> T \},$ $Z^{\epsilon,u}_{z,n}=Z^{\epsilon,u}_z, Z^{u}_{z,n}=Z^{u}_z$ furnish     	        	        	   	\pr\bigg[  \sup_{t\in[0,T]}\big|Z_z^{\epsilon,u}(t)-Z_z^{u}(t)\big|_{\e}\geq \delta\;,\;\; \tau^{\epsilon}_{n}> T\bigg]&\leq  \pr\bigg[  \sup_{t\in[0,T]}\big|Z_{z,n}^{\epsilon,u}(t)-Z_{z,n}^{0,u}(t)\big|_{\e}\geq \delta\bigg]\\&\leq \frac{1}{\delta}\ex\sup_{t\in[0,T]}\big|Z_{z,n}^{\epsilon,u}(t)-Z_{z,n}^{0,u}(t)\big|_{\e}.     	                   \noindent We can now estimate the latter using the local Lipschitz continuity and Gr\""onwall's inequality. Indeed,       	        	        	    \big|Z_{z,n}^{\epsilon,u}(t)-Z_{z,n}^{0,u}(t)\big|_{\e}&\leq \bigg|\int_{0}^{t}S(t-s)\big[B_n(Z_{z,n}^{\epsilon,u}(s))-B_n(Z_{z,n}^{0,u}(s))\big]ds\bigg|_{\e}\\&+ \bigg|\int_{0}^{t}S(t-s)\big[\Sigma(Z_{z,n}^{\epsilon,u}(s))-\Sigma(Z_{z,n}^{0,u}(s))\big]u(s)ds\bigg|_{\e}\\& +\epsilon\bigg|\int_{0}^{t}S(t-s)\Sigma(Z_{z,n}^{\epsilon,u}(s))dW(s)\bigg|_{\e}\\&\leq C\int_{0}^{t}\big|b_n(\Pi_1Z_{z,n}^{\epsilon,u}(s))-b_n(\Pi_1Z_{z,n}^{0,u}(s))\big|_{H}ds\\& +C\int_{0}^{t}\big|\big[\sigma(\Pi_1Z_{z,n}^{\epsilon,u}(s))-\sigma(\Pi_1Z_{z,n}^{0,u}(s))\big]u(s)\big|_{H}ds+2C\epsilon\sup_{t\in[0,T]}\big|\Gamma_n^\epsilon(t)\big|_\e     	        	    where $\Gamma^\epsilon_n(t)$ is the stochastic convolution.  Thus, from the Lipschitz continuity of $b_n$ and the (global) Lipschitz continuity of $\sigma$ (Assumption \ref{Assumption:sigmaGlobal}) there exists for each $n$ a constant $L_n>0$ such that    \big|Z_{z,n}^{\epsilon,u}(t)-Z_{z,n}^{0,u}(t)\big|_{\e}&\leq L_n\int_{0}^{t}\big|\Pi_1Z_{z,n}^{\epsilon,u}(s))-\Pi_1Z_{z,n}^{0,u}(s))\big|_{\infty}ds\\& +C_{\sigma}\int_{0}^{t}\big|\Pi_1Z_{z,n}^{\epsilon,u}(s)-\Pi_1Z_{z,n}^{0,u}(s)\big|_{\infty}|u(s)|_{H}ds+C\epsilon\sup_{t\in[0,T]}|\Gamma_n^\epsilon(t)|_\e.    \noindent From the $L^2-$bound on $u$ and Gr\""onwall's inequality we get    \ex\sup_{t\in[0,T]}\big|Z_{z,n}^{\epsilon,u}(t)-Z_{z,n}^{0,u}(t)\big|^2_{\e}\leq C \epsilon^2e^{C_{\sigma, n}T}\sup_{\epsilon\in(0,1), n\in\N}\ex\sup_{t\in[0,T]}\big|\Gamma_n^\epsilon(t)\big|^2_\e\leq C\epsilon^2e^{C_{\sigma, n}T},    \noindent where the last estimate follows by applying Lemma \ref{lem:StochasticConvolutionApriori} with $\Psi_2=0, p=2$ and using the boundedness of $\sigma.$  Combining the latter with \eqref{p1bnd}, \eqref{p2bnd} and taking limits, first as $\epsilon\to0 $ and then as $n\to\infty,$ we see that \eqref{eq:EULPsufficientGlobal} holds true for any $\delta, T>0$ and any bounded set $D\subset\e.$",2502.01783
proof,"Recall that $\hat{\cdot}$ denotes anti-differentiation (see Section \ref{Sec:Notation}). Since we do not require uniform estimates, it suffices to prove the case $\epsilon=1.$ Furthermore, from linearity we can take $\Psi_2=0$ (the general case will then follow by substituting $\Psi_1$ by $\Psi_2-\Psi_1).$ To this end, let $\Psi\in L^p(\Omega; C([0,T]; C_0(0,\ell))).$ Then $\Gamma:=\Gamma_{\Psi}$ is a mild solution of  $$ \partial_t^2\Gamma+\alpha\partial_t\Gamma=\partial^2_{x}\Gamma+\Psi\dot{W}\;, \Gamma(0)=\partial_t\Gamma(0)=0.     $$  Hence, letting $G=e^{\alpha t/2}\Gamma$ and applying the chain rule it holds that   $$  \partial_t^2G=\partial^2_{x}G+\frac{\alpha^2}{4}G+e^{\alpha t/2}\Psi\dot{W}, G(0)=\partial_tG(0)=0,$$ in the sense of distributions, or in mild form $$G(t)=\frac{\alpha^2}{4}\int_0^ t S_0(t-s)G(s)ds+\int_0^t S_0(t-s)(0, e^{\alpha s/2}\Psi(s))dW(s).$$ \noindent The above, along with Gr\""onwall's inequality, furnishes       \sup_{t\in[0,T]}|G(t)|_{\e}\leq \exp(C T)\sup_{t\in[0,T]}\bigg|\int_0^t S_0(t-s)(0, e^{\alpha s/2}\Psi(s))dW(s)   \bigg|_{\e},    for a constant $C>0$ that depends on the wave semigroup, $T$ and $\alpha.$ Moreover, in view of \eqref{equation:D'Alembert1}, \eqref{equation:D'Alembert2}       \Pi_1\int_0^t S_0(t-s)(0, e^{\alpha s/2}\Psi(s))dW(s)   =\frac{1}{2}\int_0^t\int_{x-(t-s)}^{x+(t-s)}e^{\alpha s/2}\Psi(y,s)dW(y,s)    and         -\widehat{\Pi}_2\int_0^t S_0(t-s)(0, e^{\alpha s/2}\Psi(s))dW(s)= \frac{1}{2}\int_0^t\bigg(\int_{0}^{x+(t-s)}+\int_0^{x-(t-s)}\bigg)e^{\alpha s/2}\Psi(y,s)dW(y,s),    where $W$ is interpreted as a Brownian sheet in $[0, \infty)\times\R.$ Thus, from the BDG inequality,       \ex \bigg|\Pi_1\int_0^t S_0(t-s)(0, e^{\alpha s/2}\Psi(s))dW(s)   \bigg|_{\infty}^p&\leq C_p\bigg(\int_0^t\int_{x-(t-s)}^{x+(t-s)}e^{\alpha s}\ex\Psi^2(y,s)dyds\bigg)^{p/2}\\&     \leq C(t-s)e^{p\alpha T/2}\ex\sup_{t\in[0,T]}|\Psi(s)|^p_\infty   and similarly        \ex \bigg|\Pi_2 \int_0^t S_0(t-s)(0, e^{\alpha s/2}\Psi(s))dW(s)   \bigg|_{C^{-1}}^p&= \ex \bigg|\widehat{\Pi}_2\int_0^t S_0(t-s)(0, e^{\alpha s/2}\Psi(s))dW(s)   \bigg|_{\infty}^p\\&\leq C\ex\sup_{t\in[0,T]}|\Psi(s)|^p_\infty,   where $C$ depends on $T, \ell, \alpha.$ The last two estimates yield         \ex\sup_{t\in[0,T]}|\Gamma_{\Psi}(t)|^p_{\e}= e^{-\frac{p\alpha t}{2}}\ex\sup_{t\in[0,T]}|G(t)|^p_{\e}\leq C \ex\sup_{t\in[0,T]}|\Psi(s)|^p_\infty.    The proof is complete.",2502.01783
proof,"Let $h \in \mathbb{R}$. For any $x^\star \in \partial|x|_E$, 		 			|x+hy|_E - |x|_E \geq \left<x+hy,x^\star\right> - \left<x,x^\star \right>\geq h \left<y,x^\star\right>. 		 		For $h>0$, 		 			\frac{|x + hy|_E - |x|_E}{h} \geq \left<y,x^\star\right>. 		 		This is true for all $x^\star \in \partial |x|_E$, so  		  			\liminf_{h \downarrow 0} \frac{|x + hy|_E - |x|_E}{h}\geq \max\{\left<y,x^\star\right>: x^\star \in \partial|x|_E\}. 		 		To prove the other direction, chose a sequence $h_n \downarrow 0$ such that 		 			\lim_{n \to \infty} \frac{|x + h_n y|_E - |x|_E}{h_n}  = \limsup_{h \downarrow 0} \frac{|x + hy|_E - |x|_E}{h}.  		 		Let $x_n^\star \in \partial|f + h_ng|_E$. Note that $\{x_n^\star; n\in\N\}\subset B_{E^\star}(0,1).$ By virtue of Alaoglu's theorem $B_{E^\star}(0,1)$ is  weak-$\star$ compact. Hence there exists a subsequence (relabelled $h_n$) such that 		$x_{n}^\star$ converges in weak-$\star$ topology to some $x^\star\in E^{\star}$ and, as a consequence,  		 			&\left<x,x^\star_{n} \right> \to \left<x,x^\star\right>\\ 			&\left<y, x^\star_{n} \right> \to \left<y, x^\star \right>. 		 		Therefore,  		 			\lim_{n \to \infty} \frac{|x+h_n y|_E - |x|_E}{h_n} \leq \lim_{n \to \infty}\frac{\left<x, x_{n}^\star\right> + h_n \left<x, x_{n}^\star\right> - \left<x, x_{n}^\star\right>}{h_n} = \left<y,x^\star\right>. 		 		Now we claim that $x^\star$ in $\partial |x|_E.$ Indeed, we know that  		 			\lim_{n \to \infty} |x + h_n g|_E = |x|_E 		 		and that 		 			\lim_{n \to \infty} |x + h_n y|_E =\lim_{n \to \infty}\left( \left< x,x_{n}^\star \right> + h_n \left< y, x_{n}^\star\right>\right)  = \left<x,x^\star\right>. 		 		Hence $x^\star \in \partial |x|_E$. 		We have proved that  		  			\limsup_{h \downarrow 0} \frac{|x + hy|_E - |x|_E}{h} \leq \left<y,x^\star \right>_E. 		 		From \eqref{eq:geq-max} and \eqref{eq:leq-max} the proof is complete.",2502.01783
example,"A simple and important example of a nonlinearity  that satisfies the assumptions of Theorem \ref{thm:domainofattraction} is given by $b(x)=x-x^3.$ Indeed, Assumption \ref{Assumption:xstar} can be seen to hold from the analysis of \cite[Section 7]{faris1982large}. Explicit expressions for the equilibrium point $x^*$ and eigenvalues of the Schr\""odinger operator $\partial^2_x+b'(x^*)$ for this example as well as for polynomial nonlinearities of higher degree can be found in \cite[Section 5.1]{gasteratos2023importance} and references therein.  For this case, it is also possible to find an explicit expression for the size $\rho_0$ of domains of uniform attraction to $z^*.$ Indeed, by examining the proof of Theorem \ref{thm:domainofattraction}, we have that  $$F^{-1}(z)=\frac{\zeta}{A_1}-\ell(R_2 \zeta^2+R_3\zeta^3).$$ Since the roots of $F'(\zeta)=A_1^{-1}-2\ell R_2\zeta-3\ell R_3\zeta^2$ are given by $\pm\rho,$ $$\rho_{\pm}:=\frac{2 R_2\pm\sqrt{4R_2^2+12A_1^{-1}\ell^{-1} R_3}}{6 R_3},$$ it suffices to take  $$\rho_0=\rho_{+}=\frac{2|b''(x^*)|_{\infty}+2\sqrt{|b''(x^*)|_{\infty}^2+A_1^{-1}\ell^{-1}|b^{(3)}(x^*)|_{\infty} }}{|b^{(3)}(x^*)|_{\infty}}.$$",2502.01783
example,"[Regular boundary points of cylindrical sets: outward pointing velocity]  Let $R>0, \rho>0$ and consider the domain             D=B(x^*, R)\times B(0, \rho)=\bigg\{ (x,v)\in C_0(0,\ell)\times C^{-1}(0,\ell):   |x-x^*|_{\infty}< R, |v|_{C^{-1}}<\rho\bigg\}.           \noindent The boundary points  $$\mathcal{B}_{out}:=\bigg\{(x,v)\in C^1_0(0,\ell)\times C_0(0,\ell)\bigg| \;|x-x^*|_{\infty}=R, \exists\mu\in\partial|x-x^*|_{\infty}:\langle v, \mu\rangle>0\bigg\}\subset \partial D $$ with ""outward pointing"" velocity are regular. To this end let $z=(x,v)\in\mathcal{B}_{out}.$  From Proposition \ref{prop:subdifferential}, there exists a probability measure $\tilde{\mu}$ supported on $\arg\max|x-x^*|_\infty$ such that $$\int_{\arg\max|x-x^*|} v(\xi)\textnormal{sgn}\big(x(\xi)-x^*(\xi)\big)\;d\tilde{\mu}(\xi)>0.$$ Hence, there must exist $v_0>0$ and $\xi_0\in \arg\max|x-x^*|$ such that $$v(\xi_0)\textnormal{sgn}\big(x(\xi_0)-x^*(\xi_0)\big)>v_0.$$ Noting that, for each $z\in \mathcal{B}_{out},$ $Z^0_z\in C([0,\infty);C^1_0(0,\ell)\times C_0(0,\ell)) $ we let $$\zeta:=\sup_{ t>0}|\Pi_1Z^0_z(t)|_{\infty}+\sup_{t>0}|\Pi_2Z^0_z(t)|_{\infty}<\infty    $$ and  $\zeta_b:=\sup_{|x|\leq \zeta}|b(x)|+\alpha\zeta. $ Here, we are using that $D$ is uniformly  attracting in $\e$ which follows e.g. from Theorem \ref{thm:domainofattraction} (at least for $\rho, R>0$ small enough). The fact that the $C_0-$norm of the velocity is also uniformly bounded for all $t\geq 0$ is straightforward to show from a similar argument.   From the continuity of $v$ at $\xi_0,$ there exists $t_0>0$ such that for all $|y-\xi_0|<t_0$     |v(y)-v(\xi_0)|<v(\xi_0)/2.   For $t\leq T_0:=\min\{t_0, v_0/2\zeta_b,   \xi_0, \ell-\xi_0\}$ and from a first-order Taylor approximation, there exist   $\delta,  \delta'\in(0, T_0)$ such that        &x(\xi_0+t)=x(\xi_0)+x'(\xi_0+\delta)t, \\&      x(\xi_0-t)=x(\xi_0)-x'(\xi_0-\delta')t.    \noindent From the latter and the choice of $\xi_0$ we obtain         \Pi_1Z^0_z(\xi_0,t)-x^*(\xi_0)&=\frac{1}{2}\bigg(x(\xi_0+t) + x(\xi_0-t)    \bigg)-x^*(\xi_0)+\frac{1}{2}  \int_{\xi_0-t}^{\xi_0+t}v(y)dy\\&+\frac{1}{2}\int_0^{t}\int_{\xi_0-t+s}^{\xi_0+t-s}[b(\Pi_1Z^0_z(y, s))+\alpha\Pi_2Z^0_z(y,s)]dyds \\&=   |x-x^*|_\infty\textnormal{sgn}\big(x(\xi_0)-x^*(\xi_0)\big)+\frac{t}{2}\bigg(x'(\xi_0+\delta)-x'(\xi_0-\delta) \bigg)                    \\&+\frac{1}{2}  \int_{\xi_0-t}^{\xi_0+t}v(y)dy+\frac{1}{2}\int_0^{t}\int_{\xi_0-t+s}^{\xi_0+t-s}[b(\Pi_1Z^0_z(y, s))+\alpha\Pi_2Z^0_z(y,s)]dyds.     Moreover,                \bigg|\int_0^{t}&\int_{\xi_0-t+s}^{\xi_0+t-s}[b(\Pi_1Z^0_z(y, s))+\alpha\Pi_2Z^0_z(y,s)]dyds\bigg|\\&\leq \bigg(\sup_{|x|\leq \zeta}|b(x)|+\alpha\sup_{ s>0}\sup_{\xi\in(0,\ell)}\big|\Pi_2Z^0_z(y,s)dy\big|_{\infty}   \bigg)\int_{0}^{t} 2(t-s)ds\\&\leq \zeta_b(2t^2-t^2)         =\zeta_bt^2.               \noindent\underline{\textit{Case 1}}:  $x(\xi_0)-x^*(\xi_0)>0.$ From the last two displays along with \eqref{eq:vcontinuity} we obtain the lower bound        |\Pi_1Z^0_z(t)-x^*|_{\infty}&\geq  R+\frac{t}{2}\bigg(x'(\xi_0+\delta) -x'(\xi_0-\delta) \bigg)\\&+\frac{1}{4}\int_{\xi_0-t}^{\xi_0+t}\bigg[v(\xi_0)\textnormal{sgn}\big(x(\xi_0)-x^*(\xi_0)\big)\bigg]d\xi-\frac{\zeta_b t^2}{2}\\&\geq       R+\frac{t}{2}\bigg(x'(\xi_0+\delta) -x'(\xi_0-\delta) \bigg)+\frac{v_0 t}{2}-\frac{\zeta_b t^2}{2}.   Since $x'$ is continuous we can (by possibly reducing $t_0$ and remembering that $\delta<t_0$) take  $$\frac{t}{2}\bigg(x'(\xi_0+\delta)-x'(\xi_0-\delta)\bigg)\geq -v_0t/4    $$ so that        |\Pi_1Z^0_z(t)&-x^*|_{\infty}\geq  R+tv_0/4- \zeta_bt^2/2.    From the choice of $T_0$ we have $t<v_0/2\zeta_b$ and $tv_0/4-\zeta_bt^2/2>0.$ In turn, the latter imply  $$|\Pi_1Z^0_z(t)-x^*|_{\infty}>R.$$  \noindent\underline{\textit{Case 2}}:  $x(\xi_0)-x^*(\xi_0)<0.$ From the symmetric lower bound        \Pi_1Z^0_z(\xi_0,t)-x^*(\xi_0)\leq -R-\frac{v_0t}{2}+\frac{t}{2}\bigg(x'(\xi_0-\delta)-x'(\xi_0-\delta)\bigg)+ \frac{\zeta_bt^2}{2}  and the continuity of $x'$ we obtain        \Pi_1Z^0_z(\xi_0,t)-x^*(\xi_0)\leq -R-\frac{v_0t}{8}- \frac{\zeta_bt^2}{2}.  As in the previous case, the choice of $T_0$ implies $$\Pi_1Z^0_z(t, \xi_0)-x^*(\xi_0)<-R\implies |\Pi_1Z^0_z(t)-x^*|_{\infty}>R. $$ Hence, in  both cases and for all $t\in (0,T_0),$ we have $$\phi(t):=Z^0_z(t)\notin D.$$ Therefore, according to Definition \ref{def:regularpoints}, $z\in \mathcal{B}_{out}$ is indeed regular. Since no control is required to exit $D$ instantaneously, we have $I_{z,T_0}(\phi)=0.$",2502.01783
example,"[Irregular boundary points of cylindrical sets: inward pointing velocity]      Let $D$ as in \eqref{eq:cylindricalset} and consider the set  $$\mathcal{B}_{in}:=\bigg\{(x,v)\in C^1_0(0,\ell)\times C_0(0,\ell)\bigg| \;|x-x^*|_{\infty}=R, \forall\mu\in\partial|x-x^*|_{\infty}:\langle v, \mu\rangle< 0\bigg\}\subset \partial D $$ of boundary points with an ""inward-pointing"" velocity. We claim that $\mathcal{B}_{in}$ consists of irregular boundary points. To this end,  let $z=(x,v)\in\mathcal{B}_{in}$ and fix $T>0$ and a control $u\in L^2([0, T];H).$ Since $\partial_t( \Pi_1Z^u_z)\in H,$  \eqref{eq:rightDinibound} cannot be used directly to estimate the supremum norm of $\Pi_1Z^u_z(t)-x^*.$ At $\xi=\xi_0$ the latter satisfies       \Pi_1 Z^u_z(\xi_0,t) - x^*(\xi_0) = &[\Pi_1 S_0(t)z](\xi_0) -x^*(\xi_0) \nonumber\\     &+\int_0^t \Pi_1 S_\alpha(t-s)  0 \\  b(\Pi_1 Z^u_z(s)) ds\nonumber\\     &+\int_0^t \Pi_1 S_\alpha(t-s)  0 \\ \sigma(\Pi_1 Z^u_z(y,s))u(s)ds.   The controlled convolution term is not as regular as the other two terms, so we subtract it off by letting      q(t) = \Pi_1 Z^u_z(t) - \int_0^t \Pi_1 S_\alpha(t-s) 0 \\\sigma(\Pi_1 Z^u_z(s)) u(s) ds.  $q(\xi,t)$ is differentiable in $t$ and satisfies $\frac{\partial q}{\partial t} \Big|_{t=0} = v = \Pi_2 z$.   We estimate the derivative of the supremum norm of $q$ with \eqref{eq:rightDinibound}.      \frac{d^+}{dt}|q(t) - x^*|_\infty \leq \max_{\mu_0 \in \partial |x-x^*|_\infty}\left< \frac{\partial q}{\partial t}(t,\cdot),\mu\right>=:-\gamma<0.   This limit is negative because the initial data $z$ was assumed to be in $\mathcal{B}_{in}$. Therefore, we can find $t_0$ such that for all $t \in [0,t_0]$, $$|q(t) - x^*|_{L\infty} \leq R-\frac{\gamma}{2} t.$$    The control term can be estimated using arguments similar to Lemma \ref{lem:integral-bound}. We do the same transformation from Section \ref{Sec:Linfty-decay}. Let $\Psi(t) = e^{-\frac{\alpha t}{2}}\int_0^t S_\alpha(t-s)  0\\ \sigma(\Pi_1 Z^u_z(y,s))u(s) ds$. Then $\Psi$ satisfies      \Psi(\xi,t) = \frac{\alpha^2}{4}\int_0^t \int_{\xi-(t-s)}^{\xi + (t-s)} \Psi(y,s)dyds + \int_0^t \int_{\xi-(t-s)}^{\xi + (t-s)}\sigma(\Pi_1 Z^u_z(y,s))u(y,s)dyds.  By H\""older's inequality, uniformly for $\xi \in [0,\ell]$,      &\left|\int_0^t \int_{\xi-(t-s)}^{\xi + (t-s)}\sigma(\Pi_1 Z^u_z(y,s))u(y,s)dyds \right|     \leq \left(\int_0^t \int_{\xi-(t-s)}^{\xi+(t-s)}dyds \right)^{\frac{1}{2}}|\sigma|_{\infty}|u|_{L^2([0,t]\times[0,\ell])}\nonumber\\     &\leq t|u|_{L^2([0,t]\times[0,\ell])}.   The linear term is bounded by      \sup_{\xi ]in [0,\ell]} \left|\frac{\alpha^2}{8}\int_0^t \int_{\xi-(t-s)}^{\xi + (t-s)} \Psi(y,s)dyds \right| \leq \frac{\alpha^2 t}{8}\int_0^t \sup_{\xi \in [0,\ell]} |\Psi(\xi,s)ds.  Gr\""onwall's inequality implies that for small $t>0$,      |\Psi(t)|_\infty \leq t |u|_{L^2([0,t]\times[0,\ell])}e^{\frac{\alpha^2 t^2}{8}}.  Therefore, for small $t>0$,      \left|\int_0^t S_\alpha(t-s)  0\\\sigma(\Pi_1 Z^u_z(s))u(s) ds\right|_\infty \leq Ct |u|_{L^2([0,t]\times[0,\ell])}.   Choose $t_0$ small enough so that $|u|_{L^2([0,t_0]\times[0,\ell])}\leq \frac{\gamma}{4}$.    These estimates prove that for all $t\in[0,t_0]$,      |\Pi_1 Z^u_z(t) - x^*|_\infty \leq  R - \frac{\gamma}{4} t <R.    We showed that all controlled trajectories issued from $z\in\mathcal{B}_{in}$ will not exit $D$ instantaneously. Per Definition \ref{def:regularpoints}, all points in $\mathcal{B}_{in}$ are not regular.",2502.01783
example,"[Regular boundary points of cylindrical sets: ""orthogonal"" initial velocity]    Let $D$ as in \eqref{eq:cylindricalset} and consider the set  $$\mathcal{B}_{\perp}:=\bigg\{(x,v)\in C^2_0(0,\ell)\times C^1_0(0,\ell)\bigg| \;|x-x^*|_{\infty}=R, \exists\mu\in\partial|x-x^*|_{\infty}:\langle v, \mu\rangle=0\bigg\}\subset \partial D. $$    \noindent Let $T>0, \xi_0\in\arg\max|x-x^*|_{\infty},$  $u: C^1([0,T];C^2_0(0,\ell))\rightarrow C((0,\ell)\times [0,T])$ a control function  that will be specified below. Any controlled trajectory issued from $z=(x,v)\in \mathcal{B}_{\perp}$ satisfies $\phi=Z^u_z\in C^2_0(0,\ell)\times C^1_0(0,\ell).$ A temporal second-order Taylor expansion around $t=0$ thus furnishes          \Pi_1\phi(\xi_0, t)&=\Pi_1 \phi(\xi_0, 0)+\Pi_2 \phi(\xi_0, 0)t+\frac{t^2}{2}\partial_t^2 \Pi_1 \phi(\xi_0, t')\\&      = x(\xi_0)+v(\xi_0)t     \\&+\frac{t^2}{2} \bigg(-\alpha\partial_t\Pi_1\phi(\xi_0,t')+\partial_\xi^2\Pi_1\phi(\xi_0,t')+b\big(\Pi_1\phi(\xi_0, t')\big)+\sigma\big(\Pi_1\phi(\xi_0,t')\big)u\big(\Pi_1\phi\big)(\xi_0,t')\bigg)      for any $t\in[0,T]$ and some $t'\in (0,t).$ For some $\rho>0$ we choose  $$u(\psi)(\xi,s):=\frac{1}{\sigma(\psi(\xi,s))}\bigg(\rho+\alpha\partial_t\psi(\xi,s)-\partial_\xi^2\psi(\xi,s)-b\big(\psi(\xi,s)\big)      \bigg), (\xi, s)\in (0,\ell)\times(0, t) $$     and note  that $v(\xi_0)=0.$ Thus,           \Pi_1\phi(\xi_0, t)-x^*(\xi_0)&=x(\xi_0)-x^*(\xi_0)+\rho t^2/2      and assuming, without loss of generality, that $x(\xi_0)-x^*(\xi_0)>0$ we deduce that   $$ | \Pi_1\phi(t)-x^*|_{\infty}\geq \Pi_1\phi(\xi_0, t)-x^*(\xi_0)=|x-x^*|_{\infty}+\rho t^2/2> R.$$ Clearly, the same conclusion follows from a symmetric bound when $x(\xi_0)-x^*(\xi_0)<0.$ Finally, the energy of this path is given by               I_{z, t}(\phi)&=\frac{1}{2}|u(\Pi_1\phi)|^2_{L^2[0,t]\times[0,\ell]}\\&               =\frac{1}{2}\int_0^t\int_0^\ell\bigg|\frac{1}{\sigma(\Pi_1\phi(\xi,s))}\bigg(\rho+\alpha\partial_t\Pi_1\phi(\xi,s)-\partial_\xi^2\Pi_1\phi(\xi,s)-b\big(\Pi_1\phi(\xi,s)\big)      \bigg)  \bigg|^2d\xi ds\\&         \\&\leq C_\sigma^{-1}\bigg(\rho^2\ell+\sup_{(\xi,s)\in[0,\ell]\times[0,T]}\bigg| \alpha\partial_t\Pi_1\phi(\xi,s)-\partial_\xi^2\Pi_1\phi(\xi,s)-b\big(\Pi_1\phi(\xi,s)\big)\bigg|^2\ell  \bigg)t\\&         =: C' t,       where $C_\sigma$ is the constant from Assumption \ref{Assumption:sigmaNondeg}.  Letting $\delta>0$ and $t<\delta/C'$ we conclude from the last two displays that the path $\phi$ has energy smaller than $\delta, \phi(0)\in\mathcal{B}_{\perp}$ and $\phi(s)\notin \bar{D}^c$ for all $s\in (0, t].$ Hence any point in $\mathcal{B}_\perp$ is regular per Definition \ref{def:regularpoints}.",2502.01783
example,"[Regular boundary points of spherical sets]      Let $R>0$ and  $$D:=\bigg\{ (x, v)\in\mathcal{E}:\sqrt{ |x-x^*|^2_{\infty}+ |v|^2_{C^{-1}}}<R\bigg\}. $$  We shall now show that, under Assumption \ref{Assumption:sigmaNondeg}, the set                    \mathcal{B}_{flat}:=\bigg\{(x, 0)\in C_0^2(0,\ell)\bigg|\; |x-x^*|_{\infty}=R,\;\exists \;t_0>0, \xi_0\in\arg\max|x-x^*|_{\infty}: x-x^*=R\;\textnormal{on}\;(\xi_0-t_0, \xi_0+t_0)  \bigg\}          is regular. Indeed, for $z=(x,0)\in \mathcal{B}_{flat}$ and from a  second-order Taylor approximation, there exist $\delta_1, \delta_2<t_0$ such that          &x(\xi_0+t)=x(\xi_0)+ x'(\xi_0)t+x''(\xi_0+\delta_1)\frac{t^2}{2}=x(\xi_0)+x''(\xi_0+\delta_1)\frac{t^2}{2}, \\&      x(\xi_0-t)=x(\xi_0)-x'(\xi_0)t+x''(\xi_0-\delta_2)\frac{t^2}{2}=x(\xi_0)+x''(\xi_0-\delta_2)\frac{t^2}{2}.    Thus, for $t<t_0,$               \Pi_1Z^u_z(\xi_0,t)-x^*(\xi_0)&=\frac{1}{2}\bigg(x(\xi_0+t)+  x(\xi_0-t)    \bigg)-x^*(\xi_0)+\frac{1}{2}\int_0^{t}\int_{\xi_0-t+s}^{\xi_0+t-s}b(\Pi_1Z^u_z(y, s))dyds\\&      +\frac{1}{2}\int_0^{t}\int_{\xi_0-t+s}^{\xi_0+t-s}\sigma(\Pi_1Z^u_z(y, s))u(y,s)dyds\\&       =   R+\frac{t^2}{4}\bigg(x''(\xi_0+\delta_1)+x''(\xi_0-\delta_2) \bigg)+\frac{1}{2}\int_0^{t}\int_{\xi_0-t+s}^{\xi_0+t-s}b(\Pi_1Z^u_z(y, s))dyds\\&       +\frac{1}{2}\int_0^{t}\int_{\xi_0-t+s}^{\xi_0+t-s}\sigma(\Pi_1Z^u_z(y, s))u(y,s)dyds.   For a constant $V\in\R$ to be specified later, we consider the feedback control   $$u(x):=\frac{V-b(x)}{\sigma(x)}.     $$ The corresponding controlled dynamics then satisfy             \Pi_1Z^u_z(\xi_0,t)-x^*(\xi_0)&       =  % R+\int_0^{t}\int_{\xi_0-t+s}^{\xi_0+t-s}b(\Pi_1Z^u_z(y, s))dyds\\&       %+\int_0^{t}\int_{\xi_0-t+s}^{\xi_0+t-s}\sigma(\Pi_1Z^u_z(y, s))u(\Pi_1Z^u_z(y, s))dyds\\&    R+\bigg(V+x''(\xi_0+\delta_1)+x''(\xi_0-\delta_2)  \bigg)\frac{t^2}{4}.   For some $\eta>0$ we choose $$V:=\eta-\bigg(x''(\xi_0+\delta_1)+x''(\xi_0-\delta_2)\bigg) $$ to obtain the lower bound             |\Pi_1Z^u_z(t)-x^*|_\infty&       \geq   R+\eta t^2>R    which holds for all $t\in(0,t_0).$ Hence the path $\phi=\Pi_1Z^u_z$ starting from the boundary point $z$ exits $\bar{D}$ instantaneously and stays in $\bar{D}^c$ for all $t<t_0.$ Moreover, for any $\delta>0,$ $C_\sigma$ as in Assumption \ref{Assumption:sigmaNondeg} $$\kappa:= \frac{1}{2}\bigg(\frac{V+|b|_\infty}{C_\sigma}\bigg)^2\ell$$ and $$t<\bigg(t_0\wedge\frac{\delta}{\kappa}   \bigg)$$ the energy of this path satisfies      I_{z,t}(\phi)\leq \frac{1}{2}\int_{0}^{t}\int_{0}^{\ell}|u(y, s)|^2dyds\leq\kappa t<\delta.   Therefore, any boundary point in $\mathcal{B}_{flat}$ with the properties described above is regular per Definition \ref{def:regularpoints}.",2502.01783
theorem,The cluster-interaction cross section $\sigma_\mathrm{c}$ and the reaction intensity $\mathbf{I}_{\mathrm{R}}^0(\mathbf{r})$ in $V_0$ are connected by the relation %   \frac{\sigma_\mathrm{c}}{\zeta_0}=\lim_{R\rightarrow\infty}\int_{S_R}\hat{\mathbf{r}}\cdot\mathbf{I}_{\mathrm{R}}^0(\mathbf{r})\mathrm{d}s(\hat{\mathbf{r}})  % with $S_R$ a sphere of radius $R$ surrounding the cluster and $\zeta_0=\sqrt{\rho_0/\gamma_0}$.,2502.01791
theorem,"The cluster-interaction cross section is connected to the active interaction intensity through the host medium and the active interaction kinetic energy densities, by the relation  %   \frac{\sigma_{\mathrm{c}}}{\zeta_0}=\mathrm{Re}\left[\int_{S_h}\hat{\mathbf{n}}\cdot\mathbf{I}_{\mathrm{R}}^{h}(\mathbf{r})\mathrm{d}s(\mathbf{r})\right]-2\omega\sum_{\substack{n=1\\n\ne h}}^{N}\int_{V_n}\mathrm{Im}\left[\frac{\beta_n}{\rho_n}-1\right]\mathcal{K}_{\mathrm{R}}^n(\mathbf{r})\mathrm{d}v(\mathbf{r}),  % while the interaction Lagrangian densities are connected to the reaction intensity and the reactive interaction kinetic energy densities as follows: %  \nonumber \sum_{\substack{n=0\\n\ne h}}^{N}\int_{V_n}\mathcal{L}_{\mathrm{R}}^n(\mathbf{r})\mathrm{d}v(\mathbf{r})=-\frac{1}{2\omega}\mathrm{Im}\left[\int_{S_h}\hat{\mathbf{n}}\cdot\mathbf{I}_{\mathrm{R}}^{h}(\mathbf{r})\mathrm{d}s(\mathbf{r})\right]-\\\sum_{\substack{n=1\\n\ne h}}^{N}\int_{V_n}\mathrm{Re}\left[\frac{\beta_n}{\rho_n}-1\right]\mathcal{K}_{\mathrm{R}}^n(\mathbf{r})\mathrm{d}v(\mathbf{r}).   %",2502.01791
theorem,"For the active reaction intensity $\mathbf{I}_{\mathrm{R}}^h$ out of the host medium, it holds %   \int_{S_h}\mathrm{Re}\left[\hat{\mathbf{r}}\cdot\mathbf{I}_{\mathrm{R}}^h(\mathbf{r})\right]\mathrm{d}s(\mathbf{r})=\frac{4\pi\lvert A\rvert^2}{\zeta_h}-2\omega\mathrm{Im}\left[\frac{\beta_h}{\rho_h}\right]\int_{V_h}\mathcal{K}_{\mathrm{R}}^h(\mathbf{r})\mathrm{d}v(\mathbf{r}).  %",2502.01791
theorem,"The ratio $R_\mathrm{c}$ of the cluster interaction SCS to the overall SCS and the minimum single-scatterer SCS, $\mathrm{R}_{\mathrm{min}}$, satisfy %              R_\mathrm{c}\leq\min\left\{\frac{N-1}{N},1-N\mathrm{R}_{\mathrm{min}}\right\}.      %",2502.01791
theorem,"It holds that                   \mathrm{R}_{\mathrm{max}}=\frac{1}{N^2}         if and only if                      \mathrm{R}_{n}=\frac{1}{N^2},\quad \mbox{\rm{for all}} \quad n=1,\ldots,N.      %",2502.01791
theorem,"For a cluster composed by scatterers with $\sigma_1\leq\ldots\leq\sigma_N$, it holds                       \sigma^{N}- \sigma_n^{N-1}\leq(2n-1)\sigma_n+2(N-n-1)\sigma_N.",2502.01791
theorem,% The overall SCS satisfies the relation %  \nonumber \frac{\sigma}{\zeta_0}=\sum_{n=1}^{N-1}4\pi\lvert A_n\rvert^2\left( \frac{1}{\zeta_0}-\frac{1}{\omega\rho_0}\mathrm{Im}\left[\frac{u_0^{\mathrm{sc}}(\mathbf{b}_n)}{A_n}\right]\right)+\\\frac{4\pi\lvert A\rvert^2}{\zeta_h}\left(1-\mathrm{Im}\left[\frac{\zeta_h}{\beta_h}A\overline{u_h^{\mathrm{sc}}}(\mathbf{a})\right]\right)-2\omega\mathrm{Im}\left[\frac{\beta_h}{\rho_h}\right]\int_{V_h}\mathcal{K}^h(\mathbf{r})\mathrm{d}v(\mathbf{r}).,2502.01791
definition,"%A cluster of scatterers $V_n$, $n=1,\ldots,N$ and a distribution of point sources $\mathbf{r}_\ell$ with $\ell=1,\ldots,L$ satisfy the \emph{close proximity assumption} if and only if there exists an open ball of finite radius $R$, $B_R(\mathbf{r}_0)=\{\mathbf{r}\in\mathbb{R}^3:\lvert \mathbf{r}-\mathbf{r}_0\rvert <R\}$ such that the following conditions hold: %  %   \item $V_n\subset B_R$, \quad $n=1,\ldots,N$   %  \item $\mathbf{r}_\ell\in \mathrm{int}(B_R)$, \quad $\ell=1,\ldots,L$   %  \item $\lim_{r\rightarrow R}\left\lvert u_\ell^{\mathrm{pr}}(\mathbf{r})-\mathrm{exp}({-\mathrm{i}k\hat{\mathbf{r}}_\ell\cdot\mathbf{r}})\right\rvert \ne0$, \quad $\ell=1,\ldots,L$, % %where $u_\ell^{\mathrm{pr}}$ is the primary field elicited by the source at $\mathbf{r}_\ell$, $\mathrm{exp}({-\mathrm{i}k\mathbf{r}_\ell\cdot\mathbf{r}})$ a plane wave propagating at the direction of $-\hat{\mathbf{r}}_\ell$ and $\mathrm{int}(B_R)$ the interior of $B_R$.   %",2502.01791
lemma,"The primary-interaction cross section $\sigma_{\mathrm{R}}^{\mathrm{pr}}$ is given by %                       \sigma_{\mathrm{R}}^{\mathrm{pr}}=4\pi\sum_{\substack{k,m\\k\ne m}}A_k\overline{A}_mj_0(k_0\lvert\mathbf{b}_k-\mathbf{b}_m\rvert),      % with $j_0$ the spherical Bessel function of $0$-th order. %",2502.01791
theorem,"[Abstract estimator]  % Let $M_h$ be a quasi-optimal method, induced by the discretization \eqref{Eq:DisEq}. Suppose that \eqref{A:equiv-to-dist-to-conf}, \eqref{A:partition-of-unity}, and \eqref{A:construction-Pz-local} hold and, given tuning constants $C_1, C_2 >0$, define an abstract estimator by     \Est_h^2   :=   (1 + C_1^2 \delta_h^2) \Ncf_h^2 + C_2^2 (\eta_h^2 + \Osc_h^2),  \text{ where } \\   \Ncf_h^2  &:=    \norm{ u_h - \calA_h u_h }^2,  &&\text{(approximate distance to conformity)} \\  \eta_h^2   &:=   \textstyle \sum_{z\in\Index} \norm[\Dual{V_z}]{\calP_z f- \tA u_h}^2 ,  &&\text{(approximate conforming residual)} \\  \Osc_h^2  &:=   \textstyle \sum_{z\in\Index} \norm[\Dual{V_z}]{f - \calP_z f}^2, &&\text{(data oscillation)}   and the projections $\calP_z$ %_{z \in \Index}$ are defined by \eqref{Eq:construction-Pz-local}. Then this estimator quantifies the error by  %  \underline{C} \Est_h  \leq  \norm{u-u_h}  \leq  \overline{C}\Est_h  where the equivalence constants $\underline{C}$, $\overline{C}$ depend only on the norm $\normtr{A_h}$ of the discrete operator $A_h$, the constants arising from the assumptions \eqref{A:equiv-to-dist-to-conf}, \eqref{A:partition-of-unity}, and \eqref{A:construction-Pz-local}, and the tuning constants $C_1$, $C_2$.",2502.01799
theorem,"[Estimator for $\mathsf{CR}$@Poisson]  % Let $u \in \mathring{H}^1(\Omega)$  be the weak solution of the Poisson problem \eqref{Eq:Poisson} and $u_h \in \CR_1$ its quasi-optimal Crouzeix-Raviart approximation from \eqref{Eq:CR-qopt}. Given tuning constants \(C_1, C_2>0\), define  	\Est_\mathsf{CR}^2 	:= 	\Ncf_\mathsf{CR}^2 + C_1^2 \eta_\mathsf{CR}^2 + C_2^2 \Osc_\mathsf{CR}^2,  \text{ where } 	\\ 	 		\Ncf_\mathsf{CR}^2 		&:=  		\norm[L^2(\Omega)]{ \nabla_h( u_h - \calA_\mathsf{CR} u_h ) }^2, 		\\  		\eta_\mathsf{CR}^2 		&:=  		\sum_{T \in \grid} \eta_{\mathsf{CR},T}^2 		%\\ 		\text{ with  } 		\eta_{\mathsf{CR},T} 		:= 		\max_{ K \in \mathcal{K}_T } 		 \frac{|\scp{f}{\Psi_K} - \int_\Omega \nabla_h u_h \cdot \nabla \Psi_K |}{\|\nabla \Psi_K\|_{L^2(\Omega)}},   		\\ 		\Osc_\mathsf{CR}^2 		&:=  		\sum_{z\in\vertices} \norm[H^{-1}(\omega_z)]{f - \calP_z f}^2,  	  with the averaging operator $\calA_\mathsf{CR}$ from \eqref{Eq:CR1-averaging}, $\mathcal{K}_T =  \{T\} \cup \{F \in \sides^i \mid F \subset T \}$, the bubble functions $\Psi_T$ and $\Psi_F$ from \eqref{Eq:bubbles}, and the local projections \( \calP_z\) from Lemma~\ref{L:CR-local-projections-1}. This estimator quantifies the error by   \underline{C} \Est_\mathsf{CR}  \leq  \norm[L^2(\Omega)]{\nabla_h(u-u_h)}  \leq  \overline{C} \Est_\mathsf{CR} \quad\text{and}\quad  \eta_{\mathsf{CR},T}   \leq \norm[L^2(\widetilde{\omega}_T)]{\nabla_h(u-u_h)}  where $\widetilde{\omega}_T = \bigcup_{F \in \sides^i, F \subset \partial T} \omega_F$  and the equivalence constants $\underline{C}$ and $\overline{C}$ depend only on the dimension \(d\),  the shape constant \(\gamma_\grid\), and the tuning constants \(C_1, C_2\).  Furthermore, if $f \in L^2(\Omega)$, the oscillation indicator is bounded in terms of the classical $L^2$-oscillation:   \Osc_\mathsf{CR}^2  \lesssim  \sum_{T \in \grid} h_T^2 \inf_{c \in \R} \norm[L^2(T)]{f-c}^2.",2502.01799
theorem,"[Simplified estimator for $\mathsf{CR}$@Poisson]  % Let $u \in \mathring{H}^1(\Omega)$  be the weak solution of the Poisson problem \eqref{Eq:Poisson} and $u_h \in \CR_1$ its quasi-optimal Crouzeix-Raviart approximation from \eqref{Eq:CR-qopt}. Given tuning constants \(C_1,C_2>0\), define  	\Est_{\widetilde{\mathsf{CR}}}^2 	:= 	\Ncf_{\widetilde{\mathsf{CR}}}^2 + C_1^2 \eta_{\widetilde{\mathsf{CR}}}^2 + C_2^2 \Osc_{\widetilde{\mathsf{CR}}}^2,  \text{ where } 	\\ 	 		\Ncf_{\widetilde{\mathsf{CR}}}^2 		&:=  		\norm[L^2(\Omega)]{ \nabla_h( u_h - \calA_\mathsf{CR} u_h ) }^2, 		\\  		\eta_{\widetilde{\mathsf{CR}}}^2 		&:=  		\sum_{T \in \grid} \eta_{{\widetilde{\mathsf{CR}}},T}^2 		%\\ 		\text{ with  } 		\eta_{{\widetilde{\mathsf{CR}}},T} 		:= 		\frac{|\scp{f}{\Psi_T} - \int_\Omega \nabla_h u_h \cdot \nabla \Psi_T |}{\|\nabla \Psi_T\|_{L^2(\Omega)}},  \qquad\qquad 		\\ 		\Osc_{\widetilde{\mathsf{CR}}}^2 		&:=  		\sum_{z\in\vertices} \norm[H^{-1}(\omega_z)]{f - \calP_z f}^2,  	  with the averaging operator $\calA_\mathsf{CR}$ from \eqref{Eq:CR1-averaging}, the element-bubble functions $\Psi_T$  from \eqref{Eq:bubbles}, and the local projections \( \calP_z\) from Lemma~\ref{L:CR-local-projections-2}. This estimator quantifies the error by  	\underline{C} \Est_{\widetilde{\mathsf{CR}}} 	\leq 	\norm[L^2(\Omega)]{\nabla_h(u-u_h)} 	\leq 	\overline{C} \Est_{\widetilde{\mathsf{CR}}} 	\quad\text{and}\quad 	\eta_{{\widetilde{\mathsf{CR}}},T}  	\leq \norm[L^2(T)]{\nabla_h(u-u_h)}  and the equivalence constants $\underline{C}$ and $\overline{C}$ depend only on the dimension \(d\),  the shape constant \(\gamma_\grid\), and the tuning constants \(C_1,C_2\).  Furthermore, if $f \in L^2(\Omega)$, the oscillation indicator is bounded in terms of the classical $L^2$-oscillation:  	\Osc_{\widetilde{\mathsf{CR}}}^2 	\lesssim 	\sum_{T \in \grid} h_T^2 \inf_{c \in \R} \norm[L^2(T)]{f-c}^2.",2502.01799
theorem,"[Estimator for $\mathsf{dG}$@Poisson]  % Let $u \in \mathring{H}^1(\Omega)$  be the weak solution of the Poisson problem \eqref{Eq:Poisson} and $u_h \in S_\ell^0$ its quasi-optimal discontinuous Galerkin approximation from \eqref{Eq:dG-qopt}. Given tuning constants $C_1, C_2,C_3 >0$, define   		\Est_\ell^2 		:=  		 C_1 &\Ncf_\ell^2 + C_2 \eta_\ell^2 + C_3 \Osc_\ell^2, 		\quad\text{where} 		\\ 		\Ncf_\ell^2 		&:= 		\norm[\mathtt{dG}]{u_h - \calA_\ell u_h}^2, 		\quad 		\Osc_\ell^2 		:= 		\sum_{z \in \vertices} \norm[H^{-1}(\omega_z)]{f-\calP_z f}^2, 		\\ 		\eta_\ell^2 		&:= 		\sum_{z \in \vertices}   \eta_{\ell,z}^2 		\quad\text{with}\quad 		\eta_{\ell,z} 		:= 		\sup_{ s \in S_z} 		 \frac{|\scp{f}{s} - \int_{\Omega} \nabla_h u_h \cdot \nabla s|}{\|\nabla s\|_{L^2(\omega_z)}}		  with the averaging operator $\calA_\ell$ from \eqref{Eq:dG-averaging}, the local projections $\calP_z$ from Lemma~\ref{L:dG-local-projections}, the test simple functions $S_z$ from \eqref{Eq:dG-simple-test-functions}, and $\eta_{\ell,z}$ can be computed as indicated in Remark~\ref{R:computing-local-projections}. This estimator quantifies the error by    \underline{C} \Est_\ell   \lesssim   \norm[\mathtt{dG}]{u_h - u }   \lesssim    \underline{C} \Est_\ell  \qquad   \eta_{\ell,z} \leq \norm[L^2(\omega_z)]{\nabla_h(u_h-u)},  where the equivalence constants $\underline{C}, \overline{C}$ depend only on the dimension $d$, the shape constant $\gamma_\grid$, the polynomial degree $\ell$, the stabilization parameter $\sigma$, and the tuning constants $C_1, C_2$ and $C_3$.   Furthermore, if $f \in L^2(\Omega)$, the oscillation indicator is bounded in terms of the classical higher-order $L^2$-oscillation:  	\Osc_\ell^2 	\lesssim 	\sum_{T \in \grid} h_T^2 \inf_{p \in \poly_{\ell-1}} \norm[L^2(T)]{f-p}^2.",2502.01799
theorem,"[Estimator for biharmonic $\COip$] 	 	% 	Let $u\in \mathring{H}^2(\Omega)$ be the weak solution of the biharmonic problem \eqref{Eq:Biharmonic} and   $u_h\in\mathring{S}_2^1$ be its quasi-optimal approximation of the $C^0$ interior penalty method in \eqref{Eq:C0-qopt} with sufficiently large stabilization parameter $\sigma$. Given tuning constants \(C_1,C_2>0\), define 	 		\Est_{\COip}^2 		:= 		\Ncf_{\COip}^2 + C_1^2 \eta_{\COip}^2 + C_2^2\Osc_{\COip}^2,  \text{ where } 		\\ 		 			\Ncf_{\COip}^2 			&:=  			\norm[\mathtt{C0}]{u_h - \calA_{\COip} u_h }^2, 			\\  			\eta_{\COip}^2 			&:=  			\sum_{T \in \grid} \eta_{\COip,T}^2 			\text{ with  } 			\eta_{\COip,T} 			:= 			\max_{ K \in \vertices_T^i \cup \sides_T^i} 			\frac{|\scp{f}{\Upsilon_K} - \int_\Omega D^2_h u_h : D^2 \Upsilon_K |}{\|D^2 \Upsilon_K\|_{L^2(\Omega)}},   			\\ 			\Osc_{\COip}^2 			&:=  			\sum_{z\in\vertices} \norm[H^{-2}(\omega_z)]{f - \calP_z f}^2,  		  swith the averaging operator $\calA_{\COip}$ from \eqref{df:AC0}, $\vertices_T^i = \vertices^i \cap T$, $\sides_T^i = \{ F \in \sides^i \mid F \subset T \}$, the $\HCT$ nodal basis functions $\Upsilon_z := \Upsilon_z^0$ and $\Upsilon_F$, as well as the 	local projections \( \calP_z:H^{-2}(\omega_z) \to D_z \) from Lemma~\ref{L:C0construction-Pz-local}. 	 	This estimator quantifies the error by 	 		\underline{C} \Est_{\COip} 		\leq 		\norm[\COip]{u-u_h} 		\leq 		\overline{C} \Est_{\COip} 		\quad\text{and}\quad 		\eta_{\COip,T}  		\leq 		\norm[L^2(\widetilde{\omega}_T)]{D^2_h(u-u_h)} 	 	where $\widetilde{\omega}_T = \bigcup_{z  \in \vertices_T^i} \omega_z $ and the equivalence 	constants $\underline{C}$, $\overline{C}$ depend only on the shape constant \(\gamma_\grid\), the stabilization constant $\sigma$,  and the tuning constants \(C_1, C_2\). 	 Finally, if $f \in L^2(\Omega)$, we have  		\Osc_{\COip}^2 		\lesssim 		\sum_{T \in \grid} h_T^4 \norm[L^2(T)]{f}^2,  where the latter is formally of higher order.",2502.01799
theorem,"[Estimator for biharmonic $\mr$]  	Let $u\in \mathring{H}^2(\Omega)$ be the weak solution 	of~\eqref{Eq:Biharmonic} and   $u_h\in\MR$ be its quasi-optimal 	Morley approximation from~\eqref{eq:qo-MR}. 	Given a tuning constant \(C>0\), define 	 		\Est_{\mr}^2 		:= 		\Ncf_{\mr}^2 + C^2 \Osc_{\mr}^2,  \text{ where} \quad 		[t] 			\Ncf_{\mr}^2 			&:=  			\norm[L^2(\Omega)]{ D^2_h( u_h - \calA_{\mr} u_h )}^2, 		\\ %\quad\text{and}\quad 			\Osc_{\mr}^2 			&:=  			\sum_{z\in\vertices} \norm[H^{-2}(\omega_z)]{f - \calP_z f}^2,      with the averaging operator $\calA_{\mr}$ from \eqref{df:AHCT}  and the local projections \( \calP_z %:H^{-2}(\omega_z^+) \to D_z \) from Lemma~\ref{L:MRconstruction-Pz-local}. This estimator quantifies the error by  		\underline{C} \Est_{\mr} 		\leq 		\norm[L^2(\Omega)]{D_h^2(u-u_h)} 		\leq 		\overline{C} \Est_{\mr}. %		\intertext{and} %		\underline{C} \Ncf_{\mr,T}:= \underline{C} \norm[L^2(T)]{ D^2_h( u_h - \calA_{\mr} u_h ) %		} %		\le \norm[L^2(\widetilde{\omega}_T)]{D^2_h(u-u_h)}  %	where $\widetilde{\omega}_T = \{ T \} \cup \bigcup_{T'\in \grid, T ' \cap T \in \sides^i} T'$. The equivalence constants $\underline{C}$, and $\overline{C}$ depend only on  the shape constant \(\gamma_\grid\) and the tuning constant \(C\).  Finally, if $f \in L^2(\Omega)$, we have  	\Osc_{\mr}^2 	\lesssim 	\sum_{T \in \grid} h_T^4 \norm[L^2(T)]{f}^2,  where the latter is formally of higher order.",2502.01799
proof,"See \cite[Theorem~4.14]{Veeser.Zanotti:18} and, for the gap between the barriers for $\Cqo$, \cite[Remark~3.5]{Veeser.Zanotti:18}.",2502.01799
proof,"Let us write $e_h := u - u_h$ for the error function and observe $\Pi_V u = u$. In light of \eqref{var-char-of-err},   \norm{u - \Pi_V u_h}  =  \sup_{v \in V, \norm{v} \leq 1} \ta(e_h, v), \quad\text{and}\quad  \norm{u_h - \Pi_V u_h}  =  \sup_{v^\perp \in V^\perp, \norm{v^\perp} \leq 1} \ta(e_h, v^\perp),  the identities for these errors follow from \eqref{extended-var-eq} and the fact that $\tA$ is a linear isometry. The missing identity is then a consequence of orthogonality   \ta(u - \Pi_V u_h, u_h - \Pi_V u_h)  =  \ta(\Pi_V e_h, e_h - \Pi_V e_h)  =  0,   which expresses also the orthogonality of the residual components in $\Dual{\tV}$ endowed with the scalar product $\ta(\tA^{-1}\cdot, \tA^{-1}\cdot)$.",2502.01799
proof,"The upper bound is an immediate consequence of $\calA v_h \in V$, while the lower bound essentially follows from the proof of \cite[Theorem~3.2]{Veeser.Zanotti:18} about the quasi-optimality of a nonconforming method. We provide a sketch for the sake of completeness. Thanks to the compatibility condition in \eqref{A:equiv-to-dist-to-conf}, the following extension of $\calA_h$ to $\widetilde{V}$ is well-defined:  		\widetilde{\calA}_h \widetilde{v} 		:= 		v + \calA_h v_h, 		\quad 		\widetilde{v} = v + v_h \text{ with } v \in V, v_h \in V_h.  Since $V$ and $V_h$ are closed subspaces of $\widetilde{V}$, the extension $\widetilde{\calA}_h$ is bounded, too; cf.\ \cite[Lemma~3.1]{Veeser.Zanotti:18}, swapping the roles of $V$ and $V_h$.  Given $v_h \in V_h$, we can thus write  		v_h - \calA_h v_h  		= 		( \mathrm{id}_{\widetilde{V}} - \widetilde{\calA}_h  ) (v_h - v)  with an arbitrary $v \in V$ and immediately get  		\norm{ v_h - \calA_h v_h } 		\leq 		\norm{ \mathrm{id}_{\widetilde{V}} - \widetilde{\calA}_h } \inf_{v \in V} \norm{v_h - v} 		= 		\norm{ \mathrm{id}_{\widetilde{V}} - \widetilde{\calA}_h }  \norm{v_h - \Pi_V v_h}.  Notably,  \cite[Lemma~3.4]{Veeser.Zanotti:18} shows that $\norm{ \mathrm{id}_{\widetilde{V}} - \widetilde{\calA}_h }^{-1}$ is actually the largest constant $\Cav$ such that the claimed lower bound holds.",2502.01799
proof,"Let $v_h \in V_h$ be such that $\norm{v_h} \leq K \norm{v}$. We add and subtract $\calE_h v_h$ in the action of the conforming %component of the residual   \scp{\Res_h^{\mathtt{C}}}{v}   =  \scp{\Res_h^{\mathtt{C}}}{v - \calE_h v_h}   +  \scp{\Res_h^{\mathtt{C}}}{\calE_h v_h}.   For the second term on the right-hand side, we use the method \eqref{Eq:DisEq}, the $\ta$-orthogonal projection $\Pi_V$, and the quasi-optimality of the method through Proposition~\ref{P:QuasiOptMethods}\eqref{QuasiOptMethods-ConsistencyMeasure}, to derive   \scp{\Res_h^{\mathtt{C}}}{\calE_h v_h}   =  a_h(u_h, v_h) - a(\Pi_V u_h, \calE_h v_h)  \leq  \delta_h \norm[\Dual{V_h}]{A_h^* v_h} \norm{u_h-\Pi_V u_h}.   We thus conclude by recalling that the operator norm of the adjoint $A_h^*$ equals the operator norm of $A_h$.",2502.01799
proof,"We begin by verifying the lower bound. Given $z \in \Index$, let $v_z \in V_z$ be the Riesz representer of $\Res_h^{\mathtt{C}}{}_{|{V_z}}$ in $V_z$ entailing $\norm{v_z} = \norm[\Dual{V_z}]{\Res_h^{\mathtt{C}}}$ and $\scp{\Res_h^{\mathtt{C}}}{v_z} = \norm[\Dual{V_z}]{\Res_h^{\mathtt{C}}}^2$. Defining $v := \sum_{z\in \Index} v_z \in V$, we infer   \sum_{z\in \Index} \norm[\Dual{V_z}]{\Res_h^{\mathtt{C}}}^2  =  \sum_{z\in \Index} \scp{\Res_h^{\mathtt{C}}}{v_z}  =  \scp{\Res_h^{\mathtt{C}}}{v}  \leq  \norm[\Dual{V}]{\Res_h^{\mathtt{C}}}\norm{v}.  Thus, by invoking (ii) in \eqref{A:partition-of-unity}, we obtain the lower bound   \sum_{z\in \Index} \norm[\Dual{V_z}]{\Res_h^{\mathtt{C}}}^2  \leq   \Ccol^2 \norm[\Dual{V}]{\Res_h^{\mathtt{C}}}^2.   To prove the upper bound, let $v \in V$ with $\norm{v} \leq 1$ and set $v_h := \calI_h v \in V_h$. The assumptions (i) and (iii) in \eqref{A:partition-of-unity} provide   \scp{\Res_h^{\mathtt{C}}}{v - \calE_h v_h}  =  \sum_{z\in \Index} \scp{\Res_h^{\mathtt{C}}}{(v - \calE_h \calI_h v)\Phi_z} %\\  \leq  \Cloc \left(   \sum_{z\in \Index} \norm[\Dual{V_z}]{\Res_h^{\mathtt{C}}}^2  \right)^{\frac{1}{2}}.   We use this estimate in Lemma~\ref{L:conforming-residual} with $K = \normtr{\calI_h}$, then take the supremum over $v$ and conclude the upper bound   \norm[\Dual{V}]{\Res_h^{\mathtt{C}}}^2  \leq  2 \delta_h^2 \normtr{A_h}^2 \normtr{\calI_h}^2 \norm{ u_h - \Pi_V u_h}^2  +  2 \Cloc^2 \sum_{z\in \Index} \norm[\Dual{V_z}]{\Res_h^{\mathtt{C}}}^2. \qedhere",2502.01799
proof,"% Pz well-defined Fix any $z \in \Index$. Thanks to the rank-nullity theorem and condition~(iii) in \eqref{A:construction-Pz-local}, the well-posedness of the linear variational problem for $\calP_z$ follows from its uniqueness. To show the latter,  let $\chi \in D_z$ with  $\scp{\chi }{s} = 0$ for all $s \in S_z$, that is \ $\chi_{|S_z} = 0$. Condition~(iv) in \eqref{A:construction-Pz-local} then implies $\chi_{|V_z} = 0$. By its linearity, $\chi$ vanishes on the sum $V_z + S_z$, meaning $\chi = 0$ in the light of (i) in \eqref{A:construction-Pz-local}. Consequently, \eqref{Eq:construction-Pz-local} has a unique solution in $D_z$ and $\calP_z$ is the linear projection from $\Dual{\tV_z}$ onto $D_z$ with the orthogonality property    \forall s \in S_z \qquad \scp{g - \calP_z g}{s} = 0.  % invariance for \tA(V_h) The invariance \eqref{Pz-invariance} then follows from the observation that, for \(v_h\in V_h\), the difference $\calP_z\tA v_h - (\tA v_h)_{|\tV_z}$ is in the image $D_z$ of $\calP_z$ thanks to (ii) in \eqref{A:construction-Pz-local}. 	 % stability Finally, given any $g \in \Dual{V}$, the collective stability bound  \eqref{Eq:boundedness-Pz-local} readily follows by combining (iv) and (v) in \eqref{A:construction-Pz-local} and the orthogonality \eqref{Pz-orthogonality} of $\calP_z$:	   \sum_{z \in \Index} \norm[\Dual{V_z}]{\calP_z g}^2   \leq  \CL^2  \sum_{z \in \Index} \norm[\Dual{S_z}]{\calP_z g}^2  =  \CL^2  \sum_{z \in \Index} \norm[\Dual{S_z}]{g}^2  \leq  \CL^2 \CNL^2  \sum_{z \in \Index} \norm[\Dual{V_z}]{g}^2.\qedhere",2502.01799
proof,"The upper bound follows from the triangle inequality and the special case $(\calP_z \tA u_h){}_{|V_z} = \tA u_h{}_{|V_z}$ of the invariance \eqref{Pz-invariance}:    \norm[\Dual{V_z}]{\Res_h^{\mathtt{C}}}  \le  \norm[\Dual{V_z}]{\calP_z\Res_h^{\mathtt{C}}}   +  \norm[\Dual{V_z}]{\Res_h^{\mathtt{C}}-\calP_z \Res_h^{\mathtt{C}}}  =  \norm[\Dual{V_z}]{\calP_z\Res_h^{\mathtt{C}}}  +  \norm[\Dual{V_z}]{f-\calP_z f}.  The lower bound follows from using the last equality in the opposite direction and applying the collective stability~\eqref{Eq:boundedness-Pz-local} % and near-best approximation \eqref{Pz_qopt}  of the local projections,   \sum_{z\in \Index}\norm[\Dual{V_z}]{\calP_z \Res_h^{\mathtt{C}}}^2  +  \norm[\Dual{V_z}]{f - \calP_z f}^2  \leq  (2 + 3\CL^2\CNL^2)  \sum_{z\in \Index}\norm[\Dual{V}_z]{\Res_h^{\mathtt{C}}}^2.    To show the quantifiability of $\eta_h$, observe that $\bar{\eta}_h^2 := \sum_{z \in \Index} \norm[\Dual{S_z}]{\calP_z \Res_h^{\mathtt{C}}}^2$ is computable thanks to Remark~\ref{R:computing-local-projections} and the assumed knowledge on $\Res_h^{\texttt{C}}$. Furthermore, it is equivalent to $\eta_h$ thanks to (iv) and (v) of \eqref{A:construction-Pz-local}.",2502.01799
proof,"We first show the upper bound. Combining Lemmas~\ref{L:err-res-decomps}, \ref{L:localizating-conf-res}, \ref{L:splitting-of-conf-res}, and Proposition~\ref{P:inds-for-dist-to-conf} leads to   \norm{u-u_h}^2   &=   \norm[\tV']{\Res_h}^2   =   \norm{u_h - \Pi_V u_h}^2  + \norm[V']{\Res_h^\mathtt{C}}^2  \\   &\le    (1 + 2  \Cobl^2 \delta_h^2 ) \Ncf_h^2 + 2 \Cloc^2 \sum_{z \in \Index} \norm[\Dual{V_z}]{\Res_h^\mathtt{C}}^2 \\   &\le   (1 + 2  \Cobl^2 \delta_h^2 ) \Ncf_h^2 + 4 \Cloc^2 (\eta_h^2 + \Osc_h^2).  This implies the upper bound for some  		\overline{C} 		\leq 		\max\left\{ 1, \frac{\sqrt{2}\Cobl}{C_1}, \frac{2\Cloc}{C_2} \right\}.  Regarding the lower bound, we apply the same auxiliary results to derive   \Est_h^2  &\leq  (1 + C_1^2 \delta_h^2) \Cav^{-2} \norm{u_h - \Pi_V u_h}^2  +  C_2^2  \Csplt^{-2} \Ccol^2 \norm[\Dual{V}]{\Res_h^\mathtt{C}}^2 \\  &\leq  \max \big\{ (1 + C_1^2 \delta_h^2) \Cav^{-2}, C_2^2  \Csplt^{-2} \Ccol^2 \big\}   \norm{u-u_h}^2,  whence the lower bound holds for some  	\underline{C} 	\geq 	\max \big\{ (1 + C_1^2 \delta_h^2) \Cav^{-2}, C_2^2  \Csplt^{-2} \Ccol^2 \big\}^{-1}.\qedhere",2502.01799
proof,"Clearly,  $\mathcal{A}_\mathsf{CR}$ satisfies \eqref{A:equiv-to-dist-to-conf} and so the second bound of the claimed equivalence holds. For its first bound, which is equivalent to  $\Cav\gtrsim1$, we have      \norm[L^2(\Omega)]{\nabla_h(v_h - \mathcal{A}_\mathsf{CR} v_h)}^2     \lesssim     \int_\Sigma \dfrac{|\jump{v_h}|^2}{h};    see, e.g., \cite[Theorem~2.2]{Karakashian.Pascal:03}. To conclude, we adapt ideas from~\cite[Theorem 10]{Achdou.Bernardi.Coquel:03} to prove  that the jumps are bounded by the distance to $\mathring{H}^1(\Omega)$.  Let $F \in \sides$ be any face and, for any element \(T\in\grid\) with  \(\partial T\supset F\), define \(\phi_T\in H^1(T)\) as the weak solution of the Neumann problem         -\Delta \phi_T=0~\text{in}~T,\qquad \partial_\normal     \phi_T=\jump{v_h}~\text{on}~F, \quad\text{and}\quad \partial_\normal     \phi_T=0~\text{on}~\partial T\setminus F,     with $\int_T \phi_T = 0$. Note that the existence of $\phi_T$ hinges on $\int_F \jump{v_h} = 0$ and thus on $v_h \in \CR_1$.  For all \(v\in \mathring{H}^1(\Omega)\), integration by parts yields  	\int_F |\jump{v_h}|^2 	= 	\sum_{T \in \grid, T \supset F} \int_{T} \nabla \phi_T \cdot \nabla(v_h-v) 	\le  	\sum_{T \in \grid, T \supset F} \norm[L^2(T)]{\nabla \phi_T}\norm[L^2(T)]{\nabla (v_h-v)}.   For any $T \in \grid$ with $\partial T \supset F$, the norm of $\phi_T$ can be further estimated by  		\norm[L^2(T)]{\nabla \phi_T}^2  		=  		\int_F \jump{v_h}\phi_T 		\lesssim 		h_F^{\frac12}\norm[L^2(F)]{\jump{v_h}}\norm[L^2(T)]{\nabla\phi_T}  with the help of the scaled trace theorem, a Poincar\'e inequality thanks to \(\int_T \phi_T=0\), and $h_T  \lesssim h_F$. Inserting this bound into the previous one shows 	 		\int_{F} \dfrac{|\jump{v_h}|^2}{h} \lesssim \inf_{v \in \mathring{H}^1(\Omega)} \norm[L^2(\omega_F)]{\nabla_h(v_h-v)}^2. 	 	We conclude by summing over all faces, because the number of patches $\omega_F$ containing a given simplex is bounded by $d+1$.",2502.01799
proof,"Property~(i) in \eqref{A:partition-of-unity} is valid because $\Psi_z \in W^{1,\infty}(\Omega)$ and $\operatorname{supp} \Psi_z = \omega_z$ for all $z \in \vertices$ as well as $\sum_{z \in \vertices} \Psi_z = 1$. Property~(ii) follows from  the fact that each given element $T \in \grid$ is contained in $(d+1)$ stars $\omega_z$, $z \in\vertices$, the triangle and the Cauchy-Schwarz inequality. Indeed, given any $v_z \in \mathring{H}^1(\omega_z)$, $z \in \vertices$, we have   \left\| \nabla \left(\sum_{z\in\vertices} v_z \right) \right\|_{L^2(T)}^2  &=  \left\| \sum_{z\in\vertices \cap T} \nabla v_z \right\|_{L^2(T)}^2  \leq  \left( \sum_{z\in\vertices \cap T} \| \nabla v_z  \|_{L^2(T)} \right)^2 \\  &\leq   (d+1) \sum_{z\in\vertices \cap T} \| \nabla v_z  \|_{L^2(T)}^2,  and summing over $T \in \grid$ yields $\Ccol  \leq \sqrt{d+1}$. Finally, in order to verify property~(iii), let $v \in \mathring{H}^1(\Omega)$ and $z \in \vertices$. The scaling properties $\norm[L^\infty(\Omega)]{\Psi_z} = 1$ and $\norm[L^\infty(\Omega)]{\nabla \Psi_z} \eqsim h_z^{-1}$ of the Courant basis functions and a triangle inequality entail  		 			\norm[L^2(\Omega)]{\nabla \big( (v - \calE_{\mathsf{CR}} \calI_\mathsf{CR}v)\Psi_z \big)} 			&\lesssim  			h_z^{-1}\left( \norm[L^2(\omega_z)]{v- \calI_\mathsf{CR} v} 			+ 			\norm[L^2(\omega_z)]{\calI_\mathsf{CR} v - \calE_{\mathsf{CR}} \calI_\mathsf{CR} v}\right) \\ 			&\quad + \norm[L^2(\omega_z)]{\nabla (v - \calE_{\mathsf{CR}} \calI_\mathsf{CR} v)}. 		  Then, the stability properties of the smoother $\calE_{\mathsf{CR}}$, see \eqref{Eq:CR-smoother-stability},  and of  the interpolation $\calI_\mathsf{CR}$ (see \cite[eq. (2.14)]{Brenner:15}) imply   		\sum_{z \in \vertices} \norm[L^2(\Omega)]{\nabla((v - \calE_{\mathsf{CR}} \calI_\mathsf{CR}v)\Psi_z)}^2 		\lesssim  		\sum_{z \in \vertices} \norm[L^2(\omega_z^+)]{\nabla v}^2 		\lesssim 		\norm[L^2(\Omega)]{\nabla v}^2.  Here the second inequality follows from the observation that the number of enlarged stars $\omega_z^+$ containing a given simplex is bounded in terms of the shape constant \(\gamma_\grid\) and $d$. Hence $\Cloc \lesssim 1$.",2502.01799
proof,"Let $z \in \vertices$. As $S_z \subset \mathring{H}^1(\omega_z) = V_z$, the simple test functions are locally conforming. This readily yields condition (i) of \eqref{A:construction-Pz-local} with $\tV_z =  \mathring{H}^1(\omega_z)$, condition (v) with $\CNL=1$, and condition (ii) in the light of \eqref{Eq:action-laplacian}. Condition (iii) holds because the functionals $\mathring{H}^1(\omega_z) \ni v \mapsto \int_K v$, $K \in \grid_z \cup \sides_z^i$, form a basis of $D_z$. Condition (iv) is proved in \cite[Theorems~8-10]{Kreuzer.Veeser:21} with $\CL \lesssim 1$; see also Lemma~\ref{L:CR-local-projections-2} below for a similar argument. Finally, Proposition~\ref{P:construction-Pz-local} provides the existence of $\calP_z$ and the claimed stability bound.",2502.01799
proof,"[Proof of Theorem~\ref{T:CR-error-estimator-1}] % equivalence between estimator and error Thanks to Lemmas~~\ref{L:CR-distance-to-conformity}, \ref{L:CR-partition-of-unity}, and~\ref{L:CR-local-projections-1}, we can apply Theorem~\ref{T:error-estimator} with \eqref{setting-for-Poisson-and-CR1} and \eqref{Eq:CR-partition-of-unity}. The overconsistency of the Crouzeix-Raviart method \eqref{Eq:CR-qopt}, i.e.\ $\delta_h=0$, simplifies the abstract estimator therein and   the claimed equivalence follows with the help of      \sum_{z \in \vertices} \norm[H^{-1}(\omega_z)]{\calP_z\Res_h^{\mathtt{C}}}^2  \eqsim  \sum_{z \in \vertices}  \norm[S_z']{\Res_h^{\mathtt{C}}}^2  \eqsim  \eta_\mathsf{CR}^2,    where the first equivalence is a consequence of properties (iv) and (v) of  \eqref{A:construction-Pz-local} and the second one can be shown with  the arguments in \cite[\S4.1]{Kreuzer.Veeser:21}.    % lower bound  To verify the claimed lower bound, let $T \in \grid$ and $K \in \{T\} \cup \{ F \in \sides^i \mid F \subset \partial T\}$ be arbitrary. Thanks to the weak formulation of \eqref{Eq:Poisson} and $\operatorname{supp} \Psi_K \subset \widetilde{\omega}_T$, we readily obtain the constant-free lower bound    	\frac{|\scp{f}{\Psi_K} - \int_\Omega \nabla_h u_h \cdot \nabla \Psi_K |}{\|\nabla \Psi_K\|_{L^2(\Omega)}}  	=  	\frac{|\int_\Omega \nabla_h (u-u_h) \cdot \nabla \Psi_K|}{\|\nabla \Psi_K\|_{L^2(\Omega)}}  	\leq  	\norm[L^2(\widetilde{\omega}_T)]{\nabla_h(u-u_h)}.   To show the bound for the oscillation, write $\bar{f}$ for the piecewise constant function with $\bar{f}_{|T} = |T|^{-1} \int_T f$ for all $T \in \grid$. Since $\bar{f}_{|\omega_z} \in D_z$ for any vertex $z \in \vertices$, the properties of the local projections and the Poincar\'e inequality imply   \sum_{z \in \vertices} \norm[H^{-1}(\omega_z)]{f - \calP_z f}^2  &=  \sum_{z \in \vertices} \norm[H^{-1}(\omega_z)]{f - \bar{f} - \calP_z(f-\Bar{f})}^2  \lesssim  \sum_{z \in \vertices} \norm[H^{-1}(\omega_z)]{f - \bar{f}}^2 \\  &\lesssim  \sum_{z \in \vertices} h_z^2 \norm[L^2(\omega_z)]{f - \bar{f}}^2  \lesssim  \sum_{T \in \grid} h_T^2 \inf_{c \in \R} \norm[L^2(T)]{f-c}^2  and the proof is finished.",2502.01799
proof,"Let $z \in \vertices$. Clearly, the choices \eqref{simple-CR1-nconf} satisfy conditions (i) and (iii) of  \eqref{A:construction-Pz-local}. In order to verify (ii), let $ v_h \in V_h$, \( v \in \mathring{H}^1(\omega_z)\) and \(s \in S_z\). Then the representation \eqref{Eq:action-laplacian} and $\Delta (v_{h|T}) = 0$ in each $T \in \grid$ yield   \int_\Omega\nabla_hv_h\cdot\nabla (v+s)  =  \sum_{F \in \sides^i_z}  \int_F \jump{\nabla v_h} \cdot \normal (v+s)  +  \sum_ {F' \in \sides \setminus \sides^i_z} \int_{F'} \jump{\nabla v_h} \cdot \normal s  and we have to show that the second sum vanishes. Let $F '\in \sides \setminus \sides^i_z$ be any face appearing therein and observe,  for any $T \in \grid_z^+$ and any $F \in \sides_z^i$, that    \Psi_T{}_{|F'}  = 0, \quad  \int_{F'} \calE_\mathsf{CR} \Psi_F^\mathsf{CR} =  \int_{F'} \Psi_F^\mathsf{CR} = \Psi_F^\mathsf{CR} (m_{F'})= 0  thanks to the moment conservation \eqref{Eq:CR-smoother-moments} and the definition of the Crouzeix-Raviart basis. Therefore, $\int_{F'}  \jump{\nabla v_h} \cdot \normal s =  0$ and condition (ii) is verified.  We next show condition (iv) of \eqref{A:construction-Pz-local}. Given any $\chi \in D_z$ and $v \in \mathring{H}^1(\omega_z)$, we can write	   \langle \chi, v\rangle   =   \sum_{T\in\grid_z^+}\int_T r_T v   +   \sum_{F\in\sides_z^i}\int_F r_F v   for some $r_T \in \poly_0(T)$, $T \in \grid_z^+$ and $r_F\in \poly_0(F)$,  $F\in\sides_z^i$.  Fixing a local test function $v$, we  choose the simple test function  	s 	= 	\sum_{T\in\grid_z^+} s_T \Psi_T + \sum_{F \in \sides_z^i} s_F \calE_{\mathsf{CR}} \Psi_F^\mathsf{CR} \in S_z  where $s_T \in \poly_0(T)$, $T \in \grid_z^+$, and $s_F \in \poly_0(F)$, $F \in \sides_z^i$, solve the problems  		&\forall p_F \in \poly_0(F) \qquad \int_F s_F p_F \Psi_F^\mathsf{CR} = \int_F v p_F, \\ 		% 		&\forall p_T \in \poly_0(T) \qquad \int_Ts_T p_T \Psi_T = \int_T v p_T - \sum_{F \in \sides_z^i} \int_T s_F p_T \calE_{\mathsf{CR}} \Psi_F^\mathsf{CR}.  These problems are uniquely solvable because $\Psi_F^\mathsf{CR}$ and $\Psi_T$ are strictly positive in the interior of $F$ and $T$, respectively. We then have $%  \scp{\chi}{v} = \scp{\chi}{s} $ % and  	\norm[L^2(\omega_z^+)]{\nabla s}  	\lesssim 	h_z^{-1}  \sum_{T\in\grid_z^+} \norm[L^2(T)]{s_T} + h_z^{-\frac{1}{2}}\sum_{F \in \sides_z^i} \norm[L^2(F)]{s_F}  	\lesssim 	\norm[L^2(\omega_z)]{\nabla v},  where the first inequality follows from \eqref{Eq:CR-smoother-stability} and the scaling properties of the basis functions of $S_z$ and, for the second one, we use in addition norm equivalences with bubble functions~\cite[Proposition~1.4]{Verfuerth:13}, trace and Poincar\'e inequalities. Hence, we arrive at   		\dfrac{\left\langle \chi, v\right\rangle }{\norm[L^2(\omega_z)]{\nabla v}} 		\lesssim  		\dfrac{\left\langle \chi, s\right\rangle }{\norm[L^2(\omega_z^+)]{\nabla s}} 		\leq \norm[S_z']{\chi}   and, taking the supremum over $v$, we  obtain the desired condition (iv).          Finally, for verifying condition (v)  in \eqref{A:construction-Pz-local}, assume $g \in H^{-1}(\Omega)$. Since we have $S_z \subset \mathring{H}^1(\omega_z^+)$ and so $\norm[\Dual{S_z}]{g} \leq \norm[H^{-1}(\omega_z^+)]{g}$ for all vertices $z \in \vertices$, the desired bound follows from    \sum_{z\in\vertices}	 \norm[H^{-1}(\omega_z^+)]{g}^2  \lesssim  \sum_{z\in\vertices}	 \norm[H^{-1}(\omega_z)]{g}^2.   Given any vertex $z \in \vertices$ and $v \in \mathring{H}^1(\omega_z^+)$, we can write $ v = \sum_{y \in \vertices \cap \omega_z^+} v \Psi_y$ and have the stability bounds $\norm[L^2(\omega_y)]{\nabla(v \Psi_y)} \lesssim \norm[L^2(\omega_z^+)]{\nabla v}$ thanks to scaling properties of the Courant basis and the Poincar\'e inequality with zero boundary values on $\omega_z^+$. Hence, similarly to the proof of Lemma~\ref{L:CR-partition-of-unity}, we derive     \dfrac{\left\langle g, v\right\rangle }{\norm[L^2(\omega_z^+)]{\nabla v}}  &\lesssim  \sum_{y \in \vertices \cap \omega_z^+} \dfrac{\left\langle g, v\Psi_y\right\rangle }{\norm[L^2(\omega_y)]{\nabla(v \Psi_y)}}  \lesssim   \sum_{y \in \vertices \cap \omega_z^+} \norm[H^{-1}(\omega_y)]{g} \\  & \lesssim  \left(   \sum_{y \in \vertices \cap \omega_z^+} \norm[H^{-1}(\omega_y)]{g}^2  \right)^{1/2},   where in the last inequality we used that $\#(\vertices\cap\omega_z^+)$ is bounded in terms of the shape constant $\gamma_\grid$ and $d$. We take the supremum over $v$, square and sum over all vertices $z$. This verifies \eqref{stability-of-overlapping} because the number of patches $\omega_z^+$ containing a vertex $y$ is again bounded in terms of shape constant \(\gamma_\grid\) and $d$.",2502.01799
proof,"The proof is very similar to the one of Theorem~\ref{T:CR-error-estimator-1}. The main differences for the estimator equivalence are that we must invoke Lemma~\ref{L:CR-local-projections-2} instead of Lemma~\ref{L:CR-local-projections-1} and that  the smoothed CR basis functions do not appear in the estimator in view of their orthogonality \eqref{Eq:CR-further-orthogonality} to the residual. Also the  oscillation bound follows along the same lines, with the caveat that now the condition    \bar{f}_{|\omega_z^+} \in D_z  ensures the invariance $(\calP_z \bar{f})_{|\mathring{H}^1(\omega_z)} = \bar{f}_{|\omega_z}$, where we identify $\bar{f}_{|\omega_z}$ with the functional $\mathring{H}^1(\omega_z) \ni v \mapsto \int_\Omega \bar{f} v$.",2502.01799
proof,"[Proof of \eqref{CR-indicator-comparison}] We use the superscript `$\sim$' to distinguish the spaces and operators related to the estimator $\Est_{\widetilde{\mathsf{CR}}}$ from those related to $\Est_\mathsf{CR}$.   \fbox{\scriptsize 1} The first claimed inequality readily follows by the respective definitions. Furthermore, the  invariance and stability properties of $\calP_z$ as well as $\widetilde{D}_{z}{}_{|\mathring{H}^1(\omega_z)} = D_z$ imply   	\| f - \calP_z  f\|_{H^{-1}(\omega_z)} 	= 	\| (\operatorname{id} - \calP_z) ( f - \widetilde{\calP}_{z} f)\|_{H^{-1}(\omega_z)} 	\lesssim 	\| f - \widetilde{\calP}_{z} f\|_{H^{-1}(\omega_z)}.   Hence, summing over $z \in \vertices$, gives the oscillation bound $\Osc_\mathsf{CR} \lesssim \Osc_{\widetilde{\mathsf{CR}}}$.  \fbox{\scriptsize 2} To prepare the proof of inequality  $\Osc_{\widetilde{\mathsf{CR}}} \lesssim \Osc_\mathsf{CR}$, we introduce a further local projection acting over the extended star $\omega_z^+$: for any vertex $z \in \vertices$, the pair      S_z^+   :=   \mathrm{span}\{ \Psi_T \mid T \in \grid_z^+ \} \oplus \mathrm{span}\{\Psi_F \mid F \in \sides_z^{i+}\}, \\     D_z^+   :=   \Big\{ \chi\in H^{-1}(\omega_z^+)&\mid     \scp{\chi}{v} =\sum_{T\in\grid_z^+} \int_T r_T v + \sum_{F\in\sides_z^{i+}}\int_F r_F v \\ 	&\phantom{\mid} \text{with}~r_T\in \R,\,  T \in \grid_z^+,  \text{ and } r_F\in\R,\, F\in\sides_z^{i+}\Big\},   induces through Proposition~\ref{P:construction-Pz-local} a local projection $\calP_z^+:H^{-1}(\omega_z^+) \to D_z^+$. For a given vertex $y \in \vertices \cap \omega_z$,  combining $D_z^+{}_{|\mathring{H}^1(\omega_y)} = D_y$, $S_y \subset S_z^+$, and  the uniqueness of \eqref{Eq:construction-Pz-local} for \eqref{simple-CR1-conf} yield that, for any $g \in H^{-1}(\Omega)$,   	( \calP_z^+ g)_{|\mathring{H}^1(\omega_y)} = \calP_y g.  Also, there are constants $r_T$, $ T \in \grid_z^+$, and $r_F$, $F \in \sides_z^i$, such that, for all $ v \in \mathring{H}^1( \omega_z)$ and $s \in \widetilde{S}_z$, we have    \scp{\calP_z^+ g}{v+s}   =   \sum_{T \in \grid_z^+} \int_T r_T (v+s)   +   \sum_{F \in \sides_z^i} \int_F r_F  (v+s)  thanks to \eqref{CR-nconf-sides}. In other words, $(\calP_z^+ g)_{|(\mathring{H}^1(\omega_z) + \widetilde{S}_z)}  \in \widetilde{D}_z$ and the invariance of $\widetilde{\calP}_z$ ensure     \big( \calP_z^+g \big)_{|(\mathring{H}^1(\omega_z) + \widetilde{S}_z)}  =  \widetilde{\calP}_z ( \calP_z^+g ).  Note that this property hinges on the companions of the nonconforming element-bubble functions in Remark~\ref{R:nconf-elm-bubbles}.   \fbox{\scriptsize 3} We turn to the proper proof of $\Osc_{\widetilde{\mathsf{CR}}} \lesssim \Osc_\mathsf{CR}$. Employing \eqref{Pzvar-and-Pz+} restricted to $\mathring{H}^1(\omega_z)$, the stability properties of $\widetilde{\calP}_z$, $\widetilde{S}_z \subset \mathring{H}^1(\omega_z^+)$, \eqref{E:omega+<omega} and \eqref{P_z^+-orthogonality},  we obtain   	\norm[H^{-1}(\omega_z)]{ f - \widetilde{\calP}_{z} f} 	&= 	\norm[H^{-1}(\omega_z)]{ f - \calP_z^+ f - \widetilde{\calP}_{z} ( f - \calP_z^+ f)}  	\\ 	& \lesssim 	\norm[H^{-1}(\omega_z^+)]{ f - \calP_z^+ f}  	\lesssim 	\left( 	\sum_{y \in \vertices \cap \omega_z^+} \norm[H^{-1}(\omega_y)]{ f -  \calP_y f }^2 	\right)^{1/2},  and  so squaring, and summing over all vertices, yields the desired bound.  \fbox{\scriptsize 4} Finally, we verify that $\eta_{{{\mathsf{CR}}}}$ cannot be bounded by $\eta_{{\widetilde{\mathsf{CR}}}}$. For $f \in H^{-1}(\Omega)$ and $T \in \grid$, an integration by parts reveals   	\scp{f}{\Psi_T} - \int_\Omega \nabla_h u_h \cdot \nabla \Psi_T = \scp{f}{\Psi_T}.   Moreover, for $F \in \sides^i$, the orthogonality property of the interpolant $\calI_\mathsf{CR}$ in \eqref{Eq:CR-partition-of-unity}, see \cite[Section~2.1]{Brenner:15}, and \eqref{Eq:CR-qopt} entail that  	\scp{f}{\Psi_F} - \int_\Omega \nabla_h u_h \cdot \nabla \Psi_F = \scp{f}{\Psi_F - \calE_{\mathsf{CR}} \calI_\mathsf{CR} \Psi_F}.   The construction of $\calE_{\mathsf{CR}}$ in \cite[Proposition~3.3]{Veeser.Zanotti:19b} reveals that there is a face $F$ such that  $(\Psi_F - \calE_{\mathsf{CR}} \calI_\mathsf{CR} \Psi_F)_{|F}$ is not the zero function. Therefore, fixing that face and taking the source $f$ so that $\scp{f}{v} = \int_F (\Psi_F - \calE_{\mathsf{CR}} \calI_\mathsf{CR} \Psi_F) v$ for $v \in \mathring{H}^1(\Omega)$, we have $\eta_{{{\mathsf{CR}}}} \neq 0$, whereas $\eta_{{\widetilde{\mathsf{CR}}}} = 0$.",2502.01799
proof,"The second inequality holds because the operator $\calA_\ell$ verifies assumption~\eqref{A:equiv-to-dist-to-conf} and it remains to show the first one. Similar to Lemma~\ref{L:CR-distance-to-conformity}, \cite[(3.17)]{Veeser.Zanotti:18b} assures  	\norm[\texttt{dG}]{v_h - \mathcal{A}_\ell v_h}^2     \lesssim     (1+\sigma) \int_\Sigma \dfrac{|\jump{v_h}|^2}{h}.  Since the right-hand side scaled by \(\frac\sigma{1+\sigma}\) is bounded by \(\|v-v_h\|_{\texttt{dG}}\) for any \(v\in \mathring{H}^1(\Omega)\), the proof is finished.",2502.01799
proof,"Since the difference between the settings \eqref{setting-for-Poisson-and-CR1} and \eqref{dG-setting} does not affect the proofs of (i) and (ii) of \eqref{A:partition-of-unity} in Lemma~\ref{L:CR-partition-of-unity}, they  are still valid here. The proof  of condition (iii), however, requires a small change due to the different smoothing operators, namely invoking the stability properties \eqref{Eq:dG-smoother-stability} of $\calE_\ell$ instead of those of $\calE_\mathsf{CR}$ in \eqref{Eq:CR-smoother-stability}.",2502.01799
proof,"Given any vertex $z \in \vertices$, we have \(S_z\subset V_z\), viz.\ the simple functions are locally conforming, and therefore (i) of \eqref{A:construction-Pz-local} holds with $\tV_z = \mathring{H}^1(\omega_z)$, (v) with $\CNL=1$, and (ii) in view of \eqref{Laplace-action-dG}. Condition (iii) holds because $S_z$ determines $D_z$. Condition~(iv) with $\CL \lesssim 1$ is shown in  \cite{Kreuzer.Veeser.Zanotti:24} by using an argument similar to the corresponding one in Lemma~\ref{L:CR-local-projections-2}.  Then Proposition~\ref{P:construction-Pz-local} implies the existence of $\calP_z$ and the collective stability bound.",2502.01799
proof,"[Proof of Theorem~\ref{T:dG-error-estimator}] Supposing the settings \eqref{dG-setting} and \eqref{Eq:dG-partition-of-unity}, Lemmas~\ref{L:dG-distance-to-conformity}, \ref{L:dG-partition-of-unity}, and \ref{L:dG-local-projections} verify \eqref{A:equiv-to-dist-to-conf}, \eqref{A:partition-of-unity} and \eqref{A:construction-Pz-local}. Hence, we can apply Theorem~\ref {T:error-estimator}  and  the claimed equivalence follows from        \sum_{z \in \vertices} \norm[H^{-1}(\omega_z)]{\calP_z \Res_h^{\mathtt{C}}}^2     \eqsim \sum_{z \in \vertices}     \norm[S_z']{\Res_h^{\mathtt{C}}}^2,  which is a consequence of (iv) and (v) in \eqref{A:construction-Pz-local}. The lower bound is an immediate consequence of the definition of $\eta_{\ell,z}$ and $\scp{\Res_h^\mathtt{C}}{s} = \int_\Omega \nabla_h (u-u_h) \cdot \nabla s$ for all $s \in S_z$.",2502.01799
proof,"The functions $\Upsilon_z^0$, $z \in \vertices$, form a partition of unity because the function $1_\Omega$ that equals $1$ in $\Omega$ satisfies $1_\Omega \in \HCT$ and $\nabla 1_\Omega = 0$ in $\Omega$. The identities for the supports are also immediate. Regarding the scaling properties, we only prove those of $\Upsilon_z^0$, $z \in \vertices$,  while those for $\Upsilon_z^j$, $z\in\vertices$, $j=1,2$, and $\Upsilon_F$, $F \in \sides$, follow from a similar reasoning; compare also with \cite[Lemma~3.14]{Veeser.Zanotti:19b}. 	 	The first two equivalences for $\Upsilon_z^0$ immediately follow from the fact that \(\Upsilon^0_z{}_{|T}\in S_3^0(\grid_T)\), which is finite dimensional and affine equivalent to a corresponding reference space. 	 	For the third or last equivalence for $\Upsilon_z^0$, however, notice that the nodal variables involve normal derivatives and are thus not affine equivalent. To overcome this, we follow the idea in the proof of~\cite[Theorem 6.1.3]{Ciarlet:2002}, which involves a similar, affine equivalent finite element: Fix \(T\in\grid\) with \(z\in T\) and observe that \(S_3^2(\grid_T)\) is also determined by the evaluations of \(p(z)\), \(\nabla p(z)\cdot(y-z)\), for \(z,y\in\vertices\cap T\) with \(z\neq y\) and \(\nabla p(m_F)\cdot(m_T-m_F)\) for 	\(F\in\sides(T) :=\{F\in\sides\mid F\subset T\}\). We denote the corresponding nodal basis functions by \(\tilde\Upsilon_z\), 	\(\tilde \Upsilon_z^y\),  \(z,y\in\vertices\cap T\) with \(z\neq y\) and \(\tilde\Upsilon_F\) for \(F\in\sides(T)\), respectively. As this new finite element is affine equivalent, we derive in particular 	 		 		\norm[L^\infty(T)]{\tilde\Upsilon_z} \eqsim 1 		\quad\text{and}\quad 		\norm[L^\infty(T)]{\tilde\Upsilon_F} \eqsim 1  	 	by standard arguments. To conclude, we relate the new basis functions with the original ones. Given \(F \in\sides(T)\) with \(z\in F\), let \(y_F\in\vertices\cap F\) with \(y\neq z\) and,  from the definition of \(\Upsilon_z^0\), deduce the representation 	 		\Upsilon_z^0 		= 		\tilde \Upsilon_z + \frac32 \sum_{F\in\sides(T),z\in F} \frac{(z-y_F)}{|z-y_F|^2}% \cdot\tangent_F 		% \tangent_F 		\cdot(m_T-m_F)\tilde\Upsilon_F.  	 	 	% Indeed, this is based on the observation that 	% \(\Upsilon_z^0(m_F)\cdot\normal_F=0\) implies that 	% \(\nabla\Upsilon_z^0(m_F)=\nabla\Upsilon_z^0(m_F)\cdot\texsf{t}_F\texsf{t}_F\). 	% Moreover, thanks to the nodal conditions on \(\Upsilon_z^0\), we have 	% that   \(3t^2-2t^3:=\Upsilon_z^0(tz+(1-t)y))\in\poly_3([0,1])\) 	% and thus 	%  		%   \frac32=\frac{d}{dt}(3t^2-2t^3)_{|t=\frac12}=\nabla\Upsilon_z^0(m_F)\cdot(z-y_F)=\nabla\Upsilon_z^0(m_F)\cdot 		%   \texsf{t}_F(z-y_F)  \texsf{t}_F. 		%  	% Now the claimed representation follows by observing that 	% \((z-y_F)  \cdot\texsf{t}_F=\pm |x-y_F|\). Hence the desired equivalence $\norm[L^\infty(T)]{\Upsilon_z^0} \eqsim 1$ follows from \eqref{scaling-for-similar-affequiv} and the relationship	\(|m_T-m_F|/|z-y_F|\eqsim1\), where, as before, the hidden constants depend only on the shape constant \(\gamma_\grid\).",2502.01799
proof,"We first verify \eqref{A:equiv-to-dist-to-conf} for $\calA_{\COip}$. Since $\HCT \subset H^2(\Omega)$ and definition \eqref{df:AC0} does not involve any basis functions associated with the boundary $\partial\Omega$, we have $\calA_{\COip} v_h \in \mathring{\HCT} := \HCT \cap \mathring{H}^2(\Omega)$ for all $v \in \mathring{S}^1_2$. Clearly, $\calA_{\COip}$ is invariant on $\mathring{S}^1_2 \cap \mathring{H}^2(\Omega) = \mathring{S}^1_2 \cap \mathring{\HCT}$. Assumption \eqref{A:equiv-to-dist-to-conf} is thus verified, as well as the second inequality of the claimed equivalence. 	 	To show the first inequality, we combine stability properties of $\calA_{\COip}$ and properties of the basis function in Lemma~\ref{L:ScalingUpsilon}. Given $v_h \in \mathring{S}^1_2 \subset C^0(\bar{\Omega})$ and an element \(T\in\grid\), we have $v_h{}_{|T} \in \poly_2(T) \subset S^2_3(\grid_T)$ and  	 		%D^2_h 		(v_h - \calA_{\COip}(v_h))_{|T} 		= 		\sum_{z\in\vertices^i \cap T} \sum_{j=1}^2 \frac{\partial}{\partial x_j}({v_h}_{|T}-\calA_{\COip} v_h)(z) %D^2 		\Upsilon_{z|T}^{j} 		\\ 		{} + \sum_{F\in\sides,\,F\subset T} \partial_{\normal}(v_{h|T} -\calA_{\COip}v_h) (m_F) %D^2 		\Upsilon_{F|T}, 	 	whence 	 		\norm[L^2(T)]{D^2_h(v_h - \calA_{\COip}(v_h))} 		\le 		\sum_{z \in \vertices^i \cap T} |\nabla({v_h}_{|T}-\calA_{\COip}v_h)(z)| \, 		\left( \sum_{j=1}^2\norm[L^2(T)]{D^2\Upsilon_z^{j}}^2\right)^{\frac12} 		\\ 		{} +\sum_{F\in \sides,F\subset T} |\partial_\normal ({v_h}_{|T}-\calA_{\COip}v_h)(m_F)| \, \norm[L^2(T)]{D^2\Upsilon_F}. 	 	Thanks to the definition \eqref{df:AC0}, we observe $ \nabla(\calA_{\COip}v_h)(z) = \nabla (v_h{}_{|T_z})(z)$ as well as $ \partial_\normal (\calA_{\COip}v_h)(m_F) = \partial_\normal (v_h{}_{|T_F})(m_F)$.  Furthermore, the continuity of \(v_h\) entails |\(\jump{\nabla v_h}| = |\jump{\partial_{\normal}v_h}| \) on the skeleton $\Sigma$.  We thus obtain 	 		 			 			|\nabla({v_h}_{|T}-\calA_{\COip}v_h)(z)| 			&\lesssim 			\sum_{F\in\sides_z^i} \|h^{-\frac12}\jump{\partial_{\normal}  v_h}\|_{L^2(F)}, 			\quad 			z\in\vertices^i, 			\\ 			% = 			% \sum_{F\in\sides,z\inF}\|h^{-\frac12}\jump{\partial_\normal 				% v_h}\|_{L^2(F)}; 			%\intertext{and} 			|\nabla({v_h}_{|T}-\calA_{\COip}v_h)(m_F)| 			&\lesssim 			\|h^{-\frac12}\jump{\partial_{\normal} v_h}\|_{L^2(F)}, 			\quad 			F\in\sides. 		 	 	We insert these two inequalities in the preceding one and use the scaling properties in Lemma~\ref{L:ScalingUpsilon}. As each side \(F\in\sides\) is contained in at most two of the sets \(\{\sides_z^i\}_{z\in\vertices^i}\), we conclude the proof by arriving at 	 		\norm[\COip]{\calA_{\COip}v_h-v_h}^2 		\lesssim 		(1+\sigma)\sum_{F\in\sides}\|h^{-\frac12}\jump{\partial_{\normal} v_h}\|_{L^2(F)}^2 		\le 		\frac{1+\sigma}{\sigma}\norm[\COip]{v-v_h}^2, 	 	where  \(v\in \mathring{H}^2(\Omega)\) is arbitrary.",2502.01799
proof,"%  We first 	%    employ that \(\int_F \jump{\nabla_h v_h}=0\). (Indeed, 	%    \(\int_F \jump{\nabla_h v_h\cdot\normal}=0\) follows 	%    explicitly from the definition of \(\MR\) and \(\int_F \jump{\nabla_h v_h\cdot\tangent_F}=0\) 	%    follows from the continuity of \(v_h\) in \(\vertices\).) We thus 	%    have from Poincar\'e estimates that 	%     		%      \|h^{-\frac12}\jump{\nabla_h 			%      v_h}\|_{L^2(F)}\lesssim \|h^{\frac12}\jump{D^2_h 			%      v_h}\tangent_F\|_{L^2(F)}. 		%     	%    We can now proceed as in the proof of 	%    \cite[Proposition 2.3]{GallistlMorley} and define 	%    \(\phi_F:=\jump{D^2_h  		%      v_h}\tangent_F \Psi_F\) with  	%    the piecewise 	%    quadratic edge-bubble function \(\Psi_F\) 	%    from~\eqref{eq:bubbles}. Since \(\int_F \Psi_F=1\), we 	%    have for any \(v\in \mathring{H}^2(\Omega)\) that 	%     		%      \|\jump{D^2_h 			%      v_h}\tangent_F\|_{L^2(F)}^2=\int_F \jump{D^2_h 			%      v_h}\tangent_F\cdot \phi_F 		%      =\int_{\omega_F}D^2_h(v_h-v):\operatorname{Curl} \phi_F 		%     	%    with 	%     		%      \operatorname{Curl} \phi_F= 		%       			%        -\partial\phi_{F,1}/\partial 			%        x_2&\partial\phi_{F,1}/\partial x_1\\ 			%        -\partial\phi_{F,2}/\partial 			%        x_2&\partial\phi_{F,2}/\partial x_1 			%      . 		%     	%     Cauchy and inverse inequalities 	%    imply 	%     		%      \|h^{-\frac12}\jump{\nabla_h 			%      v_h}\|_{L^2(F)}^2\lesssim \norm[L^2(\omega_F)]{D^2_h(v_h-v)}^2. 		%     	%    The assertion follows by  	%    taking the infimum over all \(v\in \mathring{H}^2(\Omega)\). 	%",2502.01799
proof,%   The fact that that \(\EMR \) is a right inverse of \(\PiMorley\) implies \(v_h - \EMR  	%   v_h=(\operatorname{id}-\PiMorley)(v_h - \EMR  v_h) \) and the 	%   claim follows from interpolation properties of the Morley projection~\cite[Proposition 2.3]{GallistlMorley}. 	%,2502.01799
proof,"%  We first conclude from \( \calA^{\textsf{MR}} v_h\in \mathring{H}^2(\Omega)\) that \(\norm[L^2(\Omega)]{D^2_h(\Pi_V v_h - v_h)}^2 \le 	%    \norm[L^2(\Omega)]{D^2_h(\calA^{\textsf{MR}}  v_h - v_h)}^2\). Recalling the 	%    definition~\eqref{df:AHCT} of \(\calA^{\textsf{MR}} \), we have in \(T\in\grid\) 	%    % 	%     		%      D^2_h(v_h - \calA^{\textsf{MR}}(v_h)) = 		%      %\\ 		%      \sum_{F\in\sides^i} 		%      \sum_{z\in\vertices\capF}\sum_{i=1}^2 		%      \partial_i({v_h}_{|T}-\calA^{\textsf{MR}} v_h)(z) D^2\Upsilon_z^{i} 		%     	%      % \left[\int_F\nabla\cdot\normal, 	%      %   \int_F\nabla\Upsilon_z^{2}\cdot\normal\right]^\top D^2 \norFaceBubb. 	%    % 	%    Now using that \(\nabla_h({v_h}-\calA^{\textsf{MR}} v_h)\) is piecewise 	%    polynomial, we obtain with classical equivalence of norms and scaling arguments that 	%     		%      |\nabla_h({v_h}_{|T}-\calA^{\textsf{MR}} v_h)(z)| \lesssim  \sum_{F\in\sides_z^i}\|h^{-\frac12}\jump{\nabla_h 			%      v_h}\|_{L^2(F)}; 		%    % = \sum_{F\in\sides,z\inF}\|h^{-\frac12}\jump{\partial_\normal 			%    %   v_h}\|_{L^2(F)}; 		%     	%    compare with the proof of~\cite[Proposition 3.17]{VZ2}.  	%    The inequality \(\norm[L^2(\Omega)]{D^2_h(\calA^{\textsf{MR}}  v_h - v_h)}^2 \lesssim 	%    \sum_{F\in\sides} \int_F \frac{1}{h} 	%    \abs{\jump{\nabla_h v_h}}^2\) follows with the scaling of 	%    the averaged HCT basis functions~\cite[Lemma 3.14]{VZ2}. 	 	%    The reversed inequality follows from 	%    Proposition~\ref{P:jumps<confMR} 	%    summing over all \(F\in\sides\) and accounting for the fact 	%    that the patches \(\omega_F\), \(F\in\sides\), overlap at 	%    most twice. 	%",2502.01799
proof,"% checking (i) and (ii) 	Since \(\Upsilon^0_z\in W^{2,\infty}(\Omega)\) and  \(\operatorname{supp}\Upsilon_z^0=\omega_z\), condition~(i) of \eqref{A:partition-of-unity} holds with \(V_z=\mathring{H}^2(\omega_z)\) and \(\Index=\vertices\). Similarly to the proof in Lemma~\ref{L:CR-partition-of-unity}, condition~(ii) follows with \(\Ccol=3\) from the fact that  each mesh element is contained in three stars. % \(\omega_z\), \(z\in\vertices\). 	 	% checking (iii) 	It remains to check condition (iii) of \eqref{A:partition-of-unity}. Given any \(v\in \mathring{H}^2(\Omega)\) and $z \in \vertices$, we may write 	 		\norm[\COip]{\big((v - \calE_{\COip}(\mathcal{I}_{L} v) \big)\Upsilon_z^0}  		\leq 		\norm[\COip]{(v-\mathcal{I}_{L} v) \Upsilon_z^0} 		+ 		\norm[\COip]{ \big( \mathcal{I}_{L} v - \calE_{\COip} (\mathcal{I}_{L} v) \big) \Upsilon_z^0}. 	 	The first term on the right-hand side can be bounded by means of trace inequalities, standard interpolation error estimates, the stability bound $\norm[L^2(\omega_z)]{D^2_h(\calI_ L v)} \lesssim  \norm[L^2(\omega_z)]{D^2 v}$ and the scaling properties of $\Upsilon_z^0$ in Lemma~\ref{L:ScalingUpsilon}. For the second term, we use again Lemma~\ref{L:ScalingUpsilon}, \eqref{eq:EC0stab}, a scaled trace inequality and  again error and stability bounds of $\calI_{L}$ to derive  	 		\norm[\COip]{ \big( \mathcal{I}_{L} v - \calE_{\COip} (\mathcal{I}_{L} v) \big) \Upsilon_z^0}^2\\ 		 			&\lesssim 			\norm[{L^2(\omega_z)}]{ h^{-2} \big( \mathcal{I}_{L}v-\calE_{\COip}(\mathcal{I}_{L} v) \big)}^2 			+ 			\norm[{L^2(\omega_z)}]{ h^{-1} \nabla \big( \mathcal{I}_{L} v-\calE_{\COip}(\mathcal{I}_{L} v) \big)}^2 			\\ 			&\quad 			{} + 			\norm[{L^2(\omega_z)}]{ D^2_h \big( \mathcal{I}_{L} v-\calE_{\COip}(\mathcal{I}_{L} v) \big)}^2 			+ 			\sigma\sum_{F\in\sides_z}\int_{F}\frac1h\jump{\partial_\normal\mathcal{I}_{L} v}^2 			\\ 			&\lesssim 			\norm[L^2(\omega_z^+)]{D^2 v}^2 %			+ %			\sigma \sum_{F\in\sides_z^{+}}\int_{F}\frac1h\jump{\partial_\normal\mathcal{I}_{L} v}^2, 		 	 	%  In particular, the last inequality follows as in \cite[Proposition 3.17]{Veeser.Zanotti:18b}. 	where \(\sides_z^{+}=\bigcup\{\sides_y\mid  y\in \vertices\cap\omega_z\}\). We collect the previous bounds and sum over all vertices $z \in \vertices$. This finishes the proof as  the stars \(\omega_z^+\), \(z\in\vertices\), overlap finitely many times and, for each edge \(F\in\sides\), we have $\#\{ z \in \vertices \mid \sides_z^+ \ni F\} \lesssim 1$.",2502.01799
proof,"%   Thanks to Lemma~\ref{L:C0-partition-of-unity}, the assertion readily 	%   follows from Lemma~\ref{L:localizating-conf-res}. The boundedness of 	%   the constants \(\Cobl\le \normtr{A_h} 	%  \normtr{\calI_h}\), \(\Cloc\) and  	%  \(\delta_{\COip}\) is proved in \cite[\S 3.4]{Veeser.Zanotti:18b}. 	%",2502.01799
proof,"Conditions (i), (ii) and (v) of \eqref{A:construction-Pz-local} immediately follow from \(S_z\subset \mathring{H}^2(\omega_z)\) and~\eqref{eq:StructOfDC0}. In view of Remark~\ref{R:C0BiorthogonalSystem}, we have \(\dim S_z= \dim D_z < \infty\) for all \(z\in\vertices\), which implies (iii) and it remains to prove (iv). To this end, we combine the duality in Remark~\ref{R:C0BiorthogonalSystem} with the scaling properties of the involved basis functions, considering only the case of an interior vertex \(z\in\vertices^i\). Given a simple functional \(\chi\in D_z\) and $v \in \mathring{H}^2(\omega_z)$, we write  	 		\langle{\chi,v}\rangle 		= 		r_zv(z)+\sum_{F \in \sides_z^i} r_F\int_F \partial_\normal v, 	 	and, by means of scaled trace and Poincar\'e inequalities, derive 	 		 		\langle\chi,v\rangle 		\lesssim 		\Big(h^2_z |r_z|^2 +\sum_{F\in\sides_z^i} h_z^2 |r_F|^2 \Big)^{\frac12} \norm[L^2(\omega_z)]{D^2v}. 	 	In addition, the duality of Remark~\ref{R:C0BiorthogonalSystem} and the scaling properties in Lemma~\ref{L:ScalingUpsilon} ensure  	 		h_z |r_z| 		= 		h_z|\langle \chi,\Upsilon_z \rangle| 		\lesssim 		\norm[\Dual{S_z}]{\chi} , 		\qquad \text{and} \qquad 		h_z^{\frac12} |r_F| 		= 		h_z|\langle \chi,\tfrac32 h_F^{-1}\Upsilon_F\rangle| 		\lesssim 		\norm[\Dual{S_z}]{\chi}, 	 	with hidden constants depending only on the shape constant \(\gamma_\grid\). Inserting these estimates in~\eqref{Eq:BiScaledResiduals} and taking the supremum over all \(v\in \mathring{H}^2(\omega_z)\) finishes the proof of \eqref{A:construction-Pz-local}.",2502.01799
proof,"[Proof of Theorem~\ref{TH:mainC0}] Recall that, according to \cite[Theorem 3.18]{Veeser.Zanotti:18b}, we have that \(\delta_h\lesssim 1\) depending only on the shape constant  \(\gamma_\grid\) and the penalty parameter \(\sigma>\sigma_*\). Thanks to Lemmas~\ref{L:C0dist2conf},~\ref{L:C0construction-Pz-local} and~\ref{L:C0-partition-of-unity}, we can apply Theorem~\ref{T:error-estimator} and the claimed equivalence as well as the local lower bound follow with similar arguments as in the proof of Theorem~\ref{T:CR-error-estimator-1}; note that for the oscillation bound, just stability and no invariance of $\calP_{z}$ is invoked.",2502.01799
proof,"The operator $\calA_{\mr}$ maps \(\MR\) into $ \mathring{\HCT} = \HCT \cap \mathring{H^2}(\Omega) $ and is invariant on \( \MR\cap \mathring{H}^2(\Omega)\subset \mathring{\HCT}\). Hence, \eqref{A:equiv-to-dist-to-conf} and the second claimed inequality hold.  % second inequality It remains to show the first claimed inequality. Given $v_h \in \MR$ and a fixed  element \(T\in\grid\), we have $v_h{}_{|T} \subset S^2_3(\grid_T)$ and thus  		D^2_h \big( v_h - \calA_{\mr}(v_h) \big)_{|T} 		= 		%\\ 		\sum_{z\in\vertices^i\cap T} \sum_{j=1}^2 		\partial_j({v_h}_{|T}-\calA_{\mr} v_h)(z) D^2\Upsilon_z^{j}{}_{|T}.  Furthermore, arguing similarly as for~\eqref{Eq:Dvh-DAvh<DJumps}, % from \(\operatorname{supp}\Upsilon_z^i=\omega_z\), \(i=1,2\), that %  %   \norm[L^2(T)]{D^2_h(v_h - \calA_{\mr}(v_h))}\le %   \sum_{z\in T\cap\vertices}|\nabla_h({v_h}_{|T}-\calA_{\mr} v_h)(z)|\, \norm[L^2(T)]{D^2\Upsilon_z^{i}} %  % Using that \(\nabla_h({v_h}-\calA_{\mr} v_h)\) is piecewise % polynomial, we obtain with classical equivalence of norms and scaling arguments that   		|\nabla_h({v_h}_{|T}-\calA_{\mr} v_h)(z)| 		\lesssim  		\sum_{F\in\sides_z^i}\|h^{-\frac12}\jump{\nabla_h v_h}\|_{L^2(F)}, 		% = \sum_{F\in\sides,z\inF}\|h^{-\frac12}\jump{\partial_\normal 		%   v_h}\|_{L^2(F)};  % compare with the proof of~\cite[Proposition % 3.17]{Veeser.Zanotti:19b}. % It follows from the scaling of % the averaged HCT basis functions~\cite[Lemma % 3.14]{Veeser.Zanotti:19b} that % In order to prove the second inequality,  where each face contribution has mean value zero, i.e.	\(\int_F \jump{\nabla_h v_h}=0\) for all $F \in \sides_z^i$.  Indeed, \(\int_F \jump{\nabla_h v_h\cdot\normal}=0\) follows explicitly from the definition of \(\MR\), while \(\int_F \jump{\nabla_h v_h\cdot\tangent_F}=0\), where the unit vector $\tangent_F = (-\normal_2,\normal_1)_{|F}$ is  tangent to $F$, is a consequence of  the continuity of \(v_h\) in \(\vertices\). Hence,  a Poincar\'e inequality implies   		\|h^{-\frac12}\jump{\nabla_h v_h}\|_{L^2(F)} 		\lesssim 		\|h^{\frac12}\jump{D^2_h v_h}\tangent_F\|_{L^2(F)}.  As in the proof of \cite[Proposition 2.3]{Gallistl:15}, we introduce \(\phi_F := \jump{D^2_h v_h} \tangent_F \Psi_F / \int_F\Psi_F \) with the piecewise quadratic edge-bubble function \(\Psi_F\) from~\eqref{Eq:bubbles} and observe that,  for \(v \in \mathring{H}^2(\Omega)\),  		\|\jump{D^2_h v_h}\tangent_F\|_{L^2(F)}^2 		= 		\int_F \jump{D^2_h	v_h} \tangent_F \cdot \phi_F 		= 		\int_{\omega_F}D^2_h(v_h-v):\operatorname{Curl} \phi_F  with  		\operatorname{Curl} \phi_F= 		 			-\partial\phi_{F,1}/\partial 			x_2&\partial\phi_{F,1}/\partial x_1\\ 			-\partial\phi_{F,2}/\partial 			x_2&\partial\phi_{F,2}/\partial x_1 		.  Cauchy and inverse inequalities thus lead to   		\|h^{-\frac12}\jump{\nabla_h v_h}\|_{L^2(F)}^2 		\lesssim 		\norm[L^2(\omega_F)]{D^2_h(v_h-v)}^2.  We combine the above bounds with the scaling properties of $\Upsilon_z^{j}$, $j=1,2$, in Lemma~\ref{L:ScalingUpsilon} , sum over all elements $T\in\grid$,  and  take the infimum over all \(v\in \mathring{H}^2(\Omega)\). This concludes the second claimed inequality thanks to  the fact that the overlapping of the sets $\omega_F $ with $F \in \sides_z^i$, $z \in \vertices^i \cap T$, and $T \in \grid$ is bounded in terms of the shape constant $\gamma_\grid$.",2502.01799
proof,"%  We first 	%    employ that \(\int_F \jump{\nabla_h v_h}=0\). (Indeed, 	%    \(\int_F \jump{\nabla_h v_h\cdot\normal}=0\) follows 	%    explicitly from the definition of \(\MR\) and \(\int_F \jump{\nabla_h v_h\cdot\tangent_F}=0\) 	%    follows from the continuity of \(v_h\) in \(\vertices\).) We thus 	%    have from Poincar\'e estimates that 	%     		%      \|h^{-\frac12}\jump{\nabla_h 			%      v_h}\|_{L^2(F)}\lesssim \|h^{\frac12}\jump{D^2_h 			%      v_h}\tangent_F\|_{L^2(F)}. 		%     	%    We can now proceed as in the proof of 	%    \cite[Proposition 2.3]{GallistlMorley} and define 	%    \(\phi_F:=\jump{D^2_h  		%      v_h}\tangent_F \Psi_F\) with  	%    the piecewise 	%    quadratic edge-bubble function \(\Psi_F\) 	%    from~\eqref{eq:bubbles}. Since \(\int_F \Psi_F=1\), we 	%    have for any \(v\in \mathring{H}^2(\Omega)\) that 	%     		%      \|\jump{D^2_h 			%      v_h}\tangent_F\|_{L^2(F)}^2=\int_F \jump{D^2_h 			%      v_h}\tangent_F\cdot \phi_F 		%      =\int_{\omega_F}D^2_h(v_h-v):\operatorname{Curl} \phi_F 		%     	%    with 	%     		%      \operatorname{Curl} \phi_F= 		%       			%        -\partial\phi_{F,1}/\partial 			%        x_2&\partial\phi_{F,1}/\partial x_1\\ 			%        -\partial\phi_{F,2}/\partial 			%        x_2&\partial\phi_{F,2}/\partial x_1 			%      . 		%     	%     Cauchy and inverse inequalities 	%    imply 	%     		%      \|h^{-\frac12}\jump{\nabla_h 			%      v_h}\|_{L^2(F)}^2\lesssim \norm[L^2(\omega_F)]{D^2_h(v_h-v)}^2. 		%     	%    The assertion follows by  	%    taking the infimum over all \(v\in \mathring{H}^2(\Omega)\). 	%",2502.01799
proof,%   The fact that that \(\EMR \) is a right inverse of \(\PiMorley\) implies \(v_h - \EMR  	%   v_h=(\operatorname{id}-\PiMorley)(v_h - \EMR  v_h) \) and the 	%   claim follows from interpolation properties of the Morley projection~\cite[Proposition 2.3]{GallistlMorley}. 	%,2502.01799
proof,"%  We first conclude from \( \calA_{\mr} v_h\in \mathring{H}^2(\Omega)\) that \(\norm[L^2(\Omega)]{D^2_h(\Pi_V v_h - v_h)}^2 \le 	%    \norm[L^2(\Omega)]{D^2_h(\calA_{\mr}  v_h - v_h)}^2\). Recalling the 	%    definition~\eqref{df:AHCT} of \(\calA_{\mr} \), we have in \(T\in\grid\) 	%    % 	%     		%      D^2_h(v_h - \calA_{\mr}(v_h)) = 		%      %\\ 		%      \sum_{F\in\sides^i} 		%      \sum_{z\in\vertices\capF}\sum_{i=1}^2 		%      \partial_i({v_h}_{|T}-\calA_{\mr} v_h)(z) D^2\Upsilon_z^{i} 		%     	%      % \left[\int_F\nabla\cdot\normal, 	%      %   \int_F\nabla\Upsilon_z^{2}\cdot\normal\right]^\top D^2 \norFaceBubb. 	%    % 	%    Now using that \(\nabla_h({v_h}-\calA_{\mr} v_h)\) is piecewise 	%    polynomial, we obtain with classical equivalence of norms and scaling arguments that 	%     		%      |\nabla_h({v_h}_{|T}-\calA_{\mr} v_h)(z)| \lesssim  \sum_{F\in\sides_z^i}\|h^{-\frac12}\jump{\nabla_h 			%      v_h}\|_{L^2(F)}; 		%    % = \sum_{F\in\sides,z\inF}\|h^{-\frac12}\jump{\partial_\normal 			%    %   v_h}\|_{L^2(F)}; 		%     	%    compare with the proof of~\cite[Proposition 3.17]{VZ2}.  	%    The inequality \(\norm[L^2(\Omega)]{D^2_h(\calA_{\mr}  v_h - v_h)}^2 \lesssim 	%    \sum_{F\in\sides} \int_F \frac{1}{h} 	%    \abs{\jump{\nabla_h v_h}}^2\) follows with the scaling of 	%    the averaged HCT basis functions~\cite[Lemma 3.14]{VZ2}. 	 	%    The reversed inequality follows from 	%    Proposition~\ref{P:jumps<confMR} 	%    summing over all \(F\in\sides\) and accounting for the fact 	%    that the patches \(\omega_F\), \(F\in\sides\), overlap at 	%    most twice. 	%",2502.01799
proof,"Conditions (i) and (ii) in~\eqref{A:partition-of-unity} follow as in the proof of Lemma~\ref{L:C0-partition-of-unity} and we only need to verify condition~(iii). Let \(v\in \mathring{H}^2(\Omega)\).  The properties \eqref{eq:EMR} ensure that \(\calE_{\mr}\) is a bounded right inverse of \(\Pi_{\mr}\); see \cite[Lemma~3.13]{Veeser.Zanotti:19b}. We thus have \(v - \calE_{\mr}\Pi_{\mr} v = w -\Pi_{\mr} w \) with \(w=v-\calE_{\mr}\Pi_{\mr} v\). Using the scaling properties of $\Upsilon_z^0$ in Lemma~\ref{L:ScalingUpsilon}, stability and approximation properties of the Morley interpolation (see also \cite[Proposition 2.3]{Gallistl:15}),  and the stability~\eqref{eq:EMRstab} of the smoothing operator, we derive    \norm[L^2(\Omega)]{D^2_h((v - \calE_{\mr}\Pi_{\mr} v)\Upsilon^0_z)}   =   \norm[L^2(\omega_z)]{D_h^2\big((w - \Pi_{\mr} w)\Upsilon^0_z\big)} \\   \lesssim h^{-2}_z \norm[L^2(\omega_z)]{w - \Pi_{\mr} w}    +   h^{-1}_z \norm[L^2(\omega_z)]{\nabla_h (w - \Pi_{\mr} w)}   +   \norm[L^2(\omega_z)]{D_h^2(w-\Pi_{\mr} w)} \\ 	\lesssim \norm[L^2(\omega_z)]{D^2w} 	= 	\norm[L^2(\omega_z)]{D^2 (v - \calE_{\mr}\Pi_{\mr} v)} 	\lesssim 	\norm[L^2(\omega_z^+)]{D^2v}.  Consequently,  summing over all \(z\in\vertices\) and accounting for the finite overlapping of the enlarged stars \(\omega_z^+\), \(z\in\vertices\), concludes the proof.",2502.01799
proof,"% checking (i) Condition~(i) of \eqref{A:construction-Pz-local} is clear from the definitions \eqref{Eq:DzSzMR} of the respective spaces.  % checking (ii) To verify condition~(ii), %of \eqref{A:construction-Pz-local}, let $z \in \vertices$ be arbitrary. Observations similar to the proof of~\eqref{eq:StructOfDC0} imply \(\tA(\MR)_{|\mathring{H}^2(\omega_z)}\subset D_z\) and it  remains to verify  \(\tA(\MR)_{|S_z}\subset D_z\). To this end, we let \(v_h\in \MR\)  and proceed similarly as for~\eqref{eq:StructOfDC0} and denote by $\tangent_z^+$ an extension of the tangent field $\tangent_z$ in \eqref{def-t_z} to $\Sigma_z^+ = \cup_{F \in \sides_z^{i+}} F$, where the orientation of the unit vectors $\tangent_z^+{}_{|F}$, $F \in \sides_z^{i+} \setminus \sides_z^+$,  is arbitrary but fixed. For \(F\in\sides_z^i\), we have $\operatorname{supp} \calE_{\mr} \Psi^{\mr}_F \subset \omega_z^+$ and thus   \ta(v_h, \calE_{\mr}\Psi^{\mr}_F)  &=  \int_{\Sigma_z^+} \jump{D_h^2 v_h \normal\cdot\normal} \partial_{\normal} \calE_{\mr}\Psi^{\mr}_F  +  \int_{\Sigma_z^+} \jump{D_h^2 v_h  \normal\cdot\tangent_z^+} \nabla \calE_{\mr} \Psi^{\mr}_F \cdot \tangent_z^+  The second integral vanishes thanks to the fundamental theorem of calculus since \(\jump{D_h^2 v_h  \normal\cdot\tangent_z^+}\) is piecewise constant on \(\sides_z^{i+}\) and \( \calE_{\mr}\Psi^{\mr}_F(y) = \Psi^{\mr}_F(y) = 0\) for all \(y\in \vertices\).  In the light of \( \scp{\chi_{F'}}{\calE_{\mr}\Psi^{\mr}_F} = \scp{\chi_{F'}}{\Psi^{\mr}_F} = \delta_{FF'} \), the first  integral reduces to an integral over $F$ and we arrive at  	\ta( v_h, \calE_{\mr}\Psi^{\mr}_F) 	=    \int_{F} \jump{D_h^2 v_h \normal\cdot\normal}\partial_{\normal} \calE_{\mr}\Psi^{\mr}_F.  If $z \in \vertices^i$, a similar reasoning yields  	\ta( v_h, \calE_{\mr}\Psi^{\mr}_z ) 	= 	\sum_{F\in\sides_z^i}\jump{D_h^2 v_h \normal\cdot \tangent_z}.  This shows \(\tA(\MR)_{|S_z} \subset D_z\) and thus (ii) of \eqref{A:construction-Pz-local} is verified. 	 % checking (iii) Remark~\ref{R:MRBiorthogonalSystem} readily implies \(\operatorname{\dim} D_z= \operatorname{\dim} S_z<\infty\) and thus (iii) of \eqref{A:construction-Pz-local}. %Note that this already implies the existence of \(\calP_z:\Dual{\tV_z}\to D_z\) as defined	in~\eqref{Eq:construction-Pz-local}.  % checking (iv) To prove (iv), fix \(z\in\vertices\),  without loss of generality $z \in \vertices^i$, and let   $\chi \in D_z$ with  		\scp{\chi}{v} 		= 		r_z v(z) 		+ 		\sum_{F\in\sides_z^i} \int_F r_F \partial_\normal v  \quad\text{for}~v\in \mathring{H}^2(\omega_z).  Standard arguments with scaled trace and Poincar\'e inequalities yield  		\scp{\chi}{v} % &\lesssim \sum_{F\in\sides_z^i} 		% \norm[L^2(F)]{r_F} \norm[L^2(F)]{\partial_\normal v}  		% + h \abs{r_z} \norm[H^2(\pat)]{v} \\ 		% &\lesssim 		% \sum_{F\in\sides_z^i}  		% \norm[L^2(F)]{r_F} h^{\frac{1}{2}}\norm[H^2({\pat[F]})]{v} 		% + h \abs{r_z}  \norm[H^2(\pat)]{v}\\ 		&\lesssim  		\Big(\sum_{F\in\sides_z^i} h_z^2 |{r_F}|^2 		+ 		h^2_z |r_z|^2 \Big)^{\frac12} \norm[L^2(\omega_z)]{D^2v}.  To further bound the right-hand side, we use the duality of the bases of \(D_z\) and \(S_z\) and their scaling properties. For \(F\in\sides_z^i\), we obtain  		|r_F| 		&= 		\Big|\int_F r_F \partial_\normal\calE_{\mr}(\Psi^{\mr}_F)\Big| 		\leq \norm[\Dual{S_z}]{\chi} \norm[L^2(\omega_z^+)]{D^2\calE_{\mr}(\Psi^{\mr}_F)} 		% \lesssim \norm[\Dual{{S^{\mr}_z}} ]{\chi} 		%   \norm[L^2(\omega_F)]{D_h^2\Psi^{\mr}_F} 		\lesssim 		\norm[\Dual{S_z}]{\chi} h_F^{-1},  where we use the stability of \(\calE_{\mr}\) and  \(\norm[L^2(\Omega)]{D_h^2\Psi^{\mr}_F} \lesssim h_F^{-1}\), which follows from the fact that the Morley element is almost affine~\cite[Theorem~6.1.3]{Ciarlet:2002}. A similar reasoning yields   	|r_z| 	= 	|r_z \calE_{\mr}\Psi^{\mr}_z(z)| 	= 	\left|\langle \chi, \calE_{\mr}\Psi^{\mr}_z\rangle\right|  	&\leq 	\norm[\Dual{S_z}]{\chi} \norm[L^2(\omega_z^+)]{D^2 \calE_{\mr}{\Psi^{\mr}_z}} 	\lesssim 	h^{-1}_z\norm[\Dual{S_z} ]{\chi}.   % Here again, we used the stability of \(\calE_{\mr}\) and the scaling % property \(\norm[L^2(\Omega)]{D_h^2\Psi^{\mr}_z}\lesssim % h_z^{-1}\) using again techniques % for almost affine elements. Combining the above results, and  taking the supremum over all \(v\in \mathring{H}^2(\omega_z)\) proves the desired assertion.  % checking local and global, ie (v) of (H2), stability	 The last step is to verify the collective stability property of $\calP_z$, $z \in \vertices$.  Given  any vertex \(z\in\vertices\) and \(g\in H^{-2}(\omega_z^+)\), we have   S_z\subset \mathring{H}^2(\omega_z^+) \quad\text{and thus}\quad   \norm[{\Dual{S_z}}]{g}   \le   \norm[H^{-2}(\omega_z^+)]{g}.  Furthermore, we recall from Lemma~\ref{L:ScalingUpsilon} that the functions \(\Upsilon_y^0\), \(y\in\vertices\), form a partition of unity with $\Upsilon_y^0 \in W^{2,\infty}(\Omega)$ and \(\operatorname{supp} \Upsilon_y^0=\omega_y\). Consequently, for local test functions \(v\in \mathring{H}^2(\omega_z^+)\), we derive   	 \langle g, v\rangle 	 &= 	 \sum_{y\in\vertices\cap\omega_z^+} \langle g,v\Upsilon_y^0\rangle 	\le 	\sum_{y\in\vertices\cap\omega_z^+} \norm[H^{-2}(\omega_y)]{g} \norm[L^2(\omega_y)]{D^2(v\Upsilon_y^0)} 	\\ 	&\lesssim 	\sum_{y\in\vertices\cap\omega_z^+}\norm[H^{-2}(\omega_y)]{g} \norm[L^2(\omega_z^+)]{D^2v},  where, similarly to	\eqref{E:omega+<omega}, we use the scaling properties of $\Upsilon_y^0$, the Poincar\'e inequality with vanishing boundary values, and \(\operatorname{diam}(\omega_z^+)\eqsim h_y \) for all \(y\in\vertices\cap\omega_z^+\). As $\# \{ z \in V \mid \omega_z^+ \ni y\} \lesssim 1$ uniformly in $y \in \vertices$, we arrive at  		\sum_{z\in\vertices}\norm[H^{-2}(\omega_z^+)]{g}^2 		\lesssim 		\adjustlimits{\sum}_{z\in\vertices}{\sum}_{y\in\vertices\cap\omega_z^+}\norm[H^{-2}(\omega_y)]{g}^2 		\lesssim 		\sum_{z\in\vertices}\norm[H^{-2}(\omega_z)]{g}^2.  This proves (v) of \eqref{A:construction-Pz-local} with $\Ccol \lesssim 1$. The collective stability bound follows from Proposition~\ref{P:construction-Pz-local}.",2502.01799
proof,"[Proof of Theorem~\ref{TH:mainMR}] The claimed equivalence is  a direct consequence of Theorems~\ref{T:error-estimator} and the observation  	\norm[H^{-2}(\omega_z)]{\calP_z\Res^{\mathtt{C}}_h} 	\lesssim 	\norm[\Dual{S_z}]{\calP_z\Res^{\mathtt{C}}_h}=\norm[\Dual{S_z}]{\Res^{\mathtt{C}}_h} 	= 	0,   which follows from (iv) of \eqref{A:construction-Pz-local},  \eqref{Eq:construction-Pz-local} and~\eqref{eq:qo-MR}. The oscillation bounds follows as in the proof of Theorem~\ref{TH:mainC0}. %The local lower bound follows from~\eqref{Eq:Dvh-DAvh<DJumps;MR} and~\eqref{eq:MRlocal-jumpEst}.",2502.01799
proposition,"[Quasi-optimality]  For the fully stable method $M_h$, induced by the discretization \eqref{Eq:DisEq}, the following statements are equivalent:   	\item  $M_h$ is quasi-optimal, i.e.\  \eqref{eq:apriori-new} is verified for some constant $\Cqo\geq 1$. 	% 	\item  $M_h$ is fully consistent, i.e.\  \eqref{Eq:AlgCons} is verified. 	% 	\item  There is a constant $\delta_h \geq 0$ verifying 	  	\forall w_h\in V_h\quad  	\sup_{v_h\in V_h}\frac{a_h(w_h,v_h)-a(\Pi_V w_h, \calE_h v_h)} 	{\norm[\Dual{V_h}]{A_h^* v_h}} 	\le \delta_h\|w_h-\Pi_V w_h\|. 	    Moreover, if \eqref{QuasiOptMethods-QuasiOptimality}-\eqref{QuasiOptMethods-ConsistencyMeasure} are verified, then the constant $\Cqo$ from \eqref{eq:apriori-new} is such that   \max\{\Cstab, \delta_h\}\le \Cqo\le \sqrt{\Cstab^2+ \delta_h^2}  with    \Cstab:= \sup_{v_h \in V_h} \dfrac{\norm{\calE_h v_h}}{\norm[\Dual{V_h}]{A_h^*v_h}}.",2502.01799
proposition,"[Approximating the distance to conformity]  % If    % \stepcounter{AssumptionCounter} \tag{H\arabic{AssumptionCounter}} %   \calA_h:V_h \to V &\text{ is a bounded linear operator with }  \\  	&\forall w_h \in V \cap V_h  	\quad  	\calA_h w_h = w_h,    then there exists a constant $\Cav > 0$ such that  %  \forall v_h \in V_h \quad  \Cav  \| v_h - \calA_h v_h\|  \leq  \| v_h - \Pi_V v_h\|  \leq  \| v_h - \calA_h v_h \|.",2502.01799
proposition,"[Local projections]  % Suppose assumption~\eqref{A:construction-Pz-local} holds. Then the variational equations   % \text{find }\calP_z g \in D_z \text{ s.th.\ }  \forall s \in S_z \qquad \scp{\calP_z g}{s} = \scp{g}{s}, \quad  z \in \Index,  define linear projections $\calP_z: \Dual{\tV_z} \to D_z$, satisfying the invariances     \forall z \in \Index, v_h\in V_h  \qquad  \big( \calP_z\tA v_h \big)_{|V_z} = \big( \tA v_h \big)_{|V_z} \intertext{and the collective stability bound}   \forall g \in \Dual{V} \qquad  \sum_{z\in\Index}\norm[\Dual{V_z}]{\calP_z g}^2  \le  \CL^2 \CNL^2 \sum_{z\in\Index}\norm[\Dual{V_z}]{g}^2.  Hereafter, we also write simply $\calP_z g$ instead of $\calP_z (g_{|\Dual{\tV_z}})$ for $g \in \Dual{V}$.",2502.01799
proposition,"For any \(v_h\in \MR\) and \(F\in\sides\), we 	%  have 	%   		%    \|h^{-\frac12}\jump{\nabla_h 			%      v_h}\|_{L^2(F)}^2\lesssim \inf_{v\in \mathring{H}^2(\Omega)}\norm[L^2(\omega_F)]{D^2_h(v_h-v)}^2. 		%   	%",2502.01799
proposition,"%  For $v_h \in \MR$, we have % then we have for the $\ta$-orthogonal projection 	%  % $\PiV: \mathring{H}^2(\Omega) + \MR \to \mathring{H}^2(\Omega) + \MR$  onto 	%  % \(\mathring{H}^2(\Omega)\) that 	%   		%    \inf_{v\in \mathring{H}^2(\Omega)}\norm[L^2(\Omega)]{D^2_h(v - v_h)}^2 % \eqsim 		%    % \normMR{D^2_h(\EMR  v_h - v_h)}^2 		%    \eqsim 		%    \sum_{F\in\sides} \int_F \frac{1}{h} \abs{\jump{\nabla_h v_h}}^2.  		%   	%",2502.01799
proposition,"For any \(v_h\in \MR\) and \(F\in\sides\), we 	%  have 	%   		%    \|h^{-\frac12}\jump{\nabla_h 			%      v_h}\|_{L^2(F)}^2\lesssim \inf_{v\in \mathring{H}^2(\Omega)}\norm[L^2(\omega_F)]{D^2_h(v_h-v)}^2. 		%   	%",2502.01799
proposition,"%  For $v_h \in \MR$, we have % then we have for the $\ta$-orthogonal projection 	%  % $\PiV: \mathring{H}^2(\Omega) + \MR \to \mathring{H}^2(\Omega) + \MR$  onto 	%  % \(\mathring{H}^2(\Omega)\) that 	%   		%    \inf_{v\in \mathring{H}^2(\Omega)}\norm[L^2(\Omega)]{D^2_h(v - v_h)}^2 % \eqsim 		%    % \normMR{D^2_h(\EMR  v_h - v_h)}^2 		%    \eqsim 		%    \sum_{F\in\sides} \int_F \frac{1}{h} \abs{\jump{\nabla_h v_h}}^2.  		%   	%",2502.01799
lemma,"[Error, residual and their decompositions]  % For the respective solutions $u$ and $u_h$ of \eqref{Eq:AnaPro} and \eqref{Eq:DisEq}, we have   \norm{u-u_h}^2  =  \norm[\Dual{\tV}]{\Res_h}^2  =  \norm[\Dual{V}]{\Res_h^{\mathtt{C}}}^2   + \norm[\Dual{(V^\perp)}]{\Res_h^{\mathtt{NC}}}^2, \\  \norm{u-\Pi_V u_h}  =  \norm[\Dual{V}]{\Res_h^{\mathtt{C}}}, \quad\text{and}\quad  \norm{u_h - \Pi_V u_h}  =  \norm[\Dual{(V^\perp)}]{\Res_h^{\mathtt{NC}}}.",2502.01799
lemma,"[Near orthogonality of conforming residual]  % If the discretization \eqref{Eq:DisEq} induces a quasi-optimal method $M_h$, then we have, for all $v \in V$ and $K > 0$,   %  \scp{\Res_h^{\mathtt{C}}}{v}  \leq   \inf_{v_h\in V_h, \norm{v_h} \leq K \norm{v}} \scp{\Res_h^{\mathtt{C}}}{v - \calE_h v_h} %\\   + K \delta_h \normtr{A_h} \norm{u_h - \Pi_V u_h} \norm{v}. %",2502.01799
lemma,"[Localizing the conforming residual norm]  % If  the discretization \eqref{Eq:DisEq} induces a quasi-optimal method $M_h$, then \eqref{A:partition-of-unity} implies that    \frac{1}{\Ccol^2} \sum_{z\in\Index} \norm[\Dual{V}_z]{\Res_h^{\mathtt{C}}}^2  \le  \norm[\Dual{V}]{\Res_h^{\mathtt{C}}}^2  \le  2 \Cobl^2 \delta_h^2 \norm{ u_h - \Pi_V u_h}^2  +   2 \Cloc^2 \sum_{z\in\Index} \norm[\Dual{V}_z]{\Res_h^{\mathtt{C}}}^2    holds for some constant $\Cobl \leq \normtr{A_h} \normtr{\calI_h} $ arising through near orthogonality properties of the residual.",2502.01799
lemma,"[Conforming residual splitting]  % Assumption~\eqref{A:construction-Pz-local} ensures   \Csplt^2 \left( \eta_h^2 + \Osc_h^2 \right)  \leq  \sum_{z\in\Index} \norm[\Dual{V}_z]{\Res_h^{\mathtt{C}}}^2  \leq  2 \left( \eta_h^2 + \Osc_h^2 \right)  with some $\Csplt \geq (1 + 2\CL^2\CNL^2)^{-1/2}$ and the indicators    \eta_h^2  :=  \sum_{z\in\Index} \norm[\Dual{V_z}]{\calP_z \Res_h^{\mathtt{C}}}^2   \qquad \text{and} \qquad  \Osc_h^2  :=  \sum_{z\in\Index} \norm[\Dual{V_z}]{f - \calP_z f}^2,  where the indicator $\eta_h$ is computationally quantifiable up to $\max\{\CL,\CNL^{-1}\}$ whenever $\Res_h^{\mathtt{C}} = f - \tA u_h$ can be computationally evaluated for all simple test functions.",2502.01799
lemma,"[Approximate $\|\nabla_h\cdot\|_{L^2}$-distance to $\mathring{H}^1$ by averaging]  % In the setting \eqref{setting-for-Poisson-and-CR1}, the operator $\mathcal{A}_\mathsf{CR}$ in \eqref{Eq:CR1-averaging} satisfies assumption \eqref{A:equiv-to-dist-to-conf}  and \(\Cav\gtrsim 1\). In particular,  for all $v_h \in    \CR_1$ we have that    		\norm[L^2(\Omega)]{\nabla_h(v_h - \mathcal{A}_\mathsf{CR} v_h)} 		\lesssim 		\inf_{v\in \mathring{H}^1(\Omega)}\norm[L^2(\Omega)]{\nabla_h(v_h - v)} 		\leq 		\norm[L^2(\Omega)]{\nabla_h(v_h - \mathcal{A}_\mathsf{CR} v_h)}.",2502.01799
lemma,"[Partition of unity in $H^1$ for $\mathsf{CR}$] 	 % In the  setting  \eqref{setting-for-Poisson-and-CR1}, the choices  \eqref{Eq:CR-partition-of-unity} satisfy assumption \eqref{A:partition-of-unity} with constants $\Cloc,\Ccol \lesssim 1$.",2502.01799
lemma,"[Local projections for $\mathsf{CR}$@Poisson with face bubbles]  % In the settings \eqref{setting-for-Poisson-and-CR1} and \eqref{Eq:CR-partition-of-unity},  the choices \eqref{simple-CR1-conf} verify assumption \eqref{A:construction-Pz-local} with \(\CL\lesssim1\) and \(\CNL=1\). Therefore, \eqref{Eq:construction-Pz-local} defines projections $\calP_z: H^{-1}(\omega_z) \to D_z \subset H^{-1}(\omega_z)$ satisfying    \forall g \in H^{-1}(\Omega) \quad  \sum_{z\in\vertices}  \norm[H^{-1}(\omega_z)]{\calP_z g}^2 	\lesssim   \sum_{z\in\vertices}  \norm[H^{-1}(\omega_z)]{g}^2.",2502.01799
lemma,"[Local projections for $\mathsf{CR}$@Poisson with smoothed CR basis]  % In the settings \eqref{setting-for-Poisson-and-CR1} and \eqref{Eq:CR-partition-of-unity},  the choices \eqref{simple-CR1-nconf} satisfy assumption \eqref{A:construction-Pz-local} with \(\CL\lesssim1\) and \(\CNL \lesssim1\). Hence, \eqref{Eq:construction-Pz-local} defines projections $\calP_z: \Dual{\tV_z} \to D_z \subset \Dual{\tV_z}$  with $\tV_z = \mathring{H}^1(\omega_z) + S_z$ and we have   \forall g \in H^{-1}(\Omega) \quad  \sum_{z\in\vertices}  \norm[H^{-1}(\omega_z)]{\calP_z g}^2   \lesssim  \sum_{z\in\vertices}  \norm[H^{-1}(\omega_z)]{g}^2.",2502.01799
lemma,"[Approximate $\|\cdot\|_{\mathtt{dG}}$-distance to $\mathring{H}^1$ by averaging]  % In the setting~\eqref{dG-setting},  the operator $\calA_\ell$  from \eqref{Eq:dG-averaging} satisfies assumption \eqref{A:equiv-to-dist-to-conf} and \(\Cav\gtrsim \sqrt{{\sigma}/{(1+\sigma)}}\). In particular, we have that,  for all $v_h \in S_\ell^0$,    		\sqrt{\frac{\sigma}{1+\sigma}}\|v_h - \mathcal{A}_\ell v_h\|_{\mathtt{dG}} 		\lesssim 		\inf_{v\in \mathring{H}^1(\Omega)}\|v_h - v\|_{\mathtt{dG}} 		\leq 			\|v_h - \mathcal{A}_\ell v_h\|_{\mathtt{dG}}.  %The hidden constants depend only on the the dimension \(d\), the shape constant \(\gamma_\grid\) and the polynomial degree \(\ell\).",2502.01799
lemma,"[Partition of unity in $H^1$] 	 % In the setting \eqref{dG-setting}, the choices \eqref{Eq:dG-partition-of-unity} satisfy	assumption~\eqref{A:partition-of-unity} with constants $\Cloc, \Ccol \lesssim 1$.",2502.01799
lemma,"[Local projections for $\mathsf{dG}$@Poisson]  % In the settings \eqref{dG-setting} and \eqref{Eq:dG-partition-of-unity},  the choices \eqref{dG-simple} satisfy assumption	 \eqref{A:construction-Pz-local} with \(\CL\lesssim1\) and \(\CNL=1\). Hence, \eqref{Eq:construction-Pz-local} defines projections $\calP_z: H^{-1}(\omega_z) \to D_z \subset H^{-1}(\omega_z)$ with    %  \forall g \in H^{-1}(\Omega) \quad  \sum_{z\in\vertices} 	\norm[H^{-1}(\omega_z)]{\calP_z g}^2  \lesssim  \sum_{z\in\vertices} \norm[H^{-1}(\omega_z)]{g}^2.",2502.01799
lemma,"[Properties of $\HCT$ basis] 	 	% 	We have 	$% 	\sum_{z \in \vertices} \Upsilon^0_z = 1 \text{ in }\Omega, 	$ % 	where, for all $z \in \vertices$, 	 		\operatorname{supp}\Upsilon_z^0=\omega_z, 		\quad%\text{and}\quad 		h_z^2\norm[L^\infty(\Omega)]{D^2\Upsilon_z^0}\eqsim 		h_z\norm[L^\infty(\Omega)]{\nabla\Upsilon_z^0}\eqsim\norm[L^\infty(\Omega)]{\Upsilon_z^0}\eqsim1. 	 	Furthermore, for all $z \in \vertices$, $j=1,2$,  all $T\in\grid$ with $T\ni z$,  as well as  all \(F\in\sides\), $T \in \grid$ with $T \supset F$, 	 		\operatorname{supp}\Upsilon_z^j = \omega_z, 		\quad 		\norm[L^2(T)]{D^2\Upsilon_z^j} \lesssim 1, 		\qquad  		\operatorname{supp}\Upsilon_F = \omega_F, 		\quad 		\norm[L^2(T)]{D^2\Upsilon_F} \lesssim 1. 	 	All hidden constants only depend on the shape constant \(\gamma_\grid\).",2502.01799
lemma,"[Approximate $\|\cdot\|_\mathtt{C0}$-distance to $\mathring{H}^2$ by averaging] 	 	% 	In the setting \eqref{setting-for-Biharmonic-and-C0}, the operator  $\mathcal{A}_{\COip}$ in \eqref{df:AC0} satisfies assumption \eqref{A:equiv-to-dist-to-conf}  and \(  \Cav \gtrsim \sqrt{{\sigma}/{(1+\sigma)}} \): for all $v_h \in \mathring{S}_2^1$, we have 	 		\sqrt{\frac{\sigma}{1+\sigma}} 		\norm[\COip]{\calA_{\COip}v_h-v_h} 		\lesssim 		 \inf_{v \in \mathring{H}^2(\Omega)}\norm[\COip]{v-v_h} 		 \leq 		 \norm[\COip]{\calA_{\COip}v_h-v_h}.",2502.01799
lemma,"[Partition of unity in $H^2$ for biharmonic $\COip$] 	 	% 	In the  setting  \eqref{setting-for-Biharmonic-and-C0}, the choices  \eqref{Eq:C0-partition-of-unity} satisfy assumption \eqref{A:partition-of-unity} with constants $\Cloc,\Ccol \lesssim 1$.  	%  For the \(C^0\)-interior penalty method~\eqref{Eq:C0ip-method} 	% the index set \(\Index=\vertices\), functions 	% \(\Phi_z=\Upsilon_z^0\), subspaces  	% \(V_z=\mathring{H}^2(\omega_z)\), \(z\in\vertices\), and the nodal Lagrange interpolation 	% operator  	% \(\mathcal{I}_h=\mathcal{I}_{L}\) into \(\mathring{S}_2^1\) satisfy 	% Assumption~\eqref{A:partition-of-unity} with constants 	% \(\Ccol =d+1\) and \(\Cloc>0\) only depending on the shape 	% constant \(\gamma_\grid\).",2502.01799
lemma,"[Local projections for biharmonic $\COip$]  % In the settings \eqref{setting-for-Biharmonic-and-C0} and \eqref{Eq:C0-partition-of-unity},  the choices \eqref{Eq:DzSzBiC0} satisfy assumption \eqref{A:construction-Pz-local} with \(\CL\lesssim1\) and \(\CNL=1\). Consequently, \eqref{Eq:construction-Pz-local} defines projections $\calP_z: H^{-2}(\omega_z) \to D_z \subset H^{-2}(\omega_z)$ with   	 		\forall g \in H^{-2}(\Omega) 		\quad 		\sum_{z \in \vertices}  \norm[H^{-2}(\omega_z)]{\calP_z g}^2 		\lesssim 		\sum_{z \in \vertices} \norm[H^{-2}(\omega_z)]{g}^2.",2502.01799
lemma,"[Approximate $\|D^2_h\cdot\|_{L^2}$-distance to $\mathring{H}^2$ by averaging]  % In the setting~\eqref{setting-for-Biharmonic-and-MR}, the operator \(\calA_{\mr}\) in~\eqref{df:AHCT} satisfies assumption~\eqref{A:equiv-to-dist-to-conf}  and \(\Cav\gtrsim 1\):  for all $v_h \in \MR$,  	\norm[L^2(\Omega)]{D_h^2(\calA_{\mr}v_h-v_h)} 	% \lesssim 	% \left(\sum_{F\in\sides} \int_F \frac{1}{h} \left|\jump{\nabla_h 	% v_h}\right|^2\right)^{\frac12} 	\lesssim \inf_{v\in \mathring{H}^2(\Omega)}\norm[L^2(\Omega)]{D_h^2(v-v_h)} 	\leq 	\norm[L^2(\Omega)]{D_h^2(\calA_{\mr}v_h-v_h)}.",2502.01799
lemma,"[Partition of unity in $H^2$ for biharmonic $\mr$]  % In the  setting  \eqref{setting-for-Biharmonic-and-MR}, the choices \eqref{Eq:MR-partition-of-unity} satisfy assumption \eqref{A:partition-of-unity} with constants $\Cloc,\Ccol \lesssim 1$.",2502.01799
lemma,"[Local projections for biharmonic $\mr$]  % In the settings \eqref{setting-for-Biharmonic-and-MR} and \eqref{Eq:MR-partition-of-unity},  the choices \eqref{Eq:DzSzMR} satisfy assumption \eqref{A:construction-Pz-local} with \(\CL,\CNL\lesssim1\). In particular, \eqref{Eq:construction-Pz-local} defines projections $\calP_z: \Dual{\tV_z}\to D_z \subset \Dual{\tV_z}$ with \(\Dual{\tV_z}= \Dual{(\mathring{H}^2(\omega_z)+S_z)}\)~and    %   \forall g \in H^{-2}(\Omega)  \quad   \sum_{z \in \vertices}   \norm[H^{-2}(\omega_z)]{\calP_z g}^2   \lesssim   \sum_{z \in \vertices}   \norm[H^{-2}(\omega_z)]{g}^2.",2502.01799
example,"[No $\mathring{H}^2$-conforming quadratics]  % Subdivide \(\Omega=(0,1)^2\) for a given \(n\in \mathbb{N}\) into \(n^2\) equal sized squares and obtain a triangulation \(\grid\) by inserting in each square the  diagonal parallel to the line \(\{(x,x)\mid x\in\mathbb{R}\}\). Then \(S_2^0\cap \mathring{H}^2(\Omega)=\{0\}\). To see this, let $v \in S_2^0\cap \mathring{H}^2(\Omega)$ and consider first the square containing the origin, denoting by $T_i$, $i=1,2$, its two triangles. Factorizing $v_{|T_i} \in \poly_2$ by means of the boundary conditions yields $v = c_i a_i^2$ on $T_i$ with $c_i \in \mathbb{R}$ and $a_i \in \poly_1$, $i=1,2$. The $C^1$-transition along the diagonal  \(\{(x,x)\mid x\in\mathbb{R}\}\) implies $c_1 = c_2$ and $\nabla a_1 = \nabla a_2$ and therefore $v_{|(T_1 \cup T_2)} = 0$. Inductively repeating this argument for the other squares provides the desired identity $v =0$.",2502.01799
theorem,"Let $(\Gamma,\varphi)$ be an incidence gain graph with underlying incidence structure $(\mathscr{P},\mathscr{B},\mathrm{I})$ a linear space, and gain group acting on a nonempty set $\Lambda$.  We have $\mathfrak{M}(\Gamma,\varphi)$ is a generalized quadrangle if and only if for every $p \in \mathscr{P}$ and $b \in \mathscr{B}$ with $p \  \cancel{\mathrm{I}} \  b$, and for every $\lambda \in \Lambda$, the rho function $\rho_{b,p,\lambda}$ is bijective.  When $\mathfrak{M}(\Gamma,\varphi)$ is a generalized quadrangle we have the following.  \item The set $X = \{ x_p \  | \  p \in \mathscr{P} \}$ is an ovoid of $\mathfrak{M}(\Gamma,\varphi)$. \item For every $b \in \mathscr{B}$, the set $\mathscr{P}_b$ has the same cardinality as $\Lambda$.  Hence $(\mathscr{P},\mathscr{B},\mathrm{I})$ is a Steiner system. \item If $\mathscr{P}$ is finite, then $\Lambda$ is finite, and $|\mathscr{P}| = v \geq 3$, $|\Lambda| = k \geq 2$, and $\mathfrak{M}(\Gamma,\varphi)$ has that every line is incident with exactly $1+s$ points and every point is incident with exactly $1+t$ lines, where $\displaystyle s=\frac{v-1}{k-1}$ and $t=k-1$.",2502.01805
theorem,"Suppose $(\mathscr{P},\mathscr{B},\mathrm{I})$ is an affine plane over a field $\mathbb{F}$ and let $\mathbb{F}$ act on itself via addition.  Let $\Gamma = (V,E)$ be the incidence graph of the affine plane, and let us define a gain function $\varphi : \mathscr{F}(E) \rightarrow (\mathbb{F},+)$ as follows:  $$\varphi(e) =               -by, & \text{if } e = \{ L_b, (b,y) \}, \\         xb, & \text{if } e = \{ L_{m,b} , (x,mx+b) \}.     $$  We have $\mathfrak{M}(\Gamma,\varphi)$ a generalized quadrangle.",2502.01805
proof,"It is clear that $g_1$ and $g_2$ are both bijections.  Also, it is clear that we need only to verify the condition on incidence for the points of type $y_{b, \lambda}$.  Let $b \in \mathscr{B}$ and $p \in \mathscr{P}$ with $b \  \mathrm{I} \  p$, and let $e = bp$ be the edge of $\Gamma$.  We have $$y_{b, \lambda} \  \mathrm{I}' \  z_{p,\mu} \Longleftrightarrow \mu = \varphi(e) \cdot \lambda.$$  Now $g_1(y_{b, \lambda}) = y_{b,\lambda_1}$ where $\lambda_1 = f(b) \cdot \lambda$, and $g_2(z_{p, \mu}) = z_{p,\mu_1}$ where $\mu_1 = f(p) \cdot \mu$.  Hence  \varphi(e) \cdot \lambda = \mu \Longleftrightarrow \\ f(p)\varphi(e) \cdot \lambda = \mu_1 \Longleftrightarrow \\  f(p)\varphi(e) f(b)^{-1} \cdot \lambda_1 = \mu_1 \Longleftrightarrow \\  g_1(y_{b, \lambda}) \  \mathrm{I}'_f \  g_2(z_{p, \mu}). \qedhere",2502.01805
proof,"Items 1 and 3 are clear.  \textit{Item 2.}  We have the $3$-chain $(x_p, z_{p,\lambda_1}, y_{b',\lambda_2}, z_{q,\lambda})$, where $b'$ is the unique line incident with $p$ and $q$, and $\lambda_2 = \varphi(b'q)^{-1} \cdot \lambda$ and $\lambda_1 = \varphi(b'p) \cdot \lambda_2$.  This chain is unique since the second term in a $3$-chain from $x_p$ to $z_{q,\lambda}$ must be a line with first index $p$, and the third term must be a point of ``line'' type.  The $b'$ is uniquely determined as are $\lambda_1$ and $\lambda_2$.  \textit{Item 4.}  We have the $3$-chain $(y_{b,\lambda}, z_{p,\lambda_1}, x_p, z_{p,\mu})$, where $\lambda_1 = \varphi(bp) \cdot \lambda$.  We argue that this $3$-chain is unique.  Consider any $3$-chain from $y_{b,\lambda}$ to $z_{p,\mu}$.  If the second term in such $3$-chain has first index $p'$ for some $p \neq p'$, then the third term would have to be a point of ``line'' type.  But the first index on this ``line'' type point would have to be $b$, since $b$ is the unique line incident with $p$ and $p'$.  So we have a $3$-chain of the form $(y_{b,\lambda}, z_{p',\lambda_1}, y_{b,\lambda_2}, z_{p,\mu})$.  But then $\lambda = \lambda_2$, and the first and third terms in the $3$-chain are equal, a contradiction.  So the second term in such $3$-chain has first index $p$.  Suppose that the third term is a ``line'' type point.  So we have a $3$-chain of the form \\ $(y_{b,\lambda}, z_{p,\lambda_1}, y_{b',\lambda_2}, z_{p,\mu})$ for some $b'$.  But then $\mu = \lambda_1$, and the second and fourth terms in the $3$-chain are equal, a contradiction.",2502.01805
proof,"\textit{Case 1.}  Suppose $u = z_{p,\lambda}$ and $v = z_{q,\mu}$ for some $p,q \in \mathscr{P}$ and $\lambda,\mu \in \Lambda$.    If $p=q$ and $\lambda \neq \mu$, then $(z_{p,\lambda}, x_p, z_{q,\mu})$ is a $2$-chain, and if we have a $2$-chain from $z_{p,\lambda}$ to $z_{q,\mu}$ where the second term is a ``line'' type point, then $\lambda = \mu$, a contradiction.  And so this is the unique $2$-chain from $u$ to $v$.    If $p \neq q$, then we have a $2$-chain $(z_{p,\lambda}, y_{b,\lambda_1}, z_{q,\mu})$ where $b$ is the unique line incident with $p$ and $q$, and where $\lambda_1 = \varphi(bp)^{-1} \cdot \lambda = \varphi(bq)^{-1} \cdot \mu$, and so $\lambda = \mu$ and this is the unique $2$-chain from $u$ to $v$.    \textit{Case 2.}  If $u = x_p$ and $v =x_q$ for some $p,q \in \mathscr{P}$, then $p=q$ and $d(u,v) = 0$.  \textit{Case 3.} Suppose $u = x_p$ and $v = y_{b,\lambda}$ for some $p \in \mathscr{P}$, $b \in \mathscr{B}$, and $\lambda \in \Lambda$.  Then $(x_p, z_{p,\mu}, y_{b,\lambda})$ is the unique $2$-chain from $u$ to $v$, where $\mu = \varphi(bp) \cdot \lambda$.  \textit{Case 4.} Suppose $u = y_{b,\lambda}$ and $v = y_{b',\mu}$ for some $b,b' \in \mathscr{B}$ and $\lambda, \mu \in \Lambda$.  We have a $2$-chain $(y_{b,\lambda},z_{p,\lambda_1}, y_{b',\mu})$ where $b$ and $b'$ are incident with a common point $p$, and $\lambda_1 = \varphi(bp) \cdot \lambda = \varphi(b'p) \cdot \mu$.  This $2$-chain is unique as $(\mathscr{P},\mathscr{B},\mathrm{I})$ a linear space and hence a common point $p$ is unique.",2502.01805
proof,"Suppose first that for every $p \in \mathscr{P}$ and $b \in \mathscr{B}$ with $p \  \cancel{\mathrm{I}} \  b$, and for every $\lambda \in \Lambda$, the rho function $\rho_{b,p,\lambda}$ is bijective.  We work to prove that $\mathfrak{M}(\Gamma,\varphi)$ is a generalized quadrangle (a generalized $n$-gon for $n=4$).  Lemma 3 establishes that if $m_1$ is a point and $m_2$ is a line of $\mathfrak{M}(\Gamma,\varphi)$, then $d(m_1,m_2) \leq 3$, with the exception of one case.  We will take care of the missing case at the end of the proof of this direction.  Let us assume for the moment that $d(m_1,m_2) \leq 3$ whenever $m_1$ is a point and $m_2$ is a line of $\mathfrak{M}(\Gamma,\varphi)$.  There is a simple argument to show that the distance between any objects of the same type is less than or equal to four.  Suppose $n_1,n_2$ are either both points or are both lines of $\mathfrak{M}(\Gamma,\varphi)$.  Let $n'$ be an object of $\mathfrak{M}(\Gamma,\varphi)$ that is incident with $n_2$ (by Construction $\mathfrak{M}$ we have no isolated objects in $\mathfrak{M}(\Gamma,\varphi)$).  Then $d(n_1,n') \leq 3$, and so $d(n_1,n_2) \leq 4$.  And so pending this missing case, we have $d(u,v) \leq 4$ for all objects $u,v$ of $\mathfrak{M}(\Gamma,\varphi)$.  Also, pending the missing case of Lemma 3, we have by Lemma 3 and Lemma 4 that if $d(u,v) < 4$ then there is a unique chain from $u$ to $v$.  We are left to establish the missing case.  We show that if $b \in \mathscr{B}$ and $p \in \mathscr{P}$ and $b \  \cancel{\mathrm{I}} \  p$, and if $\lambda, \mu \in \Lambda$, then $d(y_{b,\lambda},z_{p,\mu}) = 3$ and that there is a unique $3$-chain in $\mathfrak{M}(\Gamma,\varphi)$ from $y_{b,\lambda}$ to $z_{p,\mu}$.  Consider the rho function $\rho_{b,p,\lambda}$.  Since $\rho_{b,p,\lambda}$ is surjective, there exists $q \ \mathrm{I} \ b$ so that $\rho_{b,p,\lambda}(q) = \mu$.  In other words, if $b'$ is the unique line incident with $p$ and $q$, and if $w = (b,e_1,q,e_2,b',e_2,p)$ is the walk in $\Gamma$, then $$\mu = \varphi_w \cdot \lambda = \varphi(e_3)\varphi(e_2)^{-1} \varphi(e_1) \cdot \lambda.$$  Hence we have the $3$-chain $$(y_{b,\lambda}, z_{q,\lambda_1}, y_{b',\lambda_2}, z_{p,\mu}),$$ where $\lambda_1 = \varphi(e_1) \cdot \lambda$, $\lambda_2 = \varphi(e_2)^{-1} \cdot \lambda_1$, and $\mu = \varphi(e_3) \cdot \lambda_2 = \varphi_w \cdot \lambda$.  We now argue that this is the unique $3$-chain from $y_{b,\lambda}$ to $z_{p,\mu}$.  Note that any $3$-chain from $y_{b,\lambda}$ to $z_{p,\mu}$ has that the second term has first index $q'$ for some $q' \  \mathrm{I} \  b$, and the third term has first index $b''$ where $b''$ is the unique line incident with $p$ and $q'$.  If $$(y_{b,\lambda}, z_{q',\lambda'_1}, y_{b'',\lambda'_2}, z_{p,\mu})$$  is any $3$-chain from $y_{b,\lambda}$ to $z_{p,\mu}$, then since $\rho_{b,p,\lambda}$ is injective, and since $\mu = \varphi_w \cdot \lambda = \varphi_{w'} \cdot \lambda$ where $w'$ is the walk in $\Gamma$ associated with $q'$ and $b''$, it follows that $q = q'$.  And so $b' = b''$, and so $\lambda_1 = \lambda_1'$ and $\lambda_2 = \lambda_2'$.  Hence the $3$-chain  $$(y_{b,\lambda}, z_{q,\lambda_1}, y_{b',\lambda_2}, z_{p,\mu})$$ is the unique one from $y_{b,\lambda}$ to $z_{p,\mu}$.  Thus we have established that $\mathfrak{M}(\Gamma,\varphi)$ is a generalized quadrangle.  Conversely, suppose $\mathfrak{M}(\Gamma,\varphi)$ is a generalized quadrangle.  Let $p \in \mathscr{P}$ and $b \in \mathscr{B}$ with $p \  \cancel{\mathrm{I}} \  b$, and let $\lambda \in \Lambda$.  We argue that $\rho_{b,p,\lambda}$ is bijective.    Let $\mu \in \Lambda$ be arbitrary.  Since $\mathfrak{M}(\Gamma,\varphi)$ is a generalized quadrangle, $d(y_{b,\lambda},z_{p,\mu}) = 3$ (it cannot be one since $b \  \cancel{\mathrm{I}} \  p$).  And so we have a $3$-chain $(y_{b,\lambda},z_{q,\lambda_1},y_{b',\lambda_2},z_{p,\mu})$.  Hence there exists $q \ \mathrm{I} \ b$ so that $\rho_{b,p,\lambda}(q) = \mu$.  And since $\mathfrak{M}(\Gamma,\varphi)$ is a generalized quadrangle, this is the unique chain from $y_{b,\lambda}$ to $z_{p,\mu}$, and hence there is a unique $q \ \mathrm{I} \ b$, so that $\rho_{b,p,\lambda}(q) = \mu$.  Thus $\rho_{b,p,\lambda}$ is bijective.   Suppose $\mathfrak{M}(\Gamma,\varphi)$ is a generalized quadrangle.  \textit{Item 1.}  It is clear from Construction $\mathfrak{M}$ that the set $X$ is an ovoid of $\mathfrak{M}(\Gamma,\varphi)$.  \textit{Item 2.}  Since for every $b \in \mathscr{B}$, $\rho_{b,p,\lambda}$ is a bijection from $\mathscr{P}_b$ to $\Lambda$, it follows that for every $b \in \mathscr{B}$, $\mathscr{P}_b$ and $\Lambda$ have the same cardinality.  \textit{Item 3.}  As $(\mathscr{P},\mathscr{B},\mathrm{I})$ is a linear space, we have a point and a line not incident, and every line is incident with at least two points, and so $|\mathscr{P}| \geq 3$.  Since $\mathscr{P}$ is finite, $\mathscr{P}_b$ is finite for every line $b$, and so $\Lambda$ is finite with $|\Lambda| =k \geq 2$.  We have $(\mathscr{P},\mathscr{B},\mathrm{I})$ a Steiner system, and so every point of $(\mathscr{P},\mathscr{B},\mathrm{I})$ is incident with exactly $\displaystyle r =  \frac{v-1}{k-1}$ lines.   It follows by the construction of $\mathfrak{M}(\Gamma,\varphi)$ that every line $z_{p,\mu}$ is incident with exactly $r+1$ points $x_p,y_{b_1,\lambda_1}, \dots, y_{b_r,\lambda_r}$ where $\lambda_i = \varphi(b_i p )^{-1} \cdot \mu$ for each $i \in \{1,\dots,r\}$.  Also, in $\mathfrak{M}(\Gamma,\varphi)$, we have every point of the form $y_{b,\lambda}$ incident with exactly $k$ lines of the form $z_{q_1,\mu_1}, \dots, z_{q_k,\mu_k}$ where $\mu_i = \varphi(bq_i) \cdot \lambda$ for each $i \in \{1,\dots,k\}$.  It is clear by the construction of $\mathfrak{M}(\Gamma,\varphi)$ that a point of type $x_p$ is incident with exactly $|\Lambda| = k$ lines.",2502.01805
proof,"As the action is free,   q_1 = q_2 \Longrightarrow \rho_{b,p}(q_1) \cdot \lambda = \rho_{b,p}(q_2) \cdot \lambda \\ \text{if and only if} \\ q_1 = q_2 \Longrightarrow \rho_{b,p}(q_1) = \rho_{b,p}(q_2).  Thus $\rho_{b,p,\lambda}$ is injective if and only if $\rho_{b,p}$ is injective.  We now show that   \text{for every } \mu \in \Lambda \text{ there exists } q \ \mathrm{I} \ b \text{ so that } \rho_{b,p}(q) \cdot \lambda = \mu \\ \text{if and only if} \\ \text{for every } g \in G \text{ there exists } q \ \mathrm{I} \ b \text{ so that } \rho_{b,p}(q) = g.  Suppose first that $$\text{for every } g \in G \text{ there exists } q \ \mathrm{I} \ b \text{ so that } \rho_{b,p}(q) = g,$$ and let $\mu \in \Lambda$ be arbitrary.  As the action is transitive, there exists $g \in G$ so that $\mu = g \cdot \lambda$.  And so there exists $q$ so that $\rho_{b,p}(q) = g$, and hence $\rho_{b,p}(q) \cdot \lambda = g \cdot \lambda = \mu$.  Conversely, suppose that  $$\text{for every } \mu \in \Lambda \text{ there exists } q \ \mathrm{I} \ b \text{ so that } \rho_{b,p}(q) \cdot \lambda = \mu,$$ and let $g \in G$ be arbitrary.  Let $\mu = g \cdot \lambda$.  And so there exists $q$ so that $\rho_{b,p}(q) \cdot \lambda = \mu = g \cdot \lambda$.  Since the action is free, $\rho_{b,p}(q)  = g $.  Thus $\rho_{b,p,\lambda}$ is surjective if and only if $\rho_{b,p}$ is surjective.",2502.01805
proof,"Since the additive action of $\mathbb{F}$ on itself is regular, it follows from Theorem 5 and Proposition 6 that it suffices to show that for every $p \in \mathscr{P}$ and $L \in \mathscr{B}$ so that $p \ \cancel{\mathrm{I}} \ L$, $\rho_{L,p}$ is bijective.   \textit{Proof of the injectivity of $\rho_{L,p}$.}  Suppose $L \in \mathscr{B}$ and $p \in \mathscr{P}$ so that $p \ \cancel{\mathrm{I}} \ L$.  Let $p_1,p_2$ be distinct points incident with $L$, and let $M_1$ be the unique line incident with $p$ and $p_1$ and let $M_2$ be the unique line incident with $p$ and $p_2$.  Let $w_1 = (L,e_1,p_1,e_2,M_1,e_3,p)$ and let $w_2 = (L,e_6,p_2,e_5,M_2,e_4,p)$ be the corresponding walks in $\Gamma$.  We need to show that $\rho_{L,p}(p_1) \neq \rho_{L,p}(p_2)$.  \textit{Case 1.}  Suppose that $L = L_b$ is a vertical line.  Let $p_1 = (b,y_1)$, $p_2 = (b,y_2)$, and $p = (x,y)$.  And so $x \neq b$ and $y_1 \neq y_2$.  Now $M_1 = L_{m_1,b_1}$ with slope $m_1 = (y-y_1)(x-b)^{-1}$ and $y$-intercept $b_1 = y_1 - m_1 b,$ and $M_2 = L_{m_2,b_2}$ with slope $m_2 = (y-y_2)(x-b)^{-1}$ and $y$-intercept $b_2 = y_2 - m_2 b.$  Hence we need to show that   \nonumber \varphi(e_3) - \varphi(e_2) + \varphi(e_1) \neq  \varphi(e_4) - \varphi(e_5) + \varphi(e_6), \text{  i.e.  } \\ xb_1 - bb_1 - by_1 \neq xb_2 - bb_2 - by_2.   Substituting for $b_1$, the left hand side of (1) becomes  x(y_1 - (y-y_1)(x-b)^{-1}b) - b(y_1 - (y-y_1)(x-b)^{-1}b) - by_1 = \\ (x-b)y_1 - (x-b)(y-y_1)(x-b)^{-1}b - by_1 = \\ (x-b)y_1 - (y-y_1)b - by_1 = \\ xy_1 - yb - by_1.   Similarly, the right hand side of (1) becomes $$xy_2 - yb - by_2.$$  Hence we need to show that $$y_1(x - b) \neq y_2(x-b),$$ and this is true since $x \neq b$ and $y_1 \neq y_2$.  \textit{Case 2.}  Suppose that $L = L_{m,b}$ is a non-vertical line.  Let $p_1 = (x_1, y_1)$, $p_2 = (x_2, y_2)$, and $p = (x,y)$.  And so $y \neq mx + b$ and $x_1 \neq x_2$.  If $x=x_1$, then $M_1 = L_x$ is a vertical line, and we have   \varphi(e_3) - \varphi(e_2) + \varphi(e_1) = \\ -x_1y + xy_1 + x_1b.   If $x=x_2$, then $M_2 = L_x$ is a vertical line, and we have  \varphi(e_4) - \varphi(e_5) + \varphi(e_6) = \\ -x_2y + xy_2 + x_2b.   If $x \neq x_1$, then $M_1 = L_{m_1,b_1}$ is a non-vertical line with slope $m_1 = (y-y_1)(x-x_1)^{-1}$ and $y$-intercept $b_1 = y_1 - m_1 x_1.$  In this case we have  \varphi(e_3) - \varphi(e_2) + \varphi(e_1) = \\ xb_1 - x_1b_1 + x_1b.  Substituting for $b_1$, we obtain  x(y_1 - (y-y_1)(x-x_1)^{-1}x_1) - x_1(y_1 - (y-y_1)(x-x_1)^{-1}x_1) + x_1b = \\ (x-x_1)y_1 - (x-x_1)(y-y_1)(x-x_1)^{-1}x_1 + x_1b = \\ (x-x_1)y_1 - (y-y_1)x_1 + x_1b = \\ xy_1 - x_1y + x_1b.   If $x \neq x_2$, then $M_2 = L_{m_2,b_2}$ is a non-vertical line with slope $m_2 = (y-y_2)(x-x_2)^{-1}$ and $y$-intercept $b_2 = y_2 - m_2 x_2.$ Similarly we obtain   \varphi(e_4) - \varphi(e_5) + \varphi(e_6) = \\ xy_2 - x_2y + x_2b.   In any case, we need to show that   \varphi(e_3) - \varphi(e_2) + \varphi(e_1) \neq \varphi(e_4) - \varphi(e_5) + \varphi(e_6), \text{  i.e.  } \\ xy_1 - x_1y + x_1b \neq xy_2 - x_2y + x_2b.   Now $y_1 = mx_1 + b$, and $y_2 = mx_2 + b$, and, after substituting, we need then to show that $$x_1(mx + b - y) \neq x_2(mx + b - y),$$ and this is true since $y \neq mx + b$ and $x_1 \neq x_2$.  \textit{Proof of the surjectivity of $\rho_{L,p}$.}  \textit{Case 1.}  Suppose that $L = L_b$ is a vertical line and $p = (x,y)$ is not incident with $L$.  And so $x \neq b$.  Let $z \in \mathbb{F}$ be arbitrary.  Let $y_1 = (x-b)^{-1}(z + yb).$  Let $p_1 = (b,y_1)$.  Let $M_1$ be the unique line incident with $p$ and $p_1$, and so $M_1 = L_{m_1,b_1}$ with slope $m_1 = (y-y_1)(x-b)^{-1}$ and $y$-intercept $b_1 = y_1 - m_1 b.$  Let $w_1 = (L,e_1,p_1,e_2,M_1,e_3,p)$ be the corresponding walk in $\Gamma$.  It follows by a similar computation as in the injectivity proof that   y_1(x-b) - yb = z, \text{  i.e.  } \\ xy_1 - yb - by_1 =z, \text{  i.e.  } \\ xb_1 - bb_1 - by_1 = z, \text{  i.e.  } \\ \varphi(e_3) - \varphi(e_2) + \varphi(e_1) = z.   \textit{Case 2.}  Suppose that $L = L_{m,b}$ is a non-vertical line and $p = (x,y)$ is not incident with $L$.  And so $y \neq mx + b$.  Let $z \in \mathbb{F}$ be arbitrary.  Let  $x_1 = (mx + b - y)^{-1} (z - xb).$  Let $p_1 = (x_1, y_1)$ be incident with $L$, and so $y_1 = mx_1 + b$.  Let $M_1$ be the unique line incident with $p$ and $p_1$.  Let $w_1 = (L,e_1,p_1,e_2,M_1,e_3,p)$ be the corresponding walk in $\Gamma$.    If $x=x_1$, then $M_1 = L_x$ is a vertical line.   It follows by a similar computation as in the injectivity proof that  x_1(mx + b - y) + xb = z, \text{ i.e. } \\ - x_1y + xy_1 + x_1b = z, \text{ i.e. } \\ \varphi(e_3) - \varphi(e_2) + \varphi(e_1) = z.   If $x \neq x_1$, then $M_1 = L_{m_1,b_1}$ is a non-vertical line with slope $m_1 = (y-y_1)(x-x_1)^{-1}$ and $y$-intercept $b_1 = y_1 - m_1 x_1.$   It follows by a similar computation as in the injectivity proof that  x_1(mx + b - y) + xb = z, \text{ i.e. } \\ xy_1 - x_1y + x_1b = z, \text{ i.e. } \\ xb_1 - x_1b_1 + x_1b = z, \text{  i.e.  } \\ \varphi(e_3) - \varphi(e_2) + \varphi(e_1) = z. \qedhere",2502.01805
proposition,"Let $(\Gamma,\varphi)$ be an incidence gain graph with underlying incidence structure $(\mathscr{P},\mathscr{B},\mathrm{I})$ and gain group acting on a nonempty set $\Lambda$.  Let $f$ be a switching function and let $\mathfrak{M}(\Gamma,\varphi) = (\mathscr{P}',\mathscr{B}', \mathrm{I}')$ and $\mathfrak{M}(\Gamma,{}^f\varphi) = (\mathscr{P}',\mathscr{B}',\mathrm{I}'_f)$.     \item Define a function $g_1: \mathscr{P}' \rightarrow \mathscr{P}'$ by $g_1(x_p) = x_p$ and $g_1(y_{b,\lambda}) = y_{b,\mu}$ where $\mu = f(b) \cdot \lambda$. \item Define a function $g_2: \mathscr{B}' \rightarrow \mathscr{B}'$ by $g_2(z_{p,\lambda}) = z_{p,\mu}$ where $\mu = f(p) \cdot \lambda$.   The pair $(g_1,g_2)$ is an incidence structure isomorphism from $\mathfrak{M}(\Gamma,\varphi)$ to $\mathfrak{M}(\Gamma,{}^f\varphi)$.",2502.01805
proposition,"Let $(\Gamma,\varphi)$ be an incidence gain graph with underlying incidence structure $(\mathscr{P},\mathscr{B},\mathrm{I})$ and gain group acting on a nonempty set $\Lambda$.  Let $u_0,\dots,u_k \in \mathscr{P} \cup \mathscr{B}$ for some integer $k \geq 1$.  We have $(u_0,\dots,u_k)$ is a $k$-chain in $(\mathscr{P},\mathscr{B},\mathrm{I})$ if and only if \\ $(m_0,\dots,m_k)$ is a $k$-chain in $\mathfrak{M}(\Gamma,\varphi)$, where for each $i \in \{ 0,\dots,k \}$, $m_i = y_{u_i,\lambda_i}$ for some $\lambda_i \in \Lambda$ if $u_i \in \mathscr{B}$ and $m_i = z_{u_i,\lambda_i}$ for some $\lambda_i \in \Lambda$ if $u_i \in \mathscr{P}$.  Furthermore, if we have such $k$-chains, then $\lambda_k = \varphi_{w} \cdot \lambda_0$, where $$w = (u_0,e_1,u_1,e_2,\dots,u_{k-1},e_{k},u_{k})$$ is the corresponding walk in $\Gamma$.",2502.01805
proposition,"Let $(\Gamma,\varphi)$ be an incidence gain graph with underlying incidence structure $(\mathscr{P},\mathscr{B},\mathrm{I})$ a linear space, and gain group $G$ acting regularly on a nonempty set $\Lambda$.  Let $p \in \mathscr{P}$ and $b \in \mathscr{B}$ with $p \  \cancel{\mathrm{I}} \  b$, and let $\lambda \in \Lambda$.  We have $\rho_{b,p,\lambda}$ is bijective if and only if $\rho_{b,p}$ is bijective.",2502.01805
lemma,"Let $(\Gamma,\varphi)$ be an incidence gain graph with underlying incidence structure $(\mathscr{P},\mathscr{B},\mathrm{I})$ a linear space, and gain group acting on a nonempty set $\Lambda$.  Let $p,q \in \mathscr{P}$, $b \in \mathscr{B}$, and $\lambda, \mu \in \Lambda$.    \item If $p=q$, then $d(x_p,z_{q,\lambda}) = 1$ and $(x_p,z_{q,\lambda})$ is the unique $1$-chain in $\mathfrak{M}(\Gamma,\varphi)$ from $x_p$ to $z_{q,\lambda}$. \item If $p\neq q$, then $d(x_p,z_{q,\lambda}) = 3$ and there is a unique $3$-chain in $\mathfrak{M}(\Gamma,\varphi)$ from $x_p$ to $z_{q,\lambda}$. \item If $b \  \mathrm{I} \  p$ and $\mu = \varphi(bp) \cdot \lambda$, then $d(y_{b,\lambda},z_{p,\mu}) = 1$ and $(y_{b,\lambda},z_{p,\mu})$ is the unique $1$-chain in $\mathfrak{M}(\Gamma,\varphi)$ from $y_{b,\lambda}$ to $z_{p,\mu}$. \item If $b \  \mathrm{I} \  p$ and $\mu \neq \varphi(bp) \cdot \lambda$, then $d(y_{b,\lambda},z_{p,\mu}) = 3$ and there is a unique $3$-chain in $\mathfrak{M}(\Gamma,\varphi)$ from $y_{b,\lambda}$ to $z_{p,\mu}$.",2502.01805
lemma,"Let $(\Gamma,\varphi)$ be an incidence gain graph with underlying incidence structure $(\mathscr{P},\mathscr{B},\mathrm{I})$ a linear space, and gain group acting on a nonempty set $\Lambda$.  Let $\mathfrak{M}(\Gamma,\varphi) = (\mathscr{P}',\mathscr{B}',\mathrm{I}')$.  If $u,v \in \mathscr{P}' \cup \mathscr{B}'$ are either both points or are both lines, and if $d(u,v) \leq 2$, then there is a unique $2$-chain in $\mathfrak{M}(\Gamma,\varphi)$ from $u$ to $v$.",2502.01805
theorem,"[Existence and uniqueness \cite{HofmeisterThesis} {\cite[art.\ 74]{GS2}} ] 	The spectral degree exponent (SDE) exists, is unique and is bounded in $q \in [2,\infty]$.",2502.01815
theorem,"[Theorem 4.1 in \cite{hofmeister1988spectralradius}] Let $G$ be a simple, non-regular graph. \\ 	\phantom{a}\qquad (a) If $G$ is biregular, then $q=2$. \\ 	\phantom{a}\qquad (b) If $G$ is connected and $q=2$, then $G$ is biregular.",2502.01815
theorem,"[Satz II.9 in \cite{HofmeisterThesis}] 	Let $G$ be a simple, non-regular graph with maximum weighted degree $d_{\max}$. It holds that $q=\infty$ if and only if $G$ is disconnected and one component of $G$ is a clique of weighted size $d_{\max}+1$.",2502.01815
theorem,The spectral degree exponent (SDE) $q$ is bounded by 	 		\frac{\log N - \log\left( c + ( N-c) \left( \frac{d_{2}}{d_{\max}}\right)  ^{2} \right) }{\log\left( \frac{d_{\max}}{\lambda_{1}}\right)} \leq q \leq \frac{\log \frac{N}{c}}{\log\left( \frac{d_{\max}}{\lambda_{1}}\right) } 	 	where $c$ is the multiplicity of the maximum weighted degree $d_{\max}$ and $d_2$ is the second-largest weighted degree.,2502.01815
theorem,"For the path graph $P_N$ on $N$ nodes, it holds that 	 		q =\frac{4}{\pi^2} N + \frac{12}{\pi^2} + \left( \frac{1}{3} + \frac{52}{3\pi^{2}} \right) \frac{1}{N} + O\left(\frac{1}{N^2}\right), \qquad \textnormal{for } N \to\infty.",2502.01815
theorem,"For the \textbf{wheel graph} $W_N$ on $N$ nodes, the SDE $q = 2 + o(1)$ for $N\to\infty$.",2502.01815
theorem,"Define the ``path with double fork"" graph $A_N$ on $N+4$ nodes, consisting of a path graph $G$ on $N$ nodes, with two nodes connected to the end of the path and another two nodes attached to the other end of the path. We find that $q \approx 2.36864$, independent of $N$.",2502.01815
theorem,"The modified lollipop graph $B_N$ on $N+5$ nodes is constructed by starting with a complete graph $K_4$ with one link removed. The nodes adjacent to the removed link are connected to a new node~5. To node 5, a path graph of length $N$ is connected, see Figure~\ref{fig_graph_B}. For the graph $B_N$ on $N+5$ nodes, it holds that 	 		q \approx 30.11 \log(N) - 48.46 \qquad \text{for } N \to \infty",2502.01815
definition,"The \textbf{spectral degree exponent} (SDE) of a simple, undirected, non-regular (but possibly disconnected and weighted) graph $G$ is defined as the solution for $q$ of the equation 	 		\lambda_1 = \left( \frac{1}{N} \sum_{i=1}^N d_i^{\, q} \right)^{1/q}.",2502.01815
definition,A graph $G$ is \textbf{biregular} (also known as semiregular bipartite) if it is bipartite and the nodes in the same group have the same (weighted) degree.,2502.01815
theorem,Let $K$ be the unlink of two unknotted $S^2$'s in $S^4$. Then there exist infinitely many pairwise non-isotopic splitting spheres for $K$.,2502.01817
proof,"Let $L \# R$ denote $S^1 \times B^3 \# S^1 \times B^3$, where $L$ and $R$ are $S^1 \times B^3$'s. Let $\Sigma$ denote the $S^3$ along which $L$ and $R$ are identified in the connect sum.           \noindent Consider the barbell diffeomorphism $\beta_k: L \# R \rightarrow L \# R$ given by the red barbell implantation below, $k\geq 4$. As in \cite{BG}, we think of $S^1 \times B^3$ as $S^1 \times D^2 \times [-1,1]$, where the $t\in[-1,1]$ parameter represents time. We think of $L \# R$ as two copies of $(S^1 \times D^2) \times [-1,1] \setminus D^3 \times (-0.5, 0.5)$ ($L$ on the left and $R$ on the right) which are identified along the $S^3$ boundary of the $B^4=D^3 \times [-0.5,0.5]$. \Cref{beta} shows the barbell in the $t=0$ slice of $L\# R$. The orange $S^2$'s on left and right are identified and depict the equatorial cross-section of $\Sigma$ in this slice, which gets filled in by $B^3$'s in the future and past.           [h!]         \centering         \includegraphics[width=0.5\linewidth]{beta.jpeg}         \caption{$\beta_k$ in the $t=0$ slice of $L\# R$. The numbering on the orange $S^2$'s denotes which points are identified.}                    \noindent First we note that $\beta_k$ is not isotopic to the identity. If it were, then after gluing an $S^2 \times D^2$ to $R$ and extending $\beta_k$ over it by the identity, the extension $\hat{\beta_k}$ would also be isotopic to the identity as a diffeomorphism of $L \# (R \cup_{S^1 \times S^2}D^2 \times S^2)=S^1 \times B^3 \# S^4 \approx S^1 \times B^3$. On the other hand, we can see that $\hat{\beta_k} \approx  \delta_k$ of \cite{BG} (\Cref{isotope beta to delta}), which they showed to be nontrivial in $\pi_0(\text{Diff}_\partial(S^1 \times B^3)/\text{Diff}_\partial(B^4))$ for $k\geq 4$.          [h!]         \centering         \includegraphics[width=0.75\linewidth]{isotope_beta_to_delta.jpeg}         \caption{The isotopy of $\hat{\beta_k}$ to $\delta_k.$ Note that we also recover $\delta_k$ if we cap off $L$ rather than $R$.}                     \noindent Now suppose that $\beta_k(\Sigma)$ is isotopic to $\Sigma$. By \cite{Ce}, $\beta_k$ is isotopic rel $\partial$ to a diffeomorphism $\Bar{\beta}_k$ such that $\Bar{\beta}_k\restriction_\Sigma=id$. Then $\Bar{\beta_k}$ factors as a diffeomorphism $\Bar{\beta_k}=f_L \# f_R$, where $f_L$ and $f_R$ are diffeomorphisms of $L \setminus B^4$ and $R \setminus B^4$ that are the identity near the $S^1 \times S^2 \sqcup S^3$ boundary (\Cref{fLfR}). Moreover, since $\Bar{\beta_k}\not\approx id$ rel $B^4$, then either $f_L\not\approx id$ rel $B^4$ or $f_R\not\approx id$ rel $B^4$. Suppose $f_L\not\approx id$ rel $B^4$. Fill in the missing $B^4$ to $L\setminus B^4$ and extend $f_L$ over it by the identity, and let $\hat{f_L}: S^1 \times B^3 \rightarrow S^1 \times B^3$ denote the extension. Then $\hat{f_L}$ is nontrivial in $\pi_0(\text{Diff}_\partial (S^1 \times B^3)/\text{Diff}_\partial (B^4))$: after gluing an $S^2 \times D^2$ to $R$ in $L \# R$ and extending $f_L \# f_R$ over it by the identity, the extension $\hat{f_L \# f_R}$ agrees with $\hat{f_L}$ outside of a $B^4$ containing $R\setminus B^4 \cup_{S^1\times S^2} D^2 \times S^2 \subset S^1 \times B^3$, so $\hat{f_L}=\hat{f_L \# f_R}$ in $\text{Diff}_\partial (S^1 \times B^3)/\text{Diff}_\partial (B^4)$; since $f_L \# f_R \approx \beta$ in $L \# R$, then $\hat{f_L \# f_R} \approx \hat{\beta}$ in $S^1 \times B^3$, and $\hat{\beta}$ was nontrivial in $\pi_0(\text{Diff}_\partial (S^1 \times B^3)/\text{Diff}_\partial (B^4))$ as we saw above.            [h!]          \centering          \includegraphics[width=0.4\linewidth]{fL_fR.jpeg}          \caption{Schematic of $f_L \# f_R$.}                       \noindent Consider the $k$-fold cyclic cover $X\approx \#_{k+1} S^1 \times B^3$ of $L \# R$ obtained by ""unwinding"" the $R$ factor; see \Cref{2D pic} for the analogous 2-dimensional picture.       [h!]          \centering          \includegraphics[width=0.4\linewidth]{2D_pic.jpeg}          \caption{The 2-dimensional analogue of $X$ for $k=5$. The central $S^1 \times B^1$ covers $R$, and the orbiting $S^1 \times B^1$'s cover $L$.}                       \noindent Lifting the barbell representing $\beta_k$ to $X$ and considering the resultant lift $\Tilde{\beta_k}:X \rightarrow X$ of $\beta_k$, we see that $\Tilde{\beta_k}$ is represented by $k$ disjoint copies of a barbell which can be isotoped into a $B^4\subset X$, so that $\Tilde{\beta_k}$ is a composition of trivial elements in $\pi_0(\text{Diff}_\partial(X)/\text{Diff}_\partial(B^4))$ and is therefore trivial too. (\Cref{beta lift})       [h!]          \centering          \includegraphics[width=0.75\linewidth]{lift_of_beta.jpeg}          \caption{One of the $k$ copies of the barbell for the lift $\Tilde{\beta_k}$ when $k=5$. Here we depict the $t=0$ slice of $X\approx \#_{k+1} S^1 \times D^2 \times [-1,1]$. The orange $S^2$'s are cross-sections of the $k$ $S^3$'s which we identify in the connect sum, and are labeled according to that identification. The barbell begins in $L_1$, hits $\Sigma_1$ and travels to $\Tilde{R}$, then hits $\Sigma_2$ and travels to $L_2$, and so on until ending in $L_5$.  The barbell no longer loops around any $S^1$ factors, so we can pull it into a 4-ball.}                       \noindent On the other hand, consider the lift of $f_L \# f_R$ to $X$; call it $F$. Let $L_1,...,L_k$ denote the $S^1 \times B^3$ summands of $X$ which cover $L$, let $\Tilde{R}$ denote the $S^1 \times B^3$ summand of $X$ which covers $R$, and let $\Sigma_1,...\Sigma_k$ denote the $S^3$'s in $X$ which cover $\Sigma$. Then $F\restriction_{L_i}=f_L$, $F\restriction_{\Tilde{R}}=\Tilde{f_R}$ some lift of $f_R$, and $F$ is the identity on a neighborhood of $\partial X$ and of $\Sigma_1,...,\Sigma_k$.  (\Cref{lift of fL fR})       [h!]          \centering          \includegraphics[width=0.4\linewidth]{lift_of_fL_fR.jpeg}          \caption{Schematic of the lift $F$ for $k=5$.}                       \noindent But $F$ is nontrivial in $\pi_0(\text{Diff}_\partial(X)/\text{Diff}_\partial(B^4))$; if it were trivial, then after gluing $D^2 \times S^2$'s to $L_2,...,L_k, \Tilde{R}$ and extending $F$ over them by the identity, the extension $\hat{F}:S^1 \times B^3 \rightarrow S^1 \times B^3$ would also be trivial in $\pi_0(\text{Diff}_\partial(S^1 \times B^3)/\text{Diff}_\partial(B^4))$. But $\hat{F}=\hat{f_L}$ outside of a $B^4 \subset S^1 \times B^3$, so $\hat{F}=\hat{f_L}$ in $\text{Diff}_\partial(S^1 \times B^3)/\text{Diff}_\partial(B^4)$, and $\hat{f_L}$ was nontrivial in $\pi_0(\text{Diff}_\partial(S^1 \times B^3)/\text{Diff}_\partial(B^4))$ by assumption. So $F$ is nontrivial in $\pi_0(\text{Diff}_\partial(X)/\text{Diff}_\partial(B^4))$.        \noindent Therefore $F\not\approx \Tilde{\beta_k}$, so $f_L \# f_R \not\approx \beta_k$, giving us our contradiction. Therefore $\beta_k(\Sigma)$ is not isotopic to $\Sigma$.       \noindent Replacing $\beta_k$ by $\beta_i \circ \beta_j^{-1}$ for $i\neq j, i, j \geq 4$, and lifting to the $ij$ -fold cyclic cover of $L\#R$, we see that $\beta_i \circ \beta_j^{-1}(\Sigma)\not\approx \Sigma$; therefore all the $\beta_k$'s for $k\geq 4$ give pairwise non-isotopic $S^3$'s in $S^1 \times B^3 \# S^1 \times B^3$, providing our infinite family of non-isotopic splitting spheres for two unlinked, unknotted $S^2$'s in $S^4$.",2502.01817
theorem,"For any given $c$, the KL divergence between $p^{\theta}$ and $p^{\theta_{pre}}$ is:  &\operatorname{KL}(p^{\theta}(T,\cdot,c)\|p^{\theta_{pre}}(T,\cdot,c))\nonumber\\ &= \mathbb{E}\int_{0}^{T} \frac{g^2(T-t)}{2}\|\mu^{\theta}(t,X_t^{\theta},c)-\mu^{\theta_{pre}}(t,X_t^{\theta},c)\|^2\mathrm{d}t.",2502.01819
theorem,"%We have that the policy  The gradient of an admissible policy $\pi^{\theta}$ parameterized by $\theta$ takes the form:  \nabla_{\theta} V^{\theta}= \mathbb{E}\left[\int _ { 0 } ^ { T }\nabla_{\theta} \log \pi^ { \theta} ( a _ { t } ^ {\theta} | t , X _ { t } ^ {\theta} ) q(t, X_t^{\theta}, a_t^{\theta} ; \pi^\theta)\mathrm{d} t\right],  where $\pi^\theta$, $a^\theta_t$ and $q$ are as defined in \eqref{atht} and \eqref{defqvalue}.",2502.01819
theorem,"Under Assumption \ref{Difference Bound Assumptions}, then for any policy $\hat{\theta}$ such that $\bigl|\ln \bigl(\tfrac{p^{\hat{\theta}}(x)}{p^{\theta_{\mathrm{pre}}}(x)}\bigr)\bigr|$ is bounded, and $\mathrm{KL}(p^{\theta} \,\|\, p^{\hat{\theta}})\leq 1$, there exists a constant $C > 0$ such that:  |V^{\hat{\theta}} & - L^{\theta}(\hat{\theta})|\leq \nonumber\\ &C \, \left(\mathbb{E}\int_{0}^{T} \operatorname{KL}(\pi^{\theta}(\cdot | t , X _ { t } ^ {\theta} )\|\pi^{\hat{\theta}}( \cdot | t , X _ { t } ^ {\theta} ))\mathrm{d}t\right)^{\frac{1}{2}}.",2502.01819
theorem,"For $t \in[0, T]$, let $\mathcal{L}_t=\int_0^t b_s \mathrm{~d} B_s$ where $B$ is a $Q$-Brownian motion. Assume that $\mathbb{E}_Q \int_0^T\left\|b_s\right\|^2 \mathrm{~d} s<\infty$. Then, $\mathcal{L}$ is a $Q$-martingale in $L^2(Q)$. Moreover, if   \mathbb{E}_Q \mathcal{E}(\mathcal{L})_T=1, \quad \text { where } \mathcal{E}(\mathcal{L})_t:=\exp \left(\int_0^t b_s \mathrm{~d} B_s-\frac{1}{2} \int_0^t\left\|b_s\right\|^2 \mathrm{~d} s\right),  then $\mathcal{E}(\mathcal{L})$ is also a $Q$-martingale, and the process  t \mapsto B_t-\int_0^t b_s \mathrm{~d} s  is a Brownian motion under $P:=\mathcal{E}(\mathcal{L})_T Q$, the probability distribution with density $\mathcal{E}(\mathcal{L})_T$ w.r.t. $Q$.",2502.01819
lemma,"We have that:   V^{\hat{\theta}} - V^{\theta} =\mathbb{E}\int _ { 0 } ^ { T } q(t, X_t^{\hat{\theta}}, a_t^{\hat{\theta}} ; \pi^{\theta})\mathrm{d} t.",2502.01819
lemma,"[Theorem 5 of \cite{jia2022policy_gradient} when $R\equiv 0$]  Under some regularity conditions, given an admissible parameterized policy $\pi_{\theta}$, the policy gradient of the value function $V\left(t, x ; \pi^\theta\right)$ admits the following representation:    \frac{\partial}{\partial \theta} V(t, x ; \pi^\theta)= & \mathbb{E}^{\mathbb{P}}\left[\int _ { t } ^ { T } e ^ { - \beta ( s - t ) } \left\{\frac { \partial } { \partial \theta} \operatorname { l o g } \pi^ { \theta} ( a _ { s } ^ { \boldsymbol { \pi } ^ {\theta} } | s , X _ { s } ^ { \boldsymbol { \pi } ^ {\theta} } ) \left(\mathrm{d} V(s, X_s^{\pi^\theta} ; \pi^\theta)\right.\right.\right. \\ & \left.\left.\left.+\left[r_R(s, X_s^{\pi^\theta}, a_s^{\pi^\theta})-\beta V(s, X_s^{\pi^\theta} ; \pi^\theta)\right] \mathrm{d} s\right) \right\} \mid X_t^{\pi^\theta}=x\right], \quad(t, x) \in[0, T] \times \mathbb{R}^d   in which we denote the regularized reward $$ r_R(t, X_t^{\pi^\theta}, a_t^{\pi^\theta}) = \gamma(t) \|a_t^{\pi^\theta}-s^{\theta^{*}}(t,X_t)\|^2. $$",2502.01819
theorem,"$(\mathbf{P1})=(\mathbf{P2})$, where ``$=$"" stands for equivalence between the two problems.",2502.01827
theorem,"When $p_0, p_1 \geq \frac{1}{2}$, the optimal policy choices at the two states are:              \item $b \in [0, b_l) $                                        a_0 = p_0, ~ a_1 = \eta_1^{-}(b), &\mbox{if}~ |\frac{1}{2} - p_1 | \geq |\frac{1}{2} - p_0 |\\                 a_0 = \eta_0^{-}(b), ~ a_1 = p_1, &\mbox{if} ~ |\frac{1}{2} - p_1 | < |\frac{1}{2} - p_0 |                                \item $b \in [b_l, b_h)$                       & a_0 = a_1 = -M(\frac{b}{2} - \mathbf{d}_{0}^\gamma p_0 - \mathbf{d}_{1}^\gamma p_1 )                   \item $b \in [b_h, \infty)$                       & a_0 = a_1 = \frac{1}{2}                   where we defined                           b_l & = 2\max\{(1 -\gamma p_0 - \mathbf{d}^{\gamma}_0 )(p_1 - p_0), \notag\\             &\qquad\qquad\qquad (\mathbf{d}^{\gamma}_0 +\gamma p_1)(p_0 - p_1)\}\\ 		b_h & = (2\mathbf{d}^{\gamma}_0 +\gamma)(p_0 - p_1)+2p_1-1\\         M & = \frac{1}{1-\gamma p_0 + \gamma p_1}.",2502.01827
theorem,"When $p_1 \geq \frac{1}{2}>p_0$, the optimal policy choices at the two states are:              \item $b \in [0, b_l') $                                       a_0 = p_0, ~ a_1 = \eta_1^{-}(b), & \mbox{if}~ |\frac{1}{2} - p_1 | \geq |\frac{1}{2} - p_0 |\\                 a_0 = \eta_0^{+}(b), ~ a_1 = p_1, & \mbox{if} ~ |\frac{1}{2} - p_1 | < |\frac{1}{2} - p_0 |                                \item $b \in [b_l', b_h']$                      &(a_0, a_1) \in S_b  \triangleq \bigg\{ (a_0,a_1) \in [p_0,\frac{1}{2}]\times[\frac{1}{2},p_1] ~ :~\nonumber              \\ &\qquad \Phi_-(a_1) = \Phi_+(a_0)               \cap m(a_0,a_1) = \frac{b}{2} \bigg\}                  \item $b \in (b_h', \infty)$                       & a_0 = a_1 = \frac{1}{2}                   where we define                            &b_l'  = 2\left( \frac{\mathbf{d}^{\gamma}_0 +\gamma p_{1}}{1-\gamma \psi_{0} +\gamma p_{1}} \right)  (\psi_{0} -p_{0})u(1-p_{0}-p_{1})  \nonumber \\ 		 & \quad + 2\left( \frac{1-\gamma p_{0}-\mathbf{d}^{\gamma}_0 }{1-\gamma p_{0}+\gamma \psi_{1} } \right)  (p_{1}-\psi_{1} )u(-1+p_{0}+p_{1}) \\ 		&b_h'  = (2\mathbf{d}^{\gamma}_0 +\gamma)(1-p_0 - p_1)+2p_1-1              and                      &\Phi_{\pm}(a)  = ( \pm1 + \gamma p_0 + \gamma p_1) \log \left(\frac{1-a}{a}\right) \notag\\         &\qquad\qquad\qquad-2 \gamma \log(1-a) \\         &\Psi_{p_0} (a_1)  = \Phi_+(p_0) - \Phi_-(a_1), ~\psi_0 = \Psi^{-1}_{p_1} (0) \\         &\Psi_{p_1} (a_0) = \Phi_+(a_0) - \Phi_-(p_1),~ \psi_1  = \Psi^{-1}_{p_0} (0) \\         &m(a_0,a_1)  = d_0(a_0-p_0)+d_1(p_1-a_1)                  and $u(\cdot)$ is a unit step function in $b_l'$.",2502.01827
theorem,"[Informal formulation]    Let $H^\Z$ be the  the  random XXZ Hamiltonian on $\cH_\Z$ with  parameters $\Delta>1$and $\lambda >0$. Fix the energy    interval $I(E_0)=[0,E_0]$, where $E_0>0$.   Then, if  $\lambda \Delta^2$ is sufficiently large, we have:      \item   Spectral   and eigenstate  localization in the interval  $I(E_0)$:  The spectrum of $H^\Z$ in $I(E_0)$ is almost surely pure point, and the corresponding eigenvectors  in  $I(E_0)$ decay exponentially fast away from their localization centers (in a suitable sense). % \item  Weak dynamical localization in the interval $I(E_0)$:  The expectation of the absolute value of the   matrix elements of $\chi_{I(E_0)}(H^\Z)\e^{itH^\Z}$ decays exponentially fast (in a suitable sense), uniformly in $t\in \R$.",2502.01831
theorem,"Fix parameters $\Delta_0>1$ and $ \lambda_0 >0$. Given  $q\in \frac 12 \N^0$,   there exists a constant $Y$ (which depends on $\Delta_0\,,\lambda_0$, $\mu$, and $q$) such that,   for all $\Delta \ge \Delta_0$ and $\lambda\ge \lambda_0$ satisfying  $\lambda \Delta^2\ge Y$ the following holds:       \item  $H^\Z$ exhibits spectral and eigenstate  localization  in the interval  $I_{\le q}$, more precisely, there exists an event $\cE$, with $\P_\Z(\cE)=1$, such that for $\omega \in \cE$  the spectrum of $H^\Z$ in $I_{\le q}$ is pure point, and if $\psi=\psi_\omega$ is an eigenfunction of $H^\Z$ with corresponding eigenvalue  in  $I_{{\le q}}$, so $\cN^\Z\psi =N_\psi \psi$, where   $ N_\psi \in \N^0$,  it decays exponentially   in the following sense:    \be \abs{\psi(\y)} \le C_{\omega,N_\psi}   \abs{\x_{\psi}}_2^{N_\psi +1}\e^{-{c_q} \wtilde d_{H}^\Z({\bf y},\x_{\psi})} \qtx{for all} \y \in \cP_+(\Z),  \ee where $\x_{\psi}\in \cP_{N_\psi}(\Z)$ is a center of localization for $\psi$,  that is, it satisfies \be \abs{\psi(\x_{\psi})}^2 \ge   \frac {\pa{\abs{\x_{\psi}}_2+1}^{-\pa{N_\psi+1}}}{\sum_{\u \in  \cP_{N_\psi}(\Z)}       \pa{    \abs{\u}_2+1}^{-\pa{N_\psi +1}}} . \ee   \item $H^\Z$ exhibits weak dynamical localization in the interval  $I_{{ \le q}}$, more precisely, \be \E_\Z \set{\sup_{f\in B_1(I_{\le q})}\abs{ f(H^\Z) (\x,\y)}}\le  C_q \e^{-c_q \wtilde d_{H}^\Z({\bf x},{\bf y})} \qtx{for all}\x,\y\in \cP_{+}(\Z). \ee",2502.01831
theorem,"Fix parameters $\Delta_0>1$ and $ \lambda_0 >0$. Let $q\in \frac 12 \N^0$ and $s \in (0,\frac 13)$.   Then there exists a constant $Y$ (which depends on $\Delta_0\,,\lambda_0$, $\mu$, $q$, and $s$) such that,   for all $\Delta \ge \Delta_0$ and $\lambda\ge \lambda_0$ satisfying  $\lambda \Delta^2\ge Y$ the following holds:   For  all finite $D\subset \Z$  we have  \be \sup_{z\in\mathds{H}_q} \E_D\set{\abs{G^{D}_{z}({\bf x},{\bf y})}^s}\le C_q \abs{D}^{C_q}\e^{-c_q  \wtilde d^D_H ({\bf x},{\bf y})} \mqtx{for all} {\bf x},{\bf y} \in \cP_+(D). \ee",2502.01831
theorem,"[Finite volumes criterion]  Fix $\Delta >1$ and $\lambda >0$.   Let  $s\in (0,\frac 13)$ and  $q\in \frac 12 \N^0$.    Suppose that for  all finite $D\subset \Z$  we have  \be \sup_{z\in\mathds{H}_q} \E_D\set{\abs{G^{D}_{z}({\bf x},{\bf y})}^s}\le C_q \abs{D}^{C_q}\e^{-c_q  \wtilde d^D_H ({\bf x},{\bf y})} \mqtx{for all} {\bf x},{\bf y} \in \cP_+(D). \ee  Then    for all  $\La\subset\Z$     we have  \be  \sup_{z\in\mathds{H}_q}\E_\La \set{\abs{G^{\La}_{z} ({\bf x},{\bf y})}^s}\le  C_{q}\e^{-c_{q} \wtilde d_H^\La ({\bf x},{\bf y})} \mqtx{for all}  {\bf x},{\bf y} \in \cP_+(\La). \ee        Furthermore, for all $D\subset \Z$ finite we have  \be  \E_{D}\set{\cQ_q^D ({\bf x},{\bf y})}\le  C_q e^{-c_q \wtilde d_{H}^D({\bf x},{\bf y})}  \mqtx{for all}\x,\y\in \cP_{+}(D). \ee",2502.01831
theorem,"Let $q\in \frac 12 \N^0$, and suppose that for all $D\subset \Z$ finite  we have  \be % \E_{D}\set{\cQ_q^D ({\bf x},{\bf y})}\le  C_q \e^{-c_q \wtilde d_{H}^D({\bf x},{\bf y})}  \qtx{for all}\x,\y\in \cP_{+}(D). \ee   Then  \be \E_\Z \set{\sup_{f\in B_1(I_{\le q})}\abs{f(H^\Z) ({\bf x},{\bf y})} }\le  C_q \e^{-c_q \wtilde d_{H}^\Z({\bf x},{\bf y})} \qtx{for all}\x,\y\in \cP_{+}(\Z). \ee Moreover, there exists an event $\cE$, with $\P_\Z(\cE)=1$, such that for $\omega \in \cE$  the spectrum of $H^\Z$ in $I_{\le q}$ is pure point, and if $\psi_\omega$ is an eigenfunction of $H^\Z$ with corresponding eigenvalue  in  $I_{q}$, so $\psi \in \cH_\Z^{N_\psi}$ for some $N_\psi \in \N$,  it decays exponentially   in the following sense:    \be \abs{\psi(\y)} \le C_{\omega,N_\psi}   \abs{\x_{\psi}}_2^{N_\psi +1}\e^{-\frac {c_q}2 \wtilde d_{H}^\Z({\bf y},\x_{\psi})},  \ee where $\x_{\psi}\in \cH_\Z\up{N_\psi}$ is a center of localization for $\psi$, that is, \be \abs{\psi(\x_{\psi})}^2 \ge   \frac {\pa{\abs{\x_{\psi}}_2+1}^{-\pa{N_\psi+1}}}{\sum_{\u \in \cH_\Z^{(\N_\psi)}     }          \pa{    \abs{\u}_2+1}^{-\pa{N_\psi +1}}}. \ee",2502.01831
theorem,"Given $t\in \R_+$ and $a\in\R$,  let $F_{t,a}$ be the $C^\infty$  function on $\R$ given  in \eqref{defF}.  Let   $S\subsetneq  T\subset \La$, $S,T$  finite, where $S\subset K_1$ is is connected in $K_1$,  and  let $\ell= \d_\Z\pa{S,T^c}-1$. Then, taking   $ \beta= \frac \Delta {5} $,  for all  $t>1$,  $a\in \R$,  and  $E\in \R$ we have  \be \norm{P_-^{{S}}  F_{t,a}(H-E) P_+^{{T}}}\le  C    \pa{  \e^{-\frac 12\ell} +   \sqrt{t} \,\e^{-\frac { \beta^2\ell^2}{8t}} }, \ee  where all constants are $a$-independent.   In particular,  taking  $t=\frac {\beta^2}8 \ell$,    we have   ($\ell \in \N^0$) \be \norm{P_-^{{S}}  F_{\frac {\beta^2}8 \ell,a}(H-E) P_+^{{T}}}  \le C\e^{- \frac 12 \ell} . \ee",2502.01831
proof,"We proved a slightly stronger result  in  \cite[Theorem 2.4]{EK22}, where it is shown that under the hypotheses of the theorem there exists a constant $Y$ (which depends on $\Delta_0$, $\lambda_0$,  $\mu$, $s$, and $q$) such that,   for all $\Delta \ge \Delta_0$ and $\lambda\ge \lambda_0$ satisfying  $\lambda \Delta^2\ge Y$, for all $D\subset \Z$ finite  we have  \be \sup_{z\in\mathds{H}_q} \E_D\set{\norm{ P_-^AR^{D}_{z}P_+^B}^s}\le C_q\abs{D}^{C^\pr_q}    \e^{-c_q\dist_D\pa{A,\La \setminus B}},       \ee for all  $A\subset B\subset D$ with    $A$ connected in $D$. ({\cite[Theorem 2.4]{EK22}  is stated and proved  for real energies in the  intervals $(-\infty, k+\tfrac 3 4]$,   where $k\in \N^0$. The  proof  is also valid for complex energies $z$ with  $ \Rea z  \le (k+\tfrac 3 4)\nfd$, with the same constants.  The above result follows.)}    Given     $\x, \y \in \cP_+ (D)$  with $\abs{\x}=\abs{\y}$, and letting  $r=d_H^D ({\bf x},{\bf y})$,  then either $r=d_D (x, \y)$   for some $x \in \x$, or  $r=d_D (y, \x)$   for some $y \in \y$.  Both cases being similar, we assume the former. In this case, using \eq{eq:Txy} and  \eq{piu}, we have \be \abs{G^{D}_{z}({\bf x},{\bf y})}= \norm{\pi_{\x} R_z^D \pi_{\y}}\le  \norm{ \cN_x R_z^D  P_+^{[x]^D_{r-1}}}, \ee and hence \eqref{eq:FVC56} follows from  \eqref{eq:oldp4589}  as      $d_D\pa{\set{x},\La \setminus {[x]^D_{r-1}}}\ge  r$.",2502.01831
proof,"We use the following resolvent identity:  \be R_{z}^{\Lambda}=\what  R^{\Lambda}_{q,z}+ \clq\tfd R^{\Lambda}_{z} \what Q^\Lambda_{\le \clq}\what  R^{\Lambda}_{q,z}=\what  R^{\Lambda}_{q,z}+ \clq \tfd\what  R^{\Lambda}_{q,z}\what Q^\Lambda_{\le \clq}  R^{\Lambda}_{z}. \ee \sout{Using} Applying it twice, we get   \be R_{z}^{\Lambda}=\what  R^{\Lambda}_{q,z}+ \clq\tfd\what  R^{\Lambda}_{q,z} \what Q^\Lambda_{\le \clq} \what  R^{\Lambda}_{q,z}+\clq^2\tfd^2\what  R^{\Lambda}_{q,z}\what Q^\Lambda_{\le \clq}   R^{\Lambda}_{z} \what Q^\Lambda_{\le \clq}\what  R^{\Lambda}_{q,z}. \ee    Suppose now  that \eqref{eq:weakinf} holds for all  ${\bf u},{\bf v}\in \cP_{N,\cl{q}}(\La)$.   Then,   using  also \eqref{eq:resmod'1} and   \eqref{eq:CTk}, we can bound \be  \sup_{z\in\mathds{H}_q}\sup_{\La\subset \Z}\E_\La\set{\abs{G^{ \La}_{z}({\bf x},{\bf y})}^s}&  \le C_q  \e^{-c_q\abs{{\bf x}-{\bf y}}_1}+C_q\sum_{{\bf u}\in \cP_{N,\cl{q}}(\La)}\e^{-c_q\abs{{\bf x}-{\bf u}}_1}\e^{-c_q\abs{{\bf u}-{\bf y}}_1}\\& \quad  \quad +C_q  \sum_{{\bf u},{\bf v}\in \cP_{N,\cl{q}}(\La)}\e^{-c_q\abs{{\bf x}-{\bf u}}_1}\e^{-c_qd^\La_H\pa{{\bf u},{\bf v}}}\e^{-c_q\abs{{\bf v}-{\bf y}}_1}\\ &\le  C_q    e^{-c_qd^\La_H\pa{{\bf x},{\bf y}}}, \ee  where in the last step we used  properties of exponential sums, see \eqref{eq:d1bn43} below.",2502.01831
proof,"[Proof of  Theorem \ref{cor:weakinf}]    We take  $q\in \frac 12 \N^0$, and assume     that \eq{eq:FVC} holds for  all finite $D\subset \Z$.   Given $\La \subset \Z$,  in view of \eq{fxy0} we only have to prove  \eq{eq:weakinf}   for   ${\bf x},{\bf y}\in \cP_+ (\La)$  with  $\abs{\x}=\abs{\y}$.      The proof will proceed by induction on  $q\in \frac 12 \N^0$.   For $q=0,\frac 12$, the theorem  (i.e.,  \eq{eq:weakinf}) follows from the Combes Thomas bound \eq{eq:CT}.  Given $q\in \frac 12 \N^0$, $q\ge 1$, we l  assume the theorem holds  for  $q-\frac 12$,   and will  prove it then holds for $q$.     The proof proceeds by a series of Lemmas. In view of Lemma~\ref{lemweakstrong},   it suffices to prove  \eqref{eq:weakinf}  for all  ${\bf x},{\bf y}\in \cP_{N,\cl{q}}(\La)$.     Let $D\subset \Z$ be finite, let $N\in \N$,  and assume \be   \sup_{z\in\mathds{H}_{ q}}\E_D \set{\abs{G^{D}_{z}({\bf x},{\bf y})}^s}\le  C_q \e^{-c_{q}   d_H^D ({\bf x},{\bf y})} \mqtx{for all}\x,\y\in \cP_{N,\cl{q}}(D). \ee  Then         \be  \E_{D}\set{\cQ_q^D ({\bf x},{\bf y})}\le  C_q e^{-c_q d_{H}^D({\bf x},{\bf y})} \ \mqtx{for all}\x,\y\in \cP_{N}(D). \ee         Let $D\subset \Z$ finite, $N\in \N$, and $\x,\y\in \cP_{N}$. We  assume that there is $x\in {\bf x}$ such that   \be   \dist_D (x, {\bf y})= d^D_{H}({\bf x}, {\bf y}),  \ee    the other case being similar.    We first prove the lemma for $\x,\y\in \cP_{N,\cl{q}}(D)$. This is done using the reduction to  resolvents  achieved by using   the estimate \cite[Eq. (7.44)]{AW} and the spectral averaging as in {\cite[Theorem 4.5]{AW2}}.  The final result can be re-formulated in our setting as:    \emph{Let $r\in(0, 1)$, $N\in \N$, and  let $I\subset \R$ be an interval.   Then for all finite $D \subset \Z$ and    ${\bf x},{\bf y}\in \cP_N(D)$  we  have   \be  \E_{D}\set{\cQ_I^D({\bf x},{\bf y})}\le C_r\sum_{{\bf u}\in \cP_N(D): x\in {\bf u}} \int_I \E_{D}\set{\abs{G_E^D ({\bf u},{\bf y})}^r}dE  \qtx{for any} x\in {\bf x}.   \ee}     Note that that  $d^D_{H}({\bf u}, {\bf y})\ge d^D_{H}({\bf x}, {\bf y})$  if $x\in \u \subset D$.   Given $\x,\y\in \cP_{N,\cl{q}}$,  we estimate $\E_{D}\set{\cQ_q^D({\bf x},{\bf y})}$ by  \eqref{eq:eigencorwea}, and estimate the term  $\E_{D}\set{\abs{G_E^D ({\bf u},{\bf y})}^s}$ inside the integral as in \eqref{eq:genco}, using \eq{eq:weakinf46} ,  getting \be  \E_{D}\set{\cQ_q^D({\bf x},{\bf y})}&\le C_q \sum_{{\bf u}\in \cP_N(D): x\in {\bf u}}\e^{-c_q\abs{{\bf u}-{\bf y}}_1}+C_q  \sum_{{\bf u}\in \cP_N(D): x\in {\bf u}}\ \sum_{{\bf v}\in \cP_{N,\cl{q}}(D)}\e^{-c_q\abs{{\bf u}-{\bf v}}_1}\e^{-c_q\abs{{\bf v}-{\bf y}}_1}\\& \quad  \quad +C_q\sum_{{\bf u}\in \cP_N(D): x\in {\bf u}}\ \sum_{{\bf v},{\bf w}\in \cP_{N,\cl{q}}(D)}\e^{-c_q\abs{{\bf u}-{\bf v}}_1}\e^{-c_qd^D_H\pa{{\bf v},{\bf w}}}\e^{-c_q\abs{{\bf w}-{\bf y}}_1}. \ee    To bound the first sum, we note that  \be \abs{{\bf u}-{\bf y}}_1\ge d_H({{\bf u},{\bf y}})\ge  \dist_D (x, {\bf y})=d_{H}^D({\bf x}, {\bf y}), \ee using \eqref{defHD}. Hence  \be \sum_{{\bf u}\in \cP_N(D): x\in {\bf u}}\e^{-c_q\abs{{\bf u}-{\bf y}}_1} \le \e^{-\frac {c_q}2d_{H}^D({\bf x}, {\bf y})}\sum_{{\bf u}\in \cP_N(D)} \e^{-\frac {c_q}2\abs{{\bf u}-{\bf y}}_1}   \le   C_{q} \e^{-\frac  {c_q} 2d_{H}^D({\bf x}, {\bf y})}, \ee  where in the last step we used \eqref{eq:d1bn}  and $\y\in \cP_{N,\cl{q}}(D)$.    To estimate the second sum in \eqref{eq:smva}, we use  the triangle inequality to conclude that  \be \abs{{\bf u}-{\bf v}}_1+\abs{{\bf v}-{\bf y}}_1&\ge \abs{{\bf u}-{\bf y}}_1\ge d_{H}^D({\bf x},{\bf y}),\\ \abs{{\bf u}-{\bf v}}_1+\abs{{\bf v}-{\bf y}}_1&\ge \tfrac12\pa{\abs{{\bf u}-{\bf y}}_1+\abs{{\bf v}-{\bf y}}_1}. \ee Hence \be & \sum_{{\bf u}\in \cP_N(D): x\in {\bf u}}\ \sum_{{\bf v}\in \cP_{N,\cl{q}}(D)}\e^{-c_q\abs{{\bf u}-{\bf v}}_1}\e^{-c_q\abs{{\bf v}-{\bf y}}_1}\\  & \quad \le \e^{-\frac {c_q}2d_{H}^D(({\bf x},{\bf y})} \sum_{{\bf u}\in \cP_N(D)}\sum_{{\bf v}\in \cP_{N,\cl{q}}(D)}\e^{-\frac {c_q}4\abs{{\bf u}-{\fg {\bf y}}}_1}e^{-\frac {c_q}2\abs{{\bf v}-{\bf y}}_1}\  \le  C_qe^{-\frac {c_q}2 d_{H}^D({\bf x}, {\bf y})}, \ee using   $\y\in \cP_{N,\cl{q}}(D)$  and \eqref{eq:d1bn}  twice in the last step.  Finally, to estimate the last sum in \eqref{eq:smva}, we use  the triangle inequality  and \eq{defHD32} to conclude that  \be &\abs{{\bf u}-{\bf v}}_1+d_H^D\pa{{\bf v},{\bf w}}+\abs{{\bf w}-{\bf y}}_1\ge d_{H}^D({\bf x},{\bf y}),\\ &\abs{{\bf u}-{\bf v}}_1+d_H^D\pa{{\bf v},{\bf w}}+\abs{{\bf w}-{\bf y}}_1\ge\abs{{\bf u}-{\bf v}}_1+ \frac12\pa{d_H^D\pa{{\bf v},{\bf y}}+\abs{{\bf w}-{\bf y}}_1}. \ee Hence \be & \sum_{{\bf u}\in \cP_N(D): x\in {\bf u}}\ \sum_{{\bf v},{\bf w}\in \cP_{N,\cl{q}}(D)}\e^{-c_q\abs{{\bf u}-{\bf v}}_1}\e^{-c_qd^D_H\pa{{\bf v},{\bf w}}}\e^{-c_q\abs{{\bf w}-{\bf y}}_1}\\  & \qquad \le e^{-\frac  {c_q}2d_{H}^D({\bf x}, {\bf y})}\sum_{{\bf u}\in \cP_N(D):}\ \sum_{{\bf v},{\bf w}\in \cP_{N,\cl{q}}(D)}e^{-\frac  {c_q}2\abs{{\bf u}-{\bf v}}_1}e^{-\frac  {c_q}4d_H^D\pa{{\bf v},{\bf w}}}e^{-\frac {c_q}4\abs{{\bf w}-{\bf y}}_1}\\ \\& \qquad \le C_q N^{2\cl{q}}e^{-\frac  {c_q}2d_{H}^D({\bf x}, {\bf y})}, \ee using $\y\in \cP_{N,\cl{q}}$,   \eqref{eq:dhbn} and \eqref{eq:d1bn}  in the last step.     Putting together \eqref{eq:smva}, \eqref{eq:smva2}, \eqref{eq:smva3}, and  \eqref{eq:smva4} , we get \be  \E_{D}\set{\cQ_q^D ({\bf x},{\bf y})}\le  C_q N^{2\cl{q}}\e^{-c_q d_{H}^D({\bf x},{\bf y})}  \mqtx{for all}\x,\y\in \cP_{N,\clq}(D). \ee    To remove the $N$ dependence in \eqref{eq:smva5}, we will show \be \E_{D}\set{\cQ_q^D({\bf x},{\bf y})}\le C_q \e^{-c_q N}\mqtx{for all}\x,\y\in \cP_{N,\clq}(D), \ee using  a large deviation estimate.   Let $\bar{\mu}= \E \set{\omega_0}$, and assume $N \lambda \bar{\mu} > 2 \clq\tfd$.  Then the standard large deviations estimate (recall \eqref{bD2}) gives \be \P\set{  \lambda V_\omega ({\bf u})< \clq \tfd}\le \P\set{V_\omega ({\bf u})< N \tfrac {\bar{\mu}} 2}\le \e^{- c_\mu N}\sqtx{for all} {\bf u}\in \cP_{N,\clq}(\Z). \ee Thus,  for any $N\in \N$,   letting $S=[{\bf x}]^D_N$, and defining the event \be \cE^S_N= \set{ \lambda  V_\omega ({\bf u})< {\clq\tfd} \sqtx{for some} {\bf u} \in  \cP_{N,\cl{q}}(S)}, \ee  we have      \P\set{\cE^S_N} \le  C_{\mu,q}  \abs{\cP_{N,\cl{q}}(S)} \e^{- c_\mu N} \le C_{\mu,q} \clq \pa{N(2N+1)}^{2\clq } \e^{- c_\mu N} \le C_{\mu,q}^\pr \e^{- c_{\mu,q}^\pr N},      where we used $\abs{\cP_{N,\cl{q}}(S)}=\tr Q_{\le k}^{S}$, \eq{trXk}, and $\abs{S}\le N (2N+1)$.   Moreover,   on the  complimentary event   $\pa{\cE_N^S}^c $ we have     \be \chi_N(\mathcal N^S)H^S\ge (\clq+1)\tfd\chi_N(\mathcal N^S) ,   \ee   so we can use \cite[Proposition 4.1]{EKS1} to obtain  the Combes-Thomas bound  \be \sup_{z\in \mathds{H}_{\clq}}\abs{ G^S_{z}({\bf x},{\bf y})}\le C_q e^{-c_q\abs{{\bf x}-{\bf y}}_1} \qtx{for all} \x,\y\in \cP_{N,\cl{q}}(S). \ee   To show \eqref{eq:almost1}, we start by observing that for  $\nu \in \sigma_q (H^D)$ we have  \be \pi_{_\nu}\phi_{\bf x}=\pi_{\nu}\pa{H^{S,S^c}-\nu}R_\nu^{S,S^c}\phi_{\bf x}=\pi_{\nu}\Gamma^S R_\nu^{S,S^c}\phi_{\bf x}. \ee By the construction of $S$ we have \be R_\nu^{S,S^c}\phi_{\bf x}=P_+^{S^c}R_\nu^{S}\phi_{\bf x}. \ee It follows that on the  complimentary event   $\pa{\cE_N^S}^c $ we have \be \sum_{\nu\in\sigma_q(H^D)} \abs{\langle\phi_{\bf y},\pi_{\nu}\phi_{\bf x}\rangle}&\le \sum_{\nu\in\sigma_q(H^D)}\sum_{{\bf u}\in\cP_N^{\partial_{ex}}(D)}\abs{\langle \phi_{\bf y},\pi_{\nu}\phi_{\bf u}\rangle}\abs{\langle \phi_{\bf u},\Gamma^S R_\nu^{S}\phi_{\bf x}\rangle}\\ &\le C_q\sum_{\nu\in\sigma_q(H^D)}\sum_{{\bf u}\in\cP_N^{\partial_{ex}}(D)}e^{-c_q\abs{{\bf u}-{\bf x}}_1}\abs{\langle \phi_{\bf y},\pi_{\nu}\phi_{\bf u}\rangle},  \ee where we used \eq{eq:CTkS}, and   \be \cP_N^{\partial_{ex}}(D)=\cP_N(D, \partial_{ex}^\La D) = \set{{\bf u}\in\cP_N(D), {\bf u}\cap\partial_{ex}^D S\neq\emptyset}. \ee        We next observe that by the Cauchy-Schwarz inequality, \be \pa{\sum_{\nu\in\sigma_q (H^D)}\abs{\langle \phi_{\bf y},\pi_{\nu}\phi_{\bf u}\rangle}}^2 &\le \sum_{\nu\in\sigma_q (H^D)}\langle \phi_{\bf y},\pi_{\nu}\phi_{\bf y}\rangle\,\sum_{\nu\in\sigma_q (H^D)}\langle \phi_{\bf u},\pi_{\nu}\phi_{\bf u}\rangle\\ &= \langle \phi_{\bf y},\chi_{I_{q}}(H^D)\phi_{\bf y}\rangle\, \langle \phi_{\bf u},\chi_{I_{q}}(H^D)\phi_{\bf u}\rangle\le 1. \ee Plugging this into \eqref{eq:alm}, we see that \be \sum_{\nu\in\sigma_q (H^D) }\abs{\langle\phi_{\bf y},\pi_{\nu}\phi_{\bf x}\rangle}\le C_q\sum_{{\bf u}\in\Psi_N}e^{-c_q \abs{{\bf u}-{\bf x}}_1}. \ee  Since for any ${\bf u}\in\cP_N^{\partial_{ex}}(D)$ we have  $\abs{{\bf u}-{\bf x}}_1\ge N$,  we deduce from \eqref{eq:almo}  and \eqref{eq:d1bn} (recall $\y \in \cP_{N,\clq}(D)$), that on $ \cE_N^c$ we have  \be \cQ_q^D ({\bf x},{\bf y})=\sum_{\nu\in\sigma_q (H^D)}\abs{\langle\phi_{\bf y},\pi_{\nu}\phi_{\bf x}\rangle}\le C_q \e^{-c_qN}. \ee Hence \be \E_D\set{\cQ_q^D ({\bf x},{\bf y})}&=\E_D\set{\chi_{\cE^S_N}\cQ_q^D ({\bf x},{\bf y})}+\E_D\set{\chi_{\pa{\cE_N^S}^c }\cQ_q^D ({\bf x},{\bf y})}  \\&\le \P\pa{\cE_N^S}+C_q\e^{-c_q N}\le C_qe^{-c_qN}, \ee where we have used \eq{PV<} and  \eqref{eq:almost}. The relation \eqref{eq:almost1} follows.  Using \eq{eq:smva5} for   $ d_{H}^D({\bf x},{\bf y})   \ge N$ and  \eqref{eq:almost1} for $ d_{H}^D({\bf x},{\bf y})   <N$ we get \be  \E_{D}\set{\cQ_q^D ({\bf x},{\bf y})}\le  C_q\e^{-c_q d_{H}^D({\bf x},{\bf y})}  \mqtx{for all}\x,\y\in \cP_{N,\clq}(D). \ee    We now consider the general case $\x,\y\in \cP_N(D)$.  For any $\nu \in \sigma_{\clq}  (D)$, using  \eq{eigest}, we have \be \pi_\nu^D (\x,\y)= C_q  \sum_{\u,\v \in \cP_{N,\clq}(D)}    \what G_{\clq,\nu}(\x,\u) \pi_\nu^D (\u,\v){\what G}_{\clq,\nu}(\v,\y) \ee It follows that \be \cQ^D(\x,\y) &\le \sum_{\u,\v \in \cP_{N,\clq}(D)} \abs{ \what G_{\clq,\nu}(\x,\u) }\cQ^D (\u,\v)\abs{  \what G_{\clq,\nu}(\v,\y)}\\ &  \le C_q \sum_{\u,\v \in \cP_{N,\clq}(D)}  \e^{-c_q\abs{\x-\u}_1}\cQ^D (\u,\v) \e^{-c_q\abs{\v-\y}_1}, \ee where we used \eqref{eq:CTk}.  Using \eq{eq:smva79}, we conclude that \be \E_D\set{\cQ^D(\x,\y} &\le C_q  N^{2\clq} \sum_{\u,\v \in \cP_{N,\clq}(D)}  \e^{-c_q\abs{\x-\u}_1}\e^{- c_q d_H^D(\u,\v) } \e^{-c_q\abs{\v-\y}_1}\\ & \le  C_q  \e^{- c^\pr_q d_H^D(\x,\y)} \sum_{\u,\v \in \cP_{N,\clq}(D)}  \e^{-c^\pr_q\abs{\x-\u}_1}\e^{-c^\pr_q\abs{\v-\y}_1} \\ & \le  C_q \e^{- c_q d_H^D(\x,\y)} , \ee   where we used  \eq{eq:d1bn43} twice. The Lemma is proven.",2502.01831
proof,"Let $D \subset \La$ be  finite and connected, and let $\x,\y\in \cP_{N,\cl{q}}(\La)$,    with  $ (\x\cup \y)_D \neq\emptyset$ and $(\x\cup \y)_{D^c}\neq\emptyset$.   We only  need  to consider the case  $1\le \abs{\x _ D}= \abs{\y_D}\le N-1  $, as otherwise $G^{D,D^c}_{z}({\bf x},{\bf y})=0$.  To do so, given  $a\in\R$,  let $F_{a}$ be the  analytic  function on $\R$ given by   \be    F_{\xi,a} (x)&= \frac{1-\e^{-\xi x^2}}{x-ia} \qtx{for} x \in \R \qtx{if} a\ne 0,\\     F_{\xi,0} (x)&= \frac{1-\e^{-\xi x^2}}{x} \qtx{for} x \in  \R\setminus \set{0} \qtx{and} F_{\xi,0} (0)=0.    \ee  Given $z\in\mathds{H}_q$, let $E=\Rea z$ and $a=\Ima z$.   Setting $r= d_H^\La \pa{{\bf x},{\bf y}}-1$, and taking $F_a (x)=  F_{\xi,a} (x)$ with  $ \xi= \frac {\Delta^2}{200}  r$, we have the following bound (recall \eqref{eq:Txy}):   \be & \abs{G^{D,D^c}_{z}({\bf x},{\bf y})}\le \abs{\pa{R^{D,D^c}_{z}P_{I_{\le q-\frac12}}(H^{D})}({\bf x},{\bf y})}+\abs{\pa{R^{D,D^c}_{z}\bar P_{I_{\le q-\frac12}}(H^{D})}({\bf x},{\bf y})}\\ &  \quad \le \abs{\pa{R^{D,D^c}_{z}P_{I_{\le q-\frac12}}(H^{D})}({\bf x},{\bf y})}+   \abs{\pa{F_{a}(H^{D,D^c}-E)\bar P_{I_{\le q-\frac12}}(H^{D})}({\bf x},{\bf y})}\\ &\hspace{2cm}  + \abs{\pa{R_z^{D,D^c}\exp\pa{-r(H^{D,D^c}-E)^2}P_{I_{\le q+\frac12}}(H^{D,D^c})\bar P_{I_{\le q-\frac12}}(H^{D})}({\bf x},{\bf y})}\\ &\hspace{2cm} + \abs{\pa{R_z^{D,D^c}\exp\pa{-r(H^{D,D^c}-E)^2}\bar P_{I_{\le q+\frac12}}(H^{D,D^c})\bar P_{I_{\le q-\frac12}}(H^{D})}({\bf x},{\bf y})}. \ee   Since  $z\in\mathds{H}_q$, we have  \be &\abs{\pa{R_z^{D,D^c}\exp\pa{-r(H^{D,D^c}-E)^2}\bar P_{I_{\le q+\frac12}}(H^{D,D^c})\bar P_{I_{\le q-\frac12}}(H^{D})}({\bf x},{\bf y})}\\ & \qquad  \le \norm{{R_z^{D,D^c}\exp\pa{-r(H^{D,D^c}-E)^2}\bar P_{I_{\le q+\frac12}}(H^{D,D^c})}} \le 2 \e^{-\frac r 4 }. \ee  Moreover, since  $ \abs{\x_{D^c}}= \abs{\y _{D^c}}\ge 1 $, we have $P_{I_{\le q+\frac12}}(H^{D,D^c})\bar P_{I_{\le q-\frac12}}(H^{D})=0$. Since  \be & \abs{\pa{F_{a}(H^{D,D^c}-E)\bar P_{I_{\le q-\frac12}}(H^{D})}({\bf x},{\bf y})}\\ & \qquad \le \abs{\pa{R^{D,D^c}_{z}P_{I_{\le q-\frac12}}(H^{D})}({\bf x},{\bf y})} +  \abs{\pa{F_{a}(H^{D,D^c}-E) P_{I_{\le q-\frac12}}(H^{D})}({\bf x},{\bf y})},  \ee  we obtain the estimate \be &\abs{G^{D,D^c}_{z}({\bf x},{\bf y})}\le \abs{\pa{R^{D,D^c}_{z}P_{I_{\le q-\frac12}}(H^{D})}({\bf x},{\bf y})} +     \abs{\pa{F_{a}(H^{D,D^c}-E)}({\bf x},{\bf y})}\\ &\hskip60pt  + \abs{\pa{F_{a}(H^{D,D^c}-E) P_{I_{\le q-\frac12}}(H^{D})}({\bf x},{\bf y})}+  2 \e^{-\frac r 4 }\\ &\hskip20pt \le \abs{\pa{R^{D,D^c}_{z}P_{I_{\le q-\frac12}}(H^{D})}({\bf x},{\bf y})} +  \abs{\pa{F_{a}(H^{D,D^c}-E) P_{I_{\le q-\frac12}}(H^{D})}({\bf x},{\bf y})}   \\&\hskip60pt  +C\pa{\e^{-\frac r 2} +\e^{-\frac r 4 }}, \ee  where we used  \eqref{locest2} to get the last inequality.     We first estimate the second term in  the last line of \eq{eq:decena}. Given $\nu \in \sigma_{q-\frac12}(H^D)$, we get, using \eq{eigest}, \be &\abs{\pa{F_{a}(H^{D,D^c}-E-\nu)\pi_{\nu}^D}(\x,\y)}\\ &\hspace{20pt}=\lceil q-\tfrac12\rceil\tfd  \abs{\pa{F_{a}(H^{D,D^c}-E-\nu) \what  R^{D}_{q-\frac12,\nu}\what Q^D_{\le \lceil  q-\frac12 \rceil} \pi_{\nu}^D}(\x,\y)} \\ &\hspace{20pt}\le q\sum_{{\u_D}\in \cP_{N_D}(D)}\sum_{{\v_D}\in\cP_{{N_D},\lceil q-\frac12\rceil}(D)}\abs{F_{a}(H^{D,D^c}-E-\nu)({\bf x},\u_D \cup\y_{D^c})}\\&\hspace{7cm}\times\abs{\what  G^{D}_{ q-\frac12,\nu}(\u_D,\v_D)}\abs{\pi^D_{\nu}(\v_D,\y_D)}\\& \hspace{20pt}\le C_q\sum_{{\u_D}\in \cP_{N_D}(D)}\sum_{{\v_D}\in\cP_{{N_D},\lceil q-\frac12\rceil}(D)} \e^{-c d_H^{  \La } \pa{{\bf x},\u_D \cup\y_{D^c}}}\e^{-c_{q-\frac 1 2}\abs{{\u_D}-{\v_D}}_1}\abs{\pi^D_{\nu}(\v_D,\y_D)}, \ee where we used   \eqref{eq:CTk} and \eqref{locest2} for the last  inequality  and   $N_D= \abs{\x_D}$.   It follows that  \be &\abs{\pa{F_{a}(H^{D,D^c}-E)P_{I_{\le q-\frac12}}(H^{D})}({\bf x},{\bf y})}\\ & \hspace{20pt} \le   C_q {\sum_{{\u_D}\in \cP_{N_D}(D)}\sum_{{\v_D}\in\cP_{{N_D},\lceil q-\frac12\rceil}(D)} \e^{-c d_H^{  \La } {({\bf x},\u_D \cup\y_{D^c})}}\e^{-c_{q-\frac 1 2}\abs{{\u_D}-{\v_D}}_1}}\\&\hspace{6cm}\times\sum_{\nu \in \sigma_{q-\frac12}(H^D)}\abs{\pi^D_{\nu}(\v_D,\y_D)}\\ & \hspace{20pt}  \le   C_q {\sum_{{\u_D}\in \cP_{N_D}(D)}\sum_{{\v_D}\in\cP_{{N_D},\lceil q-\frac12\rceil}(D)} \e^{-c d_H^{  \La } {({\bf x},\u_D \cup\y_{D^c})}}\e^{-c_{q-\frac 1 2}\abs{{\u_D}-{\v_D}}_1}} \cQ^D_{q-\frac 12}(\v_D,\y_D). \ee    We have \be d_H^{  \La } ({\bf x},\u_D \cup\y_{D^c}) +\abs{{\u_D}-{\v_D}}_1+d_H^D (\v_D,\y_D)  \ge d_H^{  \La }(\x,\y), \ee since \be d_H^D (\u_D,\y_D) =   d_H^\La (\u_D \cup\y_{D^c}, \y_D \cup \y_{D^c})=  d_H^\La (\u_D \cup\y_{D^c}, \y) , \ee and hence \be &d_H^{  \La } ({\bf x},\u_D \cup\y_{D^c} )+\abs{{\u_D}-{\v_D}}_1+d_H^D (\v_D \cup \y_D)  \ge d_H^{  \La } ({\bf x},\u_D \cup\y_{D^c} ) + d_H^D (\u_D,\y_D)\\ & \quad =  d_H^{  \La } ({\bf x},\u_D \cup\y_{D^c} ) +   d_H^\La (\u_D \cup\y_{D^c}, \y) \ge    d_H^{  \La }(\x,\y), \ee   Taking expectations in \eq{FHDDEP}, using  Lemma \ref{thm:eigencorweak} for $q-\frac 12$ (the hypotheses of the  Lemma  are satisfied for $q-\frac 12$ by the induction hypothesis), and using \eq{dHxyu}, we obtain the bound \be  &\E_\La \set{\abs{\pa{F_{a}(H^{D,D^c}-E) P_{I_{\le q-\frac12}}(H^{D})}({\bf x},{\bf y})}} \\& \quad  \le  C_q {\sum_{{\u_D}\in \cP_{N_D}(D)}\sum_{{\v_D}\in\cP_{{N_D},\lceil q-\frac12\rceil}(D)} \e^{-c d_H^{  \La } {({\bf x},\u_D \cup\y_{D^c})}}\e^{-c_{q-\frac 1 2}\abs{{\u_D}-{\v_D}}_1}} \e^{-c_{q-\frac 12 } d_H^D (\v_D,\y_D)}\\ &\quad \le  C_q \e^{-c_{q-\frac 12 }  d_H^{  \La } {({\bf x},\y)}} {\sum_{{\u_D}\in \cP_{N_D}(D)}\sum_{{\v_D}\in\cP_{{N_D},\lceil q-\frac12\rceil}(D)} \e^{-c d_H^{  \La } {({\bf x},\u_D \cup\y_{D^c})}}\e^{-c_{q-\frac 1 2}\abs{{\u_D}-{\v_D}}_1}} \e^{-c_{q-\frac 12 }  d_H^D (\v_D,\y_D)}\\ &\quad \le  C_q \e^{-c_{q-\frac 12 }  d_H^{  \La } {({\bf x},\y)}} \sum_{{\v_D}\in\cP_{{N_D},\lceil q-\frac12\rceil}(D)}   \pa{\sum_{{\u_D}\in \cP_{N_D}(D)}\e^{-c_{q-\frac 1 2}\abs{{\u_D}-{\v_D}}_1}} \e^{-c_{q-\frac 12 }  d_H^D (\v_D,\y_D)}\\ &\quad \le  C_q C_{q-\frac 1 2} \e^{-c_{q-\frac 12 }  d_H^{  \La } {({\bf x},\y)}} \sum_{{\v_D}\in\cP_{{N_D},\lceil q-\frac  12\rceil}(D)}    \e^{-c_{q-\frac 12 }  d_H^D (\v_D,\y_D)}\\ &\quad \le  C_q  N_D^{2\cl{q}}  \e^{-c_{q-\frac 12 }  d_H^{  \La } {({\bf x},\y)}}\le  C_q  \abs{D}^{2\cl{q}}  \e^{-c_{q-\frac 12 }  d_H^{  \La } {({\bf x},\y)}},  \ee   where in the last two steps we used  \eq{eq:d1bn} and \eq{eq:dhbn}.  The use of the latter is justified  as $\y_D\in \cP_{{N_D},\lceil q\rceil}(D)$ since $ \y\in \cP_{{N},\lceil q\rceil}(\La)$ and $D$ is connected.      It remains to estimate the first term in \eq{eq:decena}.  We use  the decomposition   (recall that $D$ is assumed to be finite)  \be R_z^{D,D^c} =\sum_{\nu\in \sigma (H^{D})} R_{z-\nu}^{D^c}\otimes \pi_{\nu}^{D}  \qtx{on} \cH_\La= \cH_{D^c}\otimes \cH_{D}, \ee  Since $1\le \abs{\x _ D}= \abs{\y_D}\le N-1  $, we have  \be \pa{R_z^{D,D^c}P_{I_{\le q-\frac12}}(H^{D})}({\bf x},{\bf y})=\sum_{\nu \in \sigma_{q-\frac12}(H^D)} G_{z-\nu}^{D^c}({\bf x}_{D^c},{\bf y}_{D^c})\, \pi^D_{\nu}({\bf x}_D,{\bf y}_D), \ee  so \be \abs{\pa{R_z^{D,D^c}P_{I_{\le q-\frac12}}(H^{D})}({\bf x},{\bf y})}^{s}\le\sum_{\nu \in \sigma_{q-\frac12}(H^D)}\abs{G_{z-\nu}^{D^c}({\bf x}_{D^c},{\bf y}_{D^c})}^{s}  \abs{ \pi^D_{\nu}({\bf x}_D,{\bf y}_D)}^{s}. \ee   If  $z\in\mathds{H}_{q}$, we have  $z-\nu\in \mathds{H}_{\le q-\frac 12}$ for $  {\nu \in \sigma_{q-\frac12}(H^D)}$, so it follows from  the induction hypothesis that \be \sup_{\zeta \in\mathds{H}_{q- \frac 12}}\E_{D^c}\abs{G_{\zeta}^{D^c}({\bf x}_{D^c},{\bf y}_{D^c})}^{s}\le  C_{ q-\frac 12}  \e^{-c_{ q- \frac 12} d_H^{D^c} ({\bf x}_{D^c},{\bf y}_{D^c})}. \ee Thus, for  $ z\in\mathds{H}_{q}$, using also H\""older's inequality and  the deterministic estimate  \eq{trkH}.  we get   \be &\E_{D^c} \set{\abs{\pa{R_z^{D,D^c}P_{I_{\le q-\frac12}}(H^{D})}({\bf x},{\bf y})}^s}\\& \qquad  \le  C_{ q-1}\e^{-c_{ q-1} d_H^{D^c} ({\bf x}_{D^c},{\bf y}_{D^c})} \sum_{\nu \in \sigma_{q-\frac12}(H^D)}  \abs{ \pi^D_{\nu}({\bf x}_D,{\bf y}_D)}^{s}\\ & \qquad  \le  C_{ q-1}\e^{-c_{ q-1} d_H^{D^c} ({\bf x}_{D^c},{\bf y}_{D^c})}\pa{ \sum_{\nu \in \sigma_{q-\frac12}(H^D)}  \abs{ \pi^D_{\nu}({\bf x}_D,{\bf y}_D)}}^{s}\pa{\tr \chi_{I_{ q-\frac 12}}(H^D)}^{1-s}\\ & \qquad  = C_{ q-1}\e^{-c_{ q-1} d_H^{D^c} ({\bf x}_{D^c},{\bf y}_{D^c})}\pa{\tr \chi_{I_{ q-\frac 12}}(H^D)}^{1-s}\cQ^D_{q-\frac12}({\bf x}_D,{\bf y}_D)^s \\ & \qquad  \le C_{ q-1}\pa{{ \cl{q-\tfrac 12} \abs{D}^{2\cl{q-\tfrac 12}} +1}}^{1-s}\e^{-c_{ q-1} d_H^{D^c} ({\bf x}_{D^c},{\bf y}_{D^c})}\cQ^D_{q-\frac12}({\bf x}_D,{\bf y}_D)^s \\ & \qquad  \le C_{ q} \abs{D}^{2(1-s)\cl{q-\tfrac 12}} \e^{-c_{ q-1} d_H^{D^c} ({\bf x}_{D^c},{\bf y}_{D^c})}\cQ^D_{q-\frac12}({\bf x}_D,{\bf y}_D)^s . \ee    It follows from H\""older's inequality, the induction hypothesis, and  Lemma \ref{thm:eigencorweak} for $q-\frac 12$ that \be \E_D \set{\pa{ \cQ^D_{q-\frac12}({\bf x}_D,{\bf y}_D)}^s}& \le\pa{  \E_D \set{ \cQ^D_{q-\frac12}({\bf x}_D,{\bf y}_D)}}^s \\   &  \le C_{q-\frac12}^s   \e^{-sc_{q-\frac12}d_H^D ({\bf x}_D,{\bf y}_D)}. \ee    Combining  \eq{CNpinu} and \eq{CNpinu3} we get \be \E_{\La} \set{\abs{\pa{R_z^{D,D^c}P_{I_{\le q-\frac12}}(H^{D})}({\bf x},{\bf y})}^s}&\le   C_{ q}{\abs{D}}^{2\cl{q-\frac12}}\e^{-s c_{q-\frac12} \pa{ d_H^{D^c} ({\bf x}_{D^c},{\bf y}_{D^c})+d_H^D ({\bf x}_D,{\bf y}_D)} }\\ & \le    C_{ q}{\abs{D}}^{2\cl{q-\frac12}} \e^{-sc_{q-\frac12} { d_H^\La ({\bf x},{\bf y})} }, \ee where we used  \be d_H^\La ({\bf x},{\bf y}) \le \max \pa{d_H^D ({\bf x}_D,{\bf y}_D),d_H^{D^c} ({\bf x}_{D^c},{\bf y}_{D^c})}. \ee   It now follows from \eq{eq:decena}, \eq{FPxy}, and \eq{CNpinu98} that, incorporating $s$ into the constants, that \be E_\La\set{ \abs{G^{D,D^c}_{z}({\bf x},{\bf y})}^s} \le  C_{ q}\abs{D}^{2\cl{q}} \e^{-c_{q-\frac12} { d_H^\La ({\bf x},{\bf y})} }, \ee and the lemma is proved.",2502.01831
proof,"Fix  $z\in\mathds{H}_q$ and $\x,\y\in \cP_{N,\cl{q}}(\La)$. We assume $d_H^\La ({\bf x},{\bf y})=  d_\La (x, {\bf y})$ for some $x\in \x$, with the other case being similar.     We first assume $d_H^\La ({\bf x},{\bf y})>6\cl{q}N$.    In this case, we claim there exists $ r <d_H^\La ({\bf x},{\bf y})$, such that, setting   $D=[x]^\La_r $,   we have   \be  d_\La (\x, \partial^\La D )\ge  \tfrac 1 {6\cl{q}} d_H^\La(\x,\y)-1 \qtx{and} d_\La (\y, \partial^\La D)\ge  \tfrac 1 {6\cl{q}} d_H^\La(\x,\y)-1.   \ee Note that it follows that  $ \x_D \ne \emptyset$ and $\y_D=\emptyset$, which implies  $G_z^{D,D^c} ({\bf x},{\bf y})=0$.    The claim can be proven as follows. If $\cl{q}=1$,  or if $\x$ consists of one cluster, simply take $r= 3N$.  If  $\cl{q}\ge 2$, and   $\x$ consists of  $p$ clusters  where $2\le p \le \cl{q}$,  we must have  $N\ge 2$. let  $b=\fl{\tfrac 1 {6\cl{q}}  d_\La (x, {\bf y})}>N-1$, and set   \be  S_1=  [x]^\La_{b} \qtx{and} S_j=  [x]^\La_{jb}\setminus  [x]^\La_{(j-1) b } \sqtx{for} \quad j=2,3,,\ldots 6\cl{q}.  \ee  Since $\x\in \cP_{N,\cl{q}}(\La)$, $\x$ has at most $\cl{q}$ clusters of length $\le N-1$, so a cluster  can intersect at most two of the $S_{j}$'s (as $ b> N-1$), hence $\x $ can intersect at most $2\cl{q}$ of the $S_{j}$,  $j=2,3,\ldots 6\cl{q}$. It follows that there exists    ${j}_* \in \set{2,3,\ldots 6\cl{q}-2}$ such that   \be  \x\cap \pa{S_{{j}_*}\cup S_{{j}_*+1}}=\emptyset,  \ee   Setting $r= {{j}_*}b$, we get \eq{dLadH}.      The resolvent identity and  $G_z^{D,D^c} ({\bf x},{\bf y})=0$ give \be G_z^\La ({\bf x},{\bf y})=\pa{R_z^{D,D^c} \Gamma^D  R_z^\La }({\bf x},{\bf y}), \ee so using   \eqref{eq:resmodl} and inserting partitions of identity, we get \be &\abs{G_z^\La ({\bf x},{\bf y}) }\le C\sum_{{\bf u}\in\cP^D_N(\La)}  \abs{\what G_{z,q}^{D,D^c} ({\bf x},{\bf u})}\abs{ \pa{\Gamma^D R_z^\La} ({\bf u},{\bf y})}\\&\hspace{1cm}+C\sum_{{\bf u}\in \cP^D_N(\La)}\sum_{{\bf v}\in \cP_{N,\cl{q}}(\La)}     \abs{ G_z^{D,D^c} ({\bf x},{\bf v})} \abs{\what G_{z,q}^{D,D^c} ({\bf v},{\bf u})} \abs{ \pa{\Gamma^D R_z^\La} ({\bf u},{\bf y})} , \ee where $\cP^D_N(\La)=\set{{\bf u}\in \cP_N(\La), \  {\bf u}_{\partial^\La D}\neq\emptyset}$.    For all $\u^\pr, \v^\pr \in \cP_N(\La)$ we have \be  &   \E\set{\abs{ \pa{\Gamma^D R_z^\La } (\u^\pr, \v^\pr)}^{s^\pr}}\le C_{s^\pr}  \qtx{for all } s^\pr  \in (0,1),  \\ & \abs{\what G_{z,q}^{D,D^c} (\u^\pr, \v^\pr)} \le  C_q\e^{-c_q \abs{\u^\pr- \v^\pr}_1} , \ee where the first bound follows from \eqref {eq:weak1-1}  since  $  \Gamma^D \phi_{\u^\pr} $ can be decomposed into a linear combination of at most 4 canonical basis vectors, and   the second is just  \eqref{eq:CTk}.   We also have the inequality  \be  \E_\La\set{\abs{ G_z^{D,D^c} ({\bf x},{\bf v})}^{s}}\le C_q\abs{D}^{C_q}  \e^{-c_q d^\La_H ({\bf x},{\bf v})} \qtx{for all}  \v\in \cP_{N,\cl{q}}(\La). \ee  If ${\bf x}_{D^c}\neq\emptyset$, this inequality follows from Lemma \ref {prop:decbn}. On the other hand,  if ${\bf x}_{D^c}=\emptyset$,  $G_z^{D,D^c} ({\bf x},{\bf v})=0$  unless  ${\bf v}_{D^c}=\emptyset$, and in this case    $G_z^{D,D^c} ({\bf x},{\bf v})= G_z^{D} ({\bf x},{\bf v})$ and $d^\La_H ({\bf x},{\bf v})=d^D_H ({\bf x},{\bf v})$, and hence \eq{GDDcxv} follows from the hypothesis  \eqref{eq:FVC}. Moreover, since $0<s <2s <\frac 23$, using the Riesz-Thorin Interpolation Theorem, it follows from \eq{GDDcxv}  and  \eqref {eq:weak1-1}   (with $s^\pr=\frac 23 $)  that  \be  \E_\La\set{\abs{ G_z^{D,D^c} ({\bf x},{\bf v})}^{2s}}\le C^\pr_q {\abs{D}}^{C^\pr_q}  \e^{-c^\pr_q d^\La_H ({\bf x},{\bf v})}. \ee          It then follows from \eq{eq:par+},\eq{eq:par+2},   \eq{GDDcxv22}, and $\abs{D} \le 2r +1$, using also  H\""older's inequality  that \be \sup_{z\in\mathds{H}_q}\E_\La\set{\abs{G_z^\La ({\bf x},{\bf y})}^{{\fg s}}}&\le  C_q\sum_{{\bf u}\in \cP^D_{N}} \e^{-c_q \abs{{\bf x}-{\bf u}}_1}\\&+ C_q r^{C_q}\sum_{{\bf u}\in \cP^D_N(\La)}\sum_{{\bf v}\in\cP_{N,\cl{q}}}  \e^{-c_q d_H^\La  ({\bf x},{\bf v})} \e^{-c_q \abs{{\bf u}-{\bf v}}_1}. \ee  Since $\abs{{\bf x}-{\bf u}}_1\ge \tfrac 1 {6\cl{q}} d_H^\La(\x,\y)-1 $ for any ${\bf u}\in\cP^D_N(\La)$ by  \eq{dLadH}, we can bound \be \sum_{{\bf u}\in \cP^D_{N}}\e^{-c_q  \abs{{\bf x}-{\bf u}}_1}\le C_q e^{-\frac {c_q } {12\cl{q}} d_H^\La(\x,\y)}\sum_{{\bf u}\in \cP_{N}} \e^{-\frac {c_q} 2 \abs{{\bf x}-{\bf u}}_1} \le C_q \e^{-c_q^\pr  d_H^\La(\x,\y)}, \ee  where in the last step we used \eqref{eq:d1bn}. On the other hand, since it follows from \eq{dLadH} that  \be d_H^\La ({\bf x},{\bf v})+\abs{{\bf u}-{\bf v}}_1\ge d_H^\La ({\bf x},{\bf u})\ge   \tfrac 1 {6\cl{q}} d_H^\La(\x,\y)-1 \ee for ${\bf u}\in \cP^D_N(\La)$, we can bound     \be &\sum_{{\bf u}\in \cP^D_N(\La)}\sum_{{\bf v}\in\cP_{N,\cl{q}}}   \e^{-c_q d_H ({\bf x},{\bf v})} \e^{-c_q \abs{{\bf u}-{\bf v}}_1}\le C_q r^{C^\pr_q}\e^{-c_q^\pr  d_H^\La(\x,\y)}\sum_{{\bf u}\in \cP^D_N(\La)}\sum_{{\bf v}\in\cP_{N,\cl{q}}}  \e^{-\frac  {c_q}2 d_H ({\bf x},{\bf v})} \e^{-\frac {c_q}2 \abs{{\bf u}-{\bf v}}_1}\\& \quad  \le C_q  r^{C^\pr_q}N^{2\cl{q}}\e^{-c_q^{\prr } d_H^\La(\x,\y)} \le C_q  \pa{d_H^\La(\x,\y)}^{C_q}\e^{-c_q^{\prr } d_H^\La(\x,\y)} \le  C_q  \e^{-c_qd_H^\La(\x,\y)}, \ee using \eqref{eq:dhbn} and \eqref{eq:d1bn}.  Using these bounds in \eqref{eq:almth55} yields \eq{eq:spr} if $d_H^\La ({\bf x},{\bf y})>6\cl{q}N$.    It remains consider the case $d_H^\La ({\bf x},{\bf y})\le6\cl{q}N$.  To do so we   will prove \be  \sup_{z\in\mathds{H}_q}\E_\La\set{\abs{G^{\La}_{z}({\bf x},{\bf y})}^s}\le C_q\e^{-c_q \abs{{\bf x}-{\bf y}}_1}+C_qe^{-c_qN}\mqtx{for all}  N \in \N, \ee  which yields, for $d_H^\La ({\bf x},{\bf y})\le6\cl{q}N$, \be  \sup_{z\in\mathds{H}_q}\E_\La\set{\abs{G^{\La}_{z}({\bf x},{\bf y})}^s}\le C_q\e^{-c_q \abs{{\bf x}-{\bf y}}_1}+C_qe^{-c_qd_H^\La ({\bf x},{\bf y})}  \le C_qe^{-c_qd_H^\La ({\bf x},{\bf y})}, \ee  which is \eq{eq:spr}.  To prove \eq{eq:weakinfN} we use a large deviation argument. For $N\in \N$,   letting $S=[{\bf x}]^\La_N$, let $\cE^S_N$ be the event defined in \eq{eventENS}, so we have  \eq{PV<}, and \eq{eq:CTkS} holds  on the  complimentary event   $\pa{\cE_N^S}^c $.    For $z\in \mathds{H}_{\clq}$  we also  have, using  H\""older's inequality  and the a-priori bound \eqref{eq:weak1-1},   \be \E_{\La}\set{\chi_{\cE_N^S}\abs{ G^{\La}_{z}({\bf x},{\bf y})}^s}\le\pa{ \P\set{\chi_{\cE_N^S} }}^{\frac 12} \pa{\E_{\La}\set{\abs{ G^{\La}_{z}({\bf x},{\bf y})}^{2s}}} \le C_q e^{-c_qN}. \ee           On the  complimentary event   $\pa{\cE_N^S}^c $ we use \be G^{\La}_{z}({\bf x},{\bf y})=G^{S,S^c}_{z}({\bf x},{\bf y})-\pa{R^{\La}_{z}\Gamma R^{S,S^c}_{z}}({\bf x},{\bf y}), \ee where $\Gamma=H^\La-H^{S,S^c}$. Since $\x \subset S$, we have  $G^{S,S^c}_{z}({\bf x},{\bf y})=0$ unless ${\bf y}\subset S$, in which case $G^{S,S^c}_{z}({\bf x},{\bf y})=G^{S}_{z}({\bf x},{\bf y})$. Thus \eqref{eq:CTkS} implies that in this case we have \be \sup_{z\in \mathds{H}_q} {\abs{ G^{S,S^c}_{z}({\bf x},{\bf y})}^s}\le C_q e^{-c_q\abs{{\bf x}-{\bf y}}_1}. \ee On the other hand, setting $\cP_N^\partial(S) = \set{{\bf u}\in\cP_N(S): \ {\bf u}\cap \partial S\neq\emptyset}$,  we have, for $\omega\notin \cE_N^S$ and $z\in \mathds{H}_q$,  \be \abs{\pa{R^{\La}_{z}\Gamma R^{S,S^c}_{z}}({\bf x},{\bf y})}^s&\le \sum_{{\bf u}\in\cP_N^\partial(S)} \abs{ \pa{R^{\La}_{z}\Gamma}({\bf x},{\bf u})}^s\abs{ G^{S,S^c}_{z}({\bf u},{\bf y})}^s\\&\le C_q \sum_{{\bf u}\in\cP_N^\partial(S)} e^{-c_q\abs{{\bf u}-{\bf y}}_1}\abs{ \pa{R^{\La}_{z}\Gamma}({\bf x},{\bf u})}^s. \ee It follows, using \eq{eq:par+2}, that \be \sup_{z\in \mathds{H}_q}\E_{\La}\set{\chi_{\pa{\cE_N^S}^c}\abs{\pa{R^{\La}_{z}\Gamma R^{S,S^c}_{z}}({\bf x},{\bf y})}^s}\le C_q \sum_{{\bf u}\in\cP_N^\partial(S)} e^{-c_q\abs{{\bf u}-{\bf y}}_1}\e^{-c_q d_H^\La ({\bf x},{\bf u})}.  \ee Since ${\bf u}\in\cP_N^\partial(S)$, we have $d_H^\La ({\bf x},{\bf u})\ge N$, and hence \be \sup_{z\in \mathds{H}_q}\E_{\La}\set{\chi_{\pa{\cE_N^S}^c}\abs{\pa{R^{\La}_{z}\Gamma R^{S,S^c}_{z}}({\bf x},{\bf y})}^s}\le C_q e^{-c_q N}\sum_{{\bf u}\in\cP_N^\partial(S)} e^{-c_q\abs{{\bf u}-{\bf y}}_1}\le C_q \e^{-c_q N}, \ee where we used \eqref{eq:d1bn}  (recall $\y \in \cP_{N,\clq}(\La)$) to get the last inequality.   Combining \eq{eq:smset48}, \eq{eq:b2a}, and \eqref{eq:b1a} we get  \be \sup_{z\in \mathds{H}_q}\E_{\La}\set{\chi_{\pa{\cE_N^S}^c} \abs{G^{\La}_{z}({\bf x},{\bf y})}^s}\le  C_q e^{-c_q\abs{{\bf x}-{\bf y}}_1} + C_q \e^{-c_q N}. \ee The estimate  \eqref{eq:weakinfN}  now follows from \eq{eq:smset999}  and    \eq{eq:b35a}.",2502.01831
proof,"We will show that the theorem can be derived from \cite[Theorem 4.1]{AW2}. We start by reviewing the representation of the XXZ  quantum spin chain Hamiltonian by  a direct sum of discrete Schr\""odinger-like operators.   As discussed in Section \ref{sec:feat},  given $\La \subset \Z$, we have the the Hilbert space decomposition $ \cH_\La= \bigoplus_{N=0}^{\abs{\La}} \cH_\La\up{N}$, where   $\cH_\Lambda\up{N}=\Ran {\chi_N(\mathcal N^\Lambda)}$.  We define \be \Z\up{N} = \set{(x_1,x_2,\ldots,x_N) \in \Z^N: \  x_1 < x_2<\ldots < x_N  } \qtx{and }\La\up{N}= \La^N \cap\Z\up{N}. \ee   Since $\cH_\La\up{N}$ has the orthonormal basis $\Phi_\La\up{N}$,   identifying   $\x\in \cP_N(\La)$ with $(x_1,\ldots,x_N)\in \La\up{N}$ yields the identification of $ \cH_\La\up{N}$ with $\ell^2(\La\up{N})$.   Since  $\H^\La, \bD^\Lambda, \cW^\Lambda, V^\La_\omega$ commute with the number of particles operator $\mathcal N^\Lambda$, they leaves each $\cH_\La\up{N}$ invariant.  Let  $T_N^\La$ be the restriction of $T^\La$ to  $\cH_\La\up{N}=\ell^2(\La\up{N})$, where  $T^\La= \H^\La, \bD^\Lambda, \cW^\Lambda, V^\La_\omega$.  We still have the decomposition given in \eq{bD}: \be H_N^\La= -\tfrac 1 {2\Delta} \bD^\Lambda_N +\cW^\Lambda_N +\lambda   V^\La_{N,\omega} \qtx{acting on} \ell^2(\La\up{N}), \ee where  $\bD^\Lambda_N $  is the adjacency operator on the graph $\La\up{N}$,  $\cW^\Lambda_N$ is a deterministic bounded potential, and $V^\La_{N,\omega}$ is a random potential.  In other words, $H_N^\La$ is a random Schr\""odinger operator on $\ell^2(\La\up{N})$.    For a fixed $N\in \N$, $H_N^\La$ satisfies all the  hypothesis of the operators studied on \cite{AW2} except that it is  a Schr\""odinger operator on $\ell^2(\La\up{N})$, not  on $\ell^2(\La^N)$.  This does not affect the analysis in \cite{AW2}, and all the results of \cite{AW2} hold for $H_N^\La$ for a fixed $N$.   Given $S\subset \Z$, we define the eigencorrelator   $\cQ^S_{N,q}({\bf x},{\bf y}) $ for $H_N^\La$ similarly  as we did for $H^S$  in Section \ref{secfinvol}. The hypothesis of the theorem can then be rewritten as:   \emph{Let $q\in \frac 12 \N^0$, and suppose that for all $D\subset \Z$ finite  and all  $N\in \N$ we have  \be % \E_{D}\set{\cQ_{N,q}^D ({\bf x},{\bf y})}\le  C_q \e^{-c_q  d_{H}^D({\bf x},{\bf y})}  \qtx{for all}\x,\y\in \ell^2(D\up{N}). \ee where the constants $C_q$ and $c_q$ are independent of $N$.}  We can then apply \cite[Theorem 4.1]{AW2}  to $H_N^\La$ for all $N\in \N$. We  obtain the conclusions of  the theorem for  $H_N^\Z$ for all $N\in \N$, with the constants independent of $N$ unless explicitly  stated.  It follows that the theorem holds as stated.",2502.01831
proof,"The lemma is proven by adapting the argument of  \cite[Lemma B.2]{BeW},   who estimate the case $k=1$ of  \eqref{eq:d1bn43}.  Let $\x \in \cP_{N,k}(\Z)$, and  suppose that ${\bf x}$ has $m=m_\x$ clusters (where $m\in\set{1,\ldots,k}$). Then   ${\bf x}=(x_1, \ldots, x_N)$, where  $x_1< \ldots < x_N$, and let  $x_{j_1}< \ldots <x_{j_{2m}}$, where $j_1=1$, $j_{2m}=N$, are the end points for its $m$ clusters. (Note that  $m$ and  $j_2,,\ldots,j_{2m-1}$ are $\x$-dependent.) Given  $\y \in \cP_{N}(\Z)$  with $\y=(y_1, \ldots,y_N)$,  where  $y_1<\ldots<y_N$, we set $t_i=y_i-x_i$,  $i=1,\ldots,N$. Then the finite sequences  $\tau_{q}=(t_{j_{2q-1}},\ldots, t_{j_{2q}})$ are monotone non-decreasing for each  $q=1,\ldots,m$.   Let $\cT_{q}$ denote the collection of such monotone non-decreasing finite sequences $\tau_{q}$. Let $\cT\up{N}$ denote the collection of all monotone non-decreasing finite sequences $\tau\up{N}=(t_1,\ldots,t_N)$.     To prove \eqref{eq:d1bn43}, fix  $\y \in \cP_{N}(\Z)$.  Then each $\x \in \cP_{N,k}(\Z)$ is determined uniquely by the corresponding $\set{t_i}_{i=1}^N$, so we have   \be &\sum_{{\x}\in\cP_{N,k}(\Z)} \e^{-\alpha \abs{\x-\y}_1}=\sum_{{\x}\in\cP_{N,k}(\Z)}\prod_{q=1}^{m_\x} \e^{-\alpha \sum_{j=2q-1}^{2q} \abs{x_j-y_j}}    {\fg \le } \sum _{m=1}^k \sum_{ \tau_1\in \cT_{1}, \tau_2\in \cT_{1},\ldots, \tau_m\in\cT_{m} }     \prod_{q=1}^m \e^{-\alpha \sum_{t\in \tau_q} \abs{t}}  \\  & \le  \sum _{m=1}^k \sum_{ \tau\up{N}_1,\tau\up{N}_2,\ldots,  \tau\up{N}_m\in\cT\up{N} }     \prod_{q=1}^m \e^{-\alpha \sum_{t\in \tau\up{N}_q} \abs{t}} {\fg \le}\sum _{m=1}^k  \pa{\sum_{\tau\up{N}\in\cT\up{N}} \e^{-\alpha \sum_{t\in \tau\up{N}} \abs{t}}}^m. \ee  Given $\tau\up{N} \in \cT\up{N}$, since $\tau\up{N}$ is monotone nondecreasing   there exists an index $0\le p\le N+1$, such that   such that   $t_{j}< 0$ for $1\le  j\le  p$ and $t_{j}\ge 0$ for  $ {p}+1\le j\le  N$. (Note that sets are allowed to be empty). Thus, \be &\sum_{\tau \in \cT\up{N}} \e^{-\alpha \sum_{j=1}^{N} \abs{t_{j}}}\\ & \  = \sum_{p=0}^{N+1}\pa{\sum_{t_1\le t_2\le \ldots \le t_p\le -1} \e^{\alpha (t_1 +t_2+\ldots +t_p)}}\pa{\sum_{0\le t_{p+1}\le t_{p+2}\le \ldots \le t_{N}} \e^{-\alpha (t_{p+1}+ t_{p+2}+\ldots +t_{N})}}\\ & \ = \sum_{p=0}^{N+1} \e^{-\alpha  p}\pa{\sum_{0\le t_1\le t_2\le \ldots \le t_p} \e^{-\alpha (t_1 +t_2+\ldots +t_p)}}\pa{\sum_{0\le t_{p+1}\le t_{p+2}\le \ldots \le t_{N}} \e^{-\alpha (t_{p+1}+ t_{p+2}+\ldots +t_{N})}}\\ &  \ \le  \pa{ \sum_{p=0}^{\infty} \e^{-\alpha  p}}  \pa{  \sum_{n=0}^\infty  P(n)    \e^{-\alpha  n} }^2  =   (1-\e^{-\alpha})^{-1} \pa{ \prod_{n=1}^\infty (1- \e^{-\alpha n})^{-1}}^2=C_\alpha, \ee where $P(n) $ is the number of  integer partitions of $n$, and we used  the formula for the generating function for $P(n) $.  It follows from \eq{appA19} and \eq{appA29} that  \be \sum_{{\x}\in\cP_{N,k}(\Z)} \e^{-\alpha \abs{\x-\y}_1} \le \sum_{m=1}^k  C_\alpha^m=  \tfrac {C_\alpha^{k+1}-C_\alpha}{C_\alpha-1}\le C_\alpha^{k+1}, \ee  which yields \eq{eq:d1bn43}.        To establish \eqref{eq:d1bn}, we  modify  the above argument. We fix  $\x \in \cP_{N,k}(\Z)$, and note that every   ${\bf y} \in   \cP_{N}(\Z)$ is determined uniquely by the corresponding $\set{t_i}_{i=1}^N$, so we have  \be \sum_{{\bf y}\in\cP_{N}(\Z)} \e^{-\alpha \abs{\x-\y}_1}&=\sum_{{\bf y}\in\cP_{N}(\Z)} \prod_{q=1}^m \e^{-\alpha \sum_{j=2q-1}^{2q} \abs{x_j-y_j}} \le  \prod_{q=1}^m \sum_{\tau_q \in \cT_q} \e^{-\alpha \sum_{j=j_{2q-1}}^{j_{2q}} \abs{t_{j}}}\\ & =  \prod_{q=1}^m \sum_{\tau\up{n_q} \in \cT\up{n_q}} \e^{-\alpha \sum_{j=1}^{n_q} \abs{t_{j}}} . \ee  where    $n_q{\fg =n_q(\x)}= j_{2q}- j_{2q-1}$ for $q=1,2,\ldots,m$.      Let $n\in \N$, then  \be &\sum_{\tau \in \cT\up{n}} \e^{-\alpha \sum_{j=1}^{n} \abs{t_{j}}}\\ & \  = \sum_{p=0}^{N+1}\pa{\sum_{t_1\le t_2\le \ldots \le t_p\le -1} \e^{\alpha (t_1 +t_2+\ldots +t_p)}}\pa{\sum_{0\le t_{p+1}\le t_{p+2}\le \ldots \le t_{N}} \e^{-\alpha (t_{p+1}+ t_{p+2}+\ldots +t_{N})}}\\ & \ = \sum_{p=0}^{N+1} \e^{-\alpha  p}\pa{\sum_{0\le t_1\le t_2\le \ldots \le t_p} \e^{-\alpha (t_1 +t_2+\ldots +t_p)}}\pa{\sum_{0\le t_{p+1}\le t_{p+2}\le \ldots \le t_{N}} \e^{-\alpha (t_{p+1}+ t_{p+2}+\ldots +t_{N})}}\\ &  \ \le  \pa{ \sum_{p=0}^{\infty} \e^{-\alpha  p}}  \pa{  \sum_{n=0}^\infty  P(n)    \e^{-\alpha  n} }^2 =  C_\alpha, \ee  as in \eq{appA29}.   It follows from \eq{appA1} and \eq{appA2} that  \be \sum_{{\bf y}\in\cP_{N}(\Z)} \e^{-\alpha \abs{\x-\y}_1} \le C_\alpha^m, \ee  which yields \eq{eq:d1bn}.",2502.01831
proof,"Fix $N \in \N$ and $k\in \N$, $k\le N$. For $m \in \N$ let $\cP_N\up{m}(\Z)= \set{\x \in \cP_N(\Z), W_\x^\Z= m}$.    In addition, for $\x\in \cP_{N}(\Z)$, and  $r\in \N$ let   \be    \mathcal S_{{\bf x},r}& = \set{{\bf y}\in \cP_{N}(\Z), \ d_H({\bf x},{\bf y})=r},\quad \mathcal S_{{\bf x},r}\up{m} = \set{{\bf y}\in\cP_N\up{m}(\Z), \ d_H({\bf x},{\bf y})=r}\\  \mathcal S_{{\bf x},r,k}& =  \bigcup_{m=1}^k \mathcal S_{{\bf x},r}\up{m}.  \ee  Let now   $\x\in \cP_{N,k}(\Z)$.   We note that ${\bf y}\in\mathcal S_{{\bf x},r}$  implies ${\bf y}\subset  [{\bf x}]^\Z_r$. Since    $\abs{[{\bf x}]_r}\le N+ 2kr$, we deduce that    \be  \abs{\mathcal S_{{\bf x},r}}\le \binom{ N+ 2kr}{N}\le (N+ 2kr)^{N}.  \ee As a consequence, for ${\bf x}\in  \cP_{N,k}(\Z)$ and  $\alpha >0$, we obtain the estimate \be \sum_{{\bf y}\in \cP_{N}(\Z)}e^{-\alpha d_H({\bf x},{\bf y})}&=1+\sum_{r=1}^\infty\abs{\mathcal S_{{\bf x},r}}\e^{-\alpha r}\\ &\le 1+{\sum_{r=1}^{\lfloor N/2{k}\rfloor}(2N)^{N}\e^{-\alpha r}+  \sum^\infty_{\fl{N/2{k}}+1}}  (4{k}r+1)^{N}\e^{-\alpha r}\le C_{\alpha,k}^N N^{N+1}. \ee   We also have the  following bounds:  \be \abs{\mathcal S_{{\bf x},r}\up{m}}\le (N+2{k} r)^{2m},\quad \abs{\mathcal S_{{\bf x},r,k}}\le {   k} (N+2{k} r)^{2k}. \ee Clearly, the second bound follows immediately from the first one by summing over $m$. To obtain the first bound, we  note that ${\bf y}\in\mathcal S_{{\bf x},r}\up{m}$  implies ${\bf y}\subset  [{\bf x}]^\Z_r$,  and  hence $\y$ is completely determined by the   $2m$ points in $[{\bf x}]^\Z_r$ that are the end points for its $m$ clusters. Since    $\abs{[{\bf x}]_r}\le N+  2{k} r$, we deduce that    \be  \abs{\mathcal S_{{\bf x},r}\up{m}}\le \binom{ N+2{k} r}{2m}\le (N+2{k} r)^{2m}.  \ee        As a consequence, for ${\bf x}\in  \cP_{N,k}(\Z)$ and  $\alpha >0$, we obtain the estimate \be \sum_{{\bf y}\in \cP_{N,k}(\Z)}e^{-\alpha d_H({\bf x},{\bf y})}&=1+\sum_{r=1}^\infty\abs{\mathcal S_{{\bf x},r}}\e^{-\alpha r}\\ &\le 1+k\sum_{r=1}^{\lfloor N/2{k}\rfloor}(2N)^{2k}\e^{-\alpha r}+ k \sum^\infty_{ r=\fl{N/2{k}}+1} (4{k}r+1)^{2k}\e^{-\alpha r}\le C_{\alpha,k} N^{2k}. \ee",2502.01831
proof,"$H$ satisfies the input conditions (i) and (ii)  of  \cite[Lemma B.1]{EK22}, so its output (i.e., \eqref{eq:loca1}) is valid as well.",2502.01831
proof,"We introduce a introduce a function $F_{t,a,\eps} \in \cS(\R)$, where   $0<\eps$, given by     \be    F_{t,a,\eps} (x)&= \frac{\e^{-\eps x^2}-\e^{-t x^2}}{x-ia} \qtx{for} x \in \R \qtx{if} a\ne 0,\\     F_{t,0,\eps} (x)&= \frac{\e^{-\eps x^2}-\e^{-t x^2}}{x} \qtx{for} x \in  \R\setminus \set{0} \qtx{and} F_{t,0} (0)=0.    \ee  Let  $\hat f$ denote the Fourier transform of the function $f$.  We note that for $a>0$, the Fourier transform of $f_a(x)=\frac1{x-ia}$ exists as an $L^2$  function, and is given by $\hat f_a(\xi)=2i\pi\e^{a\xi}\chi_{(-\infty,0)}(\xi)$, whereas for $a=0$ it exists in a distributional sense, $\hat f_0(\xi)=-i\pi\sgn(\xi)$. We will only consider the more delicate case $a=0$, the argument for $a\neq0$ is very similar.    A standard calculation gives \be \hat F_{t,0,\eps}(\xi) &= \tfrac 1 {\sqrt{2\pi}}\int_{-\infty}^\infty \pa{-i \sqrt{\tfrac \pi 2} \sgn (\xi-s) }\pa{\tfrac{1}{\sqrt{2\eps}}\e^{-s^2/4\eps} -\tfrac{1}{\sqrt{2 t}}\e^{-s^2/4t} } \, \d s\\ &  = \tfrac i {2\sqrt{2}}  \pa{\int_{\xi}^{\infty} -  \int_{-\infty}^\xi } \pa{\tfrac{1}{\sqrt\eps}\e^{-s^2/4\eps} -\tfrac{1}{\sqrt t}\e^{-s^2/4t} } \, \d s. \ee    Since  $F_{t,0,\eps}\in L^1$, by the Riemann--Lebesgue Lemma we have \be 0= \lim_{\xi \to \infty} \hat F_{t,0,\eps}(\xi)= -\tfrac i {2\sqrt{2}}  \int_{-\infty}^\infty   \e^{i\lambda s}\pa{\frac{1}{\sqrt\eps}\e^{-s^2/4\eps} -\frac{1}{\sqrt t}\e^{-s^2/4t} } \, \d s, \ee so it follows that \be \hat F_{t,0,\eps}(\xi)&= \tfrac i {\sqrt{2}}  \int_{\xi}^{\infty} \pa{\tfrac{1}{\sqrt\eps}\e^{-s^2/4\eps} -\tfrac{1}{\sqrt t}\e^{-s^2/4t} } \, \d s\\ & \notag =- \tfrac i {\sqrt{2}}  \int_{-\infty}^\xi    \pa{\tfrac{1}{\sqrt\eps}\e^{-s^2/4\eps} -\tfrac{1}{\sqrt t}\e^{-s^2/4t} } \, \d s. \ee   If $\xi >0$, we estimate \be \abs{\hat F_{t,0,\eps}(\xi)}\le  \tfrac 1 {\sqrt{2}}   \int_{\xi}^{\infty}{\tfrac{1}{\sqrt\eps}\e^{-s^2/4\eps} }  \, \d s+  \tfrac 1 {\sqrt{2}}  \int_{\xi}^{\infty}{\tfrac{1}{\sqrt t}\e^{-s^2/4t} }\, \d s. \ee Using the Gaussian estimate \be \int_x^\infty \e^{-\frac {y^2}2}\, \d y \le \tfrac 1 x \e^{-\frac {x^2}2} \qtx{for} x>0, \ee and recalling $ \int_{0}^{\infty}\e^{-y^2/2}  \, \d y=\sqrt{\frac \pi  2}$, we conclude that  \be \int_x^\infty \e^{-\frac {y^2}2}\, \d y \le \sqrt{\tfrac {\pi\e } 2}  \, \e^{-\frac {x^2}2} \qtx{for all} x\ge 0. \ee (Note that $\int_x^\infty \e^{-\frac {y^2}2}\, \d y \le \e^{-\frac {x^2}2} $ for $x \ge 1$ and $\e^{-\frac {x^2}2} \sqrt{\e} \ge 1$ for $x\in [0,1]$.) Thus \be   \int_{\xi}^{\infty}\e^{-s^2/4 b}  \, \d s &= \sqrt{2b} \int_{\frac \xi{ \sqrt{2b}}}^{\infty}\e^{-\frac{y^2}2}  \, \d s \le \sqrt{\tfrac {\pi\e } 2}  \,  \sqrt{2b} \, \e^{-\xi^2/4 b}\\   &  \le   \sqrt{\pi\e\, b} \, \e^{-\xi^2/4 b} \le  3\sqrt{b}  \, \e^{-\xi^2/4 b}\qtx{for} \xi\ge 0, \ b>0. \ee  It follows from \eq{Fxipi} and \eq{eq:erfc} that  \be \abs{\hat F_{t,0,\eps}(\xi)}&   \le  \tfrac 3 {\sqrt{2}}\e^{-\xi^2/4\eps} + \tfrac 3 {\sqrt{2}}\e^{-\xi^2/4t}\le 5 \e^{-\xi^2/4t}, \ee for all $\xi >0$, and since the same estimate can be established for $\xi<0$, for all $\xi \in \R$.  Moreover, the  same upper bound also holds for an arbitrary value of $a$. %In particular, we get %\be %\norm{\hat F_{t,\eps}}_\infty \le 5  %\ee %and %\be % \norm{F_{t,\eps}}_\infty  \le \tfrac{1}{\sqrt{2\pi}} \norm{\hat F_{t,\eps}}_1\le   \tfrac{5}{\sqrt{2\pi}}  % \int_{\R} \e^{-\xi^2/4t} \, \di \xi =    \tfrac{5}{\sqrt{2\pi}}  \sqrt{2\pi t}= 5\sqrt{t} . % \ee %Since % \be % F_{t}(x)= \lim_{\eps \to 0} F_{t,\eps}(x) \qtx{for all} x\in \R, % \ee %we see that \eqref{Finfty} holds.   We can bound \be \norm{P_-^A\ f(H)\, P_+^B}\le \int_{\mathcal R}\norm{P_-^A\ e^{itH}\, P_+^B}\abs{\hat f(t)}dt+\int_{\mathcal R^c}\abs{\hat f(t)}dt, \ee where $\mathcal R = [-R,R]$.   Using \eqref{eq:2int} with $R=c\ell$ and Lemma \ref{lem:F}, we have \be &\norm{P_- ^{S} f(H-E)P_+^{T}} \le  C  \norm{\hat f}_\infty \frac{  \abs{\Delta^{-1} c\,  \ell}^\ell}{\ell!}+ \int_{\abs{t}> c\ell} \abs{ \hat f(t)}\, \d t. \ee Hence for $0<\eps<t$ and appropriately chosen value for $c$,   say $ c=\frac \Delta{5}$, \eqref{eq:Ft1} implies, via Stirling's approximation, that \be \norm{P_- ^{S} F_{t,0,\eps}(H-E)P_+^{T}}\le  C       \e^{-\frac 12 \ell}} + C\int_{\abs{\xi}> \frac \Delta{5} \ell} \e^{-\xi^2/4t} \, \d \xi \le C \e^{- \frac 12 \ell}+ C\sqrt{t} \,\e^{-{\frac {\Delta^2\ell^2 }{200 t} }. \ee  %Using \eq{PFteps}, $F_{t,0}-F_{t,0,\eps}= F_{\eps,0}$, and    Using $\abs{(F_{t,0}-F_{t,0,\eps})(x)}\le \eps \abs{x}$, \eq{PFteps},   restricting to   the N-particle sector $\cH_\La\up{N}$, and recalling thatb $H_N$ is a bounded operator,  we get  \be \norm{P_-^{{S}} F_{t,0}(H_{N}-E) P_+^{{T}}}& \le \norm{P_-^{{S}} F_{t,0,\eps}(H_{N}-E) P_+^{{T}}} + \norm{ (F_{t,0}-F_{t,0,\eps})(H_{N}-E)}\\  & \le  C    \pa{  \e^{- \frac 12\ell} +   \sqrt{t} \,\e^{-\frac {\Delta^2 \ell^2 }{200t}} } + \eps \norm{H_{N}-E}, \ee    where $C$ is $N$-independent.  Letting $\eps \to 0$ we get \be \norm{P_-^{{S}}  F_{t,a}(H_N-E) P_+^{{T}}}\le  C    \pa{  \e^{-\frac 12\ell} +   \sqrt{t} \,\e^{-\frac {\Delta^2 \ell^2 }{200t}}  }\qtx{for all} N\in \N. \ee   The desired estimate \eq{locest} follows.",2502.01831
lemma,"Let $q\ \in  \frac 12 \N$, $1\le q $, and  $N\in \N$.  Fix $\La \subset \Z$, and and suppose  \eq{eq:weakinf} holds for all  ${\bf x},{\bf y}\in \cP_{N,\cl{q}}(\La)$.  Then \eq{eq:weakinf} holds for all ${\bf x},{\bf y}\in \cP_{N}(\La)$ (with different constants, independent of $\La$ and $N$).",2502.01831
lemma,"Let $D\subset \Z$ be finite, let $N\in \N$,  and assume \be   \sup_{z\in\mathds{H}_{ q}}\E_D \set{\abs{G^{D}_{z}({\bf x},{\bf y})}^s}\le  C_q \e^{-c_{q}   d_H^D ({\bf x},{\bf y})} \mqtx{for all}\x,\y\in \cP_{N,\cl{q}}(D). \ee  Then         \be  \E_{D}\set{\cQ_q^D ({\bf x},{\bf y})}\le  C_q e^{-c_q d_{H}^D({\bf x},{\bf y})} \ \mqtx{for all}\x,\y\in \cP_{N}(D). \ee",2502.01831
lemma,"Let $q\ \in  \frac 12 \N$, $1\le q $, and   assume the the induction hypothesis,  that is,  Theorem~\ref{cor:weakinf} is proven for $q-\frac 12$.  Let  $\La \subset \Z$ and  $N\in \N$.  Then for all $\x,\y\in \cP_{N,\cl{q}}$ and  any finite  connected set $D\subset\La$ satisfying $ (\x\cup \y)_D \neq\emptyset$ and $(\x\cup \y)_{D^c}\neq\emptyset$ we have \be   \sup_{z\in\mathds{H}_q}\E_\La\set{\abs{G^{D,D^c}_{z}({\bf x},{\bf y})}^s}\le C_{ q} \abs{D}^{2\cl{q}} \e^{-c_{q-\frac12} { d_H^\La ({\bf x},{\bf y})} } \mqtx{for all}\x,\y\in \cP_{N,\cl{q}}(D). \ee",2502.01831
lemma,"Let $q\ \in  \frac 12 \N$, $1\le q $, and   assume the the induction hypothesis,  that is,  Theorem~\ref{cor:weakinf} is proven for $q-\frac 12$.  Let  $\La \subset \Z$ and  $N\in \N$.  Then \be \sup_{z\in\mathds{H}_q}\E_{\La}\set{\abs{G_z^\La ({\bf x},{\bf y}) }^{\ s}}\le C_q e^{-c_q d_H^\La(\x,\y)} \sqtx{for}\x,\y\in \cP_{N,\cl{q}}(\La), \ee",2502.01831
lemma,"Let  $k,N\in \N$,  $k\le N$,   $\alpha>0$, and let \beq C_\alpha=(1-\e^{-\alpha})^{-1} \pa{ \prod_{n=1}^\infty (1- \e^{-\alpha n})^{-1}}^2. \eeq    Then \be \sup_{\y\in \cP_{N}(\Z)} \sum_{{\x}\in\cP_{N,k}(\Z)} \e^{-\alpha \abs{\x-\y}_1}\le  C_{\alpha}^{k+1} , \ee  and \be \sup_{\x\in \cP_{N,k}(\Z)} \sum_{{\bf y}\in\cP_{N}(\Z)} \e^{-\alpha \abs{\x-\y}_1}\le C_{\alpha}^k , \ee",2502.01831
lemma,"Let  $N\in \N$,  $k\in \N$, $k\le N$, and  $\alpha>0$.  Then \be  \sup_{\x\in \cP_{N,k}(\Z)} \sum_{{\bf y}\in\cP_{N,k}(\Z)} \e^{-\alpha d_H({\bf x},{\bf y})}\le C_{\alpha,k} N^{2k}. \ee",2502.01831
lemma,"For all $A\subsetneq B\subset {\La}$ with  $A, B$ finite,  $A\subset K_1$  connected in ${K_1}$,   we have  \be  \norm{P_-^{A}\e^{itH} P_+^{B}}\le  \Delta^{-r}\frac{  \abs{t}^r}{r!} \sqtx{for all} t\in \R, \qtx{where} r=d_{\La} \pa{A,B^c}.  \ee",2502.01831
theorem,"If graph $\mathcal{G}$ is defined such that there exists at least one path from agent, then, $i\in \mathcal{V}_R$,  then,      dynamics \eqref{networkopiniondynamics} is stable.",2502.01847
theorem,"If graph $\mathcal{G}$ is defined such that there exists at least one path from every stubborn agent to every agent, $i\in \mathcal{V}_R$,  then              \mathbf{D}=-\mathbf{I}_n+\mathbf{A}          is Hurwitz,              \mathbf{C}=-\mathbf{D}^{-1}\mathbf{B}          is one-sum row and non-negative.",2502.01847
theorem,"If the regular agent $i\in \mathcal{V}_l$ is solely influenced by $\mathcal{W}_l$, for every $l\in \mathcal{M}$, then the communication matrix $\mathbf{W}$ is reducible and network opinion dynamics is obtained by      \bar{\mathbf{x}}(k+1)=\left(\mathbf{I}_n\otimes \bar{\mathbf{A}}\right)\bar{\mathbf{x}}(k)+\left(\mathbf{I}_n\otimes          \bar{\mathbf{S}}&\mathbf{\bar{\Lambda}}     \right)\bar{\mathbf{u}}.  where       \bar{\mathbf{A}}=\mathbf{Q}\mathbf{A}\mathbf{Q}^T,       \bar{\mathbf{S}}=\mathbf{Q}\mathbf{S},       \bar{\mathbf{\Lambda}}=\mathbf{Q}\mathbf{\Lambda}\mathbf{Q}^T.",2502.01847
theorem,"Assume agents who influence of every $i\in \mathcal{V}_R$ are  defined by $\mathcal{N}_i$ and assigned such that              \left(\bigwedge_{l\in \mathcal{M}}\bigwedge_{i\in \mathcal{V}_{l}}\left(\mathcal{N}_i\subset \mathcal{W}_{l}\right)\right).         Then, matrix  $\bar{\mathbf{A}}\in \mathbb{R}^{N_R\times N_R}$ is reducible and obtained by              \bar{\mathbf{A}}=             \bar{\mathbf{A}}_{11}&\cdots&\mathbf{0}\\             \vdots&\ddots&\vdots\\             \bar{\mathbf{A}}_{M1}&\cdots&\bar{\mathbf{A}}_{MM}\\                  ,                   \bar{\mathbf{S}}=             \mathbf{Q}_1\mathbf{S}\\             \mathbf{0}_{\left(N_R-N_1\right)\times \left(N-N_R\right)}                  \in\mathbb{R}^{N_R\times \left(N-N_R\right)}.",2502.01847
theorem,"%    Assume influencers of every $i\in \mathcal{V}_R$, defined by $\mathcal{N}_i$, are assigned such that  %     %         \left(\bigwedge_{l\in \mathcal{M}}\bigwedge_{i\in \mathcal{V}_{l}}\left(\mathcal{N}_i\subset \mathcal{W}_{l}\right)\right). %      %    Then, matrix  $\bar{\mathbf{A}}\in \mathbb{R}^{N_R\times N_R}$ is reducible and obtained by %      %         \bar{\mathbf{A}}= %             \bar{\mathbf{A}}_{11}&\cdots&\mathbf{0}\\ %             \vdots&\ddots&\vdots\\ %             \bar{\mathbf{A}}_{M1}&\cdots&\bar{\mathbf{A}}_{MM}\\ %          %         . %      %",2502.01847
theorem,"Assume inter-agent influences are such that the in-neighbor set $\mathcal{N}_i$ satisfy the following condition:              \left(\bigwedge_{i\in \mathcal{V}_1}\left(\mathcal{N}_i\in \mathcal{V}_S\right)\right)\wedge\left(\bigwedge_{l\in \mathcal{M}\setminus \left\{1\right\}}\bigwedge_{i\in \mathcal{V}_l}\left(\mathcal{N}_i\subset \mathcal{W}_{l-1}\right)\right),          where $\mathcal{W}_l$ is defined by Eq. \eqref{Wl} for every $l\in \mathcal{M}$.      Then, the opinion of every regular agent $i$ converges to its final values in $M$ time steps, where $M$ is the number of layers of the DNN.     %      % \item inter-agent influences, defined by graph $\mathcal{G}$, can be represented by a deep neural network with $M$ layers, and     % \item the opinion of every regular agent $i$ converges to its final values in $M$ time steps, where $M$ is the number of layers of the DNN.     %",2502.01847
definition,"The paper defines the influence matrix $\mathbf{W}=\left[W_{i,j}\right]\in \mathbb{R}^{N_R\times N}$ as the influence matrix aggregating the influences of all agents on regular agents, where      W_{i,j}=         w_{i,j}&i\in \mathcal{V}_R,~j\in \mathcal{N}_i\\         0&\mathrm{otherwise}          .",2502.01847
definition,"The paper defines the bias matrix      \mathbf{\Lambda}(k)=\mathrm{diag}\left(\lambda_1(k),\cdots,\lambda_{N_R}(k)\right)\in \mathbb{R}^{N_R\times N_R}.  to quantify the bias of every regular agent on its initial opinion.",2502.01847
definition,"Given $\mathcal{V}_0$ through $\mathcal{V}_M$, we define      \mathcal{W}_l=         \mathcal{V}_S\cup\mathcal{V}_l&l=1\\         \mathcal{W}_{l-1}\cup\mathcal{V}_l&l\in \mathcal{M}\setminus \left\{1\right\}          ,\qquad \forall l\in \mathcal{M}.  % Opinion propagation under reducible network is achieved if $i\in \mathcal{W}_l$ %",2502.01847
definition,"Assuming $N_l=\left|\mathcal{V}_l\right|$, for every $l\in \mathcal{M}$, {\color{black}$\mathcal{O}_l$} assigns a unique order number to every $\mathcal{V}_l$'s agent. The order number of the agent $i\in \mathcal{V}_l$ is denoted by $o_i$, where $o_i=\mathcal{O}_l(i)$, for every $l\in \mathcal{M}$.",2502.01847
definition,"We define      $     \mathbf{Q}_l=\left[Q_{i,j}^l\right]\in \mathbb{R}^{N_l\times N_R}     $ as a transformation matrix      with $(i,j)$ entry      \vspace{-0.2cm}             Q_{i,j}^l=             1&j=\mathcal{O}_l(i),~i\in \mathcal{V}_l\\             0&\mathrm{else}                  ,\qquad l\in \mathcal{M}.      % as",2502.01847
definition,"%     We define  %     \vspace{-0.2cm} %      %     \bar{\mathbf{Z}}_l=\left(\mathbf{I}_3\otimes \mathbf{Q}_l\right)\mathbf{Z}\in \mathbb{R}^{3N_l\times1},\qquad l\in \mathcal{M}, %  % as the vector aggregating desired  position compblack when all agents defined by $\mathcal{V}_l$  when agents' order numbers are defined by $\mathcal{O}_l$, for every $l\in \mathcal{M}$. %",2502.01847
definition,We define      \mathbf{Q}=                   \mathbf{Q}_1\\\vdots\\\mathbf{Q}_M          \in \mathbb{R}^{N_R\times N_R}  as a transformation matrix.,2502.01847
definition,"We define      \vspace{-0.2cm}      \bar{\mathbf{x}}_l(k)=\left(\mathbf{I}_n\otimes \mathbf{Q}_l\right)\mathbf{x}(k)\in \mathbb{R}^{nN_l\times1},\qquad l\in \mathcal{M},  as the vector aggregating opinions of all agents defined by $\mathcal{V}_l$. % when agents' order numbers are defined by $\mathcal{O}_l$, for every $l\in \mathcal{M}$.",2502.01847
definition,"The paper defines              \bar{\mathbf{A}}_{pq}=\mathbf{Q}_p\mathbf{A}\mathbf{Q}_q^T\in \mathbb{R}^{N_p\times N_q},\qquad p,q\in \mathcal{M}",2502.01847
definition,"The paper defines              \bar{\mathbf{\Lambda}}_{pq}=\mathbf{Q}_p\mathbf{\Lambda}\mathbf{Q}_q^T\in \mathbb{R}^{N_p\times N_q},\qquad p,q\in \mathcal{M}.",2502.01847
definition,%     The paper defines  %      %     \bar{\mathbf{A}}=\mathbf{Q}\mathbf{A}\mathbf{Q}^T. %  %,2502.01847
definition,% %     The paper defines  % %      % %     \bar{\mathbf{S}}=\mathbf{Q}\mathbf{S} % %  % %,2502.01847
definition,%     The paper defines  %  %     \bar{\mathbf{\Lambda}}=\mathbf{Q}\mathbf{\Lambda}\mathbf{Q}^T. %  %,2502.01847
definition,"The paper defines         \bar{\mathbf{u}}=&\left(\mathbf{I}_n\otimes\mathbf{H}\right)\mathbf{u}_A^T&\mathbf{u}_S^T^T\in \mathbb{R}^{Nn\times 1}      where      \mathbf{u}_S=\mathrm{vec} \left(         \mathbf{o}_{N_R+1}(0)&\cdots&\mathbf{o}_N(0)     ^T\right)\in \mathbb{R}^{n\left(N-N_R\right)\times 1},       \mathbf{u}_A=\mathrm{vec}\left(              \mathbf{o}_{1}(0)&\cdots&\mathbf{o}_{N_R}(0)     ^T\right),   \mathbf{H}=               \mathbf{I}_{N-N_R}&\mathbf{0}_{\left(N-N_R\right)\times N_R}\\\mathbf{0}_{ N_R\times \left(N-N_R\right)}&\mathbf{Q}            .",2502.01847
proof,See the proof in \cite{proskurnikov2017tutorial}.,2502.01847
proof,"The matrix $\mathbf{A}\in \mathbb{R}^{N_R\times N_R}$ is nonnegative where the sum of the entries $\mathbf{A}(k)$ is less than $1$. Therefore, the spectral radius of $\mathbf{A}(k)$ is indicated by $r$ and is less than $1$ at every discrete time $k$. As a result, the eigenvalues of $\mathbf{D}\in \mathbb{R}^{N_R\times N_R}$ are located inside a disk of radius, $r<1$ which is centered at $-1+0\mathbf{j}$. This implies that matrix $\mathbf{D}$ is Hurwitz at every discrete time $k$.      To prove that $\mathbf{C}$ is a one-sum row, we define the matrix $\mathbf{Y}=         \mathbf{D}&\mathbf{B}     $ where every row of $\mathbf{Y}$ sums up to $0$. Applying the Gaussian Jordan elimination approach, we can convert $\mathbf{D}$ to $\mathbf{I}_{Nn}$, since $\mathbf{D}$ is invertible. Therefore, applying the Gaussian Jordan elimination approach converts $\mathbf{Y}$ to $\mathbf{Y}'=         \mathbf{I}&-\mathbf{D}^{-1}\mathbf{B}     $ by using row algebraic operations. Applying the row algebraic operations does not change sum of the rows of $\mathbf{Y}$, therefore,   every row of $\mathbf{Y}$ and $\mathbf{Y}'$ sums up to $0$. This implies that every row of the matrix $\mathbf{D}$ sums up to $1$.      The diagonal elements of $\mathbf{D}$ are all $-1$ and its off-diagonal elements are all non-zero. Therefore, $\mathbf{Y}$ can be converted to $\mathbf{Y}''=         -\mathbf{I}&\mathbf{Z}     $ by applying row-algebraic operations, where $\mathbf{Z}$ is non-positive. Because $\mathbf{Y}'=-\mathbf{Y}''$, we conclude that $-\mathbf{Z}=-\mathbf{D}^{-1}B$ is non-negative.      % Because $w_{i,j}>0$ and $\lambda_i>0$ and the                % To prove that matrix $\mathbf{D}$ is positive, we note that the r",2502.01847
proof,"When every regular agent updates its opinion by Eq. \eqref{opinionevolutionindividual}, the network opinion dynamics is obtained by              \mathbf{x}\left(k+1\right)=\left(\mathbf{I}_n\otimes \mathbf{A}\right)\mathbf{x}\left(k\right)+\left(\mathbf{I}_n\otimes             \mathbf{S}&\mathbf{\mathbf{\Lambda}}          \right)\mathbf{u}          Let both sides of  Eq. \eqref{proof1} be pre-multiplied by $\mathbf{I}_n\otimes \mathbf{Q}$, and $\mathbf{x}\left(k\right)$ and $\mathbf{u}$ be substituted by the following terms:     \[    \mathbf{x}\left(k\right)=\left(\mathbf{I}_n\otimes\mathbf{Q}^T\right)\left(\mathbf{I}_n\otimes\mathbf{Q}\right)\mathbf{x}\left(k\right)=\left(\mathbf{I}_n\otimes\mathbf{Q}^T\right)\bar{\mathbf{x}}\left(k\right)     \]     \[    \mathbf{u}=\left(\mathbf{I}_n\otimes\mathbf{H}^T\right)\left(\mathbf{I}_n\otimes\mathbf{H}\right)\mathbf{u}=\left(\mathbf{I}_n\otimes\mathbf{H}^T\right)\bar{\mathbf{u}}     \]     Then, Eq. \eqref{proof1} is converted to              \bar{\mathbf{x}}\left(k+1\right)=\left(\mathbf{I}_n\otimes \left(\mathbf{Q}\mathbf{A}\mathbf{Q}^T\right)\right)\bar{\mathbf{x}}\left(k\right)+\left(\mathbf{I}_n\otimes \left(\mathbf{Q}             \mathbf{S}&\mathbf{\Lambda}         \mathbf{H}^T\right)\right)\bar{\mathbf{u}}         .          Per Eqs. \eqref{sb}, \eqref{rb}, and \eqref{lb}, we can replace $\bar{\mathbf{A}}=\mathbf{Q}\mathbf{A}\mathbf{Q}^T$ and $             \bar{\mathbf{S}}&\bar{\mathbf{\Lambda}}         =\mathbf{Q}             \mathbf{S}&\mathbf{\Lambda}         \mathbf{H}^T$ into Eq. \eqref{proof10}. Thus, we obtain the network opinion dynamics in the form of Eq. \eqref{convertednetwork}.",2502.01847
proof,"The agent $i\in \mathcal{V}_p\subset \mathcal{V}_R$ is not influenced by any agent $j\in \mathcal{V}_q\subset \mathcal{V}_R$ if $q>p$. This implies that $(i,j)$ entries of matrices $\mathbf{A}$ and $\mathbf{W}$, denoted by $A_{i,j}$ and $W_{i,j}$, respectively, are both zero, for every $i\in \mathcal{V}_p$ and every $j\in \mathcal{V}_q$. Therefore, the entries of every row of the matrix $\bar{A}_{pq}=\mathbf{Q}_p\mathbf{A}\mathbf{Q}_q^T$ are zero, which in turn implies that $\bar{\mathbf{A}}_{pq}=\mathbf{0}_{N_p\times N_q}$. Also, $\mathbf{Q}_l\mathbf{S}=\mathbf{0}_{N_l\times \left(N-N_R\right)}$ if $l\in \mathcal{M}\setminus \left\{1\right\}$ because only $V_1$'s agents access the opinions of the stubborn agents that are defined by $\mathcal{V}_S$. Therefore, $\bar{\mathbf{S}}=\mathbf{Q}\mathbf{S}$ simplifies to the expression in Eq. \eqref{barS}.",2502.01847
proof,"If the theorem's assumption is satisfied, then the diagonal blocks of matrix $\bar{\mathbf{A}}\in \mathbb{R}^{N_R\times N_R}$ are all zero which in turn implies that eigenvalues of $\bar{\mathbf{A}}$ are  all zero, and as the result, % . By definingg %  %     \bar{d}_l=\mathbf{I}_\otimes \left(\mathbf{Q}_l %         \mathbf{S}&\mathbf{\Lambda} %     \right)\mathbf{u}, %  the opinion of the layer $l\in \mathcal{M}$ is updated by      \bar{\mathbf{x}}_l(k+1)=        \bar{\mathbf{\Lambda}}_{11}\bar{\mathbf{x}}_1(0)+\bar{\mathbf{S}}_1\bar{\mathbf{u}}_S&l=1\in \mathcal{M}\\         \sum_{h=1}^{l-1}\bar{\mathbf{A}}_{lh}\bar{\mathbf{x}}_h(k)+\bar{\mathbf{\Lambda}}_{ll}\bar{\mathbf{x}}_l(0)&l=\mathcal{M}\setminus \left\{1\right\}\\          .  %  %     \bar{\mathbf{x}}_l(k+1)= %         \bar{\mathbf{d}}_l&l=1\\ %         \sum_{h=1}^{l-1}\left(\mathbf{I}_n\otimes\bar{\mathbf{A}}_{l,h}\right)\bar{\mathbf{x}}_h(k)&l\in \mathcal{M}\setminus\left\{1\right\} %      %     . %  In Eq. \eqref{bad}, $\bar{\mathbf{x}}_l$ converges to its final value after $\bar{\mathbf{x}}_{l-1}$ converging to the  final opinion vector, where every $l\in \mathcal{M}\setminus\left\{1\right\}$, where $\bar{\mathbf{x}}_1$ converges to the final opinion vector at $k=1$. Therefore, agents of layer $l\in \mathcal{M}$ converge in $l$ time steps.",2502.01847
theorem,"Let $W =\{ w \in Q_2 \colon \norm{w}_{Q_2} \leq C_2 \sqrt{M}  \norm{\varphi_D}_{1/2,\Gamma_D} + \norm{g}_{0,\Omega}) \}$. Under the assumptions over the non-linear terms, suppose further that $1\leq \lambda$, $1\leq\mu$, $\theta \leq M^{-1}$, and $C_1 L_\ell \sqrt{2\mu} M^{2}C_2^2 L_{\bbM}(\norm{\varphi_D}_{1/2,\Gamma_D} + \norm{g}_{0,\Omega}) < 1.$ Then, for $\varphi \in W$ there is an unique solution $(\bu,p,\bzeta,\varphi)\in \bV_1\times Q_1 \times \bV_2 \times Q_2$ of \eqref{eq:weak} such that                \norm{(\bu,p)}_{\bV_1\times Q_1} &\leq C_1 \left( \norm{F_1}_{\bV'_1} + \norm{G^\varphi_1}_{Q'_1} \right),\\         \norm{(\bzeta,\varphi)}_{\bV_2\times Q_2} &\leq C_2 \left( \norm{F_2}_{\bV'_2} +\norm{G_2}_{Q'_2} \right),       where the constants $C_1$ and $C_2$ do not depend on the physical parameters.",2502.01851
theorem,"Under the assumptions of Theorem~\ref{well-posedness}. Given $(\bu,{p},\bzeta,\varphi)\in (\bH^{s_1+1}(\Omega)\cap \bV_1)\times (\text{H}^{s_1}(\Omega)\cap Q_{b_1}) \times (\bH^{s_2}\cap \bV_2) \times (\text{H}^{s_2}\cap Q_{b_2})$, $(\bu_h,{p}_h,\bzeta_h,\varphi_h)\in \bV_1^{h,k_1}\times Q_1^{h,k_1}\times \bV_2^{h,k_2}\times Q_2^{h,k_2}$ be the respective solutions of the continuous and discrete problems, with the data satisfying $\fb\in \bH^{s_1-1}\cap \bQ_{b_1}$ and $g\in H^{s_2}(\Omega)\cap Q_{b_2}$. If $\overline{C}_1 \sqrt{M} L_\ell + \overline{C}_2^2 \sqrt{M^3} L_\bbM\sqrt{2\mu}   (\norm{\varphi_D}_{1/2,\Gamma_D} + \norm{g}_{0,\Omega}) < 1/2.$ Then, the total error $\overline{\textnormal{e}}_h:=\norm{(\bu-\bu_h,{p}-{p}_h, \bzeta-\bzeta_h,\varphi-\varphi_h)}_{\bV_1\times Q_{1} \times \bV_2\times Q_2}$ decays with the following rate for $s:= \min \left\{s_1,s_2\right\}$               \overline{\textnormal{e}}_h &\lesssim h^{ s} (|\fb|_{s_1-1,\bQ_{b_1}} + |\bu|_{s_1+1,\bV_1} + |{p}|_{s_1,Q_{b_1}} + |g|_{s_2,Q_{b_2}} + |\bzeta|_{s_2,\bV_2}+|\varphi|_{s_2,Q_{b_2}}).",2502.01851
lemma,"For any $\bv \in (\bH^{s_1+1}(P)\cap \bV_1(P),|\cdot|_{1,\bV_1(P)})$, $q\in (H^{s_1+1}(P)\cap Q_{b_1}(P),|\cdot|_{1,Q_{b_1}(P)})$, $\bxi \in (\bH^{s_2+1}(P)\cap \bV_2(P),|\cdot|_{1,\bV_2(P)})$ and $\psi \in (H^{s_2+1}(P)\cap Q_{b_2}(P),|\cdot|_{1,Q_{b_2}(P)})$, the polynomial projections $\bPi_1^{\beps,k_1}\bv$, $\Pi_1^{0,k_1}q$, $\bPi_2^{0,k_2}\bxi$ and $\Pi_2^{0,k_2}\psi$ satisfy the following estimates          \norm{\bv-\bPi_1^{\beps,k_1}\bv}_{\bV_1(P)}\lesssim h_P^{s_1}|\bv|_{\bV_1(P)},\quad \norm{q-\Pi_1^{0,k_1}q}_{Q_{b_1}(P)}\lesssim h_P^{s_1+1}|q|_{Q_{b_1}(P)},\\     \norm{\bxi-\bPi_2^{0,k_2}\bxi}_{\bbM,P}\lesssim h_P^{s_2+1}|\bxi|_{\bV_2(P)},\quad \norm{\psi-\Pi_2^{0,k_2}\psi}_{Q_{b_2}(P)}\lesssim h_P^{s_2+1}|\psi|_{Q_{b_2}(P)}.",2502.01851
lemma,"Given $\bv\in (\bH^{s_1+1}(P)\cap\bV_1(P), |\cdot|_{1,\bV_1(P)})$ and $\bxi \in (\bH^{s_2+1}(P)\cap \bV_2(P),|\cdot|_{1,\bV_2(P)})$. The Fortin interpolation operators $\bPi_1^{F,k_1}$ and $\bPi_2^{F,k_2}$ satisfy      \norm{\bv-\bPi_1^{F,k_1}\bv}_{\bV_1(P)}\lesssim h_P^{s_1}|\bv|_{1,\bV_1(P)}, \quad \norm{\bxi - \bPi_2^{F,k_2}\bxi}_{\bbM,P} \lesssim h_P^{s_2+1}|\bxi|_{1,\bV_2(P)}.",2502.01851
theorem,"Assume that $\boldsymbol{b} \in \ell^{p}(\mathbb{N})$ is strictly decreasing. Then there exists $\boldsymbol{\pi}^{\normalfont\text{(rb)}}_{n} \in \mathcal{N\!N}_{D,W,s,2J}$ such that   	\norm{ 		u 		-  		\mathcal{R}         \left(             \boldsymbol{\pi}^{\normalfont\text{(rb)}}_{n}         \right)         \circ\mathcal{T}_s 	}_{L^2(\mathbb{U};X)} 	\lesssim     &     \sup_{\y \in \mathbb{U}}     \inf_{v_h \in X_h}     \norm{u(\y)-v_h}_X        +     J     n^{-\left(1/p - 1/2\right)}     \\     &     +     s^{-\left(1/p-1\right)}     +     N^{-\frac{\alpha}{2}}     +     J^{-\left(1/p-1\right)}.   with  $W = \mathcal{O}(n^2)$ and $D = \mathcal{O} \left(\log_2(n)\right)$, where for a tanh NN $\Psi$ with $s$ inputs and $2J$ outputs, the reconstruction operator $\mathcal{R}$ is defined as      \mathcal{R}     \left(         \Psi     \right)     (\y)     =     \sum_{i=1}^{J}     \left(         \left(             \Psi(\y)         \right)_{i}         +         \imath         \left(             \Psi(\y)         \right)_{i+J}     \right)     {\zeta}^{\normalfont\text{(rb)}}_i,     \quad     \y \in \mathbb{U}^{(s)}.",2502.01859
definition,"[{\cite[Definition 2.1]{CCS15}}] Let $X$ be a complex Banach space equipped with the norm $\norm{\cdot}_{X}$.  For $\varepsilon>0$ and $p\in(0,1)$, we say that map  $\mathbb{U}  \ni  \y \mapsto  u(\y)  \in  X$ is \emph{$(\boldsymbol{b},p,\varepsilon)$-holomorphic} if and only if:  	\item 	The map $\mathbb{U} \ni {\y} \mapsto u(\y) \in X$ is uniformly bounded. 	\item 	There exists a positive sequence $\boldsymbol{b}\coloneqq \{b_j\}_{j\geq 1} \in \ell^p(\mathbb{N})$  	and a constant $C_\varepsilon>0$ such that for any sequence  	$\boldsymbol\rho\coloneqq \{\rho_j\}_{j\geq1}$  	of numbers strictly larger than one that is 	$(\boldsymbol{b},\varepsilon)$-admissible, i.e.~satisfying 	$\sum_{j\geq 1}(\rho_j-1) b_j  \leq  \varepsilon$, 	the map $\y \mapsto u(\y)$ admits a complex 	extension $\z \mapsto u(\z)$  	that is holomorphic with respect to each 	variable $z_j$ on a set of the form  	 		\mathcal{O}_{\boldsymbol\rho}  		\coloneqq   		\displaystyle{\bigotimes_{j\geq 1}} \, \mathcal{O}_{\rho_j}, 	 	where 	  	\mathcal{O}_{\rho_j}= 	\{z\in\IC\colon\operatorname{dist}(z,[-1,1])<\rho_j-1\}. 	 	\item 	This extension is bounded on $\mathcal{E}_{\boldsymbol\rho}$ according to 	 		\sup_{\z\in \mathcal{E}_{\boldsymbol{\rho}}} \norm{u(\z)}_{X}  \leq C_\varepsilon.",2502.01859
proof,"Under the assumptions established in \Cref{sec_rom}, the map  $\mathbb{U} \ni \y \mapsto u_h(\y) \in X$ is  $(\boldsymbol{b},p,\varepsilon)$-holomorphic and continuous. Next, it follows from \Cref{lmm:bpe_holomorphy_pod} that the map      \mathbb{U}     \ni     \y \mapsto      \norm{         u_h(\y)         -         \mathsf{P}_{X_{h,s,N,J}^{(\text{rb})}}u_h(\y)     }^2_{X}     \in     \mathbb{R}.  is so as well.  Using this, the result of this lemma is a direct consequence of \Cref{lemma:Halton,prop:QMC_error} in \Cref{sec:QMC} for the Halton and HoQMC quadrature rules, respectively.",2502.01859
proof,"We observe that $\mathbf{C}_h=\frac{1}{N}\widetilde{\mathbf{S}}^\star\mathbf{M}\widetilde{\mathbf{S}}$ in \cref{eq:snapshotcorrelation}, $\frac{1}{N}({\bf M}_h^\star)^{1/2}\widetilde{\bf S}^\star\widetilde{\bf S}{\bf M}_h^{1/2}$, and ${\bf K}=\frac{1}{N}\widetilde{\bf S}^\star\widetilde{\bf S}{\bf M}_h$ have the very same eigenvalues $\sigma^2_{h,i}$ and that the latter, ${\bf K}$, is the matrix representation of  	\mathsf{K}_{h,s,N}w_h 	= 	\frac{1}{N} 	\sum_{n=1}^Nu_h(\y^{(n)})\Big(u_h(\y^{(n)}),w_h\Big)_X,  which also has eigenvalues $\sigma^2_{h,i}$. Using this notation, and recalling \cref{eq:continuousio}, we estimate {\small   	\varepsilon_{h,s,N}      	\Big(X_{h,s,N,J}^{(\text{rb})}\Big)       	&= 	\sum_{i=J+1}^r\sigma^2_{h,i}\\       	&=       	\min_{\substack{\mathbf{v}\in\mathbb{C}^{N_h\times J}\\ 	\mathbf{v}^\star\mathbf{v}=\mathbf{I}}}\trace\big(\mathbf{v}^\star\mathbf{C}\mathbf{v}\big)\\       	&=       	\min_{\substack{V\subset X_h\\\dim V\leq J}}\trace\big(\mathsf{P}_V\mathsf{K}_{h,s,N}\mathsf{P}_V\big)\\       	&=       	\min_{\substack{V\subset X_h\\\dim V\leq J}} 	\left( 		\trace\big(\mathsf{P}_V\mathsf{K}_{h,s,N}\mathsf{P}_V-\mathsf{P}_V\mathsf{K}_h\mathsf{P}_V\big)     \right.     +     \left. 		\trace\big(\mathsf{P}_V\mathsf{K}_h\mathsf{P}_V\big) 	\right)   }%   where, for an arbitrary orthonormal basis $\{\chi_i\}_{i=1}^{N_h}$ of $X_h$, it holds               \trace\big(&\mathsf{P}_V\mathsf{K}_{h,s,N}\mathsf{P}_V-\mathsf{P}_V\mathsf{K}_h\mathsf{P}_V\big)\\       &=       \sum_{i=1}^{N_h}\Big(\big(\mathsf{K}_{h,s,N}-\mathsf{K}_h\big)\mathsf{P}_V\chi_i,\mathsf{P}_V\chi_i\Big)_X\\       &=       \sum_{i=1}^{N_h}\Big(\mathsf{K}_{h,s,N}\mathsf{P}_V\chi_i,\mathsf{P}_V\chi_i\Big)_X       -       \sum_{i=1}^{N_h}\Big(\mathsf{K}_h\mathsf{P}_V\chi_i,\mathsf{P}_V\chi_i\Big)_X\\       &=       \frac{1}{N}\sum_{n=1}^N\sum_{i=1}^{N_h}\big(\mathsf{P}_Vu_h(\y^{(n)}),\chi_i\big)_X^2       -       \int_{\mathbb{U}^{(s)}}\sum_{i=1}^{N_h}\big(\mathsf{P}_Vu_h(\y),\chi_i\big)_X^2\dd\mu^{(s)}(\y)\\       &=       \frac{1}{N}\sum_{n=1}^N\big\|\mathsf{P}_Vu_h(\y^{(n)})\big\|_X^2       -       \int_{\mathbb{U}^{(s)}}\big\|\mathsf{P}_Vu_h(\y)\big\|_X^2\dd\mu^{(s)}(\y)\\       &\lesssim N^{-\alpha}.%           This implies          \varepsilon_{h,s,N}       \Big(X_{h,s,N,J}^{(\text{rb})}\Big)       \lesssim        N^{-\alpha}+\underbrace{\min_{\substack{V\subset X_h\\\dim V\leq J}}\trace\big(\mathsf{K}_h|_V\big)}_{=\varepsilon_h(X_{h,J}^{(\text{rb})})},      where the last term can be estimated using \cref{eq:rbbestNterm}, implying the assertion.",2502.01859
proof,Combine \cref{cor:contest} and \cref{lem:discerrdecay}.,2502.01859
proof,"This result follows from \cite[Lemma 5.7]{dolz2024parametric}, which  in turn uses tools from \cite{ABDM2022}, and \cref{eq:truncationerror}.",2502.01859
proof,"Let $\boldsymbol{\pi}^{\normalfont\text{(rb)}}_{n}$ be as in  \Cref{lmm:NN_bound}. It follows from the application of the triangle inequality that   	\norm{ 		u_h 		-  		\mathcal{R}         \left(             \boldsymbol{\pi}^{\normalfont\text{(rb)}}_{\mathcal{N\!N}}         \right)         \circ\mathcal{T}_s 	}_{L^2(\mathbb{U};X)} 	\leq 	& 	\underbrace{ 	\norm{ 		u_h 		-  		\mathsf{P}_{X_{h,J}^{(\text{rb})}} 		u_h 	}_{L^2(\mathbb{U};X)} 	}_{(\spadesuit)} 	\\ 	& 	+ 	\underbrace{ 	\norm{ 		\mathsf{P}_{X_{h,J}^{(\text{rb})}} 		u_h 		-  		\mathcal{R}         \left(             \boldsymbol{\pi}^{\normalfont\text{(rb)}}_{\mathcal{N\!N}}         \right)         \circ\mathcal{T}_s 	}_{L^2(\mathbb{U};X)} 	}_{(\clubsuit)}.   The term $(\spadesuit)$ is bounded according to \cref{cor:full_error_projection}. We proceed to bound $(\clubsuit)$. Recalling that $\zeta^{\text{(rb)}}_1,\dots,\zeta^{\text{(rb)}}_J$ is an orthonormal basis of $X_{h,J}^{(\text{rb})}$ with respect to the inner product of $X$ one may readily observe that  	\norm{ 		\mathsf{P}_{X_{h,J}^{(\text{rb})}} 		u_h 		-  		\mathcal{R}         \left(             \boldsymbol{\pi}^{\normalfont\text{(rb)}}         \right)         \circ\mathcal{T}_s 	}_{L^2(\mathbb{U};X)} 	= 	\norm{ 		\boldsymbol{\pi}^{\text{(rb)}}_{J,\mathbb{R}} 		- 		\boldsymbol{\pi}^{\text{(rb)}}_{\boldsymbol{\theta}}         \circ\mathcal{T}_s 	}_{L^2(\mathbb{U};\mathbb{R}^{2J})}.  The application of \cref{lmm:NN_bound} to bound \cref{eq:bound_NN} yields the assertion.",2502.01859
proof,"We proceed to verify \cref{def:bpe_holomorphy} item-by-item. 	Firstly, one can readily verify that the uniform boundedness of  	the map introduced in \cref{eq:normextension}. 	 	Let $\boldsymbol\rho\coloneqq (\rho_j)_{j\geq1}$  	be any $(\boldsymbol{b},p,\varepsilon)$-admissible  	sequence of numbers of numbers strictly larger than one.    	We consider the complex extension of \cref{eq:normextension} to $\mathcal{O}_{\boldsymbol\rho} $ 	given by 	 	\mathcal{O}_{\boldsymbol\rho}  	\ni 	\z 	\mapsto  	g(\z) 	\coloneqq 	\dotp{f(\z)}{f(\overline{\z})}_X. 	 	Observe that this extension is well-defined for each $\z \in \mathcal{O}_{\boldsymbol\rho} $ 	since this straightforwardly implies  $\overline{\z} \in \mathcal{O}_{\boldsymbol\rho} $.  	Computing the complex derivative of $g(\z)$ 	for $\z\in \mathcal{O}_{\boldsymbol\rho} $ we obtain 	 	 	\frac{dg}{dz_j}(\z) 	= 	& 	\lim_{\snorm{h} \rightarrow 0^{+}} 	\frac{ 		\dotp{f(\z + h \boldsymbol{e}_j)}{f(\overline{\z + h \boldsymbol{e}_j})}_X 		- 		\dotp{f(\z)}{f(\overline{\z})}_X 	}{h}  	\\ 	= 	& 	\lim_{\snorm{h} \rightarrow 0^+} 	\frac{ 		\dotp{f(\z + h \boldsymbol{e}_j)}{f(\overline{\z + h \boldsymbol{e}_j})}_X 		- 		\dotp{f(\z)}{f(\overline{\z + h \boldsymbol{e}_j})}_X 	}{h}  	\\ 	& 	+ 	\lim_{\snorm{h}\rightarrow 0^+} 	\frac{ 		\dotp{f(\z)}{f(\overline{\z + h \boldsymbol{e}_j})}_X 		- 		\dotp{f(\z)}{f(\overline{\z})}_X 	}{h}  	\\ 	= 	& 	\lim_{\snorm{h} \rightarrow 0^+} 	\dotp{ 		\frac{ 			f(\z + h \boldsymbol{e}_j)-f(\z) 		}{h} 	}{f(\overline{\z + h \boldsymbol{e}_j})}_X 	\\ 	& 	+ 	\lim_{\snorm{h} \rightarrow 0^+} 	\dotp{ 		f(\z) 	} 	{ 		\frac{ 			f(\overline{\z+h \boldsymbol{e}_j})-f(\overline{\z}) 		}{ 			\overline{h} 		} 	}_X. 	 	 	Exploiting the continuity of the inner product in each argument and that it is 	anti-linear in the second argument, yields   	\frac{dg}{dz_j}(\z) 	= 	& 	\dotp{ 		\lim_{\snorm{h} \rightarrow 0^+} 		\frac{ 			f(\z+h \boldsymbol{e}_j)-f(\z) 		}{h} 	}{f(\overline{\z})}_X 	\\ 	& 	+ 	\dotp{ 		f(\z ) 	} 	{ 		\lim_{\snorm{h}\rightarrow 0^+} 		\frac{ 			f(\overline{\z+h \boldsymbol{e}_j})-f(\overline{\z}) 		}{ 			\overline{h} 		} 	}_X.   	Observing that 	 	\lim_{\snorm{h}\rightarrow 0^+} 	\frac{ 		f(\overline{\z+h \boldsymbol{e}_j})-f(\overline{\z}) 	}{ 		\overline{h} 	} 	= 	\lim_{\snorm{h}\rightarrow 0^+} 	\frac{ 		f(\overline{\z}+h\boldsymbol{e}_j)-f(\overline{\z}) 	}{ 		h 	} 	= 	\frac{df}{dz_j}(\overline{\z}), 	 	implies 	 	\frac{dg}{dz_j}(\z) 	= 	\dotp{\frac{df}{dz_j}(\z)}{f(\overline{\z})}_X 	+ 	\dotp{f(\z)}{\frac{df}{dz_j}(\overline{\z}))}_X, 	\quad 	\z \in \mathcal{O}_{\boldsymbol\rho}. 	 	Observe that, similarly as with \cref{eq:hol_ext_norm}, 	the expression in \cref{eq:complex_der_norm} is well-defined 	for any $\z \in \mathcal{O}_{\boldsymbol\rho} $ 	since this implies $\overline{\z} \in \mathcal{O}_{\boldsymbol\rho} $.",2502.01859
lemma,"It holds   \snorm{ \norm{     u_h^{(s)}     -     \mathsf{P}_{X_{h,s,N,J}^{(\normalfont\text{rb})}}     u_h^{(s)}     }^2_{L^2(\mathbb{U}^{(s)};X)} 	- 	\varepsilon_{h,s,N,J} 	\left( 		X_{h,s,N,J}^{(\normalfont\text{rb})} 	\right) } 	\lesssim 	N^{-\alpha}.  Here, we obtain $\alpha=1-\delta$ for any $\delta\in(0,1)$ for the the Halton sequence  under the assumption $p \in (0,\frac{1}{3})$  and $\alpha=\frac{1}{p}$ for the IPL sequences. In the former case, the implicit constant in \cref{eq:PODerror} depends on $\delta$,  and tends to infinity as $\delta\rightarrow 1^+$.",2502.01859
lemma,"It holds      \varepsilon_{h,s,N}     \Big(X_{h,s,N,J}^{(\normalfont\text{rb})}\Big)     \lesssim     N^{-\alpha}     +     J^{-2\left(1/p-1\right)}  with the same considerations as stated in \Cref{cor:contest} for $\alpha$ and the hidden constant in \cref{eq:error_bound_quad}.",2502.01859
lemma,"Assume that $\boldsymbol{b} \in \ell^{p}(\mathbb{N})$ is strictly decreasing. For each $n \in \mathbb{N}$, $n\geq s$, there exists a tanh NN $\boldsymbol{\pi}^{\normalfont\text{(rb)}}_{n} \in \mathcal{N\!N}_{D,W,s,2J}$ and $C>0$ such that  	\norm{ 		\boldsymbol{\pi}^{\normalfont\text{(rb)}}_{J,\mathbb{R}} 		- 		\boldsymbol{\pi}^{\normalfont\text{(rb)}}         _{n} 		\circ 		\mathcal{T}_s 	}_{L^2(\mathbb{U};\mathbb{R}^{2J})} 	\lesssim     J     n^{-\left(1/p - 1/2\right)}     +     s^{-\left(1/p-1\right)}  with  $ 	D 	= 	\mathcal{O} 	\left( 		\log_2(n) 	\right) $ and $ 	W 	= 	\mathcal{O}(n^2) $.",2502.01859
lemma,"Let $X$ be a complex Hilbert space equipped with the inner product $\dotp{\cdot}{\cdot}_X$ and induced norm $\norm{\cdot}_X$.     Let $\mathbb{U} \ni \y \mapsto f(\y) \in X$ be $(\boldsymbol{b},p,\varepsilon)$-holomorphic and continuous continuous map  	when $\mathbb{U}$ 	is equipped with the product topology. 	Then the map 	 	\mathbb{U} 	\ni 	\y 	\mapsto     \norm{     f(\y)     }^2_{X} 	\in 	\IR 	 	is $(\boldsymbol{b},p,\varepsilon)$-holomorphic 	and continuous with the same 	$\boldsymbol{b} \in \ell^p(\IN)$, $p \in (0,1)$, 	and $\varepsilon>0$.",2502.01859
lemma,"[{Adaption of \cite[Lemma 7]{HPS16}}] 	Assume that $\mathbb{U} \ni \y \mapsto f(\y) \in \mathbb{R}$ is 	$(\boldsymbol{b},p,\varepsilon)$-holomorphic 	for some $\boldsymbol{b} \in \ell^p(\IN)$, $p\in(0,\frac{1}{3})$, and assume that the sample points in \cref{eq:MC} are drawn according to the Halton sequence. 	Then 	$$ 	\snorm{ 		\mathcal{I}^{(s)}(f) 		- 		\mathcal{Q}^{(N,s)}(f) 	} 	\leq 	C(\delta) N^{\delta-1}, 	$$ 	where $C(\delta) \rightarrow \infty$ as $\delta \rightarrow 0$.",2502.01859
lemma,"[{\cite[Theorem 3.1]{DKL14}}] 	For $m\geq1$ and a prime $\normalfont\text{b}$, let $N= \normalfont\text{b}^m$ denote the number of HoQMC points. 	Let $s\geq1$ and $\boldsymbol{\beta} = \{\beta_j\}_{j\in \mathbb{N}}$ be a positive number sequence, and let-$\boldsymbol{\beta}_s = \{\beta_j\}_{j=1}^{s}$ denote the first $s$ terms. 	Assume that $\boldsymbol{\beta} \in \ell^p(\mathbb{N})$ for some $p\in(0,1)$. 	If there exists $c>0$ such that a function $F$ satisfies for $\alpha\coloneqq  \left\lfloor \frac{1}{p} \right\rfloor +1$ that 	 	\snorm{\left(\partial^{\boldsymbol{\nu}}_\y F\right)(\y)}  	\leq  	c\snorm{\boldsymbol{\nu}}! \boldsymbol{\beta}^{\boldsymbol\nu}_s,  	\quad 	\text{for all } 	\boldsymbol{\nu} \in \{0,1,\dots,\alpha\}^s,  	\quad  	s\in \mathbb{N}, 	 	then the interlaced polynomial lattice rule of order $\alpha$ with $N$ points can be constructed in  	 	\mathcal{O}\left(\alpha s N \log N + \alpha^2 s^2N\right) 	 	operations, such that for the quadrature error holds 	 	\snorm{\mathcal{I}^{(s)}(f) - \mathcal{Q}^{(N,s)}(f)}  	\leq  	C_{\alpha,\boldsymbol{\beta},b,p} N^{-1/p} 	 	where the constant $C_{\alpha,\beta,b,p}<\infty$ is independent of $s$ and $N$.",2502.01859
theorem,"Given a $d$-polytope $P$, it is inscribable if and only if we can construct a matrix                      X =                  1 & \mymathbb{1}_n^\top & \mymathbb{1}_m^\top\\                 \mymathbb{1}_n & A & S\\                 \mymathbb{1}_m & S^\top & B              \succeq 0                  of rank $d+1$, with all diagonal elements of $A$ being the same constant, all elements of $S$ being nonnegative, and $S$ having the same support as a slack matrix of $P$.",2502.01878
theorem,"For all $n \ge 3$ and the choice of weights $\lambda_{ij} = \overline{\lambda} = \frac{2}{n}\sec^2\frac{\pi}{n}, (i,j)\notin I^z$, problem~\eqref{pro:sdp_ori} has an optimal solution of rank $3$ that certifies inscribability of the $n$-gon.",2502.01878
theorem,"For all $d \geq 2$ and the choice of weights $\lambda_{ij} = \overline{\lambda}= \frac{2d^2}{d+1}, (i,j)\notin I^z$, problem~\eqref{pro:sdp_ori} has an optimal solution of rank $d+1$ that certifies inscribability of the $d$-simplex.",2502.01878
theorem,"For all $d \ge 2$ and the choice of weights $\lambda_{ij} =  \overline{\lambda}= d2^{1-d}, (i,j)\notin I^z$, problem~\eqref{pro:sdp_ori} has an optimal solution of rank $d+1$ that certifies inscribability of the $d$-cube.",2502.01878
theorem,"For all $d \ge 2$ and the choice of weights $\lambda_{ij} =  \overline{\lambda}= 1, (i,j)\notin I^z$, problem~\eqref{pro:sdp_ori} has an optimal solution of rank $d+1$ that certifies inscribability of the $d$-cross-polytope.",2502.01878
proof,See \cite{gouveia2019slack} and \cite[Corollary 1.5]{gouveia2017four}.              $\hfill\qed$,2502.01878
proof,"Without loss of generality, we suppose that $P$ is inscribed in the unit sphere $\mathcal{S}^{d-1}$ and $\alpha e_1^{(d)}$ is in the interior of $P$, where $|\alpha|<1$.  Inspired by \cite[p. 285]{grunbaum2003convex}, we consider the projective transformation $g:\mathbb{R}^d\to\mathbb{R}^d$ defined by                      g(x) = g(x_1,\ldots,x_d) = \left[\frac{x_1-\alpha}{1-\alpha x_1},\frac{\sqrt{1-\alpha^2}x_2}{1-\alpha x_1},\ldots,\frac{\sqrt{1-\alpha^2}x_d}{1-\alpha x_1}\right]^\top.                  Then, $g(x)\in\mathcal{S}^{d-1}$ for all $x\in\mathcal{S}^{d-1}$ and $g(\alpha e_1^{(d)})=\mymathbb{0}_d$.      $\hfill\qed$",2502.01878
proof,"We first assume that the $d$-polytope $P$ is inscribable.  Moreover, we suppose that $P$ inscribed in a sphere with radius $a$, with vertices $v_1,\ldots,v_n\in\mathbb{R}^d$ and facets cut out by inequalities $1-h_1^\top x\ge 0,\ldots,1-h_m^\top x\ge 0$ with $h_1,\ldots,h_m\in\mathbb{R}^d$.  Denote matrices $V=[v_1\cdots v_n]\in\mathbb{R}^{d\times n}$ and $H=[h_1\cdots h_m]\in\mathbb{R}^{d\times m}$.  Then, we have $v_i^\top v_i=a^2,i=1,\ldots,n$.  Since $P$ is a $d$-polytope, we have $\mathrm{rank}([\mymathbb{1}_n~V^\top])=\mathrm{rank}([\mymathbb{1}_m~-H^\top])=d+1$ and thus the slack matrix of $P$, denoted by $S$, has rank $d+1$ \cite[Theorem 14]{gouveia2013nonnegative}.                    Denote the matrix                      W =                  1 & \mymathbb{0}_d^\top\\                 \mymathbb{1}_n & V^\top\\                 \mymathbb{1}_m & -H^\top             .                  Notice that $W$ also has rank $d+1$.  Then,                      WW^\top =                  1 & \mymathbb{1}_n^\top & \mymathbb{1}_m^\top\\                 \mymathbb{1}_n & \mymathbb{1}_{n\times n}+V^\top V & S\\                 \mymathbb{1}_m & S^\top & \mymathbb{1}_{m\times m}+H^\top H             \succeq 0                  has rank $d+1$ and all diagonal elements in the block $\mymathbb{1}_{n\times n}+V^\top V$ equal $a^2+1$, and thus is the desired matrix $X$.          For the other direction, suppose that there exists a matrix                      X =                  1 & \mymathbb{1}_n^\top & \mymathbb{1}_m^\top\\                 \mymathbb{1}_n & A & S\\                 \mymathbb{1}_m & S^\top & B              \succeq 0                  of rank $d+1$, with all diagonal elements of $A$ being the same constant, all elements of $S$ being nonnegative, and $S$ having the same support as a slack matrix of $P$.  Since $X\succeq 0$ and has rank $d+1$, there exist a matrix $M\in\mathbb{R}^{(n+m+1)\times (d+1)}$ with rank $d+1$ such that $X=MM^\top$.  Denote                       M =                  r_1^\top\\                 \vdots\\                 r_{n+m+1}^\top             .                  Then we have $r_1^\top r_1=1$.  Thus, there exists an orthogonal matrix $Q\in\mathbb{R}^{(d+1)\times (d+1)}$ such that $Qr_1=e_1^{(d+1)}$.  Since $MQ^\top QM^\top=MM^\top=X$, without loss of generality, we suppose that $r_1=e_1^{(d+1)}$.  Then from the first row of $X$ we get $r_1^\top r_i=1,i=1,\ldots,n+m+1$, which implies that the first element of all $r_i,i=1,\ldots,n+m+1$ must equal 1.  That is, matrix $M$ has the form                      M =                  1 & \mymathbb{0}_d^\top\\                 \mymathbb{1}_n & M_1^\top\\                 \mymathbb{1}_m & -M_2^\top             ,                  for some $M_1\in\mathbb{R}^{d\times n}$ and $M_2\in\mathbb{R}^{d\times m}$.                    Denote $M_1=[v_1\cdots v_n]$ and $M_2=[h_1\cdots h_m]$.  We claim that polytope $P_M=\mathrm{conv}\{v_1,\ldots,v_n\}$ is a $d$-polytope inscribed in a sphere, with vertices $v_1,\ldots,v_n$ and facets cut out by inequalities $1-h_1^\top x\ge 0,\ldots,1-h_m^\top x\ge 0$, and is combinatorially equivalent to $P$, which implies that $P$ is inscribable.                    Indeed, by \cite[Lemma 3.1]{gouveia2019slack}, $S$ has rank no less than $d+1$.  Since $\mathrm{rank}(S)\le\mathrm{rank}(X)=d+1$, we get $\mathrm{rank}(S)=d+1$.  From the fact that $\mathrm{rank}(X)=\mathrm{rank}(S)=d+1$ and the structure of $X$, we have $\mymathbb{1}_n$ in the column span of $S$.  Therefore, from \cite[Theorem 2.2]{gouveia2019slack}, we obtain that $S$ is a slack matrix of some realization of $P$.           Using \cite[Lemma 5 and Theorem 6]{gouveia2013nonnegative}, we have $S$ is a slack matrix of the cone generated by $             1\\             v_1         ,\ldots,             1\\             v_n         $ with an $\mathcal{H}$-representation formed by $             1\\             h_1         ,\ldots,             1\\             h_m         $.  Thus, from \cite[Theorem~14]{gouveia2013nonnegative} and the paragraph before it, we have $\{1\}\times P_M$ is isomorphic to $\mathrm{conv}(\mathrm{rows}(S))$ and so isomorphic to $P$, which implies that $P_M$ is isomorphic to $P$.  The proof is complete by noticing that all diagonal elements of $A= \mymathbb{1}_{n\times n}+M_1^\top M_1$ are constant which implies that $P_M$ is inscribed in a sphere.      $\hfill\qed$",2502.01878
proof,"For the $w^*$ given above, $M$ is the circulant matrix whose first row is         $$\frac{1}{n\cos^2\frac{\pi}{n}}\left(n-2, -2, -2, \cdots , -2, n-2 \right),$$         so $\lambda_{\max}(MM^\top)=4\sec^2\frac{\pi}{n}$ (see Appendix \ref{app:ngons_eigv} for details). Therefore, we have         $$4+4\overline{u}= 4+4\tan^2\frac{\pi}{n} = 4\sec^2\frac{\pi}{n} = \lambda_{\max}(MM^\top)  $$         which as we saw in \eqref{eq:simpl_dualfea} implies dual feasibility.      $\hfill\qed$",2502.01878
proof,"For the $w^*$ given above, $M$ is the circulant matrix whose first row is $$\frac{2d}{d+1}\left(-d, 1, 1, \cdots , 1, 1 \right),$$ so $\lambda_{\max}(MM^\top)=4d^2$ (see Appendix \ref{app:simplices_eigv} for details).  Therefore, we have $$4+4\overline{u}= 4d^2 = \lambda_{\max}(MM^\top)$$ which as we saw in \eqref{eq:simpl_dualfea} implies dual feasibility.      $\hfill\qed$",2502.01878
proof,"For the $w^*$ given above, $M$ is the matrix whose $2^n$ columns are all possible $\pm 1$ vectors of length $n$, multiplied by $d2^{1-d}$.  For this matrix $\lambda_{\max}(MM^\top)=\left(d2^{1-d}\right)^22^{d+1} = d^22^{3-d}$ (see Appendix \ref{app:cubescrosspolytopes_eigv} for details).  Therefore, we have $$4+4\overline{u}= 4d^22^{1-d} =  \lambda_{\max}(MM^\top)$$ which as we saw in \eqref{eq:simpl_dualfea}, implies dual feasibility.      $\hfill\qed$",2502.01878
proof,"Notice that $M$ is the transpose of the matrix $M$ in the proof of Lemma \ref{lem:cube} divided by $d2^{1-d}$, we have $\lambda_{\max}(MM^\top)=2^{d+1}$.  Therefore, \eqref{eq:simpl_dualfea} is still verified and implies dual feasibility.      $\hfill\qed$",2502.01878
lemma,Projective transformations preserve the combinatorial type of a polytope and the support of its slack matrix.,2502.01878
lemma,"(Inspired by \cite[p. 285]{grunbaum2003convex})         If $P$ is inscribed in a sphere, then we can apply a projective transformation that carries the sphere onto itself and maps an interior point of $P$ to the origin.",2502.01878
lemma,"Suppose $M$ is a symmetric matrix of the form                      M=                              M_1 & M_2\\                 M_2^\top & M_3             .                  Then $M\succeq 0$ if and only if $M_3\succeq 0$, $\mathrm{range}(M_2^\top)\subseteq\mathrm{range}(M_3)$, and $M_1-M_2 M_3^\dagger M_2^\top\succeq 0$.",2502.01878
lemma,"For the given polygon and weights, the pair $(u^*,w^*)$ given by                  		u_i^* = \overline{u}= \tan^2\frac{\pi}{n}, i=1,\ldots,n,~~~\text{and}~~~w_j^* = \overline{w}=\frac{n-2}{n\cos^2\frac{\pi}{n}}, j=1,\ldots,\left|I^z\right|,     	         is feasible for problem \eqref{pro:sdp_dual}.",2502.01878
lemma,"For the given polytope and weights, the pair $(u^*,w^*)$ given by                          u_i^*  = \overline{u}= -1+d^2, i=1,\ldots,n,~~~\text{and}~~~w_i^* = \overline{w}= \frac{2d}{d+1}, i=1,\ldots,\left|I^z\right|,     	         is feasible for problem \eqref{pro:sdp_dual}.",2502.01878
lemma,"For the given polytope and weights, the pair $(u^*,w^*)$ given by                      u_i^*  = -1 + d^22^{1-d}, i=1,\ldots,n,~~~\text{and}~~~w_i^* = d2^{1-d}, i=1,\ldots,\left|I^z\right|,	     	         is feasible for problem \eqref{pro:sdp_dual}.",2502.01878
lemma,"For the given polytope and weights, the pair $(u^*,w^*)$ given by                      u_i^* = -1 + 2^{d-1}, i=1,\ldots,n,~~~\text{and}~~~w_i^* = 1, i=1,\ldots,\left|I^z\right|,	     	         is feasible for problem \eqref{pro:sdp_dual}.",2502.01878
theorem,"[adapted from Theorem $1$ in \cite{Campo2017}]Under the conditions \eqref{eq:equation_4}, the dynamical system \eqref{eq:equation_1} with nonnegative initial conditions has four steady states in the region of biological interest $\mathbb{R}^2_+\setminus\{(0, 0)\}$, namely:       \item one nodal repeller $(K_b, 0)$ where              K_b = \dfrac{r_1K_0+\psi_1K_1-\sqrt{(r_1K_0+\psi_1K_1)^2-4r_1K_0K_1(\psi_1+\delta_1)}}{2r_1}>0,          indicates the MVPS threshold for species $S_1$;     \item one saddle point $(S_1^*, S_2^*)$ of unstable coexistence of both species with coordinates given by              S_1^* =& \dfrac{K_0\left[\psi_1(K_1-K_2)+\delta_1(K_1+K_2)\right]}{\psi_1(K_1-K_2)+\delta_1K_2}>0,\\         S_2^* =& K_2-S_1^*>0;          \item two nodal attractors $(0,K_2)$ and $(K_*,0)$, where              K_* = \dfrac{r_1K_0+\psi_1K_1+\sqrt{(r_1K_0+\psi_1K_1)^2-4r_1K_0K_1(\psi_1+\delta_1)}}{2r_1}>0,          defines the carrying capacity of the first species. Only one of these steady states can be reached when $t\to \infty$ according to the initial conditions $S_1(0) > 0$, $S_2(0) > 0$ assigned to the system \eqref{eq:equation_1}, namely:              \item[-]If $S_1(0) > K_b$ and $S_2(0) > 0$ then $(K_*,0)$ is reachable when $t\to \infty$ and the species $S_1$ should persist while the species $S_2$ become extinct.         \item[-]  If $S_1(0) < K_b$ and $S_2(0) > 0$ then $(0,K_2)$ is reachable when $t\to \infty$ and the species $S_2$ should persist while the species $S_1$ become extinct.",2502.01879
theorem,"{\rm (}Comparison theorem {\rm \cite{Laksh1989})}: Let $m \in \mathcal{V}_0$, and assume that       D^+m(t) \leq v(t,m(t)), \qquad t \neq t_k, \quad k = 1,2,...\\\nonumber     m(t_k^+) \leq \varphi_k(m(t_k)), \qquad t = t_k, \quad k = 1,2,... where $\varphi_k \in \mathcal{C}(\mathbb{R},\mathbb{R})$ and $\varphi_k(u)$ is non-decreasing in $u$ for each $k =1, 2,. . .$. Let $\varrho(t)$ be a maximal solution of the scalar impulsive differential equation \nonumber     \dot u(t) &= v(t,u), \qquad t \neq t_k, \quad k = 1,2,...\\     u(t_k^+)  &= \varphi_k(u(t_k)), \quad t = t_k, \quad t_k>t_0\geq0, \quad k = 1,2,...\\     u(t_0) &= u_0,\nonumber  which exists on $[t_0, \infty)$. Then, $m(t_0^+) \leq u_0$ implies that $m(t) \leq \varrho(t)$ for $t \geq t_0$. A similar result can be obtained when all the directions of the inequalities in the theorem are reversed and $\varphi_k(u)$ is non-increasing.",2502.01879
theorem,"Given the auxiliary system \eqref{eq:equation_15}, consider $Z_2(0) \geq 0$ and $u_k \in U$. Then, there exists a unique positive $\tau$-periodic solution $\Bar{Z}_2(t)$, expressed by:      \Bar{Z}_2(t) = \dfrac{K_2 Z_2^{+} e^{r_2 (t-k\tau)}}{Z_2^{+}\left(e^{r_2 (t-k\tau)} -1\right) + K_2}, \quad k\tau < t \leq (k+1)\tau, \, k \geq 0,  where,     Z_2^+ = \frac{1}{2}\left[ (u_k + K_2) + \sqrt{(u_k + K_2)^2 + 4 u_k K_2 e^{r_2 \tau} - 4 u_k K_2} \right], \quad k \geq 0.   Furthermore, the solution $\Bar{Z}_2(t)$ is globally asymptotically stable.",2502.01879
theorem,"Let $(S_1(t),S_2(t))$ be a solution of system \eqref{eq:equation_1}-\eqref{eq:equation_2}, with positive parameters, $u_k \in U$ and non-negative initial conditions. Then $(S_1(t),S_2(t))$ is uniformly  bounded.",2502.01879
theorem,"Let $S_1$ and $S_2$ be non-negative initial conditions, and $u_k \in U$. Then, $(0, \Bar{S_2}(t))$ is the unique positive $\tau$-periodic, $S_1$-free solution of system \eqref{eq:equation_1}-\eqref{eq:equation_2}.",2502.01879
theorem,"The $S_1$-free periodic solution $(0,\Bar{S}_2(t))$ of the system \eqref{eq:equation_1}-\eqref{eq:equation_2} is locally asymptotically stable.",2502.01879
theorem,"The $S_1$-free periodic solution $(0,\Bar{S}_2(t))$ is globally asymptotically stable if,      S_2(t)>K_1.",2502.01879
theorem,"[Existence of Optimal Control]     Consider the problem described in \eqref{eq:equation_46}-\eqref{eq:equation_49}. If the following conditions are satisfied:      \item The set of admissible controls $ \bar{U} $ is non-empty and compact;     \item The control system \eqref{eq:equation_47}-\eqref{eq:equation_48} is well-posed for each $ u_k \in \bar{U} $;     \item The solutions of the system \eqref{eq:equation_47}-\eqref{eq:equation_48} are uniformly bounded for each $ u_k \in \bar{U} $;     \item The cost functional $ J(u) = C \sum_{k=1}^{N} u_k $ is continuous in $ u $.  Then, there exists an optimal control $ u^* = (u^*_k)_{k=1}^{N} $ with $ u^*_k \in \bar{U} $ that minimizes the cost functional $ J(u) $, satisfying the dynamic equations and constraints of the problem.",2502.01879
definition,"{\rm (\cite{Laksh1989})}     Let $V : \mathbb{R}_+ \times \mathbb{R}^2_+\to \mathbb{R}_+$, then $V$ is said to belong to class $\mathcal{V}_0$ if is continuous on $(k\tau, (k + 1)\tau] \times \mathbb{R}^2_+$ and        \lim\limits_{(t, y) \to (k\tau^+, x)} V(t, y) = V(k\tau^+, x),       exists and is finite.",2502.01879
definition,"{\rm (\cite{Laksh1989})} Let $V \in \mathcal{V}_0$. Then for $V(t, x) \in (k\tau, (k + 1)\tau] \times \mathbb{R}^2_+$, the upper right derivative of $V(t,x)$ with respect to the impulsive differential system \eqref{eq:equation_1}-\eqref{eq:equation_2} is defined as      D^+ V(t,x) = \lim_{h \to 0} \sup{\frac{1}{h}\left[V(t+h,x+hg(t,x))-V(t,x)\right]}.",2502.01879
definition,"{\rm (\cite{Laksh1989})} Let $\varrho(t) = \varrho(t, t_0, x_0)$ be a solution of system \eqref{eq:equation_1}-\eqref{eq:equation_2} on $[t_0, t_0 + l)$. Function $\varrho(t)$ is called the maximal solution of system \eqref{eq:equation_1}-\eqref{eq:equation_2} if for any solution $x(t, t_0, x_0)$ of the system \eqref{eq:equation_1}-\eqref{eq:equation_2} existing on $[t_0, t_0 + l)$, it is verified $x(t) \leq \varrho(t) $, $t \in [t_0, t_0 + l)$.",2502.01879
proof,"Note that $\dfrac{dS_1}{dt} = 0$ if $S_1(t) = 0$. Therefore, if $S_1(0) \geq 0$, we have $S_1(t) \geq 0$ for all $t \geq 0$. Similarly, if $S_2(0) \geq 0$, then $S_2(t) \geq 0$ for all $t \geq 0$.",2502.01879
proof,"Suppose $(S_1(t), S_2(t))$ is a solution to the system \eqref{eq:equation_1}-\eqref{eq:equation_2}. It is continuous in the intervals $(k\tau, (k+1)\tau]$ for $k \geq 0$, indicating that it remains continuous between each pair of pulses. Furthermore, there exist limits defined as follows:      S_1(k\tau^+) = \lim_{\epsilon \to 0^+} S_1(k\tau + \epsilon) \text{ and } S_2(k\tau^+) = \lim_{\epsilon \to 0^+} S_2(k\tau + \epsilon).  Consequently, the existence and uniqueness of these solutions are guaranteed by the smoothness of the functions      &g_1(S_1, S_2) = S_1\left(\psi_1 - \frac{r_1}{K_1}(S_1 + S_2)\right)\left(\frac{S_1}{K_0} - 1\right) - \delta_1 S_1,\\     &g_2(S_1, S_2) = S_2\left(\psi_2 - \frac{r_2}{K_2}(S_1 + S_2)\right) - \delta_2 S_2.",2502.01879
proof,"For every solution $Z_2(t)$ of the system \eqref{eq:equation_15}, we have $Z_2(t) \to \Bar{Z}_2(t)$ as  $t \to \infty$  follows directly from the Theorem \eqref{thm:thm_3} that establishes the global asymptotic stability of  $\Bar{Z}_2(t)$.",2502.01879
proof,"By hypothesis, the initial conditions are non-negative, by \eqref{prop:prop_1}, we have that $S_1(t)$ and $S_2(t)$ are lower bounded by zero, for all $t \geq 0 $, and by the Lemma \eqref{lem:lem_1}, $K_*>0$ is an upper bound for $S_1(t)$. Now, we will show that $S_2(t)$ is also upper bounded. To do this, first consider the second and fourth equation of the system \eqref{eq:equation_1}-\eqref{eq:equation_2}, from which we get      \dfrac{dS_2}{dt}(t) \leq \dfrac{dZ_2}{dt}(t) \mbox{ and } S_2(0) = Z_2(0),   where $Z_2$ satisfies \eqref{eq:equation_15} and $Z_2(t)$ is bounded, since that for $t \neq k\tau$, the solution of the continuous ODE is bounded by $\max\{K_2, S_2(0)\}$, where $K_2$ represents the environmental carrying capacity. At the instants $t = k\tau$, the impulses add a term $u_k \in U$, which is upper-bounded by $u_{\max}$. Thus, immediately after the impulse, $Z_2(t^+) \leq \max\{K_2, S_2(0)\}+u_{\max}$. Therefore, $Z_2(t)$ remains bounded over time. By the Theorem \eqref{thm:thm_2} we have,      S_2(t)\leq Z_2(t).  Let $M_2 := \max\{K_2, S_2(0)\}+u_{\max}$, then $S_2(t)\leq M_2$ for all $t \geq 0$.  To show that the solutions are uniformly bounded, consider $V(t) = S_1(t)+S_2(t)$. Then, $V(t) \in \mathcal{V}_0$ and for some $\lambda >0$ and $k\tau \leq t \leq (k+1)\tau$, \nonumber     D^+V(t)+\lambda V(t) &= D^+S_1(t)+D^+S_2(t) + \lambda(S_1(t)+S_2(t)),\\\nonumber     &= S_1(t)\left(\psi_1-\dfrac{r_1}{K_1}(S_1(t)+S_2(t))\right) \left(\dfrac{S_1(t)}{K_0} - 1 \right) - \delta_1 S_1(t)\\\nonumber &+ S_2(t)\left(\psi_2-\dfrac{r_2}{K_2}(S_1(t)+S_2(t))\right) - \delta_2 S_2(t) + \lambda(S_1(t)+S_2(t))\\     & \leq (r_1 +\lambda)K_*+(r_2 +\lambda)M_2 := M_3.  When $t = k\tau$, we have $V(k\tau^+) = V(k\tau)+u_k$, for $u_k \in U$. Then, by the Lemma 2.2 in \cite{Bainov1993}, \nonumber     V(t)&\leq V(0) e^{-\lambda t} +\int_0^t M_3 e^{-\lambda (t-s)}\,ds + \sum_{0 \leq k\tau \leq t} u_k e^{-\lambda(t-k\tau)},\\     &\leq V(0) e^{-\lambda t} +\dfrac{M_3}{\lambda}(1-e^{-\lambda t})+\sum_{0 \leq k\tau \leq t} u_{max}e^{-\lambda(t-k\tau)}. Thus, when $t \to \infty$      V(t) \leq \dfrac{M_3}{\lambda} + u_{max}\dfrac{e^{\lambda \tau}}{(e^{\lambda \tau}-1)}.  In this way, we have $V(t)$ uniformly bounded and due to its definition, we have that each positive solution $S_1(t)$ and $S_2(t)$ of the system \eqref{eq:equation_1}-\eqref {eq:equation_2} is uniformly bounded.",2502.01879
proof,"Note that when $S_1(t) = 0$, we have $\dfrac{dS_2}{dt} = \dfrac{dZ_2}{dt}$, where $\dfrac{dZ_2}{dt}$ corresponds to the first equation of system \eqref{eq:equation_15}, with solution given by \eqref{eq:equation_61}. Therefore, by applying Theorem \eqref{thm:thm_3}, we conclude that $(0, \Bar{S_2}(t))$ is the unique periodic $S_1$-free solution of system \eqref{eq:equation_1}-\eqref{eq:equation_2}, where $\Bar{S_2}(t) = \bar{Z}_2(t)$ for all $t \geq 0$.",2502.01879
proof,"As a consequence of the second equation of the model, we obtain \eqref{eq:equation_1} that,   \dfrac{dS_2}{dt}\leq\left(\psi_2-\dfrac{r_2}{K_2}S_2\right)S_2- \delta_2 S_2,     then we can use the auxiliary system \eqref{eq:equation_15} for comparison, which we saw in the Corollary \eqref{cor:cor_1} that,      \lim_{t \to \infty} Z_2(t) = \Bar{Z}_2(t).  Thus, for small enough $\epsilon>0$, there exists $t_1>0$ such that       Z_2(t)<\Bar{Z}_2(t)+\epsilon, \mbox{ for all } t>t_1.  As $S_2(t) \leq Z_2(t)$, $Z_2(t) < \Bar{Z}_2(t)+\epsilon$ and $S_2(0) = Z_2(0)$, it follows from the Comparison Theorem \eqref{thm:thm_1} that      S_2(t)\leq\Bar{Z}_2(t)+\epsilon,  \forall t>t_1.  Furthermore, since we are considering $S_1(0)>K_b >K_0$, then $\left(\frac{S_1}{K_0} - 1\right)>0$, as we want stability for the equilibrium solution $S_1(t) = 0$, we must adjust $-\frac{r_1}{K_1}S_2(t)$ such that      \left(\psi_1 - \dfrac{r_1}{K_1}(S_1+S_2)\right)\left(\dfrac{S_1}{K_0} - 1\right) < \delta_1, then      \psi_1 - \dfrac{r_1}{K_1}(S_1+S_2) < \dfrac{\delta_1}{\left(\dfrac{S_1}{K_0} - 1\right)},  and for large enough $S_1$,       \psi_1 - \dfrac{r_1}{K_1} S_2 < \delta_1,      that is        S_2 > K_1, since $r_1 = \psi_1 - \delta_1$ by model hypothesis. Then, replacing \eqref{eq:equation_32} in the first equation of system \eqref{eq:equation_1} we have,      \dfrac{dS_1}{dt} \leq S_1\left[\left(\psi_1 - \dfrac{r_1}{K_1}(S_1+K_1)\right)\left(\dfrac{S_1}{K_0} - 1\right) - \delta_1\right],  in this way we can consider the next equation for comparison        \dfrac{dZ_1}{dt} = Z_1\left[\left(\psi_1 - \dfrac{r_1}{K_1}(Z_1+K_1)\right)\left(\dfrac{Z_1}{K_0} - 1\right) - \delta_1\right],\\     Z_1(0) = S_1(0),   which $Z_1(t) \to 0$ as $t \to \infty$. Consequently, by the Comparison Theorem, if condition \eqref{eq:equation_32} is satisfied, then for a sufficiently small $\epsilon>0$, there exists $t_2>t_3$ such that       S_1(t) \leq Z_1(t) \leq \epsilon, \, t>t_2.  Now, substituting $S_1(t) \leq \epsilon$ in the second equation of system \eqref{eq:equation_1} we have,   \dfrac{dS_2}{dt}(t)\geq S_2\left(\psi_2-\dfrac{r_2}{K_2}\left(\epsilon+S_2\right)\right)-\delta_2S_2, \quad t \neq k\tau, \ k \geq 0  \\     S_2(t^+)=S_2(t) + u_k,  \qquad t = k\tau, \ u_k \in U\\ S_2(0^+)=S_2(0).   Due to the continuity of the right side of the equation and analogously to the \eqref{thm:thm_3}, we conclude that for $\epsilon>0$ small enough, there exists $t_3>t_2$ such that       \Bar{S}_2(t)-\epsilon \leq S_2(t),\mbox{ } t>t_3.  Finally, if \eqref{eq:equation_32} is satisfied, then for $\epsilon>0$ we have,       0\leq S_1(t) \leq \epsilon \mbox{ and }  \Bar{S}_2(t)-\epsilon \leq S_2(t) \leq \Bar{S}_2(t)+\epsilon, \mbox{ } t>t_3.   Letting $\epsilon \to 0$,      S_1(t) \to 0 \mbox{ and } S_2(t) \to \Bar{S}_2(t), \mbox{ as } t \to \infty.  Therefore, if \eqref{eq:equation_32} is fulfilled, then $(0, \Bar{S}_2(t))$ is globally asymptotically stable.",2502.01879
proof,"Indeed the function $\eta(\tau)$ is continuous and differentiable on the interval $[0, \infty)$. When $\tau \to 0$, $\phi(\tau) \to K_1$ and $\eta(\tau) \to 0$, and as $ \tau \to \infty$, $\phi(\tau) \to 0$ and  $\eta(\tau)0\to 0$. Despite the interval being unbounded above, the behavior of $\eta(\tau)$ suggests that it attains a local maximum, implying that the supremum exists at some point $\tau = \tau_{\text{max}}$.",2502.01879
proof,"In Section \eqref{subs:behavior}, we showed that the system of equations \eqref{eq:equation_47}-\eqref{eq:equation_48} is well-posed for any $ u_k \in U $. Since $ \bar{U} \subset U $, we conclude that the system is also well-posed for any $ u_k \in \bar{U} $, ensuring the existence of a unique solution.      By hypothesis, we have $ u_k \geq \sup\limits_{0 < \tau \leq T} \eta(\tau) $, where $ \eta(\tau) $ is an auxiliary function given in equation \eqref{eq:equation_45}. We choose $ k^* \in \{1, \dots, N\} $ such that $ u_{k^*} = \sup\limits_{0 < \tau \leq T} \eta(\tau) $. Thus, we have $ S_2 > K_1 $ for this choice, as shown in Theorem \eqref{thm:thm_6}, where $ K_1 $ is related to the carrying capacity for $S_1$ species.       Analyzing the dynamics of $S_1$ species, given by            \dfrac{dS_1}{dt} = S_1\left(\psi_1 - \dfrac{r_1}{K_1}(S_1 + S_2)\right)\left(\dfrac{S_1}{K_0} - 1 \right) - \delta_1 S_1,            with $ S_2 > K_1 $, the term $ \dfrac{r_1}{K_1}(S_1 + S_2) $ contributes to a negative growth rate for $ S_1 $, implying that $ S_1 $ tends to zero in finite time. Therefore, the constraint $ S_1(T) < K_b $ is satisfied for the control $ u_{k^*} $.      Finally, since $ u_k \in [0, u_{\max}] $, the set $ \bar{U} $ is a closed and bounded subset of $ \mathbb{R} $, which guarantees that $ \bar{U} $ is compact.       Thus, we conclude that $ \bar{U} $ is non-empty and compact, with at least one control $ u_{k^*} \in \bar{U} $ that satisfies the control system \eqref{eq:equation_47}-\eqref{eq:equation_48} and the inequality constraint \eqref{eq:equation_49}.",2502.01879
proof,"The first condition has already been verified in Proposition \eqref{prop:prop_5}. In Subsection \eqref{subs:behavior}, we established the existence, uniqueness, positivity, and uniform boundedness of the solutions to the system \eqref{eq:equation_47}-\eqref{eq:equation_48} for each $ u_k \in \bar{U} \subset U $, which satisfies the second and third condition. Additionally, the functional $ J(u) $ is a linear sum of the control variables $ u_k \in \bar{U} $, where $ \bar{U} $ is compact. Thus, $ J(u) $ is continuous in $ u $. Therefore, there exists an optimal control $ u^* = (u^*_k)_{k=1}^{N}$ with $ u^*_k \in \bar{U} $ that minimizes the cost functional $ J(u) $, satisfying the problem constraints described in \eqref{eq:equation_46}-\eqref{eq:equation_49}.",2502.01879
proof,"First, we will show that $\Bar{Z}_2(t)$ is the unique positive $\tau$-periodic solution of system \eqref{eq:equation_15}. Let       Z_2(t) = \dfrac{c K_2 e^{r_2 t}}{ce^{r_2 t}-1}, be the solution of       \dfrac{dZ_2}{dt}=&Z_2\left(\psi_2-\dfrac{r_2}{K_2}Z_2\right)-\delta_2Z_2,\mbox{   } t \neq k\tau, \ k \geq 0  the first equation of \eqref{eq:equation_15}, where $c \in \mathbb{R}$ is a constant to be determined, which is associated with the initial conditions of the problem.  For $t = k\tau$, $k\geq 0$ we have $Z_2(k\tau^+)$ the initial value at time $k\tau$, and      c= \dfrac{Z_2(k\tau^+)e^{-r_2 k\tau^+}}{Z_2(k\tau^+)-K_2},  then,  Z_2(t) = \dfrac{K_2 Z_2(k\tau^+) e^{r_2 (t-k\tau)}}{Z_2(k\tau^+)\left(e^{r_2 (t-k\tau)}     -1\right)+K_2} \mbox{, }  k\tau < t \leq (k+1)\tau, \mbox{ }k \geq 0,  is the solution of system \eqref{eq:equation_15} between the pulses.  In moments of pulses, when $t = (k+1)\tau$, $k \geq 0$, from the second equation of \eqref{eq:equation_15} with $u_k \in U$, we have the following difference equation,  \nonumber     Z_2((k+1)\tau^+) = & Z_2((k+1)\tau) + u_k\\     = &\dfrac{K_2 Z_2(k\tau^+) e^{r_2 ((k+1)\tau-k\tau)}}{Z_2(k\tau^+)\left(e^{r_2 ((k+1)\tau-k\tau)} -1\right)+K_2} + u_k\\\nonumber     = &\dfrac{K_2 Z_2(k\tau^+) e^{r_2 \tau}}{Z_2(k\tau^+)\left(e^{r_2 \tau} -1\right)+K_2} + u_k, \nonumber  which is a recursive relation between $Z_2((k+1)\tau)$ and $Z_2(k\tau)$. We can rewrite it as      Z_2^{k+1} = \dfrac{K_2 Z_2^k e^{r_2 \tau}}{Z_2^k\left(e^{r_2 \tau} -1\right)+K_2} + u_k, where $Z_2^k = Z_2(k \tau)$. Set,      h(Z_2) = \dfrac{K_2 Z_2 e^{r_2 \tau}}{Z_2\left(e^{r_2 \tau} -1\right)+K_2} + u_k. and notice that \eqref{eq:equation_57} has a single positive equilibrium point, since for       h(Z_2) = Z_2,  the condition to determine the equilibrium point of the recursive equation \eqref{eq:equation_57}, which is $\tau$-periodic. Doing some algebraic manipulations we have,      Z_2^2-(u_k+K_2)Z_2-\dfrac{u_kK_2}{e^{r_2 \tau}-1} = 0,  which has two real solutions, but only one positive, given by      Z_2^{+} = \dfrac{1}{2}\left[(u_k+K_2)+\sqrt{(u_k+K_2)^2+4\dfrac{u_kK_2}{e^{r_2 \tau}-1}}\right], \,k \geq 0. Then, substituting $Z_2^+$ into \eqref{eq:equation_55} we have        \Bar{Z_2}(t) &= \dfrac{K_2 Z_2^+ e^{r_2 (t-k\tau)}}{Z_2^+\left(e^{r_2 (t-k\tau)} -1\right)+K_2} \mbox{, }  k\tau < t \leq (k+1)\tau, \mbox{ }k \geq 0, which is the unique positive $\tau$-periodic solution of the system \eqref{eq:equation_15}.  Now, we will show that $\Bar{Z_2}(t)$ is globally asymptotically stable, for this we will show that $Z_2^+$ is globally asymptotically stable, using the result present in \cite{CULL1981} which says that if the difference equation $$Z_2^{k+1} = h(Z_2 ^k),$$ has only one positive equilibrium point and if       Z_2<h(Z_2)<Z_2^+ \text{ for } 0<Z_2<Z_2^+ \text{ and } Z_2^+<h(Z_2)<Z_2 \text{ for } Z_2^+<Z_2, then $Z_2^+$ is a globally asymptotically stable equilibrium and that for every positive initial condition, $S_2(0)$, $Z_2^k$ monotonically approaches $Z_2^+$.  We have already seen that $Z_2^+$ is the only positive equilibrium point of \eqref{eq:equation_57}, so it remains to be shown that the condition \eqref{eq:equation_62} is satisfied. Note that,       h(Z_2) < Z_2^+ &\Longleftrightarrow \dfrac{K_2 Z_2 e^{r_2 \tau}}{Z_2\left(e^{r_2 \tau} -1\right)+K_2} + u_k < \dfrac{K_2 Z_2^+ e^{r_2 \tau}}{Z_2^+\left(e^{r_2 \tau} -1\right)+K_2} + u_k\\\nonumber      &\Longleftrightarrow \dfrac{K_2 Z_2 e^{r_2 \tau}}{Z_2\left(e^{r_2 \tau} -1\right)+K_2} < \dfrac{K_2 Z_2^+ e^{r_2 \tau}}{Z_2^+\left(e^{r_2 \tau} -1\right)+K_2}\\\nonumber      &\Longleftrightarrow K_2 Z_2 e^{r_2 \tau}\left(Z_2^+\left(e^{r_2 \tau} -1\right)+K_2\right)< K_2 Z_2^+ e^{r_2 \tau}\left(Z_2\left(e^{r_2 \tau} -1\right)+K_2\right)\\\nonumber      &\Longleftrightarrow K_2 e^{r_2 \tau}K_2 \left(Z_2 - Z_2^+\right)<0\\\nonumber     &\Longleftrightarrow Z_2<Z_2^+. therefore, $h(Z_2)<Z_2^+$ if $0<Z_2<Z_2^+$. Similarly, we can show that $Z_2^+<h(Z_2)$ if $Z_2^+<Z_2$. With this, we can conclude that $Z_2^+$ is a globally asymptotically stable equilibrium point for the equation \eqref{eq:equation_57}. It implies that the corresponding periodic solution $\Bar{Z_2}(t)$ of \eqref{eq:equation_15} is globally asymptotically stable.",2502.01879
proof,"From the first equation of system \eqref{eq:equation_1}-\eqref{eq:equation_2},      \dfrac{dS_1}{dt}(t) = S_1(t)\left(\psi_1-\dfrac{r_1}{K_1}(S_1(t)+S_2(t))\right) \left(\dfrac{S_1(t)}{K_0} - 1 \right) - \delta_1 S_1(t) which does not include impulsive releases, we will separate our study into two cases due to the critical depensation term $\left(\dfrac{S_1(t)}{K_0} - 1 \right)$.      \item[\textbf{a.}] If $S_1(t)\leq K_0$, then $\left(\dfrac{S_1(t)}{K_0} - 1 \right)\leq 0.$ Soon, $K_0$ is an upper bound of $S_1(t)$, for all $t\geq0$.     \item[\textbf{b.}] If $S_1(t)>K_0$, then $\left(\dfrac{S_1(t)}{K_0} - 1 \right)>0.$ We have, \nonumber    \dfrac{dS_1}{dt}(t) &=& S_1(t)\left[\left(\psi_1 -\dfrac{r_1}{K_1}S_1(t)\right)\left(\dfrac{S_1(t)}{K_0} - 1 \right)-\dfrac{r_1}{K_1}S_2(t)\left(\dfrac{S_1(t)}{K_0} - 1 \right)-\delta_1\right]\\    &\leq&S_1(t)\left[\left(\psi_1 -\dfrac{r_1}{K_1}S_1(t)\right)\left(\dfrac{S_1(t)}{K_0} - 1 \right)-\delta_1\right], and we can use the following comparison differential equation   \dfrac{dy}{dt}(t)=& y(t)\left[\left(\psi_1 -\dfrac{r_1}{K_1}y(t)\right)\left(\dfrac{y(t)}{K_0} - 1 \right)-\delta_1\right]\\ y(0)=&\hspace{-5.5cm}S_1(0),  which has three equilibrium points, $y(t) = 0$ and the solutions of      \left[\left(\psi_1 -\dfrac{r_1}{K_1}y(t)\right)\left(\dfrac{y(t)}{K_0} - 1 \right)-\delta_1\right] = 0.  For \eqref{eq:equation_67} we have,  -\dfrac{r_1}{K_1K_0}y^2 + \dfrac{(\psi_1K_1+r_1K_0)}{K_1K_0}y-(\delta_1+\psi_1) = 0,      solving the quadratic equation above,      \Delta = \dfrac{(\psi_1K_1+r_1K_0)}{(K_1K_0)^2}^2 - \dfrac{4r_1K_0K_1}{(K_1K_0)^2}(\delta_1+\psi_1),  then, we find two solutions        y_1 =\dfrac{\psi_1K_1+r_1K_0 - \sqrt{(\psi_1K_1+r_1K_0)^2 -4r_1K_0K_1(\delta_1+\psi_1)}}{2r_1},  and      y_2 = \dfrac{\psi_1K_1+r_1K_0 + \sqrt{(\psi_1K_1+r_1K_0)^2 -4r_1K_0K_1(\delta_1+\psi_1)}}{2r_1},  but following the naming in \cite{Campo2017} we have, $y_1 = K_b$ and $y_2 = K_*$. Since, $0<K_b<K_*$ we can analyze the sign of the right side of \eqref{eq:equation_65} among these points,      \left \{  \dfrac{dy}{dt}<0, & \mbox{if }& 0<y<K_b, \\ \dfrac{dy}{dt}>0, & \mbox{if }&K_b<y<K_*, \\ \dfrac{dy}{dt}<0, & \mbox{if }&y>K_*.  \right.  Therefore, for the initial condition $y(0) = S_1(0)$ we have,      \item[i)] if $0\leq S_1(0) < K_b$, then $y(t)$ decreases down to $0$ in finite time as $t$ increases;     \item[ii)] if $K_b<S_1(0)<K_*$, then $y(t)$ increases up to $K_*$ as $t \to \infty$;     \item[iii)] if $S_1(0)>K_*$, then $y(t)$ decreases down to $K_*$ as $t \to \infty$;   As a result, as following in \cite{Campo2017} given a population of species $S_1$ large enough to survive, that is, $S_1(0) > K_b$, $K_*$ is the steady state population and $K_b$ is the threshold for survival. With this, we can conclude that $K_*$ is an upper limit for $y(t)$ and since $\dfrac{dS_1}{dt}(t) \leq \dfrac{dy}{dt}(t)$ and $S_1(0) = y(0)$, by the Comparison Theorem, we have that $S_1(t)$ is also upper bounded by $K_*$. As shown in \cite{Campo2017}, that $K_0 < K_1 < K_*$, we have $S_1(t) \leq K_*$, $\forall t \geq 0$.",2502.01879
proof,"Let $(0,\Bar{S}_2(t))$ be the $\tau$-periodic solution of the system \eqref{eq:equation_1}-\eqref{eq:equation_2}. Consider a small perturbation $p(t)$ and $q(t)$ of the solution, that is,      S_1(t) = p(t) \mbox{ and } S_2(t) = \Bar{S_2}(t) + q(t),  then, we can to linearize the equations of system \eqref{eq:equation_1} around the solution $(0,\Bar{S_2}(t))$ to use Floquet's Theorem \cite{Bainov1993}. Thus, we have the following linearized system:   &\left.         \dfrac{dp(t)}{dt} =p(t)\left( -\psi_1+\dfrac{r_1}{K_1}\Bar{S_2}(t)\right)-p(t)\delta_1,\\        \dfrac{dq(t)}{dt} =q(t)\left( r_2-2\dfrac{r_2}{K_2}\Bar{S_2}(t) \right) -p(t)\dfrac{r_2}{K_2}\Bar{S_2}(t),  \right.\mbox{ if } t \neq k\tau, k \geq 0\\ &\left.            p(k\tau^+) = p(k\tau), \\         q(k\tau^+) = q(k\tau),  \right.\mbox{ if } t = k\tau, k \geq 0   with $\phi(t)$ being the fundamental matrix of \eqref{eq:equation_74}, which must satisfy    \dfrac{d\phi}{dt} = A\phi(t)\\ \phi(0) = I_d,   where   A&=&  -\psi_1+\dfrac{r_1}{K_1}\Bar{S_2}(t)-\delta_1 & 0  \\ -\dfrac{r_2}{K_2}\Bar{S_2}(t) & r_2-2\dfrac{r_2}{K_2}\Bar{S_2}(t)\\ .  Also for the \eqref{eq:equation_74} system we have its monodromy matrix   M&=&  1 & 0  \\ 0 & 1\\ \phi(\tau) = \phi(\tau).  Solving \eqref{eq:equation_76} we have      \phi(\tau) &=& \phi(0)\exp{\left(\int_0^{\tau}A\,dt\right)}\\     &=&  1 & 0  \\ 0 & 1\\ \exp{ \int_0^{\tau}\left(\dfrac{r_1}{K_1}\Bar{S_2}(t)-(\psi_1+\delta_1)\right)\,dt & 0  \\\nonumber \int_0^{\tau}\left(-\dfrac{r_2}{K_2}\Bar{S_2}(t)\right)\,dt & \int_0^{\tau}\left(r_2-2\dfrac{r_2}{K_2}\Bar{S_2}(t)\right)\,dt\\ }.     According to Floquet's Theorem, the solution $(0,\Bar{S_2}(t))$ is asymptotically stable if, $e^{\lambda_1}$ and $e^{\lambda_2}$ have absolute values less than one, where $\lambda_1$ and $\lambda_2$ are the eigenvalues of the matrix      \int_0^{\tau}A\,dt.  With this,      \lambda_1 = \int_0^{\tau}\left(\dfrac{r_1}{K_1}\Bar{S_2}(t)-(\psi_1+\delta_1)\right)\,dt \,\text{ and }\,\lambda_2 = \int_0^{\tau}\left(r_2-2\dfrac{r_2}{K_2}\Bar{S_2}(t)\right)\,dt.  Solving $\int_0^{\tau}\Bar{S_2}(t)\,dt$ we have \nonumber     \int_0^{\tau}\Bar{S_2}(t)\,dt =& \int_0^{\tau}\dfrac{K_2 Z_2^{+} e^{r_2 (t-k\tau)}}{Z_2^{+}\left(e^{r_2 (t-k\tau)} -1\right)+K_2}\,dt,\\     =&\dfrac{K_2}{r_2}\left[\ln{\left(Z_2^{+}e^{r_2 t}+(K_2-Z_2^{+}\right)}\right]_0^{\tau},\\     =&\dfrac{K_2}{r_2}\ln\left[\dfrac{Z_2^{+}\left(e^{r_2 \tau} -1\right)}{K_2} + 1\right].\nonumber  Hence,      \lambda_1 = -(\psi_1+\delta_1) \tau +\dfrac{K_2r_1}{K_1r_2}\ln\left[\dfrac{Z_2^{+}\left(e^{r_2 \tau} -1\right)}{K_2} + 1\right],  and,      \lambda_2 = r_2 \tau -2\ln\left[\dfrac{Z_2^{+}\left(e^{r_2 \tau} -1\right)}{K_2} + 1\right].  In order for $|e^{\lambda_1}|<1$ and $|e^{\lambda_2}|<1$ we must have $\lambda_1<0$ and $\lambda_2<0.$ Thus,      \item $\lambda_1<0$, if           \ln\left[\dfrac{Z_2^{+}\left(e^{r_2 \tau} -1\right)}{K_2} + 1\right] < \dfrac{K_1r_2}{K_2r_1}(\psi_1+\delta_1)\tau.  Observe that $\psi_1+\delta_1 < K_2$ and $r_2<r_1$ is one of the conditions imposed in the model, then      \dfrac{Z_2^{+}}{K_2} < \dfrac{\left(e^{K_1\tau} -1\right)}{\left(e^{r_2 \tau} -1\right)},  which always happens, since the exponential of $K_1 \tau$ dominates this inequality.     \item $\lambda_2<0$, if          \dfrac{r_2}{2} \tau < \ln\left[\dfrac{Z_2^{+}\left(e^{r_2 \tau} -1\right)}{K_2} + 1\right], that is,      \dfrac{\left(e^{\frac{r_2}{2} \tau} -1\right)}{\left(e^{r_2 \tau} -1\right)}<\dfrac{Z_2^{+}}{K_2},  which also always happens, since $\dfrac{Z_2^{+}}{K_2} >1$ and $\dfrac{\left(e^{\frac{r_2}{2} \tau} -1\right)}{\left(e^{r_2 \tau} -1\right)} <1$.   Therefore, the $S_1$-free $\tau$-periodic solution $(0,\Bar{S_2}(t))$ of system \eqref{eq:equation_1}-\eqref{eq:equation_2} is locally asymptotically stable.",2502.01879
proposition,"Let $(S_1(0),S_2(0))$ be a non-negative initial condition, and let $(S_1(t),S_2(t))$ be a solution to the system \eqref{eq:equation_1}-\eqref{eq:equation_2}. Then, $(S_1(t),S_2(t))$ remains non-negative for all $t\geq 0$.",2502.01879
proposition,"For each non-negative initial condition and each release a\-mount  $u_k \in U$ of individuals from species $S_2$, the system \eqref{eq:equation_1}\eqref{eq:equation_2} has a unique solution defined on the interval $[0, \infty)$.",2502.01879
proposition,"Let $\eta(\tau)$ and $\phi(\tau)$ be defined for $\tau \geq 0$ as given in \eqref{eq:equation_45}. Then, there exists a supremum of $\eta(\tau)$ for $\tau \geq 0$.",2502.01879
proposition,The set of admissible controls $ \bar{U} $ is non-empty and compact.,2502.01879
lemma,"Let $(S_1(t),S_2(t))$ be a solution of system \eqref{eq:equation_1}-\eqref{eq:equation_2}, with positive parameters, $u_k \in U$ and non-negative initial conditions. Then there exists a positive constant $K_*$ that satisfies $S_1(t)\leq K_*$ for all $t \geq 0$.",2502.01879
theorem,"Let $G\leq\Sym(\Omega)$ be a   transitive group given by   a set $S$ of generators. In   time $O(n\log^2|G|\log n+n|S|\log |G|)$,   we can determine whether or not $G$ is   primitive, and in the imprimitive case   we can find a block system.",2502.01884
theorem,"Let $G\leq\Sym(\Omega)$ be a   transitive group given by   a set $S$ of generators.  In time $O(n\log^5 n+n|S|\log^2 n)$   we can do one of the following:      \item Establish that $G$ is primitive.   \item Establish that $G$ is imprimitive, finding a     block system for $G$.   \item Establish that all primitive actions of $G$     on nontrivial partitions of $\Omega$ are large.      (In the third case we do not identify a partition on which   $G$ acts primitively, nor do we determine whether $G$ is primitive.)",2502.01884
theorem,"Let $G\leq\Sym(\Omega)$ be a   transitive group given by   a set $S$ of generators.  In time $O(n^{5/3}\log^3 n+n^{4/3}|S|\log n)$   we can do one of the following:      \item Establish that $G$ is primitive.   \item Establish that $G$ is imprimitive, finding a     block system for $G$.   \item Establish that all primitive actions of $G$     on nontrivial partitions of $\Omega$ are large, with     parameters $(m,k,d)$ satisfying $kd\leq 2$ and     $md> 3n^{1/3}$.      (In the third case we do not identify a partition on which   $G$ acts primitively, nor do we determine whether $G$ is primitive.)",2502.01884
definition,"[\cite{BabaiSzemeredi1984}]   For a list $X=(x_1,x_2,\ldots,x_j)$ of elements of $G$,   we denote by $C(X)$ set   $$\{{x_1}^{\epsilon_1}{x_2}^{\epsilon_2}\cdots{x_j}^{\epsilon_j}\mid \epsilon_1,\epsilon_2,\ldots \epsilon_j\in\{0,1\}\},$$   which we call the {\em cube}\/ generated by $X$.",2502.01884
proof,"Clearly this is true if   ${\Delta_i}^{g}\cap\Delta_i=\emptyset$, so assume otherwise.   Also, assume $g_i\not\in G^{[i+1]}$; since   the deep cube at level $i$ contains the deep cube at   level $i+1$, this assumption is without loss of generality.   Let $s$ and $t$ be the elements of $C(X_i)$ used,   so that for the next iteration we replace $g$ by   $g'=sgt^{-1}$.  The effect on ${X_1}^*$ of   sifting $g$ is identical to the effect of   sifting $g'$, and    inductively we have that   $g'$ will belong to the deep cube at level $i+1$ after   sifting is complete.  Expressing $g$ in terms of $g'$   we see that        g&=&s^{-1}g't\\     &\in& s^{-1} C(X_{i+1}^*)^{-1}C(X_{i+1}^*) t\\     &\in& C(X_i)^{-1} C(X_{i+1}^*)^{-1}C(X_{i+1}^*) C(X_i)\\     &=& C({X_i}^*)^{-1}C({X_i}^*)\\      as desired.",2502.01884
proof,"We describe the algorithm.   Select some $g\in S$   with $\alpha^g\neq\alpha$.   We initialize the   deep sifting data structure with   $\beta_1=\alpha$, set $X_1$ to be   the single element list $(g)$, and set $\ell=1$.      As long as $\ell\leq L$ and   $\Omega_1\neq \alpha^G$, we find some element   $\lambda\in\Omega_1$ and some generator $g\in S$   with $\lambda^g\not\in\Omega_1$,   and sift $r_\lambda g$.   Established methods~\cite{seress-book}   limit the total time used in   selecting $\lambda\in\Omega_1$ and $g\in S$   to $O(n|S|)$.    The tasks of computing $\Omega_1$,   computing $r_\lambda g$,   and sifting $r_\lambda g$ each take time $O(n|{X_1}^*|)$;   by the remarks above, this is $O(n\mu)$.   By Lemma~\ref{augment-transversal},   each such sift results in an increase to the   deep cube, so the number of such sifts is $O(\mu)$.   The total sifting time is thus $O(n\mu^2)$.      At termination, we either have a transversal,   or we have $\ell=L+1$. In the latter case   we can then take an arbitrary $g_i$ from each $X_i$.",2502.01884
proof,"We will focus on the block system for which $L$ is   an upper bound on the size of a nonredundant base.   Let us consider how the $g_i$ act on the blocks.   Since $g_i$ fixes all $\beta_j$ with $j<i$,   we have that $g_i$ maps the block of $\beta_j$ to itself for $j<i$.    We wish to show that for some $i$, the element $g_i$ moves the point $\beta_i$ to another point in the   same block.  Suppose to the contrary that    each $g_i$ moves the block of $\beta_i$ to a different block.   Then we have the nonredundancy   condition for the action on the blocks: the blocks containing   the $\beta_i$ are a nonredundant partial base of size $L+1$.   This is a contradiction, as desired.",2502.01884
proposition,"For any $\beta\in\Omega$ and $g\in C(X)$, we can compute $\beta^g$ in time $O(|X|)$ from the word encoding $g$.",2502.01884
proposition,"For any set $\Delta\subseteq\Omega$, we can find the set $\Delta^{C(X)}$ in time $n|X|$. If desired, for all $\gamma\in \Delta^{C(X)}$, we can in that same time find an $\beta\in \Delta$ and a word representing an element $g$ of $C(X)$ with $\beta^g=\gamma$.",2502.01884
proposition,"[\cite{BabaiSzemeredi1984}]   For $j>1$,   the cube $C(x_1,\ldots,x_j)$ is non-degenerate iff both   of the following hold:        \item The       cube $C(x_1,\ldots,x_{j-1})$ is non-degenerate.     \item The element $x_j$ satisfies       $x_j\not\in C(x_1,\ldots,x_{j-1})^{-1}C(x_1,\ldots,x_{j-1})$.",2502.01884
lemma,"Suppose we sift an element $g\in G^{[i]}$ with $\beta_{i}^g=\lambda$.   Then after sifting completes,   we will have $\lambda\in\Omega_i$.",2502.01884
lemma,"Suppose we sift an element $g\in G^{[i]}$. Then after sifting completes,   we will have that $g$ is an element of the deep cube   at level $i$.",2502.01884
lemma,"Let $L$ be an arbitrary positive integer,   let $G\leq\Sym(\Omega)$ be a   group given by   a set $S$ of generators, and let $\alpha$ be a given point not   fixed by $G$.   Let $\mu=\min(L\log n,\log|G|)$.   In time $O(n\mu^2+n|S|)$ we can   either compute a transversal for $G:G_\alpha$   with words of length $\leq 2\mu$, or compute   a partial nonredundant base  $\beta_1,\ldots,\beta_{L+1}$ of size $L+1$,   together with, for each $i=1,\ldots,L+1$, an   element $g_i\in G^{[i]}\setminus G^{[i+1]}$.",2502.01884
lemma,"Let $L$ be an arbitrary positive integer,   and let $G\leq\Sym(\Omega)$ be a   transitive group given by   a set $S$ of generators.   Let $\mu=\min(L\log n,\log|G|)$.   In time $O(n\mu^2\log n+n|S|\mu)$   we can do one of the following:      \item Establish that $G$ is primitive.   \item Establish that $G$ is imprimitive, finding a     block system for $G$.   \item Compute a nonredundant partial base  $\beta_1,\ldots,\beta_{L+1}$ of size $L+1$,     together with, for each $i=1,\ldots,L+1$, some $g_i\in G^{[i]}\setminus G^{[i+1]}$.",2502.01884
lemma,"Let $G\leq\Sym(\Omega)$ have   a certified nonredundant partial base $\beta_1,\ldots,\beta_{L+1}$,   with certificate $g_1,\ldots,g_{L+1}$.   Suppose that $G$ has a block system for which the   action on blocks has maximum nonredundant base size at most $L$.   Then with respect to this block system,   for some $i\in 1,\ldots,L+1$, the points $\beta_i$ and   ${\beta_i}^{g_i}$ lie in the same block.",2502.01884
proof,"[Proof of Lemma~\ref{lem:component-wise-bounds}]  Let us start with the statement for $S$. Enumerate the samples in $S$ as $(x_1, y_1), \dots, (x_n, y_n).$ For each $x_i$, let $z_i = \sum_{j = 1}^d (x_i)_j$ be the sum of its coordinates. Let $\bar z_1 = \frac{1}{n} \sum_{i=1}^n z_i$ and $\bar z_2 = \frac{1}{n} \sum_{i=1}^n z_i^2.$ Then, we have        \Sigma_S =           1 & \bar z_1 \\           \bar z_1 &  \bar z_2         \quad \text{and} \quad \Sigma_S^{-1} = \frac{1}{\bar z_2 - \bar z_1^2}            \bar z_2  & - \bar z_1 \\           - \bar z_1 &  1      .    Thus,         \Sigma_S^{-1} - \bar \Sigma_S^{-1} =            \frac{\bar z_2}{\bar z_2 - \bar z_1^2} - 1  & - \frac{\bar z_1}{\bar z_2 - \bar z_1^2} \\           - \frac{\bar z_1}{\bar z_2 - \bar z_1^2}&  \frac{1}{\bar z_2 - \bar z_1^2} - \frac{1}{d}      .   The random variables $z_i \sim N(0, d)$ and so $\bar z_1 \sim N(0, \frac{d}{n^2})$ and $\bar z_2 =  \frac{d}{n} w $ with $w \sim \chi^2_n$, a chi-squared distribution with $n$ degrees of freedom. [\cite{vershynin2018high}]     Let $z \sim N(0, \sigma^2),$ then for any $t \geq 0$ we have $\PP(|z| \geq t) \leq 2 \exp\left(-\frac{t^2}{2\sigma^2}\right).$  [\cite{laurent2000adaptive}]     Let $w \sim \chi_n^2$, then for any $t \geq 0$ we have that $$\max\left\{\PP( 2\sqrt{n t} + 2t \leq w - n), \PP( w - n \leq - 2\sqrt{n t})\right\} \leq \exp(-t).$$  Equipped with these two facts, it is easy to derive that for any fixed $\delta > 0,$  we have $\PP(|\bar z_1| \geq  \sqrt{\delta d}) \leq 2 \exp\left(- {\delta n^2}\right)$ and $\max\left\{\PP(2(\delta+\delta^2)d \leq \bar z_2 -d), \PP (\bar z_2 - d \leq -2\delta d) \right\}\leq \exp(-\delta n).$ Consider the event $$ \mathcal{E} = \left\{|\bar z_1 | \leq \sqrt{\delta d} \quad \text{ and } \quad (1 - 2\delta) d \leq \bar z_2 \leq ( 1+4 \delta) d \right\}. $$ A union bound argument yields $\PP(\cE) \geq 1 - 4\exp\left(-\delta n \right),$ which matches the stated probability. For the rest of the proof assume that $\cE$ holds with $\delta \in (0, 1/6)$.   We are finally ready to prove the three stated bounds for $S$. We will repeatedly use that $\delta/(1-3\delta) \leq 2 \delta$ for $\delta < 1/6.$ Let us start with the first statement:             \left| \frac{\bar z_2}{\bar z_2 - \bar z_1^2} -1\right|= \left| \frac{\bar z_1^2}{\bar z_2 - \bar z_1^2}\right| \leq \frac{|\bar z_1^2|}{|\bar z_2| - |\bar z_1^2|} \leq \frac{\delta }{(1-3\delta)} \leq 2 \delta.       Similarly,             \left| \frac{\bar z_1}{\bar z_2 - \bar z_1^2}\right|= \left| \frac{\bar z_1}{\bar z_2 - \bar z_1^2}\right| \leq \frac{|\bar z_1|}{|\bar z_2| - |\bar z_1^2|} \leq \frac{\sqrt{\delta d}}{(1-3\delta) d} \leq 2\sqrt{\frac{\delta}{d}}          where the last inequality follows for any $\delta < 1/6$ and $d \geq 1.$ Finally,       \left|\frac{1}{\bar z_2 - \bar z_1^2} - \frac{1}{d} \right| = \left| \frac{d - \bar z_2 + \bar z_1^2}{(\bar z_2 - \bar z_1^2) d}\right| \leq \frac{|d - \bar z_2| + \bar z_1^2}{(|\bar z_2| - |\bar z_1^2|) d } \leq \frac{5 \delta }{(1-3\delta)d} \leq 10 \frac{\delta}{d}.  This completes the statement involving $S$.   To show the statement for $T$ we use a very similar strategy. Notice that $\Sigma_T$ can also be written as in \eqref{eq:cov-S} for a $\bar z_1$ and $\bar z_2$ with an analogous distribution where we substitute $d$ with $\bar d.$ Then, assuming again that we are in $\cE$---defined with the the new $\bar z_1$ and $\bar z_2$ and with $\bar d$ in place of $d$---yields the stated probability bound. Hence, $\left(\Sigma_T - \bar \Sigma_T \right)_{11} = 0 $, while   \left|\left(\Sigma_T - \bar \Sigma_T \right)_{12}\right| = |z_1| \leq \sqrt{\delta d}, \quad \text{and} \quad \left|\left(\Sigma_T - \bar \Sigma_T \right)_{22}\right| = |\bar z_2 - d| \leq 4 \delta d,  which completes the proof.",2502.01886
lemma,"Let $n = |S|$ and fix $\delta \in (0, 1/6)$, then with probability at least $1 - 4\exp(-\delta n)$ we have       $$     \left|\Sigma_S^{-1} - \bar \Sigma_S^{-1}\right|_{11} \leq 2 \delta, \quad \left|\Sigma_S^{-1} - \bar \Sigma_S^{-1}\right|_{12} \leq 2  \sqrt{\frac{\delta}{d}}, \quad \text{and}\quad \left|\Sigma_S^{-1} - \bar \Sigma_S^{-1}\right|_{22} \leq 10 \frac{\delta}{d}.     $$     Similarly, let $m = |T|$ and fix $\delta \in (0, \infty),$ with probability at least $ 1- 4\exp(-\delta m)$ we have that      $$       \left|\Sigma_T - \bar \Sigma_T\right|_{11} = 0, \quad \left|\Sigma_T - \bar \Sigma_T\right|_{12} \leq  \sqrt{{\delta}{\bar d}}, \quad \text{and}\quad \left|\Sigma_T - \bar \Sigma_T\right|_{22} \leq 4 {\delta}{\bar d}.     $$",2502.01886
lemma,"Let $(X,Y) \sim N\left(0,  \Sigma_{xx} & \Sigma{xy} \\ \Sigma_{yx} & \Sigma_{yy}\right),$ then, $\EE\left(X \mid Y\right) = \Sigma_{xy}\Sigma_{yy}^{-1}Y$.",2502.01886
lemma,"Let $Q \in \R^{d \times r}$ be a rank $r$ matrix, then, $Q^\top \left(QQ^\top - I_d\right)^{-1} = \left(Q^\top Q - I_r\right)^{-1} Q^\top.$",2502.01886
proof,"[Proof of \Cref{theorem:rsvd_like_bound}]     First note that by a standard Chebyshev interpolation bound \cite[Lecture 20]{stewart}              \inf\limits_{p \in \mathbb{P}_{2r+1}}\|\exp(x)-p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])}  \leq \frac{\gamma_{1,n}^{2r+r}}{2^{4r+3}(2r+2)!}\|\exp(\bm{A})\|_2.          %      %     &\inf\limits_{p \in \mathbb{P}_{2r+1}}\|\exp(x)-p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])} = \exp(\lambda_{\min}) \inf\limits_{p \in \mathbb{P}_{2r+1}}\|\exp(x)-p(x)\|_{L^{\infty}([0,\lambda_{\max}-\lambda_{\min}])} \leq \\     %     &\exp(\lambda_{\min}) \frac{(\lambda_{\max} - \lambda_{\min})^{2r+2}}{(2r+2)!} \exp(\lambda_{\max} - \lambda_{\min}) = \frac{(\lambda_{\max} - \lambda_{\min})^{2r+2}}{(2r+2)!} \exp(\lambda_{\max})  = \\     %     &\exp(\lambda_{\max} - \lambda_{\min}) = \frac{(\lambda_{\max} - \lambda_{\min})^{2r+2}}{(2r+2)!} \|\exp(\bm{A})\|_2.     %      Hence,              4\sqrt{\ell s}  \inf\limits_{p \in \mathbb{P}_{2r+1}}\|f(x)-p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])} \leq 4\sqrt{\ell s} \frac{\gamma_{1,n}^{2r+2}}{(2r+2)!} \|\exp(\bm{A})\|_2.          We proceed with bounding $\mathcal{E}(s;\exp(x))$. Let $p(x) = \sum\limits_{i=1}^{s-1}\frac{(x-\lambda_{\min})^i}{i!}$. Then for $x \in [\lambda_{\min},\lambda_{\max}]$ we have $0 \leq p(x) \leq \exp(x-\lambda_{\min})$. Consequently, $\|p(\bm{\Lambda}_{n \setminus k })\|_{\F} \leq \|\exp(\bm{\Lambda}_{n \setminus k })\|_{\F} \exp(-\lambda_{\min})$. Furthermore, for $x \in [\lambda_{\min},\lambda_{\max}]$ we have     %      %    0 &\leq  \exp(x-\lambda_{\min}) - p(x)      %    \\&= \sum\limits_{i=s}^{\infty} \frac{(x-\lambda_{\min})^i}{i!} = \frac{(x-\lambda_{\min})^s}{s!} \sum\limits_{i=0}^{\infty} \frac{(x-\lambda_{\min})^i}{(i+s)!} s!      %    \\&\leq \frac{(x-\lambda_{\min})^s}{s!} \sum\limits_{i=0}^{\infty} \frac{(x-\lambda_{\min})^i}{i!} = \frac{(x-\lambda_{\min})^s}{s!} \exp(x-\lambda_{\min}).     %              0 \leq  \exp(x-\lambda_{\min}) - p(x)         \leq \frac{(x-\lambda_{\min})^s}{s!} \exp(x-\lambda_{\min}).          Note that by the assumption on $s$ and a Stirling approximation $s! \geq \sqrt{2\pi s} \left(\frac{s}{e}\right)^s$ \cite{stirling} we have $\frac{\gamma_{1,n}^s}{s!} < 1$.     Hence,              \max\limits_{i=1,\ldots,k} \left|\frac{\exp(\lambda_i)}{p(\lambda_i)}\right| &= \exp(\lambda_{\min})\max\limits_{i=1,\ldots,k} \left|\frac{\exp(\lambda_i - \lambda_{\min})}{p(\lambda_i)}\right|          \nonumber\\&         = \exp(\lambda_{\min}) \left(1- \frac{(\lambda_{\max}-\lambda_{\min})^s}{s!}\right)^{-1}.           Therefore, $\mathcal{E}(s;\exp(x))$ is bounded above by               \mathcal{E}(s;\exp(x)) \leq \frac{1}{(1- \frac{(\lambda_{\max}-\lambda_{\min})^s}{s!})^2} \|\exp(\bm{\Lambda}_{n \setminus k})\|_{\F}^2 = \frac{1}{(1- \frac{\gamma_{1,n}^s}{s!})^2} \|\exp(\bm{\Lambda}_{n \setminus k})\|_{\F}^2.          Plugging the inequalities  \eqref{eq:bound} and \eqref{eq:bound2} into \Cref{theorem:krylov_aware} yields the desired inequality.",2502.01888
proof,"[Proof of \Cref{theorem:fast_convergence}]     Bounding $4\sqrt{\ell s}\inf\limits_{p \in \mathbb{P}_{2r+1}}\|\exp(x)-p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])}$ is done identically to in \Cref{theorem:rsvd_like_bound}. We proceed with bounding $\mathcal{E}(s;\exp(x))$. Define $\delta(x) = \frac{x-\lambda_{k+1}}{\lambda_{k+1} - \lambda_n}$. Define the polynomial $p(x) = (1+x-\lambda_{n})T_{s-2}\left(1 + 2 \delta(x)\right)$, where $T_{s-2}$ is the Chebyshev polynomial of degree $s-2$.      Hence, recalling the definition \cref{eqn:min_ratio} of $\mathcal{E}(s;\exp(x))$, since $0\leq 1+x \leq \exp(x)$ for $x\geq 0$ and $|T_{s-2}(x)| \leq 1$ for $x \in [-1,1]$ we have,     \[     \|p(\bm{\Lambda}_{n \setminus k})\|_{\F}     \leq \|\exp(\bm{\Lambda}_{n \setminus k} - \lambda_{n}\bm{I})\|_{\F}\]     Hence, using that $\frac{\exp(x)}{1+x} \leq \exp(x)$ for $x \geq 0$ we get              \mathcal{E}(s;\exp(x))          &\leq \|p(\bm{\Lambda}_{n \setminus k})\|_{\F}^2 \max\limits_{i=1,\ldots,k} \left|\frac{\exp(\lambda_i)}{p(\lambda_i)}\right|^2          \nonumber\\&\leq          \|\exp(\bm{\Lambda}_{n \setminus k}-\lambda_{n}\bm{I})\|_{\F}^2\max\limits_{i=1,\ldots,k} e^{2\lambda_{n}} \left|\frac{\exp(\lambda_i-\lambda_{n})}{p(\lambda_i)}\right|^2          \nonumber\\&=\|\exp(\bm{\Lambda}_{n \setminus k})\|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{\exp(\lambda_i-\lambda_{n})}{p(\lambda_i)}\right|^2         \nonumber\\&\leq\|\exp(\bm{\Lambda}_{n \setminus k})\|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{\exp(\lambda_i-\lambda_{n})}{T_{s-2}\left(1 + 2 \delta(\lambda_i)\right)}\right|^2.                   First note that for $|x| \geq 1$ we have              T_{s-2}(x) = \frac{1}{2}\left(\left(x + \sqrt{x^2-1}\right)^{s-2} + \left(x - \sqrt{x^2-1}\right)^{s-2} \right).          Hence, for $\delta \geq 0$ we have $|T_{s-2}(1+2\delta)| \geq \frac{1}{2}(1+2\delta + 2\sqrt{\delta + \delta^2})^{s-2} =: \frac{1}{2}h(\delta)^{s-2}$. Therefore,              \max\limits_{i=1,\ldots,k} \left|\frac{e^{\lambda_i-\lambda_{n}}}{T_{s-2}\left(1 + 2 \delta(\lambda_i)\right)}\right|^2 &\leq 4 \max\limits_{i=1,\ldots,k} \left|\frac{\exp(\lambda_i-\lambda_{n})}{h(\delta(\lambda_i))^{s-2}}\right|^2\\         &= 4 \max\limits_{i=1,\ldots,k} \left(\exp(\lambda_i - \lambda_n - (s-2)\log(h(\delta(\lambda_i))))\right)^2.          Note that the function               g(x) := x - \lambda_n - (s-2)\log(h(\delta(x)))          is convex in $[\lambda_k,\lambda_1]$ because $\log(h(x))$ is concave for $x \geq 0$ and $\delta(x)$ is linear positive function for any $x \geq \lambda_{k}$. Hence, the maximum of $g$ on the interval $[\lambda_k,\lambda_1]$ is attained at either $x = \lambda_k$ or $x = \lambda_1$. The maximum of $g$ is attained at $x = \lambda_k$ whenever $g(\lambda_1) \leq g(\lambda_k)$ which happens whenever              \frac{\lambda_1 - \lambda_k}{\log\left(\frac{h(\delta(\lambda_1))}{h(\delta(\lambda_k))}\right)} + 2 \leq s.          Note that we have whenever $x \geq y \geq 0$ we have $\frac{h(x)}{h(y)} \geq \frac{1 + x}{1+y}$, which can be seen by noting that $\frac{h(x)}{1+x}$ is an increasing function. Hence, \eqref{eq:scondition} holds whenever              \frac{\lambda_1 - \lambda_k}{\log\left(\frac{\lambda_1 - \lambda_{n}}{\lambda_k - \lambda_{n}}\right)} + 2  \leq s,          which is our assumption on $s$. Hence,                \max\limits_{i=1,\ldots,k} \left|\frac{\exp(\lambda_i-\lambda_{n})}{T_{s-2}\left(1 + 2 \delta(\lambda_i)\right)}\right|^2 \leq 4 \frac{\exp(2(\lambda_k - \lambda_n))}{h(\delta(\lambda_k))^{2(s-2)}}.          Now we use the argument from \cite[p.21]{MM15}, which shows that $h(\delta)^{(s-2)} \geq 2^{\sqrt{\min\{1,2\delta\}}(s-2) - 1}$. Plugging this inequality into \cref{eq:upperbound} and then \cref{eqn:Esexp_bd} and  using the definition for $\gamma_{i,j}$ yields              \mathcal{E}(s;\exp(x)) \leq 16 \exp(2\gamma_{k,n}) 2^{-2(s-2) \sqrt{\min\left\{1,2 \frac{\gamma_{k,k+1}}{\gamma_{k+1,n}}\right\}}} \|\exp(\bm{\Lambda}_{n\setminus k})\|_\F^2.          % Bounding $4\sqrt{\ell s}\inf\limits_{p \in \mathbb{P}_{2r+1}}\|\exp(x)-p(x)\|_{L^{\infty}([\lambda_{\min},\lambda_{\max}])}$ is done identical to as done in \Cref{theorem:rsvd_like_bound}. We proceed with bounding $\mathcal{E}(s;\exp(x))$ by choosing the polynomial $p(x) = (1+x-\lambda_{\min})T_{s-2}\left(\frac{x-\lambda_{\min}}{\lambda_{k+1}-\lambda_{\min}}\right)$, where $T_{s-2}$ is the Chebyshev polynomial of degree $s-2$.      % Hence, recalling the definition \cref{eqn:min_ratio} of $\mathcal{E}(s;\exp(x))$, since $0\leq 1+x \leq e^x$ for $x\geq 0$,     % \[     % \|p(\bm{\Lambda}_{n \setminus k})\|_{\F}     % \leq \|\exp(\bm{\Lambda}_{n \setminus k} - \lambda_{\min}\bm{I})\|_{\F} \left\|T_{s-2}\left(\frac{\bm{\Lambda}_{n \setminus k}-\lambda_{\min}\bm{I}}{\lambda_{k+1}-\lambda_{\min}}\right)\right\|^2.     % \]     % Hence, using that $|T_{s-2}(x)\leq 1$ for $x\in[0,1]$,     %      %     \mathcal{E}(s;\exp(x))      %     &\leq \|p(\bm{\Lambda}_{n \setminus k})\|_{\F}^2 \max\limits_{i=1,\ldots,k} \left|\frac{e^{\lambda_i}}{p(\lambda_i)}\right|^2      %     \nonumber\\&\leq      %     \|\exp(\bm{\Lambda}_{n \setminus k}-\lambda_{\min}\bm{I})\|_{\F}^2\max\limits_{i=1,\ldots,k} e^{2\lambda_{\min}} \left|\frac{e^{\lambda_i-\lambda_{\min}}}{p(\lambda_i)}\right|^2      %     \nonumber\\&=\|\exp(\bm{\Lambda}_{n \setminus k})\|_{\F}^2\max\limits_{i=1,\ldots,k} \left|\frac{e^{\lambda_i-\lambda_{\min}}}{p(\lambda_i)}\right|^2.     %          %      % Finally, using that $\frac{e^x}{1+x} \leq e^x$ for $x \geq 0$,that $T_{s-2}(x)$ is increasing for $x \geq 1$, and \cite[Lemma 9.3]{tropp2023randomized} we have     %      %     \max\limits_{i=1,\ldots,k} \left|\frac{e^{\lambda_i-\lambda_{\min}}}{p(\lambda_i)}\right|^2      %     &\leq      %     \max\limits_{i=1,\ldots,k} \left|\frac{e^{\lambda_i-\lambda_{\min}}}{T_{s-2}\big(\frac{x-\lambda_{\min}}{\lambda_{k+1}-\lambda_{\min}}\big)}\right|^2      %     \\&\hspace{5em}\leq \frac{e^{2\gamma}}{T_{s-2}\big(\frac{\lambda_k-\lambda_{\min}}{\lambda_{k+1}-\lambda_{\min}}\big)^2}      %     \leq      %     4 e^{2\gamma-4(s-2)\sqrt{\gamma}},     %      % Plugging this inequality into \cref{eqn:Esexp_bd} and then \cref{eqn:Esexp_bd} into \cref{theorem:krylov_aware} yields the desired inequality.",2502.01888
proof,"Given two monomials $\bdx^\bda \bdT^\bdb$ and $\bdx^\bdc \bdT^\bdd$ in $S$, we set $\bdx^\bda \bdT^\bdb >_{\tau'} \bdx^\bdc \bdT^\bdd$ if and only if (i) $\bdx^\bda  >_{lex} \bdx^\bdc$ or (ii) $\bdx^\bda = \bdx^\bdc$ and $\bdT^\bdb >_{\tau} \bdT^\bdd$. It is the product order on $S$ of the lexicographic order on $R$ and the order $\tau$ on $T$ in the sense of \cite[page 17]{EH}.      Take any $g\in \calJ$. Since the prime ideal $\calJ$ has a binomial generating set,      we can assume that $g$ is an irreducible binomial. We have two cases.     [a]         \item Suppose that $g\in \calK$. Therefore, $\ini_{\tau'}(g)=\ini_{\tau}(g)$ is divisible by $\ini_{\tau'}(h)=\ini_{\tau}(h)$ for some $h\in \calG$.         \item Suppose that $g\notin \calK$. Therefore, we may assume that $g=x_q\bdx^{\bda}\bdT^{\bdb} - x_{q'}\bdx^{\bda'}\bdT^{\bdb'}$ where $q$ is the smallest such that $x_q$ appears in the binomial $g$. Since $g$ is irreducible, $q\ne q'$ and $q\notin \supp(\bdx^{\bda'})$. Thus, $\deg_{x_q}(u)<\deg_{x_q}(v)$, where $u\coloneqq \psi(\bdT^{\bdb})$ and $v\coloneqq \psi(\bdT^{\bdb'})$. Whence, by the strong $\ell$-exchange property of $I_1,\dots,I_r$, we can find $T_{i,\alpha_{i,j}}$ dividing $\bdT^{\bdb}$ and $q''>q$ such that $x_qf_{i,\alpha_{i,j}}/x_{q''}\in I_i$. Let $q''$ be the largest such that $x_qf_{i,\alpha_{i,j}}/x_{q''}\in I_i$ and write $f_{i,s}= x_qf_{i,\alpha_{i,j}}/x_{q''}$. Whence, $h\coloneqq x_qT_{i,\alpha_{i,j}}-x_{q''}T_{i,s}\in \calJ$ with $\ini_{\tau'}(h)=x_qT_{i,\alpha_{i,j}}$ dividing $\ini_{\tau'}(g)=x_q\bdx^{\bda}\bdT^{\bdb}$.          By the above discussion, it is clear now that $\calG'$ is a Gr\""obner basis of $\calJ$ with respect to $\tau'$. Furthermore, if $\calG$ is a reduced Gr\""obner basis, then it is clear that $\calG'$ is also a reduced Gr\""obner basis.",2502.01917
proof,"Let $\bfC=[c_{i,j}]$ be an arbitrary semi-standard tableau with $\supp(\bfC)=\supp(\bfB)$. If $\bfC\ne \bfB$, we will prove that $\bfC>_{\sigma} \bfB$. Therefore, $\bfB$ is standard.      Let $j_0=\min\{j: c_{i,j}\ne b_{i,j} \text{ for some $i\in [p]$ and $j\in [n]$}\}$ and $i_0=\min\{i\in [p]:c_{i,j_0}\ne b_{i,j_0}\}$.     Based on \Cref{rmk:reductions}\ref{rmk:reductions_b}, we can assume that $j_0=n$ and $i_0=1$.      For each $i$ and $j$, let $\bdc^i_{j}$ be the vector $(c_{i,1},c_{i,2},\dots,c_{i,j})$. Whence, $\bdc^i_{j}=\bdb^i_{j}$ for $i\in [p]$ and $j\in [n-1]$ by the choice of $i_0$ and $j_0$. Let $i_1 \coloneqq \max\{i: \bdb^i_{n-1}=\bdb^1_{n-1}\}$. Consequently, $\bdb^1_{n-1}=\bdb^2_{n-1}=\cdots=\bdb^{i_1}_{n-1}$.  It follows from \eqref{eqn:cond_1} that $c_{1,n}\le c_{2,n} \le \cdots \le c_{i_1,n}$ and  $b_{1,n}\le b_{2,n}\le \cdots \le b_{i_1,n}$. Furthermore, (Cond-2) implies that the multiset $\{b_{1,n},b_{2,n},\dots,b_{i_1,n}\}$ is the $i_1$-subset of $\supp_{n}(\bfA)$ with the largest sum. Since $c_{1,n}\ne b_{1,n}$ by the choice of $i_0$ and $j_0$, we have $\{b_{1,n},b_{2,n},\dots,b_{i_1,n}\}\ne \{c_{1,n},c_{2,n},\dots,c_{i_1,n}\}$. This implies that $[\bdc^1_{n}, \ldots,\bdc^{i_1}_{n}] >_{\sigma} [\bdb^{1}_{n},\ldots,\bdb^{i_1}_{n}]$. Since $\bdc^{i}_{j}=\bdb^i_{j}$ for $i\in [p]$ and $j\in [n-1]$, and     \[         \bdb^1_{n-1}=\bdb^2_{n-1}=\cdots=\bdb^{i_1}_{n-1}>_{\sigma}\bdb^{i_1+1}_{n-1}\ge_{\sigma} \cdots \ge_{\sigma} \bdb^{p}_{n-1},     \]     this implies that $[\bdc^1_{n},\ldots,\bdc^{p}_{n}]>_{\sigma} [ \bdb^{1}_{n}, \ldots, \bdb_{n}^p]$, i.e., $\bfC>_{\sigma} \bfB$.",2502.01917
proof,"If $\bda=\bdb$, then for any semi-standard tableau $[\bdp,\bdq]$ with $\supp ([\bdp,\bdq])=\supp([\bda,\bdb])$, we must have $\bdp=\bdq=\bda=\bdb$. Therefore, $[\bda,\bdb]$ is standard. Thus, in the following, we will assume $\bda\neq \bdb$.      Suppose that there exists a value $k$ such that $a_{i}=b_{i}$ for all $i<k$, and $a_k<b_{k}$ but $  a_{j}\geq b_j$ for all $k<j\leq n$. Then, for any semi-standard tableau $[\bdp,\bdq]$ with $\supp ([\bdp,\bdq])=\supp([\bda,\bdb])$, we have $p_i=a_{i}=b_{i}=q_i$ for all $i<k$. It is clear that $a_k=\min\{a_k,b_k\}=\min\{p_k,q_k\}=p_k$ by \eqref{eqn:cond_1}. Additionally, $a_j = \max\{a_j,b_j\} =\max\{p_j,q_j\}\ge p_j$ for all $k<j\leq n$, by the assumptions on $k$. Therefore, $\bdp \geq_{\sigma} \bda >_{\sigma} \bdb$. Moreover, $\bdp=\bda$ if and only if $\bdq=\bdb$. Thus, $[\bdp,\bdq] \geq_{\sigma} [\bda,\bdb]$, implying that $[\bda,\bdb]$ is standard.      Conversely, suppose that no such $k$ exists.      Since $\bda\ne \bdb$ and $[\bda,\bdb]$ is semi-standard, we have $a_{k'}<b_{k'}$ from \eqref{eqn:cond_1} for $k'\coloneqq \min\{j\in [n]:a_j\ne b_j\}$. Due to the non-existence of such $k$ and the choice of $k'$, we can find $j>k'$ such that $a_j<b_j$. Then, we  consider the tuples $\bdp=(p_1,\ldots, p_{n})$ and $\bdq=(q_1,\ldots, q_{n})$ such that      \[         p_\ell=                      a_{\ell}, & \text{if $\ell\ne j$,} \\             b_j, & \text{if $\ell=j$,}                  \qquad \text{and} \qquad         q_\ell=                      b_{\ell}, & \text{if $\ell\ne j$,} \\             a_j, & \text{if $\ell=j$.}              \]     It is clear that $\bda>_{\sigma}\bdp \ge_{\sigma} \bdq$ and $\supp ([\bdp,\bdq])=\supp([\bda,\bdb])$.      This indicates that $[\bda,\bdb]$ is not standard.",2502.01917
proof,"Let $\bfB=[\bdb^1, \ldots, \bdb^{p}]$ be the tableau constructed in \Cref{algo_standard_tab} from $\bfA$. According to \Cref{lem:algo_works}, $\bfB$ is standard. Furthermore, it follows from the construction of $\bfB$ in \Cref{algo_standard_tab} and \Cref{StandardProp} that $[\bdb^h, \bdb^{k}]$ is standard for every $1 \leq h < k \leq p$.     [a]         \item Suppose that $\bfA$ is standard. It follows from the uniqueness of standard tableau that $\bfA=\bfB$. Consequently, $[\bda^h, \bda^{k}]$ is standard for every $1 \leq h < k \leq p$.          \item Conversely, suppose that $[\bda^h, \bda^{k}]$ is standard for every $1 \leq h < k \leq p$. We prove that $\bfA$ is standard. For this purpose, in the following, we prove by induction on $n$ that $\bda^i=\bdb^i$ for each $i$.  Suppose that the $(i,j)$-entries of the semi-standard tableaux $\bfA$ and $\bfB$ are $a_{i,j}$ and $b_{i,j}$, respectively.              Notice that the base where $n=1$ is clear, since $a_{1,1}\le a_{2,1}\le \cdots\le a_{p,1}$ and $b_{1,1}\le b_{2,1}\le \cdots \le b_{p,1}$             from \eqref{eqn:cond_1}.             Now, consider the general case. For              $i\in [p]$ and $j\in [n]$,             let ${\bda}^i_{j}=({a}_{i,1},\dots,{a}_{i,j})$ and $\bdb^i_{j}=(b_{i,1},\dots,b_{i,j})$, by abuse of notation. It follows from \Cref{StandardProp} that both $[\bda^h_{n-1},\bda^k_{n-1}]$ and $[\bdb^h_{n-1},\bdb^k_{n-1}]$ are standard for $1\le h \le k \le p$. Furthermore, it is clear that $\supp([\bda^1_{n-1},\bda^2_{n-1},\dots,\bda^p_{n-1}])= \supp([\bdb^1_{n-1},\bdb^2_{n-1},\dots,\bdb^{p}_{n-1}])$. Hence, by the induction hypothesis for the $n-1$ case, we know that $\bda^i_{n-1}=\bdb^i_{n-1}$ for each $i$.              Moreover, for $1\le h< k \le p$, since $[{\bda}^h_{n}={\bda}^h, {\bda}^k_{n}={\bda}^k]$ and $[{\bdb}^h_{n}={\bdb}^h, {\bdb}^k_{n}={\bdb}^k]$ are standard, we have the following observations from \Cref{StandardProp}:                              \item if $\bda^h_{n-1}=\bdb^h_{n-1}>_{\sigma} \bda^k_{n-1}=\bdb^k_{n-1}$, then ${a}_{h,n}\ge {a}_{k,n}$ and $b_{h,n}\ge b_{k,n}$;                 \item if $\bda^h_{n-1}=\bdb^h_{n-1}=\bda^k_{n-1}=\bdb^k_{n-1}$, then ${a}_{h,n} \le {a}_{k,n}$ and $b_{h,n}\le b_{k,n}$.                          Since $\sigma$ is a total order, we deduce readily from \Cref{obs_inc} that the ordered multiset $\{a_{1,n},a_{2,n},\dots,a_{p,n}\}$ and $\{b_{1,n},b_{2,n},\dots,b_{p,n}\}$ are uniquely determined. Since $\supp_{n}(\bfA)=\supp_{n}(\bfB)$, we have $a_{i,n}=b_{i,n}$ for each $i$. In short, $\bda^i_{n}=\bdb^i_{n}$ for each $i$.              Consequently, $\bfA=\bfB$. In particular, $\bfA$ is standard.             \qedhere",2502.01917
proof,"By \Cref{extendtoN+1}, we need to show  $\calG\coloneqq \bfI(\widetilde{\calD_r})$ is a Gr\""{o}bner basis of the presentation ideal $\calK$ of the special fiber ring $\calF(I_{\widetilde{\calD_r}})$. By \cite[Lemma 4.1]{Sturmfels}, the set              \calG^\dag\coloneqq \{\bdT_{\bfA}-\bdT_{\bfB} &: \text{ $\bfA$ and $\bfB$ are two semi-standard tableaux with}\\         & \quad \text{ row vectors in $\widetilde{\calD_r}$ and $\supp(\bfA)=\supp(\bfB)$}\}          is a generating set of the presentation ideal of $\calF(I_{\widetilde{\calD_r}})$ as a $\KK$-vector space. Since $\calG\subseteq \calG^\dag$, it suffices to show that $\ini_\sigma(f)\in (\ini_\sigma(g):g\in \calG)$ for every $f\in\calG^\dag$. Without loss of generality, suppose that $f=\bdT_{\bfA}-\bdT_{\bfB}$ with $\text{supp}(\bfA)=\text{supp}(\bfB)$ and $\ini_{\sigma }(f)=\bdT_{\bfA}$. Furthermore, assume that $\bfA=[\bda^1,\dots,\bda^p]$.     [a]         \item If $\bfA$ is not standard, by \Cref{StandardExist}, there exist $1\le h<k\le p$ such that the $2$-row semi-standard tableau $[\bda^h,\bda^k]$ is not standard. Applying \Cref{algo_standard_tab}, we can find a standard tableau $[\bdp,\bdq]$ from $[\bda^h,\bda^k]$. Since $\widetilde{\calD_r}$ is also a rectangular diagram, $\bdp,\bdq\in \widetilde{\calD_r}$. Whence, the binomial $f'\coloneqq T_{\bda^h}T_{\bda^k}-T_{\bdp}T_{\bdq}$ belongs to $\calG$. Notice that $\ini_\sigma(f')=T_{\bda^h}T_{\bda^k}$, which divides $\ini_\sigma(f)=\bdT_{\bfA}$.             Therefore, $\ini_\sigma(f) \in (\ini_\sigma(g):g\in \calG)$.         \item If $\bfA$ is standard, then $\bfB \geq_\sigma \bfA$. Since $\ini_\sigma(f)=T_\bfA$, this implies that $T_\bfB=T_\bfA$ and $f=0$. This case is trivial. \qedhere",2502.01917
proof,"[a]         \item By the uniqueness of standard tableau, we know $[\bda,\bdb]$ is not standard.  In particular, $\bda\ne \bdb$. But since $[\bda,\bdb]$ is semi-standard, there is a $k$ such that $a_i=b_i$ for $i<k$, and $a_k<b_k$. This implies that $a_i=p_i=q_i=b_i$ for $i<k$ and $a_k=p_k<q_k=b_k$. Since $[\bdp,\bdq]$ is standard, by \Cref{StandardProp}, we must have $p_j=\max\{a_j,b_j\} \ge q_j=\min\{a_j,b_j\}$ for $j>k$.              Since $\calD$ is standardizable and $\bda,\bdb\in \calD$, we obtain $\bdp\in \calD$ by \Cref{def:SDP}. Notice that $q_j\leq b_j$ for each $j$.             Since $\bdb$ is an element of $\calD$, we can conclude that $\bdq$ is also an element of $\calD$ due to the Ferrers property of $\calD$.          \item              Since $\calD$ is standardizable, it is clear that $\widetilde{\calD_r}$             is also standardizable. Thus, it remains to apply the previous part with respect to $\widetilde{\calD_r}$.             \qedhere",2502.01917
proof,"By \Cref{extendtoN+1}, \Cref{LexClosed}, \cite[Proposition 4.13]{Sturmfels}, and \cite[Proposition 2.1]{DeNegri}, it suffices to assume that $\calD$ is a rectangular Ferrers diagram. Meanwhile, the corresponding result for this special case has already been given in \Cref{FiberofOneGen}.",2502.01917
proof,"Notice that $\calF(\bigoplus_{i=1}^{r} I_{\calD})$ is isomorphic to the semigroup ring $\KK[I_{\widetilde{\calD_r}}]$.     By \Cref{FiberD} and \Cref{2-minors}, the presentation ideal $\calK$ of $\calF(\bigoplus_{i=1}^{r} I_{\calD})$ has a squarefree initial ideal. Therefore, $\calF(\bigoplus_{i=1}^{r} I_{\calD})$ is normal by \cite[Proposition 13.15]{Sturmfels}, and it is Cohen--Macaulay by     \cite[Theorem 1]{Hochster}.      The following argument from \cite[Corollary 2.3]{Sagbi} proves the statements regarding the singularities. We cite it here for readers' convenience.     By Hochster \cite[Proposition 1]{Hochster}, since $\calF(\bigoplus_{i=1}^{r} I_{\calD})$ is normal, it is a direct summand of a polynomial ring. Thus by a theorem of Boutot \cite{Boutot}, $\calF(\bigoplus_{i=1}^{r} I_{\calD})$ has rational singularities if the characteristic of $\KK$ is zero.     Furthermore, by a theorem of Hochster and Huneke \cite{MR1044348}, $\calF(\bigoplus_{i=1}^{r} I_{\calD})$ is strongly $F$-regular. In particular, it is $F$-rational, if $\KK$ has positive characteristic.",2502.01917
proof,"For notational simplicity, we denote the variables      \[         x_{1,1},\dots,x_{1,m},x_{2,1},\dots,x_{2,m},\dots,x_{n,1},\dots,x_{n,m}      \]     in $R$ by $z_1, z_2, \dots,z_{nm}$.  Suppose that $\{f_{k,1},\dots,f_{k,\mu_i}\}$ is a minimal monomial generating set of $I_{\calD_k}$, for $k\in [r]$. Furthermore, suppose that $(w_1,\dots,w_r)\in \NN^r$, and $u=\prod_{k=1}^r\prod_{\ell=1}^{w_k} f_{k,\alpha_{k,\ell}}$, $v=\prod_{k=1}^r \prod_{\ell=1}^{w_k} f_{k,\beta_{k,\ell}}$ satisfy     [i]         \item $\deg_{z_t}(u)=\deg_{z_t}(v)$ for $t=1,\dots,q-1$ with $q\le nm-1$,         \item $\deg_{z_q}(u)<\deg_{z_q}(v)$.          Suppose that $z_q=x_{i_0,j_0}$ in the above notation.      Then,     \[         \sum_{j=1}^{j_0-1} \deg_{x_{i_0,j}}(u) =\sum_{j=1}^{j_0-1} \deg_{x_{i_0,j}}(v)             \quad\text{ and }\quad         \sum_{j=1}^{j_0} \deg_{x_{i_0,j}}(u) < \sum_{j=1}^{j_0} \deg_{x_{i_0,j}}(v).         \]     Since     \[         \sum_{j=1}^m \deg_{x_{i_0,j}}(u)         = \sum_{\substack{k\in [r],\\ n_k\ge i_0}} w_k         =\sum_{j=1}^m \deg_{x_{i_0,j}}(v),     \]     we must have $j_0\le m-1$.     Furthermore, we can find $j_1$ with $j_0<j_1\le m$ such that $\deg_{x_{i_0,j_1}}(u)\ge 1$. Let $z_{q'}=x_{i_0,j_1}$. It is clear that $q'>q$. Whence, we can find $k,\ell$ such that $f_{k,\alpha_{k,\ell}}$ divides $u$ and $\deg_{z_{q'}}(f_{k,\alpha_{k,\ell}})= 1$. Since ${\calD_{k}}$ is a Ferrers diagram, it is clear that $z_q f_{k,\alpha_{k,\ell}}/z_{q'}\in I_{\calD_{k}}$.",2502.01917
proof,"The fact that $\mathcal{G}'$ constitutes a Gr\""obner basis for the presentation ideal of $\mathcal{R}(\bigoplus_{i=1}^{r}I_{\mathcal{D}})$ with respect to the order $\sigma'$ defined in \Cref{order} is a direct outcome of \Cref{FiberD}, \Cref{LEx}, and \Cref{thm:ReesIdeal}. The remaining assertions can be established through a comparable argument employed in the proof of \Cref{CMFiber}.",2502.01917
proof,"\citet{vonStaudt} showed that $T^*$ is a spanning tree of $G^*$.   			First note that every edge $e\in E(G)$ is incident to some face $f$, and $e\subseteq B_f$. Now consider a vertex $v$ of $G$, and the set $S_v:=\{f\in V(T^*):v\in B_f\}$. 			Note for any three vertices $v',w',z'\in V(T)$, we have $T_{v',z'}\subseteq T_{v',w'}\cup T_{w',z'}$. 			Thus a face $f\in V(T^*)$ is in $S_v$ if and only if there is an edge $uw\in E(G)$ incident to $f$ such that $v\in V(T_{u,v})$. 			That is, either $v\in \{u,w\}$ or $u$ and $w$ are in different components of $T-v$. 			Let $t=\deg_G(v)$, let $\{v_i:i\in \mathbb{Z}_t\}$ be the neighbours of $v$ in clockwise order, and for each $i\in \mathbb{Z}_t$ let $C_i$ be the component of $T-v$ containing $v_i$, and let $f_i$ be the face of $G$ incident to $v$, $v_i$ and $v_{i+1}$ (we may assume this face is unique since otherwise $G\cong K_3$ and the result is trivial. 			Note that for each $i\in \mathbb{Z}_t$, the edge cut $E(V(G)\setminus V(C_i),V(C_i))$ corresponds to a cycle $O_i$ in $G^*$. Furthermore, $f_{i-1}$ and $f_i$ are adjacent in $O_i$, and the edge connecting them is the unique edge in $E(O_i)\setminus E(T^*)$. Thus, $P_i:=T^*[V(O_i)]$ is a path in $T^*$. 			With this definition, note that $P_i$ and $P_{i+1}$ intersect in the vertex $f_i$, and so  			$\bigcup \{P_i:i\in \mathbb{Z}_t\}$ is connected. 			Observe that $V(\bigcup \{P_i:i\in \mathbb{Z}_t\})$ contains all and only the faces of $G$ which are incident to some edge whose end-vertices lie in distinct components of $T-v$.  			Thus, $S_v$ induces a connected subgraph of $T^*$, as required.",2502.01927
proof,"If $V(H_1)\subseteq S$ then $S=V(H_1)$ by the minimality of $S$, implying $G[S]$ is connected, as desired.  			Now assume that $V(H_1)\setminus S\neq\emptyset$. 			Let $J_1,\dots,J_k$ be the components of $G-S$ intersecting $H_1$. Let $J:=J_1\cup\dots\cup J_k$.  			Since $S$ separates $H_1$ and $H_2$, the subgraphs $J$ and $H_2$ are disjoint. Since $H_2$ is connected, $H_2$ lies within a single face $F$ of the embedding of $J$ induced by the embedding of $G$.  			Let $B_i$ be the set of vertices of $J_i$ on the boundary of $F$. Let $N_i$ be the set of vertices in $V(G)\setminus V(J)$ that are adjacent to at least one vertex in $B_i$. Since $J_i$ is a component of $G-S$, we have $N_i\subseteq S$. One can draw a closed curve $X_i$ in $F$ touching $G$ precisely at the vertices in $N_i$. Since $G$ is a triangulation, consecutive vertices on $X_i$ are adjacent in $G$. So $G[N_i]$ is connected. By construction, $N_i$ separates $J_i$ and $H_2$.  			If $H_1$ and $S$ are disjoint, then $k=1$ and $N_1$ separates $H_1$ and $H_2$, implying $S=N_1$ by the minimality of $S$, and $G[S]=G[N_1]$ is connected, as desired. Now assume that $H_1$ intersects $S$.  			Each $J_i$ is connected and intersects $H_1$, which is connected.  			So $H_1\cup J_1\cup\dots\cup J_k$ is connected.  			Since  $H_1$ intersects $S$ and $H_1$ is connected, each set $B_i$ has a vertex in $H_1$ which is adjacent to a vertex in $N_i\cap V(H_1)$. Since $G[N_i]$ is connected, $X:=H_1\cup J_1\cup\dots\cup J_k\cup G[N_1]\cup \dots\cup G[N_k]$ is connected. 			Note that all neighbours of $J_i$ in $X-J_i$ are in $N_i$, that $X[N_i]$ is connected and that $J_i$ is disjoint from $N_1\cup\dots\cup N_k$. 			It follows that $X-(J_1\cup\dots\cup J_k)$ is connected. 			%Since  $J_i$ is a component of $X-N_i$ and $X[N_i]$ is connected, $X-J_i$ is connected.  			%Since  $J_1,\dots,J_k$ are pairwise disjoint, $X-(J_1\cup\dots\cup J_k)$ is connected.  			By construction, $X-(J_1\cup\dots\cup J_k)$ is the subgraph of $G$ induced by $T:=(N_1\cup \dots\cup N_k)\cup(V(H_1)\cap S)$, which is a subset of $S$.  			%Let $X'$ be obtained from $X$ by contracting each $J_i$ to a single vertex $j_i$. So $X'$ is connected. Note that $H_i\cap S$ is untouched by these contractions, so $V(H_i)\cap S$ is in $X'$. By construction, $\{j_1,\dots,j_k\}$ is an independent set in $X'$, and $N_{X'}(j_i)=N_i$ and $G[N_i]$ is connected. So $X'':=X'-\{j_1,\dots,j_k\}$ is connected. By construction, $X''$ is the subgraph of $G$ induced by $T:=(N_1\cup \dots\cup N_k)\cup(V(H_1)\cap S)$, which is a subset of $S$.  			By construction, $T$ separates $H_1$ and $H_2$. By the minimality of $S$, we have $S=T$. Thus $G[S]=G[T]$ is connected.",2502.01927
proof,"Let $k:=\tw(G)+1$. Let $V_i:=\{v\in V(G):\dist_G(r,v)=i\}$ for $i\geq 0$. So ($V_0,V_1,\dots)$ is a layering of $G$. Define a graph $T$ and $T$-partition $(B_x:x\in V(T))$ as follows. For each $i\geq 0$ and each component $C$ of $G[V_i]$, add one vertex $x$ to $T$ with $B_x:=V(C)$. For distinct vertices $x,y\in V(T)$, add the edge $xy$ to $T$ if and only if there is an edge of $G$ between $B_x$ and $B_y$. So $(B_x:x\in V(T))$ is a $T$-partition of $G$.  			%Note that (with $i=0$) there is one node $x\in V(T)$ with $B_x=\{r\}$; call this node \defn{$r_0$}.  			%Let $\PP$ be the partition of $G$ with one part for each component of $G[V_i]$ for $i\geq 0$.  Let $T$ be the graph with one vertex for each part of $\PP$, with an edge $PQ$ in $T$ if and only if there is an edge $vw\in E(G)$ with $v\in P$ and $w\in Q$.  			 			Consider a node $x\in V(T)$ with $B_x\subseteq V_i$ with $i\geq 1$. Let $S$ be the set of vertices in $V_{i-1}$ adjacent to at least one vertex in $B_x$. By construction, $G[B_x]$ is connected. So there is a component $C$ of $G[V_i\cup V_{i+1}\cup \dots]$ containing $B_x$. Every vertex that is not in $C$ and is adjacent to a vertex in $C$ is in $S$. So $S$ separates $C$ from $\{r\}$. Moreover, for each vertex $v\in S$, there is a neighbour $w$ of $v$ in $B_x$, and there is a path from $v$ to $r$ internally disjoint from $S$. Thus $S$ is a minimal set separating $V(C)$ from $\{r\}$. By \cref{TriangulationSeparator}, $G[S]$ is connected. Since $S\subseteq V_{i-1}$ there is a node $y$ in $T$ with $S\subseteq B_y$. By the construction of $T$, $x$ has exactly one neighbour $y$ in $T$ with $B_y\subseteq V_{i-1}$. Thus $T$ is a tree. Consider $T$ to be rooted at the node corresponding to part $\{r\}$ (which exists, by the $i=0$ case). For $i\geq 1$, since every vertex in $V_i$ has a neighbour in $V_{i-1}$, the $T$-partition $(B_x:x\in V(T))$ is parent-dominated. 			 			Suppose that $\dist_G(v,w)\geq 3k$ for some $v,w$ in one part $B_{x_i}$ with $B_{x_i} \subseteq V_i$. By the triangle-inequality, $\dist_G(v,w) \leq \dist_G(r,v)+\dist_G(r,w)=2i$, implying $2i\geq 3k$. Let  			$x_0,x_1,\dots,x_i\in V(T)$ where $x_{i-1}$ is the parent of $x_i$ in $T$. So $B_{x_j}\subseteq V_j$ for each $j\in\{0,\dots,i\}$. Abbreviate $B_{x_j}$ by $B_j$.  			 			We claim that there are $k+1$ pairwise disjoint paths in $G$ between $B_i$ and $B_{i-k}$. If not, by Menger's Theorem, there is a minimal set $S\subseteq V(G)$ separating $B_i$ and $B_{i-k}$ with $|S|\leq k$. By \cref{TriangulationSeparator}, $G[S]$ is connected. Now  			 				3k\leq \dist_G(v,w) 				& \leq \dist_G(v,S)+\dist_G(w,S)+|S|-1 \\ 				& \leq 				\dist_G(v,B_{i-k})+\dist_G(w,B_{i-k})+|S|-1 \\ 				& \leq 3k-1, 			 			which is a contradiction. Hence there are pairwise disjoint paths $Q_1,\dots,Q_{k+1}$ between $B_i$ and $B_{i-k}$.  			Let $\beta:= \{Q_a\cup B_b: a\in\{1,\dots,k+1\}, b\in\{i-k,\dots,i\}\}$.  			By construction, each of $G[B_{i-k}],\dots,G[B_i]$ is connected, and each such path $Q_a$ must intersect each of $B_{i-k},\dots,B_i$. Thus $\beta$ is a bramble.  			If $S\subseteq V(G)$ and $|S|\leq k$, then $S\cap (Q_a\cup P_b)=\emptyset$ for some $a\in\{1,\dots,k+1\}$ and $b\in\{i-k,\dots,i\}$, implying $S$ is not a hitting set for $\beta$. Hence the order of $\beta$ is at least $k+1$, and $\bn(G)\geq k+1$. By \cref{TreewidthDuality}, $\tw(G)\geq k$, which is a contradiction. 			 			Hence 			$\dist_G(v,w)\leq 3k-1=3(\tw(G)+1)-1=3\tw(G)+2$ for all $v,w$ in any one part $B_x$. Therefore, the $T$-partition $(B_x:x\in V(T))$ has weak-diameter at most $3\tw(G)+2$.",2502.01927
proof,"%     Let $u$ and $v$ be distinct vertices in $P_t$ and let $d:=\dist_G(u,v)$. 			%     Since $(T,\mathcal{P})$ has width $0$, the distance from $t$ to the root $r$ of $T$ is at least $\frac{d}{2}$.  			%     Let $t'$ be the ancestor of $t$ at distance $d/3$?? from $t$. 			%     We construct a bramble for $G$ as follows 			 			%",2502.01927
proof,"We will show that for each bag $B_f$ of $\TT$ and each component $T'$ of $F$ we have that $B_f\cap V(T')$ contains at most $2$ vertices of each layer of $\mathcal{L}_{G,(S,f)}$, which will immediately imply the result. 			Recall that $B_f$ is indexed by a face $f$ of $G$, and that $B_f=V(T_{v,w})\cup V(T_{w,z})$, where $v,w$ and $z$ are the three vertices of $G$ incident to $f$.  			Note that for any path $P$ in $T$ and any pair of vertices $v',w'\in V(P)\cap V(T')$, we have $P_{v',w'}=T_{v',w'}=T'_{v',w'}$. 			Thus $V(P)\cap V(T')$ is a connected subgraph of $P$, and is therefore a path. 			By the definition of $F$, there is a unique vertex $s$ in $T'$ which minimises $\ell_{G,(S,f)}(s)$, and $s\in S$. 			We say that a path $v_0v_1\dots v_\ell$ in $T'$ is \emph{ascending} if $\ell_{G,(S,f)}(v_i)=1+\ell_{G,(S,f)}(v_{i-1})$ for each $i\in [\ell]$. 			It follows inductively from the definition of $F$ that for each $v\in V(T')$ there is an ascending path from $v$ to $s$.  			Now, given a path $P$ in $T'$ with end-vertices $v'$ and $w'$, $P$ is contained in the union of an ascending path from $v'$ to $s$ and an ascending path from $w'$ to $s$. 			It follows that $V(T_{v,w})\cap V(T')$ contains at most two vertices of each layer, and likewise $V(T_{w,z})\cap V(T')$ contains at most two vertices of each layer. 			Thus, in total $B_f\cap V(T')$ contains at most four vertices of each layer, as required.",2502.01927
proof,"For each node $v\in V(T)$, let $w(v)$ be the number of descendents of $v$. We call $w(v)$ the \defn{weight} of $v$. 			Let $E^*$ be the set of edges $uv$ of $T$ such that $u$ is the parent of $v$ and, for some $i\in [\tau]$, we have that $k(n/k)^{i/\tau}\geq w(u)> k(n/k)^{(i-1)/\tau}$ and $w(v)>w(u)-\frac{1}{2}(n/k)^{(i-1)/\tau}$. 			Note that each component of $(V(T),E^*)$ is an upward path in $T$.  			Let $\mathcal{C}'$ be a maximum size set of pairwise edge-disjoint paths of length $k$ in the graph $(V(T),E^*)$, such that for any $i\in [k-1]$ and any component $P$ of $(V(T),E^*)$ of length congruent to $i$ mod $k$, the $i$ edges of $P$ which are furthest from $r$ in $T$ are not in $\bigcup \{E(U):U\in \mathcal{C}\}$.             Let $\mathcal{U}$ be the union of $\mathcal{U}'$ and the length $0$ path $r$. 			 			Clearly $\mathcal{U}$ satisfies \ref{item:pathlengths}. To see that \ref{item:depth} is satisfied, consider an arbitrary vertex $x\in V(T)$, and let $v^*$ be the vertex of $T_{r,x}$ of largest weight such that $w(v^*)\leq k(n/k)^{1/\tau}$. 			Note that $k(n/k)^{\tau/\tau}\geq w(u)$ for every $u\in V(T)$. 			Additionally, for each $uv\in E(P)$ such that $u$ is the parent of $v$, we have that $w(u)\geq w(v)+1$. 			It follows that for each $i\in [\tau]$, there are at most $2(n/k)^{(1/\tau)}$ edges $uv$ in $E(P)\setminus E^*$ such that $k(n/k)^{i/\tau}\geq w(u)> k(n/k)^{(i-1)/\tau}$, where $u$ is the parent of $v$. 			Thus, in total, the subpath of $P$ from $r$ to $v^*$ has at most $2\tau(n/k)^{(1/\tau)}$ edges not in $E^*$. Thus, the restriction of $P_{r,v^*}$ to $E^*$ has at most $1+2\tau(n/k)^{(1/\tau)}$ components. By our choice of $\mathcal{U}'$, each of these components has at most $k-1$ edges which are not in  			$\bigcup\{E(U):U\in\mathcal{U},U\subseteq P\}$.  			Thus, if $c_P$ is the number of paths of $\mathcal{U}\setminus \{r\}$ which are properly contained in $P$, then  			\[|E(P)| \leq (k-1)(1+2\tau(n/k)^{(1/\tau)})+\tau(n/k)^{(1/\tau)}+k(n/k)^{1/\tau}+kc_P<(3\tau(n/k)^{1/\tau}+1)k+kc_P.\] 			 			For each $i\in [\tau]$, let $S_i$ be the set $\{v\in V(T):k(n/k)^{i/\tau}\geq w(v)> k(n/k)^{(i-1)/\tau}\}$, and let $S_0:=V(T)\setminus \bigcup\{S_i:i\in [\tau]\}$. 			Now consider an upward path $P$ which intersects more than $\tau$ paths in $\mathcal{U}$. 			For each $i\in [\tau+1]$ let $U_i$ be a path in $\mathcal{U}$ which intersects $P$ and let $v_i$ be the vertex in $V(P)\cap V(U_i)$ which is furthest from $r$, ordered so that $w(v_i)>w(v_{i+1})$ for all $i\in [\tau]$. 			Note that for each $i\in [\tau]$, $P$ contains a child of $v_i$ which is not in $U_i$. 			We may assume that for each $i\in [\tau]$, $v_i$ is not the furthest vertex of $U_i$ from $r$. 			Now, since for each $i\in [\tau]$ $v_i$ has a child in $U_i$ and all edges of $U$ are in $E^*$, there is a function $f:[\tau]\to [\tau]$ such that $v_i$ is in $S_{f(i)}$ and the child of $v_i$ in $P$ is not in $S_{f(i)}$. 			In particular, $f$ must be the order reversing bijection, so $f(i)=\tau+1-i$ for all $i\in [t]$. 			But now $v_{\tau+1}\in S_0$, which means $v_{\tau+1}$ must be the vertex of $U_{\tau+1}$ which is furthest from $r$.",2502.01927
proof,"By \cref{lem:twdiamparts}, for an arbitrary vertex $v_0\in V(G)$, there is a tree $T$ rooted at node $r\in V(T)$, and $G$ has a parent-dominated $T$-partition $\PP=(P_x:x\in V(T))$ with weak-diameter at most $3\tw(G)+2$, where $P_r=\{v_0\}$. Apply \cref{lem:upwardpaths} to $T$ with $k:=3\tw(G)+3$ to obtain a set $\mathcal{U}$ of upward paths. For each $U\in \mathcal{U}$, let $r_U$ be the end-vertex of $U$ furthest from $r$ in $T$, let $q_U$ be the end-vertex of $U$ closest to $r$ in $T$, and select an arbitrary vertex $s_U\in P_{r_U}$. Let $S:=\{s_U:U\in \mathcal{U}\}$. For each $U\in \mathcal{U}$, let $\hat{U}$ be the path in $T$ from $r$ to $r_U$. 			Let $\hat{T}$ be the graph obtained from $T$ by identifying $r_U$ with $q_U$ for each $U\in \mathcal{U}$. 			Let $f:S\to \mathbb{Z}$ so that for each $U\in \mathcal{U}$, $f(s_U)=\dist_{\hat{T}}(r,r_U)$. 			Note that for each $U\in \mathcal{U}$, $f(s_U)\leq |E(\hat{U})|-kc_{\hat{U}}$, where $c_{\hat{U}}$ is the number of paths in $\mathcal{U}\setminus \{r\}$ which are properly contained in $\hat{U}$. 			Also note that for each $U\in \mathcal{U}$, $r_U$ separates $V(U)$ from $r$ in $\hat{T}$. 			 			 			%Let $f:S\to \mathbb{N}$ so that for each $U\in \mathcal{U}$, $f(s_U):=|E(\hat{U})|-c_{\hat{U}}k$, where $c_{\hat{U}}$ is the number of paths in $\mathcal{U}\setminus \{r\}$ which are properly contained in $\hat{U}$. 			 			We now verify that $(S,f)$ is a seed. 			Consider distinct paths $U$ and $U'$ in $\mathcal{U}$.  			Since $U$ and $U'$ are edge-disjoint upward paths, we may assume without loss of generality that $|E(\hat{U})|\leq |E(\hat{U'})|$ and so $\hat{U}$ and $U'$ are edge-disjoint. 			First consider the case where $r_U$ is an ancestor of $r_{U'}$ in $T$.  			Note that $\dist_{G}(s_{U'},P_{r_U})=\dist_T(r_{U'},r_U)$. Hence, since $\PP$ has weak-diameter at most $k-1$, we have $\dist_T(r_{U'},r_U)\leq \dist_G(s_U,s_{U'})\leq \dist_T(r_{U'},r_U)+k-1$. 			By the definition of $f$, we have $|f(s_{U'})-f(s_U)|\leq\dist_{\hat{T}}(r_U,r_{U'})\leq \dist_T(r_{U'},r_U)-|E(U')|=\dist_T(r_{U'},r_U)-k<\dist_{G}(s_U,s_{U'})$. 			 			Now consider the case where $U$ is not an ancestor of $U'$. 			We aim to show that $f(s_U)\leq f(s_{U'})+\dist_T(r_U,r_{U'})$, which will then imply that $f(s_U)\leq f(s_{U'})+\dist_G(s_U,s_{U'})$. 			Let $P_1$ be the shortest path in $\hat{T}$ from $r$ to $r_U'$, and let $P_2$ be the shortest path in $T$ from $r_U'$ to $U$.  			Note that $P_2$ corresponds to a walk $W_2$ from $r_U'$ to $r_U$ in $\hat{T}$. Combining $P_1$ and $W_2$, we obtain a walk from $r$ to $r_U$ in $\hat{T}$ of length $f(s_{U'})+\dist_T(r_U,r_{U'})$. Thus $f(s_{U'})+\dist_T(r_U,r_{U'})\leq \dist_{\hat{T}}(r,r_U)=f(s_U)$, as required. 			 			% Let $t_0$ be the vertex in $T_{r_U,r_{U'}}$ which is closest to $r$. 			% Let $c_1$ be the number of paths in $\mathcal{U}\setminus \{r\}$ which are properly contained in $T_{r,t_0}$, let $c_2$ be the number of paths in $\mathcal{U}\setminus \{r\}$ which are properly contained in $T_{r_U,t_0}$ and let $c_3$ be the number of paths in $\mathcal{U}\setminus \{r\}$ which are properly contained in $T_{r_{U'},t_0}$. 			% Since $t_0$ is an internal vertex of at most one path in $\mathcal{U}$, we have $c_1+c_2\leq c_{\hat{U}}\leq c_1+c_2+1$ and $c_1+c_3\leq c_{\hat{U'}}\leq c_1+c_3+1$. 			% Since $\hat{U}$ and $U'$ are edge-disjoint, $U'\subseteq T_{t_0,r_{U'}}$ and so $c_3\geq 1$. 			% Thus $|f(s_U)-f(s_{U'})|\leq k+|\dist_T(r_U,t_0)-c_2k-\dist_T(r_{U'},t_0)+c_3k|\leq k+\dist_T(r_U,t_0)+\dist_T(r_{U'},t_0)-(c_2+c_3)k\leq \dist_T(r_{U'},r_U)\leq \dist_G(s_U,s_{U'})$. 			 			Hence, $(S,f)$ is a seed for $G$. 			 			Let $F$ be an $(S,f)$ seeded spanning forest of $G$, and for each $u\in \mathcal{U}$, let $F_U$ be the component of $F$ containing $s_U$.  			 			 				For all $U\in \mathcal{U}$, we have that $P_{r_U}\subseteq V(F_U)$.  			 			 				Suppose for contradiction that there are distinct $U$ and $U'$ in $\mathcal{U}$ such that $F_{U'}$ contains a vertex $v\in P_{r_U}$. 				This implies $\dist_G(v,s_{U'})+f(s_{U'})\leq \dist_G(v,s_{U})+f(s_{U})$. 				Since $\PP$ has weak-diameter at most $k-1$, $\dist_G(v,s_{U})+f(s_{U})\leq \dist_{\hat{T}}(r,r_{U})+k-1$. 				 				Let $P_1$ be a shortest path from $r$ to $r_U'$ in $\hat{T}$, and let $P_2$ be the path in $T$ from $r_U'$ to $r_U$. 				Observe that since $U$ and $U'$ are edge-disjoint upward paths, $P_2$ either contains all of $U$ or all of $U'$, and if $P_2$ contains $r$ then it contains $U\cup U'$. Now $P_2$ corresponds to a walk $W$ in $\hat{T}$ from $r_{U'}$ to $r_U$ in $\hat{T}$. 				Combining this with $P_1$ gives a walk $W'$ of length  $\dist_G(v,s_{U'})+f(s_{U'})$ from $r$ to $r_U$ in $\hat{T}$. Furthermore, $W'$ contains a length $k$ cycle corresponding to either $U$ or $U'$ as a subwalk, so the length of $W'$ is at least $\dist_{\hat{T}}(r,r_U)+k$. Thus $\dist_G(v,s_{U'})+f(s_{U'})>\dist_G(v,s_{U})+f(s_{U})$, a contradiction. 				 				 				 				% Let $t_0$ be the closest vertex in $V(T_{r_U,r_{U'}})$ to $r$. 				% Let $a$ be the number of edges of $T_{r_U,t_0}$ which are not in $\bigcup \{E(P):P\in \mathcal{U}, P\subseteq \hat{U}\}$. 				% Now $f(s_U)\leq f(s_{U'})+a$. 				% Additionally, since $U$ and $U'$ are edge-disjoint upward paths we must have $U\subseteq T_{t_0,r_U}$ or $U'\subseteq T_{t_0,r_{U'}}$, and if $t_0=r$ we must have $U\cup U'\subseteq T_{r_U,r_{U'}}$. 				% Thus $\dist_G(v,s_{U'})\geq \dist_T(r_U,r_{U'})\geq a+k=a+3\tw(G)+3$. 				% By \cref{lem:twdiamparts}, we have $\dist_G(v,s_{U})\leq 3\tw(G)+2$. 				% But now 				% \[\dist_G(v,s_{U})+f(s_{U})\leq 3\tw(G)+2+f(s_{U'})+a<\dist_G(v,s_{U'})+f(s_{U'}),\] 				% a contradiction.",2502.01927
proof,"%     Let $F$ be an $(S,f)$-seeded forest for $G$, and suppose for contradiction that for some vertex $w\in P_v$ and some $U'\in \mathcal{U}\setminus \{U\}$, there is a component of $F$ containing both $w$ and $s_{U'}$. 				 				%     sketch: the path $T_{r_{U'},v}$ either contain $U$ or $U'$. 				%     If $T_{r_{U'},v}$ is an upward path, then $T_{r_U,r_{U'}}$ is an upward path and $f(U')\geq f(U)+|E(T_{r_U,r_{U'}})\setminus E(U')|$.  				%",2502.01927
proof,"Suppose for contradiction that there is a vertex $v\in P_t\cap V(F_U)$. 				Since $F_U$ is connected and contains a vertex in $P_{r_U}$, it also contains a vertex in $P_{q_U}$, and so by Claim~\ref{clm:rootparts} we have that $q_U\notin \{r_{U'}:U'\in \mathcal{U}\setminus \{U\}\}$. 				Let $P$ be a shortest path in $\hat{T}$ from $r$ to $r_U$. 				Note that the set of edges in $T$ which correspond to edges in $E(P)$ in $\hat{T}$ induce a linear forest $L$ in $T$ whose components are paths.  				Additionally, note that for some $U_0\in \mathcal{U}$, $T_{r_{U_0},q_U}$ is a component of $L$. 				Now $f(s_U)=|E(L)|=\dist_{\hat{T}}(r,r_{U_0})+\dist_T(r_{U_0},q_U)=f(s_{U_0})+\dist_T(r_{U_0},q_U)$. 				Since $\PP$ has weak-diameter at most $k-1$, we have $\dist_G(s_{U_0},v)\leq \dist_T(r_{U_0},t)+k-1\leq \dist_T(r_{U_0},q_U)+k$. 				Finally, we have $\dist_G(s_U,v)\geq \dist_T(r_U,t)=k+1$. 				Combining all of this together, we have $f(s_U)+\dist_G(s_U,v)=f(s_{U_0})+\dist_T(r_{U_0},q_U)+\dist_G(s_U,v)\geq f(s_{U_0})+\dist_T(r_{U_0},q_U)+k+1>f(s_{U_0})+\dist_G(s_{U_0},v)$, which is a contradiction.",2502.01927
proof,"Let $t\in V(T)$ and $U\in \mathcal{U}$ be such that $P_t$ contains a vertex $v\in V(F_U)$. 				If $T_{t,q_U}$ is not an upward path, then it contains the parent $t'$ of $q_U$ in $T$. 				But then, since $F_U$ is connected, $F_U$ contains a vertex in $P_{t'}$, contradicting Claim~\ref{clm:quparent}. 				 				If $T_{t,q_U}$ contains a vertex $t'$ in $\{r_{U'}:U'\in \mathcal{U}\}\setminus \{r_U,q_U\}$, then $t'$ is also in $T_{t,r_U}$.  				Again, since $F_U$ is connected, this means $F_U$ contains a vertex in $t'$, which contradicts Claim~\ref{clm:rootparts}. 				 				Thus $T_{t, q_U}$ is an upward path and is disjoint from $\{r_{U'}:U'\in \mathcal{U}\}\setminus \{r_U,q_U\}$, as required.",2502.01927
proof,"%[Proof of \cref{MainLemma}]  			Let $\tau:=\ceil{\frac{1}{\epsilon}}$ and $k:=\tw(G)+1$. Note that $n\geq k$ and that $\tau\leq \frac{1}{\epsilon}+1$.  			We may assume that $k> 12+\frac{4}{\epsilon}$, since otherwise an optimal tree-decomposition of $G$ and the layering of $G$ with exactly one non-empty layer satisfy the lemma.   			By \cref{Triangulate}, there is a planar triangulation $G'$ with $V(G')=V(G)$ and $E(G)\subseteq E(G')$ and $\tw(G')=\tw(G)$.  			By \cref{GenerateSeeds}, $G'$ has a seed $(S,f)$,  			a spanning tree $T'$, and  			an $(S,f)$-seeded spanning forest $F\subseteq T'$ such that: 			 				\item $|\mathcal{L}_{G',(S,f)}|\leq  				(3\tau(\frac{n}{3k})^{1/\tau}+2)(3k) 				\leq 				9\tau k^{1-\epsilon}n^\epsilon +6k 				\leq 				(\frac{9}{\epsilon}+15) k^{1-\epsilon}n^\epsilon  				$, and 				\item for every edge $vw$ of $G'$, the path $T'_{v,w}$ contains vertices from at most $\tau+2$ components of $F$. 			 			 			Let $\TT$ be the tree-decomposition of $G'$ generated by $T'$.  			By \cref{GenerateTreeDecomp}, each bag of $\TT$ has at most $4(\tau+2)\leq 12+\frac{4}{\epsilon}$ vertices in each layer of $\mathcal{L}_{G,(S,f)}$. This completes the requirements of \cref{MainLemma}.",2502.01927
proof,"We may assume that $Q$ is vertex-minimal such that $G$ is an $r$-shallow minor of $Q\boxtimes K_\ell$.          If we select a central representative vertex for each vertex of $G$ in the corresponding connected subgraph of $Q\boxtimes K_{\ell}$, then edges of $G$ naturally correspond to paths in $Q\boxtimes K_{\ell}$ with at most $2r$ internal vertices (where distinct paths are not necessarily internally disjoint).         %Each vertex of $G$ maps to a vertex of $Q$, and each edge of $G$ maps to a path in $Q$ with at most $2r$ internal vertices.          By the minimality of $Q$, we have $|V(Q)|\leq |V(G)|+2r|E(G)|= (1+rd)n$. By \cref{PGPST-sqrtn}, $Q\subsetsim H \StrongProd P \StrongProd K_c$ for some planar graph $H$ with $\tw(H)\leq 3$, for some path $P$ with          $$|V(P)|\leq  			(\tfrac{32}{\epsilon}+52) |V(Q)|^{(1+\epsilon)/2} \leq 			(\tfrac{32}{\epsilon}+52) ((1+rd)n)^{(1+\epsilon)/2},$$ and for some integer  		$c\leq 24+\frac{8}{\epsilon}$. Thus $G$ is an $r$-shallow minor of $H \StrongProd P \StrongProd K_{c\ell}$. So \cref{ShallowMinor} is applicable with $L=P$ and $k=2r$ and $t=3$. So $G \subsetsim J \boxtimes P^{2r+1} \boxtimes K_{c\ell(2r+1)}$ for some graph $J$ with treewidth at most $\binom{2r+4}{3}-1$.    			Note that $P^{2r+1}\subsetsim P'\boxtimes K_{2r+1}$, where $P'$ is a path with  			 				|V(P')| \leq \ceil{ |V(P)|/(2r+1)}  				& \leq 	\ceil{(\tfrac{32}{\epsilon}+52) ((1+rd)n)^{(1+\epsilon)/2} / (2r+1)}. 			 			Thus $G \subsetsim J \boxtimes P' \boxtimes K_{c\ell(2r+1)^2}$.",2502.01927
proof,"\citet[Lemma~33]{HW24} proved that $G$ is a $1$-shallow minor of $Q \boxtimes K_3$ for some planar graph $Q$. \citet{KU22} showed that $G$ has average degree less than $10n$. So \cref{PlanarShallowMinor} is applicable with $r=1$, $d=10$ and $\ell=3$. So $G \subsetsim J \boxtimes P \boxtimes K_{c}$ for some graph $J$ with treewidth at most $\binom{6}{3}-1=19$, some path $P$ with $|V(P)|\leq 	\ceil{\tfrac{32+52\epsilon}{3\epsilon} (11n)^{(1+\epsilon)/2}}< (\tfrac{11}{\epsilon}+18) (11n)^{(1+\epsilon)/2}$, and some integer          $c\leq 27(24+\frac{8}{\epsilon})$.",2502.01927
proof,"By Lemma~3.5 in \citep{DHSW24}, $G'$ is an $(\ell+2)$-shallow minor of  $Q \boxtimes K_{h(d,r,s,\ell)}$ for some minor $Q$ of $G$ and for some function $h$.  Thus $Q\in \GG$.  There is a natural map from vertices of $G$ to vertices of $Q\boxtimes K_{h(d,r,s,\ell)}$ and from edges of $G'$ to paths of $Q\boxtimes K_{h(d,r,s,\ell)}$ with at most $2\ell+4$ internal vertices which witnesses that $G'$ is an $(r,s)$-shallow minor of $G\boxtimes K_{d}$.  We may assume that $Q$ is vertex-minimal, implying $|V(Q)|\leq (2\ell+4)m+n$.  By assumption, $Q$ is contained in $H \boxtimes P \boxtimes K_c$  for some graph $H$ with $\tw(H)\leq t$ and for some path $P$ with $|V(P)|\leq \alpha(|V(Q)|) \leq \alpha((2\ell+4)m + n)$. Hence $G'$ is an $(\ell+2)$-shallow minor of $H \boxtimes P \boxtimes K_{c\,h(d,r,s,\ell)}$.  By \cref{ShallowMinor} with $r=\ell+2$ and $k=2\ell+4$,  $G'$ is contained in $ J \boxtimes P^{2\ell+5} \boxtimes K_{c(2\ell+5)\cdot h(d,r,s,\ell)}$ for some graph $J$ with $\tw(J)\leq \binom{2\ell+5+t}{t}-1$. The result follows with $g(d,r,s,\ell,c) := c(2(\ell+2)+1)^2\cdot h(d,r,s,\ell)$.  Now $P^{2\ell+5}\subsetsim P' \boxtimes K_{2\ell+5}$ for some path $P'$ with $|V(P')|\leq \ceil{ |V(P)| / (2\ell+5)} \leq \ceil{ \alpha((2\ell+4)m + n) / (2\ell+5)}$. By construction, $G'\subsetsim J \boxtimes P' \boxtimes K_{c(2\ell+5)^2\cdot h(d,r,s,\ell)}$.",2502.01927
proof,"Let $G$ be a $k$-planar graph with $n$ vertices and $m$ edges. \citet{PachToth97} showed that $m\leq  4.108\sqrt{k}n$. \citet{HW24} showed that $G$ is a $(\frac{k}{2},4)$-shallow minor of $Q\boxtimes K_2$ for some planar graph $Q$. By \cref{PlanarBlockingShallowProduct}, $G$ is contained in $J \boxtimes P \boxtimes K_{g_{\epsilon}(2,\frac{k}{2},4)}$ for some graph $J$ with $\tw(J)\leq \binom{452}{3}-1$ and for some path $P$ with  $|V(P)|\leq (\tfrac{7}{\epsilon}+13)(n+m)^{(1+\epsilon)/2}\leq (\tfrac{7}{\epsilon}+13)((5\sqrt{k}+1)n)^{(1+\epsilon)/2}$. Thus the result holds with $g(\epsilon,k)=g_{\epsilon}(2,\frac{k}{2},4)$.",2502.01927
proof,"Let $d$ be the maximum degree of $G^{\floor{k/2}}$, which is at most $\Delta^{\floor{k/2}}$.  Let $m:=|E(G^k)|\leq \frac12 \Delta^k n$. \citet[Lemma~25]{HW24} showed that $G^k$ is a $(\floor{\frac{k}{2}},\Delta)$-shallow minor of $G\boxtimes K_{d+1}$, and thus of $G\boxtimes K_{\Delta^{\floor{k/2}}+1}$. By \cref{PlanarBlockingShallowProduct}, $G^k$ is contained in $J \boxtimes P \boxtimes K_{g_{\epsilon}(\Delta^{\floor{k/2}}+1,\floor{\frac{k}{2}},\Delta)}$ for some graph $J$ with $\tw(J)\leq \binom{452}{3}-1$ and some path $P$ with $|V(P)|\leq  (\tfrac{7}{\epsilon}+13)(n+m)^{(1+\epsilon)/2}  \leq  (\frac{7}{\epsilon}+13) ((\tfrac12 \Delta^k+1) n)^{(1+\epsilon)/2}   $.",2502.01927
proof,"Let $\phi_q, q=0,1,\cdots,2d$ be the K-inner functions associated with $f$. By Theorem \ref{thm1}, $\phi_q \in Lip_{C_\phi}(\alpha)$ with $C_\phi$ being their common Lipschitz constant and $\alpha = \log_{10}2$. According to Lemma \ref{Jackson}, there exist  polynomials $L_q \in \mathcal{Q}_p (\mathbb{R})$ such that   \max_{x\in [0,1]}\left|\phi_q(x)-L_q(x)\right|\le  \frac{KC_\phi}{p^{\alpha}},\quad q=0,1,\cdots ,2d.  It is straightforword to confirm that $|\phi_{q}(x)-\widetilde{L}_q(x)| \le |\phi_{q}(x)-L_q(x)|$ by the definition of $\widetilde{L}_{q}(x)$.   % %|\phi_{q}(x)-\widetilde{L}_q(x)| \le |\phi_{q}(x)-L_q(x)| %\le K \cdot M \left(\frac{1}{p}\right)^{\alpha} % % %To be more precise, when $x \in\{x: L_q(x)>1\}$, we have  % %|\phi_{q}(x)-\widetilde{L}_q(x)|&= 1-\phi_{q}(x)\le L_q(x)-\phi_{q}(x)\le K \cdot M \left(\frac{1}{p}\right)^{\alpha} % %Similarly, when $x \in\{x: L_q(x)<0\}$, we have  % %|\phi_{q}(x)-\widetilde{L}_q(x)|=\phi_{q}(x)\le\phi_{q}(x) - L_q(x)\le K \cdot M \left(\frac{1}{p}\right)^{\alpha}. % Hence, we have  \max_{x\in [0,1]} \left|\phi_q(x)-\widetilde{L}_q(x)\right|\le \frac{KC_\phi}{p^{\alpha}},\quad  q=0,1,\cdots ,2d.   Let $g$ be the K-outer function  associated with $f$, which is Lipschtiz continuous with a Lipschitz constant $C_g$. By Lemma \ref{Lemma2}, there is a linear spline $S_g \in S_{1}^{0} \left ( \bigtriangleup  \right )$ over a partition $ \bigtriangleup  =\left \{ 0= z_{0}< z_{1} < \cdots < z_{n}=d\right \} $ such that  \left \| g -S_{g}  \right \|_{C([0,d])} \le \frac{C_{g}d}{2(n+1)} \le \frac{C_{g}d}{2n}.  Following the equation \eqref{KST} in Theorem \ref{thm1}, we have   \left | f(x)-\sum_{q=0}^{2d} S_g\left ( \sum_{i=1}^{d} \lambda _{i}  \phi _{q}\left ( x_{i}  \right )  \right )  \right | \le \sum_{q=0}^{2d}\left |  g\left ( \sum_{i=1}^{d} \lambda _{i}  \phi _{q}\left ( x_{i}  \right )  \right )-S_g\left ( \sum_{i=1}^{d} \lambda _{i}  \phi _{q}\left ( x_{i}  \right )  \right )\right | \le \frac{C_{g}(2d+1)d}{2n}.   We remark that when $g$ is Lipschitz continuous, so is its linear interpolatory spline $S_g$. Specifically, we have $\left | S_g(x)-S_g(y) \right | \le 2C_{g} \left | x-y \right |$. Thus, by using equation \eqref{eq2}, we obtain   |S_g\left ( \sum_{i=1}^{d} \lambda _{i}  \phi _{q}\left ( x_{i}  \right )  \right )-S_g\left ( \sum_{i=1}^{d} \lambda _{i}  \widetilde{L}_{q}\left ( x_{i}  \right )  \right )| \le 2C_{g} \sum_{i=1}^{d}\lambda _{i}\left | \phi _{q}\left ( x_{i}  \right ) -\widetilde{L}_{q}\left ( x_{i}  \right )   \right | \le  \frac{2C_{g} d K C_\phi}{p^{\alpha}}.  Combining above two inequalities we have  \left | f(x)-\sum_{q=0}^{2d} S_g\left ( \sum_{i=1}^{d} \lambda _{i}  \widetilde{L}_{q}\left ( x_{i}  \right )  \right )  \right | \le \frac{C_{g}(2d+1)d}{2n}+\frac{2C_{g} K C_\phi(2d+1)d}{p^{\alpha}}\le C_{g}(2d+1) d(\frac{1}{n}+\frac{2KC_\phi}{p^{\alpha}}).  This completes the proof.",2502.01938
proof,"Let $g$ be the K-outer function associated with $f$, whose smoothness is characterized by the standard modulus of continuity. Owing to the uniform continuity of $g$, there exists a linear spline $S_g$ over an equally partitioned sequence with uniform spacing $\delta=\frac{d}{n}$ such that  |g(z)-S_g(z)|\le \omega \left ( g, \delta \right ), \forall  z \in [0,d],   for any $\delta > 0 $. It is easy to confirm that Equation \eqref{equationA1} holds by proving its applicability within each subinterval $z \in [z_i,z_{i+1}]$.  %In fact, for $z \in [z_i,z_{i+1}]$, we have  % %|g(z) - S_g(z)| &= |g(z) - g(z_i)\frac{z_{i+1} - z}{z_{i+1} - z_{i}} - g(z_{i+1})\frac{z - z_{i}}{z_{i+1} - z_{i}}| \\ %&\le \left|\frac{(z_{i+1} - z)(g(z) - g(z_i))}{z_{i+1} - z_{i}}\right| + \left|\frac{(z - z_{i})(g(z) - g(z_{i+1}))}{z_{i+1} - z_{i}}\right| \\ %&\le \left|\frac{(z_{i+1} - z)\omega(g, \delta)}{z_{i+1} - z_{i}}\right| + \left|\frac{(z - z_{i})\omega(g, \delta)}{z_{i+1} - z_{i}}\right| = \omega(g, \delta) % \par From equation \eqref{KST} in Theorem \ref{thm1}, we conclude that \par  \left| f(x) - \sum_{q=0}^{2d} S_g \left( \sum_{i=1}^{d} \lambda_{i} \phi_q(x_{i}) \right) \right| \leq \sum_{q=0}^{2d} \left| g \left( \sum_{i=1}^{d} \lambda_{i} \phi_q(x_{i}) \right) - S_g \left( \sum_{i=1}^{d} \lambda_{i} \phi_q(x_{i}) \right) \right| \leq (2d+1)\omega(g, \delta).   Building on the definition of $\widetilde{L}_{q}$ given in Theorem \ref{thm2}, and applying equation \eqref{eq2}, we get \par  |\sum_{i=1}^{d} \lambda _{i}  \phi _{q}\left ( x_{i}  \right )   - \sum_{i=1}^{d} \lambda _{i}  \widetilde{L}_{q}\left ( x_{i}  \right  )| \le \frac{d K C_\phi}{p^{\alpha}}.   Thus, by using the triangle inequality, the estimates from \eqref{equationA1} and \eqref{equationA3}, and the property of the modulus of continuity, we deduce that   |S_g\Big(\sum_{i=1}^{d} \lambda _{i} \phi _{q}(x_{i})\Big)-S_g\Big(\sum_{i=1}^{d}\lambda _{i} \widetilde{L}_{q}(x_{i})\Big)|&\le 2\omega(g,\delta) + \Big|g\Big(\sum_{i=1}^{d} \lambda _{i} \phi _{q}(x_{i})\Big)-g\Big(\sum_{i=1}^{d} \lambda _{i} \widetilde{L}_{q}(x_{i})\Big)\Big| \\ &\le 2\omega(g,\delta) + \omega(g, \frac{d K C_\phi}{p^{\alpha}}) \\ & \le 2d\omega(g,\frac{1}{n}) + (d K C_\phi +1)\omega(g,\frac{1}{p^{\alpha}}).     By integrating the above estimations, we have  \left | f(x)-\sum_{q=0}^{2d} S_g\left ( \sum_{i=1}^{d} \lambda _{i}  \widetilde{L}_{q}\left ( x_{i}  \right )  \right )  \right | &\le (2d+1)\left ( d\omega \left ( g, \frac{1}{n} \right )+2d\omega(g,\frac{1}{n}) + (d K C_\phi +1)\omega(g,\frac{1}{p^{\alpha}}) \right ) \\ &\le d(2d+1)\left ( 3\omega \left ( g, \frac{1}{n} \right ) +(K C_\phi +1)\omega(g,\frac{1}{p^{\alpha}}) \right ) .  This completes the proof of Theorem \ref{Theorem4}.",2502.01938
proof,"Define $f(x) = g(xd) $ for $ x \in [0, 1] $. It is straightforward to verify that $ f(x) $ satisfies a Lipschitz condition with constant $ d C_g $. By using the one-dimensional case of Corollary 5.4 in \cite{de2021approximation}, there exists a tanh neural network $ \hat{f}^N $ with two hidden layers, where the layer widths are at most $ (N - 1) $ and $ 6N $, such that 	 		\| f(x) - \hat{f}^N(x; \theta) \|_{L^\infty([0,1])} \leq \frac{7d C_g}{N}. 	 	By  defining \( \hat{g}^N(t; \theta) = \hat{f}^N(t/d; \theta) \), we obtain 	 		\| g(t) - \hat{g}^N(t; \theta) \|_{L^\infty([0, d])} \leq \frac{7d C_g}{N}.",2502.01938
proof,"The function $g(t)$ is smooth and differentiable on the interval \( t \in [-\Delta, 1 + \Delta] \), and its derivative is given by:  g'(t) = w \cdot \text{sech}^2\left( \frac{t + \Delta}{w(1 + 2\Delta)} \right) \cdot \frac{1}{w(1 + 2\Delta)} - 1 \le 0.  Since $g(t)$ is monotonically decreasing on this interval, with the value of \( g(-\Delta) = \Delta > 0 \) and \( g(1 + \Delta) = w \tanh\left( \frac{1}{w} \right) - (1 + \Delta) < 0 \), it follows that the maximum value of \( |g(t)| \) occurs at either \( t = -\Delta \) or \( t = 1 + \Delta \). Thus, we have:  |g(t)| \leq \max \left( \Delta, 1 + \Delta - w \tanh\left( \frac{1}{w} \right) \right).  Next, consider the function \( 1 - w \tanh\left( \frac{1}{w} \right) \), which is continuous and monotonically decreasing for \( w > 0 \), with the limit \( 1 - w \tanh\left( \frac{1}{w} \right) \to 0 \) as \( w \to 0^+ \). Therefore, there exists a constant \( w_0 > 0 \) such that for all \( w \geq w_0 \), we have:  1 - w \tanh\left( \frac{1}{w} \right) \leq \Delta.  Consequently, for \( w \geq w_0 \), we obtain:  |g(t)| \leq \max \left( \Delta, 2\Delta \right) = 2\Delta.",2502.01938
proof,"The approximation error can be bounded as follows by applying the triangle inequality: 	 		  			\left | f(x)-\sum_{q=0}^{2d} \hat{g}^N \left ( \sum_{i=1}^{d} \lambda _{i}  \bar{L}_{q}\left ( x_{i}  \right )  \right )  \right | & \leqslant   			\sum_{q=0}^{2d} \left| g\left( \sum_{i=1}^d \lambda_i \phi_q(x_i) \right) - \hat{g}^N\left( \sum_{i=1}^d \lambda_i \phi_q(x_i) \right) \right| \\ 			& \quad + \sum_{q=0}^{2d} \left| \hat{g}^N \left( \sum_{i=1}^d \lambda_i \phi_q(x_i) \right) - \hat{g}^N \left( \sum_{i=1}^d \lambda_i \bar{L}_q(x_i) \right) \right| 		 		 	 	We now proceed with an individual approximation for each term on the right-hand side. 	\noindent  	\par 	\textbf{Step 1:} First term of \eqref{rr1}. By using Lemma \ref{lemm3:tanh}, we have  	 		  			\sum_{q=0}^{2d} \left| g\left( \sum_{i=1}^d \lambda_i \phi_q(x_i) \right) - \hat{g}^N\left( \sum_{i=1}^d \lambda_i \phi_q(x_i) \right) \right|  			\leq \frac{7d(2d+1) C_g}{N} 		 	 	\par 	\noindent \textbf{Step 2:} Second term of \eqref{rr1}. It is easy to verify that \( |\phi_{q}(x) - \bar{L}_{q}(x)| \leq 3 |\phi_{q}(x) - L_{q}(x)| \) by applying the triangle inequality, the definition of \(\bar{L}_{q}(x)\), and Lemma \ref{tanh_max_eq}. Hence, we have 	 		|\sum_{i=1}^{d} \lambda _{i}  \phi _{q}\left ( x_{i}  \right )   - \sum_{i=1}^{d} \lambda _{i}  \bar{L}_{q}\left ( x_{i}  \right  )| \le \frac{3d KC_\phi}{p^{\alpha}}. 		 	 	 	Thus, by using the triangle inequality, the estimates from Lemma \ref{lemm3:tanh} and \eqref{R:equationA3}, we deduce that 	 		 			|\hat{g}\Big(\sum_{i=1}^{d} \lambda _{i} \phi _{q}(x_{i})\Big)-\hat{g}\Big(\sum_{i=1}^{d}\lambda _{i} \bar{L}_{q}(x_{i})\Big)|&\le 2\frac{7d C_g}{N} + \Big|g\Big(\sum_{i=1}^{d} \lambda _{i} \phi _{q}(x_{i})\Big)-g\Big(\sum_{i=1}^{d} \lambda _{i} \bar{L}_{q}(x_{i})\Big)\Big| \\ 			&\le \frac{14d C_g}{N} +  \frac{C_g 3d KC_\phi}{p^{\alpha}}\\ 			& = d C_g(\frac{14}{N}+\frac{3KC_\phi}{p^{\alpha}}). 		 		 	 	\par 	\noindent \textbf{Step 3:} Final error bound. Combining the contributions from the two terms of \eqref{rr1} then proves that 	 		\left | f(x)-\sum_{q=0}^{2d} \hat{g}^N\left ( \sum_{i=1}^{d} \lambda _{i}  \bar{L}_{q}\left ( x_{i}  \right )  \right )  \right |  		\le C_g(2d+1)d (\frac{21}{N}+\frac{3KC_\phi}{p^{\alpha}}). 	 	This completes the proof.",2502.01938
theorem,"[Reformulation of Earle-Hamilton Theorem] %Let $\cH \subseteq \bbH_+^k$ be a connected open subset, and $\bF :\cH \mapsto \C^{k\times k}$ holomorphic.  If the image of $\bF(\cH)$ is bounded, and $\bF(\cH)$ lies strictly inside $\cH$, then $\bF$ has a unique fixed point $\bS$ in $\cH$. %",2502.01953
theorem,"[Theorem 2.1, \notate{Cite}] %Assume $\boldeta$ is holomorphic and satisfies $\Im(\boldeta(\bZ))\preceq\bzero$ for $\bZ\in\bbH_k^+$.  %Then  % %\bQ = \frac{1}{\alpha} \bF_z(\bQ)     % %has a unique solution in $\bbH^-_k$. %",2502.01953
proof,"%The statement follows from an element-wise application of Hanson-Wright. Namely, let $\bM_{j,l}\in\C^{d\times d}$  for $j,l\in[k]$ denote the blocks of the matrix $\bM$,  %and let  %$F^2_{jl}:=  \norm{\bM_{j,l}}_F^2$ %and %$O_{jl}:=  \norm{\bM_{j,l}}_\op$. Then Hanson-Wright~\notate{cite} gives, for any $t>0$ and some fixed universal constant $c>0$, % %\P\left( \left|\bx^\sT \bM_{l,j} \bx - \Tr(\bM_{l,j}) \right| \ge t\right)  %\le 2 \exp\left\{ - \frac{c \, t^2}{ %F_{jl}^2+ % O_{jl} \, t  %}\right\}. % %Then via a union bound, we obtain % %    \P\left(\norm{ \bxi^\sT \bM \bxi -  (\bI_k \otimes \Tr)\bM }_F   \ge t \right) %    &\le  %     \P\left(\norm{\bxi^\sT \bM \bxi -  (\bI_k \otimes \Tr)\bM }_\infty   \ge t/k \right)\\ %    &\le 2 k^2   %      \exp\left\{ - \frac{c \, t^2/k^2}{ %\max_{j,l}\left\{ F_{jl}^2\right\}+ % \max_{j,k }\left\{O_{jl} \right\}\, t /k %}\right\}. % %Now what remains is to use the bounds % %   \max_{jl}  F_{jl}^2 \le \norm{\bM}_F^2  %   \quad\textrm{and}\quad %\max_{jl}O_{jl}  %\le \norm{\bM}_\op. % %",2502.01953
proof,"Let $\cN$ be a minimal $1/4$-net of the unit ball in $\C^k$. Then we have     \|\bxi^\sT\bM \bxi - (\bI_k \otimes\Tr) \bM\|_\op \le 2 \sup_{\bu,\bv\in\cN}  \bu^\sT\left(\bxi^\sT\bM \bxi - (\bI_k \otimes\Tr) \bM\right)\bv.  Meanwhile, for any fixed $\bu,\bv\in\cN$, note that $(\bI_k\otimes\bx)\bu = (\bu \otimes\bI_d)\bx$ so that Hanson-Wright gives              \bu^\sT\bxi^\sT\bM\bxi\bv -  \bu^\sT(\bI_k \otimes \Tr)\bM\bv         &=         \bu^\sT\bxi^\sT\bM\bxi\bv - \E_\bx\left[\bu^\sT\bxi^\sT\bM\bxi\bv \right]         \\         &= \bx^\sT(\bu \otimes\bI_d)^\sT \bM (\bv \otimes\bI_d) \bx         - \Tr\left((\bu \otimes\bI_d)^\sT \bM (\bv \otimes\bI_d)\right) \\         &\le s      with probability larger than   1 - 2\exp\left\{  -c_0\left(\frac{s^2}{\norm{\bM}_\op^2 d} \wedge  \frac{s}{\norm{\bM}_\op} \right) \right\},  where we used that $\norm{\bu\otimes\bI_d}_\op \le \norm{\bu}_2 \le1$ (and same for $\bv$) to deduce      %\norm{(\bu \otimes \bI_d)^\sT \bM (\bv\otimes \bI_d)}_F \le  %\norm{\bM}_F, \quad     \|(\bu \otimes \bI_d)^\sT \bM (\bv\otimes \bI_d)\|_F \le       \sqrt{d} \norm{\bM}_\op, \quad     \|(\bu \otimes \bI_d)^\sT \bM (\bv\otimes \bI_d)\|_\op \le  \norm{\bM}_\op.  A standard result \cite{vershynin2018high} gives that the size of $\cN$ is at most $C_0^k$ for some $C_0 > 0$. Then taking   %    s = %\left(\frac{2 \log(C_0) k  \norm{\bM}_F^2}{c_0}\right)^{1/2} %    \vee   \frac{2 \log(C_0) k \norm{\bM}_\op}{c_0},     s =   \left( L^{1/2} k_+(d)^{1/2} d^{1/2} \norm{\bM}_\op \vee L k_+(d) \norm{\bM}_\op \right),  we obtain via a union bound      \P\left(\|\bxi^\sT\bM\bxi - (\bI_k\otimes\Tr)\bM\|_\op \ge 2 s \right)     &\le      \P\left( \sup_{\bv,\bu\in\cN} \bu^\sT(\bxi^\sT\bM\bxi - (\bI\otimes\Tr)\bM) \bv \ge s  \right)\\     &\le 2C_0^k \big (e^{-c L k}\wedge d^{-cL}\big)  % for some constant $c>0$. The claim follows by taking $L$ a sufficiently large universal constant.  Redefining the universal constants $c$ and $C_0$ allow us to take $L\ge 1$ as in the statement.",2502.01953
proof,"For all $i\in[n]$, we have by Lemma~\ref{lemma:hanson-wright} and the bounds on the norms of $\bR_i$ in Lemma~\ref{lemma:as_norm_bounds},   \nonumber     \norm{\bxi_i^\sT\bR_i \bxi_i - \left(\bI_k \otimes\Tr\right) \bR_i}_\op \le      %C \left(\frac{k }{\sqrt{n\alpha_n}} \frac1{\Im(z)} \vee \frac{k}{n} \frac1{\Im(z)}\right)     C L\left(     \sqrt{\frac{k_+(d)}{\alpha_n n}}      \vee \frac{k_+(d)}{n} \right)     \frac1{\Im(z)}  % with probability  at least $1-2 (e^{- cLk}\vee d^{-cL})$. Meanwhile, we have by Lemma~\ref{lemma:algebra_lemma} and bound of Lemma~\ref{lemma:as_norm_bounds} once again that          \nonumber         \norm{(\bI_k \otimes \Tr)\left(\bR_i - \bR\right) }_\op =  \norm{\bxi_i^\sT \bR_i (\bW_i \otimes \bI_d) \bR\bxi_i}_\op \le \sfK \norm{\bx_i}_2^2 \norm{\bR}_\op\norm{\bR_i}_\op \le \sfK \frac{\norm{\bx_i}^2}{n^2}\frac1{\Im(z)^2}. %      A triangle inequality and union bound gives the result.",2502.01953
proof,"The proof proceeds as in the usual scalar case. Namely, suppressing the argument $z \in\bbH_+$,  we write   \frac{d}{n} \cdot \bI_k  = \frac1n\left(\bI_k \otimes \Tr\right) \bR^{-1} \bR = \left(\bI_k \otimes \Tr\right) \left(\frac1n\sum_{i=1}^n \bxi_i \bW_i\bxi_i^\sT \bR   -z  \bR\right) &=  \left(\frac1n\sum_{i=1}^n  \left(\bI_k \otimes \Tr\right)\left( \bxi_i \bW_i\bxi_i^\sT \bR \right)  - z  \bS_n  \right).  %Via a leave-one-out argument, we show that for each $i\in[n]$, %$$\left(\bI_k \otimes \Tr\right)\bxi_i \bSec_i \bxi_i^\sT \bR   %\approx %\grad^2 \rho_i(\bI_k \otimes \Tr)\bR(\bI_k + \grad^2 \rho_i(\bI_k \otimes \Tr)\bR)^{-1}$$ %in an appropriate sense. %Taking expectations with respect to $\widehat \nu_{\bV,\bU}$ will then allow us to conclude % %    \frac{d}{n} \bI_k  \approx \E[\bSec \bQ(\bI + \bSec \bQ)^{-1}] - z \bQ. %  Letting $\bA_i = \bxi_i^\sT \bR_i\bxi_i$ and recalling the definition $\bS_n = (\bI_k \otimes \Tr)\bR$, we bound          \bDelta_i&:=         \left(\bI_k \otimes \Tr\right)\bxi_i \bW_i \bxi_i^\sT \bR - \bW_i\bS_n(\bI_k + \bW_i\bS_n)^{-1} \\         &=\left( \bI_k + \bW_i\bA_i\right)^{-1}\bW_i\bA_i         - (\bI_k + \bW_i\bS_n)^{-1}\bW_i\bS_n\\         &=         \left( \bI_k + \bW_i\bA_i\right)^{-1}\bW_i\bA_i         - (\bI_k + \bW_i\bS_n)^{-1}\bW_i\bA_i        +\left( \bI_k + \bW_i\bS_n\right)^{-1}\bW_i\bA_i         - (\bI_k + \bW_i\bS_n)^{-1}\bW_i\bS_n\\ &= (\bI_k +\bW_i\bA_i)^{-1}\bW_i (\bS_n -\bA_i) (\bI + \bW_i \bS_n)^{-1} \bW_i \bA_i + (\bI_k + \bW_i\bS_n)^{-1}\bW_i (\bA_i -\bS_n).  where the first equality follows from Lemma~\ref{lemma:algebra_lemma}.  Lemma~\ref{lemma:concentration_loo_quad_form} above provides a bound for $\norm{\bA_i -\bS_n}_\op$ on the event $\Omega_1(L)$. Meanwhile, by Lemma~\ref{lemma:tensor_trace_properties}, $\Im(\bS_n) = (\bI_k \otimes \Tr)\Im(\bR) \succ\bzero $ since $\Im(\bR) \succ\bzero$. So we have by Lemmas~\ref{lemma:re_im_properties} and~\ref{lemma:as_norm_bounds} on $\Omega_0$  \nonumber     \norm{(\bI + \bW_i\bS_n)^{-1}\bW_i}_\op      \le \norm{\Im(\bS_n)^{-1}}_\op     \le   \frac{1}{\Im(z)} \left( \frac{\sfK}{n} \norm{\bX}_\op^2 + |z|\right)^2 \le \frac{C_1}{\Im(z)} (\sfK^2 + |z|^2)  and similarly and by the same lemmas, we conclude on $\Omega_0$  \nonumber     \norm{(\bI + \bW_i\bA_i)^{-1}\bW_i}_\op      \le   \frac{1}{\Im(z)} \frac{n}{\norm{\bx_i}_2^2} \left(\frac{\sfK}{n} \norm{\bX}_\op^2 + |z|\right)^2      \le \frac{C_2 \alpha_n}{\Im(z)} (\sfK^2 + |z|^2).  % Finally, on $\Omega_0$,  \nonumber    \norm{\bA_i}_\op {\le} \norm{\bx_i}_2^2 \norm{\bR_i}_\op \le \frac{C_3}{\alpha_n \Im(z)}.   Combining these bounds along with the one in Lemma~\ref{lemma:concentration_loo_quad_form} gives on $\Omega_0 \cap\Omega_1(L)$,      \norm{\bDelta_i}_F   &\le\norm{(\bI_k + \bW_i \bS_n)^{-1}\bW_i}_\op \norm{\bA_i -\bS_n}_\op \left(\norm{(\bI_k + \bW_i \bA_i)^{-1}\bW_i}_\op\norm{\bA_i}_\op + 1\right)    \\    &\stackrel{(a)}{\le}   C_4(\sfK) \frac{1}{\Im(z)} (1 + |z|^2)  \left( \frac{L\sqrt{ k_+(d)} }{\sqrt{n\alpha_n}} \frac1{\Im(z)}     +  \frac{\sfK}{\alpha_n n \Im(z)^2}\right)    \frac{1}{\Im(z)^2}(\sfK^2 + |z|^2)   \\   &\stackrel{(b)}{\le}    C_5(\sfK) \frac{(1+|z|^4)}{\Im(z)^4}  \left( \frac{L \sqrt{k_+(d)} }{\sqrt{n}}      +  \frac{1}{ n \Im(z)}\right)\\    &\equiv \Err_{\FP}(z; n, k) %&\le\frac{C}{\Im(z)} %    \left(\frac{1}{\Im(z)} \left( \sfK^2 + |z|^2 \right)\right) %    \left( \frac{1}{ \Im(z)} \left( \sfK^2 + |z|^2 \right)  %    + 1\right) %\left( \frac{L k_+(d) }{\sqrt{n\alpha_n}} \frac1{\Im(z)}  %   +  \frac{\sfK}{\alpha_n n \Im(z)^2}\right) %\le\omega_{\textrm{FP}}(z,n,k,\alpha_n)  where in $(a)$ we used that $(\sfK + |z|^2)/\Im(z)^2+1 \le C_6(\sfK) (1+ |z|^2)/\Im(z)^2$ for some $C_6>0,$ and in $(b)$ we used that $\alpha_n \ge 1.$ % %\am{I think there is a term $\|\bA_i\|_{\op}$ missing. Please, double check. Also, some factors $\alpha_n$ seem off. I get % %    \norm{\bDelta_i}_F&\le %    \left(\frac{2}{\Im(z)} \left( 9\sfK^2 + |z|^2 \right)\right) %    \left( \frac{8\alpha_n}{ \Im(z) } \left( 9\sfK^2 + |z|^2 \right)  %    \|\bA_i\|_{\op}+ 1\right)\alpha_n %\left(C L\frac{k_+(d) }{\sqrt{n\alpha_n}} \frac1{\Im(z)}  %   +  \frac{\sfK}{\alpha_n n \Im(z)^2}\right) %} Since this holds for all $i\in[n]$. using Eq.~\eqref{eq:decomposition_resolvent_eq} we conclude % %\frac1{\alpha_n} \bI_k  + z\bQ_n %=  %\frac1n\sum_{i=1}^n  %\left(\bI_k \otimes \Tr\right)\left( %\bz_i \widetilde\bz_i^\sT \bR \right), % on $\Omega_0\cap\Omega_1$ we have  \nonumber &\norm{\frac1\alpha_n\bI_k + z \bS_n - \frac1n \sum_{i=1}^n\bW_i \bS_n(\bI_k + \bW_i \bS_n)^{-1} }_\op \le  \frac1n\sum_{i=1}^n \norm{\bDelta_i}_\op\le  \Err_{\FP}(z;n,k).",2502.01953
proof,"%The tail bound follows directly from Lemma~\ref{lemma:hanson-wright} after appying the bounds of Lemma~\ref{lemma:as_norm_bounds} on $\norm{\bR_i}_F$ and $\norm{\bR_i}_\op$. %Meanwhile, for Eq.~\eqref{eq:concentration_loo_quad_form_2}, %Lemma~\ref{lemma:algebra_lemma} and the operator norm bound of Lemma~\ref{lemma:as_norm_bounds} gives %     %        \norm{(\bI_k \otimes \Tr)\left(\bR_i - \bR\right) }_\op =  %\norm{\bz_i^\sT \bR_i (\bSec_i \otimes \bI_d) \bR\bz_i}_\op %\le \sfK \norm{\bx}_2^2 \norm{\bR}_\op\norm{\bR_i}_\op %\le \sfK \frac{\norm{\bx}_i^2}{n^2}\frac1{\Im(z)^2}. %%\norm{\grad^2 \rho_i (\bI_k \otimes \Tr)\left(\bM_i^{-1} \bz_i (\bI_k + \widetilde \bz_i^\sT \bM_i^{-1} \bz_i)^{-1} \widetilde \bz_i^\sT \bM_i^{-1}\right) }_F\\ %%&\le \frac{2\sqrt{ndk}\sfK^2}{n^2 \Im(z)^2} %     %%where the last equality holds  %%with probability at least $1- Ce^{- c d}$. %Taking $t = k^{3/2+s}n^{-1/2}/\Im(z)$ gives the result. %% %%      %1 -  2k^2 \exp\left\{-  \frac{c n\sqrt{d}  }{ \sqrt{d} k^{3/2}  +  \sqrt{n k} }\right\}. %% %%Combining with the concentration bound of Eq.~\eqref{eq:concentration_loo_quad_form_1} for $t = k^{3/2+s}n^{-1/2}/\Im(z)$ gives the result. %",2502.01953
proof,"%Let $\bA := \bM_i^{-1} (\grad^2 \rho_i \otimes \bI_k) \bM^{-1}$ and for $j,l\in[k]$ let $(\bA)_{jl}\in\R^{d}$ be the $j,l$th block of $\bA$. Then by Lemma~\ref{lemma:algebra_lemma}, we have % %   (\bI_k \otimes \Tr) %   \bM_i^{-1} %\bz_i %\left(\bI_k + \widetilde\bz_i^\sT \bM_{i}^{-1} \bz_i\right)^{-1} \widetilde\bz_i^\sT \bM_i^{-1}  %&=  %     \bz_i^\sT \bA \bz_i. % % %For all $t>0$ and some universal $c>0$, we have by Hanson-Wright and a union bound, % %\P\left( %    \norm{(\bI_k \otimes \Tr)(\bz_i^\sT \bA \bz_i) -  (\bI_{k}\otimes \Tr) \bA }_F \ge t %\right) %&\le    \P\left(\sum_{j,l}\left|\bx_i^\sT \bA_{jl}\bx_i - \Tr(\bA_{jl})\right|^2  > t^2\right)\\ %&\le    \P\left(\max_{j,l}\left|\bx_i^\sT \bA_{jl}\bx_i - \Tr(\bA_{jl})\right|^2  > \frac{t^2}{k^2}\right)\\ %&\le 2 k^2 \exp\left\{ \frac{-c (t/k)^2}{ \max_{jl}F_{jl}^2 + (t/k)\max_{jl}O_{jl} }\right\}\\ %&\le 2 k^2 \exp\left\{ \frac{-c (t/k)^2}{ \norm{\bA}_F^2 + (t/k) \norm{\bA}_\op }\right\}. % % %Now note that % %    \norm{\bA}_\op \le \norm{\bM_{i}^{-1}}_\op %    \norm{\grad^2\rho_i}_\op %    \norm{\bM^{-1}}_\op\le  \frac{\sfK}{n^2} \frac1{\Im(z)^2} % %and  % %    \norm{\bA}_F^2 \le \norm{\bM_{i}^{-1}}_F^2 %    \norm{\grad^2\rho_i}_\op^2 %    \norm{\bM^{-1}}_\op^2\le  \frac{d k \sfK^2}{n^4} \frac1{\Im(z)^4}. % %Taking $t = (\sqrt{ndk} \sfK)/n^2 \Im(z)^2$, we obtain that with probability larger than  % %   1 -  2k^2 \exp\left\{- \frac{ nd \sfK^2 }{ d k^{3/2} \sfK^2 + \sfK^2 \sqrt{nd k} }\right\} % %we have, using Lemma~\notate{ref} % %\norm{(\bI_k \otimes \Tr) (\bz_i^\sT\bA\bz_i)}_F &\le \norm{(\bI_k \otimes \Tr)\bA}_F  + t %\le \frac{ 2\sqrt{n d k } \sfK}{n^2 \Im(z)^2}. % %",2502.01953
proof,"Fix $k$ throughout and let $\bT \in\cM^{k\times k}(\cA)$ be defined by $\bT := ( T_{i,j})_{i,j\in[k]}$, where, for $i,j\in[k]$, $T_{i,j}\in(\cA,\tau)$ satisfy Eq.~\eqref{eq:taus_of_prods_of_D} for $\nu_0$.   Our goal is to use Lemma~\ref{lemma:fix_point_rate} to show that $\bS_\star(z;\alpha_0,\nu_0)$ satisfies the desired fixed point equation. Since this lemma is stated in terms of empirical measures, we define  $\{\hnu_{0,m}\}_m$, $\hnu_{0,m}\in\cuP_m(\R^{k+k_0+1})$ to be a sequence of empirical measures satisfying $\hnu_{0,m}\Rightarrow \nu_0$. These in turn define  a sequence $\bar \bSec^\up{m} = \left(\bar \bSec^\up{m}_{i,j}\right)_{i,j \in[k]}$ of deterministic matrices  satisfying~\eqref{eq:K_empirical_limit} for the given $\nu_0$.  Write $\bS_\star(z)$ via its power expansion: We have, by boundedness of $\bT$, for $|z|$ sufficiently large %\am{Need to use the fact that %$\max_{ij}\|\bar D_{i,j}\|<\infty$ or similar?}  \nonumber \bS_\star(z) := \bS_\star(z; \alpha_0,\nu_0) &= (\bI_k \otimes \tau)\left[ \frac1{z}\left( z^{-1}(\bI_k \otimes M^{1/2})\bT(\bI_k \otimes M^{1/2} )   - (\bI_k \otimes \id) \right)^{-1}\right] \\ &= \sum_{a=0}^{\infty} (-z)^{-{(a+1)}}(\bI_k \otimes \tau)\left[\left(  (\bI_k \otimes M^{1/2})\bT (\bI_k \otimes M^{1/2} ) \right)^a\right].  Then, Eq.~\eqref{eq:moment_convergence} gives  \nonumber     (\bI_k \otimes \tau)\left[\left(  (\bI_k \otimes M^{1/2})\bT (\bI_k \otimes M^{1/2} ) \right)^a\right] = \lim_{m\to\infty}      (\bI_k \otimes \frac1m \Tr)\left[\left(  (\bI_k \otimes \bX^\sT)\bar\bSec^\up{m} (\bI_k \otimes \bX ) \right)^a\right].  Hence, there exists $r_0$, possibly dependent on $k$, such that for $|z| > r_0$,       \bS_\star(z) &= \lim_{m\to\infty} \sum_{a=0}^{\infty}     (-z)^{-(a+1)}(\bI_k \otimes \frac1m \Tr)\left[\left(  (\bI_k \otimes \bX^\sT)\bar\bSec^\up{m} (\bI_k \otimes \bX ) \right)^a\right] = \lim_{m\to\infty}\bS_m(z, \hnu_{0,m})  element-wise. It follows again from  Eq.~\eqref{eq:ExpSstar} that $\|\bS\|_{\op}\le C/|z|$ for $|z|\ge r_1$. Finally, for $|z|\le r_2$, $\bS\mapsto \bF_z(\bS;\nu_0)$ is continuous  on $\|\bS\|_{\op}\le \eta$  (for suitable constants $r_1,r_2,\eta$).  Eventually increasing $r_0$, Lemma~\ref{lemma:fix_point_rate} implies that, for $|z|\ge r_0$   \nonumber     \bF_z(\bS_\star(z);\nu_0) = \lim_{m\to\infty}  \bF_z(\bS_m(z);\hnu_{0,m})      =  \lim_{m\to\infty} \alpha_0\bS_m(z; \hnu_{0,m}) = \alpha_0\bS_\star(z).  Since $z\mapsto \bF_z(\bS_\star(z))$ and $z\mapsto \bS_\star(z)$ are both analytic on $\bbH_+$  %($\bF_z(\bS)$ is analytic for all $\bS \in\bbH_+^k$), we conclude the claim by analytic continuation.",2502.01953
proof,"By the Gelfand-Naimark-Segal construction \cite[Lecture 7]{nica2006lectures}, there exists a Hilbert space $\cH$ and a $*$-representation of $\cA$, $\pi :\cA \to\cB(\cH)$ and some $\psi_0 \in \cH$ with $\norm{\psi_0}_\cH = 1$ such that for any $A \in\cA$,       \tau(A) = \inner{\psi_0,\pi(A) \psi_0}_\cH.  Let us identify $A$ with $\pi(A)$ in the notation below. Recall the product space $\cH^{k} := \cH \times \cdots \times \cH$ with Hilbert inner product given by             \inner{         (\xi_1,\cdots,\xi_k),(\bar\xi_1,\cdots,\bar\xi_k)}_{\cH^k} = \sum_{i=1}^k \inner{\xi_i, \bar \xi_i}_\cH     for $\xi_i,\bar \xi_i \in\cH$ for $i\in[k]$. Now we can bound  $\sigma_{\min}(\Im(\bS_\star))$ by the variational characterization   \sigma_{\min}(\Im(\bS_\star))  %&= \lambda_{\min}(\Im(\bS_\star))\\  &=     \lambda_{\min}\left((\bI_k \otimes \tau)\Im(\bR_\star)\right)    =\hspace{-2mm} \inf_{\substack{\bu\in\C^k\\\norm{\bu}_2 = 1}}  \bu^*     \left(\bI_k\otimes \psi_0\right)^* \Im(\bR_\star)(\bI_k \otimes \psi_0) \bu   \nonumber     \\ &= \hspace{-2mm}\inf_{\substack{\bu\in\C^k\\\norm{\bu}_2 = 1}} \psi_0^* (\bu\otimes \aid)^*      \Im(\bR_\star)(\bu \otimes \aid) \psi_0     \nonumber    \\ &\ge  \norm{\psi_0}_\cH^2 \norm{\bu \otimes \aid}_{\cH^k}^2  \lambda_{\min}\left(\Im(\bR_\star)\right)  =  \lambda_{\min}\left(\Im(\bR_\star)\right). \nonumber  So by Lemma~\ref{lemma:re_im_properties},   \sigma_{\min}(\Im(\bS_\star))  &= \Im(z)\lambda_{\min}\left(\bR_\star^* \bR_\star\right) \ge  \Im(z) \left( \norm{(\bI_k \otimes M^{1/2}) \bar \bSec (\bI_k \otimes M^{1/2})}_{\cB(\cH^k)} + |z| \right)^{-2}   %where $(a)$  follows from $\Im(\bS_\star) \succ\bzero$ To bound the norm in the term above,  note that for any nonnegative integer $p$, we have        \nonumber        \left(\frac1k \Tr \otimes \tau\right)\left(|\bar \bSec|^{2p}\right)  \stackrel{(a)}{=}        \left(\frac1k \Tr \otimes \tau\right)\left(\bar \bSec^{2p}\right)  =  \lim_{n\to\infty}\left(\frac1k \Tr \otimes \frac1n\Tr\right)\left((\bar \bSec^\up{n})^{2p}\right) \stackrel{(b)}{\le} \lim_{n\to\infty}\norm{\bar \bSec^\up{n}}_\op^{2p} \stackrel{(c)}{\le} \sfK^{2p}     where $(a)$ follows from self-adjointness, $(b)$ follows by monotonicity of $L^p$ norms and $(c)$ follows from Lemma~\ref{lemma:as_norm_bounds}. Now taking both sides to the power $1/(2p)$ and sending $p\to\infty$ gives the bound  \nonumber     \norm{\bar \bSec}_{\cB(\cH^k)} \le \sfK.  Meanwhile, by definition of the free Poisson element $M$, we have  \nonumber \norm{\bI_k \otimes M^{1/2}}_{\cH^k}^2 \le (1+ \alpha_0^{-1/2})^2.  Combining the previous two displays with Eq.~\eqref{eq:lb_on_Sstar} gives the claim.",2502.01953
proof,"The first part of the statement follows directly from Lemma~\ref{lemma:smallest_singular_value_Sstar}.   That $\mu_\star(\mu,\nu)$ is compactly supported follows from the definition of $\mu_\star$ as the measure whose Stieltjes transform is $\bS_\star$ of Eq.~\eqref{eq:def_S_star} and the definition in Eq.~\eqref{eq:def_H_star} and uniform bounds on the operator norm of $\bH_\star.$",2502.01953
proof,"%Let us suppress the dependence on $\bSec$ in what follows in the expectations. %For $\bS \in\bbH_+^k$ and $z\in\bbH_+$, %we have by Lemma~\ref{lemma:re_im_properties}, % % %    \Im(\bF_z(\bS)) = -\bF_z(\bS) \left(\Im(\E[\bG(\bS)]) - \Im(z) \bI  \right)\bF_z(\bS)^* = %\bF_z(\bS) \left(\E[\bG(\bS)\Im(\bS)\bG(\bS)^*] + \Im(z) \bI  \right)\bF_z(\bS)^*  %\succ \bzero. % %Hence, by the bounds in this same lemma, % %   \norm{\frac{1}{\alpha}\bF_z(\bS)}_\op \le \norm{\frac{1}{\alpha}\Im\left(\E[\bG(\bS;\bSec)] -z\bI\right)^{-1}}_\op  %   = \norm{\frac{1}{\alpha}(\E[\bG(\bS)\Im(\bS) \bG(\bS)] + z\bI)^{-1}}_\op \le \frac1{\alpha\Im(z)} = \frac{R(z)}{2}. % %So the image of $\cH(R,r)$ is contained strictly in $\{\norm{\bS}_\op < R\}$ for all $R \ge R(z).$ %We show now that it's contained strictly in $\{\bS \succ r\}$ for any $r\le r(z).$ %    %As an illustration, let us first consider the case of $k=1$. %    %Write $F_z$ and $\eta$ for the functions involved in this case. %    %Then we can write %    % %    %    \Im( F_z) = \Im\left(\frac{F_z \overline F_z}{\overline F_z}\right) %    %    =  |F_z|^2 \Im\left(\frac{1}{\overline F_z } \right) %    %    =|F_z|^2 \Im \left(\overline z - \overline \eta\right) \le - |F_z|^2 \Im(z). %    % %    %Now, we have  %    % %    %|F_z|^2 \Im(z) = |(z - \eta)^{-1}|^2  |\Im(z)| \ge  %    %\frac{|\Im(z)|}{\left(|z| + \sup_{q \in \cH(C)}|\eta(q)|\right)^2}. %    % %    %This gives a sufficient bound. %    %We write now %    % %    %    \Im(\bF_z) = \frac1{2i}\left(\bF_z - \bF_z^*\right) = \bF_z^* \left( \frac{\bF_z^{* -1} - \bF_z^{-1}}{2i}\right)\bF_z = \bF_z^* \Im(\bF_z^{*-1}) \bF_z = \bF_z^* \left(\Im(\overline{z}\bI)- \Im(\boldeta^*)\right) \bF_z. %    % %    %Now  since $-\Im(\boldeta^*) = \Im(\boldeta) \preceq \bzero$ by assumption, we have the bound %First, we bound the lowest singular value of $\bF_z$ using Lemma~\ref{lemma:re_im_properties}: %     %    \norm{\bF_z^{*-1}}_\op \le \norm{\E[\bG(\bS)] - z\bI}_\op %\le %    \norm{\Im(\bS)^{-1}}_\op  + |z| %    \le  \eps + |z|. %     %Consequently,  %by Eq.~\eqref{eq:imagine_part_F} once again, we have %     %        \Im(\alpha^{-1}\bF_z) \succeq  \frac{\Im(z)}{\alpha}\bF_z\bF_z^* %\succeq\frac{\Im(z)}{\alpha(|z| + r(z))^2} \bI_k = 2 r(z) \bI \succ r(z) \bI, % %which gives the desired conclusion. %",2502.01953
proof,"[Proof of Proposition~\ref{prop:existence_unqiuness}]  %Fix any $z \in \bbH_+$. Then for any $R > R(z), r<r(z)$, $\alpha^{-1}\bF_z$ has a unique fixed point in $\cH(R,r)$ be Theorem~\notate{ref}. Uniqueness of this solution on $\bbH_+^k$ follows from observing that $\cH(R_p,r_p) \uparrow \bbH_+^k$ as $p\to\infty$ for $R_p := p R(z), r_p := r(z)/p$. %",2502.01953
proof,"%Fix $\bQ \in\bbH_k^-$. %Let us first show that $(\bI-\bSec\bQ)$ is invertible for any fixed $\bSec$ real and symmetric. %Namely, we'll show that for all non-zero $\bv \in\C^k$, $\bv^*(\bI - \bSec\bQ) \neq \bzero^*$. %First note that if non-zero $\bv$ satisfies $\bSec\bv =\bzero$, then this is clear. %Meanwhile, to see this for the case of $\bv$ with $\bu := \bSec\bv \neq \bzero,$ note that $\bSec,\Re(\bQ)$ and $\Im(\bQ)$ are all self-adjoint and hence % %    \bv^* (\bI - \bSec \bQ)\bu =  \bv^*\bSec \bv - \bv^* \bSec \Re(\bQ) \bSec\bv  -i\bv^* \bSec \Im(\bQ) \bSec\bv = \bv^*\bSec \bv - \bu^* \Re(\bQ) \bu - i \bu^* \Im(\bQ) \bu % %is of the form $ a + ib$ for $a,b\in\R$ and $b = \bu^* \Im(\bQ) \bu  < 0$ by assumption on $\bQ$. Hence $\bv^*(\bI - \bSec\bQ) \neq \bzero^*$. % %This now implies that $\boldeta(\bQ)$ is holomorphic and well defined on $\bbH_k^-$. What remains is to show is that $\Im(\bQ) \preceq \bzero$ if $\bQ\in\bbH_k^-$ . % %%Let $\cG = \{\, \bSec\,\, \textrm{invertible} \,\}$. %%On $\cG$,  we have $(\bI -\bSec\bQ)^{-1}\bSec = (\bSec^{-1} - \bQ)^{-1}$. %%Since $\Im((\bSec^{-1} - \bQ)) = -\Im(\bQ) \succ\bzero$, we conclude by Lemma~\ref{lemma:re_im_properties} that $(\bSec^{-1} - \bQ)^{-1} \in\bbH_k^-$ on $\cG$. % %%Now for $\cG^c$, %For fixed $\bSec$, let $\sigma_{\min} \equiv \sigma_{\min}(\bSec) \in\R$, and for $\eps \in( 0,1)$ define % %    \bSec_\eps := \bSec + \eps \sigma_{\min} \sign(\sigma_{\min}) \bI_k % %The matrix $\bSec_\eps$ is then invertible, real and symmetric and hence  % %\Im((\bI - \bSec_\eps\bQ)^{-1}\bSec_\eps)  %=\Im((\bSec_\eps^{-1} - \bQ)^{-1}) %\prec \bzero % %so that for any non-zero $\bv \in\C^k$, $\eps \mapsto \bv^* \Im( %(\bI - \bSec_\eps\bQ)^{-1}\bSec_\eps)\bv$ is strictly negative for all $\eps \in(0,1)$. %Furthermore, it is continuous (see for instance the explicit form in Eq.~\eqref{eq:im_invs}). So taking $\eps \to 0$ shows that $\Im( %(\bI - \bSec\bQ)^{-1}\bSec) \preceq \bzero$. %Finally, note that %    $\Im(\boldeta(\bQ))= \E\left[\Im((\bI - \bSec\bQ)^{-1}\bSec)\right] \preceq \bzero.$ %",2502.01953
proof,"%In what follows,  %let $\bSec_1,\dots,\bSec_p, \widetilde \bSec_1,\dots,\widetilde\bSec_p$ be i.i.d. copies of $\bSec$. %We use the shorthand $\bG_{n,i} \equiv \bG(\bQ_n;\bSec_i)$ and  %$\widetilde\bG_{n,i} \equiv \bG(\bQ_n;\widetilde\bSec_i)$. %Now we write %\bns{Fix $\bF$ to $\bF_n$. Fix $\bB$ to $\bB^{-1}$.} % %\frac1{\alpha^{2p}}\frac1k\Tr\left( | %\bT^p(\bM)|^2\right) %&= \frac1k \Tr\left( %\E\left[ %\prod_{i=p}^1 (\bF \bG_i)\bM \prod_{i=1}^p(\bG_{n,i} \bF) %\prod_{i=p}^1 ( \bF^*\widetilde \bG_{n,i}^*) %\bM^* %\prod_{i=1}^p ( \widetilde \bG_{i}^*\bF^*) %\right] %\right) %\\ %&=  %\frac1k  %\E\left[ %\Tr\left( %\bB^{1/2}\bM \prod_{i=1}^p(\bG_{n,i} \bF) %\prod_{i=p}^1 ( \bF^*\widetilde \bG_{n,i}^* ) %\bB_n^{-1/2}\bB_n^{1/2} %\bM^* %\prod_{i=1}^p ( \widetilde \bG_{i}^*\bF^*) %\prod_{i=p}^1 (\bF \bG_i)\bB^{-1/2} %\right) %\right] %\\ %&\le  %\frac1k  %\E\left[ %\Tr\left( %\left| %\bB^{1/2} %\bM \prod_{i=1}^p(\bG_{n,i} \bF) %\prod_{i=p}^1 ( \bF^*\widetilde \bG_{n,i}^* ) %\bB_n^{-1/2} %\right|^2\right) \right]^{1/2}\\ %&\hspace{10mm} %\E\left[\Tr\left( %\left| %\bB_n^{1/2} %\bM^* %\prod_{i=1}^p ( \widetilde \bG_{i}^*\bF^*) %\prod_{i=p}^1 (\bF \bG_i) %\bB^{-1/2} %\right|^2 %\right) %\right]^{1/2} % %where the inequality follows by H\""older for $L_p(S^p)$ norms. %We bound the second expectation as  % %&\E\left[\Tr\left( %\left| %\bB_n^{1/2} %\bM^* %\prod_{i=1}^p ( \widetilde \bG_{i}^*\bF^*) %\prod_{i=p}^1 (\bF \bG_i) %\bB^{-1/2} %\right|^2 %\right) %\right]\\ %&= %\E\left[\Tr\left( %\bB_n^{1/2} %\bM^* %\prod_{i=1}^p ( \widetilde \bG_{i}^*\bF^*) %\prod_{i=p}^1 (\bF \bG_i) %\bB^{-1} %\prod_{i=1}^p (\bG_i^*\bF^* ) %\prod_{i=p}^1 (\bF \widetilde \bG_{i}) %\bM %\bB_n^{1/2} %\right) %\right]\\ %&\le %\E\left[\Tr\left( %\bB_n^{1/2} %\bM^* %\prod_{i=1}^p ( \widetilde \bG_{i}^*\bF^*) %\bB^{-1} %\prod_{i=p}^1 (\bF\widetilde \bG_{i}) %\bM %\bB_n^{1/2} %\right) %\right] %\norm{\E\left[\bB^{1/2} \bF \bG \bB^{-1}\bG^* \bF^*\bB^{1/2}\right]}_\op^p\\ %&\le %\E\left[\Tr\left( %\bB_n^{1/2} %\bM^* %\widetilde \bG_1^* %\prod_{i=2}^p (\bF^* \widetilde \bG_{i}^*) %\bB^{-1} %\prod_{i=p}^2 (\widetilde \bG_{i}\bF) \widetilde \bG_1 %\bM %\bB_n^{1/2} %\right) %\right] %\norm{\E\left[\bB^{1/2} \bF \bG \bB^{-1}\bG^* \bF^*\bB^{1/2}\right]}_\op^p %\norm{\bB^{-1}}_\op %\norm{\bB^{1/2}\bF^* \bF \bB^{1/2}}_\op %\\ %&\le  %\E\left[\Tr\left( %\bB_n^{1/2} %\bM^* %\widetilde \bG_1^* %\bB^{-1} %\widetilde\bG_1 %\bM %\bB_n^{1/2} %\right) %\right] %\norm{\E\left[\bB^{1/2} \bF \bG \bB^{-1}\bG^* \bF^*\bB^{1/2}\right]}_\op^{2p-1} %\norm{\bB^{-1}}_\op %\norm{\bB^{1/2}\bF^* \bF \bB^{1/2}}_\op\\ %&\le  %\E\left[\Tr\left( %\bM^* %\bM %\right) %\right] %\norm{\E\left[\bB^{1/2} \bF \bG \bB^{-1}\bG^* \bF^*\bB^{1/2}\right]}_\op^{2p-1} %\norm{\bB^{-1}}_\op %\norm{\bB^{1/2}\bF^* \bF \bB^{1/2}}_\op %\norm{ %\E[ \bG^* %\bB^{-1}\bG]}_\op %\norm{\bB_n}_\op. % %A similar computation gives the bound on the first expectation  % %    &\E\left[ %\Tr\left( %\left| %\bB^{1/2} %\bM \prod_{i=1}^p(\bG_{n,i} \bF) %\prod_{i=p}^1 ( \bF^*\widetilde \bG_{n,i}^* ) %\bB_n^{-1/2} %\right|^2\right) \right]\\ %&\le %\E\left[\Tr\left( %\bM^* %\bM %\right) %\right] %\norm{\E\left[\bB_n^{1/2} \bF_n \bG_n \bB_n^{-1}\bG_n^* \bF_n^*\bB_n^{1/2}\right]}_\op^{2p-1} %\norm{\bB_n^{-1}}_\op %\norm{\bB_n^{1/2}\bF_n^* \bF_n \bB_n^{1/2}}_\op %\norm{ %\E[ \bG_n^* %\bB_n^{-1}\bG_n]}_\op %\norm{\bB}_\op % %where we used that all matrices involved are symmetric. %",2502.01953
proof,"%By Lemma~\ref{lemma:re_im_properties}, we have %$\Im(\bG_\star) = -\bG_\star\bB \bG_\star^*$, and $\Im(\bS_\star^{-1}) = - \bS_\star^{-1} \bB\bS_{\star}^{*-1}.$ %So rewriting the fixed point for $\bS_\star$ as %    $z\bI = \E[\bG_\star] - \frac1\alpha \bS_\star$ and taking the imaginary parts %gives % %\bzero\prec \Im(z) \bI = - \E[\bG_\star \bB \bG_\star^*] + \frac1\alpha\bS_\star^{-1}\bB\bS_\star^{*-1}. % %This implies % %    \alpha \bB^{-1/2} \bS_\star\E[\bG_\star \bB\bG_\star^*] \bS_\star^* \bB^{-1/2} \prec  %    \bI - \frac{\alpha\Im(z)}{2} \bB^{-1/2}\bS_\star\bS^*_\star \bB^{-1/2},\quad %   \alpha \E[\bG_\star\bB\bG_\star^*]  \preceq \bS_\star^{-1}\bB\bS_\star - \Im(z)\bI, % %giving the bounds desired. %% %%    \norm{ %%\alpha \bB^{-1/2} \bS_\star\E[\bG_\star \bB\bG_\star^*] \bS_\star^* \bB^{-1/2} }_\op < 1 -\frac{\alpha \Im(z)}{2} \lambda_{\min}(\bB^{-1/2} \bS_\star \bS_\star^* \bB^{-1/2}), %% % %For the remaining two bounds, once again let us write, by definition of $\bF_n$, %   $z\bI = \E[\bG_n] - \bF_n^{-1},$ %which then gives, after multiplying to the left by $\bF_n$ and to the right by $\bF_n^*$, % %    z \bF_n \bF_n^* =  \E[\bF_n \bG_n \bF_n^*] - \bF_n^*. % %Taking the imaginary part using Lemma~\ref{lemma:re_im_properties} then gives % %    \Im(z) \bF_n \bF_n^* = - \E[\bF_n \bG_n\bB_n \bG_n^* \bF_n^*]  + \Im ( \bF_n) % %so that % %    \E[\bF_n \bG_n \bB_n \bG_n^* \bF_n^*] = \Im(\bF_n - \alpha\bQ_n)  + \alpha\bB_n - \Im(z) \bF_n\bF_n^*. % %Letting $\bE_n := (\alpha^{-1}\bI  -\bF_n^{-1} \bQ_n)$, % %    \norm{\Im(  \bF_n^{-1} (\bF_n - \alpha\bQ_n) \bF_{n}^{*-1})}_\op %    &= %   \alpha \norm{\Im(   \bE_n \bF_{n}^{*-1})}_\op %   \le   %    \alpha\norm{\bE_n}_\op\norm{\bF_n^{-1}}_\op %    \le \norm{\bE_n}_\op \norm{\bQ_n^{-1}}_\op \norm{\bI - \bE_n}_\op\\ %    &\le \frac2{\Im(z)} \left(\frac{1}{n^2}\norm{\bH}_\op^2  + |z|^2\right) \omega_{\textrm{FP}}(z;n,k) (1 + \omega_{\textrm{FP}}(z; n, k)) % %and taking $n \le n_0(z)$ so that  %\bns{Fix this} % %     \frac{10(\sfK^2 + |z|)}{\alpha\Im(z)^2}\omega_{\textrm{FP}}(z;n,k)(1 + \omega_{\textrm{FP}}(z;n,k))  \le  1, % %we have on the event $\cG_0$ of Lemma~\notate{ref} that % %    \frac1{\alpha}\norm{\E[\bB_n^{-1/2}\bF_n \bG_n \bB_n \bG_n^* \bF_n^* \bB_n^{-1/2}]  }_\op %    \le \bI -  \frac{\Im(z)}{\alpha}\lambda_{\min} \left(\bB_n^{-1/2} \bF_n\bF_n^* \bB_n^{-1/2}\right), % %and similarly, % %\norm{\E[\bG_n \bB_n\bG_n^*]}_\op \le \norm{\Im(\bF_n^{-1})}_\op. % %",2502.01953
proof,"In what follows,  let $\bW_1,\dots,\bW_p, \widetilde \bW_1,\dots,\widetilde\bW_p$ be i.i.d. copies of $\bW$. We use the shorthand $\bfeta_{\star,i} \equiv \bfeta(\bS_\star;\bG_i)$ and  $\widetilde\bfeta_{\star,i} \equiv \bfeta(\bS_\star;\widetilde\bG_i)$. Similarly define $\bfeta_i, \widetilde\bfeta_i$ for $\bS$ replacing $\bS_\star$. Fix any $\bv,\bu\in \C^{k}$ and $\bDelta \in \C^{k\times k}$ and write  \left|\bv^* \bT^p(\bDelta) \bu\right|^2 &=  \bu^* \bT^p(\bDelta)^* \bv \bv^*  \bT^p(\bDelta) \bu\\ &=  \Tr\left( \bu^*\E\left[ \prod_{i=p}^1 (\bF \bfeta_i)\bDelta \prod_{i=1}^p(\bfeta_{\star,i} \bF_\star) \bv\bv^* \prod_{i=p}^1 ( \bF_\star^*\widetilde \bfeta_{\star,i}^*) \bDelta^* \prod_{i=1}^p ( \widetilde \bfeta_{i}^*\bF^*) \right]\bu \right) \\ &=  \E\left[ \Tr\left( \bDelta \prod_{i=1}^p(\bfeta_{\star,i} \bF_\star) \bv\bv^* \prod_{i=p}^1 ( \bF_\star^*\widetilde \bfeta_{\star,i}^* ) \bDelta^* \prod_{i=1}^p ( \widetilde \bfeta_{i}^*\bF^*) \bu\bu^* \prod_{i=p}^1 (\bF \bfeta_i) \right) \right] \\ &\le  \E\left[ \Tr\left( \left| \bDelta \prod_{i=1}^p(\bfeta_{\star,i} \bF_\star) \bv\bv^* \prod_{i=p}^1 ( \bF_\star^*\widetilde \bfeta_{\star,i}^* ) \right|^2\right) \right]^{1/2}\\ &\hspace{10mm} \E\left[\Tr\left( \left| \bDelta^* \prod_{i=1}^p ( \widetilde \bfeta_{i}^*\bF^*)\bu\bu^* \prod_{i=p}^1 (\bF \bfeta_i) \right|^2 \right) \right]^{1/2}  where the inequality follows by Cauchy-Schwarz for (random)  matrices. We bound the second expectation as   &\E\left[\Tr\left( \left| \bDelta^* \prod_{i=1}^p ( \widetilde \bfeta_{i}^*\bF^*) \bu\bu^* \prod_{i=p}^1 (\bF \bfeta_i) \right|^2 \right) \right]\\ &= \E\left[\Tr\left( \bDelta^* \prod_{i=1}^p ( \widetilde \bfeta_{i}^*\bF^*) \bu\bu^* \prod_{i=p}^1 (\bF \bfeta_i) \prod_{i=1}^p (\bfeta_i^*\bF^* ) \bu\bu^* \prod_{i=p}^1 (\bF \widetilde \bfeta_{i}) \bDelta \right) \right]\\ &= \E\left[ \bu^* \prod_{i=p}^1 (\bF \widetilde \bfeta_{i}) \bDelta \bDelta^* \prod_{i=1}^p ( \widetilde \bfeta_{i}^*\bF^*) \bu \right] \E\left[ \bu^* \prod_{i=p}^1 (\bF \bfeta_i) \prod_{i=1}^p (\bfeta_i^*\bF^* ) \bu \right] \\ &\le \E\left[ \bu^* \prod_{i=p}^1 (\bF \widetilde \bfeta_{i}) \bDelta \bDelta^* \prod_{i=1}^p ( \widetilde \bfeta_{i}^*\bF^*) \bu \right] \norm{\bB^{-1}}_\op \norm{\E[\bB^{-1/2} \bF\bfeta \bB\bfeta^* \bF^* \bB^{-1/2}]}_\op^p \norm{\bB}_\op \norm{\bu}_2^2\\ &\le \norm{\bDelta}_\op^2  \norm{\E[\bB^{-1/2} \bF\bfeta \bB\bfeta^* \bF^* \bB^{-1/2}]}_\op^{2p} \norm{\bB^{-1}}_\op^2 \norm{\bB}_\op^2 \norm{\bu}_2^4,  where the last two inequalities can be proven by induction over $p$. A similar computation gives the bound on the first expectation       \E\left[ \Tr\left( \left| \bDelta \prod_{i=1}^p(\bfeta_{\star,i} \bF_\star) \bv\bv^* \prod_{i=p}^1 ( \bF_\star^*\widetilde \bfeta_{\star,i}^* ) \right|^2\right) \right] \le \norm{\bDelta}_\op^2  \norm{\E[\bB_\star^{-1/2} \bF_\star\bfeta_\star \bB_\star\bfeta_\star^* \bF_\star^* \bB_\star^{-1/2}]}_\op^{2p} \norm{\bB_\star^{-1}}_\op^2 \norm{\bB_\star}_\op^2 \norm{\bv}_2^4.  Taking supremum over $\bv,\bu$ of unit norm gives that      \frac{\norm{\bT^p(\bDelta)}_\op}{\norm{\bDelta}_\op} &\le     \Bigg(  \norm{\E[\bB_\star^{-1/2} \bF_\star\bfeta_\star \bB_\star\bfeta_\star^* \bF_\star^* \bB_\star^{-1/2}]}_\op^p \norm{\bB_\star^{-1}}_\op \norm{\bB_\star}_\op\\ &\hspace{60mm}\cdots\norm{\E[\bB^{-1/2} \bF\bfeta \bB\bfeta^* \bF^* \bB^{-1/2}]}_\op^{p} \norm{\bB^{-1}}_\op \norm{\bB}_\op \Bigg)^{1/2}  for all $\bDelta$. Taking supremum over $\norm{\bDelta}_\op = 1$ gives the result.",2502.01953
proof,"By Lemma~\ref{lemma:re_im_properties}, we have $\Im(\bfeta_0) = -\bfeta_0\bB_0 \bfeta_0^*$, and $\Im(\bS_0^{-1}) = - \bS_0^{-1} \bB_0\bS_{0}^{*-1}.$ So rewriting the fixed point for $\bS_0$ as     $z\bI = \E[\bfeta_0] - \alpha_n^{-1} \bS_0^{-1}$ and taking the imaginary parts gives  \nonumber \bzero\prec \Im(z) \bI = - \E[\bfeta_0 \bB_0 \bfeta_0^*] + \frac1\alpha_n\bS_0^{-1}\bB_0\bS_0^{*-1}.  This implies  \nonumber     \alpha_n \bB_0^{-1/2} \bS_0\E[\bfeta_0 \bB_0\bfeta_0^*] \bS_0^* \bB^{-1/2} \prec      \bI - \frac{\alpha_n\Im(z)}{2} \bB_0^{-1/2}\bS_0\bS^*_0 \bB_0^{-1/2}  giving the first bound after substituiting $\bF_0 = \alpha_n  \bS_0$. % %    \norm{ %\alpha \bB^{-1/2} \bS_\star\E[\bG_\star \bB\bG_\star^*] \bS_\star^* \bB^{-1/2} }_\op < 1 -\frac{\alpha \Im(z)}{2} \lambda_{\min}(\bB^{-1/2} \bS_\star \bS_\star^* \bB^{-1/2}), %  For the bound \eqref{eq:SecondBoundFp}, once again let us write by definition of $\bF_n$,    $z\bI = \E[\bfeta_n] - \bF_n^{-1}$ which gives after multiplying to the left by $\bF_n$ and to the right by $\bF_n^*$  \nonumber     z \bF_n \bF_n^* =  \E[\bF_n \bfeta_n \bF_n^*] - \bF_n^*.  Taking the imaginary part using Lemma~\ref{lemma:re_im_properties} then gives  \nonumber     \Im(z) \bF_n \bF_n^* = - \E[\bF_n \bfeta_n\bB_n \bfeta_n^* \bF_n^*]  + \Im ( \bF_n)  so that      \E[\bF_n \bfeta_n \bB_n \bfeta_n^* \bF_n^*] = \Im(\bF_n - \alpha_n\bS_n)  + \alpha_n\bB_n - \Im(z) \bF_n\bF_n^*.  Letting $\bE_n := (\alpha_n^{-1}\bI  -\bF_n^{-1} \bS_n)$,      \norm{\Im(  \bF_n^{-1} (\bF_n - \alpha_n\bS_n) \bF_{n}^{*-1})}_\op     &=    \alpha_n \norm{\Im(   \bE_n \bF_{n}^{*-1})}_\op    \le       \alpha_n\norm{\bE_n}_\op\norm{\bF_n^{-1}}_\op\\     &     \le \norm{\bE_n}_\op \norm{\bS_n^{-1}}_\op \norm{\bI - \alpha_n\bE_n}_\op\\     &\stackrel{(a)}\le \frac1{\Im(z)} \left(\frac{1}{n^2}\norm{\bH}_\op^2  + |z|^2\right) \Err_{\FP}(z;n,k) (1 + \alpha_n\Err_{\FP}(z; n, k))\\     &\stackrel{(b)}\le \frac{10}{\Im(z)} \left(\sfK^2  + |z|^2\right) \Err_{\FP}(z;n,k) (1 + \alpha_n\Err_{\FP}(z; n, k))\\     &\stackrel{(c)}\le \frac{\Im(z)}{2}  on $\Omega_0 \cap\Omega_1(L)$, where $(a)$ follows from Lemma~\ref{lemma:fix_point_rate} and Lemma \ref{lemma:as_norm_bounds}, $(b)$ follows from Lemma~\ref{lemma:standard_norm_bounds}, and $(c)$ follows from the assumption in Eq.~\eqref{eq:n_n(z)}. We conclude that  \nonumber     \Im(\bF_n - \alpha_n\bS_n) - \frac{\Im(z)}{2}\bF_n\bF_n^* \preceq \bzero\, ,  and therefore, using Eq.~\eqref{eq:Fn-relation}, and the fact that $\Im(z)>0$,  \nonumber     \frac1{\alpha_n}\norm{\E[\bB_n^{-1/2}\bF_n \bfeta_n \bB_n \bfeta_n^* \bF_n^* \bB_n^{-1/2}]  }_\op     \le 1 -  \frac{\Im(z)}{2\alpha_n}\sigma_{\min} \left(\bB_n^{-1/2} \bF_n\bF_n^* \bB_n^{-1/2}\right)  as desired.",2502.01953
proof,"Let $\bS_0 \in\bbH_+^k$ be any solution to this fixed point equation.  Then by Eq.~\eqref{eq:relation_F_T}       0 = \bS_0 - \bS_\star - \frac1{\alpha_0} (\bF_z(\bS_0) -\bF_z(\bS_\star)) = \left(\id - \frac1{\alpha_0} \bT_{\bS_0}\right)\left(\bS_0 -\bS_\star\right).      So to conclude uniqueness, it's sufficient to show that $\left(\id - \alpha_0^{-1} \bT_{\bS_0}\right)$ is invertible. Using Lemmas~\ref{lemma:op_norm_bound_power_T} and~\ref{lemma:op_norm_bound_for_sols_fp}, let  \nonumber     \delta_0 := \frac{\alpha_0\Im(z)}{2} \lambda_{\min}(\bB_0^{-1/2}\bS_0 \bS_0^* \bB_0^{-1/2}),     \quad     \delta_\star := \frac{\alpha_0\Im(z)}{2} \lambda_{\min}(\bB_\star^{-1/2}\bS_\star \bS_\star^* \bB_\star^{-1/2}).  Since $\bS_0,\bS_\star \in\bbH_+^k$, we have by Lemma~\ref{lemma:re_im_properties} that $\delta_0,\delta_\star > 0$. Hence by Lemmas~\ref{lemma:op_norm_bound_power_T} and~\ref{lemma:op_norm_bound_for_sols_fp}       \norm{\sum_{p}\alpha_0^{-p} \bT_{\bS_0}^p}_{\op\to\op}  &\le \sum_{p} (1-\delta_0)^{p/2}(1-\delta_\star)^{p/2} \left(\norm{\bB_0}_\op \norm{\bB_0^{-1}}_\op  \norm{\bB_\star}_\op \norm{\bB_\star^{-1}}_\op\right)^{1/2} \\&\le      \left( \frac1{\delta_0 \delta_\star}\norm{\bB_0}_\op \norm{\bB_0^{-1}}_\op  \norm{\bB_\star}_\op \norm{\bB_\star^{-1}}_\op\right)^{1/2}    %The latter quantity is bounded by Lemma~\ref{lemma:re_im_properties} and since $\bS_0,\bS_\star \in\bbH_+^k$.  implying convergence of the Neumann series, and in turn, the desired invertibility.",2502.01953
proof,"Recalling (for $\bF_{\star} = \bF_z(\bS_{\star})$, $\bF_{n} = \bF_z(\bS_{n})$) that $\alpha_n^{-1}\bF_\star = \bS_\star$ and  $\alpha_n^{-1}\bF_n = \bS_n +\bF_n\bE_n$ where $\bE_n := \alpha_n^{-1}\bI - \bF_n^{-1}\bS_n$, we have by Eq.~\eqref{eq:relation_F_T},      \bS_\star - \bS_n =     \alpha_n^{-1}(\bF_\star - \bF_n)  + \bF_n\bE_n =     \frac1\alpha_n \bT_{\bS_n}(\bS_\star -\bS_n) +  \bF_n\bE_n.  Letting  \nonumber     \delta_\star := \frac{\alpha_n\Im(z)}{2} \lambda_{\min}(\bB_\star^{-1/2} \bS_\star\bS_\star^* \bB_\star^{-1/2}),\quad     \delta_n := \frac{\Im(z)}{2\alpha_n} \lambda_{\min}(\bB_n^{-1/2} \bF_n\bF_n^* \bB_n^{-1/2}),  an argument similar to that of Lemma~\ref{lemma:uniqueness_ST} (making use of Lemmas~\ref{lemma:op_norm_bound_power_T} and~\ref{lemma:op_norm_bound_for_sols_fp})  implies that $(\id- \alpha_n^{-1}\bT_{\bS_n})$ is invertible and so  \nonumber     \norm{\bS_* - \bS_n}_\op      &= \norm{\left(\bI - \alpha_n^{-1}\bT_{\bS_n}\right)^{-1} \bF_n \bE_n}\\ \nonumber     %&\le\norm{\sum_{p=0}^\infty \frac1{\alpha^p}\bT^p  }_\op \norm{\bF_n}_\op\norm{\bE_n}_\op\\     &\le \sum_{p=0}^\infty \alpha_n^{-p}\norm{\bT_{\bS_n}^p}_{\op\to\op} \norm{\bF_n\bE_n}_\op\\ \nonumber     &\le \sum_{p=0}^\infty (1-\delta)^{p/2}(1-\delta_n)^{p/2}      \left(\norm{\bB_n^{-1}}_\op \norm{\bB_n}_\op      \norm{\bB}_\op \norm{\bB^{-1}}_\op\right)^{1/2} \norm{\bF_n}_\op\norm{\bE_n}_\op \\     &\le \left(     \frac{1}{\delta}     \frac{1}{\delta_n}     \norm{\bB_n^{-1}}_\op \norm{\bB_n}_\op      \norm{\bB}_\op \norm{\bB^{-1}}_\op     \right)^{1/2}     \norm{\bF_n}_\op \norm{\bE_n}_\op.        Now we collect the bounds appearing on the right-hand side of this equation. On the event $\Omega_0$ of Lemma~\ref{lemma:standard_norm_bounds}, we have Lemma~\ref{lemma:as_norm_bounds} and  Corollary~\ref{cor:S_star_min_singular_value_bound} (recall that $\bB_n=\Im(\bS_n)$, $\bB_{\star}=\Im(\bS_{\star})$):   \nonumber     \norm{\bB_n^{-1}}_\op \le  \frac{C_1}{\Im(z)} \left( \sfK^2 + |z|^2 \right),\quad\textrm{and}\quad     \norm{\bB_\star^{-1}}_\op \le \frac{C_2}{\Im(z)}\left(\sfK^2 + |z|^2\right),  respectively. Furthermore, by Lemma~\ref{lemma:re_im_properties}, then Lemma~\ref{lemma:as_norm_bounds} and Corollary~\ref{cor:S_star_min_singular_value_bound} respectively, we have the bounds  \nonumber    \norm{\bB_n}_\op \le \frac1{\Im(z)},\quad  \norm{\bB_\star}_\op \le\frac1{\Im(z)}.  Meanwhile, to bound the norm of $\bF_n$, we  can observe that      $\bF_n = \alpha_n (\bF_n \bE_n + \bS_n)$. Since the assumption guarantees that   \norm{\bE_n}_\op \equiv \Err_{\FP} \le \frac1{2\alpha_n}  \frac1{1+\alpha_n \Err_{\FP}} \frac{|z|^2}{10(\sfK^2 + |z|^2)} \le \frac1{2\alpha_n},  we conclude that   \nonumber     \norm{\bF_n}_\op \le 2\alpha_n \norm{\bS_n}_\op \stackrel{(a)}{\le} \frac{2\alpha_n}{\alpha_n \Im(z)} = \frac{2}{\Im(z)},  where $(a)$ follows from Lemma~\ref{lemma:as_norm_bounds}. Further, we have   \delta_{\star} &= \frac{\alpha_n \Im(z)}{2} \lambda_{\min}\left(   (\bB_\star^{-1/2}\bA_\star\bB_\star^{-1/2} + i \bI)\bB_\star (\bB_\star^{-1/2}\bA_\star\bB_\star^{-1/2} - i\bI) \right) \\ &\stackrel{(a)}{\ge} \frac{\alpha_n\Im(z)}{2} \lambda_{\min}\left(\bB_\star\right) \ge   C_3\frac{\alpha_n\Im(z)^2}{\sfK^2 + |z|^2}   \nonumber  where $(a)$ holds since the spectrum of $\bB_{\star}^{-1/2}\bA_{\star}\bB_{\star}^{-1/2}$ is real. Finally, we lower bound $\delta_n$ by writing %\delta_{n} \ge \frac{\Im(z)}{2 \alpha} \sigma_{\min}(\bB_n^{-1}) \sigma_{\min}(\bF_n)^2 \ge C   %\frac{\Im(z)}{\alpha(1 + \alpha \omega_n)} \sigma_{\min}(\bB_n^{-1}) \sigma_{\min}(\bB_n)^2 %\ge  %C   %\frac{\Im(z)^4}{\alpha(1 + \alpha \omega_n)} \sigma_{\min}(\bB_n)^2      \delta_n  &= \frac{\Im(z)}{2\alpha_n} \lambda_{\min}(\bB_n^{-1/2} \bS_n \bS_n^{-1}\bF_n \bF_n^*\bS_n^{*-1}\bS_n^*\bB_n^{-1/2})     \ge \frac{\Im(z)}{2\alpha_n} \sigma_{\min}(\bS_n^{-1} \bF_n) \lambda_{\min}\left( \bB_n^{-1/2} \bS_n \bS_n^* \bB_n^{-1/2}\right).  Noting that as a consequence of Eq.~\eqref{eq:bound_En} we have     $\norm{\bS_n \bF_n^{-1}} = \norm{\alpha_n^{-1}+\bE_n}_\op \le  3/(2\alpha_n)$ gives us the lower bound on $\sigma_{\min}(\bS_n^{-1}\bF_n) \ge 2\alpha_n/3$. This along with the decomposition of Eq.~\eqref{eq:lb_delta_star} applied to the display above gives   \nonumber     \delta_n \ge \frac{\Im(z)}{3}\lambda_{\min}(\bB_n^{-1/2} \bS_n\bS_n^* \bB_n^{-1/2}) \ge \frac{\Im(z)}{3} \lambda_{\min}(\bB_n) \ge C_4\frac{\Im(z)^2}{\sfK^2 + |z|^2}.  Using these bounds in Eq.~\eqref{eq:S_Sn_rate_expansion} above gives the claim.",2502.01953
proof,"We apply Lemma~\ref{lemma:f_bound_st}. By definition of $\mu_\star$,  for $\alpha_n >1$, there exists a constant $A_0(\sfK) > 0$ such that  \nonumber     \supp\left(\mu_\star(\nu, \alpha_n)\right) \subseteq [-A_0(\sfK),A_0(\sfK)].  Furthermore, on the event $\Omega_0$ of Lemma~\ref{lemma:standard_norm_bounds}, we have the bound (for a similarly bounded constant $A_1$)  \nonumber     \frac1n\norm{\bH}_\op      %\le C \sfK  \left( 1 + \alpha_n^{-1}\right)      \le A_1(\sfK).      %for some universal $C>0.$ % Taking  $A := A_1(\sfK) \vee A_0(\sfK)$, we have by Lemma~\ref{lemma:f_bound_st} that  for any $\gamma \in (0,1)$, denoting  \nonumber     \hat I_n(\hnu) :=      \frac1{dk} \Tr\;f \left(\frac1n \bH(\hnu)\right), \quad     I_\star(\hnu) :=  \int f(\lambda) \mu_{\MP}(\hnu,\alpha_n)(\de\lambda),   \left|     \hat I_n(\hnu)-  I_\star(\hnu)\right| &\le C_4(\sfK) \bigg( \norm{f}_{\infty,A(\sfK)}  \sup_{x \in [-2A,2A]}\left|s_n(x + i \gamma;\hnu) - s_\star(x+ i\gamma;\hnu,\alpha_n)\right|+\gamma \left(\norm{f}_{\Lip}  + \norm{f}_{\infty,A(\sfK)}  \right)  \bigg).  Meanwhile, on $\Omega_0\cap\Omega_1(1)$ (choosing $L=1$ in the definition of $\Omega_1$), we have by Lemma~\ref{lemma:rate_matrix_ST},    \sup_{x\in[-2A,2A]} |s_n(x + i \gamma) - s_\star(x+i\gamma)| &\le    \sup_{x\in [-A,A]}\norm{\bS_n(x+i \gamma) - \bS_\star(x + i\gamma)}_\op\\   &\le    C_0(\sfK) \frac{1 + |A|^4+  |\gamma|^4}{\gamma^5}     \Err_{\FP}( 2A + i\gamma;n,k)  whenever Eq.~\eqref{eq:n_n_0_2} is satisfied.  So choosing $\gamma := \gamma_n \to 0$ slow enough so that Eq.~\eqref{eq:n_n_0_2} is satisfied uniformly for all $z$ with $\Im(z) \in [-2A,A]$, and $\Err_{\FP}(2A + i\gamma_n; n, k) \to 0$   as $n\to\infty$ shows that    \lim_{n\to\infty}\sup_{\hnu\in\cuP_n(\R^{k+k_0+1})}\left|     \hat I_n(\hnu)-  I_\star(\hnu)\right| = 0  on $\Omega_0 \cap \Omega_1(1)$.  So     \left|\E[\hat I_n(\hnu)] -  I_\star(\hnu)\right| \le   \E\left[\left|\hat I_n(\hnu) -  I_\star(\hnu)\right| \one_{\Omega_0 \cap \Omega_1(1)}\right]   +  2\|f\|_{\infty,A}  \left(\P\left(\Omega_0^c \right) + \P\left(  \Omega_1^c\right)\right).  Taking supremum over $\nu$ then sending $n\to\infty$ and using  Lemmas~\ref{lemma:standard_norm_bounds} and~\ref{lemma:concentration_loo_quad_form} to bound the probability along with \eqref{eq:hatI_diff_Istar} gives the result.",2502.01953
proof,"%On $\Omega_0\cap\Omega_1(L)$, we have by Lemma~\ref{lemma:rate_matrix_ST}, for $z \in\bbH_+$, % %   |s_n(z) - s_\star(z)| \le \norm{\bS_n(z) - \bS_\star(z)}_\op \le %   C_0(\sfK) \frac{\left(1 + |z|\right)^4}{\Im(z)^5}  %   \omega_{\textrm{FP}}(z,n,k,\alpha_n) % %whenever  % %     \frac{10(\sfK^2 + |z|^2)}{\Im(z)^2} %     \omega_{\textrm{FP}}(z,n,k,\alpha_n)(1 + \alpha_n\omega_{\textrm{FP}}(z,n,k,\alpha_n))  \le  \frac1{2\alpha_n}. % %Now for $z = x+ i\gamma$, $\gamma\in(0,1)$, $|x| \le 2A$, we have, % %\omega_{\textrm{FP}}(z,n,k,\alpha_n)&=C_1(\sfK) %     \left( \frac{1 + |z|^4}{\Im(z)^4} \right) %\left(  L\sqrt{\frac{k_+(d)}{n}}  %   +  \frac{1}{n \Im(z)}\right)\\ %   &\le  C_2(\sfK) \frac{|A|^4}{\gamma^4}\left(L \sqrt{\frac{k_+(d)}{n}} + \frac1{n\gamma}\right) % %as long as $A \ge 1$. % %will denote some constant that is bounded uniformly over $\alpha_n$ bounded away %%from $0$ and $\infty$, and $A,\sfK$ bounded. %So for some $C_3(\sfK) >0$ sufficiently large, when %% %%     \frac{C_3(\sfK) |A|^4}{\gamma^5}\left(L\sqrt{\frac{k_+(d)}{n}} + \frac1{n\gamma}\right)  \le  \frac1{\alpha_n},  %%  %for any $A > 1$ and $\gamma  > 0$, we have the bound % %\sup_{x \in [-2A,2A]}\left|s_n(x + i \gamma) - s_\star(x+ i\gamma)\right| \le  % \frac{C_3(\sfK)  |A|^8}{\gamma^9}\left( L\sqrt{\frac{k_+(d)}{n}} + \frac1{n\gamma}\right) % %whenever the quantity on the right is bounded by $\alpha_n^{-1}$. %Now by definition of $\mu_\star$,  for $\alpha_n >1$, there exists a constant $A_0(\sfK) > 0$ such that % %    \supp\left(\mu_\star(\nu, \alpha_n)\right) \subseteq [-A_0(\sfK),A_0(\sfK)]. % %Furthermore, on the event $\Omega_0$ of Lemma~\ref{lemma:standard_norm_bounds}, we have the bound %(for a similarly bounded constant $A_1$) % %    \frac1n\norm{\bH}_\op  %    %\le C \sfK  \left( 1 + \alpha_n^{-1}\right)  %    \le A_1(\sfK). %     %%for some universal $C>0.$ %% %Taking  $A(\sfK) := A_1(\sfK) \vee A_0(\sfK)$, %we have by Lemma~\ref{lemma:f_bound_st} that  %for any $\gamma \in (0,1)$, %%\am{The formula below does not match Corollary~\ref{cor:f_bound_st}. RHS is nonlinear in $f$!} % %\left| %    \int f(\lambda) \de \mu_n(\lambda) - \int f(\lambda) \de \mu_\star(\lambda) %\right| %&\le C_4(\sfK) %\bigg( %\norm{f}_{\infty,A(\sfK)} % \sup_{x \in [-2A(\sfK),2A(\sfK)]}\left|s_n(x + i \gamma) - s_\star(x+ i\gamma)\right| % \\ %&\quad\quad\quad+\gamma \left(\norm{f}_{\Lip}  + \norm{f}_{\infty,A(\sfK)}  \right)  \bigg) %\\ %&\le C_5(\sfK) %\norm{f}_{\infty,A(\sfK)} %\frac{1}{\gamma^9}\left(L\sqrt{\frac{k_+(d)}{n}} + \frac{1}{n \gamma}\right) %+  %\gamma( \norm{f}_{\Lip} + \norm{f}_{\infty,A(\sfK)} ) % %whenever this quantity is bounded by $\alpha_n^{-1}$. % %Now note that $\lambda \mapsto \log(\lambda \vee \eps)$ has a Lipschitz constant equal to $\eps^{-1}$, and recalling the bounds on $\P(\Omega_0^c)$ and $\P(\Omega_1(L)^c)$ for $L\ge1$, we obtain % %&\left|\E\left[\int \log(\lambda\vee \eps) \mu_n(\de \lambda)\right] - k \int \log(\lambda\vee \eps)  \mu_\star(\widehat\nu_{\tilde\bV}) (\de \lambda) \right| %\le \E\left[\left|\int \log(\lambda\vee \eps) \mu_n(\de \lambda) - k \int \log(\lambda\vee \eps)  \mu_\star(\widehat\nu_{\tilde\bV}) (\de \lambda) \right|\right]\\ %&\quad\quad\le  %C(\sfK) %\|{\log^\up{\eps}}\|_{\infty,A(\sfK)} %\frac{k}{\gamma^9}\left(L\sqrt{\frac{k_+(d)}{n}} + \frac{1}{n \gamma}\right) %+  % k\gamma( \|\log^\up{\eps}\|_{\Lip} + \|{\log^\up{\eps}}\|_{\infty,A(\sfK)} )  % + k \log(A(\sfK)) (\P\left(\Omega_0^c\right) + \P(\Omega_1^c(L)))\\ % &\quad\quad\le C_1(\sfK)\left( \frac{k}{\gamma^9} \left(L \sqrt{\frac{k_+(d)}{n}} + \frac1{n\gamma}\right) + \frac{k\gamma }{\eps}   % + k \left( e^{-c_1d } + e^{- c_2 L k} \vee d^{-c_2 L }\right)\right). % %%Observe that whenever $k/(\gamma^{9} \sqrt{n}) <1$, we have $k/(n\gamma^{10}) <1$.  %With the choice  % %    L \equiv L(d) := %        \frac1{c_2} \vee 1& k \ge \log(d)\\  %        \frac1{c_2}\log(d)  \vee 1& k < \log(d), %     % %we have for $d > 1/{c_1}$, % %    k \left( e^{-c_1d } + e^{- c_2 L k} \vee d^{-c_2 L }\right) \le \frac{k}{d}. % %This concludes the bound. % %",2502.01953
proof,"The second bound is immediate since $\rho$ is a density.  To show the first, fix $x_0\in[-B,B]$. We have          \nonumber         \Delta_{ f,B,\gamma}(x_0) =&  f(x_0)\int_{-\infty}^\infty\rho(x;x_0,\gamma)\de x         -\int_{-B}^B  f(x) \rho(x;x_0,\gamma)\de x\\         \nonumber         =&\int_{-B}^B \left(f(x_0)-f(x) \right) \rho(x;x_0,\gamma)\de x +  f(x_0)\left(1-\int_{-B}^{B} \rho(x;x_0,\gamma)\de x\right)\\         \leq & \norm{f}_{\Lip}\left(\int_{-B}^B |x_0-x|\rho(x;x_0,\gamma)\de x\right)         +\norm{f}_\infty\left(1-\int_{-B}^B \rho(x;x_0,\gamma)\de x_0\right).                   By a change of variable, the first integral above can be bounded as              \int_{-B}^B |x_0-x|\rho(x;x_0,\gamma)\de x =          \int_{-B-x_0}^{B-x_0} |x|\rho(x;0,\gamma)\de x         \leq& \frac{2}{\pi}\int_{0}^{2B} x \frac{\gamma}{x^2+\gamma^2}\de x         = \frac{\gamma}{\pi}\log\left(\frac{4B^2}{\gamma^2} + 1\right)      where we used the even symmetry of the integrand and that $|x_0 | \le B$ to deduce the inequality. %\bns{This can be strengthened if necessary by bounding by $A$ instead but probably not needed.} Meanwhile, the second integral in Eq.~\eqref{eq:last_eq_in_DeltafB_bound} is bounded as              1-\int_{-B}^B \rho(x;x_0,v)\de x         %\le  1 - \int_{0}^{2B} \rho(x;0,\gamma) \de x         &= 1- \frac{1}{\pi }\left[\arctan \left( \frac{B-x_0}{\gamma}\right) - \arctan \left( \frac{-B-x_0}{\gamma}\right)\right]\\         &\le  1- \frac{1}{\pi }\left[\arctan \left( \frac{B-A}{\gamma}\right) + \arctan \left( \frac{B+A}{\gamma}\right)\right]\\         &\le         \frac12 \left( \frac{\gamma}{B-A}  + \frac{\gamma}{B+A}\right),         where in the last line we used that $1 -2\pi^{-1}\arctan(t) \le t^{-1}$. This concludes the proof.",2502.01953
proof,"Rewriting $f$ in terms of the quantity $\Delta_{f,B,\gamma}$ defined in Lemma~\ref{lemma:quant_dirac_integral}, we have  \nonumber     \int f(x_0) \left(\de \mu_1(x_0) - \de \mu_2(x_0)\right)      &= \int\left( \int_{-B}^B f(x) \rho(x;x_0, \gamma) \de x  + \Delta_{f,B,\gamma}(x_0) \right)       \left(\de \mu_1(x_0) - \de \mu_2(x_0)\right) \\      \nonumber     &=       \int_{-B}^B f(x)\left(\int  \rho(x;x_0, \gamma)       \left(\de \mu_1(x_0) - \de \mu_2(x_0)\right) \right)\de x\\      &\quad\quad+ \int \Delta_{f,B,\gamma}(x_0)     \left(\de \mu_1(x_0) - \de \mu_2(x_0)\right)        where the change of order of integration is justified by integrability of the continuous $f$ over $[-B,B]$. Noting that for $j\in\{1,2\}$,  \nonumber      \int \rho(x;x_0,\gamma) \de \mu_j(x_0)=      \frac1{\pi}\Im(s_j(x+i\gamma)),  %\am{I actually get (using the Wikipedia convention for ST): % %     \int \rho(x;x_0,\gamma) \de \mu_j(x_0)= %     \frac1{\pi}\Im(s_j(x+i\gamma)), % %Please double check and propagate below %} the first term in Eq.~\eqref{eq:decomp_Ex_diff} is bounded as  \nonumber      \int_{-B}^B f(x)\left(\int  \rho(x;x_0, \gamma)       \left(\de \mu_1(x_0) - \de \mu_2(x_0)\right) \right)\de x       &=      \frac1\pi\int_{-B}^B f(x) \left(     \Im\left(s_1(x + i \gamma) - s_2(x+ i\gamma)\right)      \right)      \de x\\      &\le \frac1\pi \norm{f}_\infty \int_{-B}^B \left|s_1(x + i \gamma) - s_2(x+ i\gamma)\right| \de x.         To bound the second term in Eq.~\eqref{eq:decomp_Ex_diff},  for each $j\in\{1,2\}$ we have     \int \Delta_{f,B,\gamma}(x_0) \de \mu_j(x_0)      &\le  \int_{-A}^A \left|\Delta_{f,B,\gamma}(x_0)\right| \de \mu_j(x_0)+ \int_{\R\setminus[-A,A]} \left|\Delta_{f,B,\gamma}(x_0) \right|\de \mu_j(x_0)\\    &\le   \sup_{x_0 \in [-A,A]} \left|\Delta_{f,B,\gamma}(x_0)\right|         +         \sup_{x_0 \in \R\setminus [-A,A]} \left|\Delta_{f,B,\gamma}(x_0)\right| \cdot         \mu_j\left(\R \setminus [-A,A]\right).   Applying Lemma~\ref{lemma:quant_dirac_integral} and combining with Eq.~\eqref{eq:decomp_Ex_diff} and Eq.~\eqref{eq:decom_Ex_diff_bound_1} gives the desired bound.",2502.01953
proposition,"% %Under Assumption~\ref{ass:regime},~\ref{ass:loss},~\ref{ass:regularizer} and~\ref{ass:sets}, we have %  for any Lipschitz function $f:\R\to\R$, %   %  \lim_{\substack{n\to\infty\\n/d \to \alpha}} %  \sup_{(\bbV,\bTheta)\in\cM(\cuA,\cuB)}\left|\frac1{dk}\E\left[\Tr \,f\left(\frac1n\bH(\bbV) + \grad^2\rho(\bTheta) \right)\right] %      - \int f(\lambda) \mu_\star(\hnu_\bbV,\hmu_\bTheta)(\de \lambda) %      \right| = 0. %   %",2502.01953
proposition,"%For $z \in \mathbb{H}_+$, let $\bS_\star \in\bbH_+^k$ be the unique solution to % % %\bS = \frac1{\alpha_n}\bF_z(\bS). % %Then  %    \norm{\bS_n - \bS_\star}_{2} \le \dots % %with probability $\dots$. %",2502.01953
proposition,"% %For any $z\in \bbH^+$, the equation $\alpha\bS = \bF_z(\bS)$ has a unique solution $\bS_\star$ in $\bbH_k^+$. %",2502.01953
lemma,"[Properties of $\Re$ and $\Im$.]  Let $\bZ \in\bbH^+_k$. Then,  \item  $\bZ$ is invertible,      \Im(\bZ^{-1}) = - \bZ^{-1} \Im(\bZ) \bZ^{*-1}\prec\bzero, \quad\quad \|\bZ^{-1}\|_\op \le \|\Im(\bZ)^{-1}\|_\op, \quad\textrm{and}\quad \norm{\Im(\bZ)}_\op \le \norm{\bZ}_\op.   \item For any $\bW$ self-adjoint, we have      \Im((\bI+\bW \bZ)^{-1}\bW ) &= -((\bI + \bW \bZ)^{-1}\bW)\Im(\bZ)((\bI + \bW \bZ)^{-1}\bW)^*,  and     \norm{(\bI + \bW\bZ)^{-1}\bW}_\op &\le \norm{\Im(\bZ)^{-1}}_\op.",2502.01953
lemma,"[Properties of $(\bI\otimes\Tr)$]   Let $\bM \in\C^{dk\times dk}$. Then the following hold. [(1.)]     \item We have the bounds      \norm{(\bI_k \otimes \Tr)\bM}_{\Fnorm} \le  \sqrt{d}\norm{\bM}_\Fnorm     \quad\textrm{and}\quad     \norm{(\bI_k \otimes \Tr)\bM}_\op \le  d\norm{\bM}_\op.  \item If $\bM^*  =\bM  \succ  \bzero$, then $(\bI_k \otimes \Tr)\bM \succ\bzero.$ The same statement holds if we replace both strict relations  $(\succ)$ with non-strict ones $(\succeq)$. \item If $\bM^* = \bM \succeq \bzero$, then      \lambda_{\min}\left( (\bI_k \otimes \Tr)\bM \right) \ge d \lambda_{\min}(\bM).  \item We have     \Im\left(    (\bI_k \otimes \Tr) \bM    \right) =  (\bI_k \otimes \Tr) \Im(\bM).",2502.01953
lemma,"[Woodbury and algebraic identities]      For all $i\in[n]$ and $z\in\bbH_+$, we have               \left(\bI_k \otimes \Tr\right)\bxi_i \bW_i \bxi_i^\sT \bR(z)  =  \left( \bI_k + \bW_i \bxi_i^\sT \bR_i(z) \bxi_i\right)^{-1}         \bW_i\bxi_i^\sT \bR_i(z)\bxi_i,      and       \left(\bI_k \otimes \Tr\right) \left(\bR_i(z)-  \bR(z)\right)  =  \bxi_i^\sT \bR_i(z) (\bW_i \otimes \bI_d) \bR(z)\bxi_i.   %   and %    % %      (\bI \otimes \Tr)\left(\bM_i^{-1} \bz_i (\bI_k + \widetilde \bz_i^\sT \bM_i^{-1}\bz_i)^{-1}\widetilde \bz_i^{\sT}\bM_i^{-1} \right)=  %     \bz_i^\sT \bM_i^{-1} (\grad^2 \rho_i \otimes \bI_k) \bM^{-1} \bz_i. %",2502.01953
lemma,"[Deterministic norm bounds]  For all $i\in[n]$ and $z\in\bbH_+$, we have,         \norm{\bR(z)}_\Fnorm^2 \vee \norm{\bR_i(z)}_\Fnorm^2 \le \frac{dk}{n^2} \frac{1}{\Im(z)^2},      \quad   \norm{\bR(z)}_\op \vee\norm{\bR_i(z)}_\op  \le  \frac{1}{n} \frac1{\Im(z)},   \quad   \norm{\bSec}_\op \le \sfK,    \quad    \norm{\bH}_\op \le \sfK \norm{\bX}_\op^2.  Further, for $z \in\bbH_+$, we have       \|\Im((\bI_k\otimes\Tr)\bR(z))^{-1}\|_\op      %\le  \frac1{\Im(z)}\frac{1}{\sigma_{\min}((\bH - z\bI)^{-1})^2}      \le   \frac{1}{\Im(z)} \left(\frac{1}{n}\norm{\bH}_\op  + |z|\right)^2  and       \|\Im(\bxi_i^\sT\bR_i(z)\bxi_i)^{-1}\|_\op \le \frac{n}{\norm{\bx_i}_2^2} \frac{1}{\Im(z)} \left(\frac{1}{n}\norm{\bH_i}_\op  + |z|\right)^2.  % %    \norm{\widetilde \bz_i^\sT \bM_i^{-1} \bz_i} = O(1),  %\norm{\grad^2 \rho_i (\bI\otimes \Tr) \bM_i^{-1}} = O(1)\\ %    \norm{(\bI+\widetilde \bz_i^\sT \bM_i^{-1} \bz_i)^{-1}} = O(1),  %\norm{(\bI+\grad^2 \rho_i (\bI\otimes \Tr) \bM_i^{-1})^{-1}} = O(1).\\ %",2502.01953
lemma,"[Operator norm bounds for Gaussian matrices \cite{BaiSilverstein}]   Let  $$\Omega_0 := \{\norm{\bX}_\op \le 2 d^{1/2}(1 + \sqrt{\alpha_n})),\; \norm{\bx_i}_2 \in [d^{1/2}/{2}, 2d^{1/2}] \quad\textrm{for all}\quad i\in[n]\}.$$ Then       \P(\Omega_0^c ) \le C \exp\{- c d\}  for some universal $C,c>0$.",2502.01953
lemma,"% %Let $\bx \sim \cN(0,\bI_d), \bxi := (\bI_k \otimes \bx)$. %   Let $\bM \in\C^{dk\times {dk}}$ be independent of $\bx$. Then for any $t>0$,  % %    \P\left(\norm{\bxi^\sT \bM  \bxi -  (\bI_k \otimes \Tr)\bM}_F \ge t \right) \le %    2 k^2\exp\left\{ -\frac{c t^2 }{k^2 \norm{\bM}_F^2 + k t \norm{\bM}_\op}  \right\} % %where $c>0$ is some universal constant. %",2502.01953
lemma,"Let $\bx \sim \normal(\bzero,\bI_d), \bxi := (\bI_k \otimes \bx)$.    Let $\bM \in\C^{dk\times {dk}}$ be independent of $\bx$, and     set $k_+(d):= k\vee \log d$. Then,    for any $L\ge 1$, we have      \norm{\bxi^\sT \bM  \bxi -  (\bI_k \otimes \Tr)\bM}_\op \le      C L \left( k_+(d)^{1/2} d^{1/2} \norm{\bM}_\op \vee k_+(d) \norm{\bM}_\op \right)  with probability at least      1 - 2\min\Big(e^{-cLk}, d^{-cL}\Big)\,  where $C,c > 0$ are universal constants.",2502.01953
lemma,"[Concentration of the leave-one-out quadratic forms]  There exist absolute constant $c,C$, such that the following holds. Let $k_+(d):= k\vee \log d$ and define the event (for $L\ge 1$)      \Omega_1(L) := \left\{\norm{\bxi_i^\sT \bR_i \bxi_i - (\bI_k \otimes \Tr)\bR}_\op    \le  C L\sqrt{\frac{k_+(d)}{n \alpha_n}} \frac1{\Im(z)}     +  \frac{\sfK\norm{\bx_i}_2^2}{n^2 \Im(z)^2}\quad\textrm{for all}\quad i\in[n]\right\}.  Then for  $n\ge \alpha_n k_+(d)$, $n\le d^{10}$ we have for some universal constant $c>0$.  \nonumber     \P(\Omega_1(L)^c) \le 2 (e^{- cLk}\vee d^{-cL}).",2502.01953
lemma,"[Fixed point equation for the Stieltjis transform]  Let $\Omega_0,\Omega_1(L)$ be the events of Lemmas~\ref{lemma:standard_norm_bounds} and~\ref{lemma:concentration_loo_quad_form} respectively. For any empirical distribution $\hnu\in\cuP(\R^{k+k_0+1}),$ $z \in\bbH_+$, $L\ge 1$, we have on $\Omega_0 \cap \Omega_1(L)$,      \norm{ \frac1{\alpha_n}\bI_k - \bF_z(\bS_n(z);\hnu)^{-1} \bS_n(z)     }_\op &\le    \Err_{\FP}(z; n,k)  where, letting $k_+(d) = k\vee \log d$,  \Err_{\FP}(z;n,k) :=  C(\sfK) \frac{(1+|z|^4)}{\Im(z)^4}  \left( L\sqrt{\frac{ k_+(d) }{n}}      +  \frac{1}{ n \Im(z)}\right) %\omega_{\textrm{FP}}(z,n,k,\alpha_n):=C(\sfD)(\alpha_n+\alpha_n^{-1}) %     \left( \frac{1 + |z|^2}{\Im(z)} \right) %    \left( \frac{1 + |z|^2}{\Im(z)} %    + 1\right) %\left(  L\sqrt{\frac{k_+(d)}{n}}\frac1{\Im(z)}  %   +  \frac{1}{n \Im(z)^2}\right).  for some $C(\sfK)>0$ depending only on $\sfK$. %with probability at least % %% 1 - 2 nk^2 \exp\left\{-ck\right\} - C n \exp\left\{ -c d\right\}. %",2502.01953
lemma,"[Concentration of the leave-one-out quadratic forms] % %For all $i\in[n]$ and $t>0$, we have % % %   \P\left( \norm{\bxi_i^\sT \bR_i \bxi_i - (\bI_k \otimes \Tr)\bR_i }_F  \ge  t \right) \le  %2 k^2   %      \exp\left\{ - \frac{c \Im(z)\, t^2 \, n}{ % \frac{dk^3}{ n \Im(z)} %  +  tk  %}\right\} % %for some universal constant $c >0$. %Consequently, for any $s>0$, we have % % %   \norm{\bxi_i^\sT \bR_i \bxi_i - (\bI_k \otimes \Tr)\bR}_F %   \le \frac{k^{3/2+s}}{\sqrt{n}}\frac1{\Im(z)} +  \frac{\sfK\norm{\bx_i}_2^2}{\alpha_n n^2 \Im(z)^2} % %with probability at least % %    1 - 2 k^2\exp\left\{ -  \frac{ c k^{3+2s} \alpha_n }{ k^3 + k^{5/2+s} \alpha_n^{1/2}d^{-1/2} }\right\}. %- C \exp\left\{ - cd\right\}. % %",2502.01953
lemma,"[High probability norm bounds] % %For all $i \in[n]$, we have,  % % \norm{ %   (\bI_k \otimes \Tr) %\bM_i^{-1}\bz_i %\left(\bI_k + \widetilde\bz_i^\sT \bM_{i}^{-1} \bz_i\right)^{-1} \widetilde\bz_i^\sT \bM_i^{-1}  %}_F \le  %\frac{ 2\sqrt{n d k } \sfK}{n^2 \Im(z)^2} % %with probability at least  % %      1 -  2k^2 \exp\left\{-  \frac{c n\sqrt{d}  }{ \sqrt{d} k^{3/2}  +  \sqrt{n k} }\right\} % %for some universal constant $c>0$. %",2502.01953
lemma,"[Asymptotic solution of the fixed point equation]  Fix $\nu_0\in\cuP(\R^{k+k_0+1})$. Assume $\|\grad^2 \rho(\bv,\bu,w)\|_{\op}\le \sfK$ with  probability one under $\nu_0$. For any fixed positive integer $k$, $z\in \bbH_+$,   and $\alpha_0 >1$, we have              \alpha_0 \bS_\star(z; \alpha_0, \nu_0) =          \bF_z(\bS_\star(z; \alpha_0, \nu_0);\nu_0).",2502.01953
lemma,"For any $z\in\bbH_+$, $\nu_0\in\cuP(\R^{k+k_0+1})$ and $\alpha_0 >1$, we have  \nonumber     \norm{\Im(\bS_\star(z; \alpha_0, \nu_0))^{-1}}_\op \le \frac1{\Im(z)} \left(\sfK (1+ \alpha_0^{-1/2})^2 + |z|\right)^2.",2502.01953
lemma,"%Fix $z \in \bbH_+$. Then for all $R\ge R(z)$, $r < r(z)$, the image of $\cH(R,r)$ under $\alpha^{-1}\bF_z$ lies strictly inside $\cH(R,r)$. %",2502.01953
lemma,"%The map $\boldeta$ is well-defined and holomorphic on $\bbH_k^-$. Furthermore, $\Im(\boldeta(\bQ))\preceq\bzero$ for $\bQ\in\bbH_k^{-}$. %",2502.01953
lemma,"%For any $\bM \in\C^{k\times k}$ and any integer $p>0$, we have % %    \norm{\bT^p(\bM)}_F^2&\le  %    \alpha^{2p}  %    \norm{\bM}_F^2  %\left(\norm{\E\left[\bB^{-1/2} \bF \bG \bB\bG^* \bF^*\bB^{-1/2}\right]}_\op^{2p-1} %\norm{\bB}_\op %\norm{\bB^{-1/2}\bF^* \bF \bB^{-1/2}}_\op %\norm{ %\E[ \bG^* %\bB\bG]}_\op %\norm{\bB_n^{-1}}_\op\right)^{1/2} %\nonumber\\ %& %    \quad\left(\norm{\E\left[\bB_n^{-1/2} \bF_n \bG_n \bB_n\bG_n^* \bF_n^*\bB_n^{-1/2}\right]}_\op^{2p-1} %\norm{\bB_n}_\op %\norm{\bB_n^{-1/2}\bF_n^* \bF_n \bB_n^{-1/2}}_\op %\norm{ %\E[ \bG_n^* %\bB_n\bG_n]}_\op %\norm{\bB^{-1}}_\op\right)^{1/2} % %where  %$\bT^p(\bA) := \bT(\bT^{p-1}(\bA))$ %and % %\bF_n := \bF_z(\bS_n),\quad \bF:=\bF_z(\bS_\star),\quad \bG_n \equiv\bG_n(\bSec) :=  \bG(\bS_n, \bSec),\quad \bG \equiv \bG(\bSec) := \bG(\bS_\star,\bSec). % %",2502.01953
lemma,"%    We have the bounds %     %\norm{\E\left[\bB^{-1/2} \bF \bG \bB\bG^* \bF^*\bB^{-1/2}\right]}_\op \le  %1 -\frac{\alpha \Im(z)}{2} \lambda_{\min}(\bB^{-1/2} \bS_\star \bS_\star^* \bB^{-1/2}), %\quad %\norm{\E[ \bG^* %\bB\bG]}_\op \le %    \norm{\bS_\star^{-1}\bB\bS_\star^{*-1}}_\op. %     %and  %     %\frac1\alpha\norm{\E\left[\bB_n^{-1/2} \bF_n \bG_n \bB_n\bG_n^* \bF_n^*\bB_n^{-1/2}\right]}_\op  %    \le \bI -  \frac{\Im(z)}{\alpha}\lambda_{\min} \left(\bB_n^{-1/2} \bF_n\bF_n^* \bB_n^{-1/2}\right)  %,\quad %\norm{\E[ \bG_n^* %\bB_n\bG_n]}_\op \le \norm{\Im(\bF_n^{-1})}_\op %     %with probability % %\dots % %for $n> n_0(z)$ where .. %",2502.01953
lemma,"Fix $\bS\in\C^{k\times k}$ with $\Im(\bS)\succeq \bzero,$ $\Im(z) \ge 0,\alpha >1$, and $\nu\in\cuP(\R^{k+k_0+1})$ such that $\bT_\bS(\;\cdot\;, z,\alpha,\nu)$ of Eq.~\eqref{eq:def_T} is defined. We have for any $\bB,\bB_\star \succ \bzero$, and integer $p>0$, we have      \norm{\bT_\bS^p}_{\op \to\op}&\le      \left(  \norm{\E[\bB^{-1/2} \bF\bfeta \bB\bfeta^* \bF^* \bB^{-1/2}]}_\op^p \norm{\bB^{-1}}_\op \norm{\bB}_\op \right)^{1/2} \nonumber \\ &\hspace{5cm}\left(  \norm{\E[\bB_\star^{-1/2} \bF_\star\bfeta_\star \bB_\star\bfeta_\star^* \bF_\star^* \bB_\star^{-1/2}]}_\op^{p} \norm{\bB_\star^{-1}}_\op \norm{\bB_\star}_\op \right)^{1/2}, \nonumber  where $\bS_\star$ is as defined in Eq.~\eqref{eq:def_T} and   \bF_\star := \bF_z(\bS_\star;\nu),\quad \bF:=\bF_z(\bS;\nu),\quad \bfeta_\star  :=\bfeta(\bS_\star, \bW),\quad \bfeta := \bfeta(\bS,\bW). %,\quad\bB := \Im(\bS),\quad\bB_\star:=\Im(\bS_\star).",2502.01953
lemma,"Fix $z \in\bbH_+$, $\hnu \in \cuP_n(\R^{k+k_0+1})$. Let $\bS_0$ be any solution of $\alpha_n \bS = \bF_z(\bS;\hnu)$ in    $\bbH_+^k$, and let $\bS_n(z;\hnu)$ be the quantity defined in Eq.~\eqref{eq:Sn_def}. Use the notation  \bF_0 := \bF_z(\bS_0;\hnu),\quad \bF_n:=\bF_z(\bS_n;\hnu),\quad \bfeta_0  :=\bfeta(\bS_0, \bW),\quad \bfeta_n := \bfeta(\bS_n,\bW),\quad\bB_n := \Im(\bS_n),\quad\bB_0:=\Im(\bS_0),  where $\bW\sim \grad^2\ell_{\# \hnu}$. Then we have the bound          \nonumber \frac1\alpha_n\norm{\E\left[\bB_0^{-1/2} \bF_0 \bfeta_0 \bB_0\bfeta_0^* \bF_0^*\bB_0^{-1/2}\right]}_\op \le  1 -\frac{\alpha_n \Im(z)}{2} \lambda_{\min}(\bB_0^{-1/2} \bS_0 \bS_0^* \bB_0^{-1/2}).           Further, if         \frac{10(\sfK^2 + |z|^2)}{\Im(z)^2}\Err_{\FP}(z;n,k)(1 + \alpha_n\Err_{\FP}(z;n,k))  \le  \frac12   then the following holds, for any $L\ge 1$, on the event $\Omega_0\cap\Omega_1(L)$  of  Lemmas \ref{lemma:standard_norm_bounds}, \ref{lemma:concentration_loo_quad_form}      \frac1\alpha_n\norm{\E\left[\bB_n^{-1/2} \bF_n \bfeta_n \bB_n\bfeta_n^* \bF_n^*\bB_n^{-1/2}\right]}_\op      \le 1 -  \frac{\Im(z)}{2\alpha_n}\lambda_{\min} \left(\bB_n^{-1/2} \bF_n\bF_n^* \bB_n^{-1/2}\right)\, .",2502.01953
lemma,"For any $z\in\bbH_+$, $\alpha_0 >1$, $\nu\in\cuP(\R^{k+k_0+1})$, the solution $\bS_\star(z;\alpha_0,\nu)$ of Eq.~\eqref{eq:def_S_star} is the unique solution to $\alpha_0 \bS = \bF_z(\bS;\nu)$ on $\bbH_+^k$.",2502.01953
lemma,"Whenever        \frac{10(\sfK^2 + |z|^2)}{\Im(z)^2}\Err_{\FP}(z;n,k)(1 + \alpha_n\Err_{\FP}(z;n,k))  \le  \frac1{2\alpha_n},   we have   \nonumber     \sup_{\hnu \in\cuP_n(\R^{k+k_0+1})}\norm{\bS_\star(z;\alpha_n, \hnu) -\bS_n(z;\hnu)}_\op \le C(\sfK)     %(\alpha_n+\alpha_n^{-1})^2     \frac{1 + |z|^4}{\Im(z)^5}  \Err_{\FP}(z; n, k)  on the event $\Omega_0 \cap\Omega_1(L)$ of Lemmas \ref{lemma:standard_norm_bounds}, \ref{lemma:concentration_loo_quad_form}, for $L\ge 1$.",2502.01953
lemma,"Let $f:\R\to\R$ be continuous. Let $\mu_1,\mu_2$ be two probability measures on $\R$ with support in $[-A,A]$, let $s_1,s_2$ denote their Stieltjes transforms, respectively. Then for any $\gamma \in (0,1)$, we have               \bigg|\int f(x_0)\de\mu_1(x_0) - \int f(x_0)\de\mu_2(x_0)\bigg| &\le         \frac1\pi \norm{f}_{\infty,A} \int_{-2A}^{2A} \Big|s_1(x+i\gamma)-s_2(x+i\gamma)\Big|\de x\\ &+ \gamma\left( 2\norm{f}_{\Lip,A} \log(16 A^2+ 1)         + \frac{2 \norm{f}_{\infty,A}}{A}\right),       where $\norm{f}_{\Lip,A}$ and $\norm{f}_{\infty,A}$ are the Lipschitz constant and $\ell_\infty$ norm, respectively, of the function  $$x \mapsto f(-A)\one_{\{x < -A\}} + f(x)\one_{\{x\in[-A,A]\}} +  f(A)\one_{\{x > A\}}.$$",2502.01953
lemma,"% %There exist a constant $A_0(\alpha_n,\sfK) > 0$ depending only on $\alpha_n$ and $\sfK$ such that % %    \supp\left(\mu_\star(\nu, \alpha_n)\right) \subseteq [-A_0,A_0]. % %",2502.01953
lemma,"For any Lipschitz function $f:\R\to\R$, we have  \nonumber     \limsup_{n\to\infty} \sup_{\hnu\in\cuP_n(\bR^{k+k_0+1})}      \left|     \frac1{dk} \E\left[\Tr\;f \left(\frac1n \bH(\hnu)\right)\right] - \int f(\lambda) \mu_{\MP}(\hnu,\alpha_n)(\de\lambda)\right| = 0.",2502.01953
lemma,"% %Let $\mu_\star = \mu_\star(\widehat\nu_{\bV,\bU,\bw},\alpha_n)$ %and  %$\mu_n = \mu_n(\widehat\nu_{\bV,\bU,\bw},\alpha_n)$. %   For a Lipschitz function $f:\R\to\R$,  % define  %  % \omega_{\textrm{BL}}(n,d,k, f;\gamma) :=  %C(\sfK) %\norm{f}_{\infty,A(\sfK)} %\frac{k}{\gamma^9}\left(L\sqrt{\frac{k_+(d)}{n}} + \frac{1}{n \gamma}\right) %+  % k\gamma( \norm{f}_{\Lip} + \norm{f}_{\infty,A(\sfK)} ) %  % where $A(\sfK)>0$ is a constant depending only on $\sfK$. %For any $\gamma\in(0,1)$, if %$\omega_{\textrm{BL}}(n,d,k; f,\gamma) < \alpha_n^{-1}$,  %  we have on the event $\Omega_0\cap\Omega_1(L)$ defined in %   Lemmas \ref{lemma:standard_norm_bounds}, %\ref{lemma:concentration_loo_quad_form}, %    % k \left| %    \int f(\lambda) \de \mu_n(\lambda) - \int f(\lambda) \de \mu_\star(\lambda) %\right| %\le  %\omega_{\textrm{BL}}(n,d,k; f,\gamma). %    %Consequently,  %there exists universal constant $c>0$ such that if $d > c$, we have for any $\eps > 0$, % % k \left| % \E\left[\int \log(\lambda \vee \eps) \mu_n(\de \lambda)\right]- \int \log(\lambda \vee \eps) \mu_\star(\de\lambda) %\right| \le   %\omega_{\LP}(n,d,k; \gamma, \eps) % %as long as $\omega_{\LP} < \alpha_n^{-1}$,  %where % %\omega_{\LP}(n,d,k; \eps):= %\inf_{\gamma\in(0,1)} %C(\sfK) \left(\frac{k}{\gamma^9} \left(L \sqrt{\frac{k_+(d)}{n}} + \frac1{n\gamma}\right) + \frac{k\gamma }{\eps}  \right) +  \frac{k}{d}. % %",2502.01953
lemma,"Fix positive reals $B > A > 0$. Define for $x_0 \in\R$,      \Delta_{f,B,\gamma}(x_0):= f(x_0) - \int_{-B}^B  f(x)\rho(x;x_0,\gamma)\, \de x.  We have the bounds  \nonumber         \sup_{x_0 \in [-A,A]}\left|\Delta_{ f,B,\gamma}(x_0)\right|\leq \norm{f}_{\Lip} \gamma\log(4B^2+\gamma^2)         +\norm{f}_\infty \frac{\gamma}{2} \left(\frac1{B-A} + \frac1{B+A}\right)  and  \nonumber     \sup_{x_0 \in \R \setminus [-A,A]}\left|\Delta_{ f,B,\gamma}(x_0)\right|     \leq      2\norm{f}_\infty.",2502.01953
lemma,"Let $f:\R\to\R$ be continuous. Let $\mu_1,\mu_2$ be two probability measures on $\R$ and let $s_1,s_2$ denote their corresponding Stieltjes transforms, respectively. Then for any positive reals $B > A \ge 0$ and $\gamma  > 0$, we have               \bigg|\int f(x_0)\de\mu_1(x_0) - \int f(x_0)\de\mu_2(x_0)\bigg| &\le         \frac1\pi \norm{f}_\infty \int_{-B}^B \Big|s_1(x+i\gamma)-s_2(x+i\gamma)\Big|\de x\\ &+2\norm{f}_{\Lip} \gamma\log(4B^2+\gamma^2)         +\norm{f}_\infty \gamma \left(\frac1{B-A} + \frac1{B+A}\right)\\ &+2 \norm{f}_\infty \big(\mu_1\left(\R \setminus [-A,A]\right) + \mu_2\left(\R \setminus [-A,A]\right)\big).",2502.01953
theorem,        $6$ .,2502.01958
theorem,"        $6$ ,         $1$  ,     ,       $3$.",2502.01958
theorem,"%	      $6$ ,              $1$       $3$. %",2502.01958
theorem,"    $6$ ,     \ref{l0.1},      $3$.",2502.01958
theorem,"     $6$ ,       $6$ ,     $100$  ,       .",2502.01958
theorem,"  $O$  ,                       $O$    $1$,       $1$   $O$     $1, 2, 3$ ,     ,   ---  ,    $O$.",2502.01958
theorem,"   $3$   $6$  ,      ,     $1$,       $4$   ,       ,            $1$  $2$   ,        $2$   .",2502.01958
theorem,"   $6$ ,       ,      $1$,         ,        $(1, 2)$              .",2502.01958
lemma,"   $u$  $v$       $uv$,      ,     $1$       $1$  .",2502.01958
lemma,"   $u$  $v$      ,    $z$,   $\|z-u\|<1$, $\|z-v\|>1$,         .",2502.01958
lemma,"   ,      $1$         .",2502.01958
lemma,"  $A$  $B$    $1$      $A$     $1$    $C$  $D$,    $B$  $C$  $1$,   $D$  $1$ (   $A$      ),  $B$    $1$   .",2502.01958
lemma,          $1$.,2502.01958
lemma," $\omega$ ---   $1$    $O$,  $A$  $B$   $\omega$   $1$   ,    $A$,   $B$    $\omega$    $1$,   ---   $2$.            $1$.    $\omega$,   $\omega$   $A$  $B$   ,   $1$  $2$.",2502.01958
lemma,"      $A, O, B$ ,             $OA$  $OB$    $1$,     $C$  $D$   $OA$  $OB$ ,    ,       $COD$   $1$.",2502.01958
lemma,"    ,  $O$ ---  ,       ,      $O$ ,      ,   ,   $O$    ,       ,  .",2502.01958
lemma,"    $O$.  $\alpha$ ---            $OA_{45}, OA_{46}, OA_{56}$.         $1$  $\delta \cos \alpha + \sqrt{1 - \delta^2 \sin^2\alpha}$  $O$    $1, 2, 3$.",2502.01958
lemma,  $\omega$       $\omega$.,2502.01958
lemma,"   $1$     ,        ,       ,         ,          ,    .",2502.01958
lemma,"     ,     $6$    $\frac{\pi}{3}$,      $3$     ,      $1$.",2502.01958
lemma," $\omega$      $A, B, C$ ,    $B$   $\omega$      \ref{t3},  $B$    $1$  $A$  $C$    $\{1, 2\}$,   $A$   $B$    $1$,   $C$   $B$ ---   $2$.",2502.01958
lemma," $\omega$        $A_1, \ldots, A_6$,       ,  $A_1$  $A_4$       $1$  $2$,  $A_2$  $A_5$ ---   $2$  $3$,  $A_3$  $A_6$ ---  $3$  $1$,         $A_i$     $A_{i-1}$,    ---   $A_{i+1}$. 	%     $\omega$    ,      $\omega$      \ref{t3}.",2502.01958
lemma,"     $\{1, 2\}, \{2, 3\}$  $\{3, 1\}$  $\omega$      ,     $1$   .",2502.01958
lemma,  $\gamma_1 \sim \gamma_2$       \[         |\operatorname{Ind} \gamma_1 - \operatorname{Ind} \gamma_2|\leq 1.     \],2502.01958
theorem,"Given an $[n, k, d]_{q}$ GRS code $\CC$ and $y \in \fq^{n}$, $\GRScover(\CC, y)$ returns a codeword $c \in \CC$ with $\dH(y, c) \le d - 1$.",2502.01984
theorem,"For an $[n, k, d]_{q}$ GRS code $\CC$ and a uniformly random $y \in \fq^{n}$, the expected number of punctures needed for $\GRScover(\CC, y)$ to succeed is               %\frac{(q - 1)^{\tau + 1}}{q^{\tau + 1 - k}}         \BE[P(\CC, y)]          &=          \sum_{i = 0}^{d - 1}          i \binom{n - i}{\tau_{i}}          \left(1 - \frac{1}{q}\right)^{\tau_{i} + i}          \left(\frac{1}{q}\right)^{n - i - \tau_{i}} \\          &= \frac{1}{q^{n}}         \sum_{i = 0}^{d - 1}          i \binom{n - i}{\tau_{i}}          (q - 1)^{i + \tau_{i}},           where $\tau_{i}$ is the decoding radius of $\GRSdecode(\CC_{i}, y^{(i)})$.",2502.01984
theorem,"Let $\CC$ be an $[n, k, d]_{q}$ MDS code. Then%,               \bigabs{\bigcup_{c \in \CC} B(c, \tau)}          \ge q^{k} \left(\sum_{i = 0}^{\tau} \binom{n}{i} (q - 1)^{i}          - \frac{1}{2} \sum_{w = d}^{2 \tau} A_{w} I(w, \tau)\right),           where %$A_{w}$ is the number of codewords of weight $w$, and $I(w, \tau)$ is the size of the intersection of two Hamming spheres whose centers are distance $w$ apart.               &A_{w}          = \binom{n}{w}          \sum_{j = 0}^{w - d} (-1)^{j}          \binom{w}{j} (q^{w - d + 1 - j} - 1)              and               & I(w, \tau) =           \\          &\hspace{-1mm} %\scalebox{.85}{         \resizebox{\hsize}{!}{         $\displaystyle \sum_{z = 0}^{n - w}          \binom{n - w}{z}          (q - 1)^{n - w - z}         \hspace{-3mm}         \sum_{             \substack{                 n - \tau - z \le u, v \le \tau                   \\                  %u, v \le \tau \\                   u + v \le w              }         } \binom{w}{u}          \binom{w - u}{v}         %\binom{w}{u, v, w - u - v}         (q - 2)^{w - u - v}$.}          \notag",2502.01984
proof,"Puncturing an $[n, k]$ GRS code at any coordinate gives an $[n - 1, k]$ GRS code.      Denote by $y^{(i)}$ and $\CC_{i}$ the %result of the puncturing on line \ref{line:punc} and $y[1..n-i]$     values of $y$ and $\CC$ on lines \ref{line:y} and \ref{line:punc}, respectively, at step $i$. %-th iteration.      Plainly,              \dH(y^{(i+1)}, \CC_{i + 1}(f))          &\le \dH(y^{(i)}, \CC_{i}(f))                    for any $i$.      %where $\CC$ is an $[n - i, k]$ $\GRS$ and $\CC'$ is the puncturing of $\CC$ at coordinate $n - i$.      If $\GRSdecode(\CC_{i}, y^{(i)})$ %on line~\ref{line:rsdecode}      is successful, then               \dH(y^{(i)}, \CC_{i}(f)) \le \dH(y, \CC(f)) \le d - 1           by repeated application of \eqref{eq:reduction}.      It remains to show that $\GRSdecode(\CC_{i}, y^{(i)})$ does indeed succeed for some $i < d$.           Note that               d_{\min}(\CC_{i + 1}) = d_{\min}(\CC_{i}) - 1% decreases by $1$ after each puncturing on line~\ref{line:punc}.                    for each $i$.      Hence, $\GRSdecode(\CC_{i}, y^{(i)})$ will succeed in at most $d - 1$ steps, since $d_{\min}(\CC_{i}) = 1$ when $i = d - 1$, at which point any $y^{(i)}$ becomes a valid codeword.     %it will eventually be dominated by the decoding radius of $\GRSdecode$, whence it will succeed.",2502.01984
proof,"%Let $X$ denote the random variable representing the number of punctures needed for $\GRScover$ to succeed.      %Then      Letting $f \in \CF(k - 1, q)$ with $\dH(y, \CC(f))$ minimal,               \Pr[P(\CC, y) = i]          &= \Pr[y_{j} \neq f(\alpha_{j}) \hbox{ for $\tau_{i}$ values of } j \le n - i \\          & \hspace{1.5cm}\hbox{and }  y_{j} \neq f(\alpha_{j})         \hbox{ for all $j > n - i$}         %, for some}\ f \in \CF(k - 1, q)         ] \\          &= %q^{k}          \binom{n - i}{\tau_{i}}          \left(1 - \frac{1}{q}\right)^{\tau_{i} + i}          \left(\frac{1}{q}\right)^{n - i - \tau_{i}}.           \hide{     So the expected number of punctures needed for \autoref{alg:GRS-cover} to succeed is               %\frac{(q - 1)^{\tau + 1}}{q^{\tau + 1 - k}}         \sum_{i = 0}^{d - 1}          i \binom{n - i}{\tau}          \left(1 - \frac{1}{q}\right)^{\tau + i}          \left(\frac{1}{q}\right)^{n - i - \tau}.           }(Alternatively,      the probability that a uniformly random $y \in \fq^{n}$ satisfies $y_{j} \neq f(\alpha_{j})$ for $\tau_{i}$ values of $j \le n - i$ and $y_{j} \neq f(\alpha_{j})$ for all $j > n - i$ is               %\sum_{i = 0}^{d - 1} i          \frac{1}{q^{n}}         \binom{n - i}{\tau_{i}}          (q - 1)^{\tau_{i} + i},           which is equal to $\Pr[P(\CC, y) = i]$ above.)      %the probability that $\GRScover(\CC, y)$ succeeds after $i$ punctures     \hide{So the expected number of steps for $\GRScover(\CC, y)$ to succeed is               \frac{1}{q^{n}}         \sum_{i = 0}^{d - 1} i          \binom{n - i}{\tau}          (q - 1)^{\tau + i}.           }The conclusion now follows from the definition of the expected value.",2502.01984
proof,"By the inclusion-exclusion principle, %\todo{make this a proposition/theorem}               \bigabs{\bigcup_{c \in \CC} B(c, \tau)}          &\ge \sum_{c \in \CC} |B(c, \tau)| - \frac{1}{2} \sum_{c_{1} \neq c_{2}} |B(c_{1}, \tau) \cap B(c_{2}, \tau)| \\          &= |\CC| \left(\sum_{i = 0}^{\tau} \binom{n}{i} (q - 1)^{i}          - \frac{1}{2} \sum_{w = d}^{2 \tau} A_{w} I(w, \tau)\right),           where $A_{w}$ is the number of codewords $c \in \CC$ of weight $w$, and $I(w, \tau) := |B(c_{1}, \tau) \cap B(c_{2}, \tau)|$ for $c_{1}, c_{2} \in \CC$ with $\dH(c_{1}, c_{2}) = w$.      %(\todo{There should be a power of $q - 2$ somewhere: done})      %\hide{The dominant term in the sum is obtained when $w = d$ (\todo{check this}), and i}     Now, \eqref{eq:weight-distribution} is known to hold for $d \le w \le n$ (e.g., see~\cite{Macwilliams77}), and \eqref{eq:intersection} follows by a counting argument, where $u$ (resp. $v$) represents the number of indices in $\{1, \dots, n\}$ where $y$ and $c_{1}$ (resp. $c_{2}$) agree, and $z$ represents the number of indices where $c_{1}$, $c_{2}$ and $y$ agree.      %\todo{expand upon this? Maybe if there is space.}",2502.01984
proof,"Observe that               A_{w}          &\le \binom{n}{w} q^{w - d}           by \eqref{eq:weight-distribution},      and               & I(w, \tau)          %= |B(c_{1}, \tau) \cap B(c_{2}, \tau)| =          \ \\          %&\hspace{-1cm}         %& %\scalebox{.85}{         %\resizebox{\hsize}{!}{         %$\displaystyle = \sum_{z = 0}^{n - w}          %\binom{n - w}{z}          %(q - 1)^{n - w - z}         %\hspace{-4mm}         %\sum_{         %    \substack{         %        n - \tau - z \le u, v \le \tau \\          %        u + v \le w          %    }         %} \binom{w}{u}          %\binom{w - u}{v}         %\binom{w}{u, v, w - u - v}         %(q - 2)^{w - u - v}          %(q - 1)^{n - z - u - v}          %&= \sum_{j = 0}^{n}          %\sum_{t = \max\{0, j - w\}}^{\min\{j, n - w\}}          %\binom{w}{j - t} \binom{n - w}{t}          %(q - 1)^{j + t}         %$} \\          &\resizebox{\hsize}{!}{$\displaystyle = \sum_{z = 0}^{n - w}          \binom{n - w}{z}          (q - 1)^{n - w - z}         %\hspace{-4mm}         \sum_{             %\substack{                 n - \tau - z \le u \le \tau %\\                  %u \le w              %}         } \binom{w}{u}          \sum_{             %\substack{                 n - \tau - z \le v \le \tau %\\                  %v \le w - u              %}         }          \binom{w - u}{v}         %\binom{w}{u, v, w - u - v}         (q - 2)^{w - u - v}$} \\          & %\resizebox{\hsize}{!}{$\displaystyle         \le \sum_{z = 0}^{n - w}          \binom{n - w}{z}          (q - 1)^{n - w - z}         %\hspace{-4mm}         \sum_{             %\substack{                 n - \tau - z \le u \le \tau %\\                  %u \le w              %}         } \binom{w}{u}          %\Vol_{q - 1}(\tau, w - u)         (q - 1)^{w - u}%$}          \\          &\resizebox{\hsize}{!}{$\displaystyle = \sum_{z = 0}^{n - w}          \binom{n - w}{z}          (q - 1)^{n - w - z}          [\Vol_{q}(\tau, w) - \Vol_{q}(n - \tau - z - 1, w)]$} \\          &\le          q^{n - w}          [\Vol_{q}(\tau, w) - \Vol_{q}(w - \tau - 1, w)]           by \eqref{eq:intersection}. The conclusion now follows from \autoref{thm:union-lower-bound}.",2502.01984
theorem,There exist $C^2$-smooth  convex cones with billiard trajectories having infinitely many reflections in finite time.,2502.01997
theorem,"The number of reflections of a trajectory inside $K_e$ with fixed values of the first integrals            I_1 = c_1>0 , \quad I_2 = c_2>0          is bounded by $N_{c_1,c_2}$, where     $$     N_{c_1,c_2} = \left\lceil      \frac{\pi}     {\arcsin      \frac{2 a b \sqrt{c_1 c_2}}     {a^2(b^2+1)c_1 + (b^2+1)c_2}     }      \right\rceil.     $$",2502.01997
lemma,"[Theorem 1, Lemma 2 in \cite{MY}]     Let $l \subset \mathbb{R}^n$ be an oriented line with direction vector ${v} = (v^1, \ldots, v^n)$, where $\|{v}\| = 1$. Define the function     $$   I = \sum_{1 \leq i < j \leq n} m_{i,j}^2,    $$     where $m_{i,j} := x^i v^j - x^j v^i$, $i < j$, $i,j = 1, \ldots, n$, and $x=(x^1, \ldots, x^n) \in l$.     Then $I$ is a first integral for the billiard trajectory inside $K$ and represents the square of the distance from $l$ to the origin.",2502.01997
lemma,"\item[1)]        For any $a \in \left(-\frac{\pi}{2}, \frac{\pi}{2}\right]$, there exists an integer $k_0(a)$ such that $t_k(a)$ is well-defined        (i.e., $\cos \left(a - \sum_{i=k}^\infty \theta_i \right) \neq 0$)       and positive for all $k \geq k_0(a)$.       \item[2)]        If $a \in \left(-\frac{\pi}{2}, \frac{\pi}{2}\right)$, then $t_k(a)$ converges to $\frac{1}{\cos a}$ as $k \to \infty$. Consequently, $p_k$ converges to a point $p=(\frac{1}{\cos a}, 0, \frac{1}{\cos a}) \in K_0$.       \item[3)]        If $a = \frac{\pi}{2}$, then $t_k(a)$ tends to infinity as $k \to \infty$.",2502.01997
lemma,\item[1)] The distance from $l_k$ to the origin equals $\sqrt{2}$ for all $k\geq k_0(a)$.     \item[2)] The lines $l_{k-1}$ and $l_{k}$ form the same angle with the vector $p_{k}$ for all $k > k_0(a)$.,2502.01997
lemma,"For $a \in \left(-\frac{\pi}{2}, \frac{\pi}{2}\right)$, we have    \sum_{k=k_0(a)}^{\infty} \|p_{k+1} - p_{k}\| =   \frac{\sqrt{2} \sin \left(\sum_{i=k_0(a)}^{\infty} \theta_i\right) }{\cos \left(a - \sum_{i=k_0(a)}^{\infty} \theta_i\right) \cos a}.",2502.01997
lemma,"We have the identity   $$   \sigma_k = b_k k^{-5/2},   $$   where $b_k \to \frac{3}{16}$ as $k \to \infty$.",2502.01997
lemma,"{\bf (Halpern)}   Consider a sequence of points    $q_k = (\cos \xi_k, \sin \xi_k)$ on the unit circle    $S^1 \subset \mathbb{R}^2$ with $\xi_k = k^{-1/2}$.    At each point $q_k$, a unit vector $w_k$ is assigned.    If the oriented angle $ \sigma_k $, measured counterclockwise from $z_k = -q_k $ to $ w_k $, satisfies            \left| \sigma_k \right| = b_k k^{-5/2}, \quad \text{with } b_k \to b > 0 \text{ as } k \to \infty,      then there exists $k_0 > 0$ and a strictly convex $C^2$-smooth closed curve    $ \gamma \subset \mathbb{R}^2 $ such that $ \gamma $ passes through $q_k$ for all $k \geq k_0$, with the unit normal vector at each $q_k$ given by $w_k$.",2502.01997
lemma,"Let $\tilde{K}^{n-1}$ be defined by (\ref{eq:rtilde}).    Then    $\tilde{\gamma}:= \tilde{K}^{n-1}\cap \mathcal{P}^{n-1}$ is a $C^2$-smooth, strictly convex, closed submanifold of $\mathcal{P}^{n-1}$ with nondegenerate second fundamental form.",2502.01997
lemma,"The Birkhoff billiard inside $K_e$    admits the first intergral 	$$   I_2 =    a^2 m_{2,3}^2 + b^2 m_{1,3}^2 - m_{1,2}^2. 	$$",2502.01997
lemma,"Let $l$ be an oriented line intersecting $K_e$ at points $p_1$ and $p_2$,    satisfying (\ref{eq:i-c}).   Then    $$   \angle p_1 O p_2    > \arcsin    \frac{2 a b \sqrt{c_1 c_2}}{a^2(b^2+1)c_1 + (b^2+1)c_2}.   $$",2502.01997
